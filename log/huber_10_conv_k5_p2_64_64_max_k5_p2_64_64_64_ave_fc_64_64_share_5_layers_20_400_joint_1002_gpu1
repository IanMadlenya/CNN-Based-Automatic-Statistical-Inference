Number of distributions:  20
Sample dimension:  400
model type:  joint
model architecture:  huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1
distribution
huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1
parameter
huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1
joint
huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1
Joint layer estimation
joint
huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0502 11:09:40.600687 26473 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 200000
lr_policy: "step"
gamma: 0.8
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 50000
snapshot_prefix: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/"
solver_mode: CPU
net: "./protocol/dis_20_400_dimension.protocol_parameter"
I0502 11:09:40.600888 26473 solver.cpp:91] Creating training net from net file: ./protocol/dis_20_400_dimension.protocol_parameter
I0502 11:09:40.601227 26473 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer intercept
I0502 11:09:40.601245 26473 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss
I0502 11:09:40.601330 26473 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "parameters"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_train-parameters-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HuberLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I0502 11:09:40.601384 26473 layer_factory.hpp:77] Creating layer parameters
I0502 11:09:40.601398 26473 net.cpp:94] Creating Layer parameters
I0502 11:09:40.601403 26473 net.cpp:409] parameters -> data
I0502 11:09:40.601413 26473 net.cpp:409] parameters -> label
I0502 11:09:40.601423 26473 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_train-parameters-path.txt
I0502 11:09:40.601438 26473 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0502 11:09:40.601883 26473 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0502 11:09:40.909896 26473 net.cpp:144] Setting up parameters
I0502 11:09:40.909927 26473 net.cpp:151] Top shape: 20 1 20 20 (8000)
I0502 11:09:40.909932 26473 net.cpp:151] Top shape: 20 (20)
I0502 11:09:40.909935 26473 net.cpp:159] Memory required for data: 32080
I0502 11:09:40.909941 26473 layer_factory.hpp:77] Creating layer conv1
I0502 11:09:40.909957 26473 net.cpp:94] Creating Layer conv1
I0502 11:09:40.909962 26473 net.cpp:435] conv1 <- data
I0502 11:09:40.909968 26473 net.cpp:409] conv1 -> conv1
I0502 11:09:40.915565 26473 net.cpp:144] Setting up conv1
I0502 11:09:40.915585 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:40.915590 26473 net.cpp:159] Memory required for data: 2080080
I0502 11:09:40.915599 26473 layer_factory.hpp:77] Creating layer relu1
I0502 11:09:40.915608 26473 net.cpp:94] Creating Layer relu1
I0502 11:09:40.915612 26473 net.cpp:435] relu1 <- conv1
I0502 11:09:40.915617 26473 net.cpp:396] relu1 -> conv1 (in-place)
I0502 11:09:40.915628 26473 net.cpp:144] Setting up relu1
I0502 11:09:40.915633 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:40.915637 26473 net.cpp:159] Memory required for data: 4128080
I0502 11:09:40.915639 26473 layer_factory.hpp:77] Creating layer conv2
I0502 11:09:40.915647 26473 net.cpp:94] Creating Layer conv2
I0502 11:09:40.915650 26473 net.cpp:435] conv2 <- conv1
I0502 11:09:40.915655 26473 net.cpp:409] conv2 -> conv2
I0502 11:09:40.926031 26473 net.cpp:144] Setting up conv2
I0502 11:09:40.926057 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:40.926064 26473 net.cpp:159] Memory required for data: 6176080
I0502 11:09:40.926080 26473 layer_factory.hpp:77] Creating layer relu2
I0502 11:09:40.926092 26473 net.cpp:94] Creating Layer relu2
I0502 11:09:40.926100 26473 net.cpp:435] relu2 <- conv2
I0502 11:09:40.926108 26473 net.cpp:396] relu2 -> conv2 (in-place)
I0502 11:09:40.926122 26473 net.cpp:144] Setting up relu2
I0502 11:09:40.926131 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:40.926136 26473 net.cpp:159] Memory required for data: 8224080
I0502 11:09:40.926142 26473 layer_factory.hpp:77] Creating layer pool2
I0502 11:09:40.926162 26473 net.cpp:94] Creating Layer pool2
I0502 11:09:40.926168 26473 net.cpp:435] pool2 <- conv2
I0502 11:09:40.926177 26473 net.cpp:409] pool2 -> pool2
I0502 11:09:40.926283 26473 net.cpp:144] Setting up pool2
I0502 11:09:40.926297 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.926303 26473 net.cpp:159] Memory required for data: 8736080
I0502 11:09:40.926311 26473 layer_factory.hpp:77] Creating layer conv3
I0502 11:09:40.926324 26473 net.cpp:94] Creating Layer conv3
I0502 11:09:40.926331 26473 net.cpp:435] conv3 <- pool2
I0502 11:09:40.926340 26473 net.cpp:409] conv3 -> conv3
I0502 11:09:40.931684 26473 net.cpp:144] Setting up conv3
I0502 11:09:40.931699 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.931702 26473 net.cpp:159] Memory required for data: 9248080
I0502 11:09:40.931710 26473 layer_factory.hpp:77] Creating layer relu3
I0502 11:09:40.931715 26473 net.cpp:94] Creating Layer relu3
I0502 11:09:40.931720 26473 net.cpp:435] relu3 <- conv3
I0502 11:09:40.931723 26473 net.cpp:396] relu3 -> conv3 (in-place)
I0502 11:09:40.931730 26473 net.cpp:144] Setting up relu3
I0502 11:09:40.931735 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.931737 26473 net.cpp:159] Memory required for data: 9760080
I0502 11:09:40.931740 26473 layer_factory.hpp:77] Creating layer conv4
I0502 11:09:40.931748 26473 net.cpp:94] Creating Layer conv4
I0502 11:09:40.931751 26473 net.cpp:435] conv4 <- conv3
I0502 11:09:40.931756 26473 net.cpp:409] conv4 -> conv4
I0502 11:09:40.937104 26473 net.cpp:144] Setting up conv4
I0502 11:09:40.937119 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.937121 26473 net.cpp:159] Memory required for data: 10272080
I0502 11:09:40.937127 26473 layer_factory.hpp:77] Creating layer relu4
I0502 11:09:40.937134 26473 net.cpp:94] Creating Layer relu4
I0502 11:09:40.937136 26473 net.cpp:435] relu4 <- conv4
I0502 11:09:40.937141 26473 net.cpp:396] relu4 -> conv4 (in-place)
I0502 11:09:40.937149 26473 net.cpp:144] Setting up relu4
I0502 11:09:40.937152 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.937155 26473 net.cpp:159] Memory required for data: 10784080
I0502 11:09:40.937158 26473 layer_factory.hpp:77] Creating layer conv5
I0502 11:09:40.937166 26473 net.cpp:94] Creating Layer conv5
I0502 11:09:40.937170 26473 net.cpp:435] conv5 <- conv4
I0502 11:09:40.937175 26473 net.cpp:409] conv5 -> conv5
I0502 11:09:40.943415 26473 net.cpp:144] Setting up conv5
I0502 11:09:40.943429 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.943434 26473 net.cpp:159] Memory required for data: 11296080
I0502 11:09:40.943442 26473 layer_factory.hpp:77] Creating layer relu5
I0502 11:09:40.943449 26473 net.cpp:94] Creating Layer relu5
I0502 11:09:40.943451 26473 net.cpp:435] relu5 <- conv5
I0502 11:09:40.943456 26473 net.cpp:396] relu5 -> conv5 (in-place)
I0502 11:09:40.943464 26473 net.cpp:144] Setting up relu5
I0502 11:09:40.943467 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:40.943470 26473 net.cpp:159] Memory required for data: 11808080
I0502 11:09:40.943473 26473 layer_factory.hpp:77] Creating layer pool5
I0502 11:09:40.943477 26473 net.cpp:94] Creating Layer pool5
I0502 11:09:40.943480 26473 net.cpp:435] pool5 <- conv5
I0502 11:09:40.943485 26473 net.cpp:409] pool5 -> pool5
I0502 11:09:40.943524 26473 net.cpp:144] Setting up pool5
I0502 11:09:40.943531 26473 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0502 11:09:40.943534 26473 net.cpp:159] Memory required for data: 11936080
I0502 11:09:40.943537 26473 layer_factory.hpp:77] Creating layer ip1
I0502 11:09:40.943544 26473 net.cpp:94] Creating Layer ip1
I0502 11:09:40.943547 26473 net.cpp:435] ip1 <- pool5
I0502 11:09:40.943552 26473 net.cpp:409] ip1 -> ip1
I0502 11:09:40.946074 26473 net.cpp:144] Setting up ip1
I0502 11:09:40.946082 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:40.946086 26473 net.cpp:159] Memory required for data: 11941200
I0502 11:09:40.946091 26473 layer_factory.hpp:77] Creating layer ip2
I0502 11:09:40.946097 26473 net.cpp:94] Creating Layer ip2
I0502 11:09:40.946105 26473 net.cpp:435] ip2 <- ip1
I0502 11:09:40.946110 26473 net.cpp:409] ip2 -> ip2
I0502 11:09:40.946313 26473 net.cpp:144] Setting up ip2
I0502 11:09:40.946321 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:40.946323 26473 net.cpp:159] Memory required for data: 11946320
I0502 11:09:40.946327 26473 layer_factory.hpp:77] Creating layer ip3
I0502 11:09:40.946333 26473 net.cpp:94] Creating Layer ip3
I0502 11:09:40.946336 26473 net.cpp:435] ip3 <- ip2
I0502 11:09:40.946341 26473 net.cpp:409] ip3 -> ip3
I0502 11:09:40.946439 26473 net.cpp:144] Setting up ip3
I0502 11:09:40.946445 26473 net.cpp:151] Top shape: 20 1 (20)
I0502 11:09:40.946449 26473 net.cpp:159] Memory required for data: 11946400
I0502 11:09:40.946454 26473 layer_factory.hpp:77] Creating layer loss
I0502 11:09:40.946462 26473 net.cpp:94] Creating Layer loss
I0502 11:09:40.946465 26473 net.cpp:435] loss <- ip3
I0502 11:09:40.946470 26473 net.cpp:435] loss <- label
I0502 11:09:40.946473 26473 net.cpp:409] loss -> loss
I0502 11:09:40.946522 26473 net.cpp:144] Setting up loss
I0502 11:09:40.946528 26473 net.cpp:151] Top shape: (1)
I0502 11:09:40.946532 26473 net.cpp:154]     with loss weight 1
I0502 11:09:40.946539 26473 net.cpp:159] Memory required for data: 11946404
I0502 11:09:40.946542 26473 net.cpp:220] loss needs backward computation.
I0502 11:09:40.946545 26473 net.cpp:220] ip3 needs backward computation.
I0502 11:09:40.946548 26473 net.cpp:220] ip2 needs backward computation.
I0502 11:09:40.946552 26473 net.cpp:220] ip1 needs backward computation.
I0502 11:09:40.946554 26473 net.cpp:220] pool5 needs backward computation.
I0502 11:09:40.946557 26473 net.cpp:220] relu5 needs backward computation.
I0502 11:09:40.946559 26473 net.cpp:220] conv5 needs backward computation.
I0502 11:09:40.946563 26473 net.cpp:220] relu4 needs backward computation.
I0502 11:09:40.946565 26473 net.cpp:220] conv4 needs backward computation.
I0502 11:09:40.946568 26473 net.cpp:220] relu3 needs backward computation.
I0502 11:09:40.946570 26473 net.cpp:220] conv3 needs backward computation.
I0502 11:09:40.946573 26473 net.cpp:220] pool2 needs backward computation.
I0502 11:09:40.946576 26473 net.cpp:220] relu2 needs backward computation.
I0502 11:09:40.946578 26473 net.cpp:220] conv2 needs backward computation.
I0502 11:09:40.946581 26473 net.cpp:220] relu1 needs backward computation.
I0502 11:09:40.946583 26473 net.cpp:220] conv1 needs backward computation.
I0502 11:09:40.946588 26473 net.cpp:222] parameters does not need backward computation.
I0502 11:09:40.946589 26473 net.cpp:264] This network produces output loss
I0502 11:09:40.946600 26473 net.cpp:284] Network initialization done.
I0502 11:09:40.946926 26473 solver.cpp:181] Creating test net (#0) specified by net file: ./protocol/dis_20_400_dimension.protocol_parameter
I0502 11:09:40.946954 26473 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer parameters
I0502 11:09:40.946965 26473 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0502 11:09:40.947049 26473 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "intercept"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_test-parameters-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HuberLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
  include {
    phase: TEST
  }
}
I0502 11:09:40.947098 26473 layer_factory.hpp:77] Creating layer intercept
I0502 11:09:40.947105 26473 net.cpp:94] Creating Layer intercept
I0502 11:09:40.947108 26473 net.cpp:409] intercept -> data
I0502 11:09:40.947114 26473 net.cpp:409] intercept -> label
I0502 11:09:40.947120 26473 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_test-parameters-path.txt
I0502 11:09:40.947139 26473 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0502 11:09:41.014487 26473 net.cpp:144] Setting up intercept
I0502 11:09:41.014516 26473 net.cpp:151] Top shape: 20 1 20 20 (8000)
I0502 11:09:41.014520 26473 net.cpp:151] Top shape: 20 (20)
I0502 11:09:41.014524 26473 net.cpp:159] Memory required for data: 32080
I0502 11:09:41.014530 26473 layer_factory.hpp:77] Creating layer conv1
I0502 11:09:41.014546 26473 net.cpp:94] Creating Layer conv1
I0502 11:09:41.014550 26473 net.cpp:435] conv1 <- data
I0502 11:09:41.014556 26473 net.cpp:409] conv1 -> conv1
I0502 11:09:41.015811 26473 net.cpp:144] Setting up conv1
I0502 11:09:41.015827 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.015830 26473 net.cpp:159] Memory required for data: 2080080
I0502 11:09:41.015841 26473 layer_factory.hpp:77] Creating layer relu1
I0502 11:09:41.015854 26473 net.cpp:94] Creating Layer relu1
I0502 11:09:41.015858 26473 net.cpp:435] relu1 <- conv1
I0502 11:09:41.015863 26473 net.cpp:396] relu1 -> conv1 (in-place)
I0502 11:09:41.015871 26473 net.cpp:144] Setting up relu1
I0502 11:09:41.015875 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.015878 26473 net.cpp:159] Memory required for data: 4128080
I0502 11:09:41.015882 26473 layer_factory.hpp:77] Creating layer conv2
I0502 11:09:41.015888 26473 net.cpp:94] Creating Layer conv2
I0502 11:09:41.015892 26473 net.cpp:435] conv2 <- conv1
I0502 11:09:41.015897 26473 net.cpp:409] conv2 -> conv2
I0502 11:09:41.020797 26473 net.cpp:144] Setting up conv2
I0502 11:09:41.020809 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.020813 26473 net.cpp:159] Memory required for data: 6176080
I0502 11:09:41.020822 26473 layer_factory.hpp:77] Creating layer relu2
I0502 11:09:41.020828 26473 net.cpp:94] Creating Layer relu2
I0502 11:09:41.020831 26473 net.cpp:435] relu2 <- conv2
I0502 11:09:41.020835 26473 net.cpp:396] relu2 -> conv2 (in-place)
I0502 11:09:41.020841 26473 net.cpp:144] Setting up relu2
I0502 11:09:41.020846 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.020848 26473 net.cpp:159] Memory required for data: 8224080
I0502 11:09:41.020851 26473 layer_factory.hpp:77] Creating layer pool2
I0502 11:09:41.020858 26473 net.cpp:94] Creating Layer pool2
I0502 11:09:41.020860 26473 net.cpp:435] pool2 <- conv2
I0502 11:09:41.020864 26473 net.cpp:409] pool2 -> pool2
I0502 11:09:41.020915 26473 net.cpp:144] Setting up pool2
I0502 11:09:41.020921 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.020925 26473 net.cpp:159] Memory required for data: 8736080
I0502 11:09:41.020927 26473 layer_factory.hpp:77] Creating layer conv3
I0502 11:09:41.020934 26473 net.cpp:94] Creating Layer conv3
I0502 11:09:41.020938 26473 net.cpp:435] conv3 <- pool2
I0502 11:09:41.020943 26473 net.cpp:409] conv3 -> conv3
I0502 11:09:41.024852 26473 net.cpp:144] Setting up conv3
I0502 11:09:41.024865 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.024869 26473 net.cpp:159] Memory required for data: 9248080
I0502 11:09:41.024878 26473 layer_factory.hpp:77] Creating layer relu3
I0502 11:09:41.024883 26473 net.cpp:94] Creating Layer relu3
I0502 11:09:41.024886 26473 net.cpp:435] relu3 <- conv3
I0502 11:09:41.024890 26473 net.cpp:396] relu3 -> conv3 (in-place)
I0502 11:09:41.024897 26473 net.cpp:144] Setting up relu3
I0502 11:09:41.024901 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.024904 26473 net.cpp:159] Memory required for data: 9760080
I0502 11:09:41.024907 26473 layer_factory.hpp:77] Creating layer conv4
I0502 11:09:41.024915 26473 net.cpp:94] Creating Layer conv4
I0502 11:09:41.024919 26473 net.cpp:435] conv4 <- conv3
I0502 11:09:41.024924 26473 net.cpp:409] conv4 -> conv4
I0502 11:09:41.028442 26473 net.cpp:144] Setting up conv4
I0502 11:09:41.028455 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.028458 26473 net.cpp:159] Memory required for data: 10272080
I0502 11:09:41.028465 26473 layer_factory.hpp:77] Creating layer relu4
I0502 11:09:41.028470 26473 net.cpp:94] Creating Layer relu4
I0502 11:09:41.028473 26473 net.cpp:435] relu4 <- conv4
I0502 11:09:41.028477 26473 net.cpp:396] relu4 -> conv4 (in-place)
I0502 11:09:41.028483 26473 net.cpp:144] Setting up relu4
I0502 11:09:41.028488 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.028491 26473 net.cpp:159] Memory required for data: 10784080
I0502 11:09:41.028493 26473 layer_factory.hpp:77] Creating layer conv5
I0502 11:09:41.028501 26473 net.cpp:94] Creating Layer conv5
I0502 11:09:41.028504 26473 net.cpp:435] conv5 <- conv4
I0502 11:09:41.028508 26473 net.cpp:409] conv5 -> conv5
I0502 11:09:41.033344 26473 net.cpp:144] Setting up conv5
I0502 11:09:41.033357 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.033361 26473 net.cpp:159] Memory required for data: 11296080
I0502 11:09:41.033370 26473 layer_factory.hpp:77] Creating layer relu5
I0502 11:09:41.033380 26473 net.cpp:94] Creating Layer relu5
I0502 11:09:41.033385 26473 net.cpp:435] relu5 <- conv5
I0502 11:09:41.033388 26473 net.cpp:396] relu5 -> conv5 (in-place)
I0502 11:09:41.033396 26473 net.cpp:144] Setting up relu5
I0502 11:09:41.033401 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.033403 26473 net.cpp:159] Memory required for data: 11808080
I0502 11:09:41.033406 26473 layer_factory.hpp:77] Creating layer pool5
I0502 11:09:41.033411 26473 net.cpp:94] Creating Layer pool5
I0502 11:09:41.033414 26473 net.cpp:435] pool5 <- conv5
I0502 11:09:41.033417 26473 net.cpp:409] pool5 -> pool5
I0502 11:09:41.033454 26473 net.cpp:144] Setting up pool5
I0502 11:09:41.033460 26473 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0502 11:09:41.033464 26473 net.cpp:159] Memory required for data: 11936080
I0502 11:09:41.033468 26473 layer_factory.hpp:77] Creating layer ip1
I0502 11:09:41.033473 26473 net.cpp:94] Creating Layer ip1
I0502 11:09:41.033476 26473 net.cpp:435] ip1 <- pool5
I0502 11:09:41.033481 26473 net.cpp:409] ip1 -> ip1
I0502 11:09:41.036023 26473 net.cpp:144] Setting up ip1
I0502 11:09:41.036031 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:41.036034 26473 net.cpp:159] Memory required for data: 11941200
I0502 11:09:41.036039 26473 layer_factory.hpp:77] Creating layer ip2
I0502 11:09:41.036046 26473 net.cpp:94] Creating Layer ip2
I0502 11:09:41.036048 26473 net.cpp:435] ip2 <- ip1
I0502 11:09:41.036053 26473 net.cpp:409] ip2 -> ip2
I0502 11:09:41.036267 26473 net.cpp:144] Setting up ip2
I0502 11:09:41.036273 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:41.036276 26473 net.cpp:159] Memory required for data: 11946320
I0502 11:09:41.036281 26473 layer_factory.hpp:77] Creating layer ip3
I0502 11:09:41.036286 26473 net.cpp:94] Creating Layer ip3
I0502 11:09:41.036289 26473 net.cpp:435] ip3 <- ip2
I0502 11:09:41.036294 26473 net.cpp:409] ip3 -> ip3
I0502 11:09:41.036401 26473 net.cpp:144] Setting up ip3
I0502 11:09:41.036406 26473 net.cpp:151] Top shape: 20 1 (20)
I0502 11:09:41.036409 26473 net.cpp:159] Memory required for data: 11946400
I0502 11:09:41.036414 26473 layer_factory.hpp:77] Creating layer loss
I0502 11:09:41.036422 26473 net.cpp:94] Creating Layer loss
I0502 11:09:41.036424 26473 net.cpp:435] loss <- ip3
I0502 11:09:41.036428 26473 net.cpp:435] loss <- label
I0502 11:09:41.036432 26473 net.cpp:409] loss -> loss
I0502 11:09:41.036484 26473 net.cpp:144] Setting up loss
I0502 11:09:41.036489 26473 net.cpp:151] Top shape: (1)
I0502 11:09:41.036492 26473 net.cpp:154]     with loss weight 1
I0502 11:09:41.036501 26473 net.cpp:159] Memory required for data: 11946404
I0502 11:09:41.036504 26473 net.cpp:220] loss needs backward computation.
I0502 11:09:41.036507 26473 net.cpp:220] ip3 needs backward computation.
I0502 11:09:41.036510 26473 net.cpp:220] ip2 needs backward computation.
I0502 11:09:41.036514 26473 net.cpp:220] ip1 needs backward computation.
I0502 11:09:41.036516 26473 net.cpp:220] pool5 needs backward computation.
I0502 11:09:41.036520 26473 net.cpp:220] relu5 needs backward computation.
I0502 11:09:41.036522 26473 net.cpp:220] conv5 needs backward computation.
I0502 11:09:41.036525 26473 net.cpp:220] relu4 needs backward computation.
I0502 11:09:41.036527 26473 net.cpp:220] conv4 needs backward computation.
I0502 11:09:41.036530 26473 net.cpp:220] relu3 needs backward computation.
I0502 11:09:41.036532 26473 net.cpp:220] conv3 needs backward computation.
I0502 11:09:41.036535 26473 net.cpp:220] pool2 needs backward computation.
I0502 11:09:41.036538 26473 net.cpp:220] relu2 needs backward computation.
I0502 11:09:41.036541 26473 net.cpp:220] conv2 needs backward computation.
I0502 11:09:41.036545 26473 net.cpp:220] relu1 needs backward computation.
I0502 11:09:41.036546 26473 net.cpp:220] conv1 needs backward computation.
I0502 11:09:41.036558 26473 net.cpp:222] intercept does not need backward computation.
I0502 11:09:41.036562 26473 net.cpp:264] This network produces output loss
I0502 11:09:41.036573 26473 net.cpp:284] Network initialization done.
I0502 11:09:41.036628 26473 solver.cpp:60] Solver scaffolding done.
I0502 11:09:41.037348 26473 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 200000
lr_policy: "step"
gamma: 0.8
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 50000
snapshot_prefix: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/"
solver_mode: CPU
net: "./protocol/dis_20_400_dimension.protocol_distribution"
I0502 11:09:41.037406 26473 solver.cpp:91] Creating training net from net file: ./protocol/dis_20_400_dimension.protocol_distribution
I0502 11:09:41.037706 26473 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer intercept
I0502 11:09:41.037722 26473 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0502 11:09:41.037811 26473 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "parameters"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_train-distributions-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0502 11:09:41.037864 26473 layer_factory.hpp:77] Creating layer parameters
I0502 11:09:41.037873 26473 net.cpp:94] Creating Layer parameters
I0502 11:09:41.037875 26473 net.cpp:409] parameters -> data
I0502 11:09:41.037883 26473 net.cpp:409] parameters -> label
I0502 11:09:41.037889 26473 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_train-distributions-path.txt
I0502 11:09:41.037904 26473 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0502 11:09:41.298806 26473 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0502 11:09:41.299860 26473 net.cpp:144] Setting up parameters
I0502 11:09:41.299875 26473 net.cpp:151] Top shape: 20 1 20 20 (8000)
I0502 11:09:41.299880 26473 net.cpp:151] Top shape: 20 (20)
I0502 11:09:41.299883 26473 net.cpp:159] Memory required for data: 32080
I0502 11:09:41.299888 26473 layer_factory.hpp:77] Creating layer conv1
I0502 11:09:41.299906 26473 net.cpp:94] Creating Layer conv1
I0502 11:09:41.299909 26473 net.cpp:435] conv1 <- data
I0502 11:09:41.299916 26473 net.cpp:409] conv1 -> conv1
I0502 11:09:41.302846 26473 net.cpp:144] Setting up conv1
I0502 11:09:41.302863 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.302866 26473 net.cpp:159] Memory required for data: 2080080
I0502 11:09:41.302877 26473 layer_factory.hpp:77] Creating layer relu1
I0502 11:09:41.302886 26473 net.cpp:94] Creating Layer relu1
I0502 11:09:41.302889 26473 net.cpp:435] relu1 <- conv1
I0502 11:09:41.302893 26473 net.cpp:396] relu1 -> conv1 (in-place)
I0502 11:09:41.302901 26473 net.cpp:144] Setting up relu1
I0502 11:09:41.302906 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.302908 26473 net.cpp:159] Memory required for data: 4128080
I0502 11:09:41.302911 26473 layer_factory.hpp:77] Creating layer conv2
I0502 11:09:41.302919 26473 net.cpp:94] Creating Layer conv2
I0502 11:09:41.302922 26473 net.cpp:435] conv2 <- conv1
I0502 11:09:41.302927 26473 net.cpp:409] conv2 -> conv2
I0502 11:09:41.313124 26473 net.cpp:144] Setting up conv2
I0502 11:09:41.313140 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.313143 26473 net.cpp:159] Memory required for data: 6176080
I0502 11:09:41.313153 26473 layer_factory.hpp:77] Creating layer relu2
I0502 11:09:41.313158 26473 net.cpp:94] Creating Layer relu2
I0502 11:09:41.313163 26473 net.cpp:435] relu2 <- conv2
I0502 11:09:41.313166 26473 net.cpp:396] relu2 -> conv2 (in-place)
I0502 11:09:41.313174 26473 net.cpp:144] Setting up relu2
I0502 11:09:41.313177 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.313180 26473 net.cpp:159] Memory required for data: 8224080
I0502 11:09:41.313184 26473 layer_factory.hpp:77] Creating layer pool2
I0502 11:09:41.313189 26473 net.cpp:94] Creating Layer pool2
I0502 11:09:41.313191 26473 net.cpp:435] pool2 <- conv2
I0502 11:09:41.313195 26473 net.cpp:409] pool2 -> pool2
I0502 11:09:41.313249 26473 net.cpp:144] Setting up pool2
I0502 11:09:41.313256 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.313259 26473 net.cpp:159] Memory required for data: 8736080
I0502 11:09:41.313262 26473 layer_factory.hpp:77] Creating layer conv3
I0502 11:09:41.313271 26473 net.cpp:94] Creating Layer conv3
I0502 11:09:41.313273 26473 net.cpp:435] conv3 <- pool2
I0502 11:09:41.313285 26473 net.cpp:409] conv3 -> conv3
I0502 11:09:41.319718 26473 net.cpp:144] Setting up conv3
I0502 11:09:41.319732 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.319736 26473 net.cpp:159] Memory required for data: 9248080
I0502 11:09:41.319743 26473 layer_factory.hpp:77] Creating layer relu3
I0502 11:09:41.319749 26473 net.cpp:94] Creating Layer relu3
I0502 11:09:41.319752 26473 net.cpp:435] relu3 <- conv3
I0502 11:09:41.319757 26473 net.cpp:396] relu3 -> conv3 (in-place)
I0502 11:09:41.319763 26473 net.cpp:144] Setting up relu3
I0502 11:09:41.319767 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.319771 26473 net.cpp:159] Memory required for data: 9760080
I0502 11:09:41.319773 26473 layer_factory.hpp:77] Creating layer conv4
I0502 11:09:41.319782 26473 net.cpp:94] Creating Layer conv4
I0502 11:09:41.319785 26473 net.cpp:435] conv4 <- conv3
I0502 11:09:41.319789 26473 net.cpp:409] conv4 -> conv4
I0502 11:09:41.325264 26473 net.cpp:144] Setting up conv4
I0502 11:09:41.325278 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.325283 26473 net.cpp:159] Memory required for data: 10272080
I0502 11:09:41.325289 26473 layer_factory.hpp:77] Creating layer relu4
I0502 11:09:41.325294 26473 net.cpp:94] Creating Layer relu4
I0502 11:09:41.325297 26473 net.cpp:435] relu4 <- conv4
I0502 11:09:41.325301 26473 net.cpp:396] relu4 -> conv4 (in-place)
I0502 11:09:41.325309 26473 net.cpp:144] Setting up relu4
I0502 11:09:41.325312 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.325315 26473 net.cpp:159] Memory required for data: 10784080
I0502 11:09:41.325318 26473 layer_factory.hpp:77] Creating layer conv5
I0502 11:09:41.325325 26473 net.cpp:94] Creating Layer conv5
I0502 11:09:41.325330 26473 net.cpp:435] conv5 <- conv4
I0502 11:09:41.325333 26473 net.cpp:409] conv5 -> conv5
I0502 11:09:41.330814 26473 net.cpp:144] Setting up conv5
I0502 11:09:41.330828 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.330832 26473 net.cpp:159] Memory required for data: 11296080
I0502 11:09:41.330839 26473 layer_factory.hpp:77] Creating layer relu5
I0502 11:09:41.330845 26473 net.cpp:94] Creating Layer relu5
I0502 11:09:41.330848 26473 net.cpp:435] relu5 <- conv5
I0502 11:09:41.330853 26473 net.cpp:396] relu5 -> conv5 (in-place)
I0502 11:09:41.330859 26473 net.cpp:144] Setting up relu5
I0502 11:09:41.330864 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.330868 26473 net.cpp:159] Memory required for data: 11808080
I0502 11:09:41.330870 26473 layer_factory.hpp:77] Creating layer pool5
I0502 11:09:41.330875 26473 net.cpp:94] Creating Layer pool5
I0502 11:09:41.330878 26473 net.cpp:435] pool5 <- conv5
I0502 11:09:41.330883 26473 net.cpp:409] pool5 -> pool5
I0502 11:09:41.330920 26473 net.cpp:144] Setting up pool5
I0502 11:09:41.330927 26473 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0502 11:09:41.330930 26473 net.cpp:159] Memory required for data: 11936080
I0502 11:09:41.330934 26473 layer_factory.hpp:77] Creating layer ip1
I0502 11:09:41.330940 26473 net.cpp:94] Creating Layer ip1
I0502 11:09:41.330943 26473 net.cpp:435] ip1 <- pool5
I0502 11:09:41.330947 26473 net.cpp:409] ip1 -> ip1
I0502 11:09:41.333503 26473 net.cpp:144] Setting up ip1
I0502 11:09:41.333513 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:41.333516 26473 net.cpp:159] Memory required for data: 11941200
I0502 11:09:41.333521 26473 layer_factory.hpp:77] Creating layer ip2
I0502 11:09:41.333528 26473 net.cpp:94] Creating Layer ip2
I0502 11:09:41.333530 26473 net.cpp:435] ip2 <- ip1
I0502 11:09:41.333535 26473 net.cpp:409] ip2 -> ip2
I0502 11:09:41.333758 26473 net.cpp:144] Setting up ip2
I0502 11:09:41.333765 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:41.333768 26473 net.cpp:159] Memory required for data: 11946320
I0502 11:09:41.333773 26473 layer_factory.hpp:77] Creating layer ip3
I0502 11:09:41.333778 26473 net.cpp:94] Creating Layer ip3
I0502 11:09:41.333781 26473 net.cpp:435] ip3 <- ip2
I0502 11:09:41.333786 26473 net.cpp:409] ip3 -> ip3
I0502 11:09:41.333987 26473 net.cpp:144] Setting up ip3
I0502 11:09:41.333995 26473 net.cpp:151] Top shape: 20 50 (1000)
I0502 11:09:41.333998 26473 net.cpp:159] Memory required for data: 11950320
I0502 11:09:41.334003 26473 layer_factory.hpp:77] Creating layer loss
I0502 11:09:41.334009 26473 net.cpp:94] Creating Layer loss
I0502 11:09:41.334013 26473 net.cpp:435] loss <- ip3
I0502 11:09:41.334017 26473 net.cpp:435] loss <- label
I0502 11:09:41.334022 26473 net.cpp:409] loss -> loss
I0502 11:09:41.334028 26473 layer_factory.hpp:77] Creating layer loss
I0502 11:09:41.334144 26473 net.cpp:144] Setting up loss
I0502 11:09:41.334151 26473 net.cpp:151] Top shape: (1)
I0502 11:09:41.334154 26473 net.cpp:154]     with loss weight 1
I0502 11:09:41.334164 26473 net.cpp:159] Memory required for data: 11950324
I0502 11:09:41.334167 26473 net.cpp:220] loss needs backward computation.
I0502 11:09:41.334170 26473 net.cpp:220] ip3 needs backward computation.
I0502 11:09:41.334173 26473 net.cpp:220] ip2 needs backward computation.
I0502 11:09:41.334177 26473 net.cpp:220] ip1 needs backward computation.
I0502 11:09:41.334179 26473 net.cpp:220] pool5 needs backward computation.
I0502 11:09:41.334182 26473 net.cpp:220] relu5 needs backward computation.
I0502 11:09:41.334185 26473 net.cpp:220] conv5 needs backward computation.
I0502 11:09:41.334187 26473 net.cpp:220] relu4 needs backward computation.
I0502 11:09:41.334190 26473 net.cpp:220] conv4 needs backward computation.
I0502 11:09:41.334193 26473 net.cpp:220] relu3 needs backward computation.
I0502 11:09:41.334195 26473 net.cpp:220] conv3 needs backward computation.
I0502 11:09:41.334198 26473 net.cpp:220] pool2 needs backward computation.
I0502 11:09:41.334202 26473 net.cpp:220] relu2 needs backward computation.
I0502 11:09:41.334204 26473 net.cpp:220] conv2 needs backward computation.
I0502 11:09:41.334208 26473 net.cpp:220] relu1 needs backward computation.
I0502 11:09:41.334210 26473 net.cpp:220] conv1 needs backward computation.
I0502 11:09:41.334213 26473 net.cpp:222] parameters does not need backward computation.
I0502 11:09:41.334216 26473 net.cpp:264] This network produces output loss
I0502 11:09:41.334226 26473 net.cpp:284] Network initialization done.
I0502 11:09:41.334556 26473 solver.cpp:181] Creating test net (#0) specified by net file: ./protocol/dis_20_400_dimension.protocol_distribution
I0502 11:09:41.334583 26473 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer parameters
I0502 11:09:41.334679 26473 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "intercept"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_test-distributions-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0502 11:09:41.334743 26473 layer_factory.hpp:77] Creating layer intercept
I0502 11:09:41.334750 26473 net.cpp:94] Creating Layer intercept
I0502 11:09:41.334754 26473 net.cpp:409] intercept -> data
I0502 11:09:41.334761 26473 net.cpp:409] intercept -> label
I0502 11:09:41.334767 26473 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/20_distributions_400_sample_size_test-distributions-path.txt
I0502 11:09:41.334785 26473 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0502 11:09:41.403470 26473 net.cpp:144] Setting up intercept
I0502 11:09:41.403504 26473 net.cpp:151] Top shape: 20 1 20 20 (8000)
I0502 11:09:41.403509 26473 net.cpp:151] Top shape: 20 (20)
I0502 11:09:41.403512 26473 net.cpp:159] Memory required for data: 32080
I0502 11:09:41.403518 26473 layer_factory.hpp:77] Creating layer label_intercept_1_split
I0502 11:09:41.403537 26473 net.cpp:94] Creating Layer label_intercept_1_split
I0502 11:09:41.403542 26473 net.cpp:435] label_intercept_1_split <- label
I0502 11:09:41.403548 26473 net.cpp:409] label_intercept_1_split -> label_intercept_1_split_0
I0502 11:09:41.403555 26473 net.cpp:409] label_intercept_1_split -> label_intercept_1_split_1
I0502 11:09:41.403597 26473 net.cpp:144] Setting up label_intercept_1_split
I0502 11:09:41.403604 26473 net.cpp:151] Top shape: 20 (20)
I0502 11:09:41.403606 26473 net.cpp:151] Top shape: 20 (20)
I0502 11:09:41.403609 26473 net.cpp:159] Memory required for data: 32240
I0502 11:09:41.403612 26473 layer_factory.hpp:77] Creating layer conv1
I0502 11:09:41.403623 26473 net.cpp:94] Creating Layer conv1
I0502 11:09:41.403626 26473 net.cpp:435] conv1 <- data
I0502 11:09:41.403631 26473 net.cpp:409] conv1 -> conv1
I0502 11:09:41.405020 26473 net.cpp:144] Setting up conv1
I0502 11:09:41.405040 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.405045 26473 net.cpp:159] Memory required for data: 2080240
I0502 11:09:41.405055 26473 layer_factory.hpp:77] Creating layer relu1
I0502 11:09:41.405061 26473 net.cpp:94] Creating Layer relu1
I0502 11:09:41.405066 26473 net.cpp:435] relu1 <- conv1
I0502 11:09:41.405069 26473 net.cpp:396] relu1 -> conv1 (in-place)
I0502 11:09:41.405076 26473 net.cpp:144] Setting up relu1
I0502 11:09:41.405081 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.405083 26473 net.cpp:159] Memory required for data: 4128240
I0502 11:09:41.405086 26473 layer_factory.hpp:77] Creating layer conv2
I0502 11:09:41.405094 26473 net.cpp:94] Creating Layer conv2
I0502 11:09:41.405097 26473 net.cpp:435] conv2 <- conv1
I0502 11:09:41.405102 26473 net.cpp:409] conv2 -> conv2
I0502 11:09:41.410166 26473 net.cpp:144] Setting up conv2
I0502 11:09:41.410178 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.410182 26473 net.cpp:159] Memory required for data: 6176240
I0502 11:09:41.410190 26473 layer_factory.hpp:77] Creating layer relu2
I0502 11:09:41.410197 26473 net.cpp:94] Creating Layer relu2
I0502 11:09:41.410199 26473 net.cpp:435] relu2 <- conv2
I0502 11:09:41.410203 26473 net.cpp:396] relu2 -> conv2 (in-place)
I0502 11:09:41.410210 26473 net.cpp:144] Setting up relu2
I0502 11:09:41.410214 26473 net.cpp:151] Top shape: 20 64 20 20 (512000)
I0502 11:09:41.410218 26473 net.cpp:159] Memory required for data: 8224240
I0502 11:09:41.410220 26473 layer_factory.hpp:77] Creating layer pool2
I0502 11:09:41.410226 26473 net.cpp:94] Creating Layer pool2
I0502 11:09:41.410229 26473 net.cpp:435] pool2 <- conv2
I0502 11:09:41.410233 26473 net.cpp:409] pool2 -> pool2
I0502 11:09:41.410287 26473 net.cpp:144] Setting up pool2
I0502 11:09:41.410293 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.410296 26473 net.cpp:159] Memory required for data: 8736240
I0502 11:09:41.410300 26473 layer_factory.hpp:77] Creating layer conv3
I0502 11:09:41.410307 26473 net.cpp:94] Creating Layer conv3
I0502 11:09:41.410310 26473 net.cpp:435] conv3 <- pool2
I0502 11:09:41.410315 26473 net.cpp:409] conv3 -> conv3
I0502 11:09:41.415218 26473 net.cpp:144] Setting up conv3
I0502 11:09:41.415232 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.415235 26473 net.cpp:159] Memory required for data: 9248240
I0502 11:09:41.415243 26473 layer_factory.hpp:77] Creating layer relu3
I0502 11:09:41.415251 26473 net.cpp:94] Creating Layer relu3
I0502 11:09:41.415253 26473 net.cpp:435] relu3 <- conv3
I0502 11:09:41.415258 26473 net.cpp:396] relu3 -> conv3 (in-place)
I0502 11:09:41.415264 26473 net.cpp:144] Setting up relu3
I0502 11:09:41.415269 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.415271 26473 net.cpp:159] Memory required for data: 9760240
I0502 11:09:41.415274 26473 layer_factory.hpp:77] Creating layer conv4
I0502 11:09:41.415282 26473 net.cpp:94] Creating Layer conv4
I0502 11:09:41.415285 26473 net.cpp:435] conv4 <- conv3
I0502 11:09:41.415289 26473 net.cpp:409] conv4 -> conv4
I0502 11:09:41.418853 26473 net.cpp:144] Setting up conv4
I0502 11:09:41.418865 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.418869 26473 net.cpp:159] Memory required for data: 10272240
I0502 11:09:41.418874 26473 layer_factory.hpp:77] Creating layer relu4
I0502 11:09:41.418880 26473 net.cpp:94] Creating Layer relu4
I0502 11:09:41.418884 26473 net.cpp:435] relu4 <- conv4
I0502 11:09:41.418889 26473 net.cpp:396] relu4 -> conv4 (in-place)
I0502 11:09:41.418895 26473 net.cpp:144] Setting up relu4
I0502 11:09:41.418900 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.418902 26473 net.cpp:159] Memory required for data: 10784240
I0502 11:09:41.418905 26473 layer_factory.hpp:77] Creating layer conv5
I0502 11:09:41.418912 26473 net.cpp:94] Creating Layer conv5
I0502 11:09:41.418915 26473 net.cpp:435] conv5 <- conv4
I0502 11:09:41.418920 26473 net.cpp:409] conv5 -> conv5
I0502 11:09:41.422925 26473 net.cpp:144] Setting up conv5
I0502 11:09:41.422943 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.422947 26473 net.cpp:159] Memory required for data: 11296240
I0502 11:09:41.422955 26473 layer_factory.hpp:77] Creating layer relu5
I0502 11:09:41.422960 26473 net.cpp:94] Creating Layer relu5
I0502 11:09:41.422965 26473 net.cpp:435] relu5 <- conv5
I0502 11:09:41.422968 26473 net.cpp:396] relu5 -> conv5 (in-place)
I0502 11:09:41.422976 26473 net.cpp:144] Setting up relu5
I0502 11:09:41.422979 26473 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0502 11:09:41.422982 26473 net.cpp:159] Memory required for data: 11808240
I0502 11:09:41.422986 26473 layer_factory.hpp:77] Creating layer pool5
I0502 11:09:41.422991 26473 net.cpp:94] Creating Layer pool5
I0502 11:09:41.422993 26473 net.cpp:435] pool5 <- conv5
I0502 11:09:41.422997 26473 net.cpp:409] pool5 -> pool5
I0502 11:09:41.423034 26473 net.cpp:144] Setting up pool5
I0502 11:09:41.423041 26473 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0502 11:09:41.423043 26473 net.cpp:159] Memory required for data: 11936240
I0502 11:09:41.423048 26473 layer_factory.hpp:77] Creating layer ip1
I0502 11:09:41.423053 26473 net.cpp:94] Creating Layer ip1
I0502 11:09:41.423056 26473 net.cpp:435] ip1 <- pool5
I0502 11:09:41.423061 26473 net.cpp:409] ip1 -> ip1
I0502 11:09:41.425622 26473 net.cpp:144] Setting up ip1
I0502 11:09:41.425631 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:41.425635 26473 net.cpp:159] Memory required for data: 11941360
I0502 11:09:41.425640 26473 layer_factory.hpp:77] Creating layer ip2
I0502 11:09:41.425647 26473 net.cpp:94] Creating Layer ip2
I0502 11:09:41.425649 26473 net.cpp:435] ip2 <- ip1
I0502 11:09:41.425654 26473 net.cpp:409] ip2 -> ip2
I0502 11:09:41.425886 26473 net.cpp:144] Setting up ip2
I0502 11:09:41.425894 26473 net.cpp:151] Top shape: 20 64 (1280)
I0502 11:09:41.425896 26473 net.cpp:159] Memory required for data: 11946480
I0502 11:09:41.425901 26473 layer_factory.hpp:77] Creating layer ip3
I0502 11:09:41.425909 26473 net.cpp:94] Creating Layer ip3
I0502 11:09:41.425912 26473 net.cpp:435] ip3 <- ip2
I0502 11:09:41.425917 26473 net.cpp:409] ip3 -> ip3
I0502 11:09:41.426128 26473 net.cpp:144] Setting up ip3
I0502 11:09:41.426136 26473 net.cpp:151] Top shape: 20 50 (1000)
I0502 11:09:41.426138 26473 net.cpp:159] Memory required for data: 11950480
I0502 11:09:41.426142 26473 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0502 11:09:41.426149 26473 net.cpp:94] Creating Layer ip3_ip3_0_split
I0502 11:09:41.426152 26473 net.cpp:435] ip3_ip3_0_split <- ip3
I0502 11:09:41.426156 26473 net.cpp:409] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0502 11:09:41.426162 26473 net.cpp:409] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0502 11:09:41.426203 26473 net.cpp:144] Setting up ip3_ip3_0_split
I0502 11:09:41.426208 26473 net.cpp:151] Top shape: 20 50 (1000)
I0502 11:09:41.426211 26473 net.cpp:151] Top shape: 20 50 (1000)
I0502 11:09:41.426214 26473 net.cpp:159] Memory required for data: 11958480
I0502 11:09:41.426218 26473 layer_factory.hpp:77] Creating layer accuracy
I0502 11:09:41.426223 26473 net.cpp:94] Creating Layer accuracy
I0502 11:09:41.426228 26473 net.cpp:435] accuracy <- ip3_ip3_0_split_0
I0502 11:09:41.426230 26473 net.cpp:435] accuracy <- label_intercept_1_split_0
I0502 11:09:41.426235 26473 net.cpp:409] accuracy -> accuracy
I0502 11:09:41.426242 26473 net.cpp:144] Setting up accuracy
I0502 11:09:41.426247 26473 net.cpp:151] Top shape: (1)
I0502 11:09:41.426250 26473 net.cpp:159] Memory required for data: 11958484
I0502 11:09:41.426254 26473 layer_factory.hpp:77] Creating layer loss
I0502 11:09:41.426257 26473 net.cpp:94] Creating Layer loss
I0502 11:09:41.426260 26473 net.cpp:435] loss <- ip3_ip3_0_split_1
I0502 11:09:41.426265 26473 net.cpp:435] loss <- label_intercept_1_split_1
I0502 11:09:41.426268 26473 net.cpp:409] loss -> loss
I0502 11:09:41.426275 26473 layer_factory.hpp:77] Creating layer loss
I0502 11:09:41.426391 26473 net.cpp:144] Setting up loss
I0502 11:09:41.426398 26473 net.cpp:151] Top shape: (1)
I0502 11:09:41.426400 26473 net.cpp:154]     with loss weight 1
I0502 11:09:41.426414 26473 net.cpp:159] Memory required for data: 11958488
I0502 11:09:41.426416 26473 net.cpp:220] loss needs backward computation.
I0502 11:09:41.426419 26473 net.cpp:222] accuracy does not need backward computation.
I0502 11:09:41.426424 26473 net.cpp:220] ip3_ip3_0_split needs backward computation.
I0502 11:09:41.426425 26473 net.cpp:220] ip3 needs backward computation.
I0502 11:09:41.426429 26473 net.cpp:220] ip2 needs backward computation.
I0502 11:09:41.426431 26473 net.cpp:220] ip1 needs backward computation.
I0502 11:09:41.426434 26473 net.cpp:220] pool5 needs backward computation.
I0502 11:09:41.426436 26473 net.cpp:220] relu5 needs backward computation.
I0502 11:09:41.426440 26473 net.cpp:220] conv5 needs backward computation.
I0502 11:09:41.426442 26473 net.cpp:220] relu4 needs backward computation.
I0502 11:09:41.426445 26473 net.cpp:220] conv4 needs backward computation.
I0502 11:09:41.426447 26473 net.cpp:220] relu3 needs backward computation.
I0502 11:09:41.426450 26473 net.cpp:220] conv3 needs backward computation.
I0502 11:09:41.426453 26473 net.cpp:220] pool2 needs backward computation.
I0502 11:09:41.426455 26473 net.cpp:220] relu2 needs backward computation.
I0502 11:09:41.426458 26473 net.cpp:220] conv2 needs backward computation.
I0502 11:09:41.426461 26473 net.cpp:220] relu1 needs backward computation.
I0502 11:09:41.426463 26473 net.cpp:220] conv1 needs backward computation.
I0502 11:09:41.426467 26473 net.cpp:222] label_intercept_1_split does not need backward computation.
I0502 11:09:41.426470 26473 net.cpp:222] intercept does not need backward computation.
I0502 11:09:41.426472 26473 net.cpp:264] This network produces output accuracy
I0502 11:09:41.426476 26473 net.cpp:264] This network produces output loss
I0502 11:09:41.426492 26473 net.cpp:284] Network initialization done.
I0502 11:09:41.426553 26473 solver.cpp:60] Solver scaffolding done.
I0502 11:09:41.430351 26473 solver.cpp:362] Iteration 0, Testing net (#0)
I0502 11:09:41.430366 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:41.603863 26473 solver.cpp:429]     Test net output #0: loss = 11.6034 (* 1 = 11.6034 loss)
I0502 11:09:41.624013 26473 solver.cpp:242] Iteration 0 (0 iter/s, 0.194332s/100 iter), loss = 9.0614
I0502 11:09:41.624037 26473 solver.cpp:261]     Train net output #0: loss = 9.0614 (* 1 = 9.0614 loss)
I0502 11:09:41.624047 26473 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0502 11:09:41.627017 26473 solver.cpp:362] Iteration 0, Testing net (#0)
I0502 11:09:41.627032 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:41.799530 26473 solver.cpp:429]     Test net output #0: accuracy = 0
I0502 11:09:41.799552 26473 solver.cpp:429]     Test net output #1: loss = 3.91204 (* 1 = 3.91204 loss)
I0502 11:09:41.819707 26473 solver.cpp:242] Iteration 0 (0 iter/s, 0.193384s/100 iter), loss = 3.91204
I0502 11:09:41.819730 26473 solver.cpp:261]     Train net output #0: loss = 3.91204 (* 1 = 3.91204 loss)
I0502 11:09:41.819739 26473 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0502 11:09:42.846201 26473 solver.cpp:242] Iteration 100 (81.8251 iter/s, 1.22212s/100 iter), loss = 10.027
I0502 11:09:42.846248 26473 solver.cpp:261]     Train net output #0: loss = 10.027 (* 1 = 10.027 loss)
I0502 11:09:42.846258 26473 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0502 11:09:42.851065 26473 solver.cpp:242] Iteration 100 (96.9636 iter/s, 1.03131s/100 iter), loss = 3.91394
I0502 11:09:42.851089 26473 solver.cpp:261]     Train net output #0: loss = 3.91394 (* 1 = 3.91394 loss)
I0502 11:09:42.851096 26473 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0502 11:09:43.824493 26473 solver.cpp:242] Iteration 200 (102.227 iter/s, 0.978219s/100 iter), loss = 7.95502
I0502 11:09:43.824534 26473 solver.cpp:261]     Train net output #0: loss = 7.95502 (* 1 = 7.95502 loss)
I0502 11:09:43.824543 26473 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0502 11:09:43.829465 26473 solver.cpp:242] Iteration 200 (102.212 iter/s, 0.978358s/100 iter), loss = 3.99256
I0502 11:09:43.829496 26473 solver.cpp:261]     Train net output #0: loss = 3.99256 (* 1 = 3.99256 loss)
I0502 11:09:43.829505 26473 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0502 11:09:44.780146 26473 solver.cpp:242] Iteration 300 (104.648 iter/s, 0.955587s/100 iter), loss = 5.88507
I0502 11:09:44.780190 26473 solver.cpp:261]     Train net output #0: loss = 5.88507 (* 1 = 5.88507 loss)
I0502 11:09:44.780200 26473 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0502 11:09:44.785012 26473 solver.cpp:242] Iteration 300 (104.658 iter/s, 0.955497s/100 iter), loss = 3.61215
I0502 11:09:44.785033 26473 solver.cpp:261]     Train net output #0: loss = 3.61215 (* 1 = 3.61215 loss)
I0502 11:09:44.785043 26473 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0502 11:09:45.734378 26473 solver.cpp:242] Iteration 400 (104.804 iter/s, 0.954166s/100 iter), loss = 4.9634
I0502 11:09:45.734436 26473 solver.cpp:261]     Train net output #0: loss = 4.9634 (* 1 = 4.9634 loss)
I0502 11:09:45.734446 26473 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0502 11:09:45.739301 26473 solver.cpp:242] Iteration 400 (104.794 iter/s, 0.954249s/100 iter), loss = 3.66636
I0502 11:09:45.739326 26473 solver.cpp:261]     Train net output #0: loss = 3.66636 (* 1 = 3.66636 loss)
I0502 11:09:45.739334 26473 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0502 11:09:46.685575 26473 solver.cpp:362] Iteration 500, Testing net (#0)
I0502 11:09:46.685602 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:46.810675 26473 solver.cpp:429]     Test net output #0: loss = 5.29775 (* 1 = 5.29775 loss)
I0502 11:09:46.813561 26473 solver.cpp:242] Iteration 500 (92.6692 iter/s, 1.07911s/100 iter), loss = 4.00657
I0502 11:09:46.813582 26473 solver.cpp:261]     Train net output #0: loss = 4.00657 (* 1 = 4.00657 loss)
I0502 11:09:46.813591 26473 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0502 11:09:46.815243 26473 solver.cpp:362] Iteration 500, Testing net (#0)
I0502 11:09:46.815256 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:46.946442 26473 solver.cpp:429]     Test net output #0: accuracy = 0.0505
I0502 11:09:46.946465 26473 solver.cpp:429]     Test net output #1: loss = 3.17783 (* 1 = 3.17783 loss)
I0502 11:09:46.949404 26473 solver.cpp:242] Iteration 500 (82.6407 iter/s, 1.21006s/100 iter), loss = 2.99577
I0502 11:09:46.949424 26473 solver.cpp:261]     Train net output #0: loss = 2.99577 (* 1 = 2.99577 loss)
I0502 11:09:46.949432 26473 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0502 11:09:47.899021 26473 solver.cpp:242] Iteration 600 (92.1305 iter/s, 1.08542s/100 iter), loss = 4.52603
I0502 11:09:47.899055 26473 solver.cpp:261]     Train net output #0: loss = 4.52603 (* 1 = 4.52603 loss)
I0502 11:09:47.899063 26473 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0502 11:09:47.903872 26473 solver.cpp:242] Iteration 600 (104.775 iter/s, 0.954429s/100 iter), loss = 3.26881
I0502 11:09:47.903897 26473 solver.cpp:261]     Train net output #0: loss = 3.26881 (* 1 = 3.26881 loss)
I0502 11:09:47.903904 26473 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0502 11:09:48.853567 26473 solver.cpp:242] Iteration 700 (104.768 iter/s, 0.95449s/100 iter), loss = 4.2167
I0502 11:09:48.853610 26473 solver.cpp:261]     Train net output #0: loss = 4.2167 (* 1 = 4.2167 loss)
I0502 11:09:48.853618 26473 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0502 11:09:48.858521 26473 solver.cpp:242] Iteration 700 (104.755 iter/s, 0.954608s/100 iter), loss = 2.80026
I0502 11:09:48.858544 26473 solver.cpp:261]     Train net output #0: loss = 2.80026 (* 1 = 2.80026 loss)
I0502 11:09:48.858552 26473 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0502 11:09:49.807548 26473 solver.cpp:242] Iteration 800 (104.831 iter/s, 0.953917s/100 iter), loss = 4.59037
I0502 11:09:49.807590 26473 solver.cpp:261]     Train net output #0: loss = 4.59037 (* 1 = 4.59037 loss)
I0502 11:09:49.807598 26473 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0502 11:09:49.812491 26473 solver.cpp:242] Iteration 800 (104.83 iter/s, 0.953929s/100 iter), loss = 2.99728
I0502 11:09:49.812513 26473 solver.cpp:261]     Train net output #0: loss = 2.99728 (* 1 = 2.99728 loss)
I0502 11:09:49.812541 26473 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0502 11:09:50.763805 26473 solver.cpp:242] Iteration 900 (104.581 iter/s, 0.956195s/100 iter), loss = 5.38264
I0502 11:09:50.763836 26473 solver.cpp:261]     Train net output #0: loss = 5.38264 (* 1 = 5.38264 loss)
I0502 11:09:50.763844 26473 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0502 11:09:50.768723 26473 solver.cpp:242] Iteration 900 (104.582 iter/s, 0.956191s/100 iter), loss = 2.62694
I0502 11:09:50.768745 26473 solver.cpp:261]     Train net output #0: loss = 2.62694 (* 1 = 2.62694 loss)
I0502 11:09:50.768754 26473 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0502 11:09:51.714622 26473 solver.cpp:362] Iteration 1000, Testing net (#0)
I0502 11:09:51.714653 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:51.839593 26473 solver.cpp:429]     Test net output #0: loss = 5.76997 (* 1 = 5.76997 loss)
I0502 11:09:51.842483 26473 solver.cpp:242] Iteration 1000 (92.7103 iter/s, 1.07863s/100 iter), loss = 6.10506
I0502 11:09:51.842504 26473 solver.cpp:261]     Train net output #0: loss = 6.10506 (* 1 = 6.10506 loss)
I0502 11:09:51.842512 26473 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0502 11:09:51.844159 26473 solver.cpp:362] Iteration 1000, Testing net (#0)
I0502 11:09:51.844172 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:51.975324 26473 solver.cpp:429]     Test net output #0: accuracy = 0.0925
I0502 11:09:51.975347 26473 solver.cpp:429]     Test net output #1: loss = 2.84279 (* 1 = 2.84279 loss)
I0502 11:09:51.978269 26473 solver.cpp:242] Iteration 1000 (82.6786 iter/s, 1.2095s/100 iter), loss = 2.9487
I0502 11:09:51.978289 26473 solver.cpp:261]     Train net output #0: loss = 2.9487 (* 1 = 2.9487 loss)
I0502 11:09:51.978297 26473 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0502 11:09:52.927393 26473 solver.cpp:242] Iteration 1100 (92.1773 iter/s, 1.08487s/100 iter), loss = 2.89689
I0502 11:09:52.927434 26473 solver.cpp:261]     Train net output #0: loss = 2.89689 (* 1 = 2.89689 loss)
I0502 11:09:52.927443 26473 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0502 11:09:52.932258 26473 solver.cpp:242] Iteration 1100 (104.828 iter/s, 0.953945s/100 iter), loss = 2.89313
I0502 11:09:52.932282 26473 solver.cpp:261]     Train net output #0: loss = 2.89313 (* 1 = 2.89313 loss)
I0502 11:09:52.932291 26473 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0502 11:09:53.882051 26473 solver.cpp:242] Iteration 1200 (104.756 iter/s, 0.954597s/100 iter), loss = 5.1292
I0502 11:09:53.882083 26473 solver.cpp:261]     Train net output #0: loss = 5.1292 (* 1 = 5.1292 loss)
I0502 11:09:53.882092 26473 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0502 11:09:53.886950 26473 solver.cpp:242] Iteration 1200 (104.751 iter/s, 0.954649s/100 iter), loss = 2.81887
I0502 11:09:53.886973 26473 solver.cpp:261]     Train net output #0: loss = 2.81887 (* 1 = 2.81887 loss)
I0502 11:09:53.886981 26473 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0502 11:09:54.836920 26473 solver.cpp:242] Iteration 1300 (104.732 iter/s, 0.954814s/100 iter), loss = 4.17712
I0502 11:09:54.836966 26473 solver.cpp:261]     Train net output #0: loss = 4.17712 (* 1 = 4.17712 loss)
I0502 11:09:54.836974 26473 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0502 11:09:54.841856 26473 solver.cpp:242] Iteration 1300 (104.727 iter/s, 0.954864s/100 iter), loss = 2.61122
I0502 11:09:54.841878 26473 solver.cpp:261]     Train net output #0: loss = 2.61122 (* 1 = 2.61122 loss)
I0502 11:09:54.841886 26473 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0502 11:09:55.793714 26473 solver.cpp:242] Iteration 1400 (104.523 iter/s, 0.956726s/100 iter), loss = 7.39054
I0502 11:09:55.793771 26473 solver.cpp:261]     Train net output #0: loss = 7.39054 (* 1 = 7.39054 loss)
I0502 11:09:55.793781 26473 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0502 11:09:55.798637 26473 solver.cpp:242] Iteration 1400 (104.522 iter/s, 0.956741s/100 iter), loss = 2.59166
I0502 11:09:55.798660 26473 solver.cpp:261]     Train net output #0: loss = 2.59166 (* 1 = 2.59166 loss)
I0502 11:09:55.798676 26473 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0502 11:09:56.745713 26473 solver.cpp:362] Iteration 1500, Testing net (#0)
I0502 11:09:56.745736 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:56.870685 26473 solver.cpp:429]     Test net output #0: loss = 5.49045 (* 1 = 5.49045 loss)
I0502 11:09:56.873564 26473 solver.cpp:242] Iteration 1500 (92.612 iter/s, 1.07977s/100 iter), loss = 5.24721
I0502 11:09:56.873584 26473 solver.cpp:261]     Train net output #0: loss = 5.24721 (* 1 = 5.24721 loss)
I0502 11:09:56.873592 26473 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0502 11:09:56.875257 26473 solver.cpp:362] Iteration 1500, Testing net (#0)
I0502 11:09:56.875269 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:09:57.006448 26473 solver.cpp:429]     Test net output #0: accuracy = 0.1385
I0502 11:09:57.006469 26473 solver.cpp:429]     Test net output #1: loss = 2.59916 (* 1 = 2.59916 loss)
I0502 11:09:57.009408 26473 solver.cpp:242] Iteration 1500 (82.595 iter/s, 1.21073s/100 iter), loss = 2.61902
I0502 11:09:57.009429 26473 solver.cpp:261]     Train net output #0: loss = 2.61902 (* 1 = 2.61902 loss)
I0502 11:09:57.009438 26473 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0502 11:09:57.958922 26473 solver.cpp:242] Iteration 1600 (92.1392 iter/s, 1.08531s/100 iter), loss = 4.99391
I0502 11:09:57.958964 26473 solver.cpp:261]     Train net output #0: loss = 4.99391 (* 1 = 4.99391 loss)
I0502 11:09:57.958972 26473 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0502 11:09:57.963781 26473 solver.cpp:242] Iteration 1600 (104.785 iter/s, 0.954334s/100 iter), loss = 2.48337
I0502 11:09:57.963804 26473 solver.cpp:261]     Train net output #0: loss = 2.48337 (* 1 = 2.48337 loss)
I0502 11:09:57.963812 26473 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0502 11:09:58.912119 26473 solver.cpp:242] Iteration 1700 (104.917 iter/s, 0.953134s/100 iter), loss = 5.39392
I0502 11:09:58.912161 26473 solver.cpp:261]     Train net output #0: loss = 5.39392 (* 1 = 5.39392 loss)
I0502 11:09:58.912170 26473 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0502 11:09:58.916997 26473 solver.cpp:242] Iteration 1700 (104.913 iter/s, 0.953174s/100 iter), loss = 2.63678
I0502 11:09:58.917021 26473 solver.cpp:261]     Train net output #0: loss = 2.63678 (* 1 = 2.63678 loss)
I0502 11:09:58.917029 26473 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0502 11:09:59.865998 26473 solver.cpp:242] Iteration 1800 (104.842 iter/s, 0.953817s/100 iter), loss = 3.58832
I0502 11:09:59.866029 26473 solver.cpp:261]     Train net output #0: loss = 3.58832 (* 1 = 3.58832 loss)
I0502 11:09:59.866039 26473 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0502 11:09:59.870923 26473 solver.cpp:242] Iteration 1800 (104.835 iter/s, 0.953884s/100 iter), loss = 2.59447
I0502 11:09:59.870947 26473 solver.cpp:261]     Train net output #0: loss = 2.59447 (* 1 = 2.59447 loss)
I0502 11:09:59.870955 26473 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0502 11:10:00.836256 26473 solver.cpp:242] Iteration 1900 (103.071 iter/s, 0.970203s/100 iter), loss = 4.08239
I0502 11:10:00.836304 26473 solver.cpp:261]     Train net output #0: loss = 4.08239 (* 1 = 4.08239 loss)
I0502 11:10:00.836314 26473 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0502 11:10:00.841178 26473 solver.cpp:242] Iteration 1900 (103.07 iter/s, 0.970212s/100 iter), loss = 2.20409
I0502 11:10:00.841202 26473 solver.cpp:261]     Train net output #0: loss = 2.20409 (* 1 = 2.20409 loss)
I0502 11:10:00.841210 26473 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0502 11:10:01.787818 26473 solver.cpp:362] Iteration 2000, Testing net (#0)
I0502 11:10:01.787848 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:01.912820 26473 solver.cpp:429]     Test net output #0: loss = 4.91105 (* 1 = 4.91105 loss)
I0502 11:10:01.915701 26473 solver.cpp:242] Iteration 2000 (92.6459 iter/s, 1.07938s/100 iter), loss = 6.14258
I0502 11:10:01.915721 26473 solver.cpp:261]     Train net output #0: loss = 6.14258 (* 1 = 6.14258 loss)
I0502 11:10:01.915738 26473 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0502 11:10:01.917397 26473 solver.cpp:362] Iteration 2000, Testing net (#0)
I0502 11:10:01.917410 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:02.048570 26473 solver.cpp:429]     Test net output #0: accuracy = 0.1985
I0502 11:10:02.048593 26473 solver.cpp:429]     Test net output #1: loss = 2.40404 (* 1 = 2.40404 loss)
I0502 11:10:02.051542 26473 solver.cpp:242] Iteration 2000 (82.623 iter/s, 1.21032s/100 iter), loss = 2.27998
I0502 11:10:02.051560 26473 solver.cpp:261]     Train net output #0: loss = 2.27998 (* 1 = 2.27998 loss)
I0502 11:10:02.051569 26473 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0502 11:10:03.002420 26473 solver.cpp:242] Iteration 2100 (92.0239 iter/s, 1.08667s/100 iter), loss = 4.599
I0502 11:10:03.002460 26473 solver.cpp:261]     Train net output #0: loss = 4.599 (* 1 = 4.599 loss)
I0502 11:10:03.002470 26473 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0502 11:10:03.007325 26473 solver.cpp:242] Iteration 2100 (104.63 iter/s, 0.955745s/100 iter), loss = 2.61277
I0502 11:10:03.007349 26473 solver.cpp:261]     Train net output #0: loss = 2.61277 (* 1 = 2.61277 loss)
I0502 11:10:03.007357 26473 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0502 11:10:03.957595 26473 solver.cpp:242] Iteration 2200 (104.7 iter/s, 0.955109s/100 iter), loss = 4.80736
I0502 11:10:03.957638 26473 solver.cpp:261]     Train net output #0: loss = 4.80736 (* 1 = 4.80736 loss)
I0502 11:10:03.957648 26473 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0502 11:10:03.962436 26473 solver.cpp:242] Iteration 2200 (104.705 iter/s, 0.955068s/100 iter), loss = 2.20794
I0502 11:10:03.962458 26473 solver.cpp:261]     Train net output #0: loss = 2.20794 (* 1 = 2.20794 loss)
I0502 11:10:03.962466 26473 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0502 11:10:04.911273 26473 solver.cpp:242] Iteration 2300 (104.864 iter/s, 0.953613s/100 iter), loss = 5.73037
I0502 11:10:04.911315 26473 solver.cpp:261]     Train net output #0: loss = 5.73037 (* 1 = 5.73037 loss)
I0502 11:10:04.911324 26473 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0502 11:10:04.916306 26473 solver.cpp:242] Iteration 2300 (104.841 iter/s, 0.953828s/100 iter), loss = 2.53783
I0502 11:10:04.916329 26473 solver.cpp:261]     Train net output #0: loss = 2.53783 (* 1 = 2.53783 loss)
I0502 11:10:04.916338 26473 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0502 11:10:05.867391 26473 solver.cpp:242] Iteration 2400 (104.596 iter/s, 0.956056s/100 iter), loss = 8.26964
I0502 11:10:05.867424 26473 solver.cpp:261]     Train net output #0: loss = 8.26964 (* 1 = 8.26964 loss)
I0502 11:10:05.867431 26473 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0502 11:10:05.872262 26473 solver.cpp:242] Iteration 2400 (104.612 iter/s, 0.955915s/100 iter), loss = 2.30608
I0502 11:10:05.872285 26473 solver.cpp:261]     Train net output #0: loss = 2.30608 (* 1 = 2.30608 loss)
I0502 11:10:05.872294 26473 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0502 11:10:06.819393 26473 solver.cpp:362] Iteration 2500, Testing net (#0)
I0502 11:10:06.819423 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:06.944720 26473 solver.cpp:429]     Test net output #0: loss = 5.15676 (* 1 = 5.15676 loss)
I0502 11:10:06.947602 26473 solver.cpp:242] Iteration 2500 (92.5789 iter/s, 1.08016s/100 iter), loss = 4.80978
I0502 11:10:06.947623 26473 solver.cpp:261]     Train net output #0: loss = 4.80978 (* 1 = 4.80978 loss)
I0502 11:10:06.947631 26473 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0502 11:10:06.949293 26473 solver.cpp:362] Iteration 2500, Testing net (#0)
I0502 11:10:06.949309 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:07.082142 26473 solver.cpp:429]     Test net output #0: accuracy = 0.2725
I0502 11:10:07.082165 26473 solver.cpp:429]     Test net output #1: loss = 2.32983 (* 1 = 2.32983 loss)
I0502 11:10:07.085146 26473 solver.cpp:242] Iteration 2500 (82.4512 iter/s, 1.21284s/100 iter), loss = 2.27083
I0502 11:10:07.085173 26473 solver.cpp:261]     Train net output #0: loss = 2.27083 (* 1 = 2.27083 loss)
I0502 11:10:07.085183 26473 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0502 11:10:08.040630 26473 solver.cpp:242] Iteration 2600 (91.4928 iter/s, 1.09298s/100 iter), loss = 3.9552
I0502 11:10:08.040675 26473 solver.cpp:261]     Train net output #0: loss = 3.9552 (* 1 = 3.9552 loss)
I0502 11:10:08.040683 26473 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0502 11:10:08.045490 26473 solver.cpp:242] Iteration 2600 (104.134 iter/s, 0.960299s/100 iter), loss = 2.05542
I0502 11:10:08.045514 26473 solver.cpp:261]     Train net output #0: loss = 2.05542 (* 1 = 2.05542 loss)
I0502 11:10:08.045522 26473 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0502 11:10:08.997548 26473 solver.cpp:242] Iteration 2700 (104.509 iter/s, 0.956853s/100 iter), loss = 5.83023
I0502 11:10:08.997587 26473 solver.cpp:261]     Train net output #0: loss = 5.83023 (* 1 = 5.83023 loss)
I0502 11:10:08.997596 26473 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0502 11:10:09.002423 26473 solver.cpp:242] Iteration 2700 (104.505 iter/s, 0.956889s/100 iter), loss = 2.41551
I0502 11:10:09.002445 26473 solver.cpp:261]     Train net output #0: loss = 2.41551 (* 1 = 2.41551 loss)
I0502 11:10:09.002454 26473 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0502 11:10:09.955330 26473 solver.cpp:242] Iteration 2800 (104.414 iter/s, 0.957722s/100 iter), loss = 3.15911
I0502 11:10:09.955374 26473 solver.cpp:261]     Train net output #0: loss = 3.15911 (* 1 = 3.15911 loss)
I0502 11:10:09.955381 26473 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0502 11:10:09.960288 26473 solver.cpp:242] Iteration 2800 (104.403 iter/s, 0.957823s/100 iter), loss = 2.30054
I0502 11:10:09.960310 26473 solver.cpp:261]     Train net output #0: loss = 2.30054 (* 1 = 2.30054 loss)
I0502 11:10:09.960319 26473 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0502 11:10:10.912181 26473 solver.cpp:242] Iteration 2900 (104.517 iter/s, 0.956787s/100 iter), loss = 6.01215
I0502 11:10:10.912238 26473 solver.cpp:261]     Train net output #0: loss = 6.01215 (* 1 = 6.01215 loss)
I0502 11:10:10.912247 26473 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0502 11:10:10.917094 26473 solver.cpp:242] Iteration 2900 (104.519 iter/s, 0.956765s/100 iter), loss = 2.40326
I0502 11:10:10.917119 26473 solver.cpp:261]     Train net output #0: loss = 2.40326 (* 1 = 2.40326 loss)
I0502 11:10:10.917126 26473 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0502 11:10:11.865742 26473 solver.cpp:362] Iteration 3000, Testing net (#0)
I0502 11:10:11.865767 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:11.991708 26473 solver.cpp:429]     Test net output #0: loss = 5.33813 (* 1 = 5.33813 loss)
I0502 11:10:11.994638 26473 solver.cpp:242] Iteration 3000 (92.3889 iter/s, 1.08238s/100 iter), loss = 4.79367
I0502 11:10:11.994658 26473 solver.cpp:261]     Train net output #0: loss = 4.79367 (* 1 = 4.79367 loss)
I0502 11:10:11.994668 26473 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0502 11:10:11.996325 26473 solver.cpp:362] Iteration 3000, Testing net (#0)
I0502 11:10:11.996338 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:12.128922 26473 solver.cpp:429]     Test net output #0: accuracy = 0.22
I0502 11:10:12.128945 26473 solver.cpp:429]     Test net output #1: loss = 2.31729 (* 1 = 2.31729 loss)
I0502 11:10:12.131914 26473 solver.cpp:242] Iteration 3000 (82.3198 iter/s, 1.21477s/100 iter), loss = 2.43153
I0502 11:10:12.131933 26473 solver.cpp:261]     Train net output #0: loss = 2.43153 (* 1 = 2.43153 loss)
I0502 11:10:12.131942 26473 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0502 11:10:13.084317 26473 solver.cpp:242] Iteration 3100 (91.7739 iter/s, 1.08963s/100 iter), loss = 5.32059
I0502 11:10:13.084358 26473 solver.cpp:261]     Train net output #0: loss = 5.32059 (* 1 = 5.32059 loss)
I0502 11:10:13.084367 26473 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0502 11:10:13.089174 26473 solver.cpp:242] Iteration 3100 (104.469 iter/s, 0.957222s/100 iter), loss = 1.97836
I0502 11:10:13.089203 26473 solver.cpp:261]     Train net output #0: loss = 1.97836 (* 1 = 1.97836 loss)
I0502 11:10:13.089212 26473 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0502 11:10:14.041230 26473 solver.cpp:242] Iteration 3200 (104.51 iter/s, 0.95685s/100 iter), loss = 4.89424
I0502 11:10:14.041275 26473 solver.cpp:261]     Train net output #0: loss = 4.89424 (* 1 = 4.89424 loss)
I0502 11:10:14.041283 26473 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0502 11:10:14.046170 26473 solver.cpp:242] Iteration 3200 (104.499 iter/s, 0.956949s/100 iter), loss = 2.25216
I0502 11:10:14.046193 26473 solver.cpp:261]     Train net output #0: loss = 2.25216 (* 1 = 2.25216 loss)
I0502 11:10:14.046202 26473 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0502 11:10:14.999279 26473 solver.cpp:242] Iteration 3300 (104.386 iter/s, 0.957983s/100 iter), loss = 4.16232
I0502 11:10:14.999318 26473 solver.cpp:261]     Train net output #0: loss = 4.16232 (* 1 = 4.16232 loss)
I0502 11:10:14.999327 26473 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0502 11:10:15.004226 26473 solver.cpp:242] Iteration 3300 (104.383 iter/s, 0.958014s/100 iter), loss = 2.15953
I0502 11:10:15.004251 26473 solver.cpp:261]     Train net output #0: loss = 2.15953 (* 1 = 2.15953 loss)
I0502 11:10:15.004258 26473 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0502 11:10:15.955611 26473 solver.cpp:242] Iteration 3400 (104.573 iter/s, 0.956271s/100 iter), loss = 3.31653
I0502 11:10:15.955669 26473 solver.cpp:261]     Train net output #0: loss = 3.31653 (* 1 = 3.31653 loss)
I0502 11:10:15.955678 26473 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0502 11:10:15.960508 26473 solver.cpp:242] Iteration 3400 (104.576 iter/s, 0.95624s/100 iter), loss = 2.35889
I0502 11:10:15.960531 26473 solver.cpp:261]     Train net output #0: loss = 2.35889 (* 1 = 2.35889 loss)
I0502 11:10:15.960539 26473 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0502 11:10:16.909248 26473 solver.cpp:362] Iteration 3500, Testing net (#0)
I0502 11:10:16.909276 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:17.035325 26473 solver.cpp:429]     Test net output #0: loss = 5.8679 (* 1 = 5.8679 loss)
I0502 11:10:17.038250 26473 solver.cpp:242] Iteration 3500 (92.3734 iter/s, 1.08256s/100 iter), loss = 6.51124
I0502 11:10:17.038270 26473 solver.cpp:261]     Train net output #0: loss = 6.51124 (* 1 = 6.51124 loss)
I0502 11:10:17.038280 26473 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0502 11:10:17.039933 26473 solver.cpp:362] Iteration 3500, Testing net (#0)
I0502 11:10:17.039947 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:17.172322 26473 solver.cpp:429]     Test net output #0: accuracy = 0.294
I0502 11:10:17.172346 26473 solver.cpp:429]     Test net output #1: loss = 2.20947 (* 1 = 2.20947 loss)
I0502 11:10:17.175310 26473 solver.cpp:242] Iteration 3500 (82.321 iter/s, 1.21476s/100 iter), loss = 2.17719
I0502 11:10:17.175330 26473 solver.cpp:261]     Train net output #0: loss = 2.17719 (* 1 = 2.17719 loss)
I0502 11:10:17.175339 26473 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0502 11:10:18.129300 26473 solver.cpp:242] Iteration 3600 (91.6586 iter/s, 1.09101s/100 iter), loss = 5.1779
I0502 11:10:18.129343 26473 solver.cpp:261]     Train net output #0: loss = 5.1779 (* 1 = 5.1779 loss)
I0502 11:10:18.129350 26473 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0502 11:10:18.134285 26473 solver.cpp:242] Iteration 3600 (104.282 iter/s, 0.958936s/100 iter), loss = 2.07716
I0502 11:10:18.134310 26473 solver.cpp:261]     Train net output #0: loss = 2.07716 (* 1 = 2.07716 loss)
I0502 11:10:18.134317 26473 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0502 11:10:19.098614 26473 solver.cpp:242] Iteration 3700 (103.172 iter/s, 0.969253s/100 iter), loss = 4.89859
I0502 11:10:19.098651 26473 solver.cpp:261]     Train net output #0: loss = 4.89859 (* 1 = 4.89859 loss)
I0502 11:10:19.098659 26473 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0502 11:10:19.103564 26473 solver.cpp:242] Iteration 3700 (103.174 iter/s, 0.969235s/100 iter), loss = 2.07832
I0502 11:10:19.103593 26473 solver.cpp:261]     Train net output #0: loss = 2.07832 (* 1 = 2.07832 loss)
I0502 11:10:19.103601 26473 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0502 11:10:20.066242 26473 solver.cpp:242] Iteration 3800 (103.352 iter/s, 0.967569s/100 iter), loss = 4.2814
I0502 11:10:20.066287 26473 solver.cpp:261]     Train net output #0: loss = 4.2814 (* 1 = 4.2814 loss)
I0502 11:10:20.066295 26473 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0502 11:10:20.071218 26473 solver.cpp:242] Iteration 3800 (103.348 iter/s, 0.9676s/100 iter), loss = 1.88871
I0502 11:10:20.071241 26473 solver.cpp:261]     Train net output #0: loss = 1.88871 (* 1 = 1.88871 loss)
I0502 11:10:20.071249 26473 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0502 11:10:21.033907 26473 solver.cpp:242] Iteration 3900 (103.349 iter/s, 0.967597s/100 iter), loss = 7.32166
I0502 11:10:21.033963 26473 solver.cpp:261]     Train net output #0: loss = 7.32166 (* 1 = 7.32166 loss)
I0502 11:10:21.033972 26473 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0502 11:10:21.039000 26473 solver.cpp:242] Iteration 3900 (103.334 iter/s, 0.967739s/100 iter), loss = 2.03261
I0502 11:10:21.039022 26473 solver.cpp:261]     Train net output #0: loss = 2.03261 (* 1 = 2.03261 loss)
I0502 11:10:21.039031 26473 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0502 11:10:21.998165 26473 solver.cpp:362] Iteration 4000, Testing net (#0)
I0502 11:10:21.998195 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:22.126469 26473 solver.cpp:429]     Test net output #0: loss = 4.73436 (* 1 = 4.73436 loss)
I0502 11:10:22.129448 26473 solver.cpp:242] Iteration 4000 (91.2853 iter/s, 1.09547s/100 iter), loss = 3.83495
I0502 11:10:22.129469 26473 solver.cpp:261]     Train net output #0: loss = 3.83495 (* 1 = 3.83495 loss)
I0502 11:10:22.129477 26473 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0502 11:10:22.131134 26473 solver.cpp:362] Iteration 4000, Testing net (#0)
I0502 11:10:22.131147 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:22.266065 26473 solver.cpp:429]     Test net output #0: accuracy = 0.3145
I0502 11:10:22.266086 26473 solver.cpp:429]     Test net output #1: loss = 1.89083 (* 1 = 1.89083 loss)
I0502 11:10:22.269111 26473 solver.cpp:242] Iteration 4000 (81.2964 iter/s, 1.23007s/100 iter), loss = 2.05246
I0502 11:10:22.269131 26473 solver.cpp:261]     Train net output #0: loss = 2.05246 (* 1 = 2.05246 loss)
I0502 11:10:22.269140 26473 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0502 11:10:23.228570 26473 solver.cpp:242] Iteration 4100 (90.9855 iter/s, 1.09908s/100 iter), loss = 4.06214
I0502 11:10:23.228613 26473 solver.cpp:261]     Train net output #0: loss = 4.06214 (* 1 = 4.06214 loss)
I0502 11:10:23.228622 26473 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0502 11:10:23.233454 26473 solver.cpp:242] Iteration 4100 (103.702 iter/s, 0.964304s/100 iter), loss = 1.99022
I0502 11:10:23.233476 26473 solver.cpp:261]     Train net output #0: loss = 1.99022 (* 1 = 1.99022 loss)
I0502 11:10:23.233484 26473 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0502 11:10:24.187527 26473 solver.cpp:242] Iteration 4200 (104.287 iter/s, 0.958892s/100 iter), loss = 5.56771
I0502 11:10:24.187571 26473 solver.cpp:261]     Train net output #0: loss = 5.56771 (* 1 = 5.56771 loss)
I0502 11:10:24.187579 26473 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0502 11:10:24.192387 26473 solver.cpp:242] Iteration 4200 (104.287 iter/s, 0.958893s/100 iter), loss = 2.48508
I0502 11:10:24.192410 26473 solver.cpp:261]     Train net output #0: loss = 2.48508 (* 1 = 2.48508 loss)
I0502 11:10:24.192420 26473 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0502 11:10:25.146590 26473 solver.cpp:242] Iteration 4300 (104.275 iter/s, 0.958999s/100 iter), loss = 3.26072
I0502 11:10:25.146626 26473 solver.cpp:261]     Train net output #0: loss = 3.26072 (* 1 = 3.26072 loss)
I0502 11:10:25.146636 26473 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0502 11:10:25.151439 26473 solver.cpp:242] Iteration 4300 (104.274 iter/s, 0.959011s/100 iter), loss = 1.65079
I0502 11:10:25.151470 26473 solver.cpp:261]     Train net output #0: loss = 1.65079 (* 1 = 1.65079 loss)
I0502 11:10:25.151479 26473 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0502 11:10:26.104821 26473 solver.cpp:242] Iteration 4400 (104.365 iter/s, 0.958173s/100 iter), loss = 4.14442
I0502 11:10:26.104866 26473 solver.cpp:261]     Train net output #0: loss = 4.14442 (* 1 = 4.14442 loss)
I0502 11:10:26.104876 26473 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0502 11:10:26.109853 26473 solver.cpp:242] Iteration 4400 (104.345 iter/s, 0.958364s/100 iter), loss = 1.68596
I0502 11:10:26.109879 26473 solver.cpp:261]     Train net output #0: loss = 1.68596 (* 1 = 1.68596 loss)
I0502 11:10:26.109887 26473 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0502 11:10:27.059551 26473 solver.cpp:362] Iteration 4500, Testing net (#0)
I0502 11:10:27.059579 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:27.185698 26473 solver.cpp:429]     Test net output #0: loss = 4.92317 (* 1 = 4.92317 loss)
I0502 11:10:27.188648 26473 solver.cpp:242] Iteration 4500 (92.271 iter/s, 1.08376s/100 iter), loss = 5.13262
I0502 11:10:27.188669 26473 solver.cpp:261]     Train net output #0: loss = 5.13262 (* 1 = 5.13262 loss)
I0502 11:10:27.188678 26473 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0502 11:10:27.190379 26473 solver.cpp:362] Iteration 4500, Testing net (#0)
I0502 11:10:27.190393 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:27.323134 26473 solver.cpp:429]     Test net output #0: accuracy = 0.3655
I0502 11:10:27.323158 26473 solver.cpp:429]     Test net output #1: loss = 1.86601 (* 1 = 1.86601 loss)
I0502 11:10:27.326138 26473 solver.cpp:242] Iteration 4500 (82.2209 iter/s, 1.21624s/100 iter), loss = 1.83741
I0502 11:10:27.326156 26473 solver.cpp:261]     Train net output #0: loss = 1.83741 (* 1 = 1.83741 loss)
I0502 11:10:27.326165 26473 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0502 11:10:28.279711 26473 solver.cpp:242] Iteration 4600 (91.6576 iter/s, 1.09102s/100 iter), loss = 5.13042
I0502 11:10:28.279744 26473 solver.cpp:261]     Train net output #0: loss = 5.13042 (* 1 = 5.13042 loss)
I0502 11:10:28.279753 26473 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0502 11:10:28.284605 26473 solver.cpp:242] Iteration 4600 (104.338 iter/s, 0.958428s/100 iter), loss = 1.74591
I0502 11:10:28.284628 26473 solver.cpp:261]     Train net output #0: loss = 1.74591 (* 1 = 1.74591 loss)
I0502 11:10:28.284637 26473 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0502 11:10:29.236078 26473 solver.cpp:242] Iteration 4700 (104.568 iter/s, 0.956313s/100 iter), loss = 3.18077
I0502 11:10:29.236122 26473 solver.cpp:261]     Train net output #0: loss = 3.18077 (* 1 = 3.18077 loss)
I0502 11:10:29.236131 26473 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0502 11:10:29.240928 26473 solver.cpp:242] Iteration 4700 (104.572 iter/s, 0.956282s/100 iter), loss = 1.56164
I0502 11:10:29.240950 26473 solver.cpp:261]     Train net output #0: loss = 1.56164 (* 1 = 1.56164 loss)
I0502 11:10:29.240958 26473 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0502 11:10:30.192236 26473 solver.cpp:242] Iteration 4800 (104.592 iter/s, 0.956092s/100 iter), loss = 3.4835
I0502 11:10:30.192279 26473 solver.cpp:261]     Train net output #0: loss = 3.4835 (* 1 = 3.4835 loss)
I0502 11:10:30.192288 26473 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0502 11:10:30.197099 26473 solver.cpp:242] Iteration 4800 (104.588 iter/s, 0.95613s/100 iter), loss = 1.36307
I0502 11:10:30.197124 26473 solver.cpp:261]     Train net output #0: loss = 1.36307 (* 1 = 1.36307 loss)
I0502 11:10:30.197131 26473 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0502 11:10:31.147496 26473 solver.cpp:242] Iteration 4900 (104.691 iter/s, 0.955196s/100 iter), loss = 5.33586
I0502 11:10:31.147547 26473 solver.cpp:261]     Train net output #0: loss = 5.33586 (* 1 = 5.33586 loss)
I0502 11:10:31.147557 26473 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0502 11:10:31.152508 26473 solver.cpp:242] Iteration 4900 (104.672 iter/s, 0.955366s/100 iter), loss = 1.46493
I0502 11:10:31.152540 26473 solver.cpp:261]     Train net output #0: loss = 1.46493 (* 1 = 1.46493 loss)
I0502 11:10:31.152549 26473 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0502 11:10:32.101024 26473 solver.cpp:362] Iteration 5000, Testing net (#0)
I0502 11:10:32.101054 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:32.226972 26473 solver.cpp:429]     Test net output #0: loss = 3.98924 (* 1 = 3.98924 loss)
I0502 11:10:32.229925 26473 solver.cpp:242] Iteration 5000 (92.3907 iter/s, 1.08236s/100 iter), loss = 3.64541
I0502 11:10:32.229945 26473 solver.cpp:261]     Train net output #0: loss = 3.64541 (* 1 = 3.64541 loss)
I0502 11:10:32.229954 26473 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0502 11:10:32.231609 26473 solver.cpp:362] Iteration 5000, Testing net (#0)
I0502 11:10:32.231623 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:32.364435 26473 solver.cpp:429]     Test net output #0: accuracy = 0.4805
I0502 11:10:32.364459 26473 solver.cpp:429]     Test net output #1: loss = 1.4981 (* 1 = 1.4981 loss)
I0502 11:10:32.367431 26473 solver.cpp:242] Iteration 5000 (82.3133 iter/s, 1.21487s/100 iter), loss = 1.51644
I0502 11:10:32.367452 26473 solver.cpp:261]     Train net output #0: loss = 1.51644 (* 1 = 1.51644 loss)
I0502 11:10:32.367460 26473 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0502 11:10:33.319700 26473 solver.cpp:242] Iteration 5100 (91.7658 iter/s, 1.08973s/100 iter), loss = 3.72917
I0502 11:10:33.319743 26473 solver.cpp:261]     Train net output #0: loss = 3.72917 (* 1 = 3.72917 loss)
I0502 11:10:33.319752 26473 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0502 11:10:33.324585 26473 solver.cpp:242] Iteration 5100 (104.481 iter/s, 0.957114s/100 iter), loss = 1.5268
I0502 11:10:33.324609 26473 solver.cpp:261]     Train net output #0: loss = 1.5268 (* 1 = 1.5268 loss)
I0502 11:10:33.324616 26473 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0502 11:10:34.277190 26473 solver.cpp:242] Iteration 5200 (104.447 iter/s, 0.957426s/100 iter), loss = 6.35539
I0502 11:10:34.277232 26473 solver.cpp:261]     Train net output #0: loss = 6.35539 (* 1 = 6.35539 loss)
I0502 11:10:34.277241 26473 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0502 11:10:34.282093 26473 solver.cpp:242] Iteration 5200 (104.442 iter/s, 0.957466s/100 iter), loss = 1.1248
I0502 11:10:34.282115 26473 solver.cpp:261]     Train net output #0: loss = 1.1248 (* 1 = 1.1248 loss)
I0502 11:10:34.282124 26473 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0502 11:10:35.233878 26473 solver.cpp:242] Iteration 5300 (104.534 iter/s, 0.956627s/100 iter), loss = 2.00163
I0502 11:10:35.233913 26473 solver.cpp:261]     Train net output #0: loss = 2.00163 (* 1 = 2.00163 loss)
I0502 11:10:35.233922 26473 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0502 11:10:35.238721 26473 solver.cpp:242] Iteration 5300 (104.538 iter/s, 0.956587s/100 iter), loss = 1.36156
I0502 11:10:35.238744 26473 solver.cpp:261]     Train net output #0: loss = 1.36156 (* 1 = 1.36156 loss)
I0502 11:10:35.238751 26473 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0502 11:10:36.191479 26473 solver.cpp:242] Iteration 5400 (104.434 iter/s, 0.957544s/100 iter), loss = 8.10276
I0502 11:10:36.191539 26473 solver.cpp:261]     Train net output #0: loss = 8.10276 (* 1 = 8.10276 loss)
I0502 11:10:36.191551 26473 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0502 11:10:36.196578 26473 solver.cpp:242] Iteration 5400 (104.404 iter/s, 0.957816s/100 iter), loss = 1.47998
I0502 11:10:36.196602 26473 solver.cpp:261]     Train net output #0: loss = 1.47998 (* 1 = 1.47998 loss)
I0502 11:10:36.196611 26473 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0502 11:10:37.155679 26473 solver.cpp:362] Iteration 5500, Testing net (#0)
I0502 11:10:37.155701 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:37.283152 26473 solver.cpp:429]     Test net output #0: loss = 3.78045 (* 1 = 3.78045 loss)
I0502 11:10:37.286118 26473 solver.cpp:242] Iteration 5500 (91.3609 iter/s, 1.09456s/100 iter), loss = 6.74928
I0502 11:10:37.286137 26473 solver.cpp:261]     Train net output #0: loss = 6.74928 (* 1 = 6.74928 loss)
I0502 11:10:37.286156 26473 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0502 11:10:37.287811 26473 solver.cpp:362] Iteration 5500, Testing net (#0)
I0502 11:10:37.287825 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:37.421591 26473 solver.cpp:429]     Test net output #0: accuracy = 0.4975
I0502 11:10:37.421614 26473 solver.cpp:429]     Test net output #1: loss = 1.46976 (* 1 = 1.46976 loss)
I0502 11:10:37.424628 26473 solver.cpp:242] Iteration 5500 (81.4331 iter/s, 1.228s/100 iter), loss = 1.3928
I0502 11:10:37.424648 26473 solver.cpp:261]     Train net output #0: loss = 1.3928 (* 1 = 1.3928 loss)
I0502 11:10:37.424655 26473 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0502 11:10:38.386903 26473 solver.cpp:242] Iteration 5600 (90.848 iter/s, 1.10074s/100 iter), loss = 3.01613
I0502 11:10:38.386945 26473 solver.cpp:261]     Train net output #0: loss = 3.01613 (* 1 = 3.01613 loss)
I0502 11:10:38.386955 26473 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0502 11:10:38.391813 26473 solver.cpp:242] Iteration 5600 (103.397 iter/s, 0.967148s/100 iter), loss = 1.40294
I0502 11:10:38.391837 26473 solver.cpp:261]     Train net output #0: loss = 1.40294 (* 1 = 1.40294 loss)
I0502 11:10:38.391845 26473 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0502 11:10:39.352638 26473 solver.cpp:242] Iteration 5700 (103.555 iter/s, 0.965671s/100 iter), loss = 3.9879
I0502 11:10:39.352681 26473 solver.cpp:261]     Train net output #0: loss = 3.9879 (* 1 = 3.9879 loss)
I0502 11:10:39.352690 26473 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0502 11:10:39.357527 26473 solver.cpp:242] Iteration 5700 (103.555 iter/s, 0.965671s/100 iter), loss = 1.43108
I0502 11:10:39.357549 26473 solver.cpp:261]     Train net output #0: loss = 1.43108 (* 1 = 1.43108 loss)
I0502 11:10:39.357558 26473 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0502 11:10:40.314357 26473 solver.cpp:242] Iteration 5800 (103.987 iter/s, 0.961655s/100 iter), loss = 2.45843
I0502 11:10:40.314399 26473 solver.cpp:261]     Train net output #0: loss = 2.45843 (* 1 = 2.45843 loss)
I0502 11:10:40.314406 26473 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0502 11:10:40.319228 26473 solver.cpp:242] Iteration 5800 (103.987 iter/s, 0.96166s/100 iter), loss = 1.27499
I0502 11:10:40.319252 26473 solver.cpp:261]     Train net output #0: loss = 1.27499 (* 1 = 1.27499 loss)
I0502 11:10:40.319259 26473 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0502 11:10:41.276710 26473 solver.cpp:242] Iteration 5900 (103.918 iter/s, 0.962293s/100 iter), loss = 1.7663
I0502 11:10:41.276741 26473 solver.cpp:261]     Train net output #0: loss = 1.7663 (* 1 = 1.7663 loss)
I0502 11:10:41.276749 26473 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0502 11:10:41.281692 26473 solver.cpp:242] Iteration 5900 (103.905 iter/s, 0.962415s/100 iter), loss = 1.4263
I0502 11:10:41.281713 26473 solver.cpp:261]     Train net output #0: loss = 1.4263 (* 1 = 1.4263 loss)
I0502 11:10:41.281723 26473 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0502 11:10:42.236791 26473 solver.cpp:362] Iteration 6000, Testing net (#0)
I0502 11:10:42.236822 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:42.363899 26473 solver.cpp:429]     Test net output #0: loss = 3.46805 (* 1 = 3.46805 loss)
I0502 11:10:42.366873 26473 solver.cpp:242] Iteration 6000 (91.7336 iter/s, 1.09011s/100 iter), loss = 2.31728
I0502 11:10:42.366894 26473 solver.cpp:261]     Train net output #0: loss = 2.31728 (* 1 = 2.31728 loss)
I0502 11:10:42.366902 26473 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0502 11:10:42.368573 26473 solver.cpp:362] Iteration 6000, Testing net (#0)
I0502 11:10:42.368587 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:42.502387 26473 solver.cpp:429]     Test net output #0: accuracy = 0.4975
I0502 11:10:42.502408 26473 solver.cpp:429]     Test net output #1: loss = 1.38768 (* 1 = 1.38768 loss)
I0502 11:10:42.505385 26473 solver.cpp:242] Iteration 6000 (81.7228 iter/s, 1.22365s/100 iter), loss = 1.23716
I0502 11:10:42.505414 26473 solver.cpp:261]     Train net output #0: loss = 1.23716 (* 1 = 1.23716 loss)
I0502 11:10:42.505422 26473 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0502 11:10:43.464531 26473 solver.cpp:242] Iteration 6100 (91.1074 iter/s, 1.09761s/100 iter), loss = 3.79538
I0502 11:10:43.464576 26473 solver.cpp:261]     Train net output #0: loss = 3.79538 (* 1 = 3.79538 loss)
I0502 11:10:43.464586 26473 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0502 11:10:43.469421 26473 solver.cpp:242] Iteration 6100 (103.736 iter/s, 0.963989s/100 iter), loss = 1.06151
I0502 11:10:43.469444 26473 solver.cpp:261]     Train net output #0: loss = 1.06151 (* 1 = 1.06151 loss)
I0502 11:10:43.469452 26473 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0502 11:10:44.427979 26473 solver.cpp:242] Iteration 6200 (103.801 iter/s, 0.963381s/100 iter), loss = 1.23246
I0502 11:10:44.428023 26473 solver.cpp:261]     Train net output #0: loss = 1.23246 (* 1 = 1.23246 loss)
I0502 11:10:44.428032 26473 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0502 11:10:44.432857 26473 solver.cpp:242] Iteration 6200 (103.8 iter/s, 0.963395s/100 iter), loss = 0.944897
I0502 11:10:44.432879 26473 solver.cpp:261]     Train net output #0: loss = 0.944897 (* 1 = 0.944897 loss)
I0502 11:10:44.432888 26473 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0502 11:10:45.387639 26473 solver.cpp:242] Iteration 6300 (104.211 iter/s, 0.959593s/100 iter), loss = 4.94277
I0502 11:10:45.387682 26473 solver.cpp:261]     Train net output #0: loss = 4.94277 (* 1 = 4.94277 loss)
I0502 11:10:45.387691 26473 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0502 11:10:45.392542 26473 solver.cpp:242] Iteration 6300 (104.205 iter/s, 0.959644s/100 iter), loss = 1.29263
I0502 11:10:45.392570 26473 solver.cpp:261]     Train net output #0: loss = 1.29263 (* 1 = 1.29263 loss)
I0502 11:10:45.392577 26473 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0502 11:10:46.347885 26473 solver.cpp:242] Iteration 6400 (104.147 iter/s, 0.960181s/100 iter), loss = 2.44813
I0502 11:10:46.347928 26473 solver.cpp:261]     Train net output #0: loss = 2.44813 (* 1 = 2.44813 loss)
I0502 11:10:46.347936 26473 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0502 11:10:46.352888 26473 solver.cpp:242] Iteration 6400 (104.134 iter/s, 0.960301s/100 iter), loss = 1.32844
I0502 11:10:46.352911 26473 solver.cpp:261]     Train net output #0: loss = 1.32844 (* 1 = 1.32844 loss)
I0502 11:10:46.352919 26473 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0502 11:10:47.304743 26473 solver.cpp:362] Iteration 6500, Testing net (#0)
I0502 11:10:47.304760 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:47.431385 26473 solver.cpp:429]     Test net output #0: loss = 3.44326 (* 1 = 3.44326 loss)
I0502 11:10:47.434335 26473 solver.cpp:242] Iteration 6500 (92.048 iter/s, 1.08639s/100 iter), loss = 1.80105
I0502 11:10:47.434356 26473 solver.cpp:261]     Train net output #0: loss = 1.80105 (* 1 = 1.80105 loss)
I0502 11:10:47.434365 26473 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0502 11:10:47.436110 26473 solver.cpp:362] Iteration 6500, Testing net (#0)
I0502 11:10:47.436122 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:47.569119 26473 solver.cpp:429]     Test net output #0: accuracy = 0.5515
I0502 11:10:47.569144 26473 solver.cpp:429]     Test net output #1: loss = 1.29404 (* 1 = 1.29404 loss)
I0502 11:10:47.572130 26473 solver.cpp:242] Iteration 6500 (82.0211 iter/s, 1.2192s/100 iter), loss = 1.15004
I0502 11:10:47.572150 26473 solver.cpp:261]     Train net output #0: loss = 1.15004 (* 1 = 1.15004 loss)
I0502 11:10:47.572158 26473 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0502 11:10:48.527580 26473 solver.cpp:242] Iteration 6600 (91.4746 iter/s, 1.0932s/100 iter), loss = 5.29046
I0502 11:10:48.527621 26473 solver.cpp:261]     Train net output #0: loss = 5.29046 (* 1 = 5.29046 loss)
I0502 11:10:48.527629 26473 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0502 11:10:48.532465 26473 solver.cpp:242] Iteration 6600 (104.134 iter/s, 0.960297s/100 iter), loss = 1.21632
I0502 11:10:48.532496 26473 solver.cpp:261]     Train net output #0: loss = 1.21632 (* 1 = 1.21632 loss)
I0502 11:10:48.532506 26473 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0502 11:10:49.487085 26473 solver.cpp:242] Iteration 6700 (104.227 iter/s, 0.959442s/100 iter), loss = 2.18769
I0502 11:10:49.487128 26473 solver.cpp:261]     Train net output #0: loss = 2.18769 (* 1 = 2.18769 loss)
I0502 11:10:49.487136 26473 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0502 11:10:49.491951 26473 solver.cpp:242] Iteration 6700 (104.228 iter/s, 0.959436s/100 iter), loss = 1.62531
I0502 11:10:49.491984 26473 solver.cpp:261]     Train net output #0: loss = 1.62531 (* 1 = 1.62531 loss)
I0502 11:10:49.491992 26473 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0502 11:10:50.444339 26473 solver.cpp:242] Iteration 6800 (104.473 iter/s, 0.957187s/100 iter), loss = 6.33197
I0502 11:10:50.444372 26473 solver.cpp:261]     Train net output #0: loss = 6.33197 (* 1 = 6.33197 loss)
I0502 11:10:50.444381 26473 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0502 11:10:50.449182 26473 solver.cpp:242] Iteration 6800 (104.474 iter/s, 0.95718s/100 iter), loss = 1.09735
I0502 11:10:50.449204 26473 solver.cpp:261]     Train net output #0: loss = 1.09735 (* 1 = 1.09735 loss)
I0502 11:10:50.449213 26473 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0502 11:10:51.400645 26473 solver.cpp:242] Iteration 6900 (104.575 iter/s, 0.95625s/100 iter), loss = 3.16618
I0502 11:10:51.400689 26473 solver.cpp:261]     Train net output #0: loss = 3.16618 (* 1 = 3.16618 loss)
I0502 11:10:51.400697 26473 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0502 11:10:51.405526 26473 solver.cpp:242] Iteration 6900 (104.569 iter/s, 0.956303s/100 iter), loss = 1.34422
I0502 11:10:51.405549 26473 solver.cpp:261]     Train net output #0: loss = 1.34422 (* 1 = 1.34422 loss)
I0502 11:10:51.405557 26473 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0502 11:10:52.373831 26473 solver.cpp:362] Iteration 7000, Testing net (#0)
I0502 11:10:52.373862 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:52.499639 26473 solver.cpp:429]     Test net output #0: loss = 3.03395 (* 1 = 3.03395 loss)
I0502 11:10:52.502554 26473 solver.cpp:242] Iteration 7000 (90.7567 iter/s, 1.10185s/100 iter), loss = 1.69626
I0502 11:10:52.502575 26473 solver.cpp:261]     Train net output #0: loss = 1.69626 (* 1 = 1.69626 loss)
I0502 11:10:52.502583 26473 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0502 11:10:52.504346 26473 solver.cpp:362] Iteration 7000, Testing net (#0)
I0502 11:10:52.504360 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:52.636468 26473 solver.cpp:429]     Test net output #0: accuracy = 0.548
I0502 11:10:52.636494 26473 solver.cpp:429]     Test net output #1: loss = 1.2331 (* 1 = 1.2331 loss)
I0502 11:10:52.639470 26473 solver.cpp:242] Iteration 7000 (81.0439 iter/s, 1.2339s/100 iter), loss = 0.966489
I0502 11:10:52.639492 26473 solver.cpp:261]     Train net output #0: loss = 0.966489 (* 1 = 0.966489 loss)
I0502 11:10:52.639500 26473 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0502 11:10:53.590543 26473 solver.cpp:242] Iteration 7100 (91.9164 iter/s, 1.08794s/100 iter), loss = 5.73064
I0502 11:10:53.590581 26473 solver.cpp:261]     Train net output #0: loss = 5.73064 (* 1 = 5.73064 loss)
I0502 11:10:53.590590 26473 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0502 11:10:53.595399 26473 solver.cpp:242] Iteration 7100 (104.615 iter/s, 0.955889s/100 iter), loss = 1.00969
I0502 11:10:53.595422 26473 solver.cpp:261]     Train net output #0: loss = 1.00969 (* 1 = 1.00969 loss)
I0502 11:10:53.595430 26473 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0502 11:10:54.547087 26473 solver.cpp:242] Iteration 7200 (104.55 iter/s, 0.956484s/100 iter), loss = 4.09146
I0502 11:10:54.547130 26473 solver.cpp:261]     Train net output #0: loss = 4.09146 (* 1 = 4.09146 loss)
I0502 11:10:54.547139 26473 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0502 11:10:54.551966 26473 solver.cpp:242] Iteration 7200 (104.545 iter/s, 0.956527s/100 iter), loss = 0.782035
I0502 11:10:54.551998 26473 solver.cpp:261]     Train net output #0: loss = 0.782035 (* 1 = 0.782035 loss)
I0502 11:10:54.552007 26473 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0502 11:10:55.502583 26473 solver.cpp:242] Iteration 7300 (104.665 iter/s, 0.955431s/100 iter), loss = 5.23928
I0502 11:10:55.502626 26473 solver.cpp:261]     Train net output #0: loss = 5.23928 (* 1 = 5.23928 loss)
I0502 11:10:55.502635 26473 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0502 11:10:55.507443 26473 solver.cpp:242] Iteration 7300 (104.665 iter/s, 0.955427s/100 iter), loss = 1.11902
I0502 11:10:55.507467 26473 solver.cpp:261]     Train net output #0: loss = 1.11902 (* 1 = 1.11902 loss)
I0502 11:10:55.507475 26473 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0502 11:10:56.458730 26473 solver.cpp:242] Iteration 7400 (104.593 iter/s, 0.956083s/100 iter), loss = 2.84406
I0502 11:10:56.458783 26473 solver.cpp:261]     Train net output #0: loss = 2.84406 (* 1 = 2.84406 loss)
I0502 11:10:56.458799 26473 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0502 11:10:56.463645 26473 solver.cpp:242] Iteration 7400 (104.585 iter/s, 0.956161s/100 iter), loss = 1.34434
I0502 11:10:56.463670 26473 solver.cpp:261]     Train net output #0: loss = 1.34434 (* 1 = 1.34434 loss)
I0502 11:10:56.463677 26473 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0502 11:10:57.410886 26473 solver.cpp:362] Iteration 7500, Testing net (#0)
I0502 11:10:57.410914 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:57.536164 26473 solver.cpp:429]     Test net output #0: loss = 3.97315 (* 1 = 3.97315 loss)
I0502 11:10:57.539039 26473 solver.cpp:242] Iteration 7500 (92.5722 iter/s, 1.08024s/100 iter), loss = 1.76581
I0502 11:10:57.539060 26473 solver.cpp:261]     Train net output #0: loss = 1.76581 (* 1 = 1.76581 loss)
I0502 11:10:57.539068 26473 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0502 11:10:57.540825 26473 solver.cpp:362] Iteration 7500, Testing net (#0)
I0502 11:10:57.540840 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:10:57.672452 26473 solver.cpp:429]     Test net output #0: accuracy = 0.5765
I0502 11:10:57.672475 26473 solver.cpp:429]     Test net output #1: loss = 1.17772 (* 1 = 1.17772 loss)
I0502 11:10:57.675433 26473 solver.cpp:242] Iteration 7500 (82.5258 iter/s, 1.21174s/100 iter), loss = 1.01083
I0502 11:10:57.675453 26473 solver.cpp:261]     Train net output #0: loss = 1.01083 (* 1 = 1.01083 loss)
I0502 11:10:57.675462 26473 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0502 11:10:58.631675 26473 solver.cpp:242] Iteration 7600 (91.5257 iter/s, 1.09259s/100 iter), loss = 3.51439
I0502 11:10:58.631717 26473 solver.cpp:261]     Train net output #0: loss = 3.51439 (* 1 = 3.51439 loss)
I0502 11:10:58.631726 26473 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0502 11:10:58.636581 26473 solver.cpp:242] Iteration 7600 (104.046 iter/s, 0.961109s/100 iter), loss = 1.22305
I0502 11:10:58.636603 26473 solver.cpp:261]     Train net output #0: loss = 1.22305 (* 1 = 1.22305 loss)
I0502 11:10:58.636612 26473 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0502 11:10:59.594949 26473 solver.cpp:242] Iteration 7700 (103.819 iter/s, 0.96321s/100 iter), loss = 3.89688
I0502 11:10:59.594983 26473 solver.cpp:261]     Train net output #0: loss = 3.89688 (* 1 = 3.89688 loss)
I0502 11:10:59.594991 26473 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0502 11:10:59.599818 26473 solver.cpp:242] Iteration 7700 (103.821 iter/s, 0.963196s/100 iter), loss = 1.24084
I0502 11:10:59.599841 26473 solver.cpp:261]     Train net output #0: loss = 1.24084 (* 1 = 1.24084 loss)
I0502 11:10:59.599849 26473 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0502 11:11:00.569968 26473 solver.cpp:242] Iteration 7800 (102.568 iter/s, 0.974962s/100 iter), loss = 4.10837
I0502 11:11:00.570013 26473 solver.cpp:261]     Train net output #0: loss = 4.10837 (* 1 = 4.10837 loss)
I0502 11:11:00.570022 26473 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0502 11:11:00.574888 26473 solver.cpp:242] Iteration 7800 (102.561 iter/s, 0.975029s/100 iter), loss = 1.28961
I0502 11:11:00.574921 26473 solver.cpp:261]     Train net output #0: loss = 1.28961 (* 1 = 1.28961 loss)
I0502 11:11:00.574930 26473 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0502 11:11:01.535771 26473 solver.cpp:242] Iteration 7900 (103.548 iter/s, 0.965736s/100 iter), loss = 2.8719
I0502 11:11:01.535828 26473 solver.cpp:261]     Train net output #0: loss = 2.8719 (* 1 = 2.8719 loss)
I0502 11:11:01.535845 26473 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0502 11:11:01.540714 26473 solver.cpp:242] Iteration 7900 (103.544 iter/s, 0.965774s/100 iter), loss = 0.868975
I0502 11:11:01.540737 26473 solver.cpp:261]     Train net output #0: loss = 0.868975 (* 1 = 0.868975 loss)
I0502 11:11:01.540745 26473 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0502 11:11:02.492199 26473 solver.cpp:362] Iteration 8000, Testing net (#0)
I0502 11:11:02.492224 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:02.618978 26473 solver.cpp:429]     Test net output #0: loss = 3.18988 (* 1 = 3.18988 loss)
I0502 11:11:02.621922 26473 solver.cpp:242] Iteration 8000 (92.0748 iter/s, 1.08607s/100 iter), loss = 2.454
I0502 11:11:02.621942 26473 solver.cpp:261]     Train net output #0: loss = 2.454 (* 1 = 2.454 loss)
I0502 11:11:02.621949 26473 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0502 11:11:02.623699 26473 solver.cpp:362] Iteration 8000, Testing net (#0)
I0502 11:11:02.623713 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:02.756600 26473 solver.cpp:429]     Test net output #0: accuracy = 0.5525
I0502 11:11:02.756624 26473 solver.cpp:429]     Test net output #1: loss = 1.16445 (* 1 = 1.16445 loss)
I0502 11:11:02.759585 26473 solver.cpp:242] Iteration 8000 (82.0461 iter/s, 1.21883s/100 iter), loss = 1.38872
I0502 11:11:02.759604 26473 solver.cpp:261]     Train net output #0: loss = 1.38872 (* 1 = 1.38872 loss)
I0502 11:11:02.759613 26473 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0502 11:11:03.714746 26473 solver.cpp:242] Iteration 8100 (91.5096 iter/s, 1.09278s/100 iter), loss = 2.60441
I0502 11:11:03.714777 26473 solver.cpp:261]     Train net output #0: loss = 2.60441 (* 1 = 2.60441 loss)
I0502 11:11:03.714785 26473 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0502 11:11:03.719590 26473 solver.cpp:242] Iteration 8100 (104.17 iter/s, 0.959967s/100 iter), loss = 1.50995
I0502 11:11:03.719612 26473 solver.cpp:261]     Train net output #0: loss = 1.50995 (* 1 = 1.50995 loss)
I0502 11:11:03.719620 26473 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0502 11:11:04.674104 26473 solver.cpp:242] Iteration 8200 (104.242 iter/s, 0.959304s/100 iter), loss = 5.69285
I0502 11:11:04.674147 26473 solver.cpp:261]     Train net output #0: loss = 5.69285 (* 1 = 5.69285 loss)
I0502 11:11:04.674155 26473 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0502 11:11:04.679031 26473 solver.cpp:242] Iteration 8200 (104.232 iter/s, 0.9594s/100 iter), loss = 1.14414
I0502 11:11:04.679054 26473 solver.cpp:261]     Train net output #0: loss = 1.14414 (* 1 = 1.14414 loss)
I0502 11:11:04.679062 26473 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0502 11:11:05.633651 26473 solver.cpp:242] Iteration 8300 (104.223 iter/s, 0.959483s/100 iter), loss = 4.91265
I0502 11:11:05.633690 26473 solver.cpp:261]     Train net output #0: loss = 4.91265 (* 1 = 4.91265 loss)
I0502 11:11:05.633698 26473 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0502 11:11:05.638501 26473 solver.cpp:242] Iteration 8300 (104.229 iter/s, 0.959429s/100 iter), loss = 1.11655
I0502 11:11:05.638525 26473 solver.cpp:261]     Train net output #0: loss = 1.11655 (* 1 = 1.11655 loss)
I0502 11:11:05.638533 26473 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0502 11:11:06.589470 26473 solver.cpp:242] Iteration 8400 (104.629 iter/s, 0.955759s/100 iter), loss = 2.07012
I0502 11:11:06.589526 26473 solver.cpp:261]     Train net output #0: loss = 2.07012 (* 1 = 2.07012 loss)
I0502 11:11:06.589540 26473 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0502 11:11:06.594364 26473 solver.cpp:242] Iteration 8400 (104.622 iter/s, 0.955822s/100 iter), loss = 1.11959
I0502 11:11:06.594396 26473 solver.cpp:261]     Train net output #0: loss = 1.11959 (* 1 = 1.11959 loss)
I0502 11:11:06.594405 26473 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0502 11:11:07.543962 26473 solver.cpp:362] Iteration 8500, Testing net (#0)
I0502 11:11:07.543988 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:07.669844 26473 solver.cpp:429]     Test net output #0: loss = 3.381 (* 1 = 3.381 loss)
I0502 11:11:07.672755 26473 solver.cpp:242] Iteration 8500 (92.3183 iter/s, 1.08321s/100 iter), loss = 5.35837
I0502 11:11:07.672775 26473 solver.cpp:261]     Train net output #0: loss = 5.35837 (* 1 = 5.35837 loss)
I0502 11:11:07.672785 26473 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0502 11:11:07.674533 26473 solver.cpp:362] Iteration 8500, Testing net (#0)
I0502 11:11:07.674548 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:07.807011 26473 solver.cpp:429]     Test net output #0: accuracy = 0.4495
I0502 11:11:07.807034 26473 solver.cpp:429]     Test net output #1: loss = 1.32033 (* 1 = 1.32033 loss)
I0502 11:11:07.809995 26473 solver.cpp:242] Iteration 8500 (82.2654 iter/s, 1.21558s/100 iter), loss = 1.38272
I0502 11:11:07.810015 26473 solver.cpp:261]     Train net output #0: loss = 1.38272 (* 1 = 1.38272 loss)
I0502 11:11:07.810024 26473 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0502 11:11:08.761977 26473 solver.cpp:242] Iteration 8600 (91.8124 iter/s, 1.08918s/100 iter), loss = 4.00665
I0502 11:11:08.762017 26473 solver.cpp:261]     Train net output #0: loss = 4.00665 (* 1 = 4.00665 loss)
I0502 11:11:08.762025 26473 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0502 11:11:08.766860 26473 solver.cpp:242] Iteration 8600 (104.512 iter/s, 0.956826s/100 iter), loss = 0.691259
I0502 11:11:08.766883 26473 solver.cpp:261]     Train net output #0: loss = 0.691259 (* 1 = 0.691259 loss)
I0502 11:11:08.766891 26473 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0502 11:11:09.718417 26473 solver.cpp:242] Iteration 8700 (104.561 iter/s, 0.956378s/100 iter), loss = 2.31698
I0502 11:11:09.718459 26473 solver.cpp:261]     Train net output #0: loss = 2.31698 (* 1 = 2.31698 loss)
I0502 11:11:09.718468 26473 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0502 11:11:09.723290 26473 solver.cpp:242] Iteration 8700 (104.56 iter/s, 0.956388s/100 iter), loss = 0.965124
I0502 11:11:09.723314 26473 solver.cpp:261]     Train net output #0: loss = 0.965124 (* 1 = 0.965124 loss)
I0502 11:11:09.723321 26473 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0502 11:11:10.674326 26473 solver.cpp:242] Iteration 8800 (104.619 iter/s, 0.955846s/100 iter), loss = 2.78003
I0502 11:11:10.674372 26473 solver.cpp:261]     Train net output #0: loss = 2.78003 (* 1 = 2.78003 loss)
I0502 11:11:10.674381 26473 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0502 11:11:10.679174 26473 solver.cpp:242] Iteration 8800 (104.62 iter/s, 0.955844s/100 iter), loss = 0.969764
I0502 11:11:10.679198 26473 solver.cpp:261]     Train net output #0: loss = 0.969764 (* 1 = 0.969764 loss)
I0502 11:11:10.679206 26473 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0502 11:11:11.630297 26473 solver.cpp:242] Iteration 8900 (104.613 iter/s, 0.955904s/100 iter), loss = 5.48671
I0502 11:11:11.630353 26473 solver.cpp:261]     Train net output #0: loss = 5.48671 (* 1 = 5.48671 loss)
I0502 11:11:11.630363 26473 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0502 11:11:11.635213 26473 solver.cpp:242] Iteration 8900 (104.603 iter/s, 0.955996s/100 iter), loss = 1.03152
I0502 11:11:11.635248 26473 solver.cpp:261]     Train net output #0: loss = 1.03152 (* 1 = 1.03152 loss)
I0502 11:11:11.635257 26473 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0502 11:11:12.583680 26473 solver.cpp:362] Iteration 9000, Testing net (#0)
I0502 11:11:12.583703 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:12.709404 26473 solver.cpp:429]     Test net output #0: loss = 3.8237 (* 1 = 3.8237 loss)
I0502 11:11:12.712313 26473 solver.cpp:242] Iteration 9000 (92.4265 iter/s, 1.08194s/100 iter), loss = 3.58068
I0502 11:11:12.712340 26473 solver.cpp:261]     Train net output #0: loss = 3.58068 (* 1 = 3.58068 loss)
I0502 11:11:12.712349 26473 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0502 11:11:12.714092 26473 solver.cpp:362] Iteration 9000, Testing net (#0)
I0502 11:11:12.714104 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:12.846231 26473 solver.cpp:429]     Test net output #0: accuracy = 0.6145
I0502 11:11:12.846257 26473 solver.cpp:429]     Test net output #1: loss = 1.00763 (* 1 = 1.00763 loss)
I0502 11:11:12.849218 26473 solver.cpp:242] Iteration 9000 (82.3758 iter/s, 1.21395s/100 iter), loss = 1.47595
I0502 11:11:12.849238 26473 solver.cpp:261]     Train net output #0: loss = 1.47595 (* 1 = 1.47595 loss)
I0502 11:11:12.849247 26473 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0502 11:11:13.801313 26473 solver.cpp:242] Iteration 9100 (91.8316 iter/s, 1.08895s/100 iter), loss = 4.61823
I0502 11:11:13.801355 26473 solver.cpp:261]     Train net output #0: loss = 4.61823 (* 1 = 4.61823 loss)
I0502 11:11:13.801364 26473 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0502 11:11:13.806239 26473 solver.cpp:242] Iteration 9100 (104.495 iter/s, 0.956982s/100 iter), loss = 0.82274
I0502 11:11:13.806262 26473 solver.cpp:261]     Train net output #0: loss = 0.82274 (* 1 = 0.82274 loss)
I0502 11:11:13.806272 26473 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0502 11:11:14.758791 26473 solver.cpp:242] Iteration 9200 (104.448 iter/s, 0.957413s/100 iter), loss = 2.83732
I0502 11:11:14.758832 26473 solver.cpp:261]     Train net output #0: loss = 2.83732 (* 1 = 2.83732 loss)
I0502 11:11:14.758841 26473 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0502 11:11:14.763648 26473 solver.cpp:242] Iteration 9200 (104.453 iter/s, 0.957366s/100 iter), loss = 0.871924
I0502 11:11:14.763670 26473 solver.cpp:261]     Train net output #0: loss = 0.871924 (* 1 = 0.871924 loss)
I0502 11:11:14.763679 26473 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0502 11:11:15.714184 26473 solver.cpp:242] Iteration 9300 (104.676 iter/s, 0.955331s/100 iter), loss = 1.18378
I0502 11:11:15.714228 26473 solver.cpp:261]     Train net output #0: loss = 1.18378 (* 1 = 1.18378 loss)
I0502 11:11:15.714236 26473 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0502 11:11:15.719076 26473 solver.cpp:242] Iteration 9300 (104.67 iter/s, 0.955387s/100 iter), loss = 0.819087
I0502 11:11:15.719099 26473 solver.cpp:261]     Train net output #0: loss = 0.819087 (* 1 = 0.819087 loss)
I0502 11:11:15.719106 26473 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0502 11:11:16.670583 26473 solver.cpp:242] Iteration 9400 (104.566 iter/s, 0.956334s/100 iter), loss = 3.55783
I0502 11:11:16.670641 26473 solver.cpp:261]     Train net output #0: loss = 3.55783 (* 1 = 3.55783 loss)
I0502 11:11:16.670650 26473 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0502 11:11:16.675524 26473 solver.cpp:242] Iteration 9400 (104.558 iter/s, 0.956407s/100 iter), loss = 0.786419
I0502 11:11:16.675547 26473 solver.cpp:261]     Train net output #0: loss = 0.786419 (* 1 = 0.786419 loss)
I0502 11:11:16.675556 26473 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0502 11:11:17.624089 26473 solver.cpp:362] Iteration 9500, Testing net (#0)
I0502 11:11:17.624114 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:17.749727 26473 solver.cpp:429]     Test net output #0: loss = 3.53031 (* 1 = 3.53031 loss)
I0502 11:11:17.752622 26473 solver.cpp:242] Iteration 9500 (92.4246 iter/s, 1.08196s/100 iter), loss = 3.87101
I0502 11:11:17.752642 26473 solver.cpp:261]     Train net output #0: loss = 3.87101 (* 1 = 3.87101 loss)
I0502 11:11:17.752651 26473 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0502 11:11:17.754469 26473 solver.cpp:362] Iteration 9500, Testing net (#0)
I0502 11:11:17.754483 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:17.886317 26473 solver.cpp:429]     Test net output #0: accuracy = 0.566
I0502 11:11:17.886340 26473 solver.cpp:429]     Test net output #1: loss = 1.14293 (* 1 = 1.14293 loss)
I0502 11:11:17.889291 26473 solver.cpp:242] Iteration 9500 (82.3912 iter/s, 1.21372s/100 iter), loss = 1.31292
I0502 11:11:17.889312 26473 solver.cpp:261]     Train net output #0: loss = 1.31292 (* 1 = 1.31292 loss)
I0502 11:11:17.889319 26473 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0502 11:11:18.840683 26473 solver.cpp:242] Iteration 9600 (91.9103 iter/s, 1.08802s/100 iter), loss = 3.20072
I0502 11:11:18.840720 26473 solver.cpp:261]     Train net output #0: loss = 3.20072 (* 1 = 3.20072 loss)
I0502 11:11:18.840728 26473 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0502 11:11:18.845604 26473 solver.cpp:242] Iteration 9600 (104.572 iter/s, 0.956275s/100 iter), loss = 1.26344
I0502 11:11:18.845628 26473 solver.cpp:261]     Train net output #0: loss = 1.26344 (* 1 = 1.26344 loss)
I0502 11:11:18.845635 26473 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0502 11:11:19.796721 26473 solver.cpp:242] Iteration 9700 (104.605 iter/s, 0.955979s/100 iter), loss = 2.9352
I0502 11:11:19.796764 26473 solver.cpp:261]     Train net output #0: loss = 2.9352 (* 1 = 2.9352 loss)
I0502 11:11:19.796772 26473 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0502 11:11:19.801635 26473 solver.cpp:242] Iteration 9700 (104.604 iter/s, 0.955989s/100 iter), loss = 1.22931
I0502 11:11:19.801659 26473 solver.cpp:261]     Train net output #0: loss = 1.22931 (* 1 = 1.22931 loss)
I0502 11:11:19.801667 26473 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0502 11:11:20.754402 26473 solver.cpp:242] Iteration 9800 (104.426 iter/s, 0.957617s/100 iter), loss = 4.6204
I0502 11:11:20.754443 26473 solver.cpp:261]     Train net output #0: loss = 4.6204 (* 1 = 4.6204 loss)
I0502 11:11:20.754452 26473 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0502 11:11:20.759279 26473 solver.cpp:242] Iteration 9800 (104.428 iter/s, 0.9576s/100 iter), loss = 1.15504
I0502 11:11:20.759301 26473 solver.cpp:261]     Train net output #0: loss = 1.15504 (* 1 = 1.15504 loss)
I0502 11:11:20.759310 26473 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0502 11:11:21.714073 26473 solver.cpp:242] Iteration 9900 (104.209 iter/s, 0.959608s/100 iter), loss = 2.11983
I0502 11:11:21.714130 26473 solver.cpp:261]     Train net output #0: loss = 2.11983 (* 1 = 2.11983 loss)
I0502 11:11:21.714140 26473 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0502 11:11:21.719015 26473 solver.cpp:242] Iteration 9900 (104.2 iter/s, 0.959695s/100 iter), loss = 1.17586
I0502 11:11:21.719040 26473 solver.cpp:261]     Train net output #0: loss = 1.17586 (* 1 = 1.17586 loss)
I0502 11:11:21.719048 26473 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0502 11:11:22.672327 26473 solver.cpp:362] Iteration 10000, Testing net (#0)
I0502 11:11:22.672358 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:22.798918 26473 solver.cpp:429]     Test net output #0: loss = 3.21265 (* 1 = 3.21265 loss)
I0502 11:11:22.801878 26473 solver.cpp:242] Iteration 10000 (91.9348 iter/s, 1.08773s/100 iter), loss = 3.41625
I0502 11:11:22.801898 26473 solver.cpp:261]     Train net output #0: loss = 3.41625 (* 1 = 3.41625 loss)
I0502 11:11:22.801906 26473 sgd_solver.cpp:106] Iteration 10000, lr = 8e-05
I0502 11:11:22.803594 26473 solver.cpp:362] Iteration 10000, Testing net (#0)
I0502 11:11:22.803607 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:22.937078 26473 solver.cpp:429]     Test net output #0: accuracy = 0.544
I0502 11:11:22.937101 26473 solver.cpp:429]     Test net output #1: loss = 1.07433 (* 1 = 1.07433 loss)
I0502 11:11:22.940086 26473 solver.cpp:242] Iteration 10000 (81.8984 iter/s, 1.22102s/100 iter), loss = 1.08909
I0502 11:11:22.940106 26473 solver.cpp:261]     Train net output #0: loss = 1.08909 (* 1 = 1.08909 loss)
I0502 11:11:22.940114 26473 sgd_solver.cpp:106] Iteration 10000, lr = 8e-05
I0502 11:11:23.895942 26473 solver.cpp:242] Iteration 10100 (91.4061 iter/s, 1.09402s/100 iter), loss = 3.95342
I0502 11:11:23.895985 26473 solver.cpp:261]     Train net output #0: loss = 3.95342 (* 1 = 3.95342 loss)
I0502 11:11:23.895993 26473 sgd_solver.cpp:106] Iteration 10100, lr = 8e-05
I0502 11:11:23.900918 26473 solver.cpp:242] Iteration 10100 (104.081 iter/s, 0.960792s/100 iter), loss = 0.946313
I0502 11:11:23.900941 26473 solver.cpp:261]     Train net output #0: loss = 0.946313 (* 1 = 0.946313 loss)
I0502 11:11:23.900949 26473 sgd_solver.cpp:106] Iteration 10100, lr = 8e-05
I0502 11:11:24.856628 26473 solver.cpp:242] Iteration 10200 (104.099 iter/s, 0.960623s/100 iter), loss = 4.81613
I0502 11:11:24.856667 26473 solver.cpp:261]     Train net output #0: loss = 4.81613 (* 1 = 4.81613 loss)
I0502 11:11:24.856675 26473 sgd_solver.cpp:106] Iteration 10200, lr = 8e-05
I0502 11:11:24.861503 26473 solver.cpp:242] Iteration 10200 (104.108 iter/s, 0.960545s/100 iter), loss = 0.844521
I0502 11:11:24.861526 26473 solver.cpp:261]     Train net output #0: loss = 0.844521 (* 1 = 0.844521 loss)
I0502 11:11:24.861534 26473 sgd_solver.cpp:106] Iteration 10200, lr = 8e-05
I0502 11:11:25.818419 26473 solver.cpp:242] Iteration 10300 (103.979 iter/s, 0.961731s/100 iter), loss = 1.8988
I0502 11:11:25.818464 26473 solver.cpp:261]     Train net output #0: loss = 1.8988 (* 1 = 1.8988 loss)
I0502 11:11:25.818473 26473 sgd_solver.cpp:106] Iteration 10300, lr = 8e-05
I0502 11:11:25.823279 26473 solver.cpp:242] Iteration 10300 (103.979 iter/s, 0.961735s/100 iter), loss = 1.08909
I0502 11:11:25.823303 26473 solver.cpp:261]     Train net output #0: loss = 1.08909 (* 1 = 1.08909 loss)
I0502 11:11:25.823312 26473 sgd_solver.cpp:106] Iteration 10300, lr = 8e-05
I0502 11:11:26.778882 26473 solver.cpp:242] Iteration 10400 (104.124 iter/s, 0.960394s/100 iter), loss = 2.42754
I0502 11:11:26.778939 26473 solver.cpp:261]     Train net output #0: loss = 2.42754 (* 1 = 2.42754 loss)
I0502 11:11:26.778947 26473 sgd_solver.cpp:106] Iteration 10400, lr = 8e-05
I0502 11:11:26.783819 26473 solver.cpp:242] Iteration 10400 (104.114 iter/s, 0.960488s/100 iter), loss = 0.860229
I0502 11:11:26.783843 26473 solver.cpp:261]     Train net output #0: loss = 0.860229 (* 1 = 0.860229 loss)
I0502 11:11:26.783851 26473 sgd_solver.cpp:106] Iteration 10400, lr = 8e-05
I0502 11:11:27.736438 26473 solver.cpp:362] Iteration 10500, Testing net (#0)
I0502 11:11:27.736457 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:27.863034 26473 solver.cpp:429]     Test net output #0: loss = 2.88099 (* 1 = 2.88099 loss)
I0502 11:11:27.865969 26473 solver.cpp:242] Iteration 10500 (91.9951 iter/s, 1.08701s/100 iter), loss = 2.48106
I0502 11:11:27.865989 26473 solver.cpp:261]     Train net output #0: loss = 2.48106 (* 1 = 2.48106 loss)
I0502 11:11:27.865998 26473 sgd_solver.cpp:106] Iteration 10500, lr = 8e-05
I0502 11:11:27.867653 26473 solver.cpp:362] Iteration 10500, Testing net (#0)
I0502 11:11:27.867666 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:28.000874 26473 solver.cpp:429]     Test net output #0: accuracy = 0.641
I0502 11:11:28.000893 26473 solver.cpp:429]     Test net output #1: loss = 0.88855 (* 1 = 0.88855 loss)
I0502 11:11:28.003875 26473 solver.cpp:242] Iteration 10500 (81.9666 iter/s, 1.22001s/100 iter), loss = 0.869547
I0502 11:11:28.003893 26473 solver.cpp:261]     Train net output #0: loss = 0.869547 (* 1 = 0.869547 loss)
I0502 11:11:28.003901 26473 sgd_solver.cpp:106] Iteration 10500, lr = 8e-05
I0502 11:11:28.960516 26473 solver.cpp:242] Iteration 10600 (91.3658 iter/s, 1.0945s/100 iter), loss = 2.18745
I0502 11:11:28.960564 26473 solver.cpp:261]     Train net output #0: loss = 2.18745 (* 1 = 2.18745 loss)
I0502 11:11:28.960574 26473 sgd_solver.cpp:106] Iteration 10600, lr = 8e-05
I0502 11:11:28.965464 26473 solver.cpp:242] Iteration 10600 (103.999 iter/s, 0.961551s/100 iter), loss = 0.968542
I0502 11:11:28.965487 26473 solver.cpp:261]     Train net output #0: loss = 0.968542 (* 1 = 0.968542 loss)
I0502 11:11:28.965495 26473 sgd_solver.cpp:106] Iteration 10600, lr = 8e-05
I0502 11:11:29.920543 26473 solver.cpp:242] Iteration 10700 (104.171 iter/s, 0.959958s/100 iter), loss = 2.52354
I0502 11:11:29.920593 26473 solver.cpp:261]     Train net output #0: loss = 2.52354 (* 1 = 2.52354 loss)
I0502 11:11:29.920601 26473 sgd_solver.cpp:106] Iteration 10700, lr = 8e-05
I0502 11:11:29.925436 26473 solver.cpp:242] Iteration 10700 (104.174 iter/s, 0.95993s/100 iter), loss = 0.957957
I0502 11:11:29.925459 26473 solver.cpp:261]     Train net output #0: loss = 0.957957 (* 1 = 0.957957 loss)
I0502 11:11:29.925467 26473 sgd_solver.cpp:106] Iteration 10700, lr = 8e-05
I0502 11:11:30.881937 26473 solver.cpp:242] Iteration 10800 (104.023 iter/s, 0.961324s/100 iter), loss = 3.62534
I0502 11:11:30.881973 26473 solver.cpp:261]     Train net output #0: loss = 3.62534 (* 1 = 3.62534 loss)
I0502 11:11:30.881981 26473 sgd_solver.cpp:106] Iteration 10800, lr = 8e-05
I0502 11:11:30.886796 26473 solver.cpp:242] Iteration 10800 (104.024 iter/s, 0.961319s/100 iter), loss = 0.936106
I0502 11:11:30.886819 26473 solver.cpp:261]     Train net output #0: loss = 0.936106 (* 1 = 0.936106 loss)
I0502 11:11:30.886827 26473 sgd_solver.cpp:106] Iteration 10800, lr = 8e-05
I0502 11:11:31.842034 26473 solver.cpp:242] Iteration 10900 (104.163 iter/s, 0.960038s/100 iter), loss = 1.79841
I0502 11:11:31.842079 26473 solver.cpp:261]     Train net output #0: loss = 1.79841 (* 1 = 1.79841 loss)
I0502 11:11:31.842088 26473 sgd_solver.cpp:106] Iteration 10900, lr = 8e-05
I0502 11:11:31.846935 26473 solver.cpp:242] Iteration 10900 (104.156 iter/s, 0.960096s/100 iter), loss = 0.724971
I0502 11:11:31.846958 26473 solver.cpp:261]     Train net output #0: loss = 0.724971 (* 1 = 0.724971 loss)
I0502 11:11:31.846966 26473 sgd_solver.cpp:106] Iteration 10900, lr = 8e-05
I0502 11:11:32.796757 26473 solver.cpp:362] Iteration 11000, Testing net (#0)
I0502 11:11:32.796787 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:32.922719 26473 solver.cpp:429]     Test net output #0: loss = 2.89297 (* 1 = 2.89297 loss)
I0502 11:11:32.925665 26473 solver.cpp:242] Iteration 11000 (92.2879 iter/s, 1.08357s/100 iter), loss = 4.04891
I0502 11:11:32.925686 26473 solver.cpp:261]     Train net output #0: loss = 4.04891 (* 1 = 4.04891 loss)
I0502 11:11:32.925694 26473 sgd_solver.cpp:106] Iteration 11000, lr = 8e-05
I0502 11:11:32.927389 26473 solver.cpp:362] Iteration 11000, Testing net (#0)
I0502 11:11:32.927403 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:33.059772 26473 solver.cpp:429]     Test net output #0: accuracy = 0.684
I0502 11:11:33.059795 26473 solver.cpp:429]     Test net output #1: loss = 0.834454 (* 1 = 0.834454 loss)
I0502 11:11:33.062770 26473 solver.cpp:242] Iteration 11000 (82.251 iter/s, 1.21579s/100 iter), loss = 0.572993
I0502 11:11:33.062790 26473 solver.cpp:261]     Train net output #0: loss = 0.572993 (* 1 = 0.572993 loss)
I0502 11:11:33.062799 26473 sgd_solver.cpp:106] Iteration 11000, lr = 8e-05
I0502 11:11:34.015038 26473 solver.cpp:242] Iteration 11100 (91.7997 iter/s, 1.08933s/100 iter), loss = 2.24038
I0502 11:11:34.015079 26473 solver.cpp:261]     Train net output #0: loss = 2.24038 (* 1 = 2.24038 loss)
I0502 11:11:34.015087 26473 sgd_solver.cpp:106] Iteration 11100, lr = 8e-05
I0502 11:11:34.019974 26473 solver.cpp:242] Iteration 11100 (104.475 iter/s, 0.957165s/100 iter), loss = 1.04215
I0502 11:11:34.019996 26473 solver.cpp:261]     Train net output #0: loss = 1.04215 (* 1 = 1.04215 loss)
I0502 11:11:34.020005 26473 sgd_solver.cpp:106] Iteration 11100, lr = 8e-05
I0502 11:11:34.972971 26473 solver.cpp:242] Iteration 11200 (104.398 iter/s, 0.957872s/100 iter), loss = 3.76451
I0502 11:11:34.973009 26473 solver.cpp:261]     Train net output #0: loss = 3.76451 (* 1 = 3.76451 loss)
I0502 11:11:34.973018 26473 sgd_solver.cpp:106] Iteration 11200, lr = 8e-05
I0502 11:11:34.977869 26473 solver.cpp:242] Iteration 11200 (104.4 iter/s, 0.957853s/100 iter), loss = 0.69822
I0502 11:11:34.977890 26473 solver.cpp:261]     Train net output #0: loss = 0.69822 (* 1 = 0.69822 loss)
I0502 11:11:34.977900 26473 sgd_solver.cpp:106] Iteration 11200, lr = 8e-05
I0502 11:11:35.929836 26473 solver.cpp:242] Iteration 11300 (104.515 iter/s, 0.956804s/100 iter), loss = 3.7454
I0502 11:11:35.929879 26473 solver.cpp:261]     Train net output #0: loss = 3.7454 (* 1 = 3.7454 loss)
I0502 11:11:35.929895 26473 sgd_solver.cpp:106] Iteration 11300, lr = 8e-05
I0502 11:11:35.934689 26473 solver.cpp:242] Iteration 11300 (104.517 iter/s, 0.95678s/100 iter), loss = 0.720687
I0502 11:11:35.934712 26473 solver.cpp:261]     Train net output #0: loss = 0.720687 (* 1 = 0.720687 loss)
I0502 11:11:35.934720 26473 sgd_solver.cpp:106] Iteration 11300, lr = 8e-05
I0502 11:11:36.887707 26473 solver.cpp:242] Iteration 11400 (104.405 iter/s, 0.957809s/100 iter), loss = 1.25934
I0502 11:11:36.887755 26473 solver.cpp:261]     Train net output #0: loss = 1.25934 (* 1 = 1.25934 loss)
I0502 11:11:36.887765 26473 sgd_solver.cpp:106] Iteration 11400, lr = 8e-05
I0502 11:11:36.892647 26473 solver.cpp:242] Iteration 11400 (104.393 iter/s, 0.957915s/100 iter), loss = 1.03186
I0502 11:11:36.892669 26473 solver.cpp:261]     Train net output #0: loss = 1.03186 (* 1 = 1.03186 loss)
I0502 11:11:36.892678 26473 sgd_solver.cpp:106] Iteration 11400, lr = 8e-05
I0502 11:11:37.841578 26473 solver.cpp:362] Iteration 11500, Testing net (#0)
I0502 11:11:37.841608 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:37.967521 26473 solver.cpp:429]     Test net output #0: loss = 3.1265 (* 1 = 3.1265 loss)
I0502 11:11:37.970465 26473 solver.cpp:242] Iteration 11500 (92.3625 iter/s, 1.08269s/100 iter), loss = 2.68408
I0502 11:11:37.970486 26473 solver.cpp:261]     Train net output #0: loss = 2.68408 (* 1 = 2.68408 loss)
I0502 11:11:37.970494 26473 sgd_solver.cpp:106] Iteration 11500, lr = 8e-05
I0502 11:11:37.972162 26473 solver.cpp:362] Iteration 11500, Testing net (#0)
I0502 11:11:37.972175 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:38.105480 26473 solver.cpp:429]     Test net output #0: accuracy = 0.636
I0502 11:11:38.105504 26473 solver.cpp:429]     Test net output #1: loss = 0.890377 (* 1 = 0.890377 loss)
I0502 11:11:38.108500 26473 solver.cpp:242] Iteration 11500 (82.2498 iter/s, 1.21581s/100 iter), loss = 0.550871
I0502 11:11:38.108520 26473 solver.cpp:261]     Train net output #0: loss = 0.550871 (* 1 = 0.550871 loss)
I0502 11:11:38.108528 26473 sgd_solver.cpp:106] Iteration 11500, lr = 8e-05
I0502 11:11:39.061635 26473 solver.cpp:242] Iteration 11600 (91.6486 iter/s, 1.09112s/100 iter), loss = 1.72104
I0502 11:11:39.061678 26473 solver.cpp:261]     Train net output #0: loss = 1.72104 (* 1 = 1.72104 loss)
I0502 11:11:39.061687 26473 sgd_solver.cpp:106] Iteration 11600, lr = 8e-05
I0502 11:11:39.066576 26473 solver.cpp:242] Iteration 11600 (104.38 iter/s, 0.958037s/100 iter), loss = 0.957899
I0502 11:11:39.066599 26473 solver.cpp:261]     Train net output #0: loss = 0.957899 (* 1 = 0.957899 loss)
I0502 11:11:39.066607 26473 sgd_solver.cpp:106] Iteration 11600, lr = 8e-05
I0502 11:11:40.022357 26473 solver.cpp:242] Iteration 11700 (104.095 iter/s, 0.960657s/100 iter), loss = 2.56266
I0502 11:11:40.022398 26473 solver.cpp:261]     Train net output #0: loss = 2.56266 (* 1 = 2.56266 loss)
I0502 11:11:40.022408 26473 sgd_solver.cpp:106] Iteration 11700, lr = 8e-05
I0502 11:11:40.027233 26473 solver.cpp:242] Iteration 11700 (104.1 iter/s, 0.960615s/100 iter), loss = 0.716076
I0502 11:11:40.027256 26473 solver.cpp:261]     Train net output #0: loss = 0.716076 (* 1 = 0.716076 loss)
I0502 11:11:40.027264 26473 sgd_solver.cpp:106] Iteration 11700, lr = 8e-05
I0502 11:11:40.984812 26473 solver.cpp:242] Iteration 11800 (103.908 iter/s, 0.962393s/100 iter), loss = 1.30849
I0502 11:11:40.984840 26473 solver.cpp:261]     Train net output #0: loss = 1.30849 (* 1 = 1.30849 loss)
I0502 11:11:40.984848 26473 sgd_solver.cpp:106] Iteration 11800, lr = 8e-05
I0502 11:11:40.989661 26473 solver.cpp:242] Iteration 11800 (103.908 iter/s, 0.962387s/100 iter), loss = 0.871256
I0502 11:11:40.989683 26473 solver.cpp:261]     Train net output #0: loss = 0.871256 (* 1 = 0.871256 loss)
I0502 11:11:40.989692 26473 sgd_solver.cpp:106] Iteration 11800, lr = 8e-05
I0502 11:11:41.946079 26473 solver.cpp:242] Iteration 11900 (104.035 iter/s, 0.961215s/100 iter), loss = 1.51398
I0502 11:11:41.946136 26473 solver.cpp:261]     Train net output #0: loss = 1.51398 (* 1 = 1.51398 loss)
I0502 11:11:41.946159 26473 sgd_solver.cpp:106] Iteration 11900, lr = 8e-05
I0502 11:11:41.951023 26473 solver.cpp:242] Iteration 11900 (104.023 iter/s, 0.961322s/100 iter), loss = 0.782088
I0502 11:11:41.951047 26473 solver.cpp:261]     Train net output #0: loss = 0.782088 (* 1 = 0.782088 loss)
I0502 11:11:41.951056 26473 sgd_solver.cpp:106] Iteration 11900, lr = 8e-05
I0502 11:11:42.904309 26473 solver.cpp:362] Iteration 12000, Testing net (#0)
I0502 11:11:42.904331 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:43.030375 26473 solver.cpp:429]     Test net output #0: loss = 2.88068 (* 1 = 2.88068 loss)
I0502 11:11:43.033280 26473 solver.cpp:242] Iteration 12000 (91.9858 iter/s, 1.08712s/100 iter), loss = 3.31573
I0502 11:11:43.033301 26473 solver.cpp:261]     Train net output #0: loss = 3.31573 (* 1 = 3.31573 loss)
I0502 11:11:43.033309 26473 sgd_solver.cpp:106] Iteration 12000, lr = 8e-05
I0502 11:11:43.035028 26473 solver.cpp:362] Iteration 12000, Testing net (#0)
I0502 11:11:43.035042 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:43.168553 26473 solver.cpp:429]     Test net output #0: accuracy = 0.6565
I0502 11:11:43.168576 26473 solver.cpp:429]     Test net output #1: loss = 0.852947 (* 1 = 0.852947 loss)
I0502 11:11:43.171572 26473 solver.cpp:242] Iteration 12000 (81.9334 iter/s, 1.2205s/100 iter), loss = 0.769219
I0502 11:11:43.171593 26473 solver.cpp:261]     Train net output #0: loss = 0.769219 (* 1 = 0.769219 loss)
I0502 11:11:43.171602 26473 sgd_solver.cpp:106] Iteration 12000, lr = 8e-05
I0502 11:11:44.127447 26473 solver.cpp:242] Iteration 12100 (91.3975 iter/s, 1.09412s/100 iter), loss = 2.20269
I0502 11:11:44.127490 26473 solver.cpp:261]     Train net output #0: loss = 2.20269 (* 1 = 2.20269 loss)
I0502 11:11:44.127498 26473 sgd_solver.cpp:106] Iteration 12100, lr = 8e-05
I0502 11:11:44.132416 26473 solver.cpp:242] Iteration 12100 (104.08 iter/s, 0.960798s/100 iter), loss = 0.869492
I0502 11:11:44.132441 26473 solver.cpp:261]     Train net output #0: loss = 0.869492 (* 1 = 0.869492 loss)
I0502 11:11:44.132448 26473 sgd_solver.cpp:106] Iteration 12100, lr = 8e-05
I0502 11:11:45.085940 26473 solver.cpp:242] Iteration 12200 (104.338 iter/s, 0.958428s/100 iter), loss = 3.71964
I0502 11:11:45.085985 26473 solver.cpp:261]     Train net output #0: loss = 3.71964 (* 1 = 3.71964 loss)
I0502 11:11:45.085994 26473 sgd_solver.cpp:106] Iteration 12200, lr = 8e-05
I0502 11:11:45.090951 26473 solver.cpp:242] Iteration 12200 (104.33 iter/s, 0.958493s/100 iter), loss = 0.673282
I0502 11:11:45.090975 26473 solver.cpp:261]     Train net output #0: loss = 0.673282 (* 1 = 0.673282 loss)
I0502 11:11:45.090983 26473 sgd_solver.cpp:106] Iteration 12200, lr = 8e-05
I0502 11:11:46.044507 26473 solver.cpp:242] Iteration 12300 (104.33 iter/s, 0.958501s/100 iter), loss = 5.03343
I0502 11:11:46.044553 26473 solver.cpp:261]     Train net output #0: loss = 5.03343 (* 1 = 5.03343 loss)
I0502 11:11:46.044564 26473 sgd_solver.cpp:106] Iteration 12300, lr = 8e-05
I0502 11:11:46.049376 26473 solver.cpp:242] Iteration 12300 (104.342 iter/s, 0.958383s/100 iter), loss = 0.838492
I0502 11:11:46.049398 26473 solver.cpp:261]     Train net output #0: loss = 0.838492 (* 1 = 0.838492 loss)
I0502 11:11:46.049407 26473 sgd_solver.cpp:106] Iteration 12300, lr = 8e-05
I0502 11:11:47.003276 26473 solver.cpp:242] Iteration 12400 (104.307 iter/s, 0.958705s/100 iter), loss = 3.33493
I0502 11:11:47.003334 26473 solver.cpp:261]     Train net output #0: loss = 3.33493 (* 1 = 3.33493 loss)
I0502 11:11:47.003343 26473 sgd_solver.cpp:106] Iteration 12400, lr = 8e-05
I0502 11:11:47.008258 26473 solver.cpp:242] Iteration 12400 (104.293 iter/s, 0.958841s/100 iter), loss = 0.592969
I0502 11:11:47.008285 26473 solver.cpp:261]     Train net output #0: loss = 0.592969 (* 1 = 0.592969 loss)
I0502 11:11:47.008292 26473 sgd_solver.cpp:106] Iteration 12400, lr = 8e-05
I0502 11:11:47.958945 26473 solver.cpp:362] Iteration 12500, Testing net (#0)
I0502 11:11:47.958976 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:48.085139 26473 solver.cpp:429]     Test net output #0: loss = 2.32786 (* 1 = 2.32786 loss)
I0502 11:11:48.088062 26473 solver.cpp:242] Iteration 12500 (92.1907 iter/s, 1.08471s/100 iter), loss = 1.22039
I0502 11:11:48.088081 26473 solver.cpp:261]     Train net output #0: loss = 1.22039 (* 1 = 1.22039 loss)
I0502 11:11:48.088089 26473 sgd_solver.cpp:106] Iteration 12500, lr = 8e-05
I0502 11:11:48.089781 26473 solver.cpp:362] Iteration 12500, Testing net (#0)
I0502 11:11:48.089797 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:48.222466 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7285
I0502 11:11:48.222491 26473 solver.cpp:429]     Test net output #1: loss = 0.704525 (* 1 = 0.704525 loss)
I0502 11:11:48.225466 26473 solver.cpp:242] Iteration 12500 (82.1585 iter/s, 1.21716s/100 iter), loss = 0.599136
I0502 11:11:48.225486 26473 solver.cpp:261]     Train net output #0: loss = 0.599136 (* 1 = 0.599136 loss)
I0502 11:11:48.225494 26473 sgd_solver.cpp:106] Iteration 12500, lr = 8e-05
I0502 11:11:49.181378 26473 solver.cpp:242] Iteration 12600 (91.4686 iter/s, 1.09327s/100 iter), loss = 3.35043
I0502 11:11:49.181418 26473 solver.cpp:261]     Train net output #0: loss = 3.35043 (* 1 = 3.35043 loss)
I0502 11:11:49.181427 26473 sgd_solver.cpp:106] Iteration 12600, lr = 8e-05
I0502 11:11:49.186266 26473 solver.cpp:242] Iteration 12600 (104.084 iter/s, 0.960762s/100 iter), loss = 0.646449
I0502 11:11:49.186291 26473 solver.cpp:261]     Train net output #0: loss = 0.646449 (* 1 = 0.646449 loss)
I0502 11:11:49.186300 26473 sgd_solver.cpp:106] Iteration 12600, lr = 8e-05
I0502 11:11:50.139380 26473 solver.cpp:242] Iteration 12700 (104.39 iter/s, 0.957942s/100 iter), loss = 1.34875
I0502 11:11:50.139415 26473 solver.cpp:261]     Train net output #0: loss = 1.34875 (* 1 = 1.34875 loss)
I0502 11:11:50.139422 26473 sgd_solver.cpp:106] Iteration 12700, lr = 8e-05
I0502 11:11:50.144310 26473 solver.cpp:242] Iteration 12700 (104.384 iter/s, 0.958001s/100 iter), loss = 0.595882
I0502 11:11:50.144332 26473 solver.cpp:261]     Train net output #0: loss = 0.595882 (* 1 = 0.595882 loss)
I0502 11:11:50.144340 26473 sgd_solver.cpp:106] Iteration 12700, lr = 8e-05
I0502 11:11:51.098541 26473 solver.cpp:242] Iteration 12800 (104.264 iter/s, 0.959104s/100 iter), loss = 4.15283
I0502 11:11:51.098582 26473 solver.cpp:261]     Train net output #0: loss = 4.15283 (* 1 = 4.15283 loss)
I0502 11:11:51.098592 26473 sgd_solver.cpp:106] Iteration 12800, lr = 8e-05
I0502 11:11:51.103472 26473 solver.cpp:242] Iteration 12800 (104.262 iter/s, 0.959122s/100 iter), loss = 0.723671
I0502 11:11:51.103497 26473 solver.cpp:261]     Train net output #0: loss = 0.723671 (* 1 = 0.723671 loss)
I0502 11:11:51.103504 26473 sgd_solver.cpp:106] Iteration 12800, lr = 8e-05
I0502 11:11:52.056720 26473 solver.cpp:242] Iteration 12900 (104.372 iter/s, 0.958116s/100 iter), loss = 3.18884
I0502 11:11:52.056762 26473 solver.cpp:261]     Train net output #0: loss = 3.18884 (* 1 = 3.18884 loss)
I0502 11:11:52.056771 26473 sgd_solver.cpp:106] Iteration 12900, lr = 8e-05
I0502 11:11:52.061628 26473 solver.cpp:242] Iteration 12900 (104.372 iter/s, 0.958113s/100 iter), loss = 0.824746
I0502 11:11:52.061655 26473 solver.cpp:261]     Train net output #0: loss = 0.824746 (* 1 = 0.824746 loss)
I0502 11:11:52.061662 26473 sgd_solver.cpp:106] Iteration 12900, lr = 8e-05
I0502 11:11:53.012384 26473 solver.cpp:362] Iteration 13000, Testing net (#0)
I0502 11:11:53.012413 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:53.138869 26473 solver.cpp:429]     Test net output #0: loss = 2.30603 (* 1 = 2.30603 loss)
I0502 11:11:53.141810 26473 solver.cpp:242] Iteration 13000 (92.1633 iter/s, 1.08503s/100 iter), loss = 3.0285
I0502 11:11:53.141830 26473 solver.cpp:261]     Train net output #0: loss = 3.0285 (* 1 = 3.0285 loss)
I0502 11:11:53.141839 26473 sgd_solver.cpp:106] Iteration 13000, lr = 8e-05
I0502 11:11:53.143584 26473 solver.cpp:362] Iteration 13000, Testing net (#0)
I0502 11:11:53.143599 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:53.276469 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7305
I0502 11:11:53.276495 26473 solver.cpp:429]     Test net output #1: loss = 0.700378 (* 1 = 0.700378 loss)
I0502 11:11:53.279474 26473 solver.cpp:242] Iteration 13000 (82.1155 iter/s, 1.2178s/100 iter), loss = 0.658461
I0502 11:11:53.279494 26473 solver.cpp:261]     Train net output #0: loss = 0.658461 (* 1 = 0.658461 loss)
I0502 11:11:53.279502 26473 sgd_solver.cpp:106] Iteration 13000, lr = 8e-05
I0502 11:11:54.233072 26473 solver.cpp:242] Iteration 13100 (91.6408 iter/s, 1.09122s/100 iter), loss = 3.24675
I0502 11:11:54.233114 26473 solver.cpp:261]     Train net output #0: loss = 3.24675 (* 1 = 3.24675 loss)
I0502 11:11:54.233122 26473 sgd_solver.cpp:106] Iteration 13100, lr = 8e-05
I0502 11:11:54.237936 26473 solver.cpp:242] Iteration 13100 (104.338 iter/s, 0.958423s/100 iter), loss = 0.74392
I0502 11:11:54.237959 26473 solver.cpp:261]     Train net output #0: loss = 0.74392 (* 1 = 0.74392 loss)
I0502 11:11:54.237967 26473 sgd_solver.cpp:106] Iteration 13100, lr = 8e-05
I0502 11:11:55.191501 26473 solver.cpp:242] Iteration 13200 (104.344 iter/s, 0.958365s/100 iter), loss = 3.56877
I0502 11:11:55.191543 26473 solver.cpp:261]     Train net output #0: loss = 3.56877 (* 1 = 3.56877 loss)
I0502 11:11:55.191552 26473 sgd_solver.cpp:106] Iteration 13200, lr = 8e-05
I0502 11:11:55.196499 26473 solver.cpp:242] Iteration 13200 (104.327 iter/s, 0.958521s/100 iter), loss = 0.61561
I0502 11:11:55.196522 26473 solver.cpp:261]     Train net output #0: loss = 0.61561 (* 1 = 0.61561 loss)
I0502 11:11:55.196530 26473 sgd_solver.cpp:106] Iteration 13200, lr = 8e-05
I0502 11:11:56.149317 26473 solver.cpp:242] Iteration 13300 (104.411 iter/s, 0.957752s/100 iter), loss = 1.80151
I0502 11:11:56.149354 26473 solver.cpp:261]     Train net output #0: loss = 1.80151 (* 1 = 1.80151 loss)
I0502 11:11:56.149363 26473 sgd_solver.cpp:106] Iteration 13300, lr = 8e-05
I0502 11:11:56.154242 26473 solver.cpp:242] Iteration 13300 (104.417 iter/s, 0.957701s/100 iter), loss = 0.736587
I0502 11:11:56.154264 26473 solver.cpp:261]     Train net output #0: loss = 0.736587 (* 1 = 0.736587 loss)
I0502 11:11:56.154273 26473 sgd_solver.cpp:106] Iteration 13300, lr = 8e-05
I0502 11:11:57.108695 26473 solver.cpp:242] Iteration 13400 (104.241 iter/s, 0.959317s/100 iter), loss = 2.11404
I0502 11:11:57.108741 26473 solver.cpp:261]     Train net output #0: loss = 2.11404 (* 1 = 2.11404 loss)
I0502 11:11:57.108749 26473 sgd_solver.cpp:106] Iteration 13400, lr = 8e-05
I0502 11:11:57.113620 26473 solver.cpp:242] Iteration 13400 (104.239 iter/s, 0.959337s/100 iter), loss = 0.995434
I0502 11:11:57.113646 26473 solver.cpp:261]     Train net output #0: loss = 0.995434 (* 1 = 0.995434 loss)
I0502 11:11:57.113653 26473 sgd_solver.cpp:106] Iteration 13400, lr = 8e-05
I0502 11:11:58.064191 26473 solver.cpp:362] Iteration 13500, Testing net (#0)
I0502 11:11:58.064219 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:58.190374 26473 solver.cpp:429]     Test net output #0: loss = 2.60449 (* 1 = 2.60449 loss)
I0502 11:11:58.193296 26473 solver.cpp:242] Iteration 13500 (92.2052 iter/s, 1.08454s/100 iter), loss = 1.72576
I0502 11:11:58.193317 26473 solver.cpp:261]     Train net output #0: loss = 1.72576 (* 1 = 1.72576 loss)
I0502 11:11:58.193325 26473 sgd_solver.cpp:106] Iteration 13500, lr = 8e-05
I0502 11:11:58.195029 26473 solver.cpp:362] Iteration 13500, Testing net (#0)
I0502 11:11:58.195044 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:11:58.327664 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7415
I0502 11:11:58.327687 26473 solver.cpp:429]     Test net output #1: loss = 0.64399 (* 1 = 0.64399 loss)
I0502 11:11:58.330651 26473 solver.cpp:242] Iteration 13500 (82.1703 iter/s, 1.21698s/100 iter), loss = 0.791685
I0502 11:11:58.330672 26473 solver.cpp:261]     Train net output #0: loss = 0.791685 (* 1 = 0.791685 loss)
I0502 11:11:58.330679 26473 sgd_solver.cpp:106] Iteration 13500, lr = 8e-05
I0502 11:11:59.284092 26473 solver.cpp:242] Iteration 13600 (91.6798 iter/s, 1.09075s/100 iter), loss = 2.73377
I0502 11:11:59.284137 26473 solver.cpp:261]     Train net output #0: loss = 2.73377 (* 1 = 2.73377 loss)
I0502 11:11:59.284145 26473 sgd_solver.cpp:106] Iteration 13600, lr = 8e-05
I0502 11:11:59.288957 26473 solver.cpp:242] Iteration 13600 (104.355 iter/s, 0.958267s/100 iter), loss = 0.847752
I0502 11:11:59.288981 26473 solver.cpp:261]     Train net output #0: loss = 0.847752 (* 1 = 0.847752 loss)
I0502 11:11:59.288990 26473 sgd_solver.cpp:106] Iteration 13600, lr = 8e-05
I0502 11:12:00.249702 26473 solver.cpp:242] Iteration 13700 (103.569 iter/s, 0.965539s/100 iter), loss = 2.82526
I0502 11:12:00.249765 26473 solver.cpp:261]     Train net output #0: loss = 2.82526 (* 1 = 2.82526 loss)
I0502 11:12:00.249779 26473 sgd_solver.cpp:106] Iteration 13700, lr = 8e-05
I0502 11:12:00.255960 26473 solver.cpp:242] Iteration 13700 (103.417 iter/s, 0.966956s/100 iter), loss = 0.857613
I0502 11:12:00.256003 26473 solver.cpp:261]     Train net output #0: loss = 0.857613 (* 1 = 0.857613 loss)
I0502 11:12:00.256012 26473 sgd_solver.cpp:106] Iteration 13700, lr = 8e-05
I0502 11:12:01.210551 26473 solver.cpp:242] Iteration 13800 (104.084 iter/s, 0.960767s/100 iter), loss = 1.4855
I0502 11:12:01.210594 26473 solver.cpp:261]     Train net output #0: loss = 1.4855 (* 1 = 1.4855 loss)
I0502 11:12:01.210603 26473 sgd_solver.cpp:106] Iteration 13800, lr = 8e-05
I0502 11:12:01.215400 26473 solver.cpp:242] Iteration 13800 (104.234 iter/s, 0.95938s/100 iter), loss = 0.628908
I0502 11:12:01.215423 26473 solver.cpp:261]     Train net output #0: loss = 0.628908 (* 1 = 0.628908 loss)
I0502 11:12:01.215431 26473 sgd_solver.cpp:106] Iteration 13800, lr = 8e-05
I0502 11:12:02.186836 26473 solver.cpp:242] Iteration 13900 (102.436 iter/s, 0.976219s/100 iter), loss = 1.42874
I0502 11:12:02.186892 26473 solver.cpp:261]     Train net output #0: loss = 1.42874 (* 1 = 1.42874 loss)
I0502 11:12:02.186902 26473 sgd_solver.cpp:106] Iteration 13900, lr = 8e-05
I0502 11:12:02.191740 26473 solver.cpp:242] Iteration 13900 (102.428 iter/s, 0.976297s/100 iter), loss = 0.756592
I0502 11:12:02.191764 26473 solver.cpp:261]     Train net output #0: loss = 0.756592 (* 1 = 0.756592 loss)
I0502 11:12:02.191772 26473 sgd_solver.cpp:106] Iteration 13900, lr = 8e-05
I0502 11:12:03.139340 26473 solver.cpp:362] Iteration 14000, Testing net (#0)
I0502 11:12:03.139370 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:03.264673 26473 solver.cpp:429]     Test net output #0: loss = 2.38446 (* 1 = 2.38446 loss)
I0502 11:12:03.267572 26473 solver.cpp:242] Iteration 14000 (92.5359 iter/s, 1.08066s/100 iter), loss = 2.89473
I0502 11:12:03.267591 26473 solver.cpp:261]     Train net output #0: loss = 2.89473 (* 1 = 2.89473 loss)
I0502 11:12:03.267599 26473 sgd_solver.cpp:106] Iteration 14000, lr = 8e-05
I0502 11:12:03.269306 26473 solver.cpp:362] Iteration 14000, Testing net (#0)
I0502 11:12:03.269320 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:03.401620 26473 solver.cpp:429]     Test net output #0: accuracy = 0.777
I0502 11:12:03.401640 26473 solver.cpp:429]     Test net output #1: loss = 0.61315 (* 1 = 0.61315 loss)
I0502 11:12:03.404630 26473 solver.cpp:242] Iteration 14000 (82.4508 iter/s, 1.21284s/100 iter), loss = 0.722563
I0502 11:12:03.404651 26473 solver.cpp:261]     Train net output #0: loss = 0.722563 (* 1 = 0.722563 loss)
I0502 11:12:03.404659 26473 sgd_solver.cpp:106] Iteration 14000, lr = 8e-05
I0502 11:12:04.360626 26473 solver.cpp:242] Iteration 14100 (91.4905 iter/s, 1.09301s/100 iter), loss = 1.93507
I0502 11:12:04.360666 26473 solver.cpp:261]     Train net output #0: loss = 1.93507 (* 1 = 1.93507 loss)
I0502 11:12:04.360674 26473 sgd_solver.cpp:106] Iteration 14100, lr = 8e-05
I0502 11:12:04.365494 26473 solver.cpp:242] Iteration 14100 (104.077 iter/s, 0.960824s/100 iter), loss = 0.398494
I0502 11:12:04.365517 26473 solver.cpp:261]     Train net output #0: loss = 0.398494 (* 1 = 0.398494 loss)
I0502 11:12:04.365525 26473 sgd_solver.cpp:106] Iteration 14100, lr = 8e-05
I0502 11:12:05.315637 26473 solver.cpp:242] Iteration 14200 (104.718 iter/s, 0.95495s/100 iter), loss = 0.922364
I0502 11:12:05.315683 26473 solver.cpp:261]     Train net output #0: loss = 0.922364 (* 1 = 0.922364 loss)
I0502 11:12:05.315692 26473 sgd_solver.cpp:106] Iteration 14200, lr = 8e-05
I0502 11:12:05.320544 26473 solver.cpp:242] Iteration 14200 (104.712 iter/s, 0.955002s/100 iter), loss = 0.93041
I0502 11:12:05.320574 26473 solver.cpp:261]     Train net output #0: loss = 0.93041 (* 1 = 0.93041 loss)
I0502 11:12:05.320581 26473 sgd_solver.cpp:106] Iteration 14200, lr = 8e-05
I0502 11:12:06.277863 26473 solver.cpp:242] Iteration 14300 (103.933 iter/s, 0.962158s/100 iter), loss = 1.02254
I0502 11:12:06.277906 26473 solver.cpp:261]     Train net output #0: loss = 1.02254 (* 1 = 1.02254 loss)
I0502 11:12:06.277915 26473 sgd_solver.cpp:106] Iteration 14300, lr = 8e-05
I0502 11:12:06.282742 26473 solver.cpp:242] Iteration 14300 (103.934 iter/s, 0.96215s/100 iter), loss = 0.636297
I0502 11:12:06.282765 26473 solver.cpp:261]     Train net output #0: loss = 0.636297 (* 1 = 0.636297 loss)
I0502 11:12:06.282773 26473 sgd_solver.cpp:106] Iteration 14300, lr = 8e-05
I0502 11:12:07.240624 26473 solver.cpp:242] Iteration 14400 (103.875 iter/s, 0.962691s/100 iter), loss = 1.42404
I0502 11:12:07.240670 26473 solver.cpp:261]     Train net output #0: loss = 1.42404 (* 1 = 1.42404 loss)
I0502 11:12:07.240679 26473 sgd_solver.cpp:106] Iteration 14400, lr = 8e-05
I0502 11:12:07.245560 26473 solver.cpp:242] Iteration 14400 (103.866 iter/s, 0.962776s/100 iter), loss = 0.695726
I0502 11:12:07.245584 26473 solver.cpp:261]     Train net output #0: loss = 0.695726 (* 1 = 0.695726 loss)
I0502 11:12:07.245592 26473 sgd_solver.cpp:106] Iteration 14400, lr = 8e-05
I0502 11:12:08.199039 26473 solver.cpp:362] Iteration 14500, Testing net (#0)
I0502 11:12:08.199064 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:08.326100 26473 solver.cpp:429]     Test net output #0: loss = 2.52292 (* 1 = 2.52292 loss)
I0502 11:12:08.329071 26473 solver.cpp:242] Iteration 14500 (91.8794 iter/s, 1.08838s/100 iter), loss = 2.19187
I0502 11:12:08.329092 26473 solver.cpp:261]     Train net output #0: loss = 2.19187 (* 1 = 2.19187 loss)
I0502 11:12:08.329100 26473 sgd_solver.cpp:106] Iteration 14500, lr = 8e-05
I0502 11:12:08.330754 26473 solver.cpp:362] Iteration 14500, Testing net (#0)
I0502 11:12:08.330767 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:08.464578 26473 solver.cpp:429]     Test net output #0: accuracy = 0.772
I0502 11:12:08.464602 26473 solver.cpp:429]     Test net output #1: loss = 0.633421 (* 1 = 0.633421 loss)
I0502 11:12:08.467618 26473 solver.cpp:242] Iteration 14500 (81.8322 iter/s, 1.22201s/100 iter), loss = 0.564504
I0502 11:12:08.467638 26473 solver.cpp:261]     Train net output #0: loss = 0.564504 (* 1 = 0.564504 loss)
I0502 11:12:08.467646 26473 sgd_solver.cpp:106] Iteration 14500, lr = 8e-05
I0502 11:12:09.426208 26473 solver.cpp:242] Iteration 14600 (91.1501 iter/s, 1.09709s/100 iter), loss = 2.17507
I0502 11:12:09.426237 26473 solver.cpp:261]     Train net output #0: loss = 2.17507 (* 1 = 2.17507 loss)
I0502 11:12:09.426245 26473 sgd_solver.cpp:106] Iteration 14600, lr = 8e-05
I0502 11:12:09.431044 26473 solver.cpp:242] Iteration 14600 (103.8 iter/s, 0.963387s/100 iter), loss = 0.533971
I0502 11:12:09.431067 26473 solver.cpp:261]     Train net output #0: loss = 0.533971 (* 1 = 0.533971 loss)
I0502 11:12:09.431076 26473 sgd_solver.cpp:106] Iteration 14600, lr = 8e-05
I0502 11:12:10.388921 26473 solver.cpp:242] Iteration 14700 (103.879 iter/s, 0.96266s/100 iter), loss = 2.97218
I0502 11:12:10.388962 26473 solver.cpp:261]     Train net output #0: loss = 2.97218 (* 1 = 2.97218 loss)
I0502 11:12:10.388969 26473 sgd_solver.cpp:106] Iteration 14700, lr = 8e-05
I0502 11:12:10.393875 26473 solver.cpp:242] Iteration 14700 (103.865 iter/s, 0.96279s/100 iter), loss = 1.00363
I0502 11:12:10.393898 26473 solver.cpp:261]     Train net output #0: loss = 1.00363 (* 1 = 1.00363 loss)
I0502 11:12:10.393906 26473 sgd_solver.cpp:106] Iteration 14700, lr = 8e-05
I0502 11:12:11.351028 26473 solver.cpp:242] Iteration 14800 (103.945 iter/s, 0.962047s/100 iter), loss = 6.14899
I0502 11:12:11.351071 26473 solver.cpp:261]     Train net output #0: loss = 6.14899 (* 1 = 6.14899 loss)
I0502 11:12:11.351080 26473 sgd_solver.cpp:106] Iteration 14800, lr = 8e-05
I0502 11:12:11.355998 26473 solver.cpp:242] Iteration 14800 (103.941 iter/s, 0.962081s/100 iter), loss = 0.530764
I0502 11:12:11.356020 26473 solver.cpp:261]     Train net output #0: loss = 0.530764 (* 1 = 0.530764 loss)
I0502 11:12:11.356029 26473 sgd_solver.cpp:106] Iteration 14800, lr = 8e-05
I0502 11:12:12.313671 26473 solver.cpp:242] Iteration 14900 (103.888 iter/s, 0.962578s/100 iter), loss = 3.24323
I0502 11:12:12.313724 26473 solver.cpp:261]     Train net output #0: loss = 3.24323 (* 1 = 3.24323 loss)
I0502 11:12:12.313735 26473 sgd_solver.cpp:106] Iteration 14900, lr = 8e-05
I0502 11:12:12.318604 26473 solver.cpp:242] Iteration 14900 (103.889 iter/s, 0.962564s/100 iter), loss = 0.505927
I0502 11:12:12.318627 26473 solver.cpp:261]     Train net output #0: loss = 0.505927 (* 1 = 0.505927 loss)
I0502 11:12:12.318635 26473 sgd_solver.cpp:106] Iteration 14900, lr = 8e-05
I0502 11:12:13.272615 26473 solver.cpp:362] Iteration 15000, Testing net (#0)
I0502 11:12:13.272644 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:13.399559 26473 solver.cpp:429]     Test net output #0: loss = 2.55792 (* 1 = 2.55792 loss)
I0502 11:12:13.402515 26473 solver.cpp:242] Iteration 15000 (91.8466 iter/s, 1.08877s/100 iter), loss = 2.81337
I0502 11:12:13.402535 26473 solver.cpp:261]     Train net output #0: loss = 2.81337 (* 1 = 2.81337 loss)
I0502 11:12:13.402544 26473 sgd_solver.cpp:106] Iteration 15000, lr = 8e-05
I0502 11:12:13.404263 26473 solver.cpp:362] Iteration 15000, Testing net (#0)
I0502 11:12:13.404278 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:13.537940 26473 solver.cpp:429]     Test net output #0: accuracy = 0.707
I0502 11:12:13.537964 26473 solver.cpp:429]     Test net output #1: loss = 0.679838 (* 1 = 0.679838 loss)
I0502 11:12:13.540951 26473 solver.cpp:242] Iteration 15000 (81.8128 iter/s, 1.2223s/100 iter), loss = 0.622466
I0502 11:12:13.540972 26473 solver.cpp:261]     Train net output #0: loss = 0.622466 (* 1 = 0.622466 loss)
I0502 11:12:13.540982 26473 sgd_solver.cpp:106] Iteration 15000, lr = 8e-05
I0502 11:12:14.498833 26473 solver.cpp:242] Iteration 15100 (91.2185 iter/s, 1.09627s/100 iter), loss = 2.18964
I0502 11:12:14.498875 26473 solver.cpp:261]     Train net output #0: loss = 2.18964 (* 1 = 2.18964 loss)
I0502 11:12:14.498884 26473 sgd_solver.cpp:106] Iteration 15100, lr = 8e-05
I0502 11:12:14.503737 26473 solver.cpp:242] Iteration 15100 (103.87 iter/s, 0.962746s/100 iter), loss = 0.548479
I0502 11:12:14.503760 26473 solver.cpp:261]     Train net output #0: loss = 0.548479 (* 1 = 0.548479 loss)
I0502 11:12:14.503768 26473 sgd_solver.cpp:106] Iteration 15100, lr = 8e-05
I0502 11:12:15.460505 26473 solver.cpp:242] Iteration 15200 (103.992 iter/s, 0.96161s/100 iter), loss = 1.08184
I0502 11:12:15.460538 26473 solver.cpp:261]     Train net output #0: loss = 1.08184 (* 1 = 1.08184 loss)
I0502 11:12:15.460547 26473 sgd_solver.cpp:106] Iteration 15200, lr = 8e-05
I0502 11:12:15.465430 26473 solver.cpp:242] Iteration 15200 (103.988 iter/s, 0.96165s/100 iter), loss = 0.555706
I0502 11:12:15.465457 26473 solver.cpp:261]     Train net output #0: loss = 0.555706 (* 1 = 0.555706 loss)
I0502 11:12:15.465466 26473 sgd_solver.cpp:106] Iteration 15200, lr = 8e-05
I0502 11:12:16.421756 26473 solver.cpp:242] Iteration 15300 (104.037 iter/s, 0.961194s/100 iter), loss = 1.14264
I0502 11:12:16.421798 26473 solver.cpp:261]     Train net output #0: loss = 1.14264 (* 1 = 1.14264 loss)
I0502 11:12:16.421808 26473 sgd_solver.cpp:106] Iteration 15300, lr = 8e-05
I0502 11:12:16.426699 26473 solver.cpp:242] Iteration 15300 (104.034 iter/s, 0.961223s/100 iter), loss = 0.616892
I0502 11:12:16.426723 26473 solver.cpp:261]     Train net output #0: loss = 0.616892 (* 1 = 0.616892 loss)
I0502 11:12:16.426730 26473 sgd_solver.cpp:106] Iteration 15300, lr = 8e-05
I0502 11:12:17.383735 26473 solver.cpp:242] Iteration 15400 (103.959 iter/s, 0.961915s/100 iter), loss = 2.85067
I0502 11:12:17.383791 26473 solver.cpp:261]     Train net output #0: loss = 2.85067 (* 1 = 2.85067 loss)
I0502 11:12:17.383801 26473 sgd_solver.cpp:106] Iteration 15400, lr = 8e-05
I0502 11:12:17.388676 26473 solver.cpp:242] Iteration 15400 (103.957 iter/s, 0.961935s/100 iter), loss = 0.698633
I0502 11:12:17.388700 26473 solver.cpp:261]     Train net output #0: loss = 0.698633 (* 1 = 0.698633 loss)
I0502 11:12:17.388708 26473 sgd_solver.cpp:106] Iteration 15400, lr = 8e-05
I0502 11:12:18.342943 26473 solver.cpp:362] Iteration 15500, Testing net (#0)
I0502 11:12:18.342967 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:18.469542 26473 solver.cpp:429]     Test net output #0: loss = 2.11515 (* 1 = 2.11515 loss)
I0502 11:12:18.472491 26473 solver.cpp:242] Iteration 15500 (91.8544 iter/s, 1.08868s/100 iter), loss = 2.17103
I0502 11:12:18.472510 26473 solver.cpp:261]     Train net output #0: loss = 2.17103 (* 1 = 2.17103 loss)
I0502 11:12:18.472518 26473 sgd_solver.cpp:106] Iteration 15500, lr = 8e-05
I0502 11:12:18.474189 26473 solver.cpp:362] Iteration 15500, Testing net (#0)
I0502 11:12:18.474203 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:18.607292 26473 solver.cpp:429]     Test net output #0: accuracy = 0.775
I0502 11:12:18.607314 26473 solver.cpp:429]     Test net output #1: loss = 0.559001 (* 1 = 0.559001 loss)
I0502 11:12:18.610302 26473 solver.cpp:242] Iteration 15500 (81.8611 iter/s, 1.22158s/100 iter), loss = 0.360306
I0502 11:12:18.610322 26473 solver.cpp:261]     Train net output #0: loss = 0.360306 (* 1 = 0.360306 loss)
I0502 11:12:18.610330 26473 sgd_solver.cpp:106] Iteration 15500, lr = 8e-05
I0502 11:12:19.568001 26473 solver.cpp:242] Iteration 15600 (91.2854 iter/s, 1.09546s/100 iter), loss = 2.37507
I0502 11:12:19.568038 26473 solver.cpp:261]     Train net output #0: loss = 2.37507 (* 1 = 2.37507 loss)
I0502 11:12:19.568048 26473 sgd_solver.cpp:106] Iteration 15600, lr = 8e-05
I0502 11:12:19.572924 26473 solver.cpp:242] Iteration 15600 (103.887 iter/s, 0.962583s/100 iter), loss = 0.73474
I0502 11:12:19.572947 26473 solver.cpp:261]     Train net output #0: loss = 0.73474 (* 1 = 0.73474 loss)
I0502 11:12:19.572954 26473 sgd_solver.cpp:106] Iteration 15600, lr = 8e-05
I0502 11:12:20.530167 26473 solver.cpp:242] Iteration 15700 (103.939 iter/s, 0.962105s/100 iter), loss = 0.460988
I0502 11:12:20.530210 26473 solver.cpp:261]     Train net output #0: loss = 0.460988 (* 1 = 0.460988 loss)
I0502 11:12:20.530218 26473 sgd_solver.cpp:106] Iteration 15700, lr = 8e-05
I0502 11:12:20.535027 26473 solver.cpp:242] Iteration 15700 (103.943 iter/s, 0.962062s/100 iter), loss = 0.313697
I0502 11:12:20.535051 26473 solver.cpp:261]     Train net output #0: loss = 0.313697 (* 1 = 0.313697 loss)
I0502 11:12:20.535060 26473 sgd_solver.cpp:106] Iteration 15700, lr = 8e-05
I0502 11:12:21.490459 26473 solver.cpp:242] Iteration 15800 (104.142 iter/s, 0.960229s/100 iter), loss = 1.51132
I0502 11:12:21.490492 26473 solver.cpp:261]     Train net output #0: loss = 1.51132 (* 1 = 1.51132 loss)
I0502 11:12:21.490501 26473 sgd_solver.cpp:106] Iteration 15800, lr = 8e-05
I0502 11:12:21.495425 26473 solver.cpp:242] Iteration 15800 (104.128 iter/s, 0.960355s/100 iter), loss = 0.519879
I0502 11:12:21.495448 26473 solver.cpp:261]     Train net output #0: loss = 0.519879 (* 1 = 0.519879 loss)
I0502 11:12:21.495457 26473 sgd_solver.cpp:106] Iteration 15800, lr = 8e-05
I0502 11:12:22.450436 26473 solver.cpp:242] Iteration 15900 (104.175 iter/s, 0.959922s/100 iter), loss = 3.19183
I0502 11:12:22.450481 26473 solver.cpp:261]     Train net output #0: loss = 3.19183 (* 1 = 3.19183 loss)
I0502 11:12:22.450489 26473 sgd_solver.cpp:106] Iteration 15900, lr = 8e-05
I0502 11:12:22.455289 26473 solver.cpp:242] Iteration 15900 (104.186 iter/s, 0.959822s/100 iter), loss = 0.550478
I0502 11:12:22.455313 26473 solver.cpp:261]     Train net output #0: loss = 0.550478 (* 1 = 0.550478 loss)
I0502 11:12:22.455328 26473 sgd_solver.cpp:106] Iteration 15900, lr = 8e-05
I0502 11:12:23.406119 26473 solver.cpp:362] Iteration 16000, Testing net (#0)
I0502 11:12:23.406147 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:23.532539 26473 solver.cpp:429]     Test net output #0: loss = 1.62247 (* 1 = 1.62247 loss)
I0502 11:12:23.535480 26473 solver.cpp:242] Iteration 16000 (92.1676 iter/s, 1.08498s/100 iter), loss = 1.65569
I0502 11:12:23.535501 26473 solver.cpp:261]     Train net output #0: loss = 1.65569 (* 1 = 1.65569 loss)
I0502 11:12:23.535508 26473 sgd_solver.cpp:106] Iteration 16000, lr = 8e-05
I0502 11:12:23.537179 26473 solver.cpp:362] Iteration 16000, Testing net (#0)
I0502 11:12:23.537194 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:23.670366 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7935
I0502 11:12:23.670389 26473 solver.cpp:429]     Test net output #1: loss = 0.529743 (* 1 = 0.529743 loss)
I0502 11:12:23.673346 26473 solver.cpp:242] Iteration 16000 (82.1011 iter/s, 1.21801s/100 iter), loss = 0.610952
I0502 11:12:23.673365 26473 solver.cpp:261]     Train net output #0: loss = 0.610952 (* 1 = 0.610952 loss)
I0502 11:12:23.673374 26473 sgd_solver.cpp:106] Iteration 16000, lr = 8e-05
I0502 11:12:24.628482 26473 solver.cpp:242] Iteration 16100 (91.4949 iter/s, 1.09296s/100 iter), loss = 1.15548
I0502 11:12:24.628525 26473 solver.cpp:261]     Train net output #0: loss = 1.15548 (* 1 = 1.15548 loss)
I0502 11:12:24.628532 26473 sgd_solver.cpp:106] Iteration 16100, lr = 8e-05
I0502 11:12:24.633343 26473 solver.cpp:242] Iteration 16100 (104.171 iter/s, 0.959959s/100 iter), loss = 0.505697
I0502 11:12:24.633368 26473 solver.cpp:261]     Train net output #0: loss = 0.505697 (* 1 = 0.505697 loss)
I0502 11:12:24.633375 26473 sgd_solver.cpp:106] Iteration 16100, lr = 8e-05
I0502 11:12:25.588301 26473 solver.cpp:242] Iteration 16200 (104.193 iter/s, 0.959756s/100 iter), loss = 0.747644
I0502 11:12:25.588347 26473 solver.cpp:261]     Train net output #0: loss = 0.747644 (* 1 = 0.747644 loss)
I0502 11:12:25.588356 26473 sgd_solver.cpp:106] Iteration 16200, lr = 8e-05
I0502 11:12:25.593154 26473 solver.cpp:242] Iteration 16200 (104.192 iter/s, 0.95977s/100 iter), loss = 0.749027
I0502 11:12:25.593178 26473 solver.cpp:261]     Train net output #0: loss = 0.749027 (* 1 = 0.749027 loss)
I0502 11:12:25.593185 26473 sgd_solver.cpp:106] Iteration 16200, lr = 8e-05
I0502 11:12:26.543900 26473 solver.cpp:242] Iteration 16300 (104.654 iter/s, 0.955532s/100 iter), loss = 1.96125
I0502 11:12:26.543944 26473 solver.cpp:261]     Train net output #0: loss = 1.96125 (* 1 = 1.96125 loss)
I0502 11:12:26.543952 26473 sgd_solver.cpp:106] Iteration 16300, lr = 8e-05
I0502 11:12:26.548851 26473 solver.cpp:242] Iteration 16300 (104.64 iter/s, 0.955655s/100 iter), loss = 0.415908
I0502 11:12:26.548874 26473 solver.cpp:261]     Train net output #0: loss = 0.415908 (* 1 = 0.415908 loss)
I0502 11:12:26.548882 26473 sgd_solver.cpp:106] Iteration 16300, lr = 8e-05
I0502 11:12:27.499222 26473 solver.cpp:242] Iteration 16400 (104.684 iter/s, 0.955257s/100 iter), loss = 2.36712
I0502 11:12:27.499272 26473 solver.cpp:261]     Train net output #0: loss = 2.36712 (* 1 = 2.36712 loss)
I0502 11:12:27.499281 26473 sgd_solver.cpp:106] Iteration 16400, lr = 8e-05
I0502 11:12:27.504173 26473 solver.cpp:242] Iteration 16400 (104.681 iter/s, 0.95528s/100 iter), loss = 0.458847
I0502 11:12:27.504195 26473 solver.cpp:261]     Train net output #0: loss = 0.458847 (* 1 = 0.458847 loss)
I0502 11:12:27.504204 26473 sgd_solver.cpp:106] Iteration 16400, lr = 8e-05
I0502 11:12:28.457018 26473 solver.cpp:362] Iteration 16500, Testing net (#0)
I0502 11:12:28.457046 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:28.583531 26473 solver.cpp:429]     Test net output #0: loss = 2.35814 (* 1 = 2.35814 loss)
I0502 11:12:28.586498 26473 solver.cpp:242] Iteration 16500 (91.9789 iter/s, 1.08721s/100 iter), loss = 2.43594
I0502 11:12:28.586519 26473 solver.cpp:261]     Train net output #0: loss = 2.43594 (* 1 = 2.43594 loss)
I0502 11:12:28.586534 26473 sgd_solver.cpp:106] Iteration 16500, lr = 8e-05
I0502 11:12:28.588198 26473 solver.cpp:362] Iteration 16500, Testing net (#0)
I0502 11:12:28.588212 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:28.722744 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7795
I0502 11:12:28.722767 26473 solver.cpp:429]     Test net output #1: loss = 0.544029 (* 1 = 0.544029 loss)
I0502 11:12:28.725793 26473 solver.cpp:242] Iteration 16500 (81.8615 iter/s, 1.22158s/100 iter), loss = 0.547122
I0502 11:12:28.725813 26473 solver.cpp:261]     Train net output #0: loss = 0.547122 (* 1 = 0.547122 loss)
I0502 11:12:28.725822 26473 sgd_solver.cpp:106] Iteration 16500, lr = 8e-05
I0502 11:12:29.685964 26473 solver.cpp:242] Iteration 16600 (90.9569 iter/s, 1.09942s/100 iter), loss = 0.949385
I0502 11:12:29.686007 26473 solver.cpp:261]     Train net output #0: loss = 0.949385 (* 1 = 0.949385 loss)
I0502 11:12:29.686017 26473 sgd_solver.cpp:106] Iteration 16600, lr = 8e-05
I0502 11:12:29.690857 26473 solver.cpp:242] Iteration 16600 (103.624 iter/s, 0.965025s/100 iter), loss = 0.713989
I0502 11:12:29.690881 26473 solver.cpp:261]     Train net output #0: loss = 0.713989 (* 1 = 0.713989 loss)
I0502 11:12:29.690888 26473 sgd_solver.cpp:106] Iteration 16600, lr = 8e-05
I0502 11:12:30.650827 26473 solver.cpp:242] Iteration 16700 (103.649 iter/s, 0.964798s/100 iter), loss = 2.96576
I0502 11:12:30.650866 26473 solver.cpp:261]     Train net output #0: loss = 2.96576 (* 1 = 2.96576 loss)
I0502 11:12:30.650876 26473 sgd_solver.cpp:106] Iteration 16700, lr = 8e-05
I0502 11:12:30.655742 26473 solver.cpp:242] Iteration 16700 (103.644 iter/s, 0.964844s/100 iter), loss = 0.46742
I0502 11:12:30.655766 26473 solver.cpp:261]     Train net output #0: loss = 0.46742 (* 1 = 0.46742 loss)
I0502 11:12:30.655776 26473 sgd_solver.cpp:106] Iteration 16700, lr = 8e-05
I0502 11:12:31.613646 26473 solver.cpp:242] Iteration 16800 (103.868 iter/s, 0.962759s/100 iter), loss = 2.37754
I0502 11:12:31.613692 26473 solver.cpp:261]     Train net output #0: loss = 2.37754 (* 1 = 2.37754 loss)
I0502 11:12:31.613699 26473 sgd_solver.cpp:106] Iteration 16800, lr = 8e-05
I0502 11:12:31.618613 26473 solver.cpp:242] Iteration 16800 (103.861 iter/s, 0.962828s/100 iter), loss = 0.310233
I0502 11:12:31.618636 26473 solver.cpp:261]     Train net output #0: loss = 0.310233 (* 1 = 0.310233 loss)
I0502 11:12:31.618644 26473 sgd_solver.cpp:106] Iteration 16800, lr = 8e-05
I0502 11:12:32.573246 26473 solver.cpp:242] Iteration 16900 (104.217 iter/s, 0.959534s/100 iter), loss = 3.28925
I0502 11:12:32.573304 26473 solver.cpp:261]     Train net output #0: loss = 3.28925 (* 1 = 3.28925 loss)
I0502 11:12:32.573314 26473 sgd_solver.cpp:106] Iteration 16900, lr = 8e-05
I0502 11:12:32.578192 26473 solver.cpp:242] Iteration 16900 (104.217 iter/s, 0.959537s/100 iter), loss = 0.646613
I0502 11:12:32.578217 26473 solver.cpp:261]     Train net output #0: loss = 0.646613 (* 1 = 0.646613 loss)
I0502 11:12:32.578224 26473 sgd_solver.cpp:106] Iteration 16900, lr = 8e-05
I0502 11:12:33.531642 26473 solver.cpp:362] Iteration 17000, Testing net (#0)
I0502 11:12:33.531672 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:33.658316 26473 solver.cpp:429]     Test net output #0: loss = 1.74788 (* 1 = 1.74788 loss)
I0502 11:12:33.661265 26473 solver.cpp:242] Iteration 17000 (91.9166 iter/s, 1.08794s/100 iter), loss = 4.25276
I0502 11:12:33.661285 26473 solver.cpp:261]     Train net output #0: loss = 4.25276 (* 1 = 4.25276 loss)
I0502 11:12:33.661294 26473 sgd_solver.cpp:106] Iteration 17000, lr = 8e-05
I0502 11:12:33.662978 26473 solver.cpp:362] Iteration 17000, Testing net (#0)
I0502 11:12:33.662992 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:33.796414 26473 solver.cpp:429]     Test net output #0: accuracy = 0.78
I0502 11:12:33.796455 26473 solver.cpp:429]     Test net output #1: loss = 0.562264 (* 1 = 0.562264 loss)
I0502 11:12:33.799459 26473 solver.cpp:242] Iteration 17000 (81.8852 iter/s, 1.22122s/100 iter), loss = 0.752751
I0502 11:12:33.799489 26473 solver.cpp:261]     Train net output #0: loss = 0.752751 (* 1 = 0.752751 loss)
I0502 11:12:33.799499 26473 sgd_solver.cpp:106] Iteration 17000, lr = 8e-05
I0502 11:12:34.755605 26473 solver.cpp:242] Iteration 17100 (91.383 iter/s, 1.0943s/100 iter), loss = 2.26438
I0502 11:12:34.755647 26473 solver.cpp:261]     Train net output #0: loss = 2.26438 (* 1 = 2.26438 loss)
I0502 11:12:34.755656 26473 sgd_solver.cpp:106] Iteration 17100, lr = 8e-05
I0502 11:12:34.760493 26473 solver.cpp:242] Iteration 17100 (104.06 iter/s, 0.960985s/100 iter), loss = 0.500225
I0502 11:12:34.760516 26473 solver.cpp:261]     Train net output #0: loss = 0.500225 (* 1 = 0.500225 loss)
I0502 11:12:34.760524 26473 sgd_solver.cpp:106] Iteration 17100, lr = 8e-05
I0502 11:12:35.715636 26473 solver.cpp:242] Iteration 17200 (104.17 iter/s, 0.959966s/100 iter), loss = 1.79953
I0502 11:12:35.715678 26473 solver.cpp:261]     Train net output #0: loss = 1.79953 (* 1 = 1.79953 loss)
I0502 11:12:35.715687 26473 sgd_solver.cpp:106] Iteration 17200, lr = 8e-05
I0502 11:12:35.720530 26473 solver.cpp:242] Iteration 17200 (104.167 iter/s, 0.959996s/100 iter), loss = 0.667745
I0502 11:12:35.720571 26473 solver.cpp:261]     Train net output #0: loss = 0.667745 (* 1 = 0.667745 loss)
I0502 11:12:35.720580 26473 sgd_solver.cpp:106] Iteration 17200, lr = 8e-05
I0502 11:12:36.676185 26473 solver.cpp:242] Iteration 17300 (104.114 iter/s, 0.960485s/100 iter), loss = 2.63005
I0502 11:12:36.676228 26473 solver.cpp:261]     Train net output #0: loss = 2.63005 (* 1 = 2.63005 loss)
I0502 11:12:36.676236 26473 sgd_solver.cpp:106] Iteration 17300, lr = 8e-05
I0502 11:12:36.681133 26473 solver.cpp:242] Iteration 17300 (104.106 iter/s, 0.960556s/100 iter), loss = 0.885902
I0502 11:12:36.681156 26473 solver.cpp:261]     Train net output #0: loss = 0.885902 (* 1 = 0.885902 loss)
I0502 11:12:36.681164 26473 sgd_solver.cpp:106] Iteration 17300, lr = 8e-05
I0502 11:12:37.636315 26473 solver.cpp:242] Iteration 17400 (104.159 iter/s, 0.960068s/100 iter), loss = 0.713186
I0502 11:12:37.636374 26473 solver.cpp:261]     Train net output #0: loss = 0.713186 (* 1 = 0.713186 loss)
I0502 11:12:37.636384 26473 sgd_solver.cpp:106] Iteration 17400, lr = 8e-05
I0502 11:12:37.641398 26473 solver.cpp:242] Iteration 17400 (104.143 iter/s, 0.960222s/100 iter), loss = 0.512602
I0502 11:12:37.641422 26473 solver.cpp:261]     Train net output #0: loss = 0.512602 (* 1 = 0.512602 loss)
I0502 11:12:37.641432 26473 sgd_solver.cpp:106] Iteration 17400, lr = 8e-05
I0502 11:12:38.594521 26473 solver.cpp:362] Iteration 17500, Testing net (#0)
I0502 11:12:38.594550 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:38.721160 26473 solver.cpp:429]     Test net output #0: loss = 1.9723 (* 1 = 1.9723 loss)
I0502 11:12:38.724086 26473 solver.cpp:242] Iteration 17500 (91.9376 iter/s, 1.08769s/100 iter), loss = 2.42945
I0502 11:12:38.724107 26473 solver.cpp:261]     Train net output #0: loss = 2.42945 (* 1 = 2.42945 loss)
I0502 11:12:38.724114 26473 sgd_solver.cpp:106] Iteration 17500, lr = 8e-05
I0502 11:12:38.725778 26473 solver.cpp:362] Iteration 17500, Testing net (#0)
I0502 11:12:38.725792 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:38.859028 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7895
I0502 11:12:38.859052 26473 solver.cpp:429]     Test net output #1: loss = 0.482046 (* 1 = 0.482046 loss)
I0502 11:12:38.862031 26473 solver.cpp:242] Iteration 17500 (81.9278 iter/s, 1.22059s/100 iter), loss = 0.407783
I0502 11:12:38.862051 26473 solver.cpp:261]     Train net output #0: loss = 0.407783 (* 1 = 0.407783 loss)
I0502 11:12:38.862059 26473 sgd_solver.cpp:106] Iteration 17500, lr = 8e-05
I0502 11:12:39.817375 26473 solver.cpp:242] Iteration 17600 (91.4707 iter/s, 1.09325s/100 iter), loss = 0.856956
I0502 11:12:39.817416 26473 solver.cpp:261]     Train net output #0: loss = 0.856956 (* 1 = 0.856956 loss)
I0502 11:12:39.817425 26473 sgd_solver.cpp:106] Iteration 17600, lr = 8e-05
I0502 11:12:39.822257 26473 solver.cpp:242] Iteration 17600 (104.146 iter/s, 0.960186s/100 iter), loss = 0.31203
I0502 11:12:39.822291 26473 solver.cpp:261]     Train net output #0: loss = 0.31203 (* 1 = 0.31203 loss)
I0502 11:12:39.822300 26473 sgd_solver.cpp:106] Iteration 17600, lr = 8e-05
I0502 11:12:40.778429 26473 solver.cpp:242] Iteration 17700 (104.059 iter/s, 0.960992s/100 iter), loss = 0.98689
I0502 11:12:40.778462 26473 solver.cpp:261]     Train net output #0: loss = 0.98689 (* 1 = 0.98689 loss)
I0502 11:12:40.778470 26473 sgd_solver.cpp:106] Iteration 17700, lr = 8e-05
I0502 11:12:40.783316 26473 solver.cpp:242] Iteration 17700 (104.057 iter/s, 0.961007s/100 iter), loss = 0.234264
I0502 11:12:40.783339 26473 solver.cpp:261]     Train net output #0: loss = 0.234264 (* 1 = 0.234264 loss)
I0502 11:12:40.783347 26473 sgd_solver.cpp:106] Iteration 17700, lr = 8e-05
I0502 11:12:41.738359 26473 solver.cpp:242] Iteration 17800 (104.18 iter/s, 0.959876s/100 iter), loss = 2.51415
I0502 11:12:41.738401 26473 solver.cpp:261]     Train net output #0: loss = 2.51415 (* 1 = 2.51415 loss)
I0502 11:12:41.738409 26473 sgd_solver.cpp:106] Iteration 17800, lr = 8e-05
I0502 11:12:41.743284 26473 solver.cpp:242] Iteration 17800 (104.175 iter/s, 0.959927s/100 iter), loss = 0.29646
I0502 11:12:41.743309 26473 solver.cpp:261]     Train net output #0: loss = 0.29646 (* 1 = 0.29646 loss)
I0502 11:12:41.743316 26473 sgd_solver.cpp:106] Iteration 17800, lr = 8e-05
I0502 11:12:42.695238 26473 solver.cpp:242] Iteration 17900 (104.513 iter/s, 0.956816s/100 iter), loss = 0.511544
I0502 11:12:42.695291 26473 solver.cpp:261]     Train net output #0: loss = 0.511544 (* 1 = 0.511544 loss)
I0502 11:12:42.695300 26473 sgd_solver.cpp:106] Iteration 17900, lr = 8e-05
I0502 11:12:42.700248 26473 solver.cpp:242] Iteration 17900 (104.502 iter/s, 0.956921s/100 iter), loss = 0.634067
I0502 11:12:42.700273 26473 solver.cpp:261]     Train net output #0: loss = 0.634067 (* 1 = 0.634067 loss)
I0502 11:12:42.700281 26473 sgd_solver.cpp:106] Iteration 17900, lr = 8e-05
I0502 11:12:43.648841 26473 solver.cpp:362] Iteration 18000, Testing net (#0)
I0502 11:12:43.648870 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:43.774623 26473 solver.cpp:429]     Test net output #0: loss = 1.54369 (* 1 = 1.54369 loss)
I0502 11:12:43.777540 26473 solver.cpp:242] Iteration 18000 (92.4017 iter/s, 1.08223s/100 iter), loss = 1.57348
I0502 11:12:43.777560 26473 solver.cpp:261]     Train net output #0: loss = 1.57348 (* 1 = 1.57348 loss)
I0502 11:12:43.777570 26473 sgd_solver.cpp:106] Iteration 18000, lr = 8e-05
I0502 11:12:43.779230 26473 solver.cpp:362] Iteration 18000, Testing net (#0)
I0502 11:12:43.779244 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:43.911319 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8015
I0502 11:12:43.911344 26473 solver.cpp:429]     Test net output #1: loss = 0.46711 (* 1 = 0.46711 loss)
I0502 11:12:43.914290 26473 solver.cpp:242] Iteration 18000 (82.3727 iter/s, 1.214s/100 iter), loss = 0.409101
I0502 11:12:43.914311 26473 solver.cpp:261]     Train net output #0: loss = 0.409101 (* 1 = 0.409101 loss)
I0502 11:12:43.914319 26473 sgd_solver.cpp:106] Iteration 18000, lr = 8e-05
I0502 11:12:44.866530 26473 solver.cpp:242] Iteration 18100 (91.8322 iter/s, 1.08894s/100 iter), loss = 2.52139
I0502 11:12:44.866572 26473 solver.cpp:261]     Train net output #0: loss = 2.52139 (* 1 = 2.52139 loss)
I0502 11:12:44.866580 26473 sgd_solver.cpp:106] Iteration 18100, lr = 8e-05
I0502 11:12:44.871390 26473 solver.cpp:242] Iteration 18100 (104.487 iter/s, 0.95706s/100 iter), loss = 0.386329
I0502 11:12:44.871413 26473 solver.cpp:261]     Train net output #0: loss = 0.386329 (* 1 = 0.386329 loss)
I0502 11:12:44.871421 26473 sgd_solver.cpp:106] Iteration 18100, lr = 8e-05
I0502 11:12:45.821750 26473 solver.cpp:242] Iteration 18200 (104.695 iter/s, 0.955157s/100 iter), loss = 1.75935
I0502 11:12:45.821790 26473 solver.cpp:261]     Train net output #0: loss = 1.75935 (* 1 = 1.75935 loss)
I0502 11:12:45.821799 26473 sgd_solver.cpp:106] Iteration 18200, lr = 8e-05
I0502 11:12:45.826614 26473 solver.cpp:242] Iteration 18200 (104.692 iter/s, 0.955182s/100 iter), loss = 0.514589
I0502 11:12:45.826637 26473 solver.cpp:261]     Train net output #0: loss = 0.514589 (* 1 = 0.514589 loss)
I0502 11:12:45.826644 26473 sgd_solver.cpp:106] Iteration 18200, lr = 8e-05
I0502 11:12:46.777328 26473 solver.cpp:242] Iteration 18300 (104.655 iter/s, 0.955519s/100 iter), loss = 2.95382
I0502 11:12:46.777359 26473 solver.cpp:261]     Train net output #0: loss = 2.95382 (* 1 = 2.95382 loss)
I0502 11:12:46.777366 26473 sgd_solver.cpp:106] Iteration 18300, lr = 8e-05
I0502 11:12:46.782161 26473 solver.cpp:242] Iteration 18300 (104.657 iter/s, 0.955507s/100 iter), loss = 0.561032
I0502 11:12:46.782183 26473 solver.cpp:261]     Train net output #0: loss = 0.561032 (* 1 = 0.561032 loss)
I0502 11:12:46.782191 26473 sgd_solver.cpp:106] Iteration 18300, lr = 8e-05
I0502 11:12:47.733304 26473 solver.cpp:242] Iteration 18400 (104.611 iter/s, 0.955922s/100 iter), loss = 2.05394
I0502 11:12:47.733359 26473 solver.cpp:261]     Train net output #0: loss = 2.05394 (* 1 = 2.05394 loss)
I0502 11:12:47.733368 26473 sgd_solver.cpp:106] Iteration 18400, lr = 8e-05
I0502 11:12:47.738301 26473 solver.cpp:242] Iteration 18400 (104.592 iter/s, 0.956099s/100 iter), loss = 0.268361
I0502 11:12:47.738324 26473 solver.cpp:261]     Train net output #0: loss = 0.268361 (* 1 = 0.268361 loss)
I0502 11:12:47.738332 26473 sgd_solver.cpp:106] Iteration 18400, lr = 8e-05
I0502 11:12:48.686028 26473 solver.cpp:362] Iteration 18500, Testing net (#0)
I0502 11:12:48.686054 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:48.811095 26473 solver.cpp:429]     Test net output #0: loss = 1.49607 (* 1 = 1.49607 loss)
I0502 11:12:48.813987 26473 solver.cpp:242] Iteration 18500 (92.5405 iter/s, 1.08061s/100 iter), loss = 2.15062
I0502 11:12:48.814007 26473 solver.cpp:261]     Train net output #0: loss = 2.15062 (* 1 = 2.15062 loss)
I0502 11:12:48.814014 26473 sgd_solver.cpp:106] Iteration 18500, lr = 8e-05
I0502 11:12:48.815668 26473 solver.cpp:362] Iteration 18500, Testing net (#0)
I0502 11:12:48.815682 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:48.947023 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8325
I0502 11:12:48.947047 26473 solver.cpp:429]     Test net output #1: loss = 0.422721 (* 1 = 0.422721 loss)
I0502 11:12:48.949971 26473 solver.cpp:242] Iteration 18500 (82.5337 iter/s, 1.21163s/100 iter), loss = 0.347426
I0502 11:12:48.949992 26473 solver.cpp:261]     Train net output #0: loss = 0.347426 (* 1 = 0.347426 loss)
I0502 11:12:48.950001 26473 sgd_solver.cpp:106] Iteration 18500, lr = 8e-05
I0502 11:12:49.899734 26473 solver.cpp:242] Iteration 18600 (92.106 iter/s, 1.08571s/100 iter), loss = 0.772339
I0502 11:12:49.899767 26473 solver.cpp:261]     Train net output #0: loss = 0.772339 (* 1 = 0.772339 loss)
I0502 11:12:49.899776 26473 sgd_solver.cpp:106] Iteration 18600, lr = 8e-05
I0502 11:12:49.904567 26473 solver.cpp:242] Iteration 18600 (104.761 iter/s, 0.954555s/100 iter), loss = 0.267056
I0502 11:12:49.904588 26473 solver.cpp:261]     Train net output #0: loss = 0.267056 (* 1 = 0.267056 loss)
I0502 11:12:49.904597 26473 sgd_solver.cpp:106] Iteration 18600, lr = 8e-05
I0502 11:12:50.854992 26473 solver.cpp:242] Iteration 18700 (104.69 iter/s, 0.955202s/100 iter), loss = 0.555516
I0502 11:12:50.855036 26473 solver.cpp:261]     Train net output #0: loss = 0.555516 (* 1 = 0.555516 loss)
I0502 11:12:50.855044 26473 sgd_solver.cpp:106] Iteration 18700, lr = 8e-05
I0502 11:12:50.859884 26473 solver.cpp:242] Iteration 18700 (104.682 iter/s, 0.955278s/100 iter), loss = 0.481103
I0502 11:12:50.859907 26473 solver.cpp:261]     Train net output #0: loss = 0.481103 (* 1 = 0.481103 loss)
I0502 11:12:50.859916 26473 sgd_solver.cpp:106] Iteration 18700, lr = 8e-05
I0502 11:12:51.809552 26473 solver.cpp:242] Iteration 18800 (104.768 iter/s, 0.954492s/100 iter), loss = 1.28124
I0502 11:12:51.809592 26473 solver.cpp:261]     Train net output #0: loss = 1.28124 (* 1 = 1.28124 loss)
I0502 11:12:51.809600 26473 sgd_solver.cpp:106] Iteration 18800, lr = 8e-05
I0502 11:12:51.814419 26473 solver.cpp:242] Iteration 18800 (104.768 iter/s, 0.954492s/100 iter), loss = 0.350805
I0502 11:12:51.814442 26473 solver.cpp:261]     Train net output #0: loss = 0.350805 (* 1 = 0.350805 loss)
I0502 11:12:51.814450 26473 sgd_solver.cpp:106] Iteration 18800, lr = 8e-05
I0502 11:12:52.765370 26473 solver.cpp:242] Iteration 18900 (104.629 iter/s, 0.955759s/100 iter), loss = 1.03739
I0502 11:12:52.765429 26473 solver.cpp:261]     Train net output #0: loss = 1.03739 (* 1 = 1.03739 loss)
I0502 11:12:52.765437 26473 sgd_solver.cpp:106] Iteration 18900, lr = 8e-05
I0502 11:12:52.770372 26473 solver.cpp:242] Iteration 18900 (104.612 iter/s, 0.955912s/100 iter), loss = 0.495926
I0502 11:12:52.770395 26473 solver.cpp:261]     Train net output #0: loss = 0.495926 (* 1 = 0.495926 loss)
I0502 11:12:52.770403 26473 sgd_solver.cpp:106] Iteration 18900, lr = 8e-05
I0502 11:12:53.717525 26473 solver.cpp:362] Iteration 19000, Testing net (#0)
I0502 11:12:53.717552 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:53.842782 26473 solver.cpp:429]     Test net output #0: loss = 1.95587 (* 1 = 1.95587 loss)
I0502 11:12:53.845685 26473 solver.cpp:242] Iteration 19000 (92.5721 iter/s, 1.08024s/100 iter), loss = 1.23619
I0502 11:12:53.845705 26473 solver.cpp:261]     Train net output #0: loss = 1.23619 (* 1 = 1.23619 loss)
I0502 11:12:53.845713 26473 sgd_solver.cpp:106] Iteration 19000, lr = 8e-05
I0502 11:12:53.847362 26473 solver.cpp:362] Iteration 19000, Testing net (#0)
I0502 11:12:53.847375 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:53.979480 26473 solver.cpp:429]     Test net output #0: accuracy = 0.825
I0502 11:12:53.979502 26473 solver.cpp:429]     Test net output #1: loss = 0.449174 (* 1 = 0.449174 loss)
I0502 11:12:53.982472 26473 solver.cpp:242] Iteration 19000 (82.5045 iter/s, 1.21205s/100 iter), loss = 0.378899
I0502 11:12:53.982493 26473 solver.cpp:261]     Train net output #0: loss = 0.378899 (* 1 = 0.378899 loss)
I0502 11:12:53.982501 26473 sgd_solver.cpp:106] Iteration 19000, lr = 8e-05
I0502 11:12:54.936277 26473 solver.cpp:242] Iteration 19100 (91.697 iter/s, 1.09055s/100 iter), loss = 1.35966
I0502 11:12:54.936319 26473 solver.cpp:261]     Train net output #0: loss = 1.35966 (* 1 = 1.35966 loss)
I0502 11:12:54.936328 26473 sgd_solver.cpp:106] Iteration 19100, lr = 8e-05
I0502 11:12:54.941166 26473 solver.cpp:242] Iteration 19100 (104.313 iter/s, 0.958656s/100 iter), loss = 0.376557
I0502 11:12:54.941190 26473 solver.cpp:261]     Train net output #0: loss = 0.376557 (* 1 = 0.376557 loss)
I0502 11:12:54.941198 26473 sgd_solver.cpp:106] Iteration 19100, lr = 8e-05
I0502 11:12:55.893565 26473 solver.cpp:242] Iteration 19200 (104.469 iter/s, 0.957224s/100 iter), loss = 0.709138
I0502 11:12:55.893605 26473 solver.cpp:261]     Train net output #0: loss = 0.709138 (* 1 = 0.709138 loss)
I0502 11:12:55.893615 26473 sgd_solver.cpp:106] Iteration 19200, lr = 8e-05
I0502 11:12:55.898422 26473 solver.cpp:242] Iteration 19200 (104.47 iter/s, 0.957213s/100 iter), loss = 0.299776
I0502 11:12:55.898444 26473 solver.cpp:261]     Train net output #0: loss = 0.299776 (* 1 = 0.299776 loss)
I0502 11:12:55.898453 26473 sgd_solver.cpp:106] Iteration 19200, lr = 8e-05
I0502 11:12:56.851223 26473 solver.cpp:242] Iteration 19300 (104.428 iter/s, 0.957598s/100 iter), loss = 0.786568
I0502 11:12:56.851267 26473 solver.cpp:261]     Train net output #0: loss = 0.786568 (* 1 = 0.786568 loss)
I0502 11:12:56.851277 26473 sgd_solver.cpp:106] Iteration 19300, lr = 8e-05
I0502 11:12:56.856112 26473 solver.cpp:242] Iteration 19300 (104.422 iter/s, 0.957649s/100 iter), loss = 0.282702
I0502 11:12:56.856135 26473 solver.cpp:261]     Train net output #0: loss = 0.282702 (* 1 = 0.282702 loss)
I0502 11:12:56.856143 26473 sgd_solver.cpp:106] Iteration 19300, lr = 8e-05
I0502 11:12:57.808176 26473 solver.cpp:242] Iteration 19400 (104.506 iter/s, 0.956887s/100 iter), loss = 1.34976
I0502 11:12:57.808233 26473 solver.cpp:261]     Train net output #0: loss = 1.34976 (* 1 = 1.34976 loss)
I0502 11:12:57.808256 26473 sgd_solver.cpp:106] Iteration 19400, lr = 8e-05
I0502 11:12:57.813225 26473 solver.cpp:242] Iteration 19400 (104.485 iter/s, 0.957072s/100 iter), loss = 0.323929
I0502 11:12:57.813248 26473 solver.cpp:261]     Train net output #0: loss = 0.323929 (* 1 = 0.323929 loss)
I0502 11:12:57.813256 26473 sgd_solver.cpp:106] Iteration 19400, lr = 8e-05
I0502 11:12:58.762432 26473 solver.cpp:362] Iteration 19500, Testing net (#0)
I0502 11:12:58.762459 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:58.888180 26473 solver.cpp:429]     Test net output #0: loss = 2.0513 (* 1 = 2.0513 loss)
I0502 11:12:58.891077 26473 solver.cpp:242] Iteration 19500 (92.3511 iter/s, 1.08282s/100 iter), loss = 2.74193
I0502 11:12:58.891096 26473 solver.cpp:261]     Train net output #0: loss = 2.74193 (* 1 = 2.74193 loss)
I0502 11:12:58.891104 26473 sgd_solver.cpp:106] Iteration 19500, lr = 8e-05
I0502 11:12:58.892773 26473 solver.cpp:362] Iteration 19500, Testing net (#0)
I0502 11:12:58.892787 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:12:59.024899 26473 solver.cpp:429]     Test net output #0: accuracy = 0.796
I0502 11:12:59.024920 26473 solver.cpp:429]     Test net output #1: loss = 0.534617 (* 1 = 0.534617 loss)
I0502 11:12:59.027899 26473 solver.cpp:242] Iteration 19500 (82.3296 iter/s, 1.21463s/100 iter), loss = 0.850346
I0502 11:12:59.027920 26473 solver.cpp:261]     Train net output #0: loss = 0.850346 (* 1 = 0.850346 loss)
I0502 11:12:59.027930 26473 sgd_solver.cpp:106] Iteration 19500, lr = 8e-05
I0502 11:12:59.985199 26473 solver.cpp:242] Iteration 19600 (91.4012 iter/s, 1.09408s/100 iter), loss = 2.37377
I0502 11:12:59.985242 26473 solver.cpp:261]     Train net output #0: loss = 2.37377 (* 1 = 2.37377 loss)
I0502 11:12:59.985251 26473 sgd_solver.cpp:106] Iteration 19600, lr = 8e-05
I0502 11:12:59.990108 26473 solver.cpp:242] Iteration 19600 (103.932 iter/s, 0.96217s/100 iter), loss = 0.365943
I0502 11:12:59.990131 26473 solver.cpp:261]     Train net output #0: loss = 0.365943 (* 1 = 0.365943 loss)
I0502 11:12:59.990139 26473 sgd_solver.cpp:106] Iteration 19600, lr = 8e-05
I0502 11:13:00.960136 26473 solver.cpp:242] Iteration 19700 (102.578 iter/s, 0.974872s/100 iter), loss = 2.69981
I0502 11:13:00.960181 26473 solver.cpp:261]     Train net output #0: loss = 2.69981 (* 1 = 2.69981 loss)
I0502 11:13:00.960189 26473 sgd_solver.cpp:106] Iteration 19700, lr = 8e-05
I0502 11:13:00.965034 26473 solver.cpp:242] Iteration 19700 (102.576 iter/s, 0.974884s/100 iter), loss = 0.47336
I0502 11:13:00.965059 26473 solver.cpp:261]     Train net output #0: loss = 0.47336 (* 1 = 0.47336 loss)
I0502 11:13:00.965067 26473 sgd_solver.cpp:106] Iteration 19700, lr = 8e-05
I0502 11:13:01.925432 26473 solver.cpp:242] Iteration 19800 (103.602 iter/s, 0.96523s/100 iter), loss = 0.554498
I0502 11:13:01.925470 26473 solver.cpp:261]     Train net output #0: loss = 0.554498 (* 1 = 0.554498 loss)
I0502 11:13:01.925478 26473 sgd_solver.cpp:106] Iteration 19800, lr = 8e-05
I0502 11:13:01.930306 26473 solver.cpp:242] Iteration 19800 (103.602 iter/s, 0.965229s/100 iter), loss = 0.489852
I0502 11:13:01.930330 26473 solver.cpp:261]     Train net output #0: loss = 0.489852 (* 1 = 0.489852 loss)
I0502 11:13:01.930338 26473 sgd_solver.cpp:106] Iteration 19800, lr = 8e-05
I0502 11:13:02.887174 26473 solver.cpp:242] Iteration 19900 (103.984 iter/s, 0.961682s/100 iter), loss = 1.89242
I0502 11:13:02.887231 26473 solver.cpp:261]     Train net output #0: loss = 1.89242 (* 1 = 1.89242 loss)
I0502 11:13:02.887241 26473 sgd_solver.cpp:106] Iteration 19900, lr = 8e-05
I0502 11:13:02.892196 26473 solver.cpp:242] Iteration 19900 (103.966 iter/s, 0.961848s/100 iter), loss = 0.261329
I0502 11:13:02.892220 26473 solver.cpp:261]     Train net output #0: loss = 0.261329 (* 1 = 0.261329 loss)
I0502 11:13:02.892228 26473 sgd_solver.cpp:106] Iteration 19900, lr = 8e-05
I0502 11:13:03.844938 26473 solver.cpp:362] Iteration 20000, Testing net (#0)
I0502 11:13:03.844965 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:03.971612 26473 solver.cpp:429]     Test net output #0: loss = 1.90662 (* 1 = 1.90662 loss)
I0502 11:13:03.974558 26473 solver.cpp:242] Iteration 20000 (91.9702 iter/s, 1.08731s/100 iter), loss = 1.31946
I0502 11:13:03.974578 26473 solver.cpp:261]     Train net output #0: loss = 1.31946 (* 1 = 1.31946 loss)
I0502 11:13:03.974587 26473 sgd_solver.cpp:106] Iteration 20000, lr = 6.4e-05
I0502 11:13:03.976250 26473 solver.cpp:362] Iteration 20000, Testing net (#0)
I0502 11:13:03.976264 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:04.109429 26473 solver.cpp:429]     Test net output #0: accuracy = 0.7905
I0502 11:13:04.109453 26473 solver.cpp:429]     Test net output #1: loss = 0.460142 (* 1 = 0.460142 loss)
I0502 11:13:04.112434 26473 solver.cpp:242] Iteration 20000 (81.9542 iter/s, 1.22019s/100 iter), loss = 0.30824
I0502 11:13:04.112455 26473 solver.cpp:261]     Train net output #0: loss = 0.30824 (* 1 = 0.30824 loss)
I0502 11:13:04.112463 26473 sgd_solver.cpp:106] Iteration 20000, lr = 6.4e-05
I0502 11:13:05.067663 26473 solver.cpp:242] Iteration 20100 (91.4863 iter/s, 1.09306s/100 iter), loss = 1.68667
I0502 11:13:05.067700 26473 solver.cpp:261]     Train net output #0: loss = 1.68667 (* 1 = 1.68667 loss)
I0502 11:13:05.067708 26473 sgd_solver.cpp:106] Iteration 20100, lr = 6.4e-05
I0502 11:13:05.072540 26473 solver.cpp:242] Iteration 20100 (104.159 iter/s, 0.960066s/100 iter), loss = 0.369117
I0502 11:13:05.072567 26473 solver.cpp:261]     Train net output #0: loss = 0.369117 (* 1 = 0.369117 loss)
I0502 11:13:05.072576 26473 sgd_solver.cpp:106] Iteration 20100, lr = 6.4e-05
I0502 11:13:06.028028 26473 solver.cpp:242] Iteration 20200 (104.133 iter/s, 0.960306s/100 iter), loss = 0.717562
I0502 11:13:06.028074 26473 solver.cpp:261]     Train net output #0: loss = 0.717562 (* 1 = 0.717562 loss)
I0502 11:13:06.028081 26473 sgd_solver.cpp:106] Iteration 20200, lr = 6.4e-05
I0502 11:13:06.032912 26473 solver.cpp:242] Iteration 20200 (104.131 iter/s, 0.960328s/100 iter), loss = 0.149849
I0502 11:13:06.032935 26473 solver.cpp:261]     Train net output #0: loss = 0.149849 (* 1 = 0.149849 loss)
I0502 11:13:06.032943 26473 sgd_solver.cpp:106] Iteration 20200, lr = 6.4e-05
I0502 11:13:06.988246 26473 solver.cpp:242] Iteration 20300 (104.15 iter/s, 0.960151s/100 iter), loss = 0.853566
I0502 11:13:06.988288 26473 solver.cpp:261]     Train net output #0: loss = 0.853566 (* 1 = 0.853566 loss)
I0502 11:13:06.988297 26473 sgd_solver.cpp:106] Iteration 20300, lr = 6.4e-05
I0502 11:13:06.993119 26473 solver.cpp:242] Iteration 20300 (104.149 iter/s, 0.960165s/100 iter), loss = 0.308955
I0502 11:13:06.993140 26473 solver.cpp:261]     Train net output #0: loss = 0.308955 (* 1 = 0.308955 loss)
I0502 11:13:06.993149 26473 sgd_solver.cpp:106] Iteration 20300, lr = 6.4e-05
I0502 11:13:07.948648 26473 solver.cpp:242] Iteration 20400 (104.13 iter/s, 0.96034s/100 iter), loss = 2.25993
I0502 11:13:07.948701 26473 solver.cpp:261]     Train net output #0: loss = 2.25993 (* 1 = 2.25993 loss)
I0502 11:13:07.948710 26473 sgd_solver.cpp:106] Iteration 20400, lr = 6.4e-05
I0502 11:13:07.953676 26473 solver.cpp:242] Iteration 20400 (104.111 iter/s, 0.960509s/100 iter), loss = 0.160019
I0502 11:13:07.953701 26473 solver.cpp:261]     Train net output #0: loss = 0.160019 (* 1 = 0.160019 loss)
I0502 11:13:07.953708 26473 sgd_solver.cpp:106] Iteration 20400, lr = 6.4e-05
I0502 11:13:08.905028 26473 solver.cpp:362] Iteration 20500, Testing net (#0)
I0502 11:13:08.905057 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:09.031088 26473 solver.cpp:429]     Test net output #0: loss = 1.25706 (* 1 = 1.25706 loss)
I0502 11:13:09.034013 26473 solver.cpp:242] Iteration 20500 (92.1411 iter/s, 1.08529s/100 iter), loss = 0.812307
I0502 11:13:09.034034 26473 solver.cpp:261]     Train net output #0: loss = 0.812307 (* 1 = 0.812307 loss)
I0502 11:13:09.034042 26473 sgd_solver.cpp:106] Iteration 20500, lr = 6.4e-05
I0502 11:13:09.035784 26473 solver.cpp:362] Iteration 20500, Testing net (#0)
I0502 11:13:09.035797 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:09.168308 26473 solver.cpp:429]     Test net output #0: accuracy = 0.844
I0502 11:13:09.168329 26473 solver.cpp:429]     Test net output #1: loss = 0.362571 (* 1 = 0.362571 loss)
I0502 11:13:09.171300 26473 solver.cpp:242] Iteration 20500 (82.1303 iter/s, 1.21758s/100 iter), loss = 0.445545
I0502 11:13:09.171320 26473 solver.cpp:261]     Train net output #0: loss = 0.445545 (* 1 = 0.445545 loss)
I0502 11:13:09.171329 26473 sgd_solver.cpp:106] Iteration 20500, lr = 6.4e-05
I0502 11:13:10.124832 26473 solver.cpp:242] Iteration 20600 (91.678 iter/s, 1.09077s/100 iter), loss = 2.6394
I0502 11:13:10.124876 26473 solver.cpp:261]     Train net output #0: loss = 2.6394 (* 1 = 2.6394 loss)
I0502 11:13:10.124886 26473 sgd_solver.cpp:106] Iteration 20600, lr = 6.4e-05
I0502 11:13:10.129755 26473 solver.cpp:242] Iteration 20600 (104.339 iter/s, 0.958416s/100 iter), loss = 0.409623
I0502 11:13:10.129778 26473 solver.cpp:261]     Train net output #0: loss = 0.409623 (* 1 = 0.409623 loss)
I0502 11:13:10.129786 26473 sgd_solver.cpp:106] Iteration 20600, lr = 6.4e-05
I0502 11:13:11.102300 26473 solver.cpp:242] Iteration 20700 (102.312 iter/s, 0.977401s/100 iter), loss = 0.569963
I0502 11:13:11.102346 26473 solver.cpp:261]     Train net output #0: loss = 0.569963 (* 1 = 0.569963 loss)
I0502 11:13:11.102355 26473 sgd_solver.cpp:106] Iteration 20700, lr = 6.4e-05
I0502 11:13:11.107168 26473 solver.cpp:242] Iteration 20700 (102.315 iter/s, 0.977371s/100 iter), loss = 0.199083
I0502 11:13:11.107193 26473 solver.cpp:261]     Train net output #0: loss = 0.199083 (* 1 = 0.199083 loss)
I0502 11:13:11.107201 26473 sgd_solver.cpp:106] Iteration 20700, lr = 6.4e-05
I0502 11:13:12.059856 26473 solver.cpp:242] Iteration 20800 (104.44 iter/s, 0.957488s/100 iter), loss = 1.76415
I0502 11:13:12.059895 26473 solver.cpp:261]     Train net output #0: loss = 1.76415 (* 1 = 1.76415 loss)
I0502 11:13:12.059904 26473 sgd_solver.cpp:106] Iteration 20800, lr = 6.4e-05
I0502 11:13:12.064744 26473 solver.cpp:242] Iteration 20800 (104.435 iter/s, 0.957533s/100 iter), loss = 0.528606
I0502 11:13:12.064767 26473 solver.cpp:261]     Train net output #0: loss = 0.528606 (* 1 = 0.528606 loss)
I0502 11:13:12.064775 26473 sgd_solver.cpp:106] Iteration 20800, lr = 6.4e-05
I0502 11:13:13.016981 26473 solver.cpp:242] Iteration 20900 (104.486 iter/s, 0.957064s/100 iter), loss = 1.76836
I0502 11:13:13.017025 26473 solver.cpp:261]     Train net output #0: loss = 1.76836 (* 1 = 1.76836 loss)
I0502 11:13:13.017035 26473 sgd_solver.cpp:106] Iteration 20900, lr = 6.4e-05
I0502 11:13:13.021893 26473 solver.cpp:242] Iteration 20900 (104.482 iter/s, 0.957107s/100 iter), loss = 0.267979
I0502 11:13:13.021919 26473 solver.cpp:261]     Train net output #0: loss = 0.267979 (* 1 = 0.267979 loss)
I0502 11:13:13.021927 26473 sgd_solver.cpp:106] Iteration 20900, lr = 6.4e-05
I0502 11:13:13.969530 26473 solver.cpp:362] Iteration 21000, Testing net (#0)
I0502 11:13:13.969554 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:14.095089 26473 solver.cpp:429]     Test net output #0: loss = 1.13322 (* 1 = 1.13322 loss)
I0502 11:13:14.097991 26473 solver.cpp:242] Iteration 21000 (92.5115 iter/s, 1.08095s/100 iter), loss = 0.729534
I0502 11:13:14.098012 26473 solver.cpp:261]     Train net output #0: loss = 0.729534 (* 1 = 0.729534 loss)
I0502 11:13:14.098021 26473 sgd_solver.cpp:106] Iteration 21000, lr = 6.4e-05
I0502 11:13:14.099818 26473 solver.cpp:362] Iteration 21000, Testing net (#0)
I0502 11:13:14.099833 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:14.231803 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8685
I0502 11:13:14.231825 26473 solver.cpp:429]     Test net output #1: loss = 0.319527 (* 1 = 0.319527 loss)
I0502 11:13:14.234794 26473 solver.cpp:242] Iteration 21000 (82.4502 iter/s, 1.21285s/100 iter), loss = 0.212693
I0502 11:13:14.234814 26473 solver.cpp:261]     Train net output #0: loss = 0.212693 (* 1 = 0.212693 loss)
I0502 11:13:14.234822 26473 sgd_solver.cpp:106] Iteration 21000, lr = 6.4e-05
I0502 11:13:15.188911 26473 solver.cpp:242] Iteration 21100 (91.6694 iter/s, 1.09088s/100 iter), loss = 0.883356
I0502 11:13:15.188944 26473 solver.cpp:261]     Train net output #0: loss = 0.883356 (* 1 = 0.883356 loss)
I0502 11:13:15.188953 26473 sgd_solver.cpp:106] Iteration 21100, lr = 6.4e-05
I0502 11:13:15.193740 26473 solver.cpp:242] Iteration 21100 (104.285 iter/s, 0.958907s/100 iter), loss = 0.356982
I0502 11:13:15.193763 26473 solver.cpp:261]     Train net output #0: loss = 0.356982 (* 1 = 0.356982 loss)
I0502 11:13:15.193771 26473 sgd_solver.cpp:106] Iteration 21100, lr = 6.4e-05
I0502 11:13:16.147133 26473 solver.cpp:242] Iteration 21200 (104.366 iter/s, 0.958166s/100 iter), loss = 1.12936
I0502 11:13:16.147174 26473 solver.cpp:261]     Train net output #0: loss = 1.12936 (* 1 = 1.12936 loss)
I0502 11:13:16.147182 26473 sgd_solver.cpp:106] Iteration 21200, lr = 6.4e-05
I0502 11:13:16.152014 26473 solver.cpp:242] Iteration 21200 (104.359 iter/s, 0.958232s/100 iter), loss = 0.433166
I0502 11:13:16.152039 26473 solver.cpp:261]     Train net output #0: loss = 0.433166 (* 1 = 0.433166 loss)
I0502 11:13:16.152047 26473 sgd_solver.cpp:106] Iteration 21200, lr = 6.4e-05
I0502 11:13:17.104229 26473 solver.cpp:242] Iteration 21300 (104.49 iter/s, 0.957033s/100 iter), loss = 1.4993
I0502 11:13:17.104270 26473 solver.cpp:261]     Train net output #0: loss = 1.4993 (* 1 = 1.4993 loss)
I0502 11:13:17.104279 26473 sgd_solver.cpp:106] Iteration 21300, lr = 6.4e-05
I0502 11:13:17.109128 26473 solver.cpp:242] Iteration 21300 (104.485 iter/s, 0.957072s/100 iter), loss = 0.446913
I0502 11:13:17.109151 26473 solver.cpp:261]     Train net output #0: loss = 0.446913 (* 1 = 0.446913 loss)
I0502 11:13:17.109160 26473 sgd_solver.cpp:106] Iteration 21300, lr = 6.4e-05
I0502 11:13:18.062158 26473 solver.cpp:242] Iteration 21400 (104.398 iter/s, 0.957869s/100 iter), loss = 1.23837
I0502 11:13:18.062207 26473 solver.cpp:261]     Train net output #0: loss = 1.23837 (* 1 = 1.23837 loss)
I0502 11:13:18.062216 26473 sgd_solver.cpp:106] Iteration 21400, lr = 6.4e-05
I0502 11:13:18.067071 26473 solver.cpp:242] Iteration 21400 (104.395 iter/s, 0.957902s/100 iter), loss = 0.218948
I0502 11:13:18.067095 26473 solver.cpp:261]     Train net output #0: loss = 0.218948 (* 1 = 0.218948 loss)
I0502 11:13:18.067103 26473 sgd_solver.cpp:106] Iteration 21400, lr = 6.4e-05
I0502 11:13:19.017870 26473 solver.cpp:362] Iteration 21500, Testing net (#0)
I0502 11:13:19.017899 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:19.143702 26473 solver.cpp:429]     Test net output #0: loss = 0.938455 (* 1 = 0.938455 loss)
I0502 11:13:19.146628 26473 solver.cpp:242] Iteration 21500 (92.2167 iter/s, 1.0844s/100 iter), loss = 0.676431
I0502 11:13:19.146649 26473 solver.cpp:261]     Train net output #0: loss = 0.676431 (* 1 = 0.676431 loss)
I0502 11:13:19.146657 26473 sgd_solver.cpp:106] Iteration 21500, lr = 6.4e-05
I0502 11:13:19.148406 26473 solver.cpp:362] Iteration 21500, Testing net (#0)
I0502 11:13:19.148419 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:19.280661 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8485
I0502 11:13:19.280685 26473 solver.cpp:429]     Test net output #1: loss = 0.353595 (* 1 = 0.353595 loss)
I0502 11:13:19.283654 26473 solver.cpp:242] Iteration 21500 (82.2006 iter/s, 1.21654s/100 iter), loss = 0.285328
I0502 11:13:19.283674 26473 solver.cpp:261]     Train net output #0: loss = 0.285328 (* 1 = 0.285328 loss)
I0502 11:13:19.283684 26473 sgd_solver.cpp:106] Iteration 21500, lr = 6.4e-05
I0502 11:13:20.237185 26473 solver.cpp:242] Iteration 21600 (91.7001 iter/s, 1.09051s/100 iter), loss = 1.06999
I0502 11:13:20.237227 26473 solver.cpp:261]     Train net output #0: loss = 1.06999 (* 1 = 1.06999 loss)
I0502 11:13:20.237236 26473 sgd_solver.cpp:106] Iteration 21600, lr = 6.4e-05
I0502 11:13:20.242058 26473 solver.cpp:242] Iteration 21600 (104.344 iter/s, 0.958365s/100 iter), loss = 0.44748
I0502 11:13:20.242080 26473 solver.cpp:261]     Train net output #0: loss = 0.44748 (* 1 = 0.44748 loss)
I0502 11:13:20.242089 26473 sgd_solver.cpp:106] Iteration 21600, lr = 6.4e-05
I0502 11:13:21.194666 26473 solver.cpp:242] Iteration 21700 (104.448 iter/s, 0.957419s/100 iter), loss = 1.31341
I0502 11:13:21.194697 26473 solver.cpp:261]     Train net output #0: loss = 1.31341 (* 1 = 1.31341 loss)
I0502 11:13:21.194706 26473 sgd_solver.cpp:106] Iteration 21700, lr = 6.4e-05
I0502 11:13:21.199512 26473 solver.cpp:242] Iteration 21700 (104.448 iter/s, 0.957412s/100 iter), loss = 0.452642
I0502 11:13:21.199533 26473 solver.cpp:261]     Train net output #0: loss = 0.452642 (* 1 = 0.452642 loss)
I0502 11:13:21.199542 26473 sgd_solver.cpp:106] Iteration 21700, lr = 6.4e-05
I0502 11:13:22.153270 26473 solver.cpp:242] Iteration 21800 (104.324 iter/s, 0.958549s/100 iter), loss = 1.37501
I0502 11:13:22.153309 26473 solver.cpp:261]     Train net output #0: loss = 1.37501 (* 1 = 1.37501 loss)
I0502 11:13:22.153318 26473 sgd_solver.cpp:106] Iteration 21800, lr = 6.4e-05
I0502 11:13:22.158170 26473 solver.cpp:242] Iteration 21800 (104.317 iter/s, 0.958618s/100 iter), loss = 0.30473
I0502 11:13:22.158193 26473 solver.cpp:261]     Train net output #0: loss = 0.30473 (* 1 = 0.30473 loss)
I0502 11:13:22.158202 26473 sgd_solver.cpp:106] Iteration 21800, lr = 6.4e-05
I0502 11:13:23.110833 26473 solver.cpp:242] Iteration 21900 (104.438 iter/s, 0.957502s/100 iter), loss = 1.4921
I0502 11:13:23.110877 26473 solver.cpp:261]     Train net output #0: loss = 1.4921 (* 1 = 1.4921 loss)
I0502 11:13:23.110887 26473 sgd_solver.cpp:106] Iteration 21900, lr = 6.4e-05
I0502 11:13:23.115757 26473 solver.cpp:242] Iteration 21900 (104.434 iter/s, 0.957544s/100 iter), loss = 0.178085
I0502 11:13:23.115783 26473 solver.cpp:261]     Train net output #0: loss = 0.178085 (* 1 = 0.178085 loss)
I0502 11:13:23.115792 26473 sgd_solver.cpp:106] Iteration 21900, lr = 6.4e-05
I0502 11:13:24.065574 26473 solver.cpp:362] Iteration 22000, Testing net (#0)
I0502 11:13:24.065599 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:24.191527 26473 solver.cpp:429]     Test net output #0: loss = 1.13136 (* 1 = 1.13136 loss)
I0502 11:13:24.194437 26473 solver.cpp:242] Iteration 22000 (92.2901 iter/s, 1.08354s/100 iter), loss = 1.31359
I0502 11:13:24.194456 26473 solver.cpp:261]     Train net output #0: loss = 1.31359 (* 1 = 1.31359 loss)
I0502 11:13:24.194464 26473 sgd_solver.cpp:106] Iteration 22000, lr = 6.4e-05
I0502 11:13:24.196229 26473 solver.cpp:362] Iteration 22000, Testing net (#0)
I0502 11:13:24.196243 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:24.328213 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8415
I0502 11:13:24.328235 26473 solver.cpp:429]     Test net output #1: loss = 0.353342 (* 1 = 0.353342 loss)
I0502 11:13:24.331184 26473 solver.cpp:242] Iteration 22000 (82.2788 iter/s, 1.21538s/100 iter), loss = 0.384557
I0502 11:13:24.331205 26473 solver.cpp:261]     Train net output #0: loss = 0.384557 (* 1 = 0.384557 loss)
I0502 11:13:24.331213 26473 sgd_solver.cpp:106] Iteration 22000, lr = 6.4e-05
I0502 11:13:25.284646 26473 solver.cpp:242] Iteration 22100 (91.7292 iter/s, 1.09017s/100 iter), loss = 0.523493
I0502 11:13:25.284694 26473 solver.cpp:261]     Train net output #0: loss = 0.523493 (* 1 = 0.523493 loss)
I0502 11:13:25.284703 26473 sgd_solver.cpp:106] Iteration 22100, lr = 6.4e-05
I0502 11:13:25.289543 26473 solver.cpp:242] Iteration 22100 (104.349 iter/s, 0.95832s/100 iter), loss = 0.0545203
I0502 11:13:25.289566 26473 solver.cpp:261]     Train net output #0: loss = 0.0545203 (* 1 = 0.0545203 loss)
I0502 11:13:25.289574 26473 sgd_solver.cpp:106] Iteration 22100, lr = 6.4e-05
I0502 11:13:26.242573 26473 solver.cpp:242] Iteration 22200 (104.4 iter/s, 0.957857s/100 iter), loss = 0.575659
I0502 11:13:26.242612 26473 solver.cpp:261]     Train net output #0: loss = 0.575659 (* 1 = 0.575659 loss)
I0502 11:13:26.242621 26473 sgd_solver.cpp:106] Iteration 22200, lr = 6.4e-05
I0502 11:13:26.247470 26473 solver.cpp:242] Iteration 22200 (104.397 iter/s, 0.957886s/100 iter), loss = 0.0684734
I0502 11:13:26.247508 26473 solver.cpp:261]     Train net output #0: loss = 0.0684734 (* 1 = 0.0684734 loss)
I0502 11:13:26.247524 26473 sgd_solver.cpp:106] Iteration 22200, lr = 6.4e-05
I0502 11:13:27.200687 26473 solver.cpp:242] Iteration 22300 (104.378 iter/s, 0.958054s/100 iter), loss = 1.40717
I0502 11:13:27.200716 26473 solver.cpp:261]     Train net output #0: loss = 1.40717 (* 1 = 1.40717 loss)
I0502 11:13:27.200726 26473 sgd_solver.cpp:106] Iteration 22300, lr = 6.4e-05
I0502 11:13:27.205555 26473 solver.cpp:242] Iteration 22300 (104.381 iter/s, 0.958029s/100 iter), loss = 0.16306
I0502 11:13:27.205581 26473 solver.cpp:261]     Train net output #0: loss = 0.16306 (* 1 = 0.16306 loss)
I0502 11:13:27.205590 26473 sgd_solver.cpp:106] Iteration 22300, lr = 6.4e-05
I0502 11:13:28.158478 26473 solver.cpp:242] Iteration 22400 (104.413 iter/s, 0.957739s/100 iter), loss = 2.7016
I0502 11:13:28.158535 26473 solver.cpp:261]     Train net output #0: loss = 2.7016 (* 1 = 2.7016 loss)
I0502 11:13:28.158545 26473 sgd_solver.cpp:106] Iteration 22400, lr = 6.4e-05
I0502 11:13:28.163441 26473 solver.cpp:242] Iteration 22400 (104.401 iter/s, 0.957841s/100 iter), loss = 0.405988
I0502 11:13:28.163465 26473 solver.cpp:261]     Train net output #0: loss = 0.405988 (* 1 = 0.405988 loss)
I0502 11:13:28.163473 26473 sgd_solver.cpp:106] Iteration 22400, lr = 6.4e-05
I0502 11:13:29.114372 26473 solver.cpp:362] Iteration 22500, Testing net (#0)
I0502 11:13:29.114400 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:29.240622 26473 solver.cpp:429]     Test net output #0: loss = 0.960202 (* 1 = 0.960202 loss)
I0502 11:13:29.243551 26473 solver.cpp:242] Iteration 22500 (92.1662 iter/s, 1.085s/100 iter), loss = 1.06073
I0502 11:13:29.243572 26473 solver.cpp:261]     Train net output #0: loss = 1.06073 (* 1 = 1.06073 loss)
I0502 11:13:29.243580 26473 sgd_solver.cpp:106] Iteration 22500, lr = 6.4e-05
I0502 11:13:29.245347 26473 solver.cpp:362] Iteration 22500, Testing net (#0)
I0502 11:13:29.245362 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:29.378008 26473 solver.cpp:429]     Test net output #0: accuracy = 0.877
I0502 11:13:29.378031 26473 solver.cpp:429]     Test net output #1: loss = 0.300073 (* 1 = 0.300073 loss)
I0502 11:13:29.380991 26473 solver.cpp:242] Iteration 22500 (82.1352 iter/s, 1.2175s/100 iter), loss = 0.425699
I0502 11:13:29.381012 26473 solver.cpp:261]     Train net output #0: loss = 0.425699 (* 1 = 0.425699 loss)
I0502 11:13:29.381021 26473 sgd_solver.cpp:106] Iteration 22500, lr = 6.4e-05
I0502 11:13:30.333355 26473 solver.cpp:242] Iteration 22600 (91.7635 iter/s, 1.08976s/100 iter), loss = 2.28676
I0502 11:13:30.333395 26473 solver.cpp:261]     Train net output #0: loss = 2.28676 (* 1 = 2.28676 loss)
I0502 11:13:30.333405 26473 sgd_solver.cpp:106] Iteration 22600, lr = 6.4e-05
I0502 11:13:30.338207 26473 solver.cpp:242] Iteration 22600 (104.474 iter/s, 0.957176s/100 iter), loss = 0.443618
I0502 11:13:30.338229 26473 solver.cpp:261]     Train net output #0: loss = 0.443618 (* 1 = 0.443618 loss)
I0502 11:13:30.338238 26473 sgd_solver.cpp:106] Iteration 22600, lr = 6.4e-05
I0502 11:13:31.288650 26473 solver.cpp:242] Iteration 22700 (104.687 iter/s, 0.955226s/100 iter), loss = 0.684025
I0502 11:13:31.288696 26473 solver.cpp:261]     Train net output #0: loss = 0.684025 (* 1 = 0.684025 loss)
I0502 11:13:31.288704 26473 sgd_solver.cpp:106] Iteration 22700, lr = 6.4e-05
I0502 11:13:31.293529 26473 solver.cpp:242] Iteration 22700 (104.681 iter/s, 0.955281s/100 iter), loss = 0.359446
I0502 11:13:31.293551 26473 solver.cpp:261]     Train net output #0: loss = 0.359446 (* 1 = 0.359446 loss)
I0502 11:13:31.293560 26473 sgd_solver.cpp:106] Iteration 22700, lr = 6.4e-05
I0502 11:13:32.244818 26473 solver.cpp:242] Iteration 22800 (104.591 iter/s, 0.956102s/100 iter), loss = 0.39737
I0502 11:13:32.244861 26473 solver.cpp:261]     Train net output #0: loss = 0.39737 (* 1 = 0.39737 loss)
I0502 11:13:32.244870 26473 sgd_solver.cpp:106] Iteration 22800, lr = 6.4e-05
I0502 11:13:32.249711 26473 solver.cpp:242] Iteration 22800 (104.587 iter/s, 0.956141s/100 iter), loss = 0.194493
I0502 11:13:32.249742 26473 solver.cpp:261]     Train net output #0: loss = 0.194493 (* 1 = 0.194493 loss)
I0502 11:13:32.249752 26473 sgd_solver.cpp:106] Iteration 22800, lr = 6.4e-05
I0502 11:13:33.201081 26473 solver.cpp:242] Iteration 22900 (104.581 iter/s, 0.956198s/100 iter), loss = 1.01947
I0502 11:13:33.201134 26473 solver.cpp:261]     Train net output #0: loss = 1.01947 (* 1 = 1.01947 loss)
I0502 11:13:33.201143 26473 sgd_solver.cpp:106] Iteration 22900, lr = 6.4e-05
I0502 11:13:33.205973 26473 solver.cpp:242] Iteration 22900 (104.579 iter/s, 0.956212s/100 iter), loss = 0.334428
I0502 11:13:33.205997 26473 solver.cpp:261]     Train net output #0: loss = 0.334428 (* 1 = 0.334428 loss)
I0502 11:13:33.206006 26473 sgd_solver.cpp:106] Iteration 22900, lr = 6.4e-05
I0502 11:13:34.153658 26473 solver.cpp:362] Iteration 23000, Testing net (#0)
I0502 11:13:34.153687 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:34.279170 26473 solver.cpp:429]     Test net output #0: loss = 0.689875 (* 1 = 0.689875 loss)
I0502 11:13:34.282070 26473 solver.cpp:242] Iteration 23000 (92.514 iter/s, 1.08092s/100 iter), loss = 1.48437
I0502 11:13:34.282090 26473 solver.cpp:261]     Train net output #0: loss = 1.48437 (* 1 = 1.48437 loss)
I0502 11:13:34.282099 26473 sgd_solver.cpp:106] Iteration 23000, lr = 6.4e-05
I0502 11:13:34.283885 26473 solver.cpp:362] Iteration 23000, Testing net (#0)
I0502 11:13:34.283898 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:34.415956 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8815
I0502 11:13:34.415977 26473 solver.cpp:429]     Test net output #1: loss = 0.280369 (* 1 = 0.280369 loss)
I0502 11:13:34.418922 26473 solver.cpp:242] Iteration 23000 (82.4468 iter/s, 1.2129s/100 iter), loss = 0.199755
I0502 11:13:34.418942 26473 solver.cpp:261]     Train net output #0: loss = 0.199755 (* 1 = 0.199755 loss)
I0502 11:13:34.418951 26473 sgd_solver.cpp:106] Iteration 23000, lr = 6.4e-05
I0502 11:13:35.370182 26473 solver.cpp:242] Iteration 23100 (91.906 iter/s, 1.08807s/100 iter), loss = 0.69597
I0502 11:13:35.370226 26473 solver.cpp:261]     Train net output #0: loss = 0.69597 (* 1 = 0.69597 loss)
I0502 11:13:35.370247 26473 sgd_solver.cpp:106] Iteration 23100, lr = 6.4e-05
I0502 11:13:35.375186 26473 solver.cpp:242] Iteration 23100 (104.578 iter/s, 0.956225s/100 iter), loss = 0.238255
I0502 11:13:35.375210 26473 solver.cpp:261]     Train net output #0: loss = 0.238255 (* 1 = 0.238255 loss)
I0502 11:13:35.375217 26473 sgd_solver.cpp:106] Iteration 23100, lr = 6.4e-05
I0502 11:13:36.333148 26473 solver.cpp:242] Iteration 23200 (103.853 iter/s, 0.962901s/100 iter), loss = 0.905526
I0502 11:13:36.333189 26473 solver.cpp:261]     Train net output #0: loss = 0.905526 (* 1 = 0.905526 loss)
I0502 11:13:36.333196 26473 sgd_solver.cpp:106] Iteration 23200, lr = 6.4e-05
I0502 11:13:36.338073 26473 solver.cpp:242] Iteration 23200 (103.859 iter/s, 0.962845s/100 iter), loss = 0.29932
I0502 11:13:36.338095 26473 solver.cpp:261]     Train net output #0: loss = 0.29932 (* 1 = 0.29932 loss)
I0502 11:13:36.338104 26473 sgd_solver.cpp:106] Iteration 23200, lr = 6.4e-05
I0502 11:13:37.296643 26473 solver.cpp:242] Iteration 23300 (103.795 iter/s, 0.963433s/100 iter), loss = 1.21834
I0502 11:13:37.296689 26473 solver.cpp:261]     Train net output #0: loss = 1.21834 (* 1 = 1.21834 loss)
I0502 11:13:37.296697 26473 sgd_solver.cpp:106] Iteration 23300, lr = 6.4e-05
I0502 11:13:37.301555 26473 solver.cpp:242] Iteration 23300 (103.795 iter/s, 0.963442s/100 iter), loss = 0.288357
I0502 11:13:37.301579 26473 solver.cpp:261]     Train net output #0: loss = 0.288357 (* 1 = 0.288357 loss)
I0502 11:13:37.301587 26473 sgd_solver.cpp:106] Iteration 23300, lr = 6.4e-05
I0502 11:13:38.262012 26473 solver.cpp:242] Iteration 23400 (103.595 iter/s, 0.965296s/100 iter), loss = 0.996831
I0502 11:13:38.262066 26473 solver.cpp:261]     Train net output #0: loss = 0.996831 (* 1 = 0.996831 loss)
I0502 11:13:38.262075 26473 sgd_solver.cpp:106] Iteration 23400, lr = 6.4e-05
I0502 11:13:38.266988 26473 solver.cpp:242] Iteration 23400 (103.585 iter/s, 0.96539s/100 iter), loss = 0.471332
I0502 11:13:38.267017 26473 solver.cpp:261]     Train net output #0: loss = 0.471332 (* 1 = 0.471332 loss)
I0502 11:13:38.267026 26473 sgd_solver.cpp:106] Iteration 23400, lr = 6.4e-05
I0502 11:13:39.222164 26473 solver.cpp:362] Iteration 23500, Testing net (#0)
I0502 11:13:39.222190 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:39.349717 26473 solver.cpp:429]     Test net output #0: loss = 1.00982 (* 1 = 1.00982 loss)
I0502 11:13:39.352675 26473 solver.cpp:242] Iteration 23500 (91.6935 iter/s, 1.09059s/100 iter), loss = 1.24776
I0502 11:13:39.352695 26473 solver.cpp:261]     Train net output #0: loss = 1.24776 (* 1 = 1.24776 loss)
I0502 11:13:39.352704 26473 sgd_solver.cpp:106] Iteration 23500, lr = 6.4e-05
I0502 11:13:39.354378 26473 solver.cpp:362] Iteration 23500, Testing net (#0)
I0502 11:13:39.354391 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:39.488246 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8505
I0502 11:13:39.488270 26473 solver.cpp:429]     Test net output #1: loss = 0.349796 (* 1 = 0.349796 loss)
I0502 11:13:39.491262 26473 solver.cpp:242] Iteration 23500 (81.6845 iter/s, 1.22422s/100 iter), loss = 0.253036
I0502 11:13:39.491282 26473 solver.cpp:261]     Train net output #0: loss = 0.253036 (* 1 = 0.253036 loss)
I0502 11:13:39.491291 26473 sgd_solver.cpp:106] Iteration 23500, lr = 6.4e-05
I0502 11:13:40.449193 26473 solver.cpp:242] Iteration 23600 (91.2013 iter/s, 1.09648s/100 iter), loss = 1.91859
I0502 11:13:40.449229 26473 solver.cpp:261]     Train net output #0: loss = 1.91859 (* 1 = 1.91859 loss)
I0502 11:13:40.449237 26473 sgd_solver.cpp:106] Iteration 23600, lr = 6.4e-05
I0502 11:13:40.454144 26473 solver.cpp:242] Iteration 23600 (103.859 iter/s, 0.962844s/100 iter), loss = 0.196734
I0502 11:13:40.454167 26473 solver.cpp:261]     Train net output #0: loss = 0.196734 (* 1 = 0.196734 loss)
I0502 11:13:40.454176 26473 sgd_solver.cpp:106] Iteration 23600, lr = 6.4e-05
I0502 11:13:41.410341 26473 solver.cpp:242] Iteration 23700 (104.049 iter/s, 0.961088s/100 iter), loss = 0.242307
I0502 11:13:41.410382 26473 solver.cpp:261]     Train net output #0: loss = 0.242307 (* 1 = 0.242307 loss)
I0502 11:13:41.410392 26473 sgd_solver.cpp:106] Iteration 23700, lr = 6.4e-05
I0502 11:13:41.415227 26473 solver.cpp:242] Iteration 23700 (104.054 iter/s, 0.961041s/100 iter), loss = 0.352779
I0502 11:13:41.415249 26473 solver.cpp:261]     Train net output #0: loss = 0.352779 (* 1 = 0.352779 loss)
I0502 11:13:41.415258 26473 sgd_solver.cpp:106] Iteration 23700, lr = 6.4e-05
I0502 11:13:42.370862 26473 solver.cpp:242] Iteration 23800 (104.117 iter/s, 0.960458s/100 iter), loss = 0.250915
I0502 11:13:42.370903 26473 solver.cpp:261]     Train net output #0: loss = 0.250915 (* 1 = 0.250915 loss)
I0502 11:13:42.370913 26473 sgd_solver.cpp:106] Iteration 23800, lr = 6.4e-05
I0502 11:13:42.375736 26473 solver.cpp:242] Iteration 23800 (104.116 iter/s, 0.960468s/100 iter), loss = 0.217002
I0502 11:13:42.375759 26473 solver.cpp:261]     Train net output #0: loss = 0.217002 (* 1 = 0.217002 loss)
I0502 11:13:42.375767 26473 sgd_solver.cpp:106] Iteration 23800, lr = 6.4e-05
I0502 11:13:43.331086 26473 solver.cpp:242] Iteration 23900 (104.149 iter/s, 0.960162s/100 iter), loss = 0.832647
I0502 11:13:43.331145 26473 solver.cpp:261]     Train net output #0: loss = 0.832647 (* 1 = 0.832647 loss)
I0502 11:13:43.331154 26473 sgd_solver.cpp:106] Iteration 23900, lr = 6.4e-05
I0502 11:13:43.336076 26473 solver.cpp:242] Iteration 23900 (104.134 iter/s, 0.960299s/100 iter), loss = 0.147144
I0502 11:13:43.336100 26473 solver.cpp:261]     Train net output #0: loss = 0.147144 (* 1 = 0.147144 loss)
I0502 11:13:43.336108 26473 sgd_solver.cpp:106] Iteration 23900, lr = 6.4e-05
I0502 11:13:44.289113 26473 solver.cpp:362] Iteration 24000, Testing net (#0)
I0502 11:13:44.289139 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:44.415772 26473 solver.cpp:429]     Test net output #0: loss = 0.867694 (* 1 = 0.867694 loss)
I0502 11:13:44.418725 26473 solver.cpp:242] Iteration 24000 (91.9488 iter/s, 1.08756s/100 iter), loss = 1.20237
I0502 11:13:44.418745 26473 solver.cpp:261]     Train net output #0: loss = 1.20237 (* 1 = 1.20237 loss)
I0502 11:13:44.418754 26473 sgd_solver.cpp:106] Iteration 24000, lr = 6.4e-05
I0502 11:13:44.420418 26473 solver.cpp:362] Iteration 24000, Testing net (#0)
I0502 11:13:44.420431 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:44.553839 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8815
I0502 11:13:44.553863 26473 solver.cpp:429]     Test net output #1: loss = 0.30631 (* 1 = 0.30631 loss)
I0502 11:13:44.556850 26473 solver.cpp:242] Iteration 24000 (81.9183 iter/s, 1.22073s/100 iter), loss = 0.3738
I0502 11:13:44.556871 26473 solver.cpp:261]     Train net output #0: loss = 0.3738 (* 1 = 0.3738 loss)
I0502 11:13:44.556879 26473 sgd_solver.cpp:106] Iteration 24000, lr = 6.4e-05
I0502 11:13:45.513001 26473 solver.cpp:242] Iteration 24100 (91.3885 iter/s, 1.09423s/100 iter), loss = 0.442164
I0502 11:13:45.513044 26473 solver.cpp:261]     Train net output #0: loss = 0.442164 (* 1 = 0.442164 loss)
I0502 11:13:45.513052 26473 sgd_solver.cpp:106] Iteration 24100, lr = 6.4e-05
I0502 11:13:45.517974 26473 solver.cpp:242] Iteration 24100 (104.049 iter/s, 0.961084s/100 iter), loss = 0.255
I0502 11:13:45.517998 26473 solver.cpp:261]     Train net output #0: loss = 0.255 (* 1 = 0.255 loss)
I0502 11:13:45.518007 26473 sgd_solver.cpp:106] Iteration 24100, lr = 6.4e-05
I0502 11:13:46.473685 26473 solver.cpp:242] Iteration 24200 (104.099 iter/s, 0.960621s/100 iter), loss = 0.307664
I0502 11:13:46.473721 26473 solver.cpp:261]     Train net output #0: loss = 0.307664 (* 1 = 0.307664 loss)
I0502 11:13:46.473731 26473 sgd_solver.cpp:106] Iteration 24200, lr = 6.4e-05
I0502 11:13:46.478637 26473 solver.cpp:242] Iteration 24200 (104.099 iter/s, 0.960621s/100 iter), loss = 0.264167
I0502 11:13:46.478662 26473 solver.cpp:261]     Train net output #0: loss = 0.264167 (* 1 = 0.264167 loss)
I0502 11:13:46.478670 26473 sgd_solver.cpp:106] Iteration 24200, lr = 6.4e-05
I0502 11:13:47.433780 26473 solver.cpp:242] Iteration 24300 (104.163 iter/s, 0.960037s/100 iter), loss = 0.651063
I0502 11:13:47.433823 26473 solver.cpp:261]     Train net output #0: loss = 0.651063 (* 1 = 0.651063 loss)
I0502 11:13:47.433831 26473 sgd_solver.cpp:106] Iteration 24300, lr = 6.4e-05
I0502 11:13:47.438668 26473 solver.cpp:242] Iteration 24300 (104.168 iter/s, 0.959988s/100 iter), loss = 0.32192
I0502 11:13:47.438689 26473 solver.cpp:261]     Train net output #0: loss = 0.32192 (* 1 = 0.32192 loss)
I0502 11:13:47.438699 26473 sgd_solver.cpp:106] Iteration 24300, lr = 6.4e-05
I0502 11:13:48.394803 26473 solver.cpp:242] Iteration 24400 (104.063 iter/s, 0.960958s/100 iter), loss = 0.123496
I0502 11:13:48.394857 26473 solver.cpp:261]     Train net output #0: loss = 0.123496 (* 1 = 0.123496 loss)
I0502 11:13:48.394866 26473 sgd_solver.cpp:106] Iteration 24400, lr = 6.4e-05
I0502 11:13:48.399812 26473 solver.cpp:242] Iteration 24400 (104.047 iter/s, 0.961104s/100 iter), loss = 0.111638
I0502 11:13:48.399837 26473 solver.cpp:261]     Train net output #0: loss = 0.111638 (* 1 = 0.111638 loss)
I0502 11:13:48.399845 26473 sgd_solver.cpp:106] Iteration 24400, lr = 6.4e-05
I0502 11:13:49.352074 26473 solver.cpp:362] Iteration 24500, Testing net (#0)
I0502 11:13:49.352102 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:49.478791 26473 solver.cpp:429]     Test net output #0: loss = 1.18212 (* 1 = 1.18212 loss)
I0502 11:13:49.481732 26473 solver.cpp:242] Iteration 24500 (92.0085 iter/s, 1.08686s/100 iter), loss = 1.73621
I0502 11:13:49.481752 26473 solver.cpp:261]     Train net output #0: loss = 1.73621 (* 1 = 1.73621 loss)
I0502 11:13:49.481761 26473 sgd_solver.cpp:106] Iteration 24500, lr = 6.4e-05
I0502 11:13:49.483456 26473 solver.cpp:362] Iteration 24500, Testing net (#0)
I0502 11:13:49.483469 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:49.617070 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8755
I0502 11:13:49.617094 26473 solver.cpp:429]     Test net output #1: loss = 0.288116 (* 1 = 0.288116 loss)
I0502 11:13:49.620092 26473 solver.cpp:242] Iteration 24500 (81.9514 iter/s, 1.22024s/100 iter), loss = 0.309938
I0502 11:13:49.620112 26473 solver.cpp:261]     Train net output #0: loss = 0.309938 (* 1 = 0.309938 loss)
I0502 11:13:49.620121 26473 sgd_solver.cpp:106] Iteration 24500, lr = 6.4e-05
I0502 11:13:50.578016 26473 solver.cpp:242] Iteration 24600 (91.221 iter/s, 1.09624s/100 iter), loss = 0.318471
I0502 11:13:50.578058 26473 solver.cpp:261]     Train net output #0: loss = 0.318471 (* 1 = 0.318471 loss)
I0502 11:13:50.578066 26473 sgd_solver.cpp:106] Iteration 24600, lr = 6.4e-05
I0502 11:13:50.582957 26473 solver.cpp:242] Iteration 24600 (103.861 iter/s, 0.962826s/100 iter), loss = 0.194477
I0502 11:13:50.582980 26473 solver.cpp:261]     Train net output #0: loss = 0.194477 (* 1 = 0.194477 loss)
I0502 11:13:50.582988 26473 sgd_solver.cpp:106] Iteration 24600, lr = 6.4e-05
I0502 11:13:51.540385 26473 solver.cpp:242] Iteration 24700 (103.917 iter/s, 0.962306s/100 iter), loss = 0.572786
I0502 11:13:51.540426 26473 solver.cpp:261]     Train net output #0: loss = 0.572786 (* 1 = 0.572786 loss)
I0502 11:13:51.540433 26473 sgd_solver.cpp:106] Iteration 24700, lr = 6.4e-05
I0502 11:13:51.545264 26473 solver.cpp:242] Iteration 24700 (103.921 iter/s, 0.962265s/100 iter), loss = 0.272863
I0502 11:13:51.545287 26473 solver.cpp:261]     Train net output #0: loss = 0.272863 (* 1 = 0.272863 loss)
I0502 11:13:51.545295 26473 sgd_solver.cpp:106] Iteration 24700, lr = 6.4e-05
I0502 11:13:52.498898 26473 solver.cpp:242] Iteration 24800 (104.335 iter/s, 0.958452s/100 iter), loss = 0.570226
I0502 11:13:52.498931 26473 solver.cpp:261]     Train net output #0: loss = 0.570226 (* 1 = 0.570226 loss)
I0502 11:13:52.498939 26473 sgd_solver.cpp:106] Iteration 24800, lr = 6.4e-05
I0502 11:13:52.503733 26473 solver.cpp:242] Iteration 24800 (104.338 iter/s, 0.958428s/100 iter), loss = 0.196458
I0502 11:13:52.503756 26473 solver.cpp:261]     Train net output #0: loss = 0.196458 (* 1 = 0.196458 loss)
I0502 11:13:52.503764 26473 sgd_solver.cpp:106] Iteration 24800, lr = 6.4e-05
I0502 11:13:53.457635 26473 solver.cpp:242] Iteration 24900 (104.31 iter/s, 0.958682s/100 iter), loss = 1.03409
I0502 11:13:53.457691 26473 solver.cpp:261]     Train net output #0: loss = 1.03409 (* 1 = 1.03409 loss)
I0502 11:13:53.457701 26473 sgd_solver.cpp:106] Iteration 24900, lr = 6.4e-05
I0502 11:13:53.462544 26473 solver.cpp:242] Iteration 24900 (104.3 iter/s, 0.958769s/100 iter), loss = 0.382702
I0502 11:13:53.462568 26473 solver.cpp:261]     Train net output #0: loss = 0.382702 (* 1 = 0.382702 loss)
I0502 11:13:53.462576 26473 sgd_solver.cpp:106] Iteration 24900, lr = 6.4e-05
I0502 11:13:54.411717 26473 solver.cpp:362] Iteration 25000, Testing net (#0)
I0502 11:13:54.411746 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:54.537870 26473 solver.cpp:429]     Test net output #0: loss = 0.934334 (* 1 = 0.934334 loss)
I0502 11:13:54.540788 26473 solver.cpp:242] Iteration 25000 (92.3294 iter/s, 1.08308s/100 iter), loss = 0.735179
I0502 11:13:54.540809 26473 solver.cpp:261]     Train net output #0: loss = 0.735179 (* 1 = 0.735179 loss)
I0502 11:13:54.540818 26473 sgd_solver.cpp:106] Iteration 25000, lr = 6.4e-05
I0502 11:13:54.542565 26473 solver.cpp:362] Iteration 25000, Testing net (#0)
I0502 11:13:54.542580 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:54.675305 26473 solver.cpp:429]     Test net output #0: accuracy = 0.871
I0502 11:13:54.675329 26473 solver.cpp:429]     Test net output #1: loss = 0.304271 (* 1 = 0.304271 loss)
I0502 11:13:54.678306 26473 solver.cpp:242] Iteration 25000 (82.256 iter/s, 1.21572s/100 iter), loss = 0.0996656
I0502 11:13:54.678328 26473 solver.cpp:261]     Train net output #0: loss = 0.0996656 (* 1 = 0.0996656 loss)
I0502 11:13:54.678336 26473 sgd_solver.cpp:106] Iteration 25000, lr = 6.4e-05
I0502 11:13:55.631355 26473 solver.cpp:242] Iteration 25100 (91.6993 iter/s, 1.09052s/100 iter), loss = 1.1519
I0502 11:13:55.631399 26473 solver.cpp:261]     Train net output #0: loss = 1.1519 (* 1 = 1.1519 loss)
I0502 11:13:55.631408 26473 sgd_solver.cpp:106] Iteration 25100, lr = 6.4e-05
I0502 11:13:55.636309 26473 solver.cpp:242] Iteration 25100 (104.388 iter/s, 0.957963s/100 iter), loss = 0.209696
I0502 11:13:55.636332 26473 solver.cpp:261]     Train net output #0: loss = 0.209696 (* 1 = 0.209696 loss)
I0502 11:13:55.636339 26473 sgd_solver.cpp:106] Iteration 25100, lr = 6.4e-05
I0502 11:13:56.588711 26473 solver.cpp:242] Iteration 25200 (104.462 iter/s, 0.957288s/100 iter), loss = 1.05472
I0502 11:13:56.588757 26473 solver.cpp:261]     Train net output #0: loss = 1.05472 (* 1 = 1.05472 loss)
I0502 11:13:56.588764 26473 sgd_solver.cpp:106] Iteration 25200, lr = 6.4e-05
I0502 11:13:56.593648 26473 solver.cpp:242] Iteration 25200 (104.461 iter/s, 0.957298s/100 iter), loss = 0.470433
I0502 11:13:56.593674 26473 solver.cpp:261]     Train net output #0: loss = 0.470433 (* 1 = 0.470433 loss)
I0502 11:13:56.593683 26473 sgd_solver.cpp:106] Iteration 25200, lr = 6.4e-05
I0502 11:13:57.544872 26473 solver.cpp:242] Iteration 25300 (104.592 iter/s, 0.956096s/100 iter), loss = 0.231495
I0502 11:13:57.544914 26473 solver.cpp:261]     Train net output #0: loss = 0.231495 (* 1 = 0.231495 loss)
I0502 11:13:57.544924 26473 sgd_solver.cpp:106] Iteration 25300, lr = 6.4e-05
I0502 11:13:57.549724 26473 solver.cpp:242] Iteration 25300 (104.599 iter/s, 0.956032s/100 iter), loss = 0.261146
I0502 11:13:57.549747 26473 solver.cpp:261]     Train net output #0: loss = 0.261146 (* 1 = 0.261146 loss)
I0502 11:13:57.549756 26473 sgd_solver.cpp:106] Iteration 25300, lr = 6.4e-05
I0502 11:13:58.501224 26473 solver.cpp:242] Iteration 25400 (104.571 iter/s, 0.956289s/100 iter), loss = 1.83936
I0502 11:13:58.501256 26473 solver.cpp:261]     Train net output #0: loss = 1.83936 (* 1 = 1.83936 loss)
I0502 11:13:58.501265 26473 sgd_solver.cpp:106] Iteration 25400, lr = 6.4e-05
I0502 11:13:58.506137 26473 solver.cpp:242] Iteration 25400 (104.562 iter/s, 0.956371s/100 iter), loss = 0.324528
I0502 11:13:58.506161 26473 solver.cpp:261]     Train net output #0: loss = 0.324528 (* 1 = 0.324528 loss)
I0502 11:13:58.506170 26473 sgd_solver.cpp:106] Iteration 25400, lr = 6.4e-05
I0502 11:13:59.454289 26473 solver.cpp:362] Iteration 25500, Testing net (#0)
I0502 11:13:59.454319 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:59.579872 26473 solver.cpp:429]     Test net output #0: loss = 0.792637 (* 1 = 0.792637 loss)
I0502 11:13:59.582787 26473 solver.cpp:242] Iteration 25500 (92.4631 iter/s, 1.08151s/100 iter), loss = 0.280068
I0502 11:13:59.582808 26473 solver.cpp:261]     Train net output #0: loss = 0.280068 (* 1 = 0.280068 loss)
I0502 11:13:59.582818 26473 sgd_solver.cpp:106] Iteration 25500, lr = 6.4e-05
I0502 11:13:59.584475 26473 solver.cpp:362] Iteration 25500, Testing net (#0)
I0502 11:13:59.584488 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:13:59.716348 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8835
I0502 11:13:59.716372 26473 solver.cpp:429]     Test net output #1: loss = 0.312226 (* 1 = 0.312226 loss)
I0502 11:13:59.719326 26473 solver.cpp:242] Iteration 25500 (82.4306 iter/s, 1.21314s/100 iter), loss = 0.185689
I0502 11:13:59.719346 26473 solver.cpp:261]     Train net output #0: loss = 0.185689 (* 1 = 0.185689 loss)
I0502 11:13:59.719354 26473 sgd_solver.cpp:106] Iteration 25500, lr = 6.4e-05
I0502 11:14:00.684334 26473 solver.cpp:242] Iteration 25600 (90.7853 iter/s, 1.1015s/100 iter), loss = 1.53815
I0502 11:14:00.684376 26473 solver.cpp:261]     Train net output #0: loss = 1.53815 (* 1 = 1.53815 loss)
I0502 11:14:00.684384 26473 sgd_solver.cpp:106] Iteration 25600, lr = 6.4e-05
I0502 11:14:00.689321 26473 solver.cpp:242] Iteration 25600 (103.097 iter/s, 0.969957s/100 iter), loss = 0.500427
I0502 11:14:00.689347 26473 solver.cpp:261]     Train net output #0: loss = 0.500427 (* 1 = 0.500427 loss)
I0502 11:14:00.689355 26473 sgd_solver.cpp:106] Iteration 25600, lr = 6.4e-05
I0502 11:14:01.640988 26473 solver.cpp:242] Iteration 25700 (104.538 iter/s, 0.956592s/100 iter), loss = 0.831893
I0502 11:14:01.641038 26473 solver.cpp:261]     Train net output #0: loss = 0.831893 (* 1 = 0.831893 loss)
I0502 11:14:01.641048 26473 sgd_solver.cpp:106] Iteration 25700, lr = 6.4e-05
I0502 11:14:01.645956 26473 solver.cpp:242] Iteration 25700 (104.538 iter/s, 0.95659s/100 iter), loss = 0.483622
I0502 11:14:01.645978 26473 solver.cpp:261]     Train net output #0: loss = 0.483622 (* 1 = 0.483622 loss)
I0502 11:14:01.645987 26473 sgd_solver.cpp:106] Iteration 25700, lr = 6.4e-05
I0502 11:14:02.596410 26473 solver.cpp:242] Iteration 25800 (104.674 iter/s, 0.95535s/100 iter), loss = 0.96173
I0502 11:14:02.596451 26473 solver.cpp:261]     Train net output #0: loss = 0.96173 (* 1 = 0.96173 loss)
I0502 11:14:02.596459 26473 sgd_solver.cpp:106] Iteration 25800, lr = 6.4e-05
I0502 11:14:02.601260 26473 solver.cpp:242] Iteration 25800 (104.683 iter/s, 0.955264s/100 iter), loss = 0.209053
I0502 11:14:02.601284 26473 solver.cpp:261]     Train net output #0: loss = 0.209053 (* 1 = 0.209053 loss)
I0502 11:14:02.601292 26473 sgd_solver.cpp:106] Iteration 25800, lr = 6.4e-05
I0502 11:14:03.550504 26473 solver.cpp:242] Iteration 25900 (104.818 iter/s, 0.954032s/100 iter), loss = 1.86823
I0502 11:14:03.550561 26473 solver.cpp:261]     Train net output #0: loss = 1.86823 (* 1 = 1.86823 loss)
I0502 11:14:03.550570 26473 sgd_solver.cpp:106] Iteration 25900, lr = 6.4e-05
I0502 11:14:03.555403 26473 solver.cpp:242] Iteration 25900 (104.811 iter/s, 0.954101s/100 iter), loss = 0.229683
I0502 11:14:03.555426 26473 solver.cpp:261]     Train net output #0: loss = 0.229683 (* 1 = 0.229683 loss)
I0502 11:14:03.555435 26473 sgd_solver.cpp:106] Iteration 25900, lr = 6.4e-05
I0502 11:14:04.501737 26473 solver.cpp:362] Iteration 26000, Testing net (#0)
I0502 11:14:04.501760 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:04.626868 26473 solver.cpp:429]     Test net output #0: loss = 0.805556 (* 1 = 0.805556 loss)
I0502 11:14:04.629755 26473 solver.cpp:242] Iteration 26000 (92.6633 iter/s, 1.07918s/100 iter), loss = 0.86398
I0502 11:14:04.629776 26473 solver.cpp:261]     Train net output #0: loss = 0.86398 (* 1 = 0.86398 loss)
I0502 11:14:04.629784 26473 sgd_solver.cpp:106] Iteration 26000, lr = 6.4e-05
I0502 11:14:04.631465 26473 solver.cpp:362] Iteration 26000, Testing net (#0)
I0502 11:14:04.631477 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:04.762892 26473 solver.cpp:429]     Test net output #0: accuracy = 0.897
I0502 11:14:04.762912 26473 solver.cpp:429]     Test net output #1: loss = 0.266473 (* 1 = 0.266473 loss)
I0502 11:14:04.765835 26473 solver.cpp:242] Iteration 26000 (82.6183 iter/s, 1.21039s/100 iter), loss = 0.366808
I0502 11:14:04.765856 26473 solver.cpp:261]     Train net output #0: loss = 0.366808 (* 1 = 0.366808 loss)
I0502 11:14:04.765864 26473 sgd_solver.cpp:106] Iteration 26000, lr = 6.4e-05
I0502 11:14:05.723628 26473 solver.cpp:242] Iteration 26100 (91.4222 iter/s, 1.09383s/100 iter), loss = 0.36803
I0502 11:14:05.723670 26473 solver.cpp:261]     Train net output #0: loss = 0.36803 (* 1 = 0.36803 loss)
I0502 11:14:05.723680 26473 sgd_solver.cpp:106] Iteration 26100, lr = 6.4e-05
I0502 11:14:05.728585 26473 solver.cpp:242] Iteration 26100 (103.873 iter/s, 0.962712s/100 iter), loss = 0.225191
I0502 11:14:05.728610 26473 solver.cpp:261]     Train net output #0: loss = 0.225191 (* 1 = 0.225191 loss)
I0502 11:14:05.728618 26473 sgd_solver.cpp:106] Iteration 26100, lr = 6.4e-05
I0502 11:14:06.686645 26473 solver.cpp:242] Iteration 26200 (103.847 iter/s, 0.962952s/100 iter), loss = 0.628682
I0502 11:14:06.686686 26473 solver.cpp:261]     Train net output #0: loss = 0.628682 (* 1 = 0.628682 loss)
I0502 11:14:06.686694 26473 sgd_solver.cpp:106] Iteration 26200, lr = 6.4e-05
I0502 11:14:06.691612 26473 solver.cpp:242] Iteration 26200 (103.844 iter/s, 0.962983s/100 iter), loss = 0.376168
I0502 11:14:06.691634 26473 solver.cpp:261]     Train net output #0: loss = 0.376168 (* 1 = 0.376168 loss)
I0502 11:14:06.691642 26473 sgd_solver.cpp:106] Iteration 26200, lr = 6.4e-05
I0502 11:14:07.646965 26473 solver.cpp:242] Iteration 26300 (104.139 iter/s, 0.960258s/100 iter), loss = 0.515081
I0502 11:14:07.647003 26473 solver.cpp:261]     Train net output #0: loss = 0.515081 (* 1 = 0.515081 loss)
I0502 11:14:07.647012 26473 sgd_solver.cpp:106] Iteration 26300, lr = 6.4e-05
I0502 11:14:07.651845 26473 solver.cpp:242] Iteration 26300 (104.146 iter/s, 0.960192s/100 iter), loss = 0.395923
I0502 11:14:07.651870 26473 solver.cpp:261]     Train net output #0: loss = 0.395923 (* 1 = 0.395923 loss)
I0502 11:14:07.651877 26473 sgd_solver.cpp:106] Iteration 26300, lr = 6.4e-05
I0502 11:14:08.607254 26473 solver.cpp:242] Iteration 26400 (104.142 iter/s, 0.960228s/100 iter), loss = 2.59341
I0502 11:14:08.607311 26473 solver.cpp:261]     Train net output #0: loss = 2.59341 (* 1 = 2.59341 loss)
I0502 11:14:08.607321 26473 sgd_solver.cpp:106] Iteration 26400, lr = 6.4e-05
I0502 11:14:08.612226 26473 solver.cpp:242] Iteration 26400 (104.13 iter/s, 0.960339s/100 iter), loss = 0.351599
I0502 11:14:08.612249 26473 solver.cpp:261]     Train net output #0: loss = 0.351599 (* 1 = 0.351599 loss)
I0502 11:14:08.612257 26473 sgd_solver.cpp:106] Iteration 26400, lr = 6.4e-05
I0502 11:14:09.563390 26473 solver.cpp:362] Iteration 26500, Testing net (#0)
I0502 11:14:09.563417 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:09.689968 26473 solver.cpp:429]     Test net output #0: loss = 0.697268 (* 1 = 0.697268 loss)
I0502 11:14:09.692908 26473 solver.cpp:242] Iteration 26500 (92.1168 iter/s, 1.08558s/100 iter), loss = 0.337609
I0502 11:14:09.692927 26473 solver.cpp:261]     Train net output #0: loss = 0.337609 (* 1 = 0.337609 loss)
I0502 11:14:09.692936 26473 sgd_solver.cpp:106] Iteration 26500, lr = 6.4e-05
I0502 11:14:09.694610 26473 solver.cpp:362] Iteration 26500, Testing net (#0)
I0502 11:14:09.694624 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:09.828232 26473 solver.cpp:429]     Test net output #0: accuracy = 0.893
I0502 11:14:09.828256 26473 solver.cpp:429]     Test net output #1: loss = 0.257945 (* 1 = 0.257945 loss)
I0502 11:14:09.831221 26473 solver.cpp:242] Iteration 26500 (82.0378 iter/s, 1.21895s/100 iter), loss = 0.14111
I0502 11:14:09.831241 26473 solver.cpp:261]     Train net output #0: loss = 0.14111 (* 1 = 0.14111 loss)
I0502 11:14:09.831250 26473 sgd_solver.cpp:106] Iteration 26500, lr = 6.4e-05
I0502 11:14:10.787201 26473 solver.cpp:242] Iteration 26600 (91.3869 iter/s, 1.09425s/100 iter), loss = 0.786536
I0502 11:14:10.787245 26473 solver.cpp:261]     Train net output #0: loss = 0.786536 (* 1 = 0.786536 loss)
I0502 11:14:10.787253 26473 sgd_solver.cpp:106] Iteration 26600, lr = 6.4e-05
I0502 11:14:10.792075 26473 solver.cpp:242] Iteration 26600 (104.078 iter/s, 0.960815s/100 iter), loss = 0.198688
I0502 11:14:10.792099 26473 solver.cpp:261]     Train net output #0: loss = 0.198688 (* 1 = 0.198688 loss)
I0502 11:14:10.792107 26473 sgd_solver.cpp:106] Iteration 26600, lr = 6.4e-05
I0502 11:14:11.745879 26473 solver.cpp:242] Iteration 26700 (104.317 iter/s, 0.958616s/100 iter), loss = 0.467206
I0502 11:14:11.745909 26473 solver.cpp:261]     Train net output #0: loss = 0.467206 (* 1 = 0.467206 loss)
I0502 11:14:11.745918 26473 sgd_solver.cpp:106] Iteration 26700, lr = 6.4e-05
I0502 11:14:11.750847 26473 solver.cpp:242] Iteration 26700 (104.305 iter/s, 0.958729s/100 iter), loss = 0.267476
I0502 11:14:11.750869 26473 solver.cpp:261]     Train net output #0: loss = 0.267476 (* 1 = 0.267476 loss)
I0502 11:14:11.750877 26473 sgd_solver.cpp:106] Iteration 26700, lr = 6.4e-05
I0502 11:14:12.706039 26473 solver.cpp:242] Iteration 26800 (104.155 iter/s, 0.960108s/100 iter), loss = 0.305874
I0502 11:14:12.706080 26473 solver.cpp:261]     Train net output #0: loss = 0.305874 (* 1 = 0.305874 loss)
I0502 11:14:12.706089 26473 sgd_solver.cpp:106] Iteration 26800, lr = 6.4e-05
I0502 11:14:12.710894 26473 solver.cpp:242] Iteration 26800 (104.166 iter/s, 0.960006s/100 iter), loss = 0.742761
I0502 11:14:12.710917 26473 solver.cpp:261]     Train net output #0: loss = 0.742761 (* 1 = 0.742761 loss)
I0502 11:14:12.710932 26473 sgd_solver.cpp:106] Iteration 26800, lr = 6.4e-05
I0502 11:14:13.662041 26473 solver.cpp:242] Iteration 26900 (104.609 iter/s, 0.955941s/100 iter), loss = 0.17147
I0502 11:14:13.662082 26473 solver.cpp:261]     Train net output #0: loss = 0.17147 (* 1 = 0.17147 loss)
I0502 11:14:13.662091 26473 sgd_solver.cpp:106] Iteration 26900, lr = 6.4e-05
I0502 11:14:13.666940 26473 solver.cpp:242] Iteration 26900 (104.602 iter/s, 0.956005s/100 iter), loss = 0.145657
I0502 11:14:13.666965 26473 solver.cpp:261]     Train net output #0: loss = 0.145657 (* 1 = 0.145657 loss)
I0502 11:14:13.666975 26473 sgd_solver.cpp:106] Iteration 26900, lr = 6.4e-05
I0502 11:14:14.615520 26473 solver.cpp:362] Iteration 27000, Testing net (#0)
I0502 11:14:14.615548 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:14.741518 26473 solver.cpp:429]     Test net output #0: loss = 0.86215 (* 1 = 0.86215 loss)
I0502 11:14:14.744441 26473 solver.cpp:242] Iteration 27000 (92.3925 iter/s, 1.08234s/100 iter), loss = 1.16846
I0502 11:14:14.744462 26473 solver.cpp:261]     Train net output #0: loss = 1.16846 (* 1 = 1.16846 loss)
I0502 11:14:14.744469 26473 sgd_solver.cpp:106] Iteration 27000, lr = 6.4e-05
I0502 11:14:14.746167 26473 solver.cpp:362] Iteration 27000, Testing net (#0)
I0502 11:14:14.746182 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:14.878720 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8885
I0502 11:14:14.878739 26473 solver.cpp:429]     Test net output #1: loss = 0.270843 (* 1 = 0.270843 loss)
I0502 11:14:14.881700 26473 solver.cpp:242] Iteration 27000 (82.324 iter/s, 1.21471s/100 iter), loss = 0.309259
I0502 11:14:14.881721 26473 solver.cpp:261]     Train net output #0: loss = 0.309259 (* 1 = 0.309259 loss)
I0502 11:14:14.881728 26473 sgd_solver.cpp:106] Iteration 27000, lr = 6.4e-05
I0502 11:14:15.835535 26473 solver.cpp:242] Iteration 27100 (91.6552 iter/s, 1.09105s/100 iter), loss = 1.38251
I0502 11:14:15.835578 26473 solver.cpp:261]     Train net output #0: loss = 1.38251 (* 1 = 1.38251 loss)
I0502 11:14:15.835587 26473 sgd_solver.cpp:106] Iteration 27100, lr = 6.4e-05
I0502 11:14:15.840401 26473 solver.cpp:242] Iteration 27100 (104.312 iter/s, 0.958661s/100 iter), loss = 0.511841
I0502 11:14:15.840425 26473 solver.cpp:261]     Train net output #0: loss = 0.511841 (* 1 = 0.511841 loss)
I0502 11:14:15.840433 26473 sgd_solver.cpp:106] Iteration 27100, lr = 6.4e-05
I0502 11:14:16.792436 26473 solver.cpp:242] Iteration 27200 (104.511 iter/s, 0.956837s/100 iter), loss = 1.05005
I0502 11:14:16.792479 26473 solver.cpp:261]     Train net output #0: loss = 1.05005 (* 1 = 1.05005 loss)
I0502 11:14:16.792487 26473 sgd_solver.cpp:106] Iteration 27200, lr = 6.4e-05
I0502 11:14:16.797372 26473 solver.cpp:242] Iteration 27200 (104.501 iter/s, 0.956929s/100 iter), loss = 0.125478
I0502 11:14:16.797396 26473 solver.cpp:261]     Train net output #0: loss = 0.125478 (* 1 = 0.125478 loss)
I0502 11:14:16.797405 26473 sgd_solver.cpp:106] Iteration 27200, lr = 6.4e-05
I0502 11:14:17.749732 26473 solver.cpp:242] Iteration 27300 (104.468 iter/s, 0.957233s/100 iter), loss = 0.550618
I0502 11:14:17.749768 26473 solver.cpp:261]     Train net output #0: loss = 0.550618 (* 1 = 0.550618 loss)
I0502 11:14:17.749776 26473 sgd_solver.cpp:106] Iteration 27300, lr = 6.4e-05
I0502 11:14:17.754580 26473 solver.cpp:242] Iteration 27300 (104.475 iter/s, 0.957164s/100 iter), loss = 0.222288
I0502 11:14:17.754602 26473 solver.cpp:261]     Train net output #0: loss = 0.222288 (* 1 = 0.222288 loss)
I0502 11:14:17.754611 26473 sgd_solver.cpp:106] Iteration 27300, lr = 6.4e-05
I0502 11:14:18.705607 26473 solver.cpp:242] Iteration 27400 (104.623 iter/s, 0.955817s/100 iter), loss = 0.245165
I0502 11:14:18.705665 26473 solver.cpp:261]     Train net output #0: loss = 0.245165 (* 1 = 0.245165 loss)
I0502 11:14:18.705675 26473 sgd_solver.cpp:106] Iteration 27400, lr = 6.4e-05
I0502 11:14:18.710556 26473 solver.cpp:242] Iteration 27400 (104.61 iter/s, 0.955936s/100 iter), loss = 0.353972
I0502 11:14:18.710587 26473 solver.cpp:261]     Train net output #0: loss = 0.353972 (* 1 = 0.353972 loss)
I0502 11:14:18.710597 26473 sgd_solver.cpp:106] Iteration 27400, lr = 6.4e-05
I0502 11:14:19.658676 26473 solver.cpp:362] Iteration 27500, Testing net (#0)
I0502 11:14:19.658702 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:19.784509 26473 solver.cpp:429]     Test net output #0: loss = 0.696801 (* 1 = 0.696801 loss)
I0502 11:14:19.787423 26473 solver.cpp:242] Iteration 27500 (92.4437 iter/s, 1.08174s/100 iter), loss = 1.16279
I0502 11:14:19.787444 26473 solver.cpp:261]     Train net output #0: loss = 1.16279 (* 1 = 1.16279 loss)
I0502 11:14:19.787452 26473 sgd_solver.cpp:106] Iteration 27500, lr = 6.4e-05
I0502 11:14:19.789124 26473 solver.cpp:362] Iteration 27500, Testing net (#0)
I0502 11:14:19.789136 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:19.921638 26473 solver.cpp:429]     Test net output #0: accuracy = 0.8915
I0502 11:14:19.921659 26473 solver.cpp:429]     Test net output #1: loss = 0.256238 (* 1 = 0.256238 loss)
I0502 11:14:19.924618 26473 solver.cpp:242] Iteration 27500 (82.3716 iter/s, 1.21401s/100 iter), loss = 0.466126
I0502 11:14:19.924639 26473 solver.cpp:261]     Train net output #0: loss = 0.466126 (* 1 = 0.466126 loss)
I0502 11:14:19.924648 26473 sgd_solver.cpp:106] Iteration 27500, lr = 6.4e-05
I0502 11:14:20.897436 26473 solver.cpp:242] Iteration 27600 (90.0926 iter/s, 1.10997s/100 iter), loss = 0.669143
I0502 11:14:20.897470 26473 solver.cpp:261]     Train net output #0: loss = 0.669143 (* 1 = 0.669143 loss)
I0502 11:14:20.897478 26473 sgd_solver.cpp:106] Iteration 27600, lr = 6.4e-05
I0502 11:14:20.902277 26473 solver.cpp:242] Iteration 27600 (102.289 iter/s, 0.97762s/100 iter), loss = 0.105394
I0502 11:14:20.902300 26473 solver.cpp:261]     Train net output #0: loss = 0.105394 (* 1 = 0.105394 loss)
I0502 11:14:20.902308 26473 sgd_solver.cpp:106] Iteration 27600, lr = 6.4e-05
I0502 11:14:21.855198 26473 solver.cpp:242] Iteration 27700 (104.416 iter/s, 0.957706s/100 iter), loss = 1.48676
I0502 11:14:21.855242 26473 solver.cpp:261]     Train net output #0: loss = 1.48676 (* 1 = 1.48676 loss)
I0502 11:14:21.855250 26473 sgd_solver.cpp:106] Iteration 27700, lr = 6.4e-05
I0502 11:14:21.860216 26473 solver.cpp:242] Iteration 27700 (104.395 iter/s, 0.957898s/100 iter), loss = 0.153429
I0502 11:14:21.860240 26473 solver.cpp:261]     Train net output #0: loss = 0.153429 (* 1 = 0.153429 loss)
I0502 11:14:21.860249 26473 sgd_solver.cpp:106] Iteration 27700, lr = 6.4e-05
I0502 11:14:22.812075 26473 solver.cpp:242] Iteration 27800 (104.514 iter/s, 0.956811s/100 iter), loss = 1.88505
I0502 11:14:22.812115 26473 solver.cpp:261]     Train net output #0: loss = 1.88505 (* 1 = 1.88505 loss)
I0502 11:14:22.812124 26473 sgd_solver.cpp:106] Iteration 27800, lr = 6.4e-05
I0502 11:14:22.816947 26473 solver.cpp:242] Iteration 27800 (104.527 iter/s, 0.956689s/100 iter), loss = 0.101084
I0502 11:14:22.816972 26473 solver.cpp:261]     Train net output #0: loss = 0.101084 (* 1 = 0.101084 loss)
I0502 11:14:22.816979 26473 sgd_solver.cpp:106] Iteration 27800, lr = 6.4e-05
I0502 11:14:23.767688 26473 solver.cpp:242] Iteration 27900 (104.652 iter/s, 0.95555s/100 iter), loss = 0.234074
I0502 11:14:23.767727 26473 solver.cpp:261]     Train net output #0: loss = 0.234074 (* 1 = 0.234074 loss)
I0502 11:14:23.767827 26473 sgd_solver.cpp:106] Iteration 27900, lr = 6.4e-05
I0502 11:14:23.775899 26473 solver.cpp:242] Iteration 27900 (104.286 iter/s, 0.958902s/100 iter), loss = 0.218617
I0502 11:14:23.775960 26473 solver.cpp:261]     Train net output #0: loss = 0.218617 (* 1 = 0.218617 loss)
I0502 11:14:23.775982 26473 sgd_solver.cpp:106] Iteration 27900, lr = 6.4e-05
I0502 11:14:24.776826 26473 solver.cpp:362] Iteration 28000, Testing net (#0)
I0502 11:14:24.776856 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:24.902433 26473 solver.cpp:429]     Test net output #0: loss = 0.601022 (* 1 = 0.601022 loss)
I0502 11:14:24.905323 26473 solver.cpp:242] Iteration 28000 (87.9062 iter/s, 1.13758s/100 iter), loss = 0.184935
I0502 11:14:24.905356 26473 solver.cpp:261]     Train net output #0: loss = 0.184935 (* 1 = 0.184935 loss)
I0502 11:14:24.905365 26473 sgd_solver.cpp:106] Iteration 28000, lr = 6.4e-05
I0502 11:14:24.907022 26473 solver.cpp:362] Iteration 28000, Testing net (#0)
I0502 11:14:24.907037 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:25.038326 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9085
I0502 11:14:25.038348 26473 solver.cpp:429]     Test net output #1: loss = 0.208489 (* 1 = 0.208489 loss)
I0502 11:14:25.041276 26473 solver.cpp:242] Iteration 28000 (79.0326 iter/s, 1.2653s/100 iter), loss = 0.176711
I0502 11:14:25.041296 26473 solver.cpp:261]     Train net output #0: loss = 0.176711 (* 1 = 0.176711 loss)
I0502 11:14:25.041306 26473 sgd_solver.cpp:106] Iteration 28000, lr = 6.4e-05
I0502 11:14:25.993165 26473 solver.cpp:242] Iteration 28100 (91.93 iter/s, 1.08778s/100 iter), loss = 0.639587
I0502 11:14:25.993206 26473 solver.cpp:261]     Train net output #0: loss = 0.639587 (* 1 = 0.639587 loss)
I0502 11:14:25.993216 26473 sgd_solver.cpp:106] Iteration 28100, lr = 6.4e-05
I0502 11:14:25.997995 26473 solver.cpp:242] Iteration 28100 (104.528 iter/s, 0.95668s/100 iter), loss = 0.150441
I0502 11:14:25.998018 26473 solver.cpp:261]     Train net output #0: loss = 0.150441 (* 1 = 0.150441 loss)
I0502 11:14:25.998028 26473 sgd_solver.cpp:106] Iteration 28100, lr = 6.4e-05
I0502 11:14:26.963145 26473 solver.cpp:242] Iteration 28200 (103.101 iter/s, 0.969918s/100 iter), loss = 2.10092
I0502 11:14:26.963181 26473 solver.cpp:261]     Train net output #0: loss = 2.10092 (* 1 = 2.10092 loss)
I0502 11:14:26.963189 26473 sgd_solver.cpp:106] Iteration 28200, lr = 6.4e-05
I0502 11:14:26.968075 26473 solver.cpp:242] Iteration 28200 (103.089 iter/s, 0.970038s/100 iter), loss = 0.266658
I0502 11:14:26.968097 26473 solver.cpp:261]     Train net output #0: loss = 0.266658 (* 1 = 0.266658 loss)
I0502 11:14:26.968106 26473 sgd_solver.cpp:106] Iteration 28200, lr = 6.4e-05
I0502 11:14:27.920398 26473 solver.cpp:242] Iteration 28300 (104.472 iter/s, 0.957195s/100 iter), loss = 0.906587
I0502 11:14:27.920439 26473 solver.cpp:261]     Train net output #0: loss = 0.906587 (* 1 = 0.906587 loss)
I0502 11:14:27.920447 26473 sgd_solver.cpp:106] Iteration 28300, lr = 6.4e-05
I0502 11:14:27.925268 26473 solver.cpp:242] Iteration 28300 (104.477 iter/s, 0.957152s/100 iter), loss = 0.3194
I0502 11:14:27.925292 26473 solver.cpp:261]     Train net output #0: loss = 0.3194 (* 1 = 0.3194 loss)
I0502 11:14:27.925300 26473 sgd_solver.cpp:106] Iteration 28300, lr = 6.4e-05
I0502 11:14:28.912503 26473 solver.cpp:242] Iteration 28400 (100.802 iter/s, 0.992042s/100 iter), loss = 2.05784
I0502 11:14:28.912572 26473 solver.cpp:261]     Train net output #0: loss = 2.05784 (* 1 = 2.05784 loss)
I0502 11:14:28.912588 26473 sgd_solver.cpp:106] Iteration 28400, lr = 6.4e-05
I0502 11:14:28.917554 26473 solver.cpp:242] Iteration 28400 (100.782 iter/s, 0.992244s/100 iter), loss = 0.379402
I0502 11:14:28.917577 26473 solver.cpp:261]     Train net output #0: loss = 0.379402 (* 1 = 0.379402 loss)
I0502 11:14:28.917585 26473 sgd_solver.cpp:106] Iteration 28400, lr = 6.4e-05
I0502 11:14:29.875885 26473 solver.cpp:362] Iteration 28500, Testing net (#0)
I0502 11:14:29.875910 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:30.001140 26473 solver.cpp:429]     Test net output #0: loss = 0.719871 (* 1 = 0.719871 loss)
I0502 11:14:30.004053 26473 solver.cpp:242] Iteration 28500 (91.6201 iter/s, 1.09146s/100 iter), loss = 0.663872
I0502 11:14:30.004073 26473 solver.cpp:261]     Train net output #0: loss = 0.663872 (* 1 = 0.663872 loss)
I0502 11:14:30.004082 26473 sgd_solver.cpp:106] Iteration 28500, lr = 6.4e-05
I0502 11:14:30.005856 26473 solver.cpp:362] Iteration 28500, Testing net (#0)
I0502 11:14:30.005870 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:30.137748 26473 solver.cpp:429]     Test net output #0: accuracy = 0.878
I0502 11:14:30.137773 26473 solver.cpp:429]     Test net output #1: loss = 0.279752 (* 1 = 0.279752 loss)
I0502 11:14:30.140732 26473 solver.cpp:242] Iteration 28500 (81.7573 iter/s, 1.22313s/100 iter), loss = 0.469759
I0502 11:14:30.140753 26473 solver.cpp:261]     Train net output #0: loss = 0.469759 (* 1 = 0.469759 loss)
I0502 11:14:30.140761 26473 sgd_solver.cpp:106] Iteration 28500, lr = 6.4e-05
I0502 11:14:31.094595 26473 solver.cpp:242] Iteration 28600 (91.7014 iter/s, 1.0905s/100 iter), loss = 0.554548
I0502 11:14:31.094638 26473 solver.cpp:261]     Train net output #0: loss = 0.554548 (* 1 = 0.554548 loss)
I0502 11:14:31.094647 26473 sgd_solver.cpp:106] Iteration 28600, lr = 6.4e-05
I0502 11:14:31.099463 26473 solver.cpp:242] Iteration 28600 (104.309 iter/s, 0.958692s/100 iter), loss = 0.248891
I0502 11:14:31.099488 26473 solver.cpp:261]     Train net output #0: loss = 0.248891 (* 1 = 0.248891 loss)
I0502 11:14:31.099495 26473 sgd_solver.cpp:106] Iteration 28600, lr = 6.4e-05
I0502 11:14:32.054677 26473 solver.cpp:242] Iteration 28700 (104.165 iter/s, 0.960015s/100 iter), loss = 1.00193
I0502 11:14:32.054716 26473 solver.cpp:261]     Train net output #0: loss = 1.00193 (* 1 = 1.00193 loss)
I0502 11:14:32.054725 26473 sgd_solver.cpp:106] Iteration 28700, lr = 6.4e-05
I0502 11:14:32.059628 26473 solver.cpp:242] Iteration 28700 (104.154 iter/s, 0.960115s/100 iter), loss = 0.228586
I0502 11:14:32.059653 26473 solver.cpp:261]     Train net output #0: loss = 0.228586 (* 1 = 0.228586 loss)
I0502 11:14:32.059660 26473 sgd_solver.cpp:106] Iteration 28700, lr = 6.4e-05
I0502 11:14:33.013959 26473 solver.cpp:242] Iteration 28800 (104.251 iter/s, 0.959221s/100 iter), loss = 0.23396
I0502 11:14:33.014000 26473 solver.cpp:261]     Train net output #0: loss = 0.23396 (* 1 = 0.23396 loss)
I0502 11:14:33.014009 26473 sgd_solver.cpp:106] Iteration 28800, lr = 6.4e-05
I0502 11:14:33.018915 26473 solver.cpp:242] Iteration 28800 (104.249 iter/s, 0.959245s/100 iter), loss = 0.0941232
I0502 11:14:33.018939 26473 solver.cpp:261]     Train net output #0: loss = 0.0941232 (* 1 = 0.0941232 loss)
I0502 11:14:33.018947 26473 sgd_solver.cpp:106] Iteration 28800, lr = 6.4e-05
I0502 11:14:33.973101 26473 solver.cpp:242] Iteration 28900 (104.267 iter/s, 0.959077s/100 iter), loss = 0.382873
I0502 11:14:33.973155 26473 solver.cpp:261]     Train net output #0: loss = 0.382873 (* 1 = 0.382873 loss)
I0502 11:14:33.973163 26473 sgd_solver.cpp:106] Iteration 28900, lr = 6.4e-05
I0502 11:14:33.978196 26473 solver.cpp:242] Iteration 28900 (104.25 iter/s, 0.959233s/100 iter), loss = 0.277554
I0502 11:14:33.978243 26473 solver.cpp:261]     Train net output #0: loss = 0.277554 (* 1 = 0.277554 loss)
I0502 11:14:33.978253 26473 sgd_solver.cpp:106] Iteration 28900, lr = 6.4e-05
I0502 11:14:35.049590 26473 solver.cpp:362] Iteration 29000, Testing net (#0)
I0502 11:14:35.049634 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:35.212151 26473 solver.cpp:429]     Test net output #0: loss = 0.637356 (* 1 = 0.637356 loss)
I0502 11:14:35.215417 26473 solver.cpp:242] Iteration 29000 (80.4997 iter/s, 1.24224s/100 iter), loss = 0.353248
I0502 11:14:35.215453 26473 solver.cpp:261]     Train net output #0: loss = 0.353248 (* 1 = 0.353248 loss)
I0502 11:14:35.215472 26473 sgd_solver.cpp:106] Iteration 29000, lr = 6.4e-05
I0502 11:14:35.218710 26473 solver.cpp:362] Iteration 29000, Testing net (#0)
I0502 11:14:35.218732 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:35.377249 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9095
I0502 11:14:35.377312 26473 solver.cpp:429]     Test net output #1: loss = 0.231649 (* 1 = 0.231649 loss)
I0502 11:14:35.380625 26473 solver.cpp:242] Iteration 29000 (71.3086 iter/s, 1.40235s/100 iter), loss = 0.111545
I0502 11:14:35.380666 26473 solver.cpp:261]     Train net output #0: loss = 0.111545 (* 1 = 0.111545 loss)
I0502 11:14:35.380686 26473 sgd_solver.cpp:106] Iteration 29000, lr = 6.4e-05
I0502 11:14:36.640807 26473 solver.cpp:242] Iteration 29100 (70.1595 iter/s, 1.42532s/100 iter), loss = 0.478992
I0502 11:14:36.640868 26473 solver.cpp:261]     Train net output #0: loss = 0.478992 (* 1 = 0.478992 loss)
I0502 11:14:36.640889 26473 sgd_solver.cpp:106] Iteration 29100, lr = 6.4e-05
I0502 11:14:36.645952 26473 solver.cpp:242] Iteration 29100 (79.0351 iter/s, 1.26526s/100 iter), loss = 0.10514
I0502 11:14:36.646000 26473 solver.cpp:261]     Train net output #0: loss = 0.10514 (* 1 = 0.10514 loss)
I0502 11:14:36.646011 26473 sgd_solver.cpp:106] Iteration 29100, lr = 6.4e-05
I0502 11:14:37.603772 26473 solver.cpp:242] Iteration 29200 (103.855 iter/s, 0.962881s/100 iter), loss = 0.712859
I0502 11:14:37.603816 26473 solver.cpp:261]     Train net output #0: loss = 0.712859 (* 1 = 0.712859 loss)
I0502 11:14:37.603824 26473 sgd_solver.cpp:106] Iteration 29200, lr = 6.4e-05
I0502 11:14:37.608639 26473 solver.cpp:242] Iteration 29200 (103.883 iter/s, 0.962623s/100 iter), loss = 0.133364
I0502 11:14:37.608664 26473 solver.cpp:261]     Train net output #0: loss = 0.133364 (* 1 = 0.133364 loss)
I0502 11:14:37.608672 26473 sgd_solver.cpp:106] Iteration 29200, lr = 6.4e-05
I0502 11:14:38.557430 26473 solver.cpp:242] Iteration 29300 (104.866 iter/s, 0.953595s/100 iter), loss = 0.51936
I0502 11:14:38.557466 26473 solver.cpp:261]     Train net output #0: loss = 0.51936 (* 1 = 0.51936 loss)
I0502 11:14:38.557474 26473 sgd_solver.cpp:106] Iteration 29300, lr = 6.4e-05
I0502 11:14:38.562343 26473 solver.cpp:242] Iteration 29300 (104.859 iter/s, 0.953661s/100 iter), loss = 0.193665
I0502 11:14:38.562367 26473 solver.cpp:261]     Train net output #0: loss = 0.193665 (* 1 = 0.193665 loss)
I0502 11:14:38.562376 26473 sgd_solver.cpp:106] Iteration 29300, lr = 6.4e-05
I0502 11:14:39.513082 26473 solver.cpp:242] Iteration 29400 (104.647 iter/s, 0.955597s/100 iter), loss = 0.29391
I0502 11:14:39.513118 26473 solver.cpp:261]     Train net output #0: loss = 0.29391 (* 1 = 0.29391 loss)
I0502 11:14:39.513126 26473 sgd_solver.cpp:106] Iteration 29400, lr = 6.4e-05
I0502 11:14:39.517916 26473 solver.cpp:242] Iteration 29400 (104.654 iter/s, 0.95553s/100 iter), loss = 0.46285
I0502 11:14:39.517940 26473 solver.cpp:261]     Train net output #0: loss = 0.46285 (* 1 = 0.46285 loss)
I0502 11:14:39.517947 26473 sgd_solver.cpp:106] Iteration 29400, lr = 6.4e-05
I0502 11:14:40.463819 26473 solver.cpp:362] Iteration 29500, Testing net (#0)
I0502 11:14:40.463840 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:40.589413 26473 solver.cpp:429]     Test net output #0: loss = 0.67349 (* 1 = 0.67349 loss)
I0502 11:14:40.592329 26473 solver.cpp:242] Iteration 29500 (92.6619 iter/s, 1.07919s/100 iter), loss = 0.305316
I0502 11:14:40.592350 26473 solver.cpp:261]     Train net output #0: loss = 0.305316 (* 1 = 0.305316 loss)
I0502 11:14:40.592357 26473 sgd_solver.cpp:106] Iteration 29500, lr = 6.4e-05
I0502 11:14:40.594038 26473 solver.cpp:362] Iteration 29500, Testing net (#0)
I0502 11:14:40.594053 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:40.726243 26473 solver.cpp:429]     Test net output #0: accuracy = 0.884
I0502 11:14:40.726269 26473 solver.cpp:429]     Test net output #1: loss = 0.248289 (* 1 = 0.248289 loss)
I0502 11:14:40.729231 26473 solver.cpp:242] Iteration 29500 (82.558 iter/s, 1.21127s/100 iter), loss = 0.445272
I0502 11:14:40.729252 26473 solver.cpp:261]     Train net output #0: loss = 0.445272 (* 1 = 0.445272 loss)
I0502 11:14:40.729260 26473 sgd_solver.cpp:106] Iteration 29500, lr = 6.4e-05
I0502 11:14:41.678763 26473 solver.cpp:242] Iteration 29600 (92.048 iter/s, 1.08639s/100 iter), loss = 0.217383
I0502 11:14:41.678802 26473 solver.cpp:261]     Train net output #0: loss = 0.217383 (* 1 = 0.217383 loss)
I0502 11:14:41.678810 26473 sgd_solver.cpp:106] Iteration 29600, lr = 6.4e-05
I0502 11:14:41.683635 26473 solver.cpp:242] Iteration 29600 (104.782 iter/s, 0.954365s/100 iter), loss = 0.112442
I0502 11:14:41.683658 26473 solver.cpp:261]     Train net output #0: loss = 0.112442 (* 1 = 0.112442 loss)
I0502 11:14:41.683667 26473 sgd_solver.cpp:106] Iteration 29600, lr = 6.4e-05
I0502 11:14:42.632520 26473 solver.cpp:242] Iteration 29700 (104.855 iter/s, 0.953697s/100 iter), loss = 0.750016
I0502 11:14:42.632570 26473 solver.cpp:261]     Train net output #0: loss = 0.750016 (* 1 = 0.750016 loss)
I0502 11:14:42.632580 26473 sgd_solver.cpp:106] Iteration 29700, lr = 6.4e-05
I0502 11:14:42.637441 26473 solver.cpp:242] Iteration 29700 (104.848 iter/s, 0.953763s/100 iter), loss = 0.351923
I0502 11:14:42.637465 26473 solver.cpp:261]     Train net output #0: loss = 0.351923 (* 1 = 0.351923 loss)
I0502 11:14:42.637473 26473 sgd_solver.cpp:106] Iteration 29700, lr = 6.4e-05
I0502 11:14:43.586479 26473 solver.cpp:242] Iteration 29800 (104.834 iter/s, 0.953889s/100 iter), loss = 0.71446
I0502 11:14:43.586524 26473 solver.cpp:261]     Train net output #0: loss = 0.71446 (* 1 = 0.71446 loss)
I0502 11:14:43.586532 26473 sgd_solver.cpp:106] Iteration 29800, lr = 6.4e-05
I0502 11:14:43.591431 26473 solver.cpp:242] Iteration 29800 (104.827 iter/s, 0.953948s/100 iter), loss = 0.167275
I0502 11:14:43.591455 26473 solver.cpp:261]     Train net output #0: loss = 0.167275 (* 1 = 0.167275 loss)
I0502 11:14:43.591464 26473 sgd_solver.cpp:106] Iteration 29800, lr = 6.4e-05
I0502 11:14:44.540086 26473 solver.cpp:242] Iteration 29900 (104.872 iter/s, 0.953541s/100 iter), loss = 0.670033
I0502 11:14:44.540127 26473 solver.cpp:261]     Train net output #0: loss = 0.670033 (* 1 = 0.670033 loss)
I0502 11:14:44.540136 26473 sgd_solver.cpp:106] Iteration 29900, lr = 6.4e-05
I0502 11:14:44.544965 26473 solver.cpp:242] Iteration 29900 (104.878 iter/s, 0.95349s/100 iter), loss = 0.327547
I0502 11:14:44.544987 26473 solver.cpp:261]     Train net output #0: loss = 0.327547 (* 1 = 0.327547 loss)
I0502 11:14:44.544996 26473 sgd_solver.cpp:106] Iteration 29900, lr = 6.4e-05
I0502 11:14:45.492813 26473 solver.cpp:362] Iteration 30000, Testing net (#0)
I0502 11:14:45.492846 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:45.618059 26473 solver.cpp:429]     Test net output #0: loss = 0.669002 (* 1 = 0.669002 loss)
I0502 11:14:45.620964 26473 solver.cpp:242] Iteration 30000 (92.5226 iter/s, 1.08082s/100 iter), loss = 0.247696
I0502 11:14:45.620983 26473 solver.cpp:261]     Train net output #0: loss = 0.247696 (* 1 = 0.247696 loss)
I0502 11:14:45.620993 26473 sgd_solver.cpp:106] Iteration 30000, lr = 5.12e-05
I0502 11:14:45.622658 26473 solver.cpp:362] Iteration 30000, Testing net (#0)
I0502 11:14:45.622670 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:45.754191 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9165
I0502 11:14:45.754211 26473 solver.cpp:429]     Test net output #1: loss = 0.23432 (* 1 = 0.23432 loss)
I0502 11:14:45.757166 26473 solver.cpp:242] Iteration 30000 (82.4976 iter/s, 1.21216s/100 iter), loss = 0.212709
I0502 11:14:45.757187 26473 solver.cpp:261]     Train net output #0: loss = 0.212709 (* 1 = 0.212709 loss)
I0502 11:14:45.757196 26473 sgd_solver.cpp:106] Iteration 30000, lr = 5.12e-05
I0502 11:14:46.705754 26473 solver.cpp:242] Iteration 30100 (92.1874 iter/s, 1.08475s/100 iter), loss = 0.663842
I0502 11:14:46.705785 26473 solver.cpp:261]     Train net output #0: loss = 0.663842 (* 1 = 0.663842 loss)
I0502 11:14:46.705793 26473 sgd_solver.cpp:106] Iteration 30100, lr = 5.12e-05
I0502 11:14:46.710584 26473 solver.cpp:242] Iteration 30100 (104.89 iter/s, 0.953379s/100 iter), loss = 0.352593
I0502 11:14:46.710608 26473 solver.cpp:261]     Train net output #0: loss = 0.352593 (* 1 = 0.352593 loss)
I0502 11:14:46.710616 26473 sgd_solver.cpp:106] Iteration 30100, lr = 5.12e-05
I0502 11:14:47.659442 26473 solver.cpp:242] Iteration 30200 (104.862 iter/s, 0.953637s/100 iter), loss = 0.158241
I0502 11:14:47.659476 26473 solver.cpp:261]     Train net output #0: loss = 0.158241 (* 1 = 0.158241 loss)
I0502 11:14:47.659484 26473 sgd_solver.cpp:106] Iteration 30200, lr = 5.12e-05
I0502 11:14:47.664264 26473 solver.cpp:242] Iteration 30200 (104.861 iter/s, 0.953639s/100 iter), loss = 0.149991
I0502 11:14:47.664288 26473 solver.cpp:261]     Train net output #0: loss = 0.149991 (* 1 = 0.149991 loss)
I0502 11:14:47.664295 26473 sgd_solver.cpp:106] Iteration 30200, lr = 5.12e-05
I0502 11:14:48.612468 26473 solver.cpp:242] Iteration 30300 (104.935 iter/s, 0.952969s/100 iter), loss = 0.332172
I0502 11:14:48.612509 26473 solver.cpp:261]     Train net output #0: loss = 0.332172 (* 1 = 0.332172 loss)
I0502 11:14:48.612517 26473 sgd_solver.cpp:106] Iteration 30300, lr = 5.12e-05
I0502 11:14:48.617432 26473 solver.cpp:242] Iteration 30300 (104.918 iter/s, 0.953128s/100 iter), loss = 0.185156
I0502 11:14:48.617455 26473 solver.cpp:261]     Train net output #0: loss = 0.185156 (* 1 = 0.185156 loss)
I0502 11:14:48.617465 26473 sgd_solver.cpp:106] Iteration 30300, lr = 5.12e-05
I0502 11:14:49.565876 26473 solver.cpp:242] Iteration 30400 (104.894 iter/s, 0.953346s/100 iter), loss = 1.08133
I0502 11:14:49.565923 26473 solver.cpp:261]     Train net output #0: loss = 1.08133 (* 1 = 1.08133 loss)
I0502 11:14:49.566052 26473 sgd_solver.cpp:106] Iteration 30400, lr = 5.12e-05
I0502 11:14:49.570919 26473 solver.cpp:242] Iteration 30400 (104.883 iter/s, 0.953445s/100 iter), loss = 0.54322
I0502 11:14:49.570941 26473 solver.cpp:261]     Train net output #0: loss = 0.54322 (* 1 = 0.54322 loss)
I0502 11:14:49.570950 26473 sgd_solver.cpp:106] Iteration 30400, lr = 5.12e-05
I0502 11:14:50.516258 26473 solver.cpp:362] Iteration 30500, Testing net (#0)
I0502 11:14:50.516285 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:50.641222 26473 solver.cpp:429]     Test net output #0: loss = 0.589084 (* 1 = 0.589084 loss)
I0502 11:14:50.644088 26473 solver.cpp:242] Iteration 30500 (92.7515 iter/s, 1.07815s/100 iter), loss = 0.282106
I0502 11:14:50.644109 26473 solver.cpp:261]     Train net output #0: loss = 0.282106 (* 1 = 0.282106 loss)
I0502 11:14:50.644117 26473 sgd_solver.cpp:106] Iteration 30500, lr = 5.12e-05
I0502 11:14:50.645768 26473 solver.cpp:362] Iteration 30500, Testing net (#0)
I0502 11:14:50.645781 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:50.778250 26473 solver.cpp:429]     Test net output #0: accuracy = 0.905
I0502 11:14:50.778272 26473 solver.cpp:429]     Test net output #1: loss = 0.22631 (* 1 = 0.22631 loss)
I0502 11:14:50.781234 26473 solver.cpp:242] Iteration 30500 (82.6262 iter/s, 1.21027s/100 iter), loss = 0.386962
I0502 11:14:50.781255 26473 solver.cpp:261]     Train net output #0: loss = 0.386962 (* 1 = 0.386962 loss)
I0502 11:14:50.781262 26473 sgd_solver.cpp:106] Iteration 30500, lr = 5.12e-05
I0502 11:14:51.732657 26473 solver.cpp:242] Iteration 30600 (91.8675 iter/s, 1.08852s/100 iter), loss = 0.279928
I0502 11:14:51.732697 26473 solver.cpp:261]     Train net output #0: loss = 0.279928 (* 1 = 0.279928 loss)
I0502 11:14:51.732707 26473 sgd_solver.cpp:106] Iteration 30600, lr = 5.12e-05
I0502 11:14:51.737526 26473 solver.cpp:242] Iteration 30600 (104.575 iter/s, 0.956254s/100 iter), loss = 0.22968
I0502 11:14:51.737550 26473 solver.cpp:261]     Train net output #0: loss = 0.22968 (* 1 = 0.22968 loss)
I0502 11:14:51.737558 26473 sgd_solver.cpp:106] Iteration 30600, lr = 5.12e-05
I0502 11:14:52.691666 26473 solver.cpp:242] Iteration 30700 (104.281 iter/s, 0.958947s/100 iter), loss = 0.268847
I0502 11:14:52.691709 26473 solver.cpp:261]     Train net output #0: loss = 0.268847 (* 1 = 0.268847 loss)
I0502 11:14:52.691718 26473 sgd_solver.cpp:106] Iteration 30700, lr = 5.12e-05
I0502 11:14:52.696542 26473 solver.cpp:242] Iteration 30700 (104.278 iter/s, 0.958973s/100 iter), loss = 0.161202
I0502 11:14:52.696568 26473 solver.cpp:261]     Train net output #0: loss = 0.161202 (* 1 = 0.161202 loss)
I0502 11:14:52.696578 26473 sgd_solver.cpp:106] Iteration 30700, lr = 5.12e-05
I0502 11:14:53.650179 26473 solver.cpp:242] Iteration 30800 (104.335 iter/s, 0.95845s/100 iter), loss = 1.82936
I0502 11:14:53.650219 26473 solver.cpp:261]     Train net output #0: loss = 1.82936 (* 1 = 1.82936 loss)
I0502 11:14:53.650228 26473 sgd_solver.cpp:106] Iteration 30800, lr = 5.12e-05
I0502 11:14:53.655092 26473 solver.cpp:242] Iteration 30800 (104.33 iter/s, 0.958499s/100 iter), loss = 0.257774
I0502 11:14:53.655115 26473 solver.cpp:261]     Train net output #0: loss = 0.257774 (* 1 = 0.257774 loss)
I0502 11:14:53.655133 26473 sgd_solver.cpp:106] Iteration 30800, lr = 5.12e-05
I0502 11:14:54.610688 26473 solver.cpp:242] Iteration 30900 (104.118 iter/s, 0.960446s/100 iter), loss = 0.504453
I0502 11:14:54.610743 26473 solver.cpp:261]     Train net output #0: loss = 0.504453 (* 1 = 0.504453 loss)
I0502 11:14:54.610754 26473 sgd_solver.cpp:106] Iteration 30900, lr = 5.12e-05
I0502 11:14:54.615618 26473 solver.cpp:242] Iteration 30900 (104.114 iter/s, 0.960483s/100 iter), loss = 0.13314
I0502 11:14:54.615641 26473 solver.cpp:261]     Train net output #0: loss = 0.13314 (* 1 = 0.13314 loss)
I0502 11:14:54.615649 26473 sgd_solver.cpp:106] Iteration 30900, lr = 5.12e-05
I0502 11:14:55.563699 26473 solver.cpp:362] Iteration 31000, Testing net (#0)
I0502 11:14:55.563730 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:55.689855 26473 solver.cpp:429]     Test net output #0: loss = 0.783507 (* 1 = 0.783507 loss)
I0502 11:14:55.692795 26473 solver.cpp:242] Iteration 31000 (92.4186 iter/s, 1.08203s/100 iter), loss = 0.635157
I0502 11:14:55.692816 26473 solver.cpp:261]     Train net output #0: loss = 0.635157 (* 1 = 0.635157 loss)
I0502 11:14:55.692824 26473 sgd_solver.cpp:106] Iteration 31000, lr = 5.12e-05
I0502 11:14:55.694485 26473 solver.cpp:362] Iteration 31000, Testing net (#0)
I0502 11:14:55.694497 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:14:55.827224 26473 solver.cpp:429]     Test net output #0: accuracy = 0.898
I0502 11:14:55.827246 26473 solver.cpp:429]     Test net output #1: loss = 0.225274 (* 1 = 0.225274 loss)
I0502 11:14:55.830211 26473 solver.cpp:242] Iteration 31000 (82.3352 iter/s, 1.21455s/100 iter), loss = 0.172334
I0502 11:14:55.830231 26473 solver.cpp:261]     Train net output #0: loss = 0.172334 (* 1 = 0.172334 loss)
I0502 11:14:55.830240 26473 sgd_solver.cpp:106] Iteration 31000, lr = 5.12e-05
I0502 11:14:56.779320 26473 solver.cpp:242] Iteration 31100 (92.0402 iter/s, 1.08648s/100 iter), loss = 1.7299
I0502 11:14:56.779359 26473 solver.cpp:261]     Train net output #0: loss = 1.7299 (* 1 = 1.7299 loss)
I0502 11:14:56.779368 26473 sgd_solver.cpp:106] Iteration 31100, lr = 5.12e-05
I0502 11:14:56.784157 26473 solver.cpp:242] Iteration 31100 (104.832 iter/s, 0.953907s/100 iter), loss = 0.408224
I0502 11:14:56.784179 26473 solver.cpp:261]     Train net output #0: loss = 0.408224 (* 1 = 0.408224 loss)
I0502 11:14:56.784188 26473 sgd_solver.cpp:106] Iteration 31100, lr = 5.12e-05
I0502 11:14:57.735286 26473 solver.cpp:242] Iteration 31200 (104.613 iter/s, 0.955905s/100 iter), loss = 0.11621
I0502 11:14:57.735327 26473 solver.cpp:261]     Train net output #0: loss = 0.11621 (* 1 = 0.11621 loss)
I0502 11:14:57.735335 26473 sgd_solver.cpp:106] Iteration 31200, lr = 5.12e-05
I0502 11:14:57.740149 26473 solver.cpp:242] Iteration 31200 (104.608 iter/s, 0.955951s/100 iter), loss = 0.222543
I0502 11:14:57.740171 26473 solver.cpp:261]     Train net output #0: loss = 0.222543 (* 1 = 0.222543 loss)
I0502 11:14:57.740180 26473 sgd_solver.cpp:106] Iteration 31200, lr = 5.12e-05
I0502 11:14:58.691495 26473 solver.cpp:242] Iteration 31300 (104.586 iter/s, 0.956147s/100 iter), loss = 0.371371
I0502 11:14:58.691530 26473 solver.cpp:261]     Train net output #0: loss = 0.371371 (* 1 = 0.371371 loss)
I0502 11:14:58.691540 26473 sgd_solver.cpp:106] Iteration 31300, lr = 5.12e-05
I0502 11:14:58.696444 26473 solver.cpp:242] Iteration 31300 (104.575 iter/s, 0.956253s/100 iter), loss = 0.12672
I0502 11:14:58.696467 26473 solver.cpp:261]     Train net output #0: loss = 0.12672 (* 1 = 0.12672 loss)
I0502 11:14:58.696475 26473 sgd_solver.cpp:106] Iteration 31300, lr = 5.12e-05
I0502 11:14:59.647615 26473 solver.cpp:242] Iteration 31400 (104.595 iter/s, 0.956065s/100 iter), loss = 0.511754
I0502 11:14:59.647662 26473 solver.cpp:261]     Train net output #0: loss = 0.511754 (* 1 = 0.511754 loss)
I0502 11:14:59.647672 26473 sgd_solver.cpp:106] Iteration 31400, lr = 5.12e-05
I0502 11:14:59.652618 26473 solver.cpp:242] Iteration 31400 (104.588 iter/s, 0.956132s/100 iter), loss = 0.233295
I0502 11:14:59.652649 26473 solver.cpp:261]     Train net output #0: loss = 0.233295 (* 1 = 0.233295 loss)
I0502 11:14:59.652658 26473 sgd_solver.cpp:106] Iteration 31400, lr = 5.12e-05
I0502 11:15:00.611307 26473 solver.cpp:362] Iteration 31500, Testing net (#0)
I0502 11:15:00.611328 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:00.737347 26473 solver.cpp:429]     Test net output #0: loss = 0.68611 (* 1 = 0.68611 loss)
I0502 11:15:00.740267 26473 solver.cpp:242] Iteration 31500 (91.5259 iter/s, 1.09259s/100 iter), loss = 0.805653
I0502 11:15:00.740288 26473 solver.cpp:261]     Train net output #0: loss = 0.805653 (* 1 = 0.805653 loss)
I0502 11:15:00.740295 26473 sgd_solver.cpp:106] Iteration 31500, lr = 5.12e-05
I0502 11:15:00.741952 26473 solver.cpp:362] Iteration 31500, Testing net (#0)
I0502 11:15:00.741966 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:00.874578 26473 solver.cpp:429]     Test net output #0: accuracy = 0.902
I0502 11:15:00.874599 26473 solver.cpp:429]     Test net output #1: loss = 0.222592 (* 1 = 0.222592 loss)
I0502 11:15:00.877588 26473 solver.cpp:242] Iteration 31500 (81.6382 iter/s, 1.22492s/100 iter), loss = 0.0860126
I0502 11:15:00.877609 26473 solver.cpp:261]     Train net output #0: loss = 0.0860126 (* 1 = 0.0860126 loss)
I0502 11:15:00.877617 26473 sgd_solver.cpp:106] Iteration 31500, lr = 5.12e-05
I0502 11:15:01.830050 26473 solver.cpp:242] Iteration 31600 (91.7651 iter/s, 1.08974s/100 iter), loss = 0.304494
I0502 11:15:01.830092 26473 solver.cpp:261]     Train net output #0: loss = 0.304494 (* 1 = 0.304494 loss)
I0502 11:15:01.830101 26473 sgd_solver.cpp:106] Iteration 31600, lr = 5.12e-05
I0502 11:15:01.834908 26473 solver.cpp:242] Iteration 31600 (104.463 iter/s, 0.957281s/100 iter), loss = 0.183495
I0502 11:15:01.834931 26473 solver.cpp:261]     Train net output #0: loss = 0.183495 (* 1 = 0.183495 loss)
I0502 11:15:01.834940 26473 sgd_solver.cpp:106] Iteration 31600, lr = 5.12e-05
I0502 11:15:02.785162 26473 solver.cpp:242] Iteration 31700 (104.707 iter/s, 0.955046s/100 iter), loss = 1.09022
I0502 11:15:02.785198 26473 solver.cpp:261]     Train net output #0: loss = 1.09022 (* 1 = 1.09022 loss)
I0502 11:15:02.785207 26473 sgd_solver.cpp:106] Iteration 31700, lr = 5.12e-05
I0502 11:15:02.790016 26473 solver.cpp:242] Iteration 31700 (104.705 iter/s, 0.955065s/100 iter), loss = 0.328023
I0502 11:15:02.790038 26473 solver.cpp:261]     Train net output #0: loss = 0.328023 (* 1 = 0.328023 loss)
I0502 11:15:02.790047 26473 sgd_solver.cpp:106] Iteration 31700, lr = 5.12e-05
I0502 11:15:03.739430 26473 solver.cpp:242] Iteration 31800 (104.798 iter/s, 0.954212s/100 iter), loss = 0.465694
I0502 11:15:03.739461 26473 solver.cpp:261]     Train net output #0: loss = 0.465694 (* 1 = 0.465694 loss)
I0502 11:15:03.739470 26473 sgd_solver.cpp:106] Iteration 31800, lr = 5.12e-05
I0502 11:15:03.744271 26473 solver.cpp:242] Iteration 31800 (104.798 iter/s, 0.954215s/100 iter), loss = 0.235671
I0502 11:15:03.744294 26473 solver.cpp:261]     Train net output #0: loss = 0.235671 (* 1 = 0.235671 loss)
I0502 11:15:03.744303 26473 sgd_solver.cpp:106] Iteration 31800, lr = 5.12e-05
I0502 11:15:04.694456 26473 solver.cpp:242] Iteration 31900 (104.715 iter/s, 0.954972s/100 iter), loss = 0.366166
I0502 11:15:04.694512 26473 solver.cpp:261]     Train net output #0: loss = 0.366166 (* 1 = 0.366166 loss)
I0502 11:15:04.694522 26473 sgd_solver.cpp:106] Iteration 31900, lr = 5.12e-05
I0502 11:15:04.699450 26473 solver.cpp:242] Iteration 31900 (104.697 iter/s, 0.955138s/100 iter), loss = 0.172542
I0502 11:15:04.699475 26473 solver.cpp:261]     Train net output #0: loss = 0.172542 (* 1 = 0.172542 loss)
I0502 11:15:04.699483 26473 sgd_solver.cpp:106] Iteration 31900, lr = 5.12e-05
I0502 11:15:05.646409 26473 solver.cpp:362] Iteration 32000, Testing net (#0)
I0502 11:15:05.646440 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:05.772083 26473 solver.cpp:429]     Test net output #0: loss = 0.501256 (* 1 = 0.501256 loss)
I0502 11:15:05.774984 26473 solver.cpp:242] Iteration 32000 (92.5538 iter/s, 1.08045s/100 iter), loss = 0.469864
I0502 11:15:05.775013 26473 solver.cpp:261]     Train net output #0: loss = 0.469864 (* 1 = 0.469864 loss)
I0502 11:15:05.775023 26473 sgd_solver.cpp:106] Iteration 32000, lr = 5.12e-05
I0502 11:15:05.776691 26473 solver.cpp:362] Iteration 32000, Testing net (#0)
I0502 11:15:05.776705 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:05.908681 26473 solver.cpp:429]     Test net output #0: accuracy = 0.906
I0502 11:15:05.908700 26473 solver.cpp:429]     Test net output #1: loss = 0.200981 (* 1 = 0.200981 loss)
I0502 11:15:05.911644 26473 solver.cpp:242] Iteration 32000 (82.4981 iter/s, 1.21215s/100 iter), loss = 0.159536
I0502 11:15:05.911664 26473 solver.cpp:261]     Train net output #0: loss = 0.159536 (* 1 = 0.159536 loss)
I0502 11:15:05.911674 26473 sgd_solver.cpp:106] Iteration 32000, lr = 5.12e-05
I0502 11:15:06.860910 26473 solver.cpp:242] Iteration 32100 (92.0918 iter/s, 1.08587s/100 iter), loss = 0.605803
I0502 11:15:06.860941 26473 solver.cpp:261]     Train net output #0: loss = 0.605803 (* 1 = 0.605803 loss)
I0502 11:15:06.860949 26473 sgd_solver.cpp:106] Iteration 32100, lr = 5.12e-05
I0502 11:15:06.865749 26473 solver.cpp:242] Iteration 32100 (104.814 iter/s, 0.954067s/100 iter), loss = 0.0929224
I0502 11:15:06.865773 26473 solver.cpp:261]     Train net output #0: loss = 0.0929224 (* 1 = 0.0929224 loss)
I0502 11:15:06.865782 26473 sgd_solver.cpp:106] Iteration 32100, lr = 5.12e-05
I0502 11:15:07.813608 26473 solver.cpp:242] Iteration 32200 (104.971 iter/s, 0.952645s/100 iter), loss = 0.276942
I0502 11:15:07.813652 26473 solver.cpp:261]     Train net output #0: loss = 0.276942 (* 1 = 0.276942 loss)
I0502 11:15:07.813661 26473 sgd_solver.cpp:106] Iteration 32200, lr = 5.12e-05
I0502 11:15:07.818461 26473 solver.cpp:242] Iteration 32200 (104.968 iter/s, 0.952669s/100 iter), loss = 0.144463
I0502 11:15:07.818485 26473 solver.cpp:261]     Train net output #0: loss = 0.144463 (* 1 = 0.144463 loss)
I0502 11:15:07.818492 26473 sgd_solver.cpp:106] Iteration 32200, lr = 5.12e-05
I0502 11:15:08.772866 26473 solver.cpp:242] Iteration 32300 (104.254 iter/s, 0.959192s/100 iter), loss = 0.551142
I0502 11:15:08.772905 26473 solver.cpp:261]     Train net output #0: loss = 0.551142 (* 1 = 0.551142 loss)
I0502 11:15:08.772914 26473 sgd_solver.cpp:106] Iteration 32300, lr = 5.12e-05
I0502 11:15:08.777763 26473 solver.cpp:242] Iteration 32300 (104.247 iter/s, 0.959261s/100 iter), loss = 0.149565
I0502 11:15:08.777786 26473 solver.cpp:261]     Train net output #0: loss = 0.149565 (* 1 = 0.149565 loss)
I0502 11:15:08.777794 26473 sgd_solver.cpp:106] Iteration 32300, lr = 5.12e-05
I0502 11:15:09.735741 26473 solver.cpp:242] Iteration 32400 (103.863 iter/s, 0.962804s/100 iter), loss = 0.820129
I0502 11:15:09.735797 26473 solver.cpp:261]     Train net output #0: loss = 0.820129 (* 1 = 0.820129 loss)
I0502 11:15:09.735806 26473 sgd_solver.cpp:106] Iteration 32400, lr = 5.12e-05
I0502 11:15:09.740797 26473 solver.cpp:242] Iteration 32400 (103.843 iter/s, 0.962993s/100 iter), loss = 0.144062
I0502 11:15:09.740821 26473 solver.cpp:261]     Train net output #0: loss = 0.144062 (* 1 = 0.144062 loss)
I0502 11:15:09.740829 26473 sgd_solver.cpp:106] Iteration 32400, lr = 5.12e-05
I0502 11:15:10.695767 26473 solver.cpp:362] Iteration 32500, Testing net (#0)
I0502 11:15:10.695793 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:10.822624 26473 solver.cpp:429]     Test net output #0: loss = 0.540587 (* 1 = 0.540587 loss)
I0502 11:15:10.825572 26473 solver.cpp:242] Iteration 32500 (91.7636 iter/s, 1.08976s/100 iter), loss = 0.73142
I0502 11:15:10.825592 26473 solver.cpp:261]     Train net output #0: loss = 0.73142 (* 1 = 0.73142 loss)
I0502 11:15:10.825601 26473 sgd_solver.cpp:106] Iteration 32500, lr = 5.12e-05
I0502 11:15:10.827253 26473 solver.cpp:362] Iteration 32500, Testing net (#0)
I0502 11:15:10.827266 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:10.960559 26473 solver.cpp:429]     Test net output #0: accuracy = 0.936
I0502 11:15:10.960589 26473 solver.cpp:429]     Test net output #1: loss = 0.168185 (* 1 = 0.168185 loss)
I0502 11:15:10.963577 26473 solver.cpp:242] Iteration 32500 (81.7839 iter/s, 1.22273s/100 iter), loss = 0.104102
I0502 11:15:10.963598 26473 solver.cpp:261]     Train net output #0: loss = 0.104102 (* 1 = 0.104102 loss)
I0502 11:15:10.963606 26473 sgd_solver.cpp:106] Iteration 32500, lr = 5.12e-05
I0502 11:15:11.916654 26473 solver.cpp:242] Iteration 32600 (91.6559 iter/s, 1.09104s/100 iter), loss = 0.414261
I0502 11:15:11.916697 26473 solver.cpp:261]     Train net output #0: loss = 0.414261 (* 1 = 0.414261 loss)
I0502 11:15:11.916707 26473 sgd_solver.cpp:106] Iteration 32600, lr = 5.12e-05
I0502 11:15:11.921495 26473 solver.cpp:242] Iteration 32600 (104.397 iter/s, 0.95788s/100 iter), loss = 0.221302
I0502 11:15:11.921519 26473 solver.cpp:261]     Train net output #0: loss = 0.221302 (* 1 = 0.221302 loss)
I0502 11:15:11.921526 26473 sgd_solver.cpp:106] Iteration 32600, lr = 5.12e-05
I0502 11:15:12.871851 26473 solver.cpp:242] Iteration 32700 (104.698 iter/s, 0.955132s/100 iter), loss = 0.35254
I0502 11:15:12.871892 26473 solver.cpp:261]     Train net output #0: loss = 0.35254 (* 1 = 0.35254 loss)
I0502 11:15:12.871901 26473 sgd_solver.cpp:106] Iteration 32700, lr = 5.12e-05
I0502 11:15:12.876715 26473 solver.cpp:242] Iteration 32700 (104.692 iter/s, 0.95518s/100 iter), loss = 0.135125
I0502 11:15:12.876739 26473 solver.cpp:261]     Train net output #0: loss = 0.135125 (* 1 = 0.135125 loss)
I0502 11:15:12.876746 26473 sgd_solver.cpp:106] Iteration 32700, lr = 5.12e-05
I0502 11:15:13.828416 26473 solver.cpp:242] Iteration 32800 (104.548 iter/s, 0.956501s/100 iter), loss = 0.352364
I0502 11:15:13.828457 26473 solver.cpp:261]     Train net output #0: loss = 0.352364 (* 1 = 0.352364 loss)
I0502 11:15:13.828466 26473 sgd_solver.cpp:106] Iteration 32800, lr = 5.12e-05
I0502 11:15:13.833278 26473 solver.cpp:242] Iteration 32800 (104.545 iter/s, 0.956522s/100 iter), loss = 0.13893
I0502 11:15:13.833300 26473 solver.cpp:261]     Train net output #0: loss = 0.13893 (* 1 = 0.13893 loss)
I0502 11:15:13.833309 26473 sgd_solver.cpp:106] Iteration 32800, lr = 5.12e-05
I0502 11:15:14.783428 26473 solver.cpp:242] Iteration 32900 (104.718 iter/s, 0.954949s/100 iter), loss = 0.431479
I0502 11:15:14.783483 26473 solver.cpp:261]     Train net output #0: loss = 0.431479 (* 1 = 0.431479 loss)
I0502 11:15:14.783493 26473 sgd_solver.cpp:106] Iteration 32900, lr = 5.12e-05
I0502 11:15:14.788417 26473 solver.cpp:242] Iteration 32900 (104.701 iter/s, 0.955098s/100 iter), loss = 0.115338
I0502 11:15:14.788442 26473 solver.cpp:261]     Train net output #0: loss = 0.115338 (* 1 = 0.115338 loss)
I0502 11:15:14.788450 26473 sgd_solver.cpp:106] Iteration 32900, lr = 5.12e-05
I0502 11:15:15.737493 26473 solver.cpp:362] Iteration 33000, Testing net (#0)
I0502 11:15:15.737522 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:15.863739 26473 solver.cpp:429]     Test net output #0: loss = 0.428086 (* 1 = 0.428086 loss)
I0502 11:15:15.866652 26473 solver.cpp:242] Iteration 33000 (92.3234 iter/s, 1.08315s/100 iter), loss = 0.756958
I0502 11:15:15.866672 26473 solver.cpp:261]     Train net output #0: loss = 0.756958 (* 1 = 0.756958 loss)
I0502 11:15:15.866680 26473 sgd_solver.cpp:106] Iteration 33000, lr = 5.12e-05
I0502 11:15:15.868332 26473 solver.cpp:362] Iteration 33000, Testing net (#0)
I0502 11:15:15.868345 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:16.000830 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9055
I0502 11:15:16.000851 26473 solver.cpp:429]     Test net output #1: loss = 0.207322 (* 1 = 0.207322 loss)
I0502 11:15:16.003828 26473 solver.cpp:242] Iteration 33000 (82.2799 iter/s, 1.21536s/100 iter), loss = 0.153357
I0502 11:15:16.003847 26473 solver.cpp:261]     Train net output #0: loss = 0.153357 (* 1 = 0.153357 loss)
I0502 11:15:16.003856 26473 sgd_solver.cpp:106] Iteration 33000, lr = 5.12e-05
I0502 11:15:16.954118 26473 solver.cpp:242] Iteration 33100 (91.9607 iter/s, 1.08742s/100 iter), loss = 0.627507
I0502 11:15:16.954164 26473 solver.cpp:261]     Train net output #0: loss = 0.627507 (* 1 = 0.627507 loss)
I0502 11:15:16.954174 26473 sgd_solver.cpp:106] Iteration 33100, lr = 5.12e-05
I0502 11:15:16.958950 26473 solver.cpp:242] Iteration 33100 (104.703 iter/s, 0.955084s/100 iter), loss = 0.129257
I0502 11:15:16.958973 26473 solver.cpp:261]     Train net output #0: loss = 0.129257 (* 1 = 0.129257 loss)
I0502 11:15:16.958981 26473 sgd_solver.cpp:106] Iteration 33100, lr = 5.12e-05
I0502 11:15:17.907234 26473 solver.cpp:242] Iteration 33200 (104.926 iter/s, 0.953049s/100 iter), loss = 0.991357
I0502 11:15:17.907274 26473 solver.cpp:261]     Train net output #0: loss = 0.991357 (* 1 = 0.991357 loss)
I0502 11:15:17.907284 26473 sgd_solver.cpp:106] Iteration 33200, lr = 5.12e-05
I0502 11:15:17.912124 26473 solver.cpp:242] Iteration 33200 (104.917 iter/s, 0.953133s/100 iter), loss = 0.219759
I0502 11:15:17.912147 26473 solver.cpp:261]     Train net output #0: loss = 0.219759 (* 1 = 0.219759 loss)
I0502 11:15:17.912155 26473 sgd_solver.cpp:106] Iteration 33200, lr = 5.12e-05
I0502 11:15:18.861467 26473 solver.cpp:242] Iteration 33300 (104.803 iter/s, 0.954172s/100 iter), loss = 0.416333
I0502 11:15:18.861506 26473 solver.cpp:261]     Train net output #0: loss = 0.416333 (* 1 = 0.416333 loss)
I0502 11:15:18.861515 26473 sgd_solver.cpp:106] Iteration 33300, lr = 5.12e-05
I0502 11:15:18.866293 26473 solver.cpp:242] Iteration 33300 (104.808 iter/s, 0.954128s/100 iter), loss = 0.190238
I0502 11:15:18.866315 26473 solver.cpp:261]     Train net output #0: loss = 0.190238 (* 1 = 0.190238 loss)
I0502 11:15:18.866324 26473 sgd_solver.cpp:106] Iteration 33300, lr = 5.12e-05
I0502 11:15:19.814970 26473 solver.cpp:242] Iteration 33400 (104.883 iter/s, 0.953443s/100 iter), loss = 0.926853
I0502 11:15:19.815016 26473 solver.cpp:261]     Train net output #0: loss = 0.926853 (* 1 = 0.926853 loss)
I0502 11:15:19.815026 26473 sgd_solver.cpp:106] Iteration 33400, lr = 5.12e-05
I0502 11:15:19.819962 26473 solver.cpp:242] Iteration 33400 (104.863 iter/s, 0.953627s/100 iter), loss = 0.0893571
I0502 11:15:19.819986 26473 solver.cpp:261]     Train net output #0: loss = 0.0893571 (* 1 = 0.0893571 loss)
I0502 11:15:19.819994 26473 sgd_solver.cpp:106] Iteration 33400, lr = 5.12e-05
I0502 11:15:20.765645 26473 solver.cpp:362] Iteration 33500, Testing net (#0)
I0502 11:15:20.765666 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:20.891485 26473 solver.cpp:429]     Test net output #0: loss = 0.436671 (* 1 = 0.436671 loss)
I0502 11:15:20.894405 26473 solver.cpp:242] Iteration 33500 (92.6467 iter/s, 1.07937s/100 iter), loss = 0.420362
I0502 11:15:20.894426 26473 solver.cpp:261]     Train net output #0: loss = 0.420362 (* 1 = 0.420362 loss)
I0502 11:15:20.894435 26473 sgd_solver.cpp:106] Iteration 33500, lr = 5.12e-05
I0502 11:15:20.896093 26473 solver.cpp:362] Iteration 33500, Testing net (#0)
I0502 11:15:20.896106 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:21.028357 26473 solver.cpp:429]     Test net output #0: accuracy = 0.935
I0502 11:15:21.028378 26473 solver.cpp:429]     Test net output #1: loss = 0.169789 (* 1 = 0.169789 loss)
I0502 11:15:21.031359 26473 solver.cpp:242] Iteration 33500 (82.5524 iter/s, 1.21135s/100 iter), loss = 0.31948
I0502 11:15:21.031380 26473 solver.cpp:261]     Train net output #0: loss = 0.31948 (* 1 = 0.31948 loss)
I0502 11:15:21.031388 26473 sgd_solver.cpp:106] Iteration 33500, lr = 5.12e-05
I0502 11:15:21.981452 26473 solver.cpp:242] Iteration 33600 (91.9963 iter/s, 1.087s/100 iter), loss = 0.605668
I0502 11:15:21.981488 26473 solver.cpp:261]     Train net output #0: loss = 0.605668 (* 1 = 0.605668 loss)
I0502 11:15:21.981498 26473 sgd_solver.cpp:106] Iteration 33600, lr = 5.12e-05
I0502 11:15:21.986263 26473 solver.cpp:242] Iteration 33600 (104.727 iter/s, 0.954864s/100 iter), loss = 0.0488757
I0502 11:15:21.986285 26473 solver.cpp:261]     Train net output #0: loss = 0.0488757 (* 1 = 0.0488757 loss)
I0502 11:15:21.986294 26473 sgd_solver.cpp:106] Iteration 33600, lr = 5.12e-05
I0502 11:15:22.934486 26473 solver.cpp:242] Iteration 33700 (104.934 iter/s, 0.952976s/100 iter), loss = 0.81524
I0502 11:15:22.934520 26473 solver.cpp:261]     Train net output #0: loss = 0.81524 (* 1 = 0.81524 loss)
I0502 11:15:22.934530 26473 sgd_solver.cpp:106] Iteration 33700, lr = 5.12e-05
I0502 11:15:22.939312 26473 solver.cpp:242] Iteration 33700 (104.931 iter/s, 0.953008s/100 iter), loss = 0.183235
I0502 11:15:22.939335 26473 solver.cpp:261]     Train net output #0: loss = 0.183235 (* 1 = 0.183235 loss)
I0502 11:15:22.939343 26473 sgd_solver.cpp:106] Iteration 33700, lr = 5.12e-05
I0502 11:15:23.894729 26473 solver.cpp:242] Iteration 33800 (104.146 iter/s, 0.960188s/100 iter), loss = 0.562328
I0502 11:15:23.894765 26473 solver.cpp:261]     Train net output #0: loss = 0.562328 (* 1 = 0.562328 loss)
I0502 11:15:23.894774 26473 sgd_solver.cpp:106] Iteration 33800, lr = 5.12e-05
I0502 11:15:23.899627 26473 solver.cpp:242] Iteration 33800 (104.137 iter/s, 0.960272s/100 iter), loss = 0.175486
I0502 11:15:23.899652 26473 solver.cpp:261]     Train net output #0: loss = 0.175486 (* 1 = 0.175486 loss)
I0502 11:15:23.899660 26473 sgd_solver.cpp:106] Iteration 33800, lr = 5.12e-05
I0502 11:15:24.854634 26473 solver.cpp:242] Iteration 33900 (104.183 iter/s, 0.959848s/100 iter), loss = 0.205287
I0502 11:15:24.854663 26473 solver.cpp:261]     Train net output #0: loss = 0.205287 (* 1 = 0.205287 loss)
I0502 11:15:24.854672 26473 sgd_solver.cpp:106] Iteration 33900, lr = 5.12e-05
I0502 11:15:24.859580 26473 solver.cpp:242] Iteration 33900 (104.176 iter/s, 0.95991s/100 iter), loss = 0.293461
I0502 11:15:24.859601 26473 solver.cpp:261]     Train net output #0: loss = 0.293461 (* 1 = 0.293461 loss)
I0502 11:15:24.859611 26473 sgd_solver.cpp:106] Iteration 33900, lr = 5.12e-05
I0502 11:15:25.813968 26473 solver.cpp:362] Iteration 34000, Testing net (#0)
I0502 11:15:25.813997 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:25.940640 26473 solver.cpp:429]     Test net output #0: loss = 0.718313 (* 1 = 0.718313 loss)
I0502 11:15:25.943574 26473 solver.cpp:242] Iteration 34000 (91.8366 iter/s, 1.08889s/100 iter), loss = 0.199953
I0502 11:15:25.943593 26473 solver.cpp:261]     Train net output #0: loss = 0.199953 (* 1 = 0.199953 loss)
I0502 11:15:25.943603 26473 sgd_solver.cpp:106] Iteration 34000, lr = 5.12e-05
I0502 11:15:25.945334 26473 solver.cpp:362] Iteration 34000, Testing net (#0)
I0502 11:15:25.945348 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:26.078415 26473 solver.cpp:429]     Test net output #0: accuracy = 0.883
I0502 11:15:26.078435 26473 solver.cpp:429]     Test net output #1: loss = 0.248913 (* 1 = 0.248913 loss)
I0502 11:15:26.081419 26473 solver.cpp:242] Iteration 34000 (81.8467 iter/s, 1.2218s/100 iter), loss = 0.213366
I0502 11:15:26.081439 26473 solver.cpp:261]     Train net output #0: loss = 0.213366 (* 1 = 0.213366 loss)
I0502 11:15:26.081449 26473 sgd_solver.cpp:106] Iteration 34000, lr = 5.12e-05
I0502 11:15:27.037677 26473 solver.cpp:242] Iteration 34100 (91.4027 iter/s, 1.09406s/100 iter), loss = 0.435744
I0502 11:15:27.037706 26473 solver.cpp:261]     Train net output #0: loss = 0.435744 (* 1 = 0.435744 loss)
I0502 11:15:27.037715 26473 sgd_solver.cpp:106] Iteration 34100, lr = 5.12e-05
I0502 11:15:27.042524 26473 solver.cpp:242] Iteration 34100 (104.051 iter/s, 0.961065s/100 iter), loss = 0.208731
I0502 11:15:27.042547 26473 solver.cpp:261]     Train net output #0: loss = 0.208731 (* 1 = 0.208731 loss)
I0502 11:15:27.042557 26473 sgd_solver.cpp:106] Iteration 34100, lr = 5.12e-05
I0502 11:15:27.998586 26473 solver.cpp:242] Iteration 34200 (104.073 iter/s, 0.96086s/100 iter), loss = 0.689717
I0502 11:15:27.998615 26473 solver.cpp:261]     Train net output #0: loss = 0.689717 (* 1 = 0.689717 loss)
I0502 11:15:27.998623 26473 sgd_solver.cpp:106] Iteration 34200, lr = 5.12e-05
I0502 11:15:28.003454 26473 solver.cpp:242] Iteration 34200 (104.07 iter/s, 0.960889s/100 iter), loss = 0.16315
I0502 11:15:28.003478 26473 solver.cpp:261]     Train net output #0: loss = 0.16315 (* 1 = 0.16315 loss)
I0502 11:15:28.003492 26473 sgd_solver.cpp:106] Iteration 34200, lr = 5.12e-05
I0502 11:15:28.958820 26473 solver.cpp:242] Iteration 34300 (104.147 iter/s, 0.960181s/100 iter), loss = 0.298536
I0502 11:15:28.958863 26473 solver.cpp:261]     Train net output #0: loss = 0.298536 (* 1 = 0.298536 loss)
I0502 11:15:28.958871 26473 sgd_solver.cpp:106] Iteration 34300, lr = 5.12e-05
I0502 11:15:28.963707 26473 solver.cpp:242] Iteration 34300 (104.144 iter/s, 0.960212s/100 iter), loss = 0.117779
I0502 11:15:28.963731 26473 solver.cpp:261]     Train net output #0: loss = 0.117779 (* 1 = 0.117779 loss)
I0502 11:15:28.963739 26473 sgd_solver.cpp:106] Iteration 34300, lr = 5.12e-05
I0502 11:15:29.938380 26473 solver.cpp:242] Iteration 34400 (102.093 iter/s, 0.979496s/100 iter), loss = 0.164776
I0502 11:15:29.938441 26473 solver.cpp:261]     Train net output #0: loss = 0.164776 (* 1 = 0.164776 loss)
I0502 11:15:29.938449 26473 sgd_solver.cpp:106] Iteration 34400, lr = 5.12e-05
I0502 11:15:29.943373 26473 solver.cpp:242] Iteration 34400 (102.08 iter/s, 0.979624s/100 iter), loss = 0.213914
I0502 11:15:29.943397 26473 solver.cpp:261]     Train net output #0: loss = 0.213914 (* 1 = 0.213914 loss)
I0502 11:15:29.943406 26473 sgd_solver.cpp:106] Iteration 34400, lr = 5.12e-05
I0502 11:15:30.891597 26473 solver.cpp:362] Iteration 34500, Testing net (#0)
I0502 11:15:30.891625 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:31.018076 26473 solver.cpp:429]     Test net output #0: loss = 0.543789 (* 1 = 0.543789 loss)
I0502 11:15:31.021005 26473 solver.cpp:242] Iteration 34500 (92.3748 iter/s, 1.08255s/100 iter), loss = 0.14449
I0502 11:15:31.021025 26473 solver.cpp:261]     Train net output #0: loss = 0.14449 (* 1 = 0.14449 loss)
I0502 11:15:31.021034 26473 sgd_solver.cpp:106] Iteration 34500, lr = 5.12e-05
I0502 11:15:31.022773 26473 solver.cpp:362] Iteration 34500, Testing net (#0)
I0502 11:15:31.022786 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:31.155834 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9075
I0502 11:15:31.155856 26473 solver.cpp:429]     Test net output #1: loss = 0.188193 (* 1 = 0.188193 loss)
I0502 11:15:31.158838 26473 solver.cpp:242] Iteration 34500 (82.2761 iter/s, 1.21542s/100 iter), loss = 0.147712
I0502 11:15:31.158859 26473 solver.cpp:261]     Train net output #0: loss = 0.147712 (* 1 = 0.147712 loss)
I0502 11:15:31.158869 26473 sgd_solver.cpp:106] Iteration 34500, lr = 5.12e-05
I0502 11:15:32.109676 26473 solver.cpp:242] Iteration 34600 (91.8588 iter/s, 1.08863s/100 iter), loss = 0.176571
I0502 11:15:32.109716 26473 solver.cpp:261]     Train net output #0: loss = 0.176571 (* 1 = 0.176571 loss)
I0502 11:15:32.109725 26473 sgd_solver.cpp:106] Iteration 34600, lr = 5.12e-05
I0502 11:15:32.114523 26473 solver.cpp:242] Iteration 34600 (104.641 iter/s, 0.955645s/100 iter), loss = 0.156469
I0502 11:15:32.114547 26473 solver.cpp:261]     Train net output #0: loss = 0.156469 (* 1 = 0.156469 loss)
I0502 11:15:32.114554 26473 sgd_solver.cpp:106] Iteration 34600, lr = 5.12e-05
I0502 11:15:33.063485 26473 solver.cpp:242] Iteration 34700 (104.85 iter/s, 0.953746s/100 iter), loss = 0.562017
I0502 11:15:33.063524 26473 solver.cpp:261]     Train net output #0: loss = 0.562017 (* 1 = 0.562017 loss)
I0502 11:15:33.063534 26473 sgd_solver.cpp:106] Iteration 34700, lr = 5.12e-05
I0502 11:15:33.068385 26473 solver.cpp:242] Iteration 34700 (104.842 iter/s, 0.95382s/100 iter), loss = 0.134766
I0502 11:15:33.068409 26473 solver.cpp:261]     Train net output #0: loss = 0.134766 (* 1 = 0.134766 loss)
I0502 11:15:33.068418 26473 sgd_solver.cpp:106] Iteration 34700, lr = 5.12e-05
I0502 11:15:34.016410 26473 solver.cpp:242] Iteration 34800 (104.947 iter/s, 0.952864s/100 iter), loss = 0.519441
I0502 11:15:34.016453 26473 solver.cpp:261]     Train net output #0: loss = 0.519441 (* 1 = 0.519441 loss)
I0502 11:15:34.016463 26473 sgd_solver.cpp:106] Iteration 34800, lr = 5.12e-05
I0502 11:15:34.021306 26473 solver.cpp:242] Iteration 34800 (104.945 iter/s, 0.952877s/100 iter), loss = 0.109589
I0502 11:15:34.021337 26473 solver.cpp:261]     Train net output #0: loss = 0.109589 (* 1 = 0.109589 loss)
I0502 11:15:34.021345 26473 sgd_solver.cpp:106] Iteration 34800, lr = 5.12e-05
I0502 11:15:34.969424 26473 solver.cpp:242] Iteration 34900 (104.937 iter/s, 0.95295s/100 iter), loss = 0.214377
I0502 11:15:34.969478 26473 solver.cpp:261]     Train net output #0: loss = 0.214377 (* 1 = 0.214377 loss)
I0502 11:15:34.969487 26473 sgd_solver.cpp:106] Iteration 34900, lr = 5.12e-05
I0502 11:15:34.974340 26473 solver.cpp:242] Iteration 34900 (104.933 iter/s, 0.952986s/100 iter), loss = 0.191054
I0502 11:15:34.974362 26473 solver.cpp:261]     Train net output #0: loss = 0.191054 (* 1 = 0.191054 loss)
I0502 11:15:34.974371 26473 sgd_solver.cpp:106] Iteration 34900, lr = 5.12e-05
I0502 11:15:35.920542 26473 solver.cpp:362] Iteration 35000, Testing net (#0)
I0502 11:15:35.920572 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:36.046455 26473 solver.cpp:429]     Test net output #0: loss = 0.416055 (* 1 = 0.416055 loss)
I0502 11:15:36.049383 26473 solver.cpp:242] Iteration 35000 (92.6023 iter/s, 1.07989s/100 iter), loss = 0.28082
I0502 11:15:36.049403 26473 solver.cpp:261]     Train net output #0: loss = 0.28082 (* 1 = 0.28082 loss)
I0502 11:15:36.049412 26473 sgd_solver.cpp:106] Iteration 35000, lr = 5.12e-05
I0502 11:15:36.051142 26473 solver.cpp:362] Iteration 35000, Testing net (#0)
I0502 11:15:36.051156 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:36.183583 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9305
I0502 11:15:36.183604 26473 solver.cpp:429]     Test net output #1: loss = 0.1578 (* 1 = 0.1578 loss)
I0502 11:15:36.186559 26473 solver.cpp:242] Iteration 35000 (82.4963 iter/s, 1.21218s/100 iter), loss = 0.147631
I0502 11:15:36.186579 26473 solver.cpp:261]     Train net output #0: loss = 0.147631 (* 1 = 0.147631 loss)
I0502 11:15:36.186588 26473 sgd_solver.cpp:106] Iteration 35000, lr = 5.12e-05
I0502 11:15:37.135946 26473 solver.cpp:242] Iteration 35100 (92.0371 iter/s, 1.08652s/100 iter), loss = 0.329834
I0502 11:15:37.135984 26473 solver.cpp:261]     Train net output #0: loss = 0.329834 (* 1 = 0.329834 loss)
I0502 11:15:37.135994 26473 sgd_solver.cpp:106] Iteration 35100, lr = 5.12e-05
I0502 11:15:37.140858 26473 solver.cpp:242] Iteration 35100 (104.793 iter/s, 0.954261s/100 iter), loss = 0.146007
I0502 11:15:37.140883 26473 solver.cpp:261]     Train net output #0: loss = 0.146007 (* 1 = 0.146007 loss)
I0502 11:15:37.140892 26473 sgd_solver.cpp:106] Iteration 35100, lr = 5.12e-05
I0502 11:15:38.088914 26473 solver.cpp:242] Iteration 35200 (104.942 iter/s, 0.952909s/100 iter), loss = 0.795904
I0502 11:15:38.088953 26473 solver.cpp:261]     Train net output #0: loss = 0.795904 (* 1 = 0.795904 loss)
I0502 11:15:38.088963 26473 sgd_solver.cpp:106] Iteration 35200, lr = 5.12e-05
I0502 11:15:38.093755 26473 solver.cpp:242] Iteration 35200 (104.948 iter/s, 0.952854s/100 iter), loss = 0.110204
I0502 11:15:38.093778 26473 solver.cpp:261]     Train net output #0: loss = 0.110204 (* 1 = 0.110204 loss)
I0502 11:15:38.093787 26473 sgd_solver.cpp:106] Iteration 35200, lr = 5.12e-05
I0502 11:15:39.041025 26473 solver.cpp:242] Iteration 35300 (105.036 iter/s, 0.952051s/100 iter), loss = 1.19743
I0502 11:15:39.041062 26473 solver.cpp:261]     Train net output #0: loss = 1.19743 (* 1 = 1.19743 loss)
I0502 11:15:39.041071 26473 sgd_solver.cpp:106] Iteration 35300, lr = 5.12e-05
I0502 11:15:39.045848 26473 solver.cpp:242] Iteration 35300 (105.036 iter/s, 0.952051s/100 iter), loss = 0.181967
I0502 11:15:39.045871 26473 solver.cpp:261]     Train net output #0: loss = 0.181967 (* 1 = 0.181967 loss)
I0502 11:15:39.045881 26473 sgd_solver.cpp:106] Iteration 35300, lr = 5.12e-05
I0502 11:15:39.994226 26473 solver.cpp:242] Iteration 35400 (104.916 iter/s, 0.953139s/100 iter), loss = 1.48444
I0502 11:15:39.994280 26473 solver.cpp:261]     Train net output #0: loss = 1.48444 (* 1 = 1.48444 loss)
I0502 11:15:39.994290 26473 sgd_solver.cpp:106] Iteration 35400, lr = 5.12e-05
I0502 11:15:39.999135 26473 solver.cpp:242] Iteration 35400 (104.905 iter/s, 0.953245s/100 iter), loss = 0.242797
I0502 11:15:39.999164 26473 solver.cpp:261]     Train net output #0: loss = 0.242797 (* 1 = 0.242797 loss)
I0502 11:15:39.999174 26473 sgd_solver.cpp:106] Iteration 35400, lr = 5.12e-05
I0502 11:15:40.943274 26473 solver.cpp:362] Iteration 35500, Testing net (#0)
I0502 11:15:40.943295 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:41.068342 26473 solver.cpp:429]     Test net output #0: loss = 0.902999 (* 1 = 0.902999 loss)
I0502 11:15:41.071211 26473 solver.cpp:242] Iteration 35500 (92.858 iter/s, 1.07691s/100 iter), loss = 0.709398
I0502 11:15:41.071231 26473 solver.cpp:261]     Train net output #0: loss = 0.709398 (* 1 = 0.709398 loss)
I0502 11:15:41.071240 26473 sgd_solver.cpp:106] Iteration 35500, lr = 5.12e-05
I0502 11:15:41.072975 26473 solver.cpp:362] Iteration 35500, Testing net (#0)
I0502 11:15:41.072988 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:41.204226 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9165
I0502 11:15:41.204246 26473 solver.cpp:429]     Test net output #1: loss = 0.217006 (* 1 = 0.217006 loss)
I0502 11:15:41.207182 26473 solver.cpp:242] Iteration 35500 (82.7818 iter/s, 1.208s/100 iter), loss = 0.059747
I0502 11:15:41.207202 26473 solver.cpp:261]     Train net output #0: loss = 0.059747 (* 1 = 0.059747 loss)
I0502 11:15:41.207211 26473 sgd_solver.cpp:106] Iteration 35500, lr = 5.12e-05
I0502 11:15:42.154835 26473 solver.cpp:242] Iteration 35600 (92.2867 iter/s, 1.08358s/100 iter), loss = 0.522872
I0502 11:15:42.154870 26473 solver.cpp:261]     Train net output #0: loss = 0.522872 (* 1 = 0.522872 loss)
I0502 11:15:42.154880 26473 sgd_solver.cpp:106] Iteration 35600, lr = 5.12e-05
I0502 11:15:42.159682 26473 solver.cpp:242] Iteration 35600 (104.991 iter/s, 0.952461s/100 iter), loss = 0.0389879
I0502 11:15:42.159706 26473 solver.cpp:261]     Train net output #0: loss = 0.0389879 (* 1 = 0.0389879 loss)
I0502 11:15:42.159715 26473 sgd_solver.cpp:106] Iteration 35600, lr = 5.12e-05
I0502 11:15:43.108155 26473 solver.cpp:242] Iteration 35700 (104.903 iter/s, 0.953261s/100 iter), loss = 0.481741
I0502 11:15:43.108188 26473 solver.cpp:261]     Train net output #0: loss = 0.481741 (* 1 = 0.481741 loss)
I0502 11:15:43.108197 26473 sgd_solver.cpp:106] Iteration 35700, lr = 5.12e-05
I0502 11:15:43.113034 26473 solver.cpp:242] Iteration 35700 (104.898 iter/s, 0.953309s/100 iter), loss = 0.120512
I0502 11:15:43.113056 26473 solver.cpp:261]     Train net output #0: loss = 0.120512 (* 1 = 0.120512 loss)
I0502 11:15:43.113065 26473 sgd_solver.cpp:106] Iteration 35700, lr = 5.12e-05
I0502 11:15:44.059866 26473 solver.cpp:242] Iteration 35800 (105.08 iter/s, 0.951657s/100 iter), loss = 0.2227
I0502 11:15:44.059900 26473 solver.cpp:261]     Train net output #0: loss = 0.2227 (* 1 = 0.2227 loss)
I0502 11:15:44.059909 26473 sgd_solver.cpp:106] Iteration 35800, lr = 5.12e-05
I0502 11:15:44.064694 26473 solver.cpp:242] Iteration 35800 (105.084 iter/s, 0.95162s/100 iter), loss = 0.129795
I0502 11:15:44.064718 26473 solver.cpp:261]     Train net output #0: loss = 0.129795 (* 1 = 0.129795 loss)
I0502 11:15:44.064726 26473 sgd_solver.cpp:106] Iteration 35800, lr = 5.12e-05
I0502 11:15:45.011723 26473 solver.cpp:242] Iteration 35900 (105.064 iter/s, 0.951798s/100 iter), loss = 0.634664
I0502 11:15:45.011775 26473 solver.cpp:261]     Train net output #0: loss = 0.634664 (* 1 = 0.634664 loss)
I0502 11:15:45.011783 26473 sgd_solver.cpp:106] Iteration 35900, lr = 5.12e-05
I0502 11:15:45.016688 26473 solver.cpp:242] Iteration 35900 (105.047 iter/s, 0.951952s/100 iter), loss = 0.203535
I0502 11:15:45.016712 26473 solver.cpp:261]     Train net output #0: loss = 0.203535 (* 1 = 0.203535 loss)
I0502 11:15:45.016721 26473 sgd_solver.cpp:106] Iteration 35900, lr = 5.12e-05
I0502 11:15:45.961639 26473 solver.cpp:362] Iteration 36000, Testing net (#0)
I0502 11:15:45.961660 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:46.086549 26473 solver.cpp:429]     Test net output #0: loss = 0.638598 (* 1 = 0.638598 loss)
I0502 11:15:46.089457 26473 solver.cpp:242] Iteration 36000 (92.7932 iter/s, 1.07766s/100 iter), loss = 0.273126
I0502 11:15:46.089478 26473 solver.cpp:261]     Train net output #0: loss = 0.273126 (* 1 = 0.273126 loss)
I0502 11:15:46.089486 26473 sgd_solver.cpp:106] Iteration 36000, lr = 5.12e-05
I0502 11:15:46.091245 26473 solver.cpp:362] Iteration 36000, Testing net (#0)
I0502 11:15:46.091259 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:46.222546 26473 solver.cpp:429]     Test net output #0: accuracy = 0.922
I0502 11:15:46.222565 26473 solver.cpp:429]     Test net output #1: loss = 0.203644 (* 1 = 0.203644 loss)
I0502 11:15:46.225508 26473 solver.cpp:242] Iteration 36000 (82.7284 iter/s, 1.20877s/100 iter), loss = 0.253372
I0502 11:15:46.225529 26473 solver.cpp:261]     Train net output #0: loss = 0.253372 (* 1 = 0.253372 loss)
I0502 11:15:46.225538 26473 sgd_solver.cpp:106] Iteration 36000, lr = 5.12e-05
I0502 11:15:47.172554 26473 solver.cpp:242] Iteration 36100 (92.3318 iter/s, 1.08305s/100 iter), loss = 0.360059
I0502 11:15:47.172583 26473 solver.cpp:261]     Train net output #0: loss = 0.360059 (* 1 = 0.360059 loss)
I0502 11:15:47.172592 26473 sgd_solver.cpp:106] Iteration 36100, lr = 5.12e-05
I0502 11:15:47.177392 26473 solver.cpp:242] Iteration 36100 (105.059 iter/s, 0.951845s/100 iter), loss = 0.364385
I0502 11:15:47.177415 26473 solver.cpp:261]     Train net output #0: loss = 0.364385 (* 1 = 0.364385 loss)
I0502 11:15:47.177424 26473 sgd_solver.cpp:106] Iteration 36100, lr = 5.12e-05
I0502 11:15:48.125413 26473 solver.cpp:242] Iteration 36200 (104.953 iter/s, 0.952807s/100 iter), loss = 0.330507
I0502 11:15:48.125457 26473 solver.cpp:261]     Train net output #0: loss = 0.330507 (* 1 = 0.330507 loss)
I0502 11:15:48.125465 26473 sgd_solver.cpp:106] Iteration 36200, lr = 5.12e-05
I0502 11:15:48.130259 26473 solver.cpp:242] Iteration 36200 (104.951 iter/s, 0.952824s/100 iter), loss = 0.222149
I0502 11:15:48.130280 26473 solver.cpp:261]     Train net output #0: loss = 0.222149 (* 1 = 0.222149 loss)
I0502 11:15:48.130290 26473 sgd_solver.cpp:106] Iteration 36200, lr = 5.12e-05
I0502 11:15:49.077219 26473 solver.cpp:242] Iteration 36300 (105.07 iter/s, 0.951742s/100 iter), loss = 0.61349
I0502 11:15:49.077262 26473 solver.cpp:261]     Train net output #0: loss = 0.61349 (* 1 = 0.61349 loss)
I0502 11:15:49.077271 26473 sgd_solver.cpp:106] Iteration 36300, lr = 5.12e-05
I0502 11:15:49.082046 26473 solver.cpp:242] Iteration 36300 (105.07 iter/s, 0.951746s/100 iter), loss = 0.139129
I0502 11:15:49.082067 26473 solver.cpp:261]     Train net output #0: loss = 0.139129 (* 1 = 0.139129 loss)
I0502 11:15:49.082077 26473 sgd_solver.cpp:106] Iteration 36300, lr = 5.12e-05
I0502 11:15:50.029428 26473 solver.cpp:242] Iteration 36400 (105.026 iter/s, 0.952143s/100 iter), loss = 0.613386
I0502 11:15:50.029486 26473 solver.cpp:261]     Train net output #0: loss = 0.613386 (* 1 = 0.613386 loss)
I0502 11:15:50.029495 26473 sgd_solver.cpp:106] Iteration 36400, lr = 5.12e-05
I0502 11:15:50.034353 26473 solver.cpp:242] Iteration 36400 (105.013 iter/s, 0.952267s/100 iter), loss = 0.20237
I0502 11:15:50.034375 26473 solver.cpp:261]     Train net output #0: loss = 0.20237 (* 1 = 0.20237 loss)
I0502 11:15:50.034384 26473 sgd_solver.cpp:106] Iteration 36400, lr = 5.12e-05
I0502 11:15:50.979655 26473 solver.cpp:362] Iteration 36500, Testing net (#0)
I0502 11:15:50.979687 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:51.104787 26473 solver.cpp:429]     Test net output #0: loss = 0.55353 (* 1 = 0.55353 loss)
I0502 11:15:51.107676 26473 solver.cpp:242] Iteration 36500 (92.7496 iter/s, 1.07817s/100 iter), loss = 1.03332
I0502 11:15:51.107697 26473 solver.cpp:261]     Train net output #0: loss = 1.03332 (* 1 = 1.03332 loss)
I0502 11:15:51.107704 26473 sgd_solver.cpp:106] Iteration 36500, lr = 5.12e-05
I0502 11:15:51.109468 26473 solver.cpp:362] Iteration 36500, Testing net (#0)
I0502 11:15:51.109480 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:51.240631 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9245
I0502 11:15:51.240659 26473 solver.cpp:429]     Test net output #1: loss = 0.178255 (* 1 = 0.178255 loss)
I0502 11:15:51.243600 26473 solver.cpp:242] Iteration 36500 (82.699 iter/s, 1.2092s/100 iter), loss = 0.230109
I0502 11:15:51.243620 26473 solver.cpp:261]     Train net output #0: loss = 0.230109 (* 1 = 0.230109 loss)
I0502 11:15:51.243629 26473 sgd_solver.cpp:106] Iteration 36500, lr = 5.12e-05
I0502 11:15:52.191205 26473 solver.cpp:242] Iteration 36600 (92.2949 iter/s, 1.08348s/100 iter), loss = 0.431092
I0502 11:15:52.191249 26473 solver.cpp:261]     Train net output #0: loss = 0.431092 (* 1 = 0.431092 loss)
I0502 11:15:52.191258 26473 sgd_solver.cpp:106] Iteration 36600, lr = 5.12e-05
I0502 11:15:52.196131 26473 solver.cpp:242] Iteration 36600 (104.988 iter/s, 0.952491s/100 iter), loss = 0.106381
I0502 11:15:52.196157 26473 solver.cpp:261]     Train net output #0: loss = 0.106381 (* 1 = 0.106381 loss)
I0502 11:15:52.196166 26473 sgd_solver.cpp:106] Iteration 36600, lr = 5.12e-05
I0502 11:15:53.143394 26473 solver.cpp:242] Iteration 36700 (105.028 iter/s, 0.952123s/100 iter), loss = 0.354659
I0502 11:15:53.143435 26473 solver.cpp:261]     Train net output #0: loss = 0.354659 (* 1 = 0.354659 loss)
I0502 11:15:53.143443 26473 sgd_solver.cpp:106] Iteration 36700, lr = 5.12e-05
I0502 11:15:53.148226 26473 solver.cpp:242] Iteration 36700 (105.037 iter/s, 0.95205s/100 iter), loss = 0.0867007
I0502 11:15:53.148248 26473 solver.cpp:261]     Train net output #0: loss = 0.0867007 (* 1 = 0.0867007 loss)
I0502 11:15:53.148257 26473 sgd_solver.cpp:106] Iteration 36700, lr = 5.12e-05
I0502 11:15:54.096191 26473 solver.cpp:242] Iteration 36800 (104.961 iter/s, 0.952734s/100 iter), loss = 0.543148
I0502 11:15:54.096230 26473 solver.cpp:261]     Train net output #0: loss = 0.543148 (* 1 = 0.543148 loss)
I0502 11:15:54.096238 26473 sgd_solver.cpp:106] Iteration 36800, lr = 5.12e-05
I0502 11:15:54.101056 26473 solver.cpp:242] Iteration 36800 (104.955 iter/s, 0.952789s/100 iter), loss = 0.271764
I0502 11:15:54.101079 26473 solver.cpp:261]     Train net output #0: loss = 0.271764 (* 1 = 0.271764 loss)
I0502 11:15:54.101088 26473 sgd_solver.cpp:106] Iteration 36800, lr = 5.12e-05
I0502 11:15:55.048652 26473 solver.cpp:242] Iteration 36900 (104.998 iter/s, 0.952401s/100 iter), loss = 0.51195
I0502 11:15:55.048704 26473 solver.cpp:261]     Train net output #0: loss = 0.51195 (* 1 = 0.51195 loss)
I0502 11:15:55.048714 26473 sgd_solver.cpp:106] Iteration 36900, lr = 5.12e-05
I0502 11:15:55.053571 26473 solver.cpp:242] Iteration 36900 (104.99 iter/s, 0.952474s/100 iter), loss = 0.848998
I0502 11:15:55.053596 26473 solver.cpp:261]     Train net output #0: loss = 0.848998 (* 1 = 0.848998 loss)
I0502 11:15:55.053603 26473 sgd_solver.cpp:106] Iteration 36900, lr = 5.12e-05
I0502 11:15:55.998070 26473 solver.cpp:362] Iteration 37000, Testing net (#0)
I0502 11:15:55.998100 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:56.123313 26473 solver.cpp:429]     Test net output #0: loss = 0.421859 (* 1 = 0.421859 loss)
I0502 11:15:56.126199 26473 solver.cpp:242] Iteration 37000 (92.8096 iter/s, 1.07748s/100 iter), loss = 0.652903
I0502 11:15:56.126219 26473 solver.cpp:261]     Train net output #0: loss = 0.652903 (* 1 = 0.652903 loss)
I0502 11:15:56.126227 26473 sgd_solver.cpp:106] Iteration 37000, lr = 5.12e-05
I0502 11:15:56.128026 26473 solver.cpp:362] Iteration 37000, Testing net (#0)
I0502 11:15:56.128041 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:15:56.260234 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9175
I0502 11:15:56.260258 26473 solver.cpp:429]     Test net output #1: loss = 0.18016 (* 1 = 0.18016 loss)
I0502 11:15:56.263221 26473 solver.cpp:242] Iteration 37000 (82.6717 iter/s, 1.2096s/100 iter), loss = 0.147682
I0502 11:15:56.263242 26473 solver.cpp:261]     Train net output #0: loss = 0.147682 (* 1 = 0.147682 loss)
I0502 11:15:56.263249 26473 sgd_solver.cpp:106] Iteration 37000, lr = 5.12e-05
I0502 11:15:57.212940 26473 solver.cpp:242] Iteration 37100 (92.0219 iter/s, 1.0867s/100 iter), loss = 0.646522
I0502 11:15:57.212988 26473 solver.cpp:261]     Train net output #0: loss = 0.646522 (* 1 = 0.646522 loss)
I0502 11:15:57.212998 26473 sgd_solver.cpp:106] Iteration 37100, lr = 5.12e-05
I0502 11:15:57.217869 26473 solver.cpp:242] Iteration 37100 (104.755 iter/s, 0.95461s/100 iter), loss = 0.235354
I0502 11:15:57.217893 26473 solver.cpp:261]     Train net output #0: loss = 0.235354 (* 1 = 0.235354 loss)
I0502 11:15:57.217901 26473 sgd_solver.cpp:106] Iteration 37100, lr = 5.12e-05
I0502 11:15:58.166653 26473 solver.cpp:242] Iteration 37200 (104.861 iter/s, 0.953642s/100 iter), loss = 0.477269
I0502 11:15:58.166693 26473 solver.cpp:261]     Train net output #0: loss = 0.477269 (* 1 = 0.477269 loss)
I0502 11:15:58.166702 26473 sgd_solver.cpp:106] Iteration 37200, lr = 5.12e-05
I0502 11:15:58.171541 26473 solver.cpp:242] Iteration 37200 (104.863 iter/s, 0.95363s/100 iter), loss = 0.213677
I0502 11:15:58.171564 26473 solver.cpp:261]     Train net output #0: loss = 0.213677 (* 1 = 0.213677 loss)
I0502 11:15:58.171573 26473 sgd_solver.cpp:106] Iteration 37200, lr = 5.12e-05
I0502 11:15:59.120175 26473 solver.cpp:242] Iteration 37300 (104.881 iter/s, 0.953462s/100 iter), loss = 1.77019
I0502 11:15:59.120213 26473 solver.cpp:261]     Train net output #0: loss = 1.77019 (* 1 = 1.77019 loss)
I0502 11:15:59.120221 26473 sgd_solver.cpp:106] Iteration 37300, lr = 5.12e-05
I0502 11:15:59.125030 26473 solver.cpp:242] Iteration 37300 (104.883 iter/s, 0.953446s/100 iter), loss = 0.258108
I0502 11:15:59.125051 26473 solver.cpp:261]     Train net output #0: loss = 0.258108 (* 1 = 0.258108 loss)
I0502 11:15:59.125059 26473 sgd_solver.cpp:106] Iteration 37300, lr = 5.12e-05
I0502 11:16:00.072767 26473 solver.cpp:242] Iteration 37400 (104.983 iter/s, 0.952533s/100 iter), loss = 0.243513
I0502 11:16:00.072818 26473 solver.cpp:261]     Train net output #0: loss = 0.243513 (* 1 = 0.243513 loss)
I0502 11:16:00.072826 26473 sgd_solver.cpp:106] Iteration 37400, lr = 5.12e-05
I0502 11:16:00.077678 26473 solver.cpp:242] Iteration 37400 (104.975 iter/s, 0.952608s/100 iter), loss = 0.0707749
I0502 11:16:00.077702 26473 solver.cpp:261]     Train net output #0: loss = 0.0707749 (* 1 = 0.0707749 loss)
I0502 11:16:00.077711 26473 sgd_solver.cpp:106] Iteration 37400, lr = 5.12e-05
I0502 11:16:01.038483 26473 solver.cpp:362] Iteration 37500, Testing net (#0)
I0502 11:16:01.038507 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:01.163822 26473 solver.cpp:429]     Test net output #0: loss = 0.456217 (* 1 = 0.456217 loss)
I0502 11:16:01.166712 26473 solver.cpp:242] Iteration 37500 (91.4181 iter/s, 1.09388s/100 iter), loss = 0.347619
I0502 11:16:01.166733 26473 solver.cpp:261]     Train net output #0: loss = 0.347619 (* 1 = 0.347619 loss)
I0502 11:16:01.166741 26473 sgd_solver.cpp:106] Iteration 37500, lr = 5.12e-05
I0502 11:16:01.168422 26473 solver.cpp:362] Iteration 37500, Testing net (#0)
I0502 11:16:01.168436 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:01.300158 26473 solver.cpp:429]     Test net output #0: accuracy = 0.921
I0502 11:16:01.300179 26473 solver.cpp:429]     Test net output #1: loss = 0.163321 (* 1 = 0.163321 loss)
I0502 11:16:01.303156 26473 solver.cpp:242] Iteration 37500 (81.6038 iter/s, 1.22543s/100 iter), loss = 0.136928
I0502 11:16:01.303177 26473 solver.cpp:261]     Train net output #0: loss = 0.136928 (* 1 = 0.136928 loss)
I0502 11:16:01.303186 26473 sgd_solver.cpp:106] Iteration 37500, lr = 5.12e-05
I0502 11:16:02.255780 26473 solver.cpp:242] Iteration 37600 (91.8253 iter/s, 1.08902s/100 iter), loss = 0.315869
I0502 11:16:02.255816 26473 solver.cpp:261]     Train net output #0: loss = 0.315869 (* 1 = 0.315869 loss)
I0502 11:16:02.255825 26473 sgd_solver.cpp:106] Iteration 37600, lr = 5.12e-05
I0502 11:16:02.260707 26473 solver.cpp:242] Iteration 37600 (104.437 iter/s, 0.957511s/100 iter), loss = 0.262935
I0502 11:16:02.260730 26473 solver.cpp:261]     Train net output #0: loss = 0.262935 (* 1 = 0.262935 loss)
I0502 11:16:02.260740 26473 sgd_solver.cpp:106] Iteration 37600, lr = 5.12e-05
I0502 11:16:03.211446 26473 solver.cpp:242] Iteration 37700 (104.645 iter/s, 0.955608s/100 iter), loss = 0.585653
I0502 11:16:03.211479 26473 solver.cpp:261]     Train net output #0: loss = 0.585653 (* 1 = 0.585653 loss)
I0502 11:16:03.211488 26473 sgd_solver.cpp:106] Iteration 37700, lr = 5.12e-05
I0502 11:16:03.216272 26473 solver.cpp:242] Iteration 37700 (104.655 iter/s, 0.955523s/100 iter), loss = 0.0920587
I0502 11:16:03.216295 26473 solver.cpp:261]     Train net output #0: loss = 0.0920587 (* 1 = 0.0920587 loss)
I0502 11:16:03.216303 26473 sgd_solver.cpp:106] Iteration 37700, lr = 5.12e-05
I0502 11:16:04.164903 26473 solver.cpp:242] Iteration 37800 (104.887 iter/s, 0.953403s/100 iter), loss = 0.423996
I0502 11:16:04.164935 26473 solver.cpp:261]     Train net output #0: loss = 0.423996 (* 1 = 0.423996 loss)
I0502 11:16:04.164944 26473 sgd_solver.cpp:106] Iteration 37800, lr = 5.12e-05
I0502 11:16:04.169735 26473 solver.cpp:242] Iteration 37800 (104.885 iter/s, 0.953423s/100 iter), loss = 0.239478
I0502 11:16:04.169759 26473 solver.cpp:261]     Train net output #0: loss = 0.239478 (* 1 = 0.239478 loss)
I0502 11:16:04.169766 26473 sgd_solver.cpp:106] Iteration 37800, lr = 5.12e-05
I0502 11:16:05.118839 26473 solver.cpp:242] Iteration 37900 (104.835 iter/s, 0.953884s/100 iter), loss = 0.883984
I0502 11:16:05.118885 26473 solver.cpp:261]     Train net output #0: loss = 0.883984 (* 1 = 0.883984 loss)
I0502 11:16:05.118894 26473 sgd_solver.cpp:106] Iteration 37900, lr = 5.12e-05
I0502 11:16:05.123781 26473 solver.cpp:242] Iteration 37900 (104.821 iter/s, 0.954004s/100 iter), loss = 0.100913
I0502 11:16:05.123805 26473 solver.cpp:261]     Train net output #0: loss = 0.100913 (* 1 = 0.100913 loss)
I0502 11:16:05.123812 26473 sgd_solver.cpp:106] Iteration 37900, lr = 5.12e-05
I0502 11:16:06.073045 26473 solver.cpp:362] Iteration 38000, Testing net (#0)
I0502 11:16:06.073065 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:06.199301 26473 solver.cpp:429]     Test net output #0: loss = 0.516112 (* 1 = 0.516112 loss)
I0502 11:16:06.202231 26473 solver.cpp:242] Iteration 38000 (92.3082 iter/s, 1.08333s/100 iter), loss = 0.465298
I0502 11:16:06.202252 26473 solver.cpp:261]     Train net output #0: loss = 0.465298 (* 1 = 0.465298 loss)
I0502 11:16:06.202261 26473 sgd_solver.cpp:106] Iteration 38000, lr = 5.12e-05
I0502 11:16:06.203953 26473 solver.cpp:362] Iteration 38000, Testing net (#0)
I0502 11:16:06.203966 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:06.336915 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9325
I0502 11:16:06.336935 26473 solver.cpp:429]     Test net output #1: loss = 0.171093 (* 1 = 0.171093 loss)
I0502 11:16:06.339898 26473 solver.cpp:242] Iteration 38000 (82.2319 iter/s, 1.21607s/100 iter), loss = 0.171852
I0502 11:16:06.339917 26473 solver.cpp:261]     Train net output #0: loss = 0.171852 (* 1 = 0.171852 loss)
I0502 11:16:06.339926 26473 sgd_solver.cpp:106] Iteration 38000, lr = 5.12e-05
I0502 11:16:07.289224 26473 solver.cpp:242] Iteration 38100 (92.0006 iter/s, 1.08695s/100 iter), loss = 0.865613
I0502 11:16:07.289254 26473 solver.cpp:261]     Train net output #0: loss = 0.865613 (* 1 = 0.865613 loss)
I0502 11:16:07.289263 26473 sgd_solver.cpp:106] Iteration 38100, lr = 5.12e-05
I0502 11:16:07.294173 26473 solver.cpp:242] Iteration 38100 (104.796 iter/s, 0.954237s/100 iter), loss = 0.151393
I0502 11:16:07.294194 26473 solver.cpp:261]     Train net output #0: loss = 0.151393 (* 1 = 0.151393 loss)
I0502 11:16:07.294203 26473 sgd_solver.cpp:106] Iteration 38100, lr = 5.12e-05
I0502 11:16:08.245607 26473 solver.cpp:242] Iteration 38200 (104.566 iter/s, 0.956331s/100 iter), loss = 0.436625
I0502 11:16:08.245649 26473 solver.cpp:261]     Train net output #0: loss = 0.436625 (* 1 = 0.436625 loss)
I0502 11:16:08.245658 26473 sgd_solver.cpp:106] Iteration 38200, lr = 5.12e-05
I0502 11:16:08.250457 26473 solver.cpp:242] Iteration 38200 (104.576 iter/s, 0.956243s/100 iter), loss = 0.161835
I0502 11:16:08.250479 26473 solver.cpp:261]     Train net output #0: loss = 0.161835 (* 1 = 0.161835 loss)
I0502 11:16:08.250496 26473 sgd_solver.cpp:106] Iteration 38200, lr = 5.12e-05
I0502 11:16:09.200237 26473 solver.cpp:242] Iteration 38300 (104.76 iter/s, 0.954565s/100 iter), loss = 0.180769
I0502 11:16:09.200279 26473 solver.cpp:261]     Train net output #0: loss = 0.180769 (* 1 = 0.180769 loss)
I0502 11:16:09.200287 26473 sgd_solver.cpp:106] Iteration 38300, lr = 5.12e-05
I0502 11:16:09.205128 26473 solver.cpp:242] Iteration 38300 (104.753 iter/s, 0.954631s/100 iter), loss = 0.166843
I0502 11:16:09.205152 26473 solver.cpp:261]     Train net output #0: loss = 0.166843 (* 1 = 0.166843 loss)
I0502 11:16:09.205160 26473 sgd_solver.cpp:106] Iteration 38300, lr = 5.12e-05
I0502 11:16:10.154350 26473 solver.cpp:242] Iteration 38400 (104.816 iter/s, 0.954049s/100 iter), loss = 0.525761
I0502 11:16:10.154408 26473 solver.cpp:261]     Train net output #0: loss = 0.525761 (* 1 = 0.525761 loss)
I0502 11:16:10.154417 26473 sgd_solver.cpp:106] Iteration 38400, lr = 5.12e-05
I0502 11:16:10.159277 26473 solver.cpp:242] Iteration 38400 (104.81 iter/s, 0.954108s/100 iter), loss = 0.154074
I0502 11:16:10.159301 26473 solver.cpp:261]     Train net output #0: loss = 0.154074 (* 1 = 0.154074 loss)
I0502 11:16:10.159310 26473 sgd_solver.cpp:106] Iteration 38400, lr = 5.12e-05
I0502 11:16:11.106178 26473 solver.cpp:362] Iteration 38500, Testing net (#0)
I0502 11:16:11.106206 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:11.232192 26473 solver.cpp:429]     Test net output #0: loss = 0.480016 (* 1 = 0.480016 loss)
I0502 11:16:11.235148 26473 solver.cpp:242] Iteration 38500 (92.5308 iter/s, 1.08072s/100 iter), loss = 0.346764
I0502 11:16:11.235168 26473 solver.cpp:261]     Train net output #0: loss = 0.346764 (* 1 = 0.346764 loss)
I0502 11:16:11.235177 26473 sgd_solver.cpp:106] Iteration 38500, lr = 5.12e-05
I0502 11:16:11.236912 26473 solver.cpp:362] Iteration 38500, Testing net (#0)
I0502 11:16:11.236927 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:11.369552 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9215
I0502 11:16:11.369570 26473 solver.cpp:429]     Test net output #1: loss = 0.161301 (* 1 = 0.161301 loss)
I0502 11:16:11.372534 26473 solver.cpp:242] Iteration 38500 (82.4259 iter/s, 1.21321s/100 iter), loss = 0.106773
I0502 11:16:11.372556 26473 solver.cpp:261]     Train net output #0: loss = 0.106773 (* 1 = 0.106773 loss)
I0502 11:16:11.372566 26473 sgd_solver.cpp:106] Iteration 38500, lr = 5.12e-05
I0502 11:16:12.323915 26473 solver.cpp:242] Iteration 38600 (91.8509 iter/s, 1.08872s/100 iter), loss = 1.02305
I0502 11:16:12.323958 26473 solver.cpp:261]     Train net output #0: loss = 1.02305 (* 1 = 1.02305 loss)
I0502 11:16:12.323967 26473 sgd_solver.cpp:106] Iteration 38600, lr = 5.12e-05
I0502 11:16:12.328817 26473 solver.cpp:242] Iteration 38600 (104.576 iter/s, 0.956245s/100 iter), loss = 0.272318
I0502 11:16:12.328840 26473 solver.cpp:261]     Train net output #0: loss = 0.272318 (* 1 = 0.272318 loss)
I0502 11:16:12.328848 26473 sgd_solver.cpp:106] Iteration 38600, lr = 5.12e-05
I0502 11:16:13.278434 26473 solver.cpp:242] Iteration 38700 (104.772 iter/s, 0.954454s/100 iter), loss = 0.332025
I0502 11:16:13.278476 26473 solver.cpp:261]     Train net output #0: loss = 0.332025 (* 1 = 0.332025 loss)
I0502 11:16:13.278486 26473 sgd_solver.cpp:106] Iteration 38700, lr = 5.12e-05
I0502 11:16:13.283308 26473 solver.cpp:242] Iteration 38700 (104.772 iter/s, 0.954449s/100 iter), loss = 0.116803
I0502 11:16:13.283331 26473 solver.cpp:261]     Train net output #0: loss = 0.116803 (* 1 = 0.116803 loss)
I0502 11:16:13.283340 26473 sgd_solver.cpp:106] Iteration 38700, lr = 5.12e-05
I0502 11:16:14.234082 26473 solver.cpp:242] Iteration 38800 (104.648 iter/s, 0.955584s/100 iter), loss = 0.295294
I0502 11:16:14.234125 26473 solver.cpp:261]     Train net output #0: loss = 0.295294 (* 1 = 0.295294 loss)
I0502 11:16:14.234134 26473 sgd_solver.cpp:106] Iteration 38800, lr = 5.12e-05
I0502 11:16:14.238981 26473 solver.cpp:242] Iteration 38800 (104.643 iter/s, 0.95563s/100 iter), loss = 0.104322
I0502 11:16:14.239014 26473 solver.cpp:261]     Train net output #0: loss = 0.104322 (* 1 = 0.104322 loss)
I0502 11:16:14.239023 26473 sgd_solver.cpp:106] Iteration 38800, lr = 5.12e-05
I0502 11:16:15.189177 26473 solver.cpp:242] Iteration 38900 (104.709 iter/s, 0.955029s/100 iter), loss = 0.823508
I0502 11:16:15.189229 26473 solver.cpp:261]     Train net output #0: loss = 0.823508 (* 1 = 0.823508 loss)
I0502 11:16:15.189239 26473 sgd_solver.cpp:106] Iteration 38900, lr = 5.12e-05
I0502 11:16:15.194077 26473 solver.cpp:242] Iteration 38900 (104.707 iter/s, 0.955044s/100 iter), loss = 0.179182
I0502 11:16:15.194099 26473 solver.cpp:261]     Train net output #0: loss = 0.179182 (* 1 = 0.179182 loss)
I0502 11:16:15.194108 26473 sgd_solver.cpp:106] Iteration 38900, lr = 5.12e-05
I0502 11:16:16.142756 26473 solver.cpp:362] Iteration 39000, Testing net (#0)
I0502 11:16:16.142782 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:16.269127 26473 solver.cpp:429]     Test net output #0: loss = 0.395014 (* 1 = 0.395014 loss)
I0502 11:16:16.272045 26473 solver.cpp:242] Iteration 39000 (92.3534 iter/s, 1.0828s/100 iter), loss = 0.131385
I0502 11:16:16.272066 26473 solver.cpp:261]     Train net output #0: loss = 0.131385 (* 1 = 0.131385 loss)
I0502 11:16:16.272074 26473 sgd_solver.cpp:106] Iteration 39000, lr = 5.12e-05
I0502 11:16:16.273804 26473 solver.cpp:362] Iteration 39000, Testing net (#0)
I0502 11:16:16.273819 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:16.406472 26473 solver.cpp:429]     Test net output #0: accuracy = 0.924
I0502 11:16:16.406494 26473 solver.cpp:429]     Test net output #1: loss = 0.179312 (* 1 = 0.179312 loss)
I0502 11:16:16.409456 26473 solver.cpp:242] Iteration 39000 (82.2818 iter/s, 1.21534s/100 iter), loss = 0.117784
I0502 11:16:16.409476 26473 solver.cpp:261]     Train net output #0: loss = 0.117784 (* 1 = 0.117784 loss)
I0502 11:16:16.409485 26473 sgd_solver.cpp:106] Iteration 39000, lr = 5.12e-05
I0502 11:16:17.358897 26473 solver.cpp:242] Iteration 39100 (92.0127 iter/s, 1.08681s/100 iter), loss = 0.150298
I0502 11:16:17.358938 26473 solver.cpp:261]     Train net output #0: loss = 0.150298 (* 1 = 0.150298 loss)
I0502 11:16:17.358947 26473 sgd_solver.cpp:106] Iteration 39100, lr = 5.12e-05
I0502 11:16:17.363864 26473 solver.cpp:242] Iteration 39100 (104.782 iter/s, 0.954362s/100 iter), loss = 0.48538
I0502 11:16:17.363889 26473 solver.cpp:261]     Train net output #0: loss = 0.48538 (* 1 = 0.48538 loss)
I0502 11:16:17.363898 26473 sgd_solver.cpp:106] Iteration 39100, lr = 5.12e-05
I0502 11:16:18.313730 26473 solver.cpp:242] Iteration 39200 (104.737 iter/s, 0.95477s/100 iter), loss = 0.170346
I0502 11:16:18.313767 26473 solver.cpp:261]     Train net output #0: loss = 0.170346 (* 1 = 0.170346 loss)
I0502 11:16:18.313776 26473 sgd_solver.cpp:106] Iteration 39200, lr = 5.12e-05
I0502 11:16:18.318604 26473 solver.cpp:242] Iteration 39200 (104.745 iter/s, 0.954697s/100 iter), loss = 0.175252
I0502 11:16:18.318630 26473 solver.cpp:261]     Train net output #0: loss = 0.175252 (* 1 = 0.175252 loss)
I0502 11:16:18.318639 26473 sgd_solver.cpp:106] Iteration 39200, lr = 5.12e-05
I0502 11:16:19.268045 26473 solver.cpp:242] Iteration 39300 (104.794 iter/s, 0.954251s/100 iter), loss = 1.05936
I0502 11:16:19.268081 26473 solver.cpp:261]     Train net output #0: loss = 1.05936 (* 1 = 1.05936 loss)
I0502 11:16:19.268090 26473 sgd_solver.cpp:106] Iteration 39300, lr = 5.12e-05
I0502 11:16:19.272889 26473 solver.cpp:242] Iteration 39300 (104.795 iter/s, 0.954241s/100 iter), loss = 0.15199
I0502 11:16:19.272912 26473 solver.cpp:261]     Train net output #0: loss = 0.15199 (* 1 = 0.15199 loss)
I0502 11:16:19.272920 26473 sgd_solver.cpp:106] Iteration 39300, lr = 5.12e-05
I0502 11:16:20.221194 26473 solver.cpp:242] Iteration 39400 (104.922 iter/s, 0.953091s/100 iter), loss = 1.09836
I0502 11:16:20.221245 26473 solver.cpp:261]     Train net output #0: loss = 1.09836 (* 1 = 1.09836 loss)
I0502 11:16:20.221253 26473 sgd_solver.cpp:106] Iteration 39400, lr = 5.12e-05
I0502 11:16:20.226084 26473 solver.cpp:242] Iteration 39400 (104.915 iter/s, 0.953155s/100 iter), loss = 0.15717
I0502 11:16:20.226107 26473 solver.cpp:261]     Train net output #0: loss = 0.15717 (* 1 = 0.15717 loss)
I0502 11:16:20.226115 26473 sgd_solver.cpp:106] Iteration 39400, lr = 5.12e-05
I0502 11:16:21.171408 26473 solver.cpp:362] Iteration 39500, Testing net (#0)
I0502 11:16:21.171430 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:21.296977 26473 solver.cpp:429]     Test net output #0: loss = 0.490356 (* 1 = 0.490356 loss)
I0502 11:16:21.299887 26473 solver.cpp:242] Iteration 39500 (92.7108 iter/s, 1.07862s/100 iter), loss = 0.900693
I0502 11:16:21.299907 26473 solver.cpp:261]     Train net output #0: loss = 0.900693 (* 1 = 0.900693 loss)
I0502 11:16:21.299916 26473 sgd_solver.cpp:106] Iteration 39500, lr = 5.12e-05
I0502 11:16:21.301570 26473 solver.cpp:362] Iteration 39500, Testing net (#0)
I0502 11:16:21.301584 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:21.433593 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9175
I0502 11:16:21.433614 26473 solver.cpp:429]     Test net output #1: loss = 0.195521 (* 1 = 0.195521 loss)
I0502 11:16:21.436565 26473 solver.cpp:242] Iteration 39500 (82.6148 iter/s, 1.21044s/100 iter), loss = 0.185487
I0502 11:16:21.436585 26473 solver.cpp:261]     Train net output #0: loss = 0.185487 (* 1 = 0.185487 loss)
I0502 11:16:21.436594 26473 sgd_solver.cpp:106] Iteration 39500, lr = 5.12e-05
I0502 11:16:22.385879 26473 solver.cpp:242] Iteration 39600 (92.0856 iter/s, 1.08595s/100 iter), loss = 0.151352
I0502 11:16:22.385915 26473 solver.cpp:261]     Train net output #0: loss = 0.151352 (* 1 = 0.151352 loss)
I0502 11:16:22.385924 26473 sgd_solver.cpp:106] Iteration 39600, lr = 5.12e-05
I0502 11:16:22.390807 26473 solver.cpp:242] Iteration 39600 (104.799 iter/s, 0.954204s/100 iter), loss = 0.0411029
I0502 11:16:22.390830 26473 solver.cpp:261]     Train net output #0: loss = 0.0411029 (* 1 = 0.0411029 loss)
I0502 11:16:22.390839 26473 sgd_solver.cpp:106] Iteration 39600, lr = 5.12e-05
I0502 11:16:23.339293 26473 solver.cpp:242] Iteration 39700 (104.892 iter/s, 0.953357s/100 iter), loss = 0.55317
I0502 11:16:23.339328 26473 solver.cpp:261]     Train net output #0: loss = 0.55317 (* 1 = 0.55317 loss)
I0502 11:16:23.339336 26473 sgd_solver.cpp:106] Iteration 39700, lr = 5.12e-05
I0502 11:16:23.344260 26473 solver.cpp:242] Iteration 39700 (104.887 iter/s, 0.953411s/100 iter), loss = 0.170582
I0502 11:16:23.344285 26473 solver.cpp:261]     Train net output #0: loss = 0.170582 (* 1 = 0.170582 loss)
I0502 11:16:23.344293 26473 sgd_solver.cpp:106] Iteration 39700, lr = 5.12e-05
I0502 11:16:24.405392 26473 solver.cpp:242] Iteration 39800 (93.805 iter/s, 1.06604s/100 iter), loss = 0.266879
I0502 11:16:24.405433 26473 solver.cpp:261]     Train net output #0: loss = 0.266879 (* 1 = 0.266879 loss)
I0502 11:16:24.405444 26473 sgd_solver.cpp:106] Iteration 39800, lr = 5.12e-05
I0502 11:16:24.410856 26473 solver.cpp:242] Iteration 39800 (93.7602 iter/s, 1.06655s/100 iter), loss = 0.24331
I0502 11:16:24.410882 26473 solver.cpp:261]     Train net output #0: loss = 0.24331 (* 1 = 0.24331 loss)
I0502 11:16:24.410892 26473 sgd_solver.cpp:106] Iteration 39800, lr = 5.12e-05
I0502 11:16:25.451525 26473 solver.cpp:242] Iteration 39900 (95.5958 iter/s, 1.04607s/100 iter), loss = 0.334683
I0502 11:16:25.451560 26473 solver.cpp:261]     Train net output #0: loss = 0.334683 (* 1 = 0.334683 loss)
I0502 11:16:25.451570 26473 sgd_solver.cpp:106] Iteration 39900, lr = 5.12e-05
I0502 11:16:25.456346 26473 solver.cpp:242] Iteration 39900 (95.6531 iter/s, 1.04544s/100 iter), loss = 0.325323
I0502 11:16:25.456367 26473 solver.cpp:261]     Train net output #0: loss = 0.325323 (* 1 = 0.325323 loss)
I0502 11:16:25.456377 26473 sgd_solver.cpp:106] Iteration 39900, lr = 5.12e-05
I0502 11:16:26.402654 26473 solver.cpp:362] Iteration 40000, Testing net (#0)
I0502 11:16:26.402678 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:26.527698 26473 solver.cpp:429]     Test net output #0: loss = 0.409259 (* 1 = 0.409259 loss)
I0502 11:16:26.530577 26473 solver.cpp:242] Iteration 40000 (92.6785 iter/s, 1.079s/100 iter), loss = 0.202888
I0502 11:16:26.530598 26473 solver.cpp:261]     Train net output #0: loss = 0.202888 (* 1 = 0.202888 loss)
I0502 11:16:26.530607 26473 sgd_solver.cpp:106] Iteration 40000, lr = 4.096e-05
I0502 11:16:26.532269 26473 solver.cpp:362] Iteration 40000, Testing net (#0)
I0502 11:16:26.532284 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:26.663516 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9165
I0502 11:16:26.663537 26473 solver.cpp:429]     Test net output #1: loss = 0.183945 (* 1 = 0.183945 loss)
I0502 11:16:26.666463 26473 solver.cpp:242] Iteration 40000 (82.6396 iter/s, 1.21007s/100 iter), loss = 0.188213
I0502 11:16:26.666483 26473 solver.cpp:261]     Train net output #0: loss = 0.188213 (* 1 = 0.188213 loss)
I0502 11:16:26.666492 26473 sgd_solver.cpp:106] Iteration 40000, lr = 4.096e-05
I0502 11:16:27.618441 26473 solver.cpp:242] Iteration 40100 (91.927 iter/s, 1.08782s/100 iter), loss = 0.49347
I0502 11:16:27.618480 26473 solver.cpp:261]     Train net output #0: loss = 0.49347 (* 1 = 0.49347 loss)
I0502 11:16:27.618489 26473 sgd_solver.cpp:106] Iteration 40100, lr = 4.096e-05
I0502 11:16:27.623288 26473 solver.cpp:242] Iteration 40100 (104.517 iter/s, 0.956787s/100 iter), loss = 0.165789
I0502 11:16:27.623311 26473 solver.cpp:261]     Train net output #0: loss = 0.165789 (* 1 = 0.165789 loss)
I0502 11:16:27.623320 26473 sgd_solver.cpp:106] Iteration 40100, lr = 4.096e-05
I0502 11:16:28.573941 26473 solver.cpp:242] Iteration 40200 (104.664 iter/s, 0.955439s/100 iter), loss = 0.232502
I0502 11:16:28.573974 26473 solver.cpp:261]     Train net output #0: loss = 0.232502 (* 1 = 0.232502 loss)
I0502 11:16:28.573983 26473 sgd_solver.cpp:106] Iteration 40200, lr = 4.096e-05
I0502 11:16:28.578878 26473 solver.cpp:242] Iteration 40200 (104.652 iter/s, 0.955549s/100 iter), loss = 0.161082
I0502 11:16:28.578902 26473 solver.cpp:261]     Train net output #0: loss = 0.161082 (* 1 = 0.161082 loss)
I0502 11:16:28.578910 26473 sgd_solver.cpp:106] Iteration 40200, lr = 4.096e-05
I0502 11:16:29.530709 26473 solver.cpp:242] Iteration 40300 (104.524 iter/s, 0.956714s/100 iter), loss = 0.337884
I0502 11:16:29.530737 26473 solver.cpp:261]     Train net output #0: loss = 0.337884 (* 1 = 0.337884 loss)
I0502 11:16:29.530746 26473 sgd_solver.cpp:106] Iteration 40300, lr = 4.096e-05
I0502 11:16:29.535552 26473 solver.cpp:242] Iteration 40300 (104.534 iter/s, 0.956631s/100 iter), loss = 0.0713402
I0502 11:16:29.535575 26473 solver.cpp:261]     Train net output #0: loss = 0.0713402 (* 1 = 0.0713402 loss)
I0502 11:16:29.535583 26473 sgd_solver.cpp:106] Iteration 40300, lr = 4.096e-05
I0502 11:16:30.487846 26473 solver.cpp:242] Iteration 40400 (104.484 iter/s, 0.957086s/100 iter), loss = 0.0958212
I0502 11:16:30.487890 26473 solver.cpp:261]     Train net output #0: loss = 0.0958212 (* 1 = 0.0958212 loss)
I0502 11:16:30.487897 26473 sgd_solver.cpp:106] Iteration 40400, lr = 4.096e-05
I0502 11:16:30.492717 26473 solver.cpp:242] Iteration 40400 (104.48 iter/s, 0.957124s/100 iter), loss = 0.0258098
I0502 11:16:30.492740 26473 solver.cpp:261]     Train net output #0: loss = 0.0258098 (* 1 = 0.0258098 loss)
I0502 11:16:30.492749 26473 sgd_solver.cpp:106] Iteration 40400, lr = 4.096e-05
I0502 11:16:31.438846 26473 solver.cpp:362] Iteration 40500, Testing net (#0)
I0502 11:16:31.438875 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:31.564496 26473 solver.cpp:429]     Test net output #0: loss = 0.569496 (* 1 = 0.569496 loss)
I0502 11:16:31.567385 26473 solver.cpp:242] Iteration 40500 (92.6373 iter/s, 1.07948s/100 iter), loss = 0.33778
I0502 11:16:31.567405 26473 solver.cpp:261]     Train net output #0: loss = 0.33778 (* 1 = 0.33778 loss)
I0502 11:16:31.567414 26473 sgd_solver.cpp:106] Iteration 40500, lr = 4.096e-05
I0502 11:16:31.569069 26473 solver.cpp:362] Iteration 40500, Testing net (#0)
I0502 11:16:31.569083 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:31.701501 26473 solver.cpp:429]     Test net output #0: accuracy = 0.909
I0502 11:16:31.701522 26473 solver.cpp:429]     Test net output #1: loss = 0.204259 (* 1 = 0.204259 loss)
I0502 11:16:31.704481 26473 solver.cpp:242] Iteration 40500 (82.5273 iter/s, 1.21172s/100 iter), loss = 0.169805
I0502 11:16:31.704501 26473 solver.cpp:261]     Train net output #0: loss = 0.169805 (* 1 = 0.169805 loss)
I0502 11:16:31.704510 26473 sgd_solver.cpp:106] Iteration 40500, lr = 4.096e-05
I0502 11:16:32.653758 26473 solver.cpp:242] Iteration 40600 (92.0532 iter/s, 1.08633s/100 iter), loss = 0.806838
I0502 11:16:32.653790 26473 solver.cpp:261]     Train net output #0: loss = 0.806838 (* 1 = 0.806838 loss)
I0502 11:16:32.653798 26473 sgd_solver.cpp:106] Iteration 40600, lr = 4.096e-05
I0502 11:16:32.658578 26473 solver.cpp:242] Iteration 40600 (104.815 iter/s, 0.954058s/100 iter), loss = 0.290537
I0502 11:16:32.658601 26473 solver.cpp:261]     Train net output #0: loss = 0.290537 (* 1 = 0.290537 loss)
I0502 11:16:32.658609 26473 sgd_solver.cpp:106] Iteration 40600, lr = 4.096e-05
I0502 11:16:33.607511 26473 solver.cpp:242] Iteration 40700 (104.855 iter/s, 0.9537s/100 iter), loss = 0.336144
I0502 11:16:33.607545 26473 solver.cpp:261]     Train net output #0: loss = 0.336144 (* 1 = 0.336144 loss)
I0502 11:16:33.607554 26473 sgd_solver.cpp:106] Iteration 40700, lr = 4.096e-05
I0502 11:16:33.612416 26473 solver.cpp:242] Iteration 40700 (104.844 iter/s, 0.953796s/100 iter), loss = 0.13182
I0502 11:16:33.612437 26473 solver.cpp:261]     Train net output #0: loss = 0.13182 (* 1 = 0.13182 loss)
I0502 11:16:33.612445 26473 sgd_solver.cpp:106] Iteration 40700, lr = 4.096e-05
I0502 11:16:34.561728 26473 solver.cpp:242] Iteration 40800 (104.804 iter/s, 0.95416s/100 iter), loss = 0.183395
I0502 11:16:34.561767 26473 solver.cpp:261]     Train net output #0: loss = 0.183395 (* 1 = 0.183395 loss)
I0502 11:16:34.561776 26473 sgd_solver.cpp:106] Iteration 40800, lr = 4.096e-05
I0502 11:16:34.566570 26473 solver.cpp:242] Iteration 40800 (104.809 iter/s, 0.954115s/100 iter), loss = 0.23461
I0502 11:16:34.566593 26473 solver.cpp:261]     Train net output #0: loss = 0.23461 (* 1 = 0.23461 loss)
I0502 11:16:34.566601 26473 sgd_solver.cpp:106] Iteration 40800, lr = 4.096e-05
I0502 11:16:35.514492 26473 solver.cpp:242] Iteration 40900 (104.965 iter/s, 0.952703s/100 iter), loss = 0.328744
I0502 11:16:35.514545 26473 solver.cpp:261]     Train net output #0: loss = 0.328744 (* 1 = 0.328744 loss)
I0502 11:16:35.514554 26473 sgd_solver.cpp:106] Iteration 40900, lr = 4.096e-05
I0502 11:16:35.519387 26473 solver.cpp:242] Iteration 40900 (104.957 iter/s, 0.952774s/100 iter), loss = 0.218798
I0502 11:16:35.519409 26473 solver.cpp:261]     Train net output #0: loss = 0.218798 (* 1 = 0.218798 loss)
I0502 11:16:35.519418 26473 sgd_solver.cpp:106] Iteration 40900, lr = 4.096e-05
I0502 11:16:36.465065 26473 solver.cpp:362] Iteration 41000, Testing net (#0)
I0502 11:16:36.465091 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:36.590770 26473 solver.cpp:429]     Test net output #0: loss = 0.657471 (* 1 = 0.657471 loss)
I0502 11:16:36.593685 26473 solver.cpp:242] Iteration 41000 (92.668 iter/s, 1.07912s/100 iter), loss = 0.465641
I0502 11:16:36.593705 26473 solver.cpp:261]     Train net output #0: loss = 0.465641 (* 1 = 0.465641 loss)
I0502 11:16:36.593714 26473 sgd_solver.cpp:106] Iteration 41000, lr = 4.096e-05
I0502 11:16:36.595366 26473 solver.cpp:362] Iteration 41000, Testing net (#0)
I0502 11:16:36.595378 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:36.727825 26473 solver.cpp:429]     Test net output #0: accuracy = 0.906
I0502 11:16:36.727846 26473 solver.cpp:429]     Test net output #1: loss = 0.211817 (* 1 = 0.211817 loss)
I0502 11:16:36.730810 26473 solver.cpp:242] Iteration 41000 (82.5505 iter/s, 1.21138s/100 iter), loss = 0.386974
I0502 11:16:36.730831 26473 solver.cpp:261]     Train net output #0: loss = 0.386974 (* 1 = 0.386974 loss)
I0502 11:16:36.730840 26473 sgd_solver.cpp:106] Iteration 41000, lr = 4.096e-05
I0502 11:16:37.680099 26473 solver.cpp:242] Iteration 41100 (92.0499 iter/s, 1.08637s/100 iter), loss = 0.265459
I0502 11:16:37.680141 26473 solver.cpp:261]     Train net output #0: loss = 0.265459 (* 1 = 0.265459 loss)
I0502 11:16:37.680150 26473 sgd_solver.cpp:106] Iteration 41100, lr = 4.096e-05
I0502 11:16:37.684976 26473 solver.cpp:242] Iteration 41100 (104.809 iter/s, 0.954119s/100 iter), loss = 0.0845986
I0502 11:16:37.685000 26473 solver.cpp:261]     Train net output #0: loss = 0.0845986 (* 1 = 0.0845986 loss)
I0502 11:16:37.685009 26473 sgd_solver.cpp:106] Iteration 41100, lr = 4.096e-05
I0502 11:16:38.632719 26473 solver.cpp:242] Iteration 41200 (104.981 iter/s, 0.952556s/100 iter), loss = 0.230352
I0502 11:16:38.632761 26473 solver.cpp:261]     Train net output #0: loss = 0.230352 (* 1 = 0.230352 loss)
I0502 11:16:38.632768 26473 sgd_solver.cpp:106] Iteration 41200, lr = 4.096e-05
I0502 11:16:38.637666 26473 solver.cpp:242] Iteration 41200 (104.97 iter/s, 0.952649s/100 iter), loss = 0.171753
I0502 11:16:38.637691 26473 solver.cpp:261]     Train net output #0: loss = 0.171753 (* 1 = 0.171753 loss)
I0502 11:16:38.637698 26473 sgd_solver.cpp:106] Iteration 41200, lr = 4.096e-05
I0502 11:16:39.606812 26473 solver.cpp:242] Iteration 41300 (102.666 iter/s, 0.97403s/100 iter), loss = 0.199164
I0502 11:16:39.606856 26473 solver.cpp:261]     Train net output #0: loss = 0.199164 (* 1 = 0.199164 loss)
I0502 11:16:39.606865 26473 sgd_solver.cpp:106] Iteration 41300, lr = 4.096e-05
I0502 11:16:39.611686 26473 solver.cpp:242] Iteration 41300 (102.672 iter/s, 0.973978s/100 iter), loss = 0.10198
I0502 11:16:39.611712 26473 solver.cpp:261]     Train net output #0: loss = 0.10198 (* 1 = 0.10198 loss)
I0502 11:16:39.611721 26473 sgd_solver.cpp:106] Iteration 41300, lr = 4.096e-05
I0502 11:16:40.560142 26473 solver.cpp:242] Iteration 41400 (104.903 iter/s, 0.953265s/100 iter), loss = 0.26464
I0502 11:16:40.560196 26473 solver.cpp:261]     Train net output #0: loss = 0.26464 (* 1 = 0.26464 loss)
I0502 11:16:40.560205 26473 sgd_solver.cpp:106] Iteration 41400, lr = 4.096e-05
I0502 11:16:40.565039 26473 solver.cpp:242] Iteration 41400 (104.898 iter/s, 0.953308s/100 iter), loss = 0.15011
I0502 11:16:40.565062 26473 solver.cpp:261]     Train net output #0: loss = 0.15011 (* 1 = 0.15011 loss)
I0502 11:16:40.565071 26473 sgd_solver.cpp:106] Iteration 41400, lr = 4.096e-05
I0502 11:16:41.510627 26473 solver.cpp:362] Iteration 41500, Testing net (#0)
I0502 11:16:41.510651 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:41.636005 26473 solver.cpp:429]     Test net output #0: loss = 0.427845 (* 1 = 0.427845 loss)
I0502 11:16:41.638911 26473 solver.cpp:242] Iteration 41500 (92.7045 iter/s, 1.0787s/100 iter), loss = 0.301327
I0502 11:16:41.638933 26473 solver.cpp:261]     Train net output #0: loss = 0.301327 (* 1 = 0.301327 loss)
I0502 11:16:41.638942 26473 sgd_solver.cpp:106] Iteration 41500, lr = 4.096e-05
I0502 11:16:41.640647 26473 solver.cpp:362] Iteration 41500, Testing net (#0)
I0502 11:16:41.640661 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:41.772806 26473 solver.cpp:429]     Test net output #0: accuracy = 0.931
I0502 11:16:41.772835 26473 solver.cpp:429]     Test net output #1: loss = 0.156278 (* 1 = 0.156278 loss)
I0502 11:16:41.775789 26473 solver.cpp:242] Iteration 41500 (82.5965 iter/s, 1.2107s/100 iter), loss = 0.0963389
I0502 11:16:41.775810 26473 solver.cpp:261]     Train net output #0: loss = 0.0963389 (* 1 = 0.0963389 loss)
I0502 11:16:41.775818 26473 sgd_solver.cpp:106] Iteration 41500, lr = 4.096e-05
I0502 11:16:42.724211 26473 solver.cpp:242] Iteration 41600 (92.1443 iter/s, 1.08525s/100 iter), loss = 0.216252
I0502 11:16:42.724251 26473 solver.cpp:261]     Train net output #0: loss = 0.216252 (* 1 = 0.216252 loss)
I0502 11:16:42.724261 26473 sgd_solver.cpp:106] Iteration 41600, lr = 4.096e-05
I0502 11:16:42.729061 26473 solver.cpp:242] Iteration 41600 (104.906 iter/s, 0.953232s/100 iter), loss = 0.197731
I0502 11:16:42.729084 26473 solver.cpp:261]     Train net output #0: loss = 0.197731 (* 1 = 0.197731 loss)
I0502 11:16:42.729101 26473 sgd_solver.cpp:106] Iteration 41600, lr = 4.096e-05
I0502 11:16:43.677912 26473 solver.cpp:242] Iteration 41700 (104.862 iter/s, 0.953638s/100 iter), loss = 0.113027
I0502 11:16:43.677953 26473 solver.cpp:261]     Train net output #0: loss = 0.113027 (* 1 = 0.113027 loss)
I0502 11:16:43.677973 26473 sgd_solver.cpp:106] Iteration 41700, lr = 4.096e-05
I0502 11:16:43.682858 26473 solver.cpp:242] Iteration 41700 (104.849 iter/s, 0.953756s/100 iter), loss = 0.134683
I0502 11:16:43.682883 26473 solver.cpp:261]     Train net output #0: loss = 0.134683 (* 1 = 0.134683 loss)
I0502 11:16:43.682890 26473 sgd_solver.cpp:106] Iteration 41700, lr = 4.096e-05
I0502 11:16:44.630494 26473 solver.cpp:242] Iteration 41800 (104.984 iter/s, 0.952523s/100 iter), loss = 0.346377
I0502 11:16:44.630532 26473 solver.cpp:261]     Train net output #0: loss = 0.346377 (* 1 = 0.346377 loss)
I0502 11:16:44.630540 26473 sgd_solver.cpp:106] Iteration 41800, lr = 4.096e-05
I0502 11:16:44.635335 26473 solver.cpp:242] Iteration 41800 (104.994 iter/s, 0.952435s/100 iter), loss = 0.177914
I0502 11:16:44.635359 26473 solver.cpp:261]     Train net output #0: loss = 0.177914 (* 1 = 0.177914 loss)
I0502 11:16:44.635366 26473 sgd_solver.cpp:106] Iteration 41800, lr = 4.096e-05
I0502 11:16:45.584146 26473 solver.cpp:242] Iteration 41900 (104.867 iter/s, 0.953591s/100 iter), loss = 0.263715
I0502 11:16:45.584205 26473 solver.cpp:261]     Train net output #0: loss = 0.263715 (* 1 = 0.263715 loss)
I0502 11:16:45.584223 26473 sgd_solver.cpp:106] Iteration 41900, lr = 4.096e-05
I0502 11:16:45.589058 26473 solver.cpp:242] Iteration 41900 (104.857 iter/s, 0.953682s/100 iter), loss = 0.11839
I0502 11:16:45.589082 26473 solver.cpp:261]     Train net output #0: loss = 0.11839 (* 1 = 0.11839 loss)
I0502 11:16:45.589092 26473 sgd_solver.cpp:106] Iteration 41900, lr = 4.096e-05
I0502 11:16:46.534294 26473 solver.cpp:362] Iteration 42000, Testing net (#0)
I0502 11:16:46.534317 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:46.659260 26473 solver.cpp:429]     Test net output #0: loss = 0.345335 (* 1 = 0.345335 loss)
I0502 11:16:46.662158 26473 solver.cpp:242] Iteration 42000 (92.7701 iter/s, 1.07793s/100 iter), loss = 0.219995
I0502 11:16:46.662180 26473 solver.cpp:261]     Train net output #0: loss = 0.219995 (* 1 = 0.219995 loss)
I0502 11:16:46.662189 26473 sgd_solver.cpp:106] Iteration 42000, lr = 4.096e-05
I0502 11:16:46.663856 26473 solver.cpp:362] Iteration 42000, Testing net (#0)
I0502 11:16:46.663871 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:46.795011 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9315
I0502 11:16:46.795032 26473 solver.cpp:429]     Test net output #1: loss = 0.139714 (* 1 = 0.139714 loss)
I0502 11:16:46.797960 26473 solver.cpp:242] Iteration 42000 (82.7229 iter/s, 1.20886s/100 iter), loss = 0.308876
I0502 11:16:46.797979 26473 solver.cpp:261]     Train net output #0: loss = 0.308876 (* 1 = 0.308876 loss)
I0502 11:16:46.797988 26473 sgd_solver.cpp:106] Iteration 42000, lr = 4.096e-05
I0502 11:16:47.761970 26473 solver.cpp:242] Iteration 42100 (90.9287 iter/s, 1.09976s/100 iter), loss = 0.465589
I0502 11:16:47.762019 26473 solver.cpp:261]     Train net output #0: loss = 0.465589 (* 1 = 0.465589 loss)
I0502 11:16:47.762030 26473 sgd_solver.cpp:106] Iteration 42100, lr = 4.096e-05
I0502 11:16:47.767434 26473 solver.cpp:242] Iteration 42100 (103.153 iter/s, 0.969435s/100 iter), loss = 0.0322373
I0502 11:16:47.767462 26473 solver.cpp:261]     Train net output #0: loss = 0.0322373 (* 1 = 0.0322373 loss)
I0502 11:16:47.767472 26473 sgd_solver.cpp:106] Iteration 42100, lr = 4.096e-05
I0502 11:16:48.838083 26473 solver.cpp:242] Iteration 42200 (92.9333 iter/s, 1.07604s/100 iter), loss = 0.462747
I0502 11:16:48.838127 26473 solver.cpp:261]     Train net output #0: loss = 0.462747 (* 1 = 0.462747 loss)
I0502 11:16:48.838138 26473 sgd_solver.cpp:106] Iteration 42200, lr = 4.096e-05
I0502 11:16:48.843634 26473 solver.cpp:242] Iteration 42200 (92.9236 iter/s, 1.07615s/100 iter), loss = 0.116137
I0502 11:16:48.843672 26473 solver.cpp:261]     Train net output #0: loss = 0.116137 (* 1 = 0.116137 loss)
I0502 11:16:48.843683 26473 sgd_solver.cpp:106] Iteration 42200, lr = 4.096e-05
I0502 11:16:49.889890 26473 solver.cpp:242] Iteration 42300 (95.0803 iter/s, 1.05174s/100 iter), loss = 0.211869
I0502 11:16:49.889927 26473 solver.cpp:261]     Train net output #0: loss = 0.211869 (* 1 = 0.211869 loss)
I0502 11:16:49.889936 26473 sgd_solver.cpp:106] Iteration 42300, lr = 4.096e-05
I0502 11:16:49.894876 26473 solver.cpp:242] Iteration 42300 (95.1307 iter/s, 1.05119s/100 iter), loss = 0.160156
I0502 11:16:49.894899 26473 solver.cpp:261]     Train net output #0: loss = 0.160156 (* 1 = 0.160156 loss)
I0502 11:16:49.894908 26473 sgd_solver.cpp:106] Iteration 42300, lr = 4.096e-05
I0502 11:16:50.842648 26473 solver.cpp:242] Iteration 42400 (104.965 iter/s, 0.9527s/100 iter), loss = 1.35901
I0502 11:16:50.842681 26473 solver.cpp:261]     Train net output #0: loss = 1.35901 (* 1 = 1.35901 loss)
I0502 11:16:50.842690 26473 sgd_solver.cpp:106] Iteration 42400, lr = 4.096e-05
I0502 11:16:50.847472 26473 solver.cpp:242] Iteration 42400 (104.981 iter/s, 0.952555s/100 iter), loss = 0.0944113
I0502 11:16:50.847496 26473 solver.cpp:261]     Train net output #0: loss = 0.0944113 (* 1 = 0.0944113 loss)
I0502 11:16:50.847504 26473 sgd_solver.cpp:106] Iteration 42400, lr = 4.096e-05
I0502 11:16:51.791839 26473 solver.cpp:362] Iteration 42500, Testing net (#0)
I0502 11:16:51.791859 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:51.916862 26473 solver.cpp:429]     Test net output #0: loss = 0.695497 (* 1 = 0.695497 loss)
I0502 11:16:51.919740 26473 solver.cpp:242] Iteration 42500 (92.847 iter/s, 1.07704s/100 iter), loss = 0.721492
I0502 11:16:51.919760 26473 solver.cpp:261]     Train net output #0: loss = 0.721492 (* 1 = 0.721492 loss)
I0502 11:16:51.919769 26473 sgd_solver.cpp:106] Iteration 42500, lr = 4.096e-05
I0502 11:16:51.921421 26473 solver.cpp:362] Iteration 42500, Testing net (#0)
I0502 11:16:51.921433 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:52.052490 26473 solver.cpp:429]     Test net output #0: accuracy = 0.885
I0502 11:16:52.052510 26473 solver.cpp:429]     Test net output #1: loss = 0.248281 (* 1 = 0.248281 loss)
I0502 11:16:52.055431 26473 solver.cpp:242] Iteration 42500 (82.7873 iter/s, 1.20791s/100 iter), loss = 0.474346
I0502 11:16:52.055452 26473 solver.cpp:261]     Train net output #0: loss = 0.474346 (* 1 = 0.474346 loss)
I0502 11:16:52.055460 26473 sgd_solver.cpp:106] Iteration 42500, lr = 4.096e-05
I0502 11:16:53.003746 26473 solver.cpp:242] Iteration 42600 (92.2542 iter/s, 1.08396s/100 iter), loss = 0.233341
I0502 11:16:53.003782 26473 solver.cpp:261]     Train net output #0: loss = 0.233341 (* 1 = 0.233341 loss)
I0502 11:16:53.003790 26473 sgd_solver.cpp:106] Iteration 42600, lr = 4.096e-05
I0502 11:16:53.008605 26473 solver.cpp:242] Iteration 42600 (104.917 iter/s, 0.953134s/100 iter), loss = 0.066311
I0502 11:16:53.008628 26473 solver.cpp:261]     Train net output #0: loss = 0.066311 (* 1 = 0.066311 loss)
I0502 11:16:53.008636 26473 sgd_solver.cpp:106] Iteration 42600, lr = 4.096e-05
I0502 11:16:53.956274 26473 solver.cpp:242] Iteration 42700 (104.99 iter/s, 0.952472s/100 iter), loss = 0.287871
I0502 11:16:53.956307 26473 solver.cpp:261]     Train net output #0: loss = 0.287871 (* 1 = 0.287871 loss)
I0502 11:16:53.956316 26473 sgd_solver.cpp:106] Iteration 42700, lr = 4.096e-05
I0502 11:16:53.961164 26473 solver.cpp:242] Iteration 42700 (104.985 iter/s, 0.952518s/100 iter), loss = 0.149892
I0502 11:16:53.961186 26473 solver.cpp:261]     Train net output #0: loss = 0.149892 (* 1 = 0.149892 loss)
I0502 11:16:53.961195 26473 sgd_solver.cpp:106] Iteration 42700, lr = 4.096e-05
I0502 11:16:54.908816 26473 solver.cpp:242] Iteration 42800 (104.988 iter/s, 0.952488s/100 iter), loss = 0.319483
I0502 11:16:54.908846 26473 solver.cpp:261]     Train net output #0: loss = 0.319483 (* 1 = 0.319483 loss)
I0502 11:16:54.908862 26473 sgd_solver.cpp:106] Iteration 42800, lr = 4.096e-05
I0502 11:16:54.913722 26473 solver.cpp:242] Iteration 42800 (104.985 iter/s, 0.952518s/100 iter), loss = 0.0249073
I0502 11:16:54.913744 26473 solver.cpp:261]     Train net output #0: loss = 0.0249073 (* 1 = 0.0249073 loss)
I0502 11:16:54.913753 26473 sgd_solver.cpp:106] Iteration 42800, lr = 4.096e-05
I0502 11:16:55.861939 26473 solver.cpp:242] Iteration 42900 (104.924 iter/s, 0.953071s/100 iter), loss = 0.362287
I0502 11:16:55.861999 26473 solver.cpp:261]     Train net output #0: loss = 0.362287 (* 1 = 0.362287 loss)
I0502 11:16:55.862007 26473 sgd_solver.cpp:106] Iteration 42900, lr = 4.096e-05
I0502 11:16:55.866842 26473 solver.cpp:242] Iteration 42900 (104.923 iter/s, 0.95308s/100 iter), loss = 0.0369493
I0502 11:16:55.866866 26473 solver.cpp:261]     Train net output #0: loss = 0.0369493 (* 1 = 0.0369493 loss)
I0502 11:16:55.866875 26473 sgd_solver.cpp:106] Iteration 42900, lr = 4.096e-05
I0502 11:16:56.811638 26473 solver.cpp:362] Iteration 43000, Testing net (#0)
I0502 11:16:56.811666 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:56.936640 26473 solver.cpp:429]     Test net output #0: loss = 0.357682 (* 1 = 0.357682 loss)
I0502 11:16:56.939513 26473 solver.cpp:242] Iteration 43000 (92.8077 iter/s, 1.0775s/100 iter), loss = 0.121438
I0502 11:16:56.939534 26473 solver.cpp:261]     Train net output #0: loss = 0.121438 (* 1 = 0.121438 loss)
I0502 11:16:56.939543 26473 sgd_solver.cpp:106] Iteration 43000, lr = 4.096e-05
I0502 11:16:56.941198 26473 solver.cpp:362] Iteration 43000, Testing net (#0)
I0502 11:16:56.941211 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:16:57.072278 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9375
I0502 11:16:57.072298 26473 solver.cpp:429]     Test net output #1: loss = 0.132164 (* 1 = 0.132164 loss)
I0502 11:16:57.075222 26473 solver.cpp:242] Iteration 43000 (82.7586 iter/s, 1.20833s/100 iter), loss = 0.212536
I0502 11:16:57.075243 26473 solver.cpp:261]     Train net output #0: loss = 0.212536 (* 1 = 0.212536 loss)
I0502 11:16:57.075251 26473 sgd_solver.cpp:106] Iteration 43000, lr = 4.096e-05
I0502 11:16:58.022083 26473 solver.cpp:242] Iteration 43100 (92.3765 iter/s, 1.08253s/100 iter), loss = 0.279018
I0502 11:16:58.022114 26473 solver.cpp:261]     Train net output #0: loss = 0.279018 (* 1 = 0.279018 loss)
I0502 11:16:58.022122 26473 sgd_solver.cpp:106] Iteration 43100, lr = 4.096e-05
I0502 11:16:58.026928 26473 solver.cpp:242] Iteration 43100 (105.079 iter/s, 0.951667s/100 iter), loss = 0.173242
I0502 11:16:58.026950 26473 solver.cpp:261]     Train net output #0: loss = 0.173242 (* 1 = 0.173242 loss)
I0502 11:16:58.026959 26473 sgd_solver.cpp:106] Iteration 43100, lr = 4.096e-05
I0502 11:16:58.974151 26473 solver.cpp:242] Iteration 43200 (105.04 iter/s, 0.952016s/100 iter), loss = 0.22813
I0502 11:16:58.974179 26473 solver.cpp:261]     Train net output #0: loss = 0.22813 (* 1 = 0.22813 loss)
I0502 11:16:58.974189 26473 sgd_solver.cpp:106] Iteration 43200, lr = 4.096e-05
I0502 11:16:58.978971 26473 solver.cpp:242] Iteration 43200 (105.042 iter/s, 0.952003s/100 iter), loss = 0.0507913
I0502 11:16:58.978993 26473 solver.cpp:261]     Train net output #0: loss = 0.0507913 (* 1 = 0.0507913 loss)
I0502 11:16:58.979002 26473 sgd_solver.cpp:106] Iteration 43200, lr = 4.096e-05
I0502 11:16:59.926049 26473 solver.cpp:242] Iteration 43300 (105.059 iter/s, 0.951848s/100 iter), loss = 0.673443
I0502 11:16:59.926092 26473 solver.cpp:261]     Train net output #0: loss = 0.673443 (* 1 = 0.673443 loss)
I0502 11:16:59.926101 26473 sgd_solver.cpp:106] Iteration 43300, lr = 4.096e-05
I0502 11:16:59.930966 26473 solver.cpp:242] Iteration 43300 (105.047 iter/s, 0.951954s/100 iter), loss = 0.138904
I0502 11:16:59.930989 26473 solver.cpp:261]     Train net output #0: loss = 0.138904 (* 1 = 0.138904 loss)
I0502 11:16:59.930997 26473 sgd_solver.cpp:106] Iteration 43300, lr = 4.096e-05
I0502 11:17:00.892822 26473 solver.cpp:242] Iteration 43400 (103.444 iter/s, 0.966707s/100 iter), loss = 0.271288
I0502 11:17:00.892880 26473 solver.cpp:261]     Train net output #0: loss = 0.271288 (* 1 = 0.271288 loss)
I0502 11:17:00.892890 26473 sgd_solver.cpp:106] Iteration 43400, lr = 4.096e-05
I0502 11:17:00.897722 26473 solver.cpp:242] Iteration 43400 (103.443 iter/s, 0.966714s/100 iter), loss = 0.124435
I0502 11:17:00.897747 26473 solver.cpp:261]     Train net output #0: loss = 0.124435 (* 1 = 0.124435 loss)
I0502 11:17:00.897755 26473 sgd_solver.cpp:106] Iteration 43400, lr = 4.096e-05
I0502 11:17:01.842173 26473 solver.cpp:362] Iteration 43500, Testing net (#0)
I0502 11:17:01.842200 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:01.967109 26473 solver.cpp:429]     Test net output #0: loss = 0.385721 (* 1 = 0.385721 loss)
I0502 11:17:01.969990 26473 solver.cpp:242] Iteration 43500 (92.8425 iter/s, 1.07709s/100 iter), loss = 0.136832
I0502 11:17:01.970011 26473 solver.cpp:261]     Train net output #0: loss = 0.136832 (* 1 = 0.136832 loss)
I0502 11:17:01.970019 26473 sgd_solver.cpp:106] Iteration 43500, lr = 4.096e-05
I0502 11:17:01.971652 26473 solver.cpp:362] Iteration 43500, Testing net (#0)
I0502 11:17:01.971664 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:02.102692 26473 solver.cpp:429]     Test net output #0: accuracy = 0.935
I0502 11:17:02.102713 26473 solver.cpp:429]     Test net output #1: loss = 0.138129 (* 1 = 0.138129 loss)
I0502 11:17:02.105651 26473 solver.cpp:242] Iteration 43500 (82.7895 iter/s, 1.20788s/100 iter), loss = 0.122792
I0502 11:17:02.105671 26473 solver.cpp:261]     Train net output #0: loss = 0.122792 (* 1 = 0.122792 loss)
I0502 11:17:02.105679 26473 sgd_solver.cpp:106] Iteration 43500, lr = 4.096e-05
I0502 11:17:03.053520 26473 solver.cpp:242] Iteration 43600 (92.2948 iter/s, 1.08348s/100 iter), loss = 0.452138
I0502 11:17:03.053565 26473 solver.cpp:261]     Train net output #0: loss = 0.452138 (* 1 = 0.452138 loss)
I0502 11:17:03.053573 26473 sgd_solver.cpp:106] Iteration 43600, lr = 4.096e-05
I0502 11:17:03.058357 26473 solver.cpp:242] Iteration 43600 (104.968 iter/s, 0.952667s/100 iter), loss = 0.113283
I0502 11:17:03.058380 26473 solver.cpp:261]     Train net output #0: loss = 0.113283 (* 1 = 0.113283 loss)
I0502 11:17:03.058389 26473 sgd_solver.cpp:106] Iteration 43600, lr = 4.096e-05
I0502 11:17:04.006031 26473 solver.cpp:242] Iteration 43700 (104.994 iter/s, 0.952439s/100 iter), loss = 0.167473
I0502 11:17:04.006075 26473 solver.cpp:261]     Train net output #0: loss = 0.167473 (* 1 = 0.167473 loss)
I0502 11:17:04.006084 26473 sgd_solver.cpp:106] Iteration 43700, lr = 4.096e-05
I0502 11:17:04.010871 26473 solver.cpp:242] Iteration 43700 (104.99 iter/s, 0.952472s/100 iter), loss = 0.0796717
I0502 11:17:04.010896 26473 solver.cpp:261]     Train net output #0: loss = 0.0796717 (* 1 = 0.0796717 loss)
I0502 11:17:04.010905 26473 sgd_solver.cpp:106] Iteration 43700, lr = 4.096e-05
I0502 11:17:04.958606 26473 solver.cpp:242] Iteration 43800 (104.986 iter/s, 0.952511s/100 iter), loss = 0.190796
I0502 11:17:04.958645 26473 solver.cpp:261]     Train net output #0: loss = 0.190796 (* 1 = 0.190796 loss)
I0502 11:17:04.958654 26473 sgd_solver.cpp:106] Iteration 43800, lr = 4.096e-05
I0502 11:17:04.963531 26473 solver.cpp:242] Iteration 43800 (104.974 iter/s, 0.952616s/100 iter), loss = 0.0888927
I0502 11:17:04.963554 26473 solver.cpp:261]     Train net output #0: loss = 0.0888927 (* 1 = 0.0888927 loss)
I0502 11:17:04.963563 26473 sgd_solver.cpp:106] Iteration 43800, lr = 4.096e-05
I0502 11:17:05.911536 26473 solver.cpp:242] Iteration 43900 (104.946 iter/s, 0.95287s/100 iter), loss = 0.695771
I0502 11:17:05.911589 26473 solver.cpp:261]     Train net output #0: loss = 0.695771 (* 1 = 0.695771 loss)
I0502 11:17:05.911598 26473 sgd_solver.cpp:106] Iteration 43900, lr = 4.096e-05
I0502 11:17:05.916470 26473 solver.cpp:242] Iteration 43900 (104.943 iter/s, 0.952896s/100 iter), loss = 0.114038
I0502 11:17:05.916493 26473 solver.cpp:261]     Train net output #0: loss = 0.114038 (* 1 = 0.114038 loss)
I0502 11:17:05.916502 26473 sgd_solver.cpp:106] Iteration 43900, lr = 4.096e-05
I0502 11:17:06.860676 26473 solver.cpp:362] Iteration 44000, Testing net (#0)
I0502 11:17:06.860702 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:06.985731 26473 solver.cpp:429]     Test net output #0: loss = 0.434901 (* 1 = 0.434901 loss)
I0502 11:17:06.988605 26473 solver.cpp:242] Iteration 44000 (92.8508 iter/s, 1.077s/100 iter), loss = 0.492109
I0502 11:17:06.988626 26473 solver.cpp:261]     Train net output #0: loss = 0.492109 (* 1 = 0.492109 loss)
I0502 11:17:06.988634 26473 sgd_solver.cpp:106] Iteration 44000, lr = 4.096e-05
I0502 11:17:06.990265 26473 solver.cpp:362] Iteration 44000, Testing net (#0)
I0502 11:17:06.990278 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:07.121373 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9175
I0502 11:17:07.121394 26473 solver.cpp:429]     Test net output #1: loss = 0.172207 (* 1 = 0.172207 loss)
I0502 11:17:07.124337 26473 solver.cpp:242] Iteration 44000 (82.7936 iter/s, 1.20782s/100 iter), loss = 0.124093
I0502 11:17:07.124357 26473 solver.cpp:261]     Train net output #0: loss = 0.124093 (* 1 = 0.124093 loss)
I0502 11:17:07.124366 26473 sgd_solver.cpp:106] Iteration 44000, lr = 4.096e-05
I0502 11:17:08.071712 26473 solver.cpp:242] Iteration 44100 (92.3308 iter/s, 1.08306s/100 iter), loss = 0.408933
I0502 11:17:08.071749 26473 solver.cpp:261]     Train net output #0: loss = 0.408933 (* 1 = 0.408933 loss)
I0502 11:17:08.071758 26473 sgd_solver.cpp:106] Iteration 44100, lr = 4.096e-05
I0502 11:17:08.076582 26473 solver.cpp:242] Iteration 44100 (105.019 iter/s, 0.952206s/100 iter), loss = 0.125704
I0502 11:17:08.076606 26473 solver.cpp:261]     Train net output #0: loss = 0.125704 (* 1 = 0.125704 loss)
I0502 11:17:08.076614 26473 sgd_solver.cpp:106] Iteration 44100, lr = 4.096e-05
I0502 11:17:09.024087 26473 solver.cpp:242] Iteration 44200 (105.007 iter/s, 0.952316s/100 iter), loss = 1.02418
I0502 11:17:09.024128 26473 solver.cpp:261]     Train net output #0: loss = 1.02418 (* 1 = 1.02418 loss)
I0502 11:17:09.024137 26473 sgd_solver.cpp:106] Iteration 44200, lr = 4.096e-05
I0502 11:17:09.028957 26473 solver.cpp:242] Iteration 44200 (105.005 iter/s, 0.952333s/100 iter), loss = 0.115158
I0502 11:17:09.028981 26473 solver.cpp:261]     Train net output #0: loss = 0.115158 (* 1 = 0.115158 loss)
I0502 11:17:09.028990 26473 sgd_solver.cpp:106] Iteration 44200, lr = 4.096e-05
I0502 11:17:09.976467 26473 solver.cpp:242] Iteration 44300 (105.007 iter/s, 0.952318s/100 iter), loss = 0.0810765
I0502 11:17:09.976506 26473 solver.cpp:261]     Train net output #0: loss = 0.0810765 (* 1 = 0.0810765 loss)
I0502 11:17:09.976516 26473 sgd_solver.cpp:106] Iteration 44300, lr = 4.096e-05
I0502 11:17:09.981393 26473 solver.cpp:242] Iteration 44300 (104.999 iter/s, 0.952394s/100 iter), loss = 0.200336
I0502 11:17:09.981416 26473 solver.cpp:261]     Train net output #0: loss = 0.200336 (* 1 = 0.200336 loss)
I0502 11:17:09.981425 26473 sgd_solver.cpp:106] Iteration 44300, lr = 4.096e-05
I0502 11:17:10.928609 26473 solver.cpp:242] Iteration 44400 (105.033 iter/s, 0.952082s/100 iter), loss = 0.759298
I0502 11:17:10.928644 26473 solver.cpp:261]     Train net output #0: loss = 0.759298 (* 1 = 0.759298 loss)
I0502 11:17:10.928755 26473 sgd_solver.cpp:106] Iteration 44400, lr = 4.096e-05
I0502 11:17:10.936488 26473 solver.cpp:242] Iteration 44400 (104.707 iter/s, 0.955047s/100 iter), loss = 0.36994
I0502 11:17:10.936543 26473 solver.cpp:261]     Train net output #0: loss = 0.36994 (* 1 = 0.36994 loss)
I0502 11:17:10.936575 26473 sgd_solver.cpp:106] Iteration 44400, lr = 4.096e-05
I0502 11:17:11.937366 26473 solver.cpp:362] Iteration 44500, Testing net (#0)
I0502 11:17:11.937387 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:12.063192 26473 solver.cpp:429]     Test net output #0: loss = 0.373432 (* 1 = 0.373432 loss)
I0502 11:17:12.066076 26473 solver.cpp:242] Iteration 44500 (87.9189 iter/s, 1.13741s/100 iter), loss = 0.162794
I0502 11:17:12.066097 26473 solver.cpp:261]     Train net output #0: loss = 0.162794 (* 1 = 0.162794 loss)
I0502 11:17:12.066113 26473 sgd_solver.cpp:106] Iteration 44500, lr = 4.096e-05
I0502 11:17:12.067759 26473 solver.cpp:362] Iteration 44500, Testing net (#0)
I0502 11:17:12.067770 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:12.199234 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9285
I0502 11:17:12.199254 26473 solver.cpp:429]     Test net output #1: loss = 0.15079 (* 1 = 0.15079 loss)
I0502 11:17:12.202206 26473 solver.cpp:242] Iteration 44500 (79.011 iter/s, 1.26565s/100 iter), loss = 0.224847
I0502 11:17:12.202226 26473 solver.cpp:261]     Train net output #0: loss = 0.224847 (* 1 = 0.224847 loss)
I0502 11:17:12.202235 26473 sgd_solver.cpp:106] Iteration 44500, lr = 4.096e-05
I0502 11:17:13.150760 26473 solver.cpp:242] Iteration 44600 (92.1965 iter/s, 1.08464s/100 iter), loss = 0.134768
I0502 11:17:13.150799 26473 solver.cpp:261]     Train net output #0: loss = 0.134768 (* 1 = 0.134768 loss)
I0502 11:17:13.150809 26473 sgd_solver.cpp:106] Iteration 44600, lr = 4.096e-05
I0502 11:17:13.155601 26473 solver.cpp:242] Iteration 44600 (104.893 iter/s, 0.953355s/100 iter), loss = 0.0658384
I0502 11:17:13.155624 26473 solver.cpp:261]     Train net output #0: loss = 0.0658384 (* 1 = 0.0658384 loss)
I0502 11:17:13.155633 26473 sgd_solver.cpp:106] Iteration 44600, lr = 4.096e-05
I0502 11:17:14.103384 26473 solver.cpp:242] Iteration 44700 (104.98 iter/s, 0.952564s/100 iter), loss = 0.203559
I0502 11:17:14.103416 26473 solver.cpp:261]     Train net output #0: loss = 0.203559 (* 1 = 0.203559 loss)
I0502 11:17:14.103425 26473 sgd_solver.cpp:106] Iteration 44700, lr = 4.096e-05
I0502 11:17:14.108260 26473 solver.cpp:242] Iteration 44700 (104.974 iter/s, 0.952617s/100 iter), loss = 0.107402
I0502 11:17:14.108283 26473 solver.cpp:261]     Train net output #0: loss = 0.107402 (* 1 = 0.107402 loss)
I0502 11:17:14.108291 26473 sgd_solver.cpp:106] Iteration 44700, lr = 4.096e-05
I0502 11:17:15.057122 26473 solver.cpp:242] Iteration 44800 (104.857 iter/s, 0.953684s/100 iter), loss = 0.323989
I0502 11:17:15.057163 26473 solver.cpp:261]     Train net output #0: loss = 0.323989 (* 1 = 0.323989 loss)
I0502 11:17:15.057171 26473 sgd_solver.cpp:106] Iteration 44800, lr = 4.096e-05
I0502 11:17:15.062039 26473 solver.cpp:242] Iteration 44800 (104.851 iter/s, 0.953738s/100 iter), loss = 0.237956
I0502 11:17:15.062063 26473 solver.cpp:261]     Train net output #0: loss = 0.237956 (* 1 = 0.237956 loss)
I0502 11:17:15.062072 26473 sgd_solver.cpp:106] Iteration 44800, lr = 4.096e-05
I0502 11:17:16.010677 26473 solver.cpp:242] Iteration 44900 (104.877 iter/s, 0.953495s/100 iter), loss = 0.351752
I0502 11:17:16.010706 26473 solver.cpp:261]     Train net output #0: loss = 0.351752 (* 1 = 0.351752 loss)
I0502 11:17:16.010715 26473 sgd_solver.cpp:106] Iteration 44900, lr = 4.096e-05
I0502 11:17:16.015493 26473 solver.cpp:242] Iteration 44900 (104.886 iter/s, 0.953412s/100 iter), loss = 0.265484
I0502 11:17:16.015516 26473 solver.cpp:261]     Train net output #0: loss = 0.265484 (* 1 = 0.265484 loss)
I0502 11:17:16.015523 26473 sgd_solver.cpp:106] Iteration 44900, lr = 4.096e-05
I0502 11:17:16.960638 26473 solver.cpp:362] Iteration 45000, Testing net (#0)
I0502 11:17:16.960665 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:17.085732 26473 solver.cpp:429]     Test net output #0: loss = 0.465285 (* 1 = 0.465285 loss)
I0502 11:17:17.088601 26473 solver.cpp:242] Iteration 45000 (92.775 iter/s, 1.07788s/100 iter), loss = 0.266074
I0502 11:17:17.088623 26473 solver.cpp:261]     Train net output #0: loss = 0.266074 (* 1 = 0.266074 loss)
I0502 11:17:17.088631 26473 sgd_solver.cpp:106] Iteration 45000, lr = 4.096e-05
I0502 11:17:17.090291 26473 solver.cpp:362] Iteration 45000, Testing net (#0)
I0502 11:17:17.090303 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:17.221593 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9235
I0502 11:17:17.221612 26473 solver.cpp:429]     Test net output #1: loss = 0.160601 (* 1 = 0.160601 loss)
I0502 11:17:17.224558 26473 solver.cpp:242] Iteration 45000 (82.7116 iter/s, 1.20902s/100 iter), loss = 0.160039
I0502 11:17:17.224586 26473 solver.cpp:261]     Train net output #0: loss = 0.160039 (* 1 = 0.160039 loss)
I0502 11:17:17.224596 26473 sgd_solver.cpp:106] Iteration 45000, lr = 4.096e-05
I0502 11:17:18.172488 26473 solver.cpp:242] Iteration 45100 (92.2642 iter/s, 1.08384s/100 iter), loss = 0.383133
I0502 11:17:18.172520 26473 solver.cpp:261]     Train net output #0: loss = 0.383133 (* 1 = 0.383133 loss)
I0502 11:17:18.172529 26473 sgd_solver.cpp:106] Iteration 45100, lr = 4.096e-05
I0502 11:17:18.177317 26473 solver.cpp:242] Iteration 45100 (104.963 iter/s, 0.952712s/100 iter), loss = 0.0439364
I0502 11:17:18.177340 26473 solver.cpp:261]     Train net output #0: loss = 0.0439364 (* 1 = 0.0439364 loss)
I0502 11:17:18.177350 26473 sgd_solver.cpp:106] Iteration 45100, lr = 4.096e-05
I0502 11:17:19.126096 26473 solver.cpp:242] Iteration 45200 (104.871 iter/s, 0.953554s/100 iter), loss = 0.219395
I0502 11:17:19.126140 26473 solver.cpp:261]     Train net output #0: loss = 0.219395 (* 1 = 0.219395 loss)
I0502 11:17:19.126149 26473 sgd_solver.cpp:106] Iteration 45200, lr = 4.096e-05
I0502 11:17:19.130939 26473 solver.cpp:242] Iteration 45200 (104.868 iter/s, 0.95358s/100 iter), loss = 0.23315
I0502 11:17:19.130961 26473 solver.cpp:261]     Train net output #0: loss = 0.23315 (* 1 = 0.23315 loss)
I0502 11:17:19.130970 26473 sgd_solver.cpp:106] Iteration 45200, lr = 4.096e-05
I0502 11:17:20.078793 26473 solver.cpp:242] Iteration 45300 (104.973 iter/s, 0.95263s/100 iter), loss = 0.6384
I0502 11:17:20.078836 26473 solver.cpp:261]     Train net output #0: loss = 0.6384 (* 1 = 0.6384 loss)
I0502 11:17:20.078845 26473 sgd_solver.cpp:106] Iteration 45300, lr = 4.096e-05
I0502 11:17:20.083685 26473 solver.cpp:242] Iteration 45300 (104.965 iter/s, 0.952699s/100 iter), loss = 0.376012
I0502 11:17:20.083709 26473 solver.cpp:261]     Train net output #0: loss = 0.376012 (* 1 = 0.376012 loss)
I0502 11:17:20.083717 26473 sgd_solver.cpp:106] Iteration 45300, lr = 4.096e-05
I0502 11:17:21.032647 26473 solver.cpp:242] Iteration 45400 (104.845 iter/s, 0.953788s/100 iter), loss = 0.33764
I0502 11:17:21.032693 26473 solver.cpp:261]     Train net output #0: loss = 0.33764 (* 1 = 0.33764 loss)
I0502 11:17:21.032706 26473 sgd_solver.cpp:106] Iteration 45400, lr = 4.096e-05
I0502 11:17:21.037657 26473 solver.cpp:242] Iteration 45400 (104.83 iter/s, 0.953929s/100 iter), loss = 0.077917
I0502 11:17:21.037680 26473 solver.cpp:261]     Train net output #0: loss = 0.077917 (* 1 = 0.077917 loss)
I0502 11:17:21.037689 26473 sgd_solver.cpp:106] Iteration 45400, lr = 4.096e-05
I0502 11:17:21.982774 26473 solver.cpp:362] Iteration 45500, Testing net (#0)
I0502 11:17:21.982800 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:22.107938 26473 solver.cpp:429]     Test net output #0: loss = 0.474397 (* 1 = 0.474397 loss)
I0502 11:17:22.110855 26473 solver.cpp:242] Iteration 45500 (92.7521 iter/s, 1.07814s/100 iter), loss = 0.332799
I0502 11:17:22.110875 26473 solver.cpp:261]     Train net output #0: loss = 0.332799 (* 1 = 0.332799 loss)
I0502 11:17:22.110884 26473 sgd_solver.cpp:106] Iteration 45500, lr = 4.096e-05
I0502 11:17:22.112516 26473 solver.cpp:362] Iteration 45500, Testing net (#0)
I0502 11:17:22.112529 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:22.243847 26473 solver.cpp:429]     Test net output #0: accuracy = 0.932
I0502 11:17:22.243868 26473 solver.cpp:429]     Test net output #1: loss = 0.152622 (* 1 = 0.152622 loss)
I0502 11:17:22.246806 26473 solver.cpp:242] Iteration 45500 (82.7058 iter/s, 1.20911s/100 iter), loss = 0.0437918
I0502 11:17:22.246827 26473 solver.cpp:261]     Train net output #0: loss = 0.0437918 (* 1 = 0.0437918 loss)
I0502 11:17:22.246836 26473 sgd_solver.cpp:106] Iteration 45500, lr = 4.096e-05
I0502 11:17:23.194488 26473 solver.cpp:242] Iteration 45600 (92.2861 iter/s, 1.08359s/100 iter), loss = 0.43794
I0502 11:17:23.194528 26473 solver.cpp:261]     Train net output #0: loss = 0.43794 (* 1 = 0.43794 loss)
I0502 11:17:23.194537 26473 sgd_solver.cpp:106] Iteration 45600, lr = 4.096e-05
I0502 11:17:23.199333 26473 solver.cpp:242] Iteration 45600 (104.988 iter/s, 0.952488s/100 iter), loss = 0.177058
I0502 11:17:23.199357 26473 solver.cpp:261]     Train net output #0: loss = 0.177058 (* 1 = 0.177058 loss)
I0502 11:17:23.199365 26473 sgd_solver.cpp:106] Iteration 45600, lr = 4.096e-05
I0502 11:17:24.148681 26473 solver.cpp:242] Iteration 45700 (104.808 iter/s, 0.954127s/100 iter), loss = 0.700157
I0502 11:17:24.148723 26473 solver.cpp:261]     Train net output #0: loss = 0.700157 (* 1 = 0.700157 loss)
I0502 11:17:24.148732 26473 sgd_solver.cpp:106] Iteration 45700, lr = 4.096e-05
I0502 11:17:24.153534 26473 solver.cpp:242] Iteration 45700 (104.804 iter/s, 0.954159s/100 iter), loss = 0.121779
I0502 11:17:24.153556 26473 solver.cpp:261]     Train net output #0: loss = 0.121779 (* 1 = 0.121779 loss)
I0502 11:17:24.153565 26473 sgd_solver.cpp:106] Iteration 45700, lr = 4.096e-05
I0502 11:17:25.101459 26473 solver.cpp:242] Iteration 45800 (104.963 iter/s, 0.952713s/100 iter), loss = 0.262108
I0502 11:17:25.101498 26473 solver.cpp:261]     Train net output #0: loss = 0.262108 (* 1 = 0.262108 loss)
I0502 11:17:25.101507 26473 sgd_solver.cpp:106] Iteration 45800, lr = 4.096e-05
I0502 11:17:25.106302 26473 solver.cpp:242] Iteration 45800 (104.962 iter/s, 0.952728s/100 iter), loss = 0.10545
I0502 11:17:25.106325 26473 solver.cpp:261]     Train net output #0: loss = 0.10545 (* 1 = 0.10545 loss)
I0502 11:17:25.106333 26473 sgd_solver.cpp:106] Iteration 45800, lr = 4.096e-05
I0502 11:17:26.055032 26473 solver.cpp:242] Iteration 45900 (104.875 iter/s, 0.953512s/100 iter), loss = 0.167987
I0502 11:17:26.055090 26473 solver.cpp:261]     Train net output #0: loss = 0.167987 (* 1 = 0.167987 loss)
I0502 11:17:26.055104 26473 sgd_solver.cpp:106] Iteration 45900, lr = 4.096e-05
I0502 11:17:26.060008 26473 solver.cpp:242] Iteration 45900 (104.859 iter/s, 0.953664s/100 iter), loss = 0.0882805
I0502 11:17:26.060034 26473 solver.cpp:261]     Train net output #0: loss = 0.0882805 (* 1 = 0.0882805 loss)
I0502 11:17:26.060041 26473 sgd_solver.cpp:106] Iteration 45900, lr = 4.096e-05
I0502 11:17:27.004761 26473 solver.cpp:362] Iteration 46000, Testing net (#0)
I0502 11:17:27.004786 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:27.129873 26473 solver.cpp:429]     Test net output #0: loss = 0.428942 (* 1 = 0.428942 loss)
I0502 11:17:27.132750 26473 solver.cpp:242] Iteration 46000 (92.7953 iter/s, 1.07764s/100 iter), loss = 0.184606
I0502 11:17:27.132771 26473 solver.cpp:261]     Train net output #0: loss = 0.184606 (* 1 = 0.184606 loss)
I0502 11:17:27.132778 26473 sgd_solver.cpp:106] Iteration 46000, lr = 4.096e-05
I0502 11:17:27.134415 26473 solver.cpp:362] Iteration 46000, Testing net (#0)
I0502 11:17:27.134428 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:27.265784 26473 solver.cpp:429]     Test net output #0: accuracy = 0.935
I0502 11:17:27.265806 26473 solver.cpp:429]     Test net output #1: loss = 0.147442 (* 1 = 0.147442 loss)
I0502 11:17:27.268730 26473 solver.cpp:242] Iteration 46000 (82.7351 iter/s, 1.20868s/100 iter), loss = 0.123553
I0502 11:17:27.268751 26473 solver.cpp:261]     Train net output #0: loss = 0.123553 (* 1 = 0.123553 loss)
I0502 11:17:27.268760 26473 sgd_solver.cpp:106] Iteration 46000, lr = 4.096e-05
I0502 11:17:28.217162 26473 solver.cpp:242] Iteration 46100 (92.2197 iter/s, 1.08437s/100 iter), loss = 0.45471
I0502 11:17:28.217201 26473 solver.cpp:261]     Train net output #0: loss = 0.45471 (* 1 = 0.45471 loss)
I0502 11:17:28.217211 26473 sgd_solver.cpp:106] Iteration 46100, lr = 4.096e-05
I0502 11:17:28.222000 26473 solver.cpp:242] Iteration 46100 (104.906 iter/s, 0.95323s/100 iter), loss = 0.177097
I0502 11:17:28.222023 26473 solver.cpp:261]     Train net output #0: loss = 0.177097 (* 1 = 0.177097 loss)
I0502 11:17:28.222031 26473 sgd_solver.cpp:106] Iteration 46100, lr = 4.096e-05
I0502 11:17:29.169054 26473 solver.cpp:242] Iteration 46200 (105.061 iter/s, 0.951832s/100 iter), loss = 0.171492
I0502 11:17:29.169090 26473 solver.cpp:261]     Train net output #0: loss = 0.171492 (* 1 = 0.171492 loss)
I0502 11:17:29.169107 26473 sgd_solver.cpp:106] Iteration 46200, lr = 4.096e-05
I0502 11:17:29.173925 26473 solver.cpp:242] Iteration 46200 (105.055 iter/s, 0.951884s/100 iter), loss = 0.101344
I0502 11:17:29.173949 26473 solver.cpp:261]     Train net output #0: loss = 0.101344 (* 1 = 0.101344 loss)
I0502 11:17:29.173957 26473 sgd_solver.cpp:106] Iteration 46200, lr = 4.096e-05
I0502 11:17:30.121892 26473 solver.cpp:242] Iteration 46300 (104.956 iter/s, 0.952782s/100 iter), loss = 0.361875
I0502 11:17:30.121930 26473 solver.cpp:261]     Train net output #0: loss = 0.361875 (* 1 = 0.361875 loss)
I0502 11:17:30.121939 26473 sgd_solver.cpp:106] Iteration 46300, lr = 4.096e-05
I0502 11:17:30.126740 26473 solver.cpp:242] Iteration 46300 (104.957 iter/s, 0.952774s/100 iter), loss = 0.198722
I0502 11:17:30.126763 26473 solver.cpp:261]     Train net output #0: loss = 0.198722 (* 1 = 0.198722 loss)
I0502 11:17:30.126771 26473 sgd_solver.cpp:106] Iteration 46300, lr = 4.096e-05
I0502 11:17:31.075163 26473 solver.cpp:242] Iteration 46400 (104.908 iter/s, 0.953212s/100 iter), loss = 0.470777
I0502 11:17:31.075213 26473 solver.cpp:261]     Train net output #0: loss = 0.470777 (* 1 = 0.470777 loss)
I0502 11:17:31.075223 26473 sgd_solver.cpp:106] Iteration 46400, lr = 4.096e-05
I0502 11:17:31.080163 26473 solver.cpp:242] Iteration 46400 (104.891 iter/s, 0.953371s/100 iter), loss = 0.109558
I0502 11:17:31.080185 26473 solver.cpp:261]     Train net output #0: loss = 0.109558 (* 1 = 0.109558 loss)
I0502 11:17:31.080194 26473 sgd_solver.cpp:106] Iteration 46400, lr = 4.096e-05
I0502 11:17:32.024806 26473 solver.cpp:362] Iteration 46500, Testing net (#0)
I0502 11:17:32.024826 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:32.149904 26473 solver.cpp:429]     Test net output #0: loss = 0.470303 (* 1 = 0.470303 loss)
I0502 11:17:32.152776 26473 solver.cpp:242] Iteration 46500 (92.8036 iter/s, 1.07754s/100 iter), loss = 1.32675
I0502 11:17:32.152796 26473 solver.cpp:261]     Train net output #0: loss = 1.32675 (* 1 = 1.32675 loss)
I0502 11:17:32.152804 26473 sgd_solver.cpp:106] Iteration 46500, lr = 4.096e-05
I0502 11:17:32.154469 26473 solver.cpp:362] Iteration 46500, Testing net (#0)
I0502 11:17:32.154480 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:32.285713 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9395
I0502 11:17:32.285733 26473 solver.cpp:429]     Test net output #1: loss = 0.146873 (* 1 = 0.146873 loss)
I0502 11:17:32.288673 26473 solver.cpp:242] Iteration 46500 (82.7495 iter/s, 1.20847s/100 iter), loss = 0.0556701
I0502 11:17:32.288694 26473 solver.cpp:261]     Train net output #0: loss = 0.0556701 (* 1 = 0.0556701 loss)
I0502 11:17:32.288702 26473 sgd_solver.cpp:106] Iteration 46500, lr = 4.096e-05
I0502 11:17:33.237421 26473 solver.cpp:242] Iteration 46600 (92.2 iter/s, 1.0846s/100 iter), loss = 0.655079
I0502 11:17:33.237459 26473 solver.cpp:261]     Train net output #0: loss = 0.655079 (* 1 = 0.655079 loss)
I0502 11:17:33.237468 26473 sgd_solver.cpp:106] Iteration 46600, lr = 4.096e-05
I0502 11:17:33.242256 26473 solver.cpp:242] Iteration 46600 (104.872 iter/s, 0.953544s/100 iter), loss = 0.0472842
I0502 11:17:33.242280 26473 solver.cpp:261]     Train net output #0: loss = 0.0472842 (* 1 = 0.0472842 loss)
I0502 11:17:33.242288 26473 sgd_solver.cpp:106] Iteration 46600, lr = 4.096e-05
I0502 11:17:34.189779 26473 solver.cpp:242] Iteration 46700 (105.009 iter/s, 0.9523s/100 iter), loss = 0.116671
I0502 11:17:34.189813 26473 solver.cpp:261]     Train net output #0: loss = 0.116671 (* 1 = 0.116671 loss)
I0502 11:17:34.189822 26473 sgd_solver.cpp:106] Iteration 46700, lr = 4.096e-05
I0502 11:17:34.194620 26473 solver.cpp:242] Iteration 46700 (105.006 iter/s, 0.952323s/100 iter), loss = 0.125885
I0502 11:17:34.194643 26473 solver.cpp:261]     Train net output #0: loss = 0.125885 (* 1 = 0.125885 loss)
I0502 11:17:34.194651 26473 sgd_solver.cpp:106] Iteration 46700, lr = 4.096e-05
I0502 11:17:35.142508 26473 solver.cpp:242] Iteration 46800 (104.968 iter/s, 0.952674s/100 iter), loss = 1.69435
I0502 11:17:35.142549 26473 solver.cpp:261]     Train net output #0: loss = 1.69435 (* 1 = 1.69435 loss)
I0502 11:17:35.142559 26473 sgd_solver.cpp:106] Iteration 46800, lr = 4.096e-05
I0502 11:17:35.147368 26473 solver.cpp:242] Iteration 46800 (104.964 iter/s, 0.952706s/100 iter), loss = 0.147767
I0502 11:17:35.147390 26473 solver.cpp:261]     Train net output #0: loss = 0.147767 (* 1 = 0.147767 loss)
I0502 11:17:35.147399 26473 sgd_solver.cpp:106] Iteration 46800, lr = 4.096e-05
I0502 11:17:36.096076 26473 solver.cpp:242] Iteration 46900 (104.876 iter/s, 0.953506s/100 iter), loss = 0.375879
I0502 11:17:36.096120 26473 solver.cpp:261]     Train net output #0: loss = 0.375879 (* 1 = 0.375879 loss)
I0502 11:17:36.096130 26473 sgd_solver.cpp:106] Iteration 46900, lr = 4.096e-05
I0502 11:17:36.101073 26473 solver.cpp:242] Iteration 46900 (104.859 iter/s, 0.953662s/100 iter), loss = 0.0994026
I0502 11:17:36.101095 26473 solver.cpp:261]     Train net output #0: loss = 0.0994026 (* 1 = 0.0994026 loss)
I0502 11:17:36.101104 26473 sgd_solver.cpp:106] Iteration 46900, lr = 4.096e-05
I0502 11:17:37.046392 26473 solver.cpp:362] Iteration 47000, Testing net (#0)
I0502 11:17:37.046411 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:37.171453 26473 solver.cpp:429]     Test net output #0: loss = 0.378196 (* 1 = 0.378196 loss)
I0502 11:17:37.174329 26473 solver.cpp:242] Iteration 47000 (92.7481 iter/s, 1.07819s/100 iter), loss = 0.388152
I0502 11:17:37.174348 26473 solver.cpp:261]     Train net output #0: loss = 0.388152 (* 1 = 0.388152 loss)
I0502 11:17:37.174356 26473 sgd_solver.cpp:106] Iteration 47000, lr = 4.096e-05
I0502 11:17:37.176008 26473 solver.cpp:362] Iteration 47000, Testing net (#0)
I0502 11:17:37.176021 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:37.307284 26473 solver.cpp:429]     Test net output #0: accuracy = 0.946
I0502 11:17:37.307302 26473 solver.cpp:429]     Test net output #1: loss = 0.131253 (* 1 = 0.131253 loss)
I0502 11:17:37.310236 26473 solver.cpp:242] Iteration 47000 (82.7047 iter/s, 1.20912s/100 iter), loss = 0.0985003
I0502 11:17:37.310257 26473 solver.cpp:261]     Train net output #0: loss = 0.0985003 (* 1 = 0.0985003 loss)
I0502 11:17:37.310266 26473 sgd_solver.cpp:106] Iteration 47000, lr = 4.096e-05
I0502 11:17:38.258488 26473 solver.cpp:242] Iteration 47100 (92.2411 iter/s, 1.08412s/100 iter), loss = 0.253807
I0502 11:17:38.258533 26473 solver.cpp:261]     Train net output #0: loss = 0.253807 (* 1 = 0.253807 loss)
I0502 11:17:38.258540 26473 sgd_solver.cpp:106] Iteration 47100, lr = 4.096e-05
I0502 11:17:38.263345 26473 solver.cpp:242] Iteration 47100 (104.924 iter/s, 0.95307s/100 iter), loss = 0.0900681
I0502 11:17:38.263367 26473 solver.cpp:261]     Train net output #0: loss = 0.0900681 (* 1 = 0.0900681 loss)
I0502 11:17:38.263376 26473 sgd_solver.cpp:106] Iteration 47100, lr = 4.096e-05
I0502 11:17:39.211369 26473 solver.cpp:242] Iteration 47200 (104.952 iter/s, 0.952814s/100 iter), loss = 0.271537
I0502 11:17:39.211411 26473 solver.cpp:261]     Train net output #0: loss = 0.271537 (* 1 = 0.271537 loss)
I0502 11:17:39.211421 26473 sgd_solver.cpp:106] Iteration 47200, lr = 4.096e-05
I0502 11:17:39.216210 26473 solver.cpp:242] Iteration 47200 (104.951 iter/s, 0.952824s/100 iter), loss = 0.0950897
I0502 11:17:39.216233 26473 solver.cpp:261]     Train net output #0: loss = 0.0950897 (* 1 = 0.0950897 loss)
I0502 11:17:39.216243 26473 sgd_solver.cpp:106] Iteration 47200, lr = 4.096e-05
I0502 11:17:40.165632 26473 solver.cpp:242] Iteration 47300 (104.8 iter/s, 0.954198s/100 iter), loss = 0.16321
I0502 11:17:40.165670 26473 solver.cpp:261]     Train net output #0: loss = 0.16321 (* 1 = 0.16321 loss)
I0502 11:17:40.165680 26473 sgd_solver.cpp:106] Iteration 47300, lr = 4.096e-05
I0502 11:17:40.170505 26473 solver.cpp:242] Iteration 47300 (104.794 iter/s, 0.954252s/100 iter), loss = 0.202537
I0502 11:17:40.170527 26473 solver.cpp:261]     Train net output #0: loss = 0.202537 (* 1 = 0.202537 loss)
I0502 11:17:40.170536 26473 sgd_solver.cpp:106] Iteration 47300, lr = 4.096e-05
I0502 11:17:41.118160 26473 solver.cpp:242] Iteration 47400 (104.99 iter/s, 0.952467s/100 iter), loss = 0.129126
I0502 11:17:41.118216 26473 solver.cpp:261]     Train net output #0: loss = 0.129126 (* 1 = 0.129126 loss)
I0502 11:17:41.118227 26473 sgd_solver.cpp:106] Iteration 47400, lr = 4.096e-05
I0502 11:17:41.123148 26473 solver.cpp:242] Iteration 47400 (104.976 iter/s, 0.952595s/100 iter), loss = 0.163126
I0502 11:17:41.123172 26473 solver.cpp:261]     Train net output #0: loss = 0.163126 (* 1 = 0.163126 loss)
I0502 11:17:41.123180 26473 sgd_solver.cpp:106] Iteration 47400, lr = 4.096e-05
I0502 11:17:42.069267 26473 solver.cpp:362] Iteration 47500, Testing net (#0)
I0502 11:17:42.069294 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:42.194375 26473 solver.cpp:429]     Test net output #0: loss = 0.316239 (* 1 = 0.316239 loss)
I0502 11:17:42.197265 26473 solver.cpp:242] Iteration 47500 (92.6758 iter/s, 1.07903s/100 iter), loss = 0.362007
I0502 11:17:42.197286 26473 solver.cpp:261]     Train net output #0: loss = 0.362007 (* 1 = 0.362007 loss)
I0502 11:17:42.197295 26473 sgd_solver.cpp:106] Iteration 47500, lr = 4.096e-05
I0502 11:17:42.198931 26473 solver.cpp:362] Iteration 47500, Testing net (#0)
I0502 11:17:42.198945 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:42.330384 26473 solver.cpp:429]     Test net output #0: accuracy = 0.943
I0502 11:17:42.330404 26473 solver.cpp:429]     Test net output #1: loss = 0.127759 (* 1 = 0.127759 loss)
I0502 11:17:42.333333 26473 solver.cpp:242] Iteration 47500 (82.6351 iter/s, 1.21014s/100 iter), loss = 0.110751
I0502 11:17:42.333353 26473 solver.cpp:261]     Train net output #0: loss = 0.110751 (* 1 = 0.110751 loss)
I0502 11:17:42.333361 26473 sgd_solver.cpp:106] Iteration 47500, lr = 4.096e-05
I0502 11:17:43.281533 26473 solver.cpp:242] Iteration 47600 (92.2327 iter/s, 1.08421s/100 iter), loss = 0.217284
I0502 11:17:43.281570 26473 solver.cpp:261]     Train net output #0: loss = 0.217284 (* 1 = 0.217284 loss)
I0502 11:17:43.281579 26473 sgd_solver.cpp:106] Iteration 47600, lr = 4.096e-05
I0502 11:17:43.286365 26473 solver.cpp:242] Iteration 47600 (104.933 iter/s, 0.952993s/100 iter), loss = 0.325683
I0502 11:17:43.286387 26473 solver.cpp:261]     Train net output #0: loss = 0.325683 (* 1 = 0.325683 loss)
I0502 11:17:43.286396 26473 sgd_solver.cpp:106] Iteration 47600, lr = 4.096e-05
I0502 11:17:44.235209 26473 solver.cpp:242] Iteration 47700 (104.864 iter/s, 0.953618s/100 iter), loss = 0.210516
I0502 11:17:44.235250 26473 solver.cpp:261]     Train net output #0: loss = 0.210516 (* 1 = 0.210516 loss)
I0502 11:17:44.235260 26473 sgd_solver.cpp:106] Iteration 47700, lr = 4.096e-05
I0502 11:17:44.240062 26473 solver.cpp:242] Iteration 47700 (104.859 iter/s, 0.953657s/100 iter), loss = 0.0566431
I0502 11:17:44.240087 26473 solver.cpp:261]     Train net output #0: loss = 0.0566431 (* 1 = 0.0566431 loss)
I0502 11:17:44.240094 26473 sgd_solver.cpp:106] Iteration 47700, lr = 4.096e-05
I0502 11:17:45.188340 26473 solver.cpp:242] Iteration 47800 (104.924 iter/s, 0.953067s/100 iter), loss = 0.856092
I0502 11:17:45.188382 26473 solver.cpp:261]     Train net output #0: loss = 0.856092 (* 1 = 0.856092 loss)
I0502 11:17:45.188390 26473 sgd_solver.cpp:106] Iteration 47800, lr = 4.096e-05
I0502 11:17:45.193177 26473 solver.cpp:242] Iteration 47800 (104.924 iter/s, 0.953073s/100 iter), loss = 0.0274715
I0502 11:17:45.193199 26473 solver.cpp:261]     Train net output #0: loss = 0.0274715 (* 1 = 0.0274715 loss)
I0502 11:17:45.193208 26473 sgd_solver.cpp:106] Iteration 47800, lr = 4.096e-05
I0502 11:17:46.140508 26473 solver.cpp:242] Iteration 47900 (105.03 iter/s, 0.952105s/100 iter), loss = 0.0943289
I0502 11:17:46.140566 26473 solver.cpp:261]     Train net output #0: loss = 0.0943289 (* 1 = 0.0943289 loss)
I0502 11:17:46.140581 26473 sgd_solver.cpp:106] Iteration 47900, lr = 4.096e-05
I0502 11:17:46.145503 26473 solver.cpp:242] Iteration 47900 (105.011 iter/s, 0.952284s/100 iter), loss = 0.0141955
I0502 11:17:46.145535 26473 solver.cpp:261]     Train net output #0: loss = 0.0141955 (* 1 = 0.0141955 loss)
I0502 11:17:46.145545 26473 sgd_solver.cpp:106] Iteration 47900, lr = 4.096e-05
I0502 11:17:47.089898 26473 solver.cpp:362] Iteration 48000, Testing net (#0)
I0502 11:17:47.089926 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:47.215039 26473 solver.cpp:429]     Test net output #0: loss = 0.384035 (* 1 = 0.384035 loss)
I0502 11:17:47.217918 26473 solver.cpp:242] Iteration 48000 (92.8217 iter/s, 1.07733s/100 iter), loss = 2.50329
I0502 11:17:47.217938 26473 solver.cpp:261]     Train net output #0: loss = 2.50329 (* 1 = 2.50329 loss)
I0502 11:17:47.217947 26473 sgd_solver.cpp:106] Iteration 48000, lr = 4.096e-05
I0502 11:17:47.219673 26473 solver.cpp:362] Iteration 48000, Testing net (#0)
I0502 11:17:47.219687 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:47.350915 26473 solver.cpp:429]     Test net output #0: accuracy = 0.932
I0502 11:17:47.350937 26473 solver.cpp:429]     Test net output #1: loss = 0.145688 (* 1 = 0.145688 loss)
I0502 11:17:47.353850 26473 solver.cpp:242] Iteration 48000 (82.7613 iter/s, 1.20829s/100 iter), loss = 0.134661
I0502 11:17:47.353871 26473 solver.cpp:261]     Train net output #0: loss = 0.134661 (* 1 = 0.134661 loss)
I0502 11:17:47.353880 26473 sgd_solver.cpp:106] Iteration 48000, lr = 4.096e-05
I0502 11:17:48.322963 26473 solver.cpp:242] Iteration 48100 (90.4977 iter/s, 1.105s/100 iter), loss = 1.06405
I0502 11:17:48.323010 26473 solver.cpp:261]     Train net output #0: loss = 1.06405 (* 1 = 1.06405 loss)
I0502 11:17:48.323019 26473 sgd_solver.cpp:106] Iteration 48100, lr = 4.096e-05
I0502 11:17:48.327919 26473 solver.cpp:242] Iteration 48100 (102.666 iter/s, 0.974029s/100 iter), loss = 0.235908
I0502 11:17:48.327944 26473 solver.cpp:261]     Train net output #0: loss = 0.235908 (* 1 = 0.235908 loss)
I0502 11:17:48.327953 26473 sgd_solver.cpp:106] Iteration 48100, lr = 4.096e-05
I0502 11:17:49.275337 26473 solver.cpp:242] Iteration 48200 (105.008 iter/s, 0.952307s/100 iter), loss = 0.399615
I0502 11:17:49.275374 26473 solver.cpp:261]     Train net output #0: loss = 0.399615 (* 1 = 0.399615 loss)
I0502 11:17:49.275383 26473 sgd_solver.cpp:106] Iteration 48200, lr = 4.096e-05
I0502 11:17:49.280172 26473 solver.cpp:242] Iteration 48200 (105.019 iter/s, 0.952209s/100 iter), loss = 0.334666
I0502 11:17:49.280196 26473 solver.cpp:261]     Train net output #0: loss = 0.334666 (* 1 = 0.334666 loss)
I0502 11:17:49.280205 26473 sgd_solver.cpp:106] Iteration 48200, lr = 4.096e-05
I0502 11:17:50.228091 26473 solver.cpp:242] Iteration 48300 (104.966 iter/s, 0.952691s/100 iter), loss = 1.24114
I0502 11:17:50.228129 26473 solver.cpp:261]     Train net output #0: loss = 1.24114 (* 1 = 1.24114 loss)
I0502 11:17:50.228138 26473 sgd_solver.cpp:106] Iteration 48300, lr = 4.096e-05
I0502 11:17:50.232923 26473 solver.cpp:242] Iteration 48300 (104.964 iter/s, 0.952709s/100 iter), loss = 0.330136
I0502 11:17:50.232946 26473 solver.cpp:261]     Train net output #0: loss = 0.330136 (* 1 = 0.330136 loss)
I0502 11:17:50.232955 26473 sgd_solver.cpp:106] Iteration 48300, lr = 4.096e-05
I0502 11:17:51.180925 26473 solver.cpp:242] Iteration 48400 (104.957 iter/s, 0.952775s/100 iter), loss = 0.233233
I0502 11:17:51.180974 26473 solver.cpp:261]     Train net output #0: loss = 0.233233 (* 1 = 0.233233 loss)
I0502 11:17:51.180984 26473 sgd_solver.cpp:106] Iteration 48400, lr = 4.096e-05
I0502 11:17:51.185869 26473 solver.cpp:242] Iteration 48400 (104.942 iter/s, 0.952905s/100 iter), loss = 0.222974
I0502 11:17:51.185892 26473 solver.cpp:261]     Train net output #0: loss = 0.222974 (* 1 = 0.222974 loss)
I0502 11:17:51.185900 26473 sgd_solver.cpp:106] Iteration 48400, lr = 4.096e-05
I0502 11:17:52.131582 26473 solver.cpp:362] Iteration 48500, Testing net (#0)
I0502 11:17:52.131608 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:52.256788 26473 solver.cpp:429]     Test net output #0: loss = 0.344926 (* 1 = 0.344926 loss)
I0502 11:17:52.259670 26473 solver.cpp:242] Iteration 48500 (92.7062 iter/s, 1.07868s/100 iter), loss = 0.174942
I0502 11:17:52.259698 26473 solver.cpp:261]     Train net output #0: loss = 0.174942 (* 1 = 0.174942 loss)
I0502 11:17:52.259707 26473 sgd_solver.cpp:106] Iteration 48500, lr = 4.096e-05
I0502 11:17:52.261442 26473 solver.cpp:362] Iteration 48500, Testing net (#0)
I0502 11:17:52.261456 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:52.392846 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9535
I0502 11:17:52.392866 26473 solver.cpp:429]     Test net output #1: loss = 0.130496 (* 1 = 0.130496 loss)
I0502 11:17:52.395792 26473 solver.cpp:242] Iteration 48500 (82.6529 iter/s, 1.20988s/100 iter), loss = 0.0403183
I0502 11:17:52.395812 26473 solver.cpp:261]     Train net output #0: loss = 0.0403183 (* 1 = 0.0403183 loss)
I0502 11:17:52.395822 26473 sgd_solver.cpp:106] Iteration 48500, lr = 4.096e-05
I0502 11:17:53.343375 26473 solver.cpp:242] Iteration 48600 (92.2804 iter/s, 1.08365s/100 iter), loss = 0.240171
I0502 11:17:53.343410 26473 solver.cpp:261]     Train net output #0: loss = 0.240171 (* 1 = 0.240171 loss)
I0502 11:17:53.343418 26473 sgd_solver.cpp:106] Iteration 48600, lr = 4.096e-05
I0502 11:17:53.348240 26473 solver.cpp:242] Iteration 48600 (104.997 iter/s, 0.95241s/100 iter), loss = 0.0918436
I0502 11:17:53.348263 26473 solver.cpp:261]     Train net output #0: loss = 0.0918436 (* 1 = 0.0918436 loss)
I0502 11:17:53.348273 26473 sgd_solver.cpp:106] Iteration 48600, lr = 4.096e-05
I0502 11:17:54.297075 26473 solver.cpp:242] Iteration 48700 (104.861 iter/s, 0.953643s/100 iter), loss = 0.195534
I0502 11:17:54.297106 26473 solver.cpp:261]     Train net output #0: loss = 0.195534 (* 1 = 0.195534 loss)
I0502 11:17:54.297116 26473 sgd_solver.cpp:106] Iteration 48700, lr = 4.096e-05
I0502 11:17:54.301892 26473 solver.cpp:242] Iteration 48700 (104.865 iter/s, 0.953609s/100 iter), loss = 0.0941395
I0502 11:17:54.301915 26473 solver.cpp:261]     Train net output #0: loss = 0.0941395 (* 1 = 0.0941395 loss)
I0502 11:17:54.301923 26473 sgd_solver.cpp:106] Iteration 48700, lr = 4.096e-05
I0502 11:17:55.249387 26473 solver.cpp:242] Iteration 48800 (105.013 iter/s, 0.95226s/100 iter), loss = 0.453914
I0502 11:17:55.249418 26473 solver.cpp:261]     Train net output #0: loss = 0.453914 (* 1 = 0.453914 loss)
I0502 11:17:55.249428 26473 sgd_solver.cpp:106] Iteration 48800, lr = 4.096e-05
I0502 11:17:55.254220 26473 solver.cpp:242] Iteration 48800 (105.011 iter/s, 0.952285s/100 iter), loss = 0.232323
I0502 11:17:55.254241 26473 solver.cpp:261]     Train net output #0: loss = 0.232323 (* 1 = 0.232323 loss)
I0502 11:17:55.254251 26473 sgd_solver.cpp:106] Iteration 48800, lr = 4.096e-05
I0502 11:17:56.203276 26473 solver.cpp:242] Iteration 48900 (104.84 iter/s, 0.953837s/100 iter), loss = 0.419436
I0502 11:17:56.203322 26473 solver.cpp:261]     Train net output #0: loss = 0.419436 (* 1 = 0.419436 loss)
I0502 11:17:56.203332 26473 sgd_solver.cpp:106] Iteration 48900, lr = 4.096e-05
I0502 11:17:56.208164 26473 solver.cpp:242] Iteration 48900 (104.832 iter/s, 0.953903s/100 iter), loss = 0.305609
I0502 11:17:56.208187 26473 solver.cpp:261]     Train net output #0: loss = 0.305609 (* 1 = 0.305609 loss)
I0502 11:17:56.208196 26473 sgd_solver.cpp:106] Iteration 48900, lr = 4.096e-05
I0502 11:17:57.153578 26473 solver.cpp:362] Iteration 49000, Testing net (#0)
I0502 11:17:57.153605 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:57.278707 26473 solver.cpp:429]     Test net output #0: loss = 0.349423 (* 1 = 0.349423 loss)
I0502 11:17:57.281579 26473 solver.cpp:242] Iteration 49000 (92.7438 iter/s, 1.07824s/100 iter), loss = 0.10401
I0502 11:17:57.281600 26473 solver.cpp:261]     Train net output #0: loss = 0.10401 (* 1 = 0.10401 loss)
I0502 11:17:57.281608 26473 sgd_solver.cpp:106] Iteration 49000, lr = 4.096e-05
I0502 11:17:57.283341 26473 solver.cpp:362] Iteration 49000, Testing net (#0)
I0502 11:17:57.283355 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:17:57.414682 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9395
I0502 11:17:57.414711 26473 solver.cpp:429]     Test net output #1: loss = 0.128122 (* 1 = 0.128122 loss)
I0502 11:17:57.417645 26473 solver.cpp:242] Iteration 49000 (82.6831 iter/s, 1.20944s/100 iter), loss = 0.165681
I0502 11:17:57.417665 26473 solver.cpp:261]     Train net output #0: loss = 0.165681 (* 1 = 0.165681 loss)
I0502 11:17:57.417675 26473 sgd_solver.cpp:106] Iteration 49000, lr = 4.096e-05
I0502 11:17:58.366096 26473 solver.cpp:242] Iteration 49100 (92.2107 iter/s, 1.08447s/100 iter), loss = 0.236602
I0502 11:17:58.366124 26473 solver.cpp:261]     Train net output #0: loss = 0.236602 (* 1 = 0.236602 loss)
I0502 11:17:58.366133 26473 sgd_solver.cpp:106] Iteration 49100, lr = 4.096e-05
I0502 11:17:58.370918 26473 solver.cpp:242] Iteration 49100 (104.906 iter/s, 0.953235s/100 iter), loss = 0.137884
I0502 11:17:58.370940 26473 solver.cpp:261]     Train net output #0: loss = 0.137884 (* 1 = 0.137884 loss)
I0502 11:17:58.370949 26473 sgd_solver.cpp:106] Iteration 49100, lr = 4.096e-05
I0502 11:17:59.318904 26473 solver.cpp:242] Iteration 49200 (104.959 iter/s, 0.952757s/100 iter), loss = 0.272385
I0502 11:17:59.318946 26473 solver.cpp:261]     Train net output #0: loss = 0.272385 (* 1 = 0.272385 loss)
I0502 11:17:59.318955 26473 sgd_solver.cpp:106] Iteration 49200, lr = 4.096e-05
I0502 11:17:59.323752 26473 solver.cpp:242] Iteration 49200 (104.955 iter/s, 0.952793s/100 iter), loss = 0.0701359
I0502 11:17:59.323776 26473 solver.cpp:261]     Train net output #0: loss = 0.0701359 (* 1 = 0.0701359 loss)
I0502 11:17:59.323783 26473 sgd_solver.cpp:106] Iteration 49200, lr = 4.096e-05
I0502 11:18:00.284199 26473 solver.cpp:242] Iteration 49300 (103.602 iter/s, 0.96523s/100 iter), loss = 0.220443
I0502 11:18:00.284247 26473 solver.cpp:261]     Train net output #0: loss = 0.220443 (* 1 = 0.220443 loss)
I0502 11:18:00.284256 26473 sgd_solver.cpp:106] Iteration 49300, lr = 4.096e-05
I0502 11:18:00.289083 26473 solver.cpp:242] Iteration 49300 (103.596 iter/s, 0.965288s/100 iter), loss = 0.204665
I0502 11:18:00.289108 26473 solver.cpp:261]     Train net output #0: loss = 0.204665 (* 1 = 0.204665 loss)
I0502 11:18:00.289116 26473 sgd_solver.cpp:106] Iteration 49300, lr = 4.096e-05
I0502 11:18:01.243934 26473 solver.cpp:242] Iteration 49400 (104.203 iter/s, 0.959665s/100 iter), loss = 0.46848
I0502 11:18:01.243983 26473 solver.cpp:261]     Train net output #0: loss = 0.46848 (* 1 = 0.46848 loss)
I0502 11:18:01.244395 26473 sgd_solver.cpp:106] Iteration 49400, lr = 4.096e-05
I0502 11:18:01.251564 26473 solver.cpp:242] Iteration 49400 (103.903 iter/s, 0.962433s/100 iter), loss = 0.116282
I0502 11:18:01.251615 26473 solver.cpp:261]     Train net output #0: loss = 0.116282 (* 1 = 0.116282 loss)
I0502 11:18:01.251633 26473 sgd_solver.cpp:106] Iteration 49400, lr = 4.096e-05
I0502 11:18:02.238276 26473 solver.cpp:362] Iteration 49500, Testing net (#0)
I0502 11:18:02.238304 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:02.363577 26473 solver.cpp:429]     Test net output #0: loss = 0.580288 (* 1 = 0.580288 loss)
I0502 11:18:02.366514 26473 solver.cpp:242] Iteration 49500 (89.0858 iter/s, 1.12251s/100 iter), loss = 0.613812
I0502 11:18:02.366534 26473 solver.cpp:261]     Train net output #0: loss = 0.613812 (* 1 = 0.613812 loss)
I0502 11:18:02.366544 26473 sgd_solver.cpp:106] Iteration 49500, lr = 4.096e-05
I0502 11:18:02.368367 26473 solver.cpp:362] Iteration 49500, Testing net (#0)
I0502 11:18:02.368383 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:02.499667 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9145
I0502 11:18:02.499686 26473 solver.cpp:429]     Test net output #1: loss = 0.197601 (* 1 = 0.197601 loss)
I0502 11:18:02.502622 26473 solver.cpp:242] Iteration 49500 (79.9366 iter/s, 1.25099s/100 iter), loss = 0.192627
I0502 11:18:02.502643 26473 solver.cpp:261]     Train net output #0: loss = 0.192627 (* 1 = 0.192627 loss)
I0502 11:18:02.502652 26473 sgd_solver.cpp:106] Iteration 49500, lr = 4.096e-05
I0502 11:18:03.450503 26473 solver.cpp:242] Iteration 49600 (92.2557 iter/s, 1.08394s/100 iter), loss = 0.12507
I0502 11:18:03.450556 26473 solver.cpp:261]     Train net output #0: loss = 0.12507 (* 1 = 0.12507 loss)
I0502 11:18:03.450567 26473 sgd_solver.cpp:106] Iteration 49600, lr = 4.096e-05
I0502 11:18:03.455344 26473 solver.cpp:242] Iteration 49600 (104.967 iter/s, 0.952682s/100 iter), loss = 0.108067
I0502 11:18:03.455368 26473 solver.cpp:261]     Train net output #0: loss = 0.108067 (* 1 = 0.108067 loss)
I0502 11:18:03.455377 26473 sgd_solver.cpp:106] Iteration 49600, lr = 4.096e-05
I0502 11:18:04.402724 26473 solver.cpp:242] Iteration 49700 (105.026 iter/s, 0.952147s/100 iter), loss = 0.460564
I0502 11:18:04.402765 26473 solver.cpp:261]     Train net output #0: loss = 0.460564 (* 1 = 0.460564 loss)
I0502 11:18:04.402773 26473 sgd_solver.cpp:106] Iteration 49700, lr = 4.096e-05
I0502 11:18:04.407613 26473 solver.cpp:242] Iteration 49700 (105.017 iter/s, 0.952226s/100 iter), loss = 0.145189
I0502 11:18:04.407637 26473 solver.cpp:261]     Train net output #0: loss = 0.145189 (* 1 = 0.145189 loss)
I0502 11:18:04.407645 26473 sgd_solver.cpp:106] Iteration 49700, lr = 4.096e-05
I0502 11:18:05.354437 26473 solver.cpp:242] Iteration 49800 (105.081 iter/s, 0.951651s/100 iter), loss = 0.370625
I0502 11:18:05.354476 26473 solver.cpp:261]     Train net output #0: loss = 0.370625 (* 1 = 0.370625 loss)
I0502 11:18:05.354485 26473 sgd_solver.cpp:106] Iteration 49800, lr = 4.096e-05
I0502 11:18:05.359266 26473 solver.cpp:242] Iteration 49800 (105.085 iter/s, 0.95161s/100 iter), loss = 0.118818
I0502 11:18:05.359288 26473 solver.cpp:261]     Train net output #0: loss = 0.118818 (* 1 = 0.118818 loss)
I0502 11:18:05.359297 26473 sgd_solver.cpp:106] Iteration 49800, lr = 4.096e-05
I0502 11:18:06.307610 26473 solver.cpp:242] Iteration 49900 (104.92 iter/s, 0.953111s/100 iter), loss = 0.502902
I0502 11:18:06.307665 26473 solver.cpp:261]     Train net output #0: loss = 0.502902 (* 1 = 0.502902 loss)
I0502 11:18:06.307675 26473 sgd_solver.cpp:106] Iteration 49900, lr = 4.096e-05
I0502 11:18:06.312577 26473 solver.cpp:242] Iteration 49900 (104.902 iter/s, 0.953269s/100 iter), loss = 0.0324364
I0502 11:18:06.312602 26473 solver.cpp:261]     Train net output #0: loss = 0.0324364 (* 1 = 0.0324364 loss)
I0502 11:18:06.312609 26473 sgd_solver.cpp:106] Iteration 49900, lr = 4.096e-05
I0502 11:18:07.250505 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_50000.caffemodel
I0502 11:18:07.255749 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_50000.solverstate
I0502 11:18:07.262691 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_50000.caffemodel
I0502 11:18:07.268317 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_50000.solverstate
I0502 11:18:07.271942 26473 solver.cpp:362] Iteration 50000, Testing net (#0)
I0502 11:18:07.271958 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:07.397100 26473 solver.cpp:429]     Test net output #0: loss = 0.444446 (* 1 = 0.444446 loss)
I0502 11:18:07.399979 26473 solver.cpp:242] Iteration 50000 (91.5503 iter/s, 1.0923s/100 iter), loss = 0.108194
I0502 11:18:07.400001 26473 solver.cpp:261]     Train net output #0: loss = 0.108194 (* 1 = 0.108194 loss)
I0502 11:18:07.400009 26473 sgd_solver.cpp:106] Iteration 50000, lr = 3.2768e-05
I0502 11:18:07.401790 26473 solver.cpp:362] Iteration 50000, Testing net (#0)
I0502 11:18:07.401803 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:07.533185 26473 solver.cpp:429]     Test net output #0: accuracy = 0.914
I0502 11:18:07.533211 26473 solver.cpp:429]     Test net output #1: loss = 0.19157 (* 1 = 0.19157 loss)
I0502 11:18:07.536162 26473 solver.cpp:242] Iteration 50000 (81.7301 iter/s, 1.22354s/100 iter), loss = 0.192372
I0502 11:18:07.536182 26473 solver.cpp:261]     Train net output #0: loss = 0.192372 (* 1 = 0.192372 loss)
I0502 11:18:07.536191 26473 sgd_solver.cpp:106] Iteration 50000, lr = 3.2768e-05
I0502 11:18:08.481887 26473 solver.cpp:242] Iteration 50100 (92.434 iter/s, 1.08185s/100 iter), loss = 0.125005
I0502 11:18:08.481930 26473 solver.cpp:261]     Train net output #0: loss = 0.125005 (* 1 = 0.125005 loss)
I0502 11:18:08.481937 26473 sgd_solver.cpp:106] Iteration 50100, lr = 3.2768e-05
I0502 11:18:08.486737 26473 solver.cpp:242] Iteration 50100 (105.204 iter/s, 0.950535s/100 iter), loss = 0.0382071
I0502 11:18:08.486760 26473 solver.cpp:261]     Train net output #0: loss = 0.0382071 (* 1 = 0.0382071 loss)
I0502 11:18:08.486769 26473 sgd_solver.cpp:106] Iteration 50100, lr = 3.2768e-05
I0502 11:18:09.431593 26473 solver.cpp:242] Iteration 50200 (105.304 iter/s, 0.949636s/100 iter), loss = 0.347486
I0502 11:18:09.431632 26473 solver.cpp:261]     Train net output #0: loss = 0.347486 (* 1 = 0.347486 loss)
I0502 11:18:09.431640 26473 sgd_solver.cpp:106] Iteration 50200, lr = 3.2768e-05
I0502 11:18:09.436447 26473 solver.cpp:242] Iteration 50200 (105.3 iter/s, 0.949669s/100 iter), loss = 0.130232
I0502 11:18:09.436470 26473 solver.cpp:261]     Train net output #0: loss = 0.130232 (* 1 = 0.130232 loss)
I0502 11:18:09.436478 26473 sgd_solver.cpp:106] Iteration 50200, lr = 3.2768e-05
I0502 11:18:10.381690 26473 solver.cpp:242] Iteration 50300 (105.26 iter/s, 0.95003s/100 iter), loss = 0.52281
I0502 11:18:10.381726 26473 solver.cpp:261]     Train net output #0: loss = 0.52281 (* 1 = 0.52281 loss)
I0502 11:18:10.381734 26473 sgd_solver.cpp:106] Iteration 50300, lr = 3.2768e-05
I0502 11:18:10.386530 26473 solver.cpp:242] Iteration 50300 (105.259 iter/s, 0.950042s/100 iter), loss = 0.365493
I0502 11:18:10.386554 26473 solver.cpp:261]     Train net output #0: loss = 0.365493 (* 1 = 0.365493 loss)
I0502 11:18:10.386562 26473 sgd_solver.cpp:106] Iteration 50300, lr = 3.2768e-05
I0502 11:18:11.330801 26473 solver.cpp:242] Iteration 50400 (105.369 iter/s, 0.949047s/100 iter), loss = 0.281657
I0502 11:18:11.330850 26473 solver.cpp:261]     Train net output #0: loss = 0.281657 (* 1 = 0.281657 loss)
I0502 11:18:11.330860 26473 sgd_solver.cpp:106] Iteration 50400, lr = 3.2768e-05
I0502 11:18:11.335703 26473 solver.cpp:242] Iteration 50400 (105.36 iter/s, 0.949131s/100 iter), loss = 0.113521
I0502 11:18:11.335736 26473 solver.cpp:261]     Train net output #0: loss = 0.113521 (* 1 = 0.113521 loss)
I0502 11:18:11.335746 26473 sgd_solver.cpp:106] Iteration 50400, lr = 3.2768e-05
I0502 11:18:12.278368 26473 solver.cpp:362] Iteration 50500, Testing net (#0)
I0502 11:18:12.278394 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:12.403422 26473 solver.cpp:429]     Test net output #0: loss = 0.382057 (* 1 = 0.382057 loss)
I0502 11:18:12.406306 26473 solver.cpp:242] Iteration 50500 (92.9856 iter/s, 1.07544s/100 iter), loss = 0.383376
I0502 11:18:12.406327 26473 solver.cpp:261]     Train net output #0: loss = 0.383376 (* 1 = 0.383376 loss)
I0502 11:18:12.406335 26473 sgd_solver.cpp:106] Iteration 50500, lr = 3.2768e-05
I0502 11:18:12.408082 26473 solver.cpp:362] Iteration 50500, Testing net (#0)
I0502 11:18:12.408095 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:12.539296 26473 solver.cpp:429]     Test net output #0: accuracy = 0.949
I0502 11:18:12.539316 26473 solver.cpp:429]     Test net output #1: loss = 0.135846 (* 1 = 0.135846 loss)
I0502 11:18:12.542250 26473 solver.cpp:242] Iteration 50500 (82.8849 iter/s, 1.20649s/100 iter), loss = 0.0567296
I0502 11:18:12.542279 26473 solver.cpp:261]     Train net output #0: loss = 0.0567296 (* 1 = 0.0567296 loss)
I0502 11:18:12.542289 26473 sgd_solver.cpp:106] Iteration 50500, lr = 3.2768e-05
I0502 11:18:13.487195 26473 solver.cpp:242] Iteration 50600 (92.5204 iter/s, 1.08084s/100 iter), loss = 0.450415
I0502 11:18:13.487234 26473 solver.cpp:261]     Train net output #0: loss = 0.450415 (* 1 = 0.450415 loss)
I0502 11:18:13.487243 26473 sgd_solver.cpp:106] Iteration 50600, lr = 3.2768e-05
I0502 11:18:13.492090 26473 solver.cpp:242] Iteration 50600 (105.287 iter/s, 0.949787s/100 iter), loss = 0.190458
I0502 11:18:13.492113 26473 solver.cpp:261]     Train net output #0: loss = 0.190458 (* 1 = 0.190458 loss)
I0502 11:18:13.492122 26473 sgd_solver.cpp:106] Iteration 50600, lr = 3.2768e-05
I0502 11:18:14.438220 26473 solver.cpp:242] Iteration 50700 (105.157 iter/s, 0.950955s/100 iter), loss = 0.200786
I0502 11:18:14.438256 26473 solver.cpp:261]     Train net output #0: loss = 0.200786 (* 1 = 0.200786 loss)
I0502 11:18:14.438264 26473 sgd_solver.cpp:106] Iteration 50700, lr = 3.2768e-05
I0502 11:18:14.443084 26473 solver.cpp:242] Iteration 50700 (105.158 iter/s, 0.950952s/100 iter), loss = 0.202364
I0502 11:18:14.443106 26473 solver.cpp:261]     Train net output #0: loss = 0.202364 (* 1 = 0.202364 loss)
I0502 11:18:14.443115 26473 sgd_solver.cpp:106] Iteration 50700, lr = 3.2768e-05
I0502 11:18:15.387826 26473 solver.cpp:242] Iteration 50800 (105.314 iter/s, 0.949544s/100 iter), loss = 0.657631
I0502 11:18:15.387857 26473 solver.cpp:261]     Train net output #0: loss = 0.657631 (* 1 = 0.657631 loss)
I0502 11:18:15.387866 26473 sgd_solver.cpp:106] Iteration 50800, lr = 3.2768e-05
I0502 11:18:15.392657 26473 solver.cpp:242] Iteration 50800 (105.315 iter/s, 0.949531s/100 iter), loss = 0.0231301
I0502 11:18:15.392679 26473 solver.cpp:261]     Train net output #0: loss = 0.0231301 (* 1 = 0.0231301 loss)
I0502 11:18:15.392688 26473 sgd_solver.cpp:106] Iteration 50800, lr = 3.2768e-05
I0502 11:18:16.340626 26473 solver.cpp:242] Iteration 50900 (104.961 iter/s, 0.952739s/100 iter), loss = 0.310479
I0502 11:18:16.340687 26473 solver.cpp:261]     Train net output #0: loss = 0.310479 (* 1 = 0.310479 loss)
I0502 11:18:16.340698 26473 sgd_solver.cpp:106] Iteration 50900, lr = 3.2768e-05
I0502 11:18:16.345544 26473 solver.cpp:242] Iteration 50900 (104.949 iter/s, 0.952845s/100 iter), loss = 0.031934
I0502 11:18:16.345569 26473 solver.cpp:261]     Train net output #0: loss = 0.031934 (* 1 = 0.031934 loss)
I0502 11:18:16.345578 26473 sgd_solver.cpp:106] Iteration 50900, lr = 3.2768e-05
I0502 11:18:17.287957 26473 solver.cpp:362] Iteration 51000, Testing net (#0)
I0502 11:18:17.287986 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:17.413003 26473 solver.cpp:429]     Test net output #0: loss = 0.340439 (* 1 = 0.340439 loss)
I0502 11:18:17.415859 26473 solver.cpp:242] Iteration 51000 (93.0099 iter/s, 1.07515s/100 iter), loss = 0.0755062
I0502 11:18:17.415879 26473 solver.cpp:261]     Train net output #0: loss = 0.0755062 (* 1 = 0.0755062 loss)
I0502 11:18:17.415889 26473 sgd_solver.cpp:106] Iteration 51000, lr = 3.2768e-05
I0502 11:18:17.417619 26473 solver.cpp:362] Iteration 51000, Testing net (#0)
I0502 11:18:17.417634 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:17.548715 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9405
I0502 11:18:17.548738 26473 solver.cpp:429]     Test net output #1: loss = 0.143101 (* 1 = 0.143101 loss)
I0502 11:18:17.551672 26473 solver.cpp:242] Iteration 51000 (82.9131 iter/s, 1.20608s/100 iter), loss = 0.159172
I0502 11:18:17.551692 26473 solver.cpp:261]     Train net output #0: loss = 0.159172 (* 1 = 0.159172 loss)
I0502 11:18:17.551702 26473 sgd_solver.cpp:106] Iteration 51000, lr = 3.2768e-05
I0502 11:18:18.497334 26473 solver.cpp:242] Iteration 51100 (92.4705 iter/s, 1.08143s/100 iter), loss = 0.525824
I0502 11:18:18.497366 26473 solver.cpp:261]     Train net output #0: loss = 0.525824 (* 1 = 0.525824 loss)
I0502 11:18:18.497375 26473 sgd_solver.cpp:106] Iteration 51100, lr = 3.2768e-05
I0502 11:18:18.502243 26473 solver.cpp:242] Iteration 51100 (105.205 iter/s, 0.950524s/100 iter), loss = 0.0512413
I0502 11:18:18.502265 26473 solver.cpp:261]     Train net output #0: loss = 0.0512413 (* 1 = 0.0512413 loss)
I0502 11:18:18.502285 26473 sgd_solver.cpp:106] Iteration 51100, lr = 3.2768e-05
I0502 11:18:19.446907 26473 solver.cpp:242] Iteration 51200 (105.317 iter/s, 0.94951s/100 iter), loss = 0.5702
I0502 11:18:19.446943 26473 solver.cpp:261]     Train net output #0: loss = 0.5702 (* 1 = 0.5702 loss)
I0502 11:18:19.446951 26473 sgd_solver.cpp:106] Iteration 51200, lr = 3.2768e-05
I0502 11:18:19.451736 26473 solver.cpp:242] Iteration 51200 (105.324 iter/s, 0.949453s/100 iter), loss = 0.0795828
I0502 11:18:19.451759 26473 solver.cpp:261]     Train net output #0: loss = 0.0795828 (* 1 = 0.0795828 loss)
I0502 11:18:19.451768 26473 sgd_solver.cpp:106] Iteration 51200, lr = 3.2768e-05
I0502 11:18:20.396960 26473 solver.cpp:242] Iteration 51300 (105.265 iter/s, 0.949987s/100 iter), loss = 0.115211
I0502 11:18:20.397002 26473 solver.cpp:261]     Train net output #0: loss = 0.115211 (* 1 = 0.115211 loss)
I0502 11:18:20.397011 26473 sgd_solver.cpp:106] Iteration 51300, lr = 3.2768e-05
I0502 11:18:20.401793 26473 solver.cpp:242] Iteration 51300 (105.262 iter/s, 0.950015s/100 iter), loss = 0.144649
I0502 11:18:20.401815 26473 solver.cpp:261]     Train net output #0: loss = 0.144649 (* 1 = 0.144649 loss)
I0502 11:18:20.401823 26473 sgd_solver.cpp:106] Iteration 51300, lr = 3.2768e-05
I0502 11:18:21.346637 26473 solver.cpp:242] Iteration 51400 (105.307 iter/s, 0.949606s/100 iter), loss = 0.153084
I0502 11:18:21.346693 26473 solver.cpp:261]     Train net output #0: loss = 0.153084 (* 1 = 0.153084 loss)
I0502 11:18:21.346701 26473 sgd_solver.cpp:106] Iteration 51400, lr = 3.2768e-05
I0502 11:18:21.351534 26473 solver.cpp:242] Iteration 51400 (105.296 iter/s, 0.949701s/100 iter), loss = 0.197992
I0502 11:18:21.351557 26473 solver.cpp:261]     Train net output #0: loss = 0.197992 (* 1 = 0.197992 loss)
I0502 11:18:21.351565 26473 sgd_solver.cpp:106] Iteration 51400, lr = 3.2768e-05
I0502 11:18:22.293704 26473 solver.cpp:362] Iteration 51500, Testing net (#0)
I0502 11:18:22.293730 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:22.418716 26473 solver.cpp:429]     Test net output #0: loss = 0.43803 (* 1 = 0.43803 loss)
I0502 11:18:22.421620 26473 solver.cpp:242] Iteration 51500 (93.0312 iter/s, 1.07491s/100 iter), loss = 0.463163
I0502 11:18:22.421640 26473 solver.cpp:261]     Train net output #0: loss = 0.463163 (* 1 = 0.463163 loss)
I0502 11:18:22.421649 26473 sgd_solver.cpp:106] Iteration 51500, lr = 3.2768e-05
I0502 11:18:22.423360 26473 solver.cpp:362] Iteration 51500, Testing net (#0)
I0502 11:18:22.423375 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:22.554713 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9535
I0502 11:18:22.554738 26473 solver.cpp:429]     Test net output #1: loss = 0.132225 (* 1 = 0.132225 loss)
I0502 11:18:22.557693 26473 solver.cpp:242] Iteration 51500 (82.9109 iter/s, 1.20611s/100 iter), loss = 0.021727
I0502 11:18:22.557713 26473 solver.cpp:261]     Train net output #0: loss = 0.021727 (* 1 = 0.021727 loss)
I0502 11:18:22.557721 26473 sgd_solver.cpp:106] Iteration 51500, lr = 3.2768e-05
I0502 11:18:23.502928 26473 solver.cpp:242] Iteration 51600 (92.4847 iter/s, 1.08126s/100 iter), loss = 0.116944
I0502 11:18:23.502971 26473 solver.cpp:261]     Train net output #0: loss = 0.116944 (* 1 = 0.116944 loss)
I0502 11:18:23.502980 26473 sgd_solver.cpp:106] Iteration 51600, lr = 3.2768e-05
I0502 11:18:23.507843 26473 solver.cpp:242] Iteration 51600 (105.252 iter/s, 0.950103s/100 iter), loss = 0.220064
I0502 11:18:23.507866 26473 solver.cpp:261]     Train net output #0: loss = 0.220064 (* 1 = 0.220064 loss)
I0502 11:18:23.507875 26473 sgd_solver.cpp:106] Iteration 51600, lr = 3.2768e-05
I0502 11:18:24.454084 26473 solver.cpp:242] Iteration 51700 (105.144 iter/s, 0.951081s/100 iter), loss = 0.293662
I0502 11:18:24.454136 26473 solver.cpp:261]     Train net output #0: loss = 0.293662 (* 1 = 0.293662 loss)
I0502 11:18:24.454145 26473 sgd_solver.cpp:106] Iteration 51700, lr = 3.2768e-05
I0502 11:18:24.458941 26473 solver.cpp:242] Iteration 51700 (105.146 iter/s, 0.951056s/100 iter), loss = 0.155976
I0502 11:18:24.458964 26473 solver.cpp:261]     Train net output #0: loss = 0.155976 (* 1 = 0.155976 loss)
I0502 11:18:24.458972 26473 sgd_solver.cpp:106] Iteration 51700, lr = 3.2768e-05
I0502 11:18:25.403759 26473 solver.cpp:242] Iteration 51800 (105.308 iter/s, 0.949594s/100 iter), loss = 0.137955
I0502 11:18:25.403800 26473 solver.cpp:261]     Train net output #0: loss = 0.137955 (* 1 = 0.137955 loss)
I0502 11:18:25.403808 26473 sgd_solver.cpp:106] Iteration 51800, lr = 3.2768e-05
I0502 11:18:25.408602 26473 solver.cpp:242] Iteration 51800 (105.305 iter/s, 0.949621s/100 iter), loss = 0.268078
I0502 11:18:25.408627 26473 solver.cpp:261]     Train net output #0: loss = 0.268078 (* 1 = 0.268078 loss)
I0502 11:18:25.408634 26473 sgd_solver.cpp:106] Iteration 51800, lr = 3.2768e-05
I0502 11:18:26.354303 26473 solver.cpp:242] Iteration 51900 (105.21 iter/s, 0.950476s/100 iter), loss = 0.522281
I0502 11:18:26.354357 26473 solver.cpp:261]     Train net output #0: loss = 0.522281 (* 1 = 0.522281 loss)
I0502 11:18:26.354367 26473 sgd_solver.cpp:106] Iteration 51900, lr = 3.2768e-05
I0502 11:18:26.359211 26473 solver.cpp:242] Iteration 51900 (105.2 iter/s, 0.950567s/100 iter), loss = 0.141347
I0502 11:18:26.359236 26473 solver.cpp:261]     Train net output #0: loss = 0.141347 (* 1 = 0.141347 loss)
I0502 11:18:26.359244 26473 sgd_solver.cpp:106] Iteration 51900, lr = 3.2768e-05
I0502 11:18:27.300657 26473 solver.cpp:362] Iteration 52000, Testing net (#0)
I0502 11:18:27.300680 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:27.425551 26473 solver.cpp:429]     Test net output #0: loss = 0.375245 (* 1 = 0.375245 loss)
I0502 11:18:27.428434 26473 solver.cpp:242] Iteration 52000 (93.1047 iter/s, 1.07406s/100 iter), loss = 0.31916
I0502 11:18:27.428454 26473 solver.cpp:261]     Train net output #0: loss = 0.31916 (* 1 = 0.31916 loss)
I0502 11:18:27.428462 26473 sgd_solver.cpp:106] Iteration 52000, lr = 3.2768e-05
I0502 11:18:27.430104 26473 solver.cpp:362] Iteration 52000, Testing net (#0)
I0502 11:18:27.430119 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:27.561357 26473 solver.cpp:429]     Test net output #0: accuracy = 0.933
I0502 11:18:27.561380 26473 solver.cpp:429]     Test net output #1: loss = 0.136842 (* 1 = 0.136842 loss)
I0502 11:18:27.564324 26473 solver.cpp:242] Iteration 52000 (82.9829 iter/s, 1.20507s/100 iter), loss = 0.0627672
I0502 11:18:27.564345 26473 solver.cpp:261]     Train net output #0: loss = 0.0627672 (* 1 = 0.0627672 loss)
I0502 11:18:27.564354 26473 sgd_solver.cpp:106] Iteration 52000, lr = 3.2768e-05
I0502 11:18:28.509626 26473 solver.cpp:242] Iteration 52100 (92.4946 iter/s, 1.08114s/100 iter), loss = 0.632893
I0502 11:18:28.509666 26473 solver.cpp:261]     Train net output #0: loss = 0.632893 (* 1 = 0.632893 loss)
I0502 11:18:28.509675 26473 sgd_solver.cpp:106] Iteration 52100, lr = 3.2768e-05
I0502 11:18:28.514523 26473 solver.cpp:242] Iteration 52100 (105.247 iter/s, 0.95015s/100 iter), loss = 0.211682
I0502 11:18:28.514546 26473 solver.cpp:261]     Train net output #0: loss = 0.211682 (* 1 = 0.211682 loss)
I0502 11:18:28.514555 26473 sgd_solver.cpp:106] Iteration 52100, lr = 3.2768e-05
I0502 11:18:29.458961 26473 solver.cpp:242] Iteration 52200 (105.345 iter/s, 0.949261s/100 iter), loss = 0.117913
I0502 11:18:29.458998 26473 solver.cpp:261]     Train net output #0: loss = 0.117913 (* 1 = 0.117913 loss)
I0502 11:18:29.459008 26473 sgd_solver.cpp:106] Iteration 52200, lr = 3.2768e-05
I0502 11:18:29.463810 26473 solver.cpp:242] Iteration 52200 (105.347 iter/s, 0.949245s/100 iter), loss = 0.0658261
I0502 11:18:29.463834 26473 solver.cpp:261]     Train net output #0: loss = 0.0658261 (* 1 = 0.0658261 loss)
I0502 11:18:29.463841 26473 sgd_solver.cpp:106] Iteration 52200, lr = 3.2768e-05
I0502 11:18:30.409533 26473 solver.cpp:242] Iteration 52300 (105.207 iter/s, 0.950504s/100 iter), loss = 0.423599
I0502 11:18:30.409567 26473 solver.cpp:261]     Train net output #0: loss = 0.423599 (* 1 = 0.423599 loss)
I0502 11:18:30.409576 26473 sgd_solver.cpp:106] Iteration 52300, lr = 3.2768e-05
I0502 11:18:30.414361 26473 solver.cpp:242] Iteration 52300 (105.207 iter/s, 0.95051s/100 iter), loss = 0.21805
I0502 11:18:30.414384 26473 solver.cpp:261]     Train net output #0: loss = 0.21805 (* 1 = 0.21805 loss)
I0502 11:18:30.414392 26473 sgd_solver.cpp:106] Iteration 52300, lr = 3.2768e-05
I0502 11:18:31.358968 26473 solver.cpp:242] Iteration 52400 (105.333 iter/s, 0.949374s/100 iter), loss = 0.223146
I0502 11:18:31.359015 26473 solver.cpp:261]     Train net output #0: loss = 0.223146 (* 1 = 0.223146 loss)
I0502 11:18:31.359025 26473 sgd_solver.cpp:106] Iteration 52400, lr = 3.2768e-05
I0502 11:18:31.363886 26473 solver.cpp:242] Iteration 52400 (105.32 iter/s, 0.949484s/100 iter), loss = 0.0946052
I0502 11:18:31.363910 26473 solver.cpp:261]     Train net output #0: loss = 0.0946052 (* 1 = 0.0946052 loss)
I0502 11:18:31.363919 26473 sgd_solver.cpp:106] Iteration 52400, lr = 3.2768e-05
I0502 11:18:32.306421 26473 solver.cpp:362] Iteration 52500, Testing net (#0)
I0502 11:18:32.306443 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:32.431449 26473 solver.cpp:429]     Test net output #0: loss = 0.442689 (* 1 = 0.442689 loss)
I0502 11:18:32.434329 26473 solver.cpp:242] Iteration 52500 (92.9979 iter/s, 1.07529s/100 iter), loss = 0.364529
I0502 11:18:32.434348 26473 solver.cpp:261]     Train net output #0: loss = 0.364529 (* 1 = 0.364529 loss)
I0502 11:18:32.434357 26473 sgd_solver.cpp:106] Iteration 52500, lr = 3.2768e-05
I0502 11:18:32.435997 26473 solver.cpp:362] Iteration 52500, Testing net (#0)
I0502 11:18:32.436009 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:32.567044 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9495
I0502 11:18:32.567065 26473 solver.cpp:429]     Test net output #1: loss = 0.121185 (* 1 = 0.121185 loss)
I0502 11:18:32.569999 26473 solver.cpp:242] Iteration 52500 (82.9141 iter/s, 1.20607s/100 iter), loss = 0.174187
I0502 11:18:32.570019 26473 solver.cpp:261]     Train net output #0: loss = 0.174187 (* 1 = 0.174187 loss)
I0502 11:18:32.570029 26473 sgd_solver.cpp:106] Iteration 52500, lr = 3.2768e-05
I0502 11:18:33.514363 26473 solver.cpp:242] Iteration 52600 (92.5939 iter/s, 1.07999s/100 iter), loss = 0.262784
I0502 11:18:33.514398 26473 solver.cpp:261]     Train net output #0: loss = 0.262784 (* 1 = 0.262784 loss)
I0502 11:18:33.514407 26473 sgd_solver.cpp:106] Iteration 52600, lr = 3.2768e-05
I0502 11:18:33.519259 26473 solver.cpp:242] Iteration 52600 (105.35 iter/s, 0.949213s/100 iter), loss = 0.121913
I0502 11:18:33.519284 26473 solver.cpp:261]     Train net output #0: loss = 0.121913 (* 1 = 0.121913 loss)
I0502 11:18:33.519292 26473 sgd_solver.cpp:106] Iteration 52600, lr = 3.2768e-05
I0502 11:18:34.464618 26473 solver.cpp:242] Iteration 52700 (105.242 iter/s, 0.950188s/100 iter), loss = 0.529281
I0502 11:18:34.464656 26473 solver.cpp:261]     Train net output #0: loss = 0.529281 (* 1 = 0.529281 loss)
I0502 11:18:34.464665 26473 sgd_solver.cpp:106] Iteration 52700, lr = 3.2768e-05
I0502 11:18:34.469442 26473 solver.cpp:242] Iteration 52700 (105.248 iter/s, 0.95014s/100 iter), loss = 0.100289
I0502 11:18:34.469465 26473 solver.cpp:261]     Train net output #0: loss = 0.100289 (* 1 = 0.100289 loss)
I0502 11:18:34.469473 26473 sgd_solver.cpp:106] Iteration 52700, lr = 3.2768e-05
I0502 11:18:35.413410 26473 solver.cpp:242] Iteration 52800 (105.404 iter/s, 0.948727s/100 iter), loss = 0.786432
I0502 11:18:35.413440 26473 solver.cpp:261]     Train net output #0: loss = 0.786432 (* 1 = 0.786432 loss)
I0502 11:18:35.413450 26473 sgd_solver.cpp:106] Iteration 52800, lr = 3.2768e-05
I0502 11:18:35.418222 26473 solver.cpp:242] Iteration 52800 (105.403 iter/s, 0.94874s/100 iter), loss = 0.0601499
I0502 11:18:35.418246 26473 solver.cpp:261]     Train net output #0: loss = 0.0601499 (* 1 = 0.0601499 loss)
I0502 11:18:35.418262 26473 sgd_solver.cpp:106] Iteration 52800, lr = 3.2768e-05
I0502 11:18:36.365077 26473 solver.cpp:242] Iteration 52900 (105.085 iter/s, 0.951606s/100 iter), loss = 0.133557
I0502 11:18:36.365137 26473 solver.cpp:261]     Train net output #0: loss = 0.133557 (* 1 = 0.133557 loss)
I0502 11:18:36.365152 26473 sgd_solver.cpp:106] Iteration 52900, lr = 3.2768e-05
I0502 11:18:36.369992 26473 solver.cpp:242] Iteration 52900 (105.072 iter/s, 0.951728s/100 iter), loss = 0.269189
I0502 11:18:36.370015 26473 solver.cpp:261]     Train net output #0: loss = 0.269189 (* 1 = 0.269189 loss)
I0502 11:18:36.370023 26473 sgd_solver.cpp:106] Iteration 52900, lr = 3.2768e-05
I0502 11:18:37.312309 26473 solver.cpp:362] Iteration 53000, Testing net (#0)
I0502 11:18:37.312336 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:37.437228 26473 solver.cpp:429]     Test net output #0: loss = 0.562777 (* 1 = 0.562777 loss)
I0502 11:18:37.440114 26473 solver.cpp:242] Iteration 53000 (93.0269 iter/s, 1.07496s/100 iter), loss = 0.267376
I0502 11:18:37.440135 26473 solver.cpp:261]     Train net output #0: loss = 0.267376 (* 1 = 0.267376 loss)
I0502 11:18:37.440142 26473 sgd_solver.cpp:106] Iteration 53000, lr = 3.2768e-05
I0502 11:18:37.441800 26473 solver.cpp:362] Iteration 53000, Testing net (#0)
I0502 11:18:37.441814 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:37.573148 26473 solver.cpp:429]     Test net output #0: accuracy = 0.925
I0502 11:18:37.573169 26473 solver.cpp:429]     Test net output #1: loss = 0.188454 (* 1 = 0.188454 loss)
I0502 11:18:37.576123 26473 solver.cpp:242] Iteration 53000 (82.9127 iter/s, 1.20609s/100 iter), loss = 0.176289
I0502 11:18:37.576143 26473 solver.cpp:261]     Train net output #0: loss = 0.176289 (* 1 = 0.176289 loss)
I0502 11:18:37.576153 26473 sgd_solver.cpp:106] Iteration 53000, lr = 3.2768e-05
I0502 11:18:38.521471 26473 solver.cpp:242] Iteration 53100 (92.4805 iter/s, 1.08131s/100 iter), loss = 0.717141
I0502 11:18:38.521500 26473 solver.cpp:261]     Train net output #0: loss = 0.717141 (* 1 = 0.717141 loss)
I0502 11:18:38.521509 26473 sgd_solver.cpp:106] Iteration 53100, lr = 3.2768e-05
I0502 11:18:38.526357 26473 solver.cpp:242] Iteration 53100 (105.243 iter/s, 0.950186s/100 iter), loss = 0.226685
I0502 11:18:38.526381 26473 solver.cpp:261]     Train net output #0: loss = 0.226685 (* 1 = 0.226685 loss)
I0502 11:18:38.526389 26473 sgd_solver.cpp:106] Iteration 53100, lr = 3.2768e-05
I0502 11:18:39.471803 26473 solver.cpp:242] Iteration 53200 (105.233 iter/s, 0.95027s/100 iter), loss = 0.315494
I0502 11:18:39.471843 26473 solver.cpp:261]     Train net output #0: loss = 0.315494 (* 1 = 0.315494 loss)
I0502 11:18:39.471853 26473 sgd_solver.cpp:106] Iteration 53200, lr = 3.2768e-05
I0502 11:18:39.476641 26473 solver.cpp:242] Iteration 53200 (105.236 iter/s, 0.950243s/100 iter), loss = 0.151144
I0502 11:18:39.476665 26473 solver.cpp:261]     Train net output #0: loss = 0.151144 (* 1 = 0.151144 loss)
I0502 11:18:39.476673 26473 sgd_solver.cpp:106] Iteration 53200, lr = 3.2768e-05
I0502 11:18:40.420907 26473 solver.cpp:242] Iteration 53300 (105.37 iter/s, 0.949033s/100 iter), loss = 2.33115
I0502 11:18:40.420949 26473 solver.cpp:261]     Train net output #0: loss = 2.33115 (* 1 = 2.33115 loss)
I0502 11:18:40.420958 26473 sgd_solver.cpp:106] Iteration 53300, lr = 3.2768e-05
I0502 11:18:40.425740 26473 solver.cpp:242] Iteration 53300 (105.368 iter/s, 0.949055s/100 iter), loss = 0.159699
I0502 11:18:40.425763 26473 solver.cpp:261]     Train net output #0: loss = 0.159699 (* 1 = 0.159699 loss)
I0502 11:18:40.425771 26473 sgd_solver.cpp:106] Iteration 53300, lr = 3.2768e-05
I0502 11:18:41.371803 26473 solver.cpp:242] Iteration 53400 (105.172 iter/s, 0.950824s/100 iter), loss = 0.105776
I0502 11:18:41.371860 26473 solver.cpp:261]     Train net output #0: loss = 0.105776 (* 1 = 0.105776 loss)
I0502 11:18:41.371870 26473 sgd_solver.cpp:106] Iteration 53400, lr = 3.2768e-05
I0502 11:18:41.376749 26473 solver.cpp:242] Iteration 53400 (105.156 iter/s, 0.950966s/100 iter), loss = 0.0616734
I0502 11:18:41.376780 26473 solver.cpp:261]     Train net output #0: loss = 0.0616734 (* 1 = 0.0616734 loss)
I0502 11:18:41.376790 26473 sgd_solver.cpp:106] Iteration 53400, lr = 3.2768e-05
I0502 11:18:42.319592 26473 solver.cpp:362] Iteration 53500, Testing net (#0)
I0502 11:18:42.319619 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:42.444552 26473 solver.cpp:429]     Test net output #0: loss = 0.466324 (* 1 = 0.466324 loss)
I0502 11:18:42.447423 26473 solver.cpp:242] Iteration 53500 (92.9762 iter/s, 1.07554s/100 iter), loss = 0.304091
I0502 11:18:42.447443 26473 solver.cpp:261]     Train net output #0: loss = 0.304091 (* 1 = 0.304091 loss)
I0502 11:18:42.447451 26473 sgd_solver.cpp:106] Iteration 53500, lr = 3.2768e-05
I0502 11:18:42.449100 26473 solver.cpp:362] Iteration 53500, Testing net (#0)
I0502 11:18:42.449113 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:42.580158 26473 solver.cpp:429]     Test net output #0: accuracy = 0.934
I0502 11:18:42.580179 26473 solver.cpp:429]     Test net output #1: loss = 0.147629 (* 1 = 0.147629 loss)
I0502 11:18:42.583111 26473 solver.cpp:242] Iteration 53500 (82.8974 iter/s, 1.20631s/100 iter), loss = 0.104169
I0502 11:18:42.583130 26473 solver.cpp:261]     Train net output #0: loss = 0.104169 (* 1 = 0.104169 loss)
I0502 11:18:42.583139 26473 sgd_solver.cpp:106] Iteration 53500, lr = 3.2768e-05
I0502 11:18:43.528949 26473 solver.cpp:242] Iteration 53600 (92.4663 iter/s, 1.08148s/100 iter), loss = 0.321914
I0502 11:18:43.528990 26473 solver.cpp:261]     Train net output #0: loss = 0.321914 (* 1 = 0.321914 loss)
I0502 11:18:43.529000 26473 sgd_solver.cpp:106] Iteration 53600, lr = 3.2768e-05
I0502 11:18:43.533849 26473 solver.cpp:242] Iteration 53600 (105.187 iter/s, 0.95069s/100 iter), loss = 0.079221
I0502 11:18:43.533872 26473 solver.cpp:261]     Train net output #0: loss = 0.079221 (* 1 = 0.079221 loss)
I0502 11:18:43.533881 26473 sgd_solver.cpp:106] Iteration 53600, lr = 3.2768e-05
I0502 11:18:44.478094 26473 solver.cpp:242] Iteration 53700 (105.365 iter/s, 0.94908s/100 iter), loss = 0.47227
I0502 11:18:44.478134 26473 solver.cpp:261]     Train net output #0: loss = 0.47227 (* 1 = 0.47227 loss)
I0502 11:18:44.478143 26473 sgd_solver.cpp:106] Iteration 53700, lr = 3.2768e-05
I0502 11:18:44.482995 26473 solver.cpp:242] Iteration 53700 (105.363 iter/s, 0.949099s/100 iter), loss = 0.131152
I0502 11:18:44.483018 26473 solver.cpp:261]     Train net output #0: loss = 0.131152 (* 1 = 0.131152 loss)
I0502 11:18:44.483027 26473 sgd_solver.cpp:106] Iteration 53700, lr = 3.2768e-05
I0502 11:18:45.428699 26473 solver.cpp:242] Iteration 53800 (105.204 iter/s, 0.950533s/100 iter), loss = 0.203129
I0502 11:18:45.428740 26473 solver.cpp:261]     Train net output #0: loss = 0.203129 (* 1 = 0.203129 loss)
I0502 11:18:45.428750 26473 sgd_solver.cpp:106] Iteration 53800, lr = 3.2768e-05
I0502 11:18:45.433542 26473 solver.cpp:242] Iteration 53800 (105.207 iter/s, 0.950505s/100 iter), loss = 0.00686713
I0502 11:18:45.433565 26473 solver.cpp:261]     Train net output #0: loss = 0.00686713 (* 1 = 0.00686713 loss)
I0502 11:18:45.433573 26473 sgd_solver.cpp:106] Iteration 53800, lr = 3.2768e-05
I0502 11:18:46.380434 26473 solver.cpp:242] Iteration 53900 (105.079 iter/s, 0.951664s/100 iter), loss = 1.53805
I0502 11:18:46.380486 26473 solver.cpp:261]     Train net output #0: loss = 1.53805 (* 1 = 1.53805 loss)
I0502 11:18:46.380501 26473 sgd_solver.cpp:106] Iteration 53900, lr = 3.2768e-05
I0502 11:18:46.385336 26473 solver.cpp:242] Iteration 53900 (105.069 iter/s, 0.951754s/100 iter), loss = 0.0881408
I0502 11:18:46.385360 26473 solver.cpp:261]     Train net output #0: loss = 0.0881408 (* 1 = 0.0881408 loss)
I0502 11:18:46.385370 26473 sgd_solver.cpp:106] Iteration 53900, lr = 3.2768e-05
I0502 11:18:47.325400 26473 solver.cpp:362] Iteration 54000, Testing net (#0)
I0502 11:18:47.325424 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:47.449848 26473 solver.cpp:429]     Test net output #0: loss = 0.361039 (* 1 = 0.361039 loss)
I0502 11:18:47.452718 26473 solver.cpp:242] Iteration 54000 (93.265 iter/s, 1.07221s/100 iter), loss = 0.221845
I0502 11:18:47.452739 26473 solver.cpp:261]     Train net output #0: loss = 0.221845 (* 1 = 0.221845 loss)
I0502 11:18:47.452747 26473 sgd_solver.cpp:106] Iteration 54000, lr = 3.2768e-05
I0502 11:18:47.454391 26473 solver.cpp:362] Iteration 54000, Testing net (#0)
I0502 11:18:47.454403 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:47.585161 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:18:47.585182 26473 solver.cpp:429]     Test net output #1: loss = 0.102538 (* 1 = 0.102538 loss)
I0502 11:18:47.588095 26473 solver.cpp:242] Iteration 54000 (83.1452 iter/s, 1.20271s/100 iter), loss = 0.0755911
I0502 11:18:47.588115 26473 solver.cpp:261]     Train net output #0: loss = 0.0755911 (* 1 = 0.0755911 loss)
I0502 11:18:47.588124 26473 sgd_solver.cpp:106] Iteration 54000, lr = 3.2768e-05
I0502 11:18:48.531359 26473 solver.cpp:242] Iteration 54100 (92.7136 iter/s, 1.07859s/100 iter), loss = 0.215087
I0502 11:18:48.531401 26473 solver.cpp:261]     Train net output #0: loss = 0.215087 (* 1 = 0.215087 loss)
I0502 11:18:48.531410 26473 sgd_solver.cpp:106] Iteration 54100, lr = 3.2768e-05
I0502 11:18:48.536216 26473 solver.cpp:242] Iteration 54100 (105.476 iter/s, 0.948082s/100 iter), loss = 0.0354764
I0502 11:18:48.536239 26473 solver.cpp:261]     Train net output #0: loss = 0.0354764 (* 1 = 0.0354764 loss)
I0502 11:18:48.536247 26473 sgd_solver.cpp:106] Iteration 54100, lr = 3.2768e-05
I0502 11:18:49.478238 26473 solver.cpp:242] Iteration 54200 (105.617 iter/s, 0.946813s/100 iter), loss = 0.0951003
I0502 11:18:49.478276 26473 solver.cpp:261]     Train net output #0: loss = 0.0951003 (* 1 = 0.0951003 loss)
I0502 11:18:49.478284 26473 sgd_solver.cpp:106] Iteration 54200, lr = 3.2768e-05
I0502 11:18:49.483139 26473 solver.cpp:242] Iteration 54200 (105.611 iter/s, 0.946872s/100 iter), loss = 0.169668
I0502 11:18:49.483161 26473 solver.cpp:261]     Train net output #0: loss = 0.169668 (* 1 = 0.169668 loss)
I0502 11:18:49.483170 26473 sgd_solver.cpp:106] Iteration 54200, lr = 3.2768e-05
I0502 11:18:50.426080 26473 solver.cpp:242] Iteration 54300 (105.511 iter/s, 0.947772s/100 iter), loss = 0.406696
I0502 11:18:50.426118 26473 solver.cpp:261]     Train net output #0: loss = 0.406696 (* 1 = 0.406696 loss)
I0502 11:18:50.426127 26473 sgd_solver.cpp:106] Iteration 54300, lr = 3.2768e-05
I0502 11:18:50.430910 26473 solver.cpp:242] Iteration 54300 (105.515 iter/s, 0.947731s/100 iter), loss = 0.170669
I0502 11:18:50.430934 26473 solver.cpp:261]     Train net output #0: loss = 0.170669 (* 1 = 0.170669 loss)
I0502 11:18:50.430943 26473 sgd_solver.cpp:106] Iteration 54300, lr = 3.2768e-05
I0502 11:18:51.373196 26473 solver.cpp:242] Iteration 54400 (105.591 iter/s, 0.94705s/100 iter), loss = 0.0519557
I0502 11:18:51.373229 26473 solver.cpp:261]     Train net output #0: loss = 0.0519557 (* 1 = 0.0519557 loss)
I0502 11:18:51.373237 26473 sgd_solver.cpp:106] Iteration 54400, lr = 3.2768e-05
I0502 11:18:51.378021 26473 solver.cpp:242] Iteration 54400 (105.589 iter/s, 0.947069s/100 iter), loss = 0.202261
I0502 11:18:51.378058 26473 solver.cpp:261]     Train net output #0: loss = 0.202261 (* 1 = 0.202261 loss)
I0502 11:18:51.378067 26473 sgd_solver.cpp:106] Iteration 54400, lr = 3.2768e-05
I0502 11:18:52.318050 26473 solver.cpp:362] Iteration 54500, Testing net (#0)
I0502 11:18:52.318079 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:52.442418 26473 solver.cpp:429]     Test net output #0: loss = 0.554319 (* 1 = 0.554319 loss)
I0502 11:18:52.445286 26473 solver.cpp:242] Iteration 54500 (93.2802 iter/s, 1.07204s/100 iter), loss = 0.247815
I0502 11:18:52.445307 26473 solver.cpp:261]     Train net output #0: loss = 0.247815 (* 1 = 0.247815 loss)
I0502 11:18:52.445314 26473 sgd_solver.cpp:106] Iteration 54500, lr = 3.2768e-05
I0502 11:18:52.446960 26473 solver.cpp:362] Iteration 54500, Testing net (#0)
I0502 11:18:52.446974 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:52.577610 26473 solver.cpp:429]     Test net output #0: accuracy = 0.926
I0502 11:18:52.577633 26473 solver.cpp:429]     Test net output #1: loss = 0.163138 (* 1 = 0.163138 loss)
I0502 11:18:52.580565 26473 solver.cpp:242] Iteration 54500 (83.161 iter/s, 1.20249s/100 iter), loss = 0.154565
I0502 11:18:52.580586 26473 solver.cpp:261]     Train net output #0: loss = 0.154565 (* 1 = 0.154565 loss)
I0502 11:18:52.580595 26473 sgd_solver.cpp:106] Iteration 54500, lr = 3.2768e-05
I0502 11:18:53.523177 26473 solver.cpp:242] Iteration 54600 (92.7779 iter/s, 1.07784s/100 iter), loss = 0.328771
I0502 11:18:53.523211 26473 solver.cpp:261]     Train net output #0: loss = 0.328771 (* 1 = 0.328771 loss)
I0502 11:18:53.523219 26473 sgd_solver.cpp:106] Iteration 54600, lr = 3.2768e-05
I0502 11:18:53.528022 26473 solver.cpp:242] Iteration 54600 (105.55 iter/s, 0.947418s/100 iter), loss = 0.0562869
I0502 11:18:53.528045 26473 solver.cpp:261]     Train net output #0: loss = 0.0562869 (* 1 = 0.0562869 loss)
I0502 11:18:53.528053 26473 sgd_solver.cpp:106] Iteration 54600, lr = 3.2768e-05
I0502 11:18:54.471585 26473 solver.cpp:242] Iteration 54700 (105.446 iter/s, 0.94835s/100 iter), loss = 0.16449
I0502 11:18:54.471617 26473 solver.cpp:261]     Train net output #0: loss = 0.16449 (* 1 = 0.16449 loss)
I0502 11:18:54.471626 26473 sgd_solver.cpp:106] Iteration 54700, lr = 3.2768e-05
I0502 11:18:54.476497 26473 solver.cpp:242] Iteration 54700 (105.438 iter/s, 0.948426s/100 iter), loss = 0.229188
I0502 11:18:54.476519 26473 solver.cpp:261]     Train net output #0: loss = 0.229188 (* 1 = 0.229188 loss)
I0502 11:18:54.476528 26473 sgd_solver.cpp:106] Iteration 54700, lr = 3.2768e-05
I0502 11:18:55.419924 26473 solver.cpp:242] Iteration 54800 (105.455 iter/s, 0.948276s/100 iter), loss = 0.938444
I0502 11:18:55.419955 26473 solver.cpp:261]     Train net output #0: loss = 0.938444 (* 1 = 0.938444 loss)
I0502 11:18:55.419965 26473 sgd_solver.cpp:106] Iteration 54800, lr = 3.2768e-05
I0502 11:18:55.424749 26473 solver.cpp:242] Iteration 54800 (105.462 iter/s, 0.948212s/100 iter), loss = 0.0656959
I0502 11:18:55.424772 26473 solver.cpp:261]     Train net output #0: loss = 0.0656959 (* 1 = 0.0656959 loss)
I0502 11:18:55.424782 26473 sgd_solver.cpp:106] Iteration 54800, lr = 3.2768e-05
I0502 11:18:56.369874 26473 solver.cpp:242] Iteration 54900 (105.275 iter/s, 0.949889s/100 iter), loss = 0.55203
I0502 11:18:56.369910 26473 solver.cpp:261]     Train net output #0: loss = 0.55203 (* 1 = 0.55203 loss)
I0502 11:18:56.369920 26473 sgd_solver.cpp:106] Iteration 54900, lr = 3.2768e-05
I0502 11:18:56.374716 26473 solver.cpp:242] Iteration 54900 (105.271 iter/s, 0.949925s/100 iter), loss = 0.159348
I0502 11:18:56.374739 26473 solver.cpp:261]     Train net output #0: loss = 0.159348 (* 1 = 0.159348 loss)
I0502 11:18:56.374748 26473 sgd_solver.cpp:106] Iteration 54900, lr = 3.2768e-05
I0502 11:18:57.335585 26473 solver.cpp:362] Iteration 55000, Testing net (#0)
I0502 11:18:57.335614 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:57.459939 26473 solver.cpp:429]     Test net output #0: loss = 0.390079 (* 1 = 0.390079 loss)
I0502 11:18:57.462815 26473 solver.cpp:242] Iteration 55000 (91.5009 iter/s, 1.09289s/100 iter), loss = 0.118789
I0502 11:18:57.462836 26473 solver.cpp:261]     Train net output #0: loss = 0.118789 (* 1 = 0.118789 loss)
I0502 11:18:57.462844 26473 sgd_solver.cpp:106] Iteration 55000, lr = 3.2768e-05
I0502 11:18:57.464527 26473 solver.cpp:362] Iteration 55000, Testing net (#0)
I0502 11:18:57.464540 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:18:57.595293 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9235
I0502 11:18:57.595314 26473 solver.cpp:429]     Test net output #1: loss = 0.165641 (* 1 = 0.165641 loss)
I0502 11:18:57.598242 26473 solver.cpp:242] Iteration 55000 (81.734 iter/s, 1.22348s/100 iter), loss = 0.0651774
I0502 11:18:57.598263 26473 solver.cpp:261]     Train net output #0: loss = 0.0651774 (* 1 = 0.0651774 loss)
I0502 11:18:57.598271 26473 sgd_solver.cpp:106] Iteration 55000, lr = 3.2768e-05
I0502 11:18:58.541115 26473 solver.cpp:242] Iteration 55100 (92.7429 iter/s, 1.07825s/100 iter), loss = 0.109582
I0502 11:18:58.541158 26473 solver.cpp:261]     Train net output #0: loss = 0.109582 (* 1 = 0.109582 loss)
I0502 11:18:58.541167 26473 sgd_solver.cpp:106] Iteration 55100, lr = 3.2768e-05
I0502 11:18:58.545976 26473 solver.cpp:242] Iteration 55100 (105.519 iter/s, 0.947695s/100 iter), loss = 0.214931
I0502 11:18:58.546000 26473 solver.cpp:261]     Train net output #0: loss = 0.214931 (* 1 = 0.214931 loss)
I0502 11:18:58.546008 26473 sgd_solver.cpp:106] Iteration 55100, lr = 3.2768e-05
I0502 11:18:59.488590 26473 solver.cpp:242] Iteration 55200 (105.551 iter/s, 0.947406s/100 iter), loss = 0.159239
I0502 11:18:59.488632 26473 solver.cpp:261]     Train net output #0: loss = 0.159239 (* 1 = 0.159239 loss)
I0502 11:18:59.488641 26473 sgd_solver.cpp:106] Iteration 55200, lr = 3.2768e-05
I0502 11:18:59.493542 26473 solver.cpp:242] Iteration 55200 (105.539 iter/s, 0.947515s/100 iter), loss = 0.0558944
I0502 11:18:59.493566 26473 solver.cpp:261]     Train net output #0: loss = 0.0558944 (* 1 = 0.0558944 loss)
I0502 11:18:59.493576 26473 sgd_solver.cpp:106] Iteration 55200, lr = 3.2768e-05
I0502 11:19:00.449327 26473 solver.cpp:242] Iteration 55300 (104.095 iter/s, 0.960662s/100 iter), loss = 0.293092
I0502 11:19:00.449374 26473 solver.cpp:261]     Train net output #0: loss = 0.293092 (* 1 = 0.293092 loss)
I0502 11:19:00.449383 26473 sgd_solver.cpp:106] Iteration 55300, lr = 3.2768e-05
I0502 11:19:00.454202 26473 solver.cpp:242] Iteration 55300 (104.1 iter/s, 0.960617s/100 iter), loss = 0.125042
I0502 11:19:00.454226 26473 solver.cpp:261]     Train net output #0: loss = 0.125042 (* 1 = 0.125042 loss)
I0502 11:19:00.454236 26473 sgd_solver.cpp:106] Iteration 55300, lr = 3.2768e-05
I0502 11:19:01.397778 26473 solver.cpp:242] Iteration 55400 (105.444 iter/s, 0.948374s/100 iter), loss = 0.137083
I0502 11:19:01.397819 26473 solver.cpp:261]     Train net output #0: loss = 0.137083 (* 1 = 0.137083 loss)
I0502 11:19:01.397827 26473 sgd_solver.cpp:106] Iteration 55400, lr = 3.2768e-05
I0502 11:19:01.402649 26473 solver.cpp:242] Iteration 55400 (105.44 iter/s, 0.948404s/100 iter), loss = 0.0816617
I0502 11:19:01.402673 26473 solver.cpp:261]     Train net output #0: loss = 0.0816617 (* 1 = 0.0816617 loss)
I0502 11:19:01.402681 26473 sgd_solver.cpp:106] Iteration 55400, lr = 3.2768e-05
I0502 11:19:02.342401 26473 solver.cpp:362] Iteration 55500, Testing net (#0)
I0502 11:19:02.342427 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:02.466733 26473 solver.cpp:429]     Test net output #0: loss = 0.382513 (* 1 = 0.382513 loss)
I0502 11:19:02.469607 26473 solver.cpp:242] Iteration 55500 (93.3035 iter/s, 1.07177s/100 iter), loss = 0.808755
I0502 11:19:02.469629 26473 solver.cpp:261]     Train net output #0: loss = 0.808755 (* 1 = 0.808755 loss)
I0502 11:19:02.469636 26473 sgd_solver.cpp:106] Iteration 55500, lr = 3.2768e-05
I0502 11:19:02.471280 26473 solver.cpp:362] Iteration 55500, Testing net (#0)
I0502 11:19:02.471293 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:02.601758 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9275
I0502 11:19:02.601779 26473 solver.cpp:429]     Test net output #1: loss = 0.146944 (* 1 = 0.146944 loss)
I0502 11:19:02.604706 26473 solver.cpp:242] Iteration 55500 (83.1938 iter/s, 1.20201s/100 iter), loss = 0.240333
I0502 11:19:02.604727 26473 solver.cpp:261]     Train net output #0: loss = 0.240333 (* 1 = 0.240333 loss)
I0502 11:19:02.604734 26473 sgd_solver.cpp:106] Iteration 55500, lr = 3.2768e-05
I0502 11:19:03.547446 26473 solver.cpp:242] Iteration 55600 (92.7828 iter/s, 1.07779s/100 iter), loss = 0.38734
I0502 11:19:03.547485 26473 solver.cpp:261]     Train net output #0: loss = 0.38734 (* 1 = 0.38734 loss)
I0502 11:19:03.547494 26473 sgd_solver.cpp:106] Iteration 55600, lr = 3.2768e-05
I0502 11:19:03.552335 26473 solver.cpp:242] Iteration 55600 (105.531 iter/s, 0.947591s/100 iter), loss = 0.0652163
I0502 11:19:03.552361 26473 solver.cpp:261]     Train net output #0: loss = 0.0652163 (* 1 = 0.0652163 loss)
I0502 11:19:03.552376 26473 sgd_solver.cpp:106] Iteration 55600, lr = 3.2768e-05
I0502 11:19:04.495214 26473 solver.cpp:242] Iteration 55700 (105.518 iter/s, 0.947704s/100 iter), loss = 0.48829
I0502 11:19:04.495256 26473 solver.cpp:261]     Train net output #0: loss = 0.48829 (* 1 = 0.48829 loss)
I0502 11:19:04.495265 26473 sgd_solver.cpp:106] Iteration 55700, lr = 3.2768e-05
I0502 11:19:04.500144 26473 solver.cpp:242] Iteration 55700 (105.512 iter/s, 0.947756s/100 iter), loss = 0.0787011
I0502 11:19:04.500167 26473 solver.cpp:261]     Train net output #0: loss = 0.0787011 (* 1 = 0.0787011 loss)
I0502 11:19:04.500176 26473 sgd_solver.cpp:106] Iteration 55700, lr = 3.2768e-05
I0502 11:19:05.442251 26473 solver.cpp:242] Iteration 55800 (105.601 iter/s, 0.946963s/100 iter), loss = 0.21203
I0502 11:19:05.442289 26473 solver.cpp:261]     Train net output #0: loss = 0.21203 (* 1 = 0.21203 loss)
I0502 11:19:05.442298 26473 sgd_solver.cpp:106] Iteration 55800, lr = 3.2768e-05
I0502 11:19:05.447077 26473 solver.cpp:242] Iteration 55800 (105.609 iter/s, 0.94689s/100 iter), loss = 0.0497352
I0502 11:19:05.447099 26473 solver.cpp:261]     Train net output #0: loss = 0.0497352 (* 1 = 0.0497352 loss)
I0502 11:19:05.447108 26473 sgd_solver.cpp:106] Iteration 55800, lr = 3.2768e-05
I0502 11:19:06.391974 26473 solver.cpp:242] Iteration 55900 (105.302 iter/s, 0.949654s/100 iter), loss = 0.584504
I0502 11:19:06.392015 26473 solver.cpp:261]     Train net output #0: loss = 0.584504 (* 1 = 0.584504 loss)
I0502 11:19:06.392024 26473 sgd_solver.cpp:106] Iteration 55900, lr = 3.2768e-05
I0502 11:19:06.396813 26473 solver.cpp:242] Iteration 55900 (105.297 iter/s, 0.949694s/100 iter), loss = 0.165307
I0502 11:19:06.396837 26473 solver.cpp:261]     Train net output #0: loss = 0.165307 (* 1 = 0.165307 loss)
I0502 11:19:06.396845 26473 sgd_solver.cpp:106] Iteration 55900, lr = 3.2768e-05
I0502 11:19:07.336886 26473 solver.cpp:362] Iteration 56000, Testing net (#0)
I0502 11:19:07.336910 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:07.461236 26473 solver.cpp:429]     Test net output #0: loss = 0.455157 (* 1 = 0.455157 loss)
I0502 11:19:07.464100 26473 solver.cpp:242] Iteration 56000 (93.2778 iter/s, 1.07207s/100 iter), loss = 0.245161
I0502 11:19:07.464119 26473 solver.cpp:261]     Train net output #0: loss = 0.245161 (* 1 = 0.245161 loss)
I0502 11:19:07.464128 26473 sgd_solver.cpp:106] Iteration 56000, lr = 3.2768e-05
I0502 11:19:07.465778 26473 solver.cpp:362] Iteration 56000, Testing net (#0)
I0502 11:19:07.465791 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:07.596519 26473 solver.cpp:429]     Test net output #0: accuracy = 0.936
I0502 11:19:07.596539 26473 solver.cpp:429]     Test net output #1: loss = 0.12953 (* 1 = 0.12953 loss)
I0502 11:19:07.599473 26473 solver.cpp:242] Iteration 56000 (83.1521 iter/s, 1.20262s/100 iter), loss = 0.169748
I0502 11:19:07.599494 26473 solver.cpp:261]     Train net output #0: loss = 0.169748 (* 1 = 0.169748 loss)
I0502 11:19:07.599503 26473 sgd_solver.cpp:106] Iteration 56000, lr = 3.2768e-05
I0502 11:19:08.541946 26473 solver.cpp:242] Iteration 56100 (92.7818 iter/s, 1.0778s/100 iter), loss = 0.351491
I0502 11:19:08.541982 26473 solver.cpp:261]     Train net output #0: loss = 0.351491 (* 1 = 0.351491 loss)
I0502 11:19:08.541991 26473 sgd_solver.cpp:106] Iteration 56100, lr = 3.2768e-05
I0502 11:19:08.546782 26473 solver.cpp:242] Iteration 56100 (105.567 iter/s, 0.947269s/100 iter), loss = 0.141697
I0502 11:19:08.546804 26473 solver.cpp:261]     Train net output #0: loss = 0.141697 (* 1 = 0.141697 loss)
I0502 11:19:08.546813 26473 sgd_solver.cpp:106] Iteration 56100, lr = 3.2768e-05
I0502 11:19:09.489624 26473 solver.cpp:242] Iteration 56200 (105.528 iter/s, 0.947615s/100 iter), loss = 0.444396
I0502 11:19:09.489660 26473 solver.cpp:261]     Train net output #0: loss = 0.444396 (* 1 = 0.444396 loss)
I0502 11:19:09.489670 26473 sgd_solver.cpp:106] Iteration 56200, lr = 3.2768e-05
I0502 11:19:09.494518 26473 solver.cpp:242] Iteration 56200 (105.52 iter/s, 0.947686s/100 iter), loss = 0.0726032
I0502 11:19:09.494549 26473 solver.cpp:261]     Train net output #0: loss = 0.0726032 (* 1 = 0.0726032 loss)
I0502 11:19:09.494559 26473 sgd_solver.cpp:106] Iteration 56200, lr = 3.2768e-05
I0502 11:19:10.437978 26473 solver.cpp:242] Iteration 56300 (105.453 iter/s, 0.948293s/100 iter), loss = 0.303632
I0502 11:19:10.438012 26473 solver.cpp:261]     Train net output #0: loss = 0.303632 (* 1 = 0.303632 loss)
I0502 11:19:10.438020 26473 sgd_solver.cpp:106] Iteration 56300, lr = 3.2768e-05
I0502 11:19:10.442838 26473 solver.cpp:242] Iteration 56300 (105.456 iter/s, 0.948266s/100 iter), loss = 0.0381648
I0502 11:19:10.442862 26473 solver.cpp:261]     Train net output #0: loss = 0.0381648 (* 1 = 0.0381648 loss)
I0502 11:19:10.442870 26473 sgd_solver.cpp:106] Iteration 56300, lr = 3.2768e-05
I0502 11:19:11.385198 26473 solver.cpp:242] Iteration 56400 (105.579 iter/s, 0.947158s/100 iter), loss = 1.24166
I0502 11:19:11.385231 26473 solver.cpp:261]     Train net output #0: loss = 1.24166 (* 1 = 1.24166 loss)
I0502 11:19:11.385241 26473 sgd_solver.cpp:106] Iteration 56400, lr = 3.2768e-05
I0502 11:19:11.390002 26473 solver.cpp:242] Iteration 56400 (105.583 iter/s, 0.947121s/100 iter), loss = 0.229886
I0502 11:19:11.390024 26473 solver.cpp:261]     Train net output #0: loss = 0.229886 (* 1 = 0.229886 loss)
I0502 11:19:11.390033 26473 sgd_solver.cpp:106] Iteration 56400, lr = 3.2768e-05
I0502 11:19:12.330525 26473 solver.cpp:362] Iteration 56500, Testing net (#0)
I0502 11:19:12.330549 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:12.454967 26473 solver.cpp:429]     Test net output #0: loss = 0.339379 (* 1 = 0.339379 loss)
I0502 11:19:12.457849 26473 solver.cpp:242] Iteration 56500 (93.2317 iter/s, 1.0726s/100 iter), loss = 0.226795
I0502 11:19:12.457867 26473 solver.cpp:261]     Train net output #0: loss = 0.226795 (* 1 = 0.226795 loss)
I0502 11:19:12.457876 26473 sgd_solver.cpp:106] Iteration 56500, lr = 3.2768e-05
I0502 11:19:12.459529 26473 solver.cpp:362] Iteration 56500, Testing net (#0)
I0502 11:19:12.459542 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:12.590011 26473 solver.cpp:429]     Test net output #0: accuracy = 0.944
I0502 11:19:12.590030 26473 solver.cpp:429]     Test net output #1: loss = 0.127871 (* 1 = 0.127871 loss)
I0502 11:19:12.592954 26473 solver.cpp:242] Iteration 56500 (83.1318 iter/s, 1.20291s/100 iter), loss = 0.174508
I0502 11:19:12.592974 26473 solver.cpp:261]     Train net output #0: loss = 0.174508 (* 1 = 0.174508 loss)
I0502 11:19:12.592983 26473 sgd_solver.cpp:106] Iteration 56500, lr = 3.2768e-05
I0502 11:19:13.536489 26473 solver.cpp:242] Iteration 56600 (92.7134 iter/s, 1.07859s/100 iter), loss = 0.0952713
I0502 11:19:13.536519 26473 solver.cpp:261]     Train net output #0: loss = 0.0952713 (* 1 = 0.0952713 loss)
I0502 11:19:13.536527 26473 sgd_solver.cpp:106] Iteration 56600, lr = 3.2768e-05
I0502 11:19:13.541312 26473 solver.cpp:242] Iteration 56600 (105.45 iter/s, 0.948319s/100 iter), loss = 0.0289863
I0502 11:19:13.541335 26473 solver.cpp:261]     Train net output #0: loss = 0.0289863 (* 1 = 0.0289863 loss)
I0502 11:19:13.541343 26473 sgd_solver.cpp:106] Iteration 56600, lr = 3.2768e-05
I0502 11:19:14.484113 26473 solver.cpp:242] Iteration 56700 (105.533 iter/s, 0.947568s/100 iter), loss = 0.163966
I0502 11:19:14.484158 26473 solver.cpp:261]     Train net output #0: loss = 0.163966 (* 1 = 0.163966 loss)
I0502 11:19:14.484167 26473 sgd_solver.cpp:106] Iteration 56700, lr = 3.2768e-05
I0502 11:19:14.488937 26473 solver.cpp:242] Iteration 56700 (105.532 iter/s, 0.947584s/100 iter), loss = 0.224384
I0502 11:19:14.488960 26473 solver.cpp:261]     Train net output #0: loss = 0.224384 (* 1 = 0.224384 loss)
I0502 11:19:14.488968 26473 sgd_solver.cpp:106] Iteration 56700, lr = 3.2768e-05
I0502 11:19:15.432255 26473 solver.cpp:242] Iteration 56800 (105.477 iter/s, 0.948072s/100 iter), loss = 0.244604
I0502 11:19:15.432296 26473 solver.cpp:261]     Train net output #0: loss = 0.244604 (* 1 = 0.244604 loss)
I0502 11:19:15.432312 26473 sgd_solver.cpp:106] Iteration 56800, lr = 3.2768e-05
I0502 11:19:15.437158 26473 solver.cpp:242] Iteration 56800 (105.466 iter/s, 0.948172s/100 iter), loss = 0.143574
I0502 11:19:15.437182 26473 solver.cpp:261]     Train net output #0: loss = 0.143574 (* 1 = 0.143574 loss)
I0502 11:19:15.437191 26473 sgd_solver.cpp:106] Iteration 56800, lr = 3.2768e-05
I0502 11:19:16.381098 26473 solver.cpp:242] Iteration 56900 (105.4 iter/s, 0.948771s/100 iter), loss = 0.160839
I0502 11:19:16.381145 26473 solver.cpp:261]     Train net output #0: loss = 0.160839 (* 1 = 0.160839 loss)
I0502 11:19:16.381155 26473 sgd_solver.cpp:106] Iteration 56900, lr = 3.2768e-05
I0502 11:19:16.385928 26473 solver.cpp:242] Iteration 56900 (105.404 iter/s, 0.948728s/100 iter), loss = 0.137667
I0502 11:19:16.385952 26473 solver.cpp:261]     Train net output #0: loss = 0.137667 (* 1 = 0.137667 loss)
I0502 11:19:16.385960 26473 sgd_solver.cpp:106] Iteration 56900, lr = 3.2768e-05
I0502 11:19:17.326015 26473 solver.cpp:362] Iteration 57000, Testing net (#0)
I0502 11:19:17.326040 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:17.450564 26473 solver.cpp:429]     Test net output #0: loss = 0.426636 (* 1 = 0.426636 loss)
I0502 11:19:17.453431 26473 solver.cpp:242] Iteration 57000 (93.2603 iter/s, 1.07227s/100 iter), loss = 0.20883
I0502 11:19:17.453451 26473 solver.cpp:261]     Train net output #0: loss = 0.20883 (* 1 = 0.20883 loss)
I0502 11:19:17.453460 26473 sgd_solver.cpp:106] Iteration 57000, lr = 3.2768e-05
I0502 11:19:17.455118 26473 solver.cpp:362] Iteration 57000, Testing net (#0)
I0502 11:19:17.455132 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:17.585773 26473 solver.cpp:429]     Test net output #0: accuracy = 0.949
I0502 11:19:17.585793 26473 solver.cpp:429]     Test net output #1: loss = 0.139989 (* 1 = 0.139989 loss)
I0502 11:19:17.588726 26473 solver.cpp:242] Iteration 57000 (83.1427 iter/s, 1.20275s/100 iter), loss = 0.212101
I0502 11:19:17.588745 26473 solver.cpp:261]     Train net output #0: loss = 0.212101 (* 1 = 0.212101 loss)
I0502 11:19:17.588754 26473 sgd_solver.cpp:106] Iteration 57000, lr = 3.2768e-05
I0502 11:19:18.531038 26473 solver.cpp:242] Iteration 57100 (92.8026 iter/s, 1.07756s/100 iter), loss = 0.244456
I0502 11:19:18.531080 26473 solver.cpp:261]     Train net output #0: loss = 0.244456 (* 1 = 0.244456 loss)
I0502 11:19:18.531090 26473 sgd_solver.cpp:106] Iteration 57100, lr = 3.2768e-05
I0502 11:19:18.535871 26473 solver.cpp:242] Iteration 57100 (105.585 iter/s, 0.947107s/100 iter), loss = 0.0392684
I0502 11:19:18.535893 26473 solver.cpp:261]     Train net output #0: loss = 0.0392684 (* 1 = 0.0392684 loss)
I0502 11:19:18.535902 26473 sgd_solver.cpp:106] Iteration 57100, lr = 3.2768e-05
I0502 11:19:19.479338 26473 solver.cpp:242] Iteration 57200 (105.46 iter/s, 0.94823s/100 iter), loss = 0.231716
I0502 11:19:19.479379 26473 solver.cpp:261]     Train net output #0: loss = 0.231716 (* 1 = 0.231716 loss)
I0502 11:19:19.479388 26473 sgd_solver.cpp:106] Iteration 57200, lr = 3.2768e-05
I0502 11:19:19.484177 26473 solver.cpp:242] Iteration 57200 (105.456 iter/s, 0.948266s/100 iter), loss = 0.12933
I0502 11:19:19.484200 26473 solver.cpp:261]     Train net output #0: loss = 0.12933 (* 1 = 0.12933 loss)
I0502 11:19:19.484208 26473 sgd_solver.cpp:106] Iteration 57200, lr = 3.2768e-05
I0502 11:19:20.426159 26473 solver.cpp:242] Iteration 57300 (105.624 iter/s, 0.946756s/100 iter), loss = 0.429753
I0502 11:19:20.426200 26473 solver.cpp:261]     Train net output #0: loss = 0.429753 (* 1 = 0.429753 loss)
I0502 11:19:20.426209 26473 sgd_solver.cpp:106] Iteration 57300, lr = 3.2768e-05
I0502 11:19:20.431056 26473 solver.cpp:242] Iteration 57300 (105.616 iter/s, 0.946829s/100 iter), loss = 0.0943219
I0502 11:19:20.431079 26473 solver.cpp:261]     Train net output #0: loss = 0.0943219 (* 1 = 0.0943219 loss)
I0502 11:19:20.431088 26473 sgd_solver.cpp:106] Iteration 57300, lr = 3.2768e-05
I0502 11:19:21.374197 26473 solver.cpp:242] Iteration 57400 (105.489 iter/s, 0.947964s/100 iter), loss = 0.838262
I0502 11:19:21.374248 26473 solver.cpp:261]     Train net output #0: loss = 0.838262 (* 1 = 0.838262 loss)
I0502 11:19:21.374256 26473 sgd_solver.cpp:106] Iteration 57400, lr = 3.2768e-05
I0502 11:19:21.379037 26473 solver.cpp:242] Iteration 57400 (105.492 iter/s, 0.947939s/100 iter), loss = 0.0945651
I0502 11:19:21.379060 26473 solver.cpp:261]     Train net output #0: loss = 0.0945651 (* 1 = 0.0945651 loss)
I0502 11:19:21.379070 26473 sgd_solver.cpp:106] Iteration 57400, lr = 3.2768e-05
I0502 11:19:22.318022 26473 solver.cpp:362] Iteration 57500, Testing net (#0)
I0502 11:19:22.318048 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:22.442412 26473 solver.cpp:429]     Test net output #0: loss = 0.309715 (* 1 = 0.309715 loss)
I0502 11:19:22.445297 26473 solver.cpp:242] Iteration 57500 (93.368 iter/s, 1.07103s/100 iter), loss = 0.20654
I0502 11:19:22.445317 26473 solver.cpp:261]     Train net output #0: loss = 0.20654 (* 1 = 0.20654 loss)
I0502 11:19:22.445327 26473 sgd_solver.cpp:106] Iteration 57500, lr = 3.2768e-05
I0502 11:19:22.446965 26473 solver.cpp:362] Iteration 57500, Testing net (#0)
I0502 11:19:22.446979 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:22.577666 26473 solver.cpp:429]     Test net output #0: accuracy = 0.949
I0502 11:19:22.577700 26473 solver.cpp:429]     Test net output #1: loss = 0.116496 (* 1 = 0.116496 loss)
I0502 11:19:22.580611 26473 solver.cpp:242] Iteration 57500 (83.2272 iter/s, 1.20153s/100 iter), loss = 0.0604549
I0502 11:19:22.580634 26473 solver.cpp:261]     Train net output #0: loss = 0.0604549 (* 1 = 0.0604549 loss)
I0502 11:19:22.580643 26473 sgd_solver.cpp:106] Iteration 57500, lr = 3.2768e-05
I0502 11:19:23.523324 26473 solver.cpp:242] Iteration 57600 (92.7666 iter/s, 1.07797s/100 iter), loss = 0.540854
I0502 11:19:23.523365 26473 solver.cpp:261]     Train net output #0: loss = 0.540854 (* 1 = 0.540854 loss)
I0502 11:19:23.523373 26473 sgd_solver.cpp:106] Iteration 57600, lr = 3.2768e-05
I0502 11:19:23.528174 26473 solver.cpp:242] Iteration 57600 (105.538 iter/s, 0.947522s/100 iter), loss = 0.120531
I0502 11:19:23.528198 26473 solver.cpp:261]     Train net output #0: loss = 0.120531 (* 1 = 0.120531 loss)
I0502 11:19:23.528206 26473 sgd_solver.cpp:106] Iteration 57600, lr = 3.2768e-05
I0502 11:19:24.471107 26473 solver.cpp:242] Iteration 57700 (105.517 iter/s, 0.947716s/100 iter), loss = 0.223388
I0502 11:19:24.471145 26473 solver.cpp:261]     Train net output #0: loss = 0.223388 (* 1 = 0.223388 loss)
I0502 11:19:24.471155 26473 sgd_solver.cpp:106] Iteration 57700, lr = 3.2768e-05
I0502 11:19:24.475939 26473 solver.cpp:242] Iteration 57700 (105.516 iter/s, 0.947722s/100 iter), loss = 0.100682
I0502 11:19:24.475961 26473 solver.cpp:261]     Train net output #0: loss = 0.100682 (* 1 = 0.100682 loss)
I0502 11:19:24.475970 26473 sgd_solver.cpp:106] Iteration 57700, lr = 3.2768e-05
I0502 11:19:25.419178 26473 solver.cpp:242] Iteration 57800 (105.484 iter/s, 0.948007s/100 iter), loss = 0.263949
I0502 11:19:25.419221 26473 solver.cpp:261]     Train net output #0: loss = 0.263949 (* 1 = 0.263949 loss)
I0502 11:19:25.419230 26473 sgd_solver.cpp:106] Iteration 57800, lr = 3.2768e-05
I0502 11:19:25.424090 26473 solver.cpp:242] Iteration 57800 (105.474 iter/s, 0.948103s/100 iter), loss = 0.140735
I0502 11:19:25.424114 26473 solver.cpp:261]     Train net output #0: loss = 0.140735 (* 1 = 0.140735 loss)
I0502 11:19:25.424124 26473 sgd_solver.cpp:106] Iteration 57800, lr = 3.2768e-05
I0502 11:19:26.367197 26473 solver.cpp:242] Iteration 57900 (105.491 iter/s, 0.947944s/100 iter), loss = 0.212655
I0502 11:19:26.367234 26473 solver.cpp:261]     Train net output #0: loss = 0.212655 (* 1 = 0.212655 loss)
I0502 11:19:26.367244 26473 sgd_solver.cpp:106] Iteration 57900, lr = 3.2768e-05
I0502 11:19:26.372027 26473 solver.cpp:242] Iteration 57900 (105.497 iter/s, 0.947894s/100 iter), loss = 0.279619
I0502 11:19:26.372051 26473 solver.cpp:261]     Train net output #0: loss = 0.279619 (* 1 = 0.279619 loss)
I0502 11:19:26.372061 26473 sgd_solver.cpp:106] Iteration 57900, lr = 3.2768e-05
I0502 11:19:27.312214 26473 solver.cpp:362] Iteration 58000, Testing net (#0)
I0502 11:19:27.312238 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:27.436599 26473 solver.cpp:429]     Test net output #0: loss = 0.421699 (* 1 = 0.421699 loss)
I0502 11:19:27.439474 26473 solver.cpp:242] Iteration 58000 (93.2644 iter/s, 1.07222s/100 iter), loss = 0.202277
I0502 11:19:27.439494 26473 solver.cpp:261]     Train net output #0: loss = 0.202277 (* 1 = 0.202277 loss)
I0502 11:19:27.439502 26473 sgd_solver.cpp:106] Iteration 58000, lr = 3.2768e-05
I0502 11:19:27.441192 26473 solver.cpp:362] Iteration 58000, Testing net (#0)
I0502 11:19:27.441205 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:27.571795 26473 solver.cpp:429]     Test net output #0: accuracy = 0.938
I0502 11:19:27.571816 26473 solver.cpp:429]     Test net output #1: loss = 0.134814 (* 1 = 0.134814 loss)
I0502 11:19:27.574738 26473 solver.cpp:242] Iteration 58000 (83.1487 iter/s, 1.20266s/100 iter), loss = 0.138134
I0502 11:19:27.574757 26473 solver.cpp:261]     Train net output #0: loss = 0.138134 (* 1 = 0.138134 loss)
I0502 11:19:27.574766 26473 sgd_solver.cpp:106] Iteration 58000, lr = 3.2768e-05
I0502 11:19:28.517349 26473 solver.cpp:242] Iteration 58100 (92.7794 iter/s, 1.07783s/100 iter), loss = 0.475069
I0502 11:19:28.517385 26473 solver.cpp:261]     Train net output #0: loss = 0.475069 (* 1 = 0.475069 loss)
I0502 11:19:28.517393 26473 sgd_solver.cpp:106] Iteration 58100, lr = 3.2768e-05
I0502 11:19:28.522171 26473 solver.cpp:242] Iteration 58100 (105.553 iter/s, 0.947396s/100 iter), loss = 0.148605
I0502 11:19:28.522194 26473 solver.cpp:261]     Train net output #0: loss = 0.148605 (* 1 = 0.148605 loss)
I0502 11:19:28.522203 26473 sgd_solver.cpp:106] Iteration 58100, lr = 3.2768e-05
I0502 11:19:29.465641 26473 solver.cpp:242] Iteration 58200 (105.46 iter/s, 0.948229s/100 iter), loss = 0.603818
I0502 11:19:29.465674 26473 solver.cpp:261]     Train net output #0: loss = 0.603818 (* 1 = 0.603818 loss)
I0502 11:19:29.465683 26473 sgd_solver.cpp:106] Iteration 58200, lr = 3.2768e-05
I0502 11:19:29.470469 26473 solver.cpp:242] Iteration 58200 (105.457 iter/s, 0.948257s/100 iter), loss = 0.160381
I0502 11:19:29.470494 26473 solver.cpp:261]     Train net output #0: loss = 0.160381 (* 1 = 0.160381 loss)
I0502 11:19:29.470501 26473 sgd_solver.cpp:106] Iteration 58200, lr = 3.2768e-05
I0502 11:19:30.413359 26473 solver.cpp:242] Iteration 58300 (105.523 iter/s, 0.947661s/100 iter), loss = 0.0976253
I0502 11:19:30.413389 26473 solver.cpp:261]     Train net output #0: loss = 0.0976253 (* 1 = 0.0976253 loss)
I0502 11:19:30.413398 26473 sgd_solver.cpp:106] Iteration 58300, lr = 3.2768e-05
I0502 11:19:30.418251 26473 solver.cpp:242] Iteration 58300 (105.515 iter/s, 0.94773s/100 iter), loss = 0.0365084
I0502 11:19:30.418274 26473 solver.cpp:261]     Train net output #0: loss = 0.0365084 (* 1 = 0.0365084 loss)
I0502 11:19:30.418282 26473 sgd_solver.cpp:106] Iteration 58300, lr = 3.2768e-05
I0502 11:19:31.361260 26473 solver.cpp:242] Iteration 58400 (105.503 iter/s, 0.947838s/100 iter), loss = 0.153608
I0502 11:19:31.361304 26473 solver.cpp:261]     Train net output #0: loss = 0.153608 (* 1 = 0.153608 loss)
I0502 11:19:31.361313 26473 sgd_solver.cpp:106] Iteration 58400, lr = 3.2768e-05
I0502 11:19:31.366078 26473 solver.cpp:242] Iteration 58400 (105.509 iter/s, 0.947786s/100 iter), loss = 0.0934929
I0502 11:19:31.366102 26473 solver.cpp:261]     Train net output #0: loss = 0.0934929 (* 1 = 0.0934929 loss)
I0502 11:19:31.366111 26473 sgd_solver.cpp:106] Iteration 58400, lr = 3.2768e-05
I0502 11:19:32.306226 26473 solver.cpp:362] Iteration 58500, Testing net (#0)
I0502 11:19:32.306257 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:32.430639 26473 solver.cpp:429]     Test net output #0: loss = 0.364542 (* 1 = 0.364542 loss)
I0502 11:19:32.433504 26473 solver.cpp:242] Iteration 58500 (93.2677 iter/s, 1.07218s/100 iter), loss = 0.304802
I0502 11:19:32.433535 26473 solver.cpp:261]     Train net output #0: loss = 0.304802 (* 1 = 0.304802 loss)
I0502 11:19:32.433552 26473 sgd_solver.cpp:106] Iteration 58500, lr = 3.2768e-05
I0502 11:19:32.435201 26473 solver.cpp:362] Iteration 58500, Testing net (#0)
I0502 11:19:32.435214 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:32.565888 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9275
I0502 11:19:32.565909 26473 solver.cpp:429]     Test net output #1: loss = 0.171202 (* 1 = 0.171202 loss)
I0502 11:19:32.568811 26473 solver.cpp:242] Iteration 58500 (83.1471 iter/s, 1.20269s/100 iter), loss = 0.0967246
I0502 11:19:32.568831 26473 solver.cpp:261]     Train net output #0: loss = 0.0967246 (* 1 = 0.0967246 loss)
I0502 11:19:32.568840 26473 sgd_solver.cpp:106] Iteration 58500, lr = 3.2768e-05
I0502 11:19:33.512169 26473 solver.cpp:242] Iteration 58600 (92.7124 iter/s, 1.0786s/100 iter), loss = 0.0895498
I0502 11:19:33.512205 26473 solver.cpp:261]     Train net output #0: loss = 0.0895498 (* 1 = 0.0895498 loss)
I0502 11:19:33.512214 26473 sgd_solver.cpp:106] Iteration 58600, lr = 3.2768e-05
I0502 11:19:33.517020 26473 solver.cpp:242] Iteration 58600 (105.466 iter/s, 0.948171s/100 iter), loss = 0.110692
I0502 11:19:33.517042 26473 solver.cpp:261]     Train net output #0: loss = 0.110692 (* 1 = 0.110692 loss)
I0502 11:19:33.517051 26473 sgd_solver.cpp:106] Iteration 58600, lr = 3.2768e-05
I0502 11:19:34.460026 26473 solver.cpp:242] Iteration 58700 (105.508 iter/s, 0.947795s/100 iter), loss = 0.346032
I0502 11:19:34.460069 26473 solver.cpp:261]     Train net output #0: loss = 0.346032 (* 1 = 0.346032 loss)
I0502 11:19:34.460078 26473 sgd_solver.cpp:106] Iteration 58700, lr = 3.2768e-05
I0502 11:19:34.464864 26473 solver.cpp:242] Iteration 58700 (105.507 iter/s, 0.947804s/100 iter), loss = 0.0772444
I0502 11:19:34.464889 26473 solver.cpp:261]     Train net output #0: loss = 0.0772444 (* 1 = 0.0772444 loss)
I0502 11:19:34.464897 26473 sgd_solver.cpp:106] Iteration 58700, lr = 3.2768e-05
I0502 11:19:35.407610 26473 solver.cpp:242] Iteration 58800 (105.539 iter/s, 0.947514s/100 iter), loss = 0.248475
I0502 11:19:35.407652 26473 solver.cpp:261]     Train net output #0: loss = 0.248475 (* 1 = 0.248475 loss)
I0502 11:19:35.407660 26473 sgd_solver.cpp:106] Iteration 58800, lr = 3.2768e-05
I0502 11:19:35.412530 26473 solver.cpp:242] Iteration 58800 (105.528 iter/s, 0.947615s/100 iter), loss = 0.105216
I0502 11:19:35.412569 26473 solver.cpp:261]     Train net output #0: loss = 0.105216 (* 1 = 0.105216 loss)
I0502 11:19:35.412580 26473 sgd_solver.cpp:106] Iteration 58800, lr = 3.2768e-05
I0502 11:19:36.356377 26473 solver.cpp:242] Iteration 58900 (105.407 iter/s, 0.948701s/100 iter), loss = 0.178574
I0502 11:19:36.356418 26473 solver.cpp:261]     Train net output #0: loss = 0.178574 (* 1 = 0.178574 loss)
I0502 11:19:36.356427 26473 sgd_solver.cpp:106] Iteration 58900, lr = 3.2768e-05
I0502 11:19:36.361311 26473 solver.cpp:242] Iteration 58900 (105.404 iter/s, 0.94873s/100 iter), loss = 0.0356017
I0502 11:19:36.361335 26473 solver.cpp:261]     Train net output #0: loss = 0.0356017 (* 1 = 0.0356017 loss)
I0502 11:19:36.361344 26473 sgd_solver.cpp:106] Iteration 58900, lr = 3.2768e-05
I0502 11:19:37.301630 26473 solver.cpp:362] Iteration 59000, Testing net (#0)
I0502 11:19:37.301656 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:37.425968 26473 solver.cpp:429]     Test net output #0: loss = 0.329308 (* 1 = 0.329308 loss)
I0502 11:19:37.428851 26473 solver.cpp:242] Iteration 59000 (93.2475 iter/s, 1.07241s/100 iter), loss = 0.303336
I0502 11:19:37.428871 26473 solver.cpp:261]     Train net output #0: loss = 0.303336 (* 1 = 0.303336 loss)
I0502 11:19:37.428880 26473 sgd_solver.cpp:106] Iteration 59000, lr = 3.2768e-05
I0502 11:19:37.430521 26473 solver.cpp:362] Iteration 59000, Testing net (#0)
I0502 11:19:37.430533 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:37.561275 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9355
I0502 11:19:37.561295 26473 solver.cpp:429]     Test net output #1: loss = 0.161572 (* 1 = 0.161572 loss)
I0502 11:19:37.564224 26473 solver.cpp:242] Iteration 59000 (83.1347 iter/s, 1.20287s/100 iter), loss = 0.0285626
I0502 11:19:37.564244 26473 solver.cpp:261]     Train net output #0: loss = 0.0285626 (* 1 = 0.0285626 loss)
I0502 11:19:37.564252 26473 sgd_solver.cpp:106] Iteration 59000, lr = 3.2768e-05
I0502 11:19:38.507292 26473 solver.cpp:242] Iteration 59100 (92.7309 iter/s, 1.07839s/100 iter), loss = 0.152877
I0502 11:19:38.507349 26473 solver.cpp:261]     Train net output #0: loss = 0.152877 (* 1 = 0.152877 loss)
I0502 11:19:38.507357 26473 sgd_solver.cpp:106] Iteration 59100, lr = 3.2768e-05
I0502 11:19:38.512190 26473 solver.cpp:242] Iteration 59100 (105.493 iter/s, 0.947928s/100 iter), loss = 0.129704
I0502 11:19:38.512214 26473 solver.cpp:261]     Train net output #0: loss = 0.129704 (* 1 = 0.129704 loss)
I0502 11:19:38.512223 26473 sgd_solver.cpp:106] Iteration 59100, lr = 3.2768e-05
I0502 11:19:39.455335 26473 solver.cpp:242] Iteration 59200 (105.49 iter/s, 0.94796s/100 iter), loss = 0.107361
I0502 11:19:39.455380 26473 solver.cpp:261]     Train net output #0: loss = 0.107361 (* 1 = 0.107361 loss)
I0502 11:19:39.455389 26473 sgd_solver.cpp:106] Iteration 59200, lr = 3.2768e-05
I0502 11:19:39.460160 26473 solver.cpp:242] Iteration 59200 (105.493 iter/s, 0.947928s/100 iter), loss = 0.18496
I0502 11:19:39.460185 26473 solver.cpp:261]     Train net output #0: loss = 0.18496 (* 1 = 0.18496 loss)
I0502 11:19:39.460192 26473 sgd_solver.cpp:106] Iteration 59200, lr = 3.2768e-05
I0502 11:19:40.402606 26473 solver.cpp:242] Iteration 59300 (105.574 iter/s, 0.947199s/100 iter), loss = 0.179101
I0502 11:19:40.402643 26473 solver.cpp:261]     Train net output #0: loss = 0.179101 (* 1 = 0.179101 loss)
I0502 11:19:40.402652 26473 sgd_solver.cpp:106] Iteration 59300, lr = 3.2768e-05
I0502 11:19:40.407515 26473 solver.cpp:242] Iteration 59300 (105.563 iter/s, 0.947303s/100 iter), loss = 0.136271
I0502 11:19:40.407537 26473 solver.cpp:261]     Train net output #0: loss = 0.136271 (* 1 = 0.136271 loss)
I0502 11:19:40.407546 26473 sgd_solver.cpp:106] Iteration 59300, lr = 3.2768e-05
I0502 11:19:41.350245 26473 solver.cpp:242] Iteration 59400 (105.532 iter/s, 0.947578s/100 iter), loss = 0.862539
I0502 11:19:41.350283 26473 solver.cpp:261]     Train net output #0: loss = 0.862539 (* 1 = 0.862539 loss)
I0502 11:19:41.350292 26473 sgd_solver.cpp:106] Iteration 59400, lr = 3.2768e-05
I0502 11:19:41.355145 26473 solver.cpp:242] Iteration 59400 (105.532 iter/s, 0.947584s/100 iter), loss = 0.0658037
I0502 11:19:41.355170 26473 solver.cpp:261]     Train net output #0: loss = 0.0658037 (* 1 = 0.0658037 loss)
I0502 11:19:41.355178 26473 sgd_solver.cpp:106] Iteration 59400, lr = 3.2768e-05
I0502 11:19:42.295388 26473 solver.cpp:362] Iteration 59500, Testing net (#0)
I0502 11:19:42.295413 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:42.419807 26473 solver.cpp:429]     Test net output #0: loss = 0.410991 (* 1 = 0.410991 loss)
I0502 11:19:42.422694 26473 solver.cpp:242] Iteration 59500 (93.2495 iter/s, 1.07239s/100 iter), loss = 0.660772
I0502 11:19:42.422714 26473 solver.cpp:261]     Train net output #0: loss = 0.660772 (* 1 = 0.660772 loss)
I0502 11:19:42.422724 26473 sgd_solver.cpp:106] Iteration 59500, lr = 3.2768e-05
I0502 11:19:42.424360 26473 solver.cpp:362] Iteration 59500, Testing net (#0)
I0502 11:19:42.424374 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:42.555023 26473 solver.cpp:429]     Test net output #0: accuracy = 0.939
I0502 11:19:42.555043 26473 solver.cpp:429]     Test net output #1: loss = 0.128374 (* 1 = 0.128374 loss)
I0502 11:19:42.557950 26473 solver.cpp:242] Iteration 59500 (83.1422 iter/s, 1.20276s/100 iter), loss = 0.205161
I0502 11:19:42.557971 26473 solver.cpp:261]     Train net output #0: loss = 0.205161 (* 1 = 0.205161 loss)
I0502 11:19:42.557978 26473 sgd_solver.cpp:106] Iteration 59500, lr = 3.2768e-05
I0502 11:19:43.500632 26473 solver.cpp:242] Iteration 59600 (92.7743 iter/s, 1.07789s/100 iter), loss = 0.195421
I0502 11:19:43.500672 26473 solver.cpp:261]     Train net output #0: loss = 0.195421 (* 1 = 0.195421 loss)
I0502 11:19:43.500689 26473 sgd_solver.cpp:106] Iteration 59600, lr = 3.2768e-05
I0502 11:19:43.505465 26473 solver.cpp:242] Iteration 59600 (105.543 iter/s, 0.947477s/100 iter), loss = 0.200885
I0502 11:19:43.505502 26473 solver.cpp:261]     Train net output #0: loss = 0.200885 (* 1 = 0.200885 loss)
I0502 11:19:43.505512 26473 sgd_solver.cpp:106] Iteration 59600, lr = 3.2768e-05
I0502 11:19:44.449396 26473 solver.cpp:242] Iteration 59700 (105.408 iter/s, 0.948697s/100 iter), loss = 0.490416
I0502 11:19:44.449432 26473 solver.cpp:261]     Train net output #0: loss = 0.490416 (* 1 = 0.490416 loss)
I0502 11:19:44.449441 26473 sgd_solver.cpp:106] Iteration 59700, lr = 3.2768e-05
I0502 11:19:44.454247 26473 solver.cpp:242] Iteration 59700 (105.404 iter/s, 0.948727s/100 iter), loss = 0.15182
I0502 11:19:44.454270 26473 solver.cpp:261]     Train net output #0: loss = 0.15182 (* 1 = 0.15182 loss)
I0502 11:19:44.454279 26473 sgd_solver.cpp:106] Iteration 59700, lr = 3.2768e-05
I0502 11:19:45.397287 26473 solver.cpp:242] Iteration 59800 (105.504 iter/s, 0.947831s/100 iter), loss = 0.46269
I0502 11:19:45.397320 26473 solver.cpp:261]     Train net output #0: loss = 0.46269 (* 1 = 0.46269 loss)
I0502 11:19:45.397330 26473 sgd_solver.cpp:106] Iteration 59800, lr = 3.2768e-05
I0502 11:19:45.402142 26473 solver.cpp:242] Iteration 59800 (105.502 iter/s, 0.947853s/100 iter), loss = 0.105973
I0502 11:19:45.402165 26473 solver.cpp:261]     Train net output #0: loss = 0.105973 (* 1 = 0.105973 loss)
I0502 11:19:45.402173 26473 sgd_solver.cpp:106] Iteration 59800, lr = 3.2768e-05
I0502 11:19:46.346318 26473 solver.cpp:242] Iteration 59900 (105.377 iter/s, 0.948974s/100 iter), loss = 0.163438
I0502 11:19:46.346354 26473 solver.cpp:261]     Train net output #0: loss = 0.163438 (* 1 = 0.163438 loss)
I0502 11:19:46.346362 26473 sgd_solver.cpp:106] Iteration 59900, lr = 3.2768e-05
I0502 11:19:46.351202 26473 solver.cpp:242] Iteration 59900 (105.373 iter/s, 0.94901s/100 iter), loss = 0.112181
I0502 11:19:46.351227 26473 solver.cpp:261]     Train net output #0: loss = 0.112181 (* 1 = 0.112181 loss)
I0502 11:19:46.351235 26473 sgd_solver.cpp:106] Iteration 59900, lr = 3.2768e-05
I0502 11:19:47.290776 26473 solver.cpp:362] Iteration 60000, Testing net (#0)
I0502 11:19:47.290805 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:47.415146 26473 solver.cpp:429]     Test net output #0: loss = 0.339692 (* 1 = 0.339692 loss)
I0502 11:19:47.418011 26473 solver.cpp:242] Iteration 60000 (93.315 iter/s, 1.07164s/100 iter), loss = 0.284377
I0502 11:19:47.418031 26473 solver.cpp:261]     Train net output #0: loss = 0.284377 (* 1 = 0.284377 loss)
I0502 11:19:47.418040 26473 sgd_solver.cpp:106] Iteration 60000, lr = 2.62144e-05
I0502 11:19:47.419692 26473 solver.cpp:362] Iteration 60000, Testing net (#0)
I0502 11:19:47.419705 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:47.550124 26473 solver.cpp:429]     Test net output #0: accuracy = 0.924
I0502 11:19:47.550145 26473 solver.cpp:429]     Test net output #1: loss = 0.154069 (* 1 = 0.154069 loss)
I0502 11:19:47.553063 26473 solver.cpp:242] Iteration 60000 (83.2074 iter/s, 1.20182s/100 iter), loss = 0.241956
I0502 11:19:47.553083 26473 solver.cpp:261]     Train net output #0: loss = 0.241956 (* 1 = 0.241956 loss)
I0502 11:19:47.553092 26473 sgd_solver.cpp:106] Iteration 60000, lr = 2.62144e-05
I0502 11:19:48.496237 26473 solver.cpp:242] Iteration 60100 (92.7495 iter/s, 1.07817s/100 iter), loss = 0.359329
I0502 11:19:48.496273 26473 solver.cpp:261]     Train net output #0: loss = 0.359329 (* 1 = 0.359329 loss)
I0502 11:19:48.496282 26473 sgd_solver.cpp:106] Iteration 60100, lr = 2.62144e-05
I0502 11:19:48.501056 26473 solver.cpp:242] Iteration 60100 (105.49 iter/s, 0.947955s/100 iter), loss = 0.0974553
I0502 11:19:48.501080 26473 solver.cpp:261]     Train net output #0: loss = 0.0974553 (* 1 = 0.0974553 loss)
I0502 11:19:48.501087 26473 sgd_solver.cpp:106] Iteration 60100, lr = 2.62144e-05
I0502 11:19:49.444088 26473 solver.cpp:242] Iteration 60200 (105.509 iter/s, 0.94779s/100 iter), loss = 0.40374
I0502 11:19:49.444128 26473 solver.cpp:261]     Train net output #0: loss = 0.40374 (* 1 = 0.40374 loss)
I0502 11:19:49.444138 26473 sgd_solver.cpp:106] Iteration 60200, lr = 2.62144e-05
I0502 11:19:49.448957 26473 solver.cpp:242] Iteration 60200 (105.501 iter/s, 0.94786s/100 iter), loss = 0.0702094
I0502 11:19:49.448979 26473 solver.cpp:261]     Train net output #0: loss = 0.0702094 (* 1 = 0.0702094 loss)
I0502 11:19:49.448987 26473 sgd_solver.cpp:106] Iteration 60200, lr = 2.62144e-05
I0502 11:19:50.391052 26473 solver.cpp:242] Iteration 60300 (105.608 iter/s, 0.946897s/100 iter), loss = 0.493197
I0502 11:19:50.391094 26473 solver.cpp:261]     Train net output #0: loss = 0.493197 (* 1 = 0.493197 loss)
I0502 11:19:50.391103 26473 sgd_solver.cpp:106] Iteration 60300, lr = 2.62144e-05
I0502 11:19:50.395879 26473 solver.cpp:242] Iteration 60300 (105.61 iter/s, 0.946882s/100 iter), loss = 0.118741
I0502 11:19:50.395902 26473 solver.cpp:261]     Train net output #0: loss = 0.118741 (* 1 = 0.118741 loss)
I0502 11:19:50.395911 26473 sgd_solver.cpp:106] Iteration 60300, lr = 2.62144e-05
I0502 11:19:51.339382 26473 solver.cpp:242] Iteration 60400 (105.456 iter/s, 0.948262s/100 iter), loss = 0.239456
I0502 11:19:51.339423 26473 solver.cpp:261]     Train net output #0: loss = 0.239456 (* 1 = 0.239456 loss)
I0502 11:19:51.339432 26473 sgd_solver.cpp:106] Iteration 60400, lr = 2.62144e-05
I0502 11:19:51.344316 26473 solver.cpp:242] Iteration 60400 (105.442 iter/s, 0.948386s/100 iter), loss = 0.119224
I0502 11:19:51.344339 26473 solver.cpp:261]     Train net output #0: loss = 0.119224 (* 1 = 0.119224 loss)
I0502 11:19:51.344348 26473 sgd_solver.cpp:106] Iteration 60400, lr = 2.62144e-05
I0502 11:19:52.284405 26473 solver.cpp:362] Iteration 60500, Testing net (#0)
I0502 11:19:52.284430 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:52.408814 26473 solver.cpp:429]     Test net output #0: loss = 0.313264 (* 1 = 0.313264 loss)
I0502 11:19:52.411670 26473 solver.cpp:242] Iteration 60500 (93.2637 iter/s, 1.07223s/100 iter), loss = 0.142976
I0502 11:19:52.411690 26473 solver.cpp:261]     Train net output #0: loss = 0.142976 (* 1 = 0.142976 loss)
I0502 11:19:52.411698 26473 sgd_solver.cpp:106] Iteration 60500, lr = 2.62144e-05
I0502 11:19:52.413352 26473 solver.cpp:362] Iteration 60500, Testing net (#0)
I0502 11:19:52.413367 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:52.544086 26473 solver.cpp:429]     Test net output #0: accuracy = 0.952
I0502 11:19:52.544104 26473 solver.cpp:429]     Test net output #1: loss = 0.121848 (* 1 = 0.121848 loss)
I0502 11:19:52.547044 26473 solver.cpp:242] Iteration 60500 (83.1474 iter/s, 1.20268s/100 iter), loss = 0.188025
I0502 11:19:52.547063 26473 solver.cpp:261]     Train net output #0: loss = 0.188025 (* 1 = 0.188025 loss)
I0502 11:19:52.547072 26473 sgd_solver.cpp:106] Iteration 60500, lr = 2.62144e-05
I0502 11:19:53.490581 26473 solver.cpp:242] Iteration 60600 (92.6906 iter/s, 1.07886s/100 iter), loss = 0.11181
I0502 11:19:53.490622 26473 solver.cpp:261]     Train net output #0: loss = 0.11181 (* 1 = 0.11181 loss)
I0502 11:19:53.490631 26473 sgd_solver.cpp:106] Iteration 60600, lr = 2.62144e-05
I0502 11:19:53.495417 26473 solver.cpp:242] Iteration 60600 (105.448 iter/s, 0.948335s/100 iter), loss = 0.154003
I0502 11:19:53.495440 26473 solver.cpp:261]     Train net output #0: loss = 0.154003 (* 1 = 0.154003 loss)
I0502 11:19:53.495448 26473 sgd_solver.cpp:106] Iteration 60600, lr = 2.62144e-05
I0502 11:19:54.438657 26473 solver.cpp:242] Iteration 60700 (105.485 iter/s, 0.948005s/100 iter), loss = 0.375684
I0502 11:19:54.438699 26473 solver.cpp:261]     Train net output #0: loss = 0.375684 (* 1 = 0.375684 loss)
I0502 11:19:54.438707 26473 sgd_solver.cpp:106] Iteration 60700, lr = 2.62144e-05
I0502 11:19:54.443487 26473 solver.cpp:242] Iteration 60700 (105.482 iter/s, 0.948028s/100 iter), loss = 0.0668028
I0502 11:19:54.443511 26473 solver.cpp:261]     Train net output #0: loss = 0.0668028 (* 1 = 0.0668028 loss)
I0502 11:19:54.443531 26473 sgd_solver.cpp:106] Iteration 60700, lr = 2.62144e-05
I0502 11:19:55.386840 26473 solver.cpp:242] Iteration 60800 (105.473 iter/s, 0.948114s/100 iter), loss = 0.1242
I0502 11:19:55.386884 26473 solver.cpp:261]     Train net output #0: loss = 0.1242 (* 1 = 0.1242 loss)
I0502 11:19:55.386893 26473 sgd_solver.cpp:106] Iteration 60800, lr = 2.62144e-05
I0502 11:19:55.391700 26473 solver.cpp:242] Iteration 60800 (105.466 iter/s, 0.948172s/100 iter), loss = 0.127962
I0502 11:19:55.391723 26473 solver.cpp:261]     Train net output #0: loss = 0.127962 (* 1 = 0.127962 loss)
I0502 11:19:55.391732 26473 sgd_solver.cpp:106] Iteration 60800, lr = 2.62144e-05
I0502 11:19:56.336477 26473 solver.cpp:242] Iteration 60900 (105.311 iter/s, 0.949567s/100 iter), loss = 0.350768
I0502 11:19:56.336518 26473 solver.cpp:261]     Train net output #0: loss = 0.350768 (* 1 = 0.350768 loss)
I0502 11:19:56.336526 26473 sgd_solver.cpp:106] Iteration 60900, lr = 2.62144e-05
I0502 11:19:56.341404 26473 solver.cpp:242] Iteration 60900 (105.302 iter/s, 0.949652s/100 iter), loss = 0.154795
I0502 11:19:56.341429 26473 solver.cpp:261]     Train net output #0: loss = 0.154795 (* 1 = 0.154795 loss)
I0502 11:19:56.341437 26473 sgd_solver.cpp:106] Iteration 60900, lr = 2.62144e-05
I0502 11:19:57.282083 26473 solver.cpp:362] Iteration 61000, Testing net (#0)
I0502 11:19:57.282109 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:57.406612 26473 solver.cpp:429]     Test net output #0: loss = 0.324197 (* 1 = 0.324197 loss)
I0502 11:19:57.409492 26473 solver.cpp:242] Iteration 61000 (93.2004 iter/s, 1.07296s/100 iter), loss = 0.837976
I0502 11:19:57.409513 26473 solver.cpp:261]     Train net output #0: loss = 0.837976 (* 1 = 0.837976 loss)
I0502 11:19:57.409521 26473 sgd_solver.cpp:106] Iteration 61000, lr = 2.62144e-05
I0502 11:19:57.411162 26473 solver.cpp:362] Iteration 61000, Testing net (#0)
I0502 11:19:57.411176 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:19:57.542038 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9415
I0502 11:19:57.542062 26473 solver.cpp:429]     Test net output #1: loss = 0.123896 (* 1 = 0.123896 loss)
I0502 11:19:57.544996 26473 solver.cpp:242] Iteration 61000 (83.0878 iter/s, 1.20355s/100 iter), loss = 0.0666376
I0502 11:19:57.545017 26473 solver.cpp:261]     Train net output #0: loss = 0.0666376 (* 1 = 0.0666376 loss)
I0502 11:19:57.545025 26473 sgd_solver.cpp:106] Iteration 61000, lr = 2.62144e-05
I0502 11:19:58.488327 26473 solver.cpp:242] Iteration 61100 (92.6972 iter/s, 1.07878s/100 iter), loss = 0.270617
I0502 11:19:58.488369 26473 solver.cpp:261]     Train net output #0: loss = 0.270617 (* 1 = 0.270617 loss)
I0502 11:19:58.488379 26473 sgd_solver.cpp:106] Iteration 61100, lr = 2.62144e-05
I0502 11:19:58.493197 26473 solver.cpp:242] Iteration 61100 (105.467 iter/s, 0.948162s/100 iter), loss = 0.147641
I0502 11:19:58.493221 26473 solver.cpp:261]     Train net output #0: loss = 0.147641 (* 1 = 0.147641 loss)
I0502 11:19:58.493229 26473 sgd_solver.cpp:106] Iteration 61100, lr = 2.62144e-05
I0502 11:19:59.436353 26473 solver.cpp:242] Iteration 61200 (105.49 iter/s, 0.947955s/100 iter), loss = 0.117029
I0502 11:19:59.436394 26473 solver.cpp:261]     Train net output #0: loss = 0.117029 (* 1 = 0.117029 loss)
I0502 11:19:59.436403 26473 sgd_solver.cpp:106] Iteration 61200, lr = 2.62144e-05
I0502 11:19:59.441174 26473 solver.cpp:242] Iteration 61200 (105.493 iter/s, 0.947934s/100 iter), loss = 0.0731579
I0502 11:19:59.441211 26473 solver.cpp:261]     Train net output #0: loss = 0.0731579 (* 1 = 0.0731579 loss)
I0502 11:19:59.441220 26473 sgd_solver.cpp:106] Iteration 61200, lr = 2.62144e-05
I0502 11:20:00.395683 26473 solver.cpp:242] Iteration 61300 (104.247 iter/s, 0.959261s/100 iter), loss = 0.17937
I0502 11:20:00.395732 26473 solver.cpp:261]     Train net output #0: loss = 0.17937 (* 1 = 0.17937 loss)
I0502 11:20:00.395741 26473 sgd_solver.cpp:106] Iteration 61300, lr = 2.62144e-05
I0502 11:20:00.400581 26473 solver.cpp:242] Iteration 61300 (104.237 iter/s, 0.959353s/100 iter), loss = 0.102061
I0502 11:20:00.400616 26473 solver.cpp:261]     Train net output #0: loss = 0.102061 (* 1 = 0.102061 loss)
I0502 11:20:00.400626 26473 sgd_solver.cpp:106] Iteration 61300, lr = 2.62144e-05
I0502 11:20:01.351819 26473 solver.cpp:242] Iteration 61400 (104.596 iter/s, 0.956062s/100 iter), loss = 0.811815
I0502 11:20:01.351856 26473 solver.cpp:261]     Train net output #0: loss = 0.811815 (* 1 = 0.811815 loss)
I0502 11:20:01.351866 26473 sgd_solver.cpp:106] Iteration 61400, lr = 2.62144e-05
I0502 11:20:01.356771 26473 solver.cpp:242] Iteration 61400 (104.589 iter/s, 0.956127s/100 iter), loss = 0.141544
I0502 11:20:01.356794 26473 solver.cpp:261]     Train net output #0: loss = 0.141544 (* 1 = 0.141544 loss)
I0502 11:20:01.356803 26473 sgd_solver.cpp:106] Iteration 61400, lr = 2.62144e-05
I0502 11:20:02.298955 26473 solver.cpp:362] Iteration 61500, Testing net (#0)
I0502 11:20:02.298979 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:02.423317 26473 solver.cpp:429]     Test net output #0: loss = 0.312517 (* 1 = 0.312517 loss)
I0502 11:20:02.426205 26473 solver.cpp:242] Iteration 61500 (93.0812 iter/s, 1.07433s/100 iter), loss = 0.346242
I0502 11:20:02.426225 26473 solver.cpp:261]     Train net output #0: loss = 0.346242 (* 1 = 0.346242 loss)
I0502 11:20:02.426234 26473 sgd_solver.cpp:106] Iteration 61500, lr = 2.62144e-05
I0502 11:20:02.427875 26473 solver.cpp:362] Iteration 61500, Testing net (#0)
I0502 11:20:02.427888 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:02.558399 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9385
I0502 11:20:02.558420 26473 solver.cpp:429]     Test net output #1: loss = 0.116392 (* 1 = 0.116392 loss)
I0502 11:20:02.561342 26473 solver.cpp:242] Iteration 61500 (83.0203 iter/s, 1.20453s/100 iter), loss = 0.253425
I0502 11:20:02.561362 26473 solver.cpp:261]     Train net output #0: loss = 0.253425 (* 1 = 0.253425 loss)
I0502 11:20:02.561369 26473 sgd_solver.cpp:106] Iteration 61500, lr = 2.62144e-05
I0502 11:20:03.504528 26473 solver.cpp:242] Iteration 61600 (92.7412 iter/s, 1.07827s/100 iter), loss = 0.168879
I0502 11:20:03.504582 26473 solver.cpp:261]     Train net output #0: loss = 0.168879 (* 1 = 0.168879 loss)
I0502 11:20:03.504592 26473 sgd_solver.cpp:106] Iteration 61600, lr = 2.62144e-05
I0502 11:20:03.509392 26473 solver.cpp:242] Iteration 61600 (105.484 iter/s, 0.948011s/100 iter), loss = 0.139618
I0502 11:20:03.509414 26473 solver.cpp:261]     Train net output #0: loss = 0.139618 (* 1 = 0.139618 loss)
I0502 11:20:03.509423 26473 sgd_solver.cpp:106] Iteration 61600, lr = 2.62144e-05
I0502 11:20:04.452044 26473 solver.cpp:242] Iteration 61700 (105.548 iter/s, 0.947433s/100 iter), loss = 0.152387
I0502 11:20:04.452095 26473 solver.cpp:261]     Train net output #0: loss = 0.152387 (* 1 = 0.152387 loss)
I0502 11:20:04.452105 26473 sgd_solver.cpp:106] Iteration 61700, lr = 2.62144e-05
I0502 11:20:04.456923 26473 solver.cpp:242] Iteration 61700 (105.542 iter/s, 0.94749s/100 iter), loss = 0.0915001
I0502 11:20:04.456945 26473 solver.cpp:261]     Train net output #0: loss = 0.0915001 (* 1 = 0.0915001 loss)
I0502 11:20:04.456954 26473 sgd_solver.cpp:106] Iteration 61700, lr = 2.62144e-05
I0502 11:20:05.417992 26473 solver.cpp:242] Iteration 61800 (103.534 iter/s, 0.965871s/100 iter), loss = 0.118935
I0502 11:20:05.418022 26473 solver.cpp:261]     Train net output #0: loss = 0.118935 (* 1 = 0.118935 loss)
I0502 11:20:05.418031 26473 sgd_solver.cpp:106] Iteration 61800, lr = 2.62144e-05
I0502 11:20:05.422830 26473 solver.cpp:242] Iteration 61800 (103.534 iter/s, 0.965865s/100 iter), loss = 0.0679293
I0502 11:20:05.422853 26473 solver.cpp:261]     Train net output #0: loss = 0.0679293 (* 1 = 0.0679293 loss)
I0502 11:20:05.422861 26473 sgd_solver.cpp:106] Iteration 61800, lr = 2.62144e-05
I0502 11:20:06.366302 26473 solver.cpp:242] Iteration 61900 (105.457 iter/s, 0.948252s/100 iter), loss = 0.3635
I0502 11:20:06.366345 26473 solver.cpp:261]     Train net output #0: loss = 0.3635 (* 1 = 0.3635 loss)
I0502 11:20:06.366361 26473 sgd_solver.cpp:106] Iteration 61900, lr = 2.62144e-05
I0502 11:20:06.371212 26473 solver.cpp:242] Iteration 61900 (105.448 iter/s, 0.948331s/100 iter), loss = 0.0894492
I0502 11:20:06.371235 26473 solver.cpp:261]     Train net output #0: loss = 0.0894492 (* 1 = 0.0894492 loss)
I0502 11:20:06.371244 26473 sgd_solver.cpp:106] Iteration 61900, lr = 2.62144e-05
I0502 11:20:07.310367 26473 solver.cpp:362] Iteration 62000, Testing net (#0)
I0502 11:20:07.310395 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:07.434777 26473 solver.cpp:429]     Test net output #0: loss = 0.384438 (* 1 = 0.384438 loss)
I0502 11:20:07.437636 26473 solver.cpp:242] Iteration 62000 (93.3469 iter/s, 1.07127s/100 iter), loss = 0.158334
I0502 11:20:07.437656 26473 solver.cpp:261]     Train net output #0: loss = 0.158334 (* 1 = 0.158334 loss)
I0502 11:20:07.437664 26473 sgd_solver.cpp:106] Iteration 62000, lr = 2.62144e-05
I0502 11:20:07.439400 26473 solver.cpp:362] Iteration 62000, Testing net (#0)
I0502 11:20:07.439414 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:07.569757 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9305
I0502 11:20:07.569778 26473 solver.cpp:429]     Test net output #1: loss = 0.15496 (* 1 = 0.15496 loss)
I0502 11:20:07.572710 26473 solver.cpp:242] Iteration 62000 (83.2326 iter/s, 1.20145s/100 iter), loss = 0.0454861
I0502 11:20:07.572731 26473 solver.cpp:261]     Train net output #0: loss = 0.0454861 (* 1 = 0.0454861 loss)
I0502 11:20:07.572739 26473 sgd_solver.cpp:106] Iteration 62000, lr = 2.62144e-05
I0502 11:20:08.516005 26473 solver.cpp:242] Iteration 62100 (92.7371 iter/s, 1.07832s/100 iter), loss = 0.54719
I0502 11:20:08.516037 26473 solver.cpp:261]     Train net output #0: loss = 0.54719 (* 1 = 0.54719 loss)
I0502 11:20:08.516047 26473 sgd_solver.cpp:106] Iteration 62100, lr = 2.62144e-05
I0502 11:20:08.520831 26473 solver.cpp:242] Iteration 62100 (105.476 iter/s, 0.948083s/100 iter), loss = 0.14682
I0502 11:20:08.520854 26473 solver.cpp:261]     Train net output #0: loss = 0.14682 (* 1 = 0.14682 loss)
I0502 11:20:08.520864 26473 sgd_solver.cpp:106] Iteration 62100, lr = 2.62144e-05
I0502 11:20:09.463049 26473 solver.cpp:242] Iteration 62200 (105.598 iter/s, 0.946984s/100 iter), loss = 0.322623
I0502 11:20:09.463093 26473 solver.cpp:261]     Train net output #0: loss = 0.322623 (* 1 = 0.322623 loss)
I0502 11:20:09.463102 26473 sgd_solver.cpp:106] Iteration 62200, lr = 2.62144e-05
I0502 11:20:09.467937 26473 solver.cpp:242] Iteration 62200 (105.589 iter/s, 0.947065s/100 iter), loss = 0.124734
I0502 11:20:09.467962 26473 solver.cpp:261]     Train net output #0: loss = 0.124734 (* 1 = 0.124734 loss)
I0502 11:20:09.467970 26473 sgd_solver.cpp:106] Iteration 62200, lr = 2.62144e-05
I0502 11:20:10.410948 26473 solver.cpp:242] Iteration 62300 (105.504 iter/s, 0.947828s/100 iter), loss = 0.245457
I0502 11:20:10.410993 26473 solver.cpp:261]     Train net output #0: loss = 0.245457 (* 1 = 0.245457 loss)
I0502 11:20:10.411002 26473 sgd_solver.cpp:106] Iteration 62300, lr = 2.62144e-05
I0502 11:20:10.415777 26473 solver.cpp:242] Iteration 62300 (105.508 iter/s, 0.947797s/100 iter), loss = 0.0745896
I0502 11:20:10.415801 26473 solver.cpp:261]     Train net output #0: loss = 0.0745896 (* 1 = 0.0745896 loss)
I0502 11:20:10.415809 26473 sgd_solver.cpp:106] Iteration 62300, lr = 2.62144e-05
I0502 11:20:11.358206 26473 solver.cpp:242] Iteration 62400 (105.576 iter/s, 0.947188s/100 iter), loss = 0.119263
I0502 11:20:11.358247 26473 solver.cpp:261]     Train net output #0: loss = 0.119263 (* 1 = 0.119263 loss)
I0502 11:20:11.358255 26473 sgd_solver.cpp:106] Iteration 62400, lr = 2.62144e-05
I0502 11:20:11.363041 26473 solver.cpp:242] Iteration 62400 (105.572 iter/s, 0.947223s/100 iter), loss = 0.143478
I0502 11:20:11.363065 26473 solver.cpp:261]     Train net output #0: loss = 0.143478 (* 1 = 0.143478 loss)
I0502 11:20:11.363073 26473 sgd_solver.cpp:106] Iteration 62400, lr = 2.62144e-05
I0502 11:20:12.302805 26473 solver.cpp:362] Iteration 62500, Testing net (#0)
I0502 11:20:12.302839 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:12.427217 26473 solver.cpp:429]     Test net output #0: loss = 0.454009 (* 1 = 0.454009 loss)
I0502 11:20:12.430094 26473 solver.cpp:242] Iteration 62500 (93.2987 iter/s, 1.07183s/100 iter), loss = 0.225281
I0502 11:20:12.430114 26473 solver.cpp:261]     Train net output #0: loss = 0.225281 (* 1 = 0.225281 loss)
I0502 11:20:12.430121 26473 sgd_solver.cpp:106] Iteration 62500, lr = 2.62144e-05
I0502 11:20:12.431838 26473 solver.cpp:362] Iteration 62500, Testing net (#0)
I0502 11:20:12.431851 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:12.562399 26473 solver.cpp:429]     Test net output #0: accuracy = 0.947
I0502 11:20:12.562420 26473 solver.cpp:429]     Test net output #1: loss = 0.144468 (* 1 = 0.144468 loss)
I0502 11:20:12.565335 26473 solver.cpp:242] Iteration 62500 (83.1775 iter/s, 1.20225s/100 iter), loss = 0.0388674
I0502 11:20:12.565356 26473 solver.cpp:261]     Train net output #0: loss = 0.0388674 (* 1 = 0.0388674 loss)
I0502 11:20:12.565363 26473 sgd_solver.cpp:106] Iteration 62500, lr = 2.62144e-05
I0502 11:20:13.508150 26473 solver.cpp:242] Iteration 62600 (92.7641 iter/s, 1.078s/100 iter), loss = 0.217952
I0502 11:20:13.508193 26473 solver.cpp:261]     Train net output #0: loss = 0.217952 (* 1 = 0.217952 loss)
I0502 11:20:13.508201 26473 sgd_solver.cpp:106] Iteration 62600, lr = 2.62144e-05
I0502 11:20:13.513012 26473 solver.cpp:242] Iteration 62600 (105.525 iter/s, 0.947639s/100 iter), loss = 0.0409904
I0502 11:20:13.513036 26473 solver.cpp:261]     Train net output #0: loss = 0.0409904 (* 1 = 0.0409904 loss)
I0502 11:20:13.513044 26473 sgd_solver.cpp:106] Iteration 62600, lr = 2.62144e-05
I0502 11:20:14.456068 26473 solver.cpp:242] Iteration 62700 (105.502 iter/s, 0.947845s/100 iter), loss = 0.130407
I0502 11:20:14.456112 26473 solver.cpp:261]     Train net output #0: loss = 0.130407 (* 1 = 0.130407 loss)
I0502 11:20:14.456121 26473 sgd_solver.cpp:106] Iteration 62700, lr = 2.62144e-05
I0502 11:20:14.460924 26473 solver.cpp:242] Iteration 62700 (105.5 iter/s, 0.947871s/100 iter), loss = 0.222747
I0502 11:20:14.460961 26473 solver.cpp:261]     Train net output #0: loss = 0.222747 (* 1 = 0.222747 loss)
I0502 11:20:14.460970 26473 sgd_solver.cpp:106] Iteration 62700, lr = 2.62144e-05
I0502 11:20:15.425012 26473 solver.cpp:242] Iteration 62800 (103.213 iter/s, 0.968871s/100 iter), loss = 0.221578
I0502 11:20:15.425062 26473 solver.cpp:261]     Train net output #0: loss = 0.221578 (* 1 = 0.221578 loss)
I0502 11:20:15.425073 26473 sgd_solver.cpp:106] Iteration 62800, lr = 2.62144e-05
I0502 11:20:15.430474 26473 solver.cpp:242] Iteration 62800 (103.147 iter/s, 0.969495s/100 iter), loss = 0.0197605
I0502 11:20:15.430502 26473 solver.cpp:261]     Train net output #0: loss = 0.0197605 (* 1 = 0.0197605 loss)
I0502 11:20:15.430513 26473 sgd_solver.cpp:106] Iteration 62800, lr = 2.62144e-05
I0502 11:20:16.466073 26473 solver.cpp:242] Iteration 62900 (96.0629 iter/s, 1.04099s/100 iter), loss = 0.316188
I0502 11:20:16.466114 26473 solver.cpp:261]     Train net output #0: loss = 0.316188 (* 1 = 0.316188 loss)
I0502 11:20:16.466122 26473 sgd_solver.cpp:106] Iteration 62900, lr = 2.62144e-05
I0502 11:20:16.470893 26473 solver.cpp:242] Iteration 62900 (96.1195 iter/s, 1.04037s/100 iter), loss = 0.0829496
I0502 11:20:16.470916 26473 solver.cpp:261]     Train net output #0: loss = 0.0829496 (* 1 = 0.0829496 loss)
I0502 11:20:16.470926 26473 sgd_solver.cpp:106] Iteration 62900, lr = 2.62144e-05
I0502 11:20:17.410287 26473 solver.cpp:362] Iteration 63000, Testing net (#0)
I0502 11:20:17.410310 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:17.534711 26473 solver.cpp:429]     Test net output #0: loss = 0.366487 (* 1 = 0.366487 loss)
I0502 11:20:17.537570 26473 solver.cpp:242] Iteration 63000 (93.3325 iter/s, 1.07144s/100 iter), loss = 0.787666
I0502 11:20:17.537590 26473 solver.cpp:261]     Train net output #0: loss = 0.787666 (* 1 = 0.787666 loss)
I0502 11:20:17.537598 26473 sgd_solver.cpp:106] Iteration 63000, lr = 2.62144e-05
I0502 11:20:17.539330 26473 solver.cpp:362] Iteration 63000, Testing net (#0)
I0502 11:20:17.539342 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:17.669925 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9485
I0502 11:20:17.669946 26473 solver.cpp:429]     Test net output #1: loss = 0.113074 (* 1 = 0.113074 loss)
I0502 11:20:17.672870 26473 solver.cpp:242] Iteration 63000 (83.1994 iter/s, 1.20193s/100 iter), loss = 0.0629575
I0502 11:20:17.672890 26473 solver.cpp:261]     Train net output #0: loss = 0.0629575 (* 1 = 0.0629575 loss)
I0502 11:20:17.672899 26473 sgd_solver.cpp:106] Iteration 63000, lr = 2.62144e-05
I0502 11:20:18.616052 26473 solver.cpp:242] Iteration 63100 (92.7276 iter/s, 1.07843s/100 iter), loss = 0.206142
I0502 11:20:18.616094 26473 solver.cpp:261]     Train net output #0: loss = 0.206142 (* 1 = 0.206142 loss)
I0502 11:20:18.616103 26473 sgd_solver.cpp:106] Iteration 63100, lr = 2.62144e-05
I0502 11:20:18.620906 26473 solver.cpp:242] Iteration 63100 (105.485 iter/s, 0.947998s/100 iter), loss = 0.210276
I0502 11:20:18.620929 26473 solver.cpp:261]     Train net output #0: loss = 0.210276 (* 1 = 0.210276 loss)
I0502 11:20:18.620939 26473 sgd_solver.cpp:106] Iteration 63100, lr = 2.62144e-05
I0502 11:20:19.562813 26473 solver.cpp:242] Iteration 63200 (105.631 iter/s, 0.946689s/100 iter), loss = 0.114793
I0502 11:20:19.562867 26473 solver.cpp:261]     Train net output #0: loss = 0.114793 (* 1 = 0.114793 loss)
I0502 11:20:19.562877 26473 sgd_solver.cpp:106] Iteration 63200, lr = 2.62144e-05
I0502 11:20:19.567710 26473 solver.cpp:242] Iteration 63200 (105.623 iter/s, 0.946763s/100 iter), loss = 0.153309
I0502 11:20:19.567734 26473 solver.cpp:261]     Train net output #0: loss = 0.153309 (* 1 = 0.153309 loss)
I0502 11:20:19.567742 26473 sgd_solver.cpp:106] Iteration 63200, lr = 2.62144e-05
I0502 11:20:20.511221 26473 solver.cpp:242] Iteration 63300 (105.449 iter/s, 0.948327s/100 iter), loss = 0.135956
I0502 11:20:20.511262 26473 solver.cpp:261]     Train net output #0: loss = 0.135956 (* 1 = 0.135956 loss)
I0502 11:20:20.511270 26473 sgd_solver.cpp:106] Iteration 63300, lr = 2.62144e-05
I0502 11:20:20.516093 26473 solver.cpp:242] Iteration 63300 (105.447 iter/s, 0.948341s/100 iter), loss = 0.106673
I0502 11:20:20.516115 26473 solver.cpp:261]     Train net output #0: loss = 0.106673 (* 1 = 0.106673 loss)
I0502 11:20:20.516124 26473 sgd_solver.cpp:106] Iteration 63300, lr = 2.62144e-05
I0502 11:20:21.458283 26473 solver.cpp:242] Iteration 63400 (105.597 iter/s, 0.946995s/100 iter), loss = 0.159404
I0502 11:20:21.458317 26473 solver.cpp:261]     Train net output #0: loss = 0.159404 (* 1 = 0.159404 loss)
I0502 11:20:21.458325 26473 sgd_solver.cpp:106] Iteration 63400, lr = 2.62144e-05
I0502 11:20:21.463099 26473 solver.cpp:242] Iteration 63400 (105.6 iter/s, 0.946966s/100 iter), loss = 0.0737659
I0502 11:20:21.463122 26473 solver.cpp:261]     Train net output #0: loss = 0.0737659 (* 1 = 0.0737659 loss)
I0502 11:20:21.463130 26473 sgd_solver.cpp:106] Iteration 63400, lr = 2.62144e-05
I0502 11:20:22.403188 26473 solver.cpp:362] Iteration 63500, Testing net (#0)
I0502 11:20:22.403209 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:22.527508 26473 solver.cpp:429]     Test net output #0: loss = 0.385921 (* 1 = 0.385921 loss)
I0502 11:20:22.530377 26473 solver.cpp:242] Iteration 63500 (93.28 iter/s, 1.07204s/100 iter), loss = 0.743866
I0502 11:20:22.530397 26473 solver.cpp:261]     Train net output #0: loss = 0.743866 (* 1 = 0.743866 loss)
I0502 11:20:22.530406 26473 sgd_solver.cpp:106] Iteration 63500, lr = 2.62144e-05
I0502 11:20:22.532119 26473 solver.cpp:362] Iteration 63500, Testing net (#0)
I0502 11:20:22.532131 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:22.662720 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9435
I0502 11:20:22.662742 26473 solver.cpp:429]     Test net output #1: loss = 0.125081 (* 1 = 0.125081 loss)
I0502 11:20:22.665663 26473 solver.cpp:242] Iteration 63500 (83.1588 iter/s, 1.20252s/100 iter), loss = 0.0154887
I0502 11:20:22.665691 26473 solver.cpp:261]     Train net output #0: loss = 0.0154887 (* 1 = 0.0154887 loss)
I0502 11:20:22.665701 26473 sgd_solver.cpp:106] Iteration 63500, lr = 2.62144e-05
I0502 11:20:23.608180 26473 solver.cpp:242] Iteration 63600 (92.7861 iter/s, 1.07775s/100 iter), loss = 0.0962851
I0502 11:20:23.608216 26473 solver.cpp:261]     Train net output #0: loss = 0.0962851 (* 1 = 0.0962851 loss)
I0502 11:20:23.608224 26473 sgd_solver.cpp:106] Iteration 63600, lr = 2.62144e-05
I0502 11:20:23.613000 26473 solver.cpp:242] Iteration 63600 (105.564 iter/s, 0.94729s/100 iter), loss = 0.00839843
I0502 11:20:23.613024 26473 solver.cpp:261]     Train net output #0: loss = 0.00839843 (* 1 = 0.00839843 loss)
I0502 11:20:23.613032 26473 sgd_solver.cpp:106] Iteration 63600, lr = 2.62144e-05
I0502 11:20:24.555632 26473 solver.cpp:242] Iteration 63700 (105.553 iter/s, 0.947387s/100 iter), loss = 0.705911
I0502 11:20:24.555670 26473 solver.cpp:261]     Train net output #0: loss = 0.705911 (* 1 = 0.705911 loss)
I0502 11:20:24.555678 26473 sgd_solver.cpp:106] Iteration 63700, lr = 2.62144e-05
I0502 11:20:24.560463 26473 solver.cpp:242] Iteration 63700 (105.55 iter/s, 0.947421s/100 iter), loss = 0.177457
I0502 11:20:24.560487 26473 solver.cpp:261]     Train net output #0: loss = 0.177457 (* 1 = 0.177457 loss)
I0502 11:20:24.560494 26473 sgd_solver.cpp:106] Iteration 63700, lr = 2.62144e-05
I0502 11:20:25.502477 26473 solver.cpp:242] Iteration 63800 (105.621 iter/s, 0.94678s/100 iter), loss = 0.181214
I0502 11:20:25.502512 26473 solver.cpp:261]     Train net output #0: loss = 0.181214 (* 1 = 0.181214 loss)
I0502 11:20:25.502521 26473 sgd_solver.cpp:106] Iteration 63800, lr = 2.62144e-05
I0502 11:20:25.507297 26473 solver.cpp:242] Iteration 63800 (105.62 iter/s, 0.946792s/100 iter), loss = 0.0777011
I0502 11:20:25.507319 26473 solver.cpp:261]     Train net output #0: loss = 0.0777011 (* 1 = 0.0777011 loss)
I0502 11:20:25.507328 26473 sgd_solver.cpp:106] Iteration 63800, lr = 2.62144e-05
I0502 11:20:26.450538 26473 solver.cpp:242] Iteration 63900 (105.485 iter/s, 0.948s/100 iter), loss = 0.176712
I0502 11:20:26.450567 26473 solver.cpp:261]     Train net output #0: loss = 0.176712 (* 1 = 0.176712 loss)
I0502 11:20:26.450577 26473 sgd_solver.cpp:106] Iteration 63900, lr = 2.62144e-05
I0502 11:20:26.455339 26473 solver.cpp:242] Iteration 63900 (105.485 iter/s, 0.948002s/100 iter), loss = 0.0780446
I0502 11:20:26.455363 26473 solver.cpp:261]     Train net output #0: loss = 0.0780446 (* 1 = 0.0780446 loss)
I0502 11:20:26.455370 26473 sgd_solver.cpp:106] Iteration 63900, lr = 2.62144e-05
I0502 11:20:27.394449 26473 solver.cpp:362] Iteration 64000, Testing net (#0)
I0502 11:20:27.394474 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:27.518872 26473 solver.cpp:429]     Test net output #0: loss = 0.320092 (* 1 = 0.320092 loss)
I0502 11:20:27.521740 26473 solver.cpp:242] Iteration 64000 (93.3572 iter/s, 1.07115s/100 iter), loss = 0.272156
I0502 11:20:27.521761 26473 solver.cpp:261]     Train net output #0: loss = 0.272156 (* 1 = 0.272156 loss)
I0502 11:20:27.521770 26473 sgd_solver.cpp:106] Iteration 64000, lr = 2.62144e-05
I0502 11:20:27.523507 26473 solver.cpp:362] Iteration 64000, Testing net (#0)
I0502 11:20:27.523520 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:27.654188 26473 solver.cpp:429]     Test net output #0: accuracy = 0.945
I0502 11:20:27.654208 26473 solver.cpp:429]     Test net output #1: loss = 0.117146 (* 1 = 0.117146 loss)
I0502 11:20:27.657138 26473 solver.cpp:242] Iteration 64000 (83.2116 iter/s, 1.20176s/100 iter), loss = 0.0832557
I0502 11:20:27.657158 26473 solver.cpp:261]     Train net output #0: loss = 0.0832557 (* 1 = 0.0832557 loss)
I0502 11:20:27.657166 26473 sgd_solver.cpp:106] Iteration 64000, lr = 2.62144e-05
I0502 11:20:28.599953 26473 solver.cpp:242] Iteration 64100 (92.7508 iter/s, 1.07816s/100 iter), loss = 0.101146
I0502 11:20:28.599985 26473 solver.cpp:261]     Train net output #0: loss = 0.101146 (* 1 = 0.101146 loss)
I0502 11:20:28.599994 26473 sgd_solver.cpp:106] Iteration 64100, lr = 2.62144e-05
I0502 11:20:28.604784 26473 solver.cpp:242] Iteration 64100 (105.529 iter/s, 0.947607s/100 iter), loss = 0.208567
I0502 11:20:28.604807 26473 solver.cpp:261]     Train net output #0: loss = 0.208567 (* 1 = 0.208567 loss)
I0502 11:20:28.604815 26473 sgd_solver.cpp:106] Iteration 64100, lr = 2.62144e-05
I0502 11:20:29.546592 26473 solver.cpp:242] Iteration 64200 (105.644 iter/s, 0.946575s/100 iter), loss = 0.170993
I0502 11:20:29.546634 26473 solver.cpp:261]     Train net output #0: loss = 0.170993 (* 1 = 0.170993 loss)
I0502 11:20:29.546643 26473 sgd_solver.cpp:106] Iteration 64200, lr = 2.62144e-05
I0502 11:20:29.551434 26473 solver.cpp:242] Iteration 64200 (105.64 iter/s, 0.946609s/100 iter), loss = 0.209356
I0502 11:20:29.551457 26473 solver.cpp:261]     Train net output #0: loss = 0.209356 (* 1 = 0.209356 loss)
I0502 11:20:29.551465 26473 sgd_solver.cpp:106] Iteration 64200, lr = 2.62144e-05
I0502 11:20:30.494248 26473 solver.cpp:242] Iteration 64300 (105.532 iter/s, 0.947583s/100 iter), loss = 0.117694
I0502 11:20:30.494292 26473 solver.cpp:261]     Train net output #0: loss = 0.117694 (* 1 = 0.117694 loss)
I0502 11:20:30.494300 26473 sgd_solver.cpp:106] Iteration 64300, lr = 2.62144e-05
I0502 11:20:30.499090 26473 solver.cpp:242] Iteration 64300 (105.528 iter/s, 0.947616s/100 iter), loss = 0.0905063
I0502 11:20:30.499114 26473 solver.cpp:261]     Train net output #0: loss = 0.0905063 (* 1 = 0.0905063 loss)
I0502 11:20:30.499122 26473 sgd_solver.cpp:106] Iteration 64300, lr = 2.62144e-05
I0502 11:20:31.441409 26473 solver.cpp:242] Iteration 64400 (105.586 iter/s, 0.947091s/100 iter), loss = 0.199104
I0502 11:20:31.441452 26473 solver.cpp:261]     Train net output #0: loss = 0.199104 (* 1 = 0.199104 loss)
I0502 11:20:31.441460 26473 sgd_solver.cpp:106] Iteration 64400, lr = 2.62144e-05
I0502 11:20:31.446235 26473 solver.cpp:242] Iteration 64400 (105.585 iter/s, 0.947103s/100 iter), loss = 0.0994536
I0502 11:20:31.446259 26473 solver.cpp:261]     Train net output #0: loss = 0.0994536 (* 1 = 0.0994536 loss)
I0502 11:20:31.446266 26473 sgd_solver.cpp:106] Iteration 64400, lr = 2.62144e-05
I0502 11:20:32.386365 26473 solver.cpp:362] Iteration 64500, Testing net (#0)
I0502 11:20:32.386391 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:32.510639 26473 solver.cpp:429]     Test net output #0: loss = 0.472513 (* 1 = 0.472513 loss)
I0502 11:20:32.513504 26473 solver.cpp:242] Iteration 64500 (93.2806 iter/s, 1.07203s/100 iter), loss = 0.863502
I0502 11:20:32.513525 26473 solver.cpp:261]     Train net output #0: loss = 0.863502 (* 1 = 0.863502 loss)
I0502 11:20:32.513533 26473 sgd_solver.cpp:106] Iteration 64500, lr = 2.62144e-05
I0502 11:20:32.515241 26473 solver.cpp:362] Iteration 64500, Testing net (#0)
I0502 11:20:32.515254 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:32.645913 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9395
I0502 11:20:32.645936 26473 solver.cpp:429]     Test net output #1: loss = 0.127719 (* 1 = 0.127719 loss)
I0502 11:20:32.648867 26473 solver.cpp:242] Iteration 64500 (83.154 iter/s, 1.20259s/100 iter), loss = 0.0507389
I0502 11:20:32.648888 26473 solver.cpp:261]     Train net output #0: loss = 0.0507389 (* 1 = 0.0507389 loss)
I0502 11:20:32.648896 26473 sgd_solver.cpp:106] Iteration 64500, lr = 2.62144e-05
I0502 11:20:33.591498 26473 solver.cpp:242] Iteration 64600 (92.769 iter/s, 1.07795s/100 iter), loss = 0.684196
I0502 11:20:33.591542 26473 solver.cpp:261]     Train net output #0: loss = 0.684196 (* 1 = 0.684196 loss)
I0502 11:20:33.591549 26473 sgd_solver.cpp:106] Iteration 64600, lr = 2.62144e-05
I0502 11:20:33.596410 26473 solver.cpp:242] Iteration 64600 (105.541 iter/s, 0.947496s/100 iter), loss = 0.17906
I0502 11:20:33.596432 26473 solver.cpp:261]     Train net output #0: loss = 0.17906 (* 1 = 0.17906 loss)
I0502 11:20:33.596441 26473 sgd_solver.cpp:106] Iteration 64600, lr = 2.62144e-05
I0502 11:20:34.540693 26473 solver.cpp:242] Iteration 64700 (105.361 iter/s, 0.949121s/100 iter), loss = 0.259777
I0502 11:20:34.540745 26473 solver.cpp:261]     Train net output #0: loss = 0.259777 (* 1 = 0.259777 loss)
I0502 11:20:34.540755 26473 sgd_solver.cpp:106] Iteration 64700, lr = 2.62144e-05
I0502 11:20:34.545547 26473 solver.cpp:242] Iteration 64700 (105.363 iter/s, 0.949096s/100 iter), loss = 0.00325889
I0502 11:20:34.545570 26473 solver.cpp:261]     Train net output #0: loss = 0.00325889 (* 1 = 0.00325889 loss)
I0502 11:20:34.545579 26473 sgd_solver.cpp:106] Iteration 64700, lr = 2.62144e-05
I0502 11:20:35.487382 26473 solver.cpp:242] Iteration 64800 (105.64 iter/s, 0.94661s/100 iter), loss = 0.0870834
I0502 11:20:35.487423 26473 solver.cpp:261]     Train net output #0: loss = 0.0870834 (* 1 = 0.0870834 loss)
I0502 11:20:35.487432 26473 sgd_solver.cpp:106] Iteration 64800, lr = 2.62144e-05
I0502 11:20:35.492254 26473 solver.cpp:242] Iteration 64800 (105.634 iter/s, 0.946664s/100 iter), loss = 0.0166828
I0502 11:20:35.492276 26473 solver.cpp:261]     Train net output #0: loss = 0.0166828 (* 1 = 0.0166828 loss)
I0502 11:20:35.492285 26473 sgd_solver.cpp:106] Iteration 64800, lr = 2.62144e-05
I0502 11:20:36.436892 26473 solver.cpp:242] Iteration 64900 (105.325 iter/s, 0.94944s/100 iter), loss = 0.329002
I0502 11:20:36.436935 26473 solver.cpp:261]     Train net output #0: loss = 0.329002 (* 1 = 0.329002 loss)
I0502 11:20:36.436944 26473 sgd_solver.cpp:106] Iteration 64900, lr = 2.62144e-05
I0502 11:20:36.441692 26473 solver.cpp:242] Iteration 64900 (105.33 iter/s, 0.949398s/100 iter), loss = 0.181682
I0502 11:20:36.441715 26473 solver.cpp:261]     Train net output #0: loss = 0.181682 (* 1 = 0.181682 loss)
I0502 11:20:36.441725 26473 sgd_solver.cpp:106] Iteration 64900, lr = 2.62144e-05
I0502 11:20:37.381608 26473 solver.cpp:362] Iteration 65000, Testing net (#0)
I0502 11:20:37.381633 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:37.506047 26473 solver.cpp:429]     Test net output #0: loss = 0.326118 (* 1 = 0.326118 loss)
I0502 11:20:37.508920 26473 solver.cpp:242] Iteration 65000 (93.2865 iter/s, 1.07197s/100 iter), loss = 0.0531825
I0502 11:20:37.508941 26473 solver.cpp:261]     Train net output #0: loss = 0.0531825 (* 1 = 0.0531825 loss)
I0502 11:20:37.508949 26473 sgd_solver.cpp:106] Iteration 65000, lr = 2.62144e-05
I0502 11:20:37.510584 26473 solver.cpp:362] Iteration 65000, Testing net (#0)
I0502 11:20:37.510597 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:37.641086 26473 solver.cpp:429]     Test net output #0: accuracy = 0.933
I0502 11:20:37.641108 26473 solver.cpp:429]     Test net output #1: loss = 0.126173 (* 1 = 0.126173 loss)
I0502 11:20:37.644042 26473 solver.cpp:242] Iteration 65000 (83.1736 iter/s, 1.20231s/100 iter), loss = 0.135129
I0502 11:20:37.644062 26473 solver.cpp:261]     Train net output #0: loss = 0.135129 (* 1 = 0.135129 loss)
I0502 11:20:37.644070 26473 sgd_solver.cpp:106] Iteration 65000, lr = 2.62144e-05
I0502 11:20:38.587252 26473 solver.cpp:242] Iteration 65100 (92.74 iter/s, 1.07828s/100 iter), loss = 0.283025
I0502 11:20:38.587294 26473 solver.cpp:261]     Train net output #0: loss = 0.283025 (* 1 = 0.283025 loss)
I0502 11:20:38.587302 26473 sgd_solver.cpp:106] Iteration 65100, lr = 2.62144e-05
I0502 11:20:38.592140 26473 solver.cpp:242] Iteration 65100 (105.479 iter/s, 0.948052s/100 iter), loss = 0.150971
I0502 11:20:38.592164 26473 solver.cpp:261]     Train net output #0: loss = 0.150971 (* 1 = 0.150971 loss)
I0502 11:20:38.592173 26473 sgd_solver.cpp:106] Iteration 65100, lr = 2.62144e-05
I0502 11:20:39.534171 26473 solver.cpp:242] Iteration 65200 (105.614 iter/s, 0.946847s/100 iter), loss = 0.413481
I0502 11:20:39.534209 26473 solver.cpp:261]     Train net output #0: loss = 0.413481 (* 1 = 0.413481 loss)
I0502 11:20:39.534217 26473 sgd_solver.cpp:106] Iteration 65200, lr = 2.62144e-05
I0502 11:20:39.539005 26473 solver.cpp:242] Iteration 65200 (105.617 iter/s, 0.946821s/100 iter), loss = 0.0743717
I0502 11:20:39.539028 26473 solver.cpp:261]     Train net output #0: loss = 0.0743717 (* 1 = 0.0743717 loss)
I0502 11:20:39.539036 26473 sgd_solver.cpp:106] Iteration 65200, lr = 2.62144e-05
I0502 11:20:40.481125 26473 solver.cpp:242] Iteration 65300 (105.609 iter/s, 0.946887s/100 iter), loss = 0.0872465
I0502 11:20:40.481166 26473 solver.cpp:261]     Train net output #0: loss = 0.0872465 (* 1 = 0.0872465 loss)
I0502 11:20:40.481175 26473 sgd_solver.cpp:106] Iteration 65300, lr = 2.62144e-05
I0502 11:20:40.485947 26473 solver.cpp:242] Iteration 65300 (105.608 iter/s, 0.946901s/100 iter), loss = 0.068504
I0502 11:20:40.485970 26473 solver.cpp:261]     Train net output #0: loss = 0.068504 (* 1 = 0.068504 loss)
I0502 11:20:40.485978 26473 sgd_solver.cpp:106] Iteration 65300, lr = 2.62144e-05
I0502 11:20:41.429380 26473 solver.cpp:242] Iteration 65400 (105.464 iter/s, 0.948188s/100 iter), loss = 0.189572
I0502 11:20:41.429417 26473 solver.cpp:261]     Train net output #0: loss = 0.189572 (* 1 = 0.189572 loss)
I0502 11:20:41.429425 26473 sgd_solver.cpp:106] Iteration 65400, lr = 2.62144e-05
I0502 11:20:41.434195 26473 solver.cpp:242] Iteration 65400 (105.462 iter/s, 0.948206s/100 iter), loss = 0.0451928
I0502 11:20:41.434217 26473 solver.cpp:261]     Train net output #0: loss = 0.0451928 (* 1 = 0.0451928 loss)
I0502 11:20:41.434226 26473 sgd_solver.cpp:106] Iteration 65400, lr = 2.62144e-05
I0502 11:20:42.373561 26473 solver.cpp:362] Iteration 65500, Testing net (#0)
I0502 11:20:42.373580 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:42.497916 26473 solver.cpp:429]     Test net output #0: loss = 0.254768 (* 1 = 0.254768 loss)
I0502 11:20:42.500787 26473 solver.cpp:242] Iteration 65500 (93.3401 iter/s, 1.07135s/100 iter), loss = 0.148028
I0502 11:20:42.500808 26473 solver.cpp:261]     Train net output #0: loss = 0.148028 (* 1 = 0.148028 loss)
I0502 11:20:42.500816 26473 sgd_solver.cpp:106] Iteration 65500, lr = 2.62144e-05
I0502 11:20:42.502540 26473 solver.cpp:362] Iteration 65500, Testing net (#0)
I0502 11:20:42.502553 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:42.633313 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9505
I0502 11:20:42.633337 26473 solver.cpp:429]     Test net output #1: loss = 0.104955 (* 1 = 0.104955 loss)
I0502 11:20:42.636251 26473 solver.cpp:242] Iteration 65500 (83.1938 iter/s, 1.20201s/100 iter), loss = 0.070321
I0502 11:20:42.636271 26473 solver.cpp:261]     Train net output #0: loss = 0.070321 (* 1 = 0.070321 loss)
I0502 11:20:42.636281 26473 sgd_solver.cpp:106] Iteration 65500, lr = 2.62144e-05
I0502 11:20:43.578636 26473 solver.cpp:242] Iteration 65600 (92.7813 iter/s, 1.0778s/100 iter), loss = 0.763992
I0502 11:20:43.578670 26473 solver.cpp:261]     Train net output #0: loss = 0.763992 (* 1 = 0.763992 loss)
I0502 11:20:43.578678 26473 sgd_solver.cpp:106] Iteration 65600, lr = 2.62144e-05
I0502 11:20:43.583545 26473 solver.cpp:242] Iteration 65600 (105.569 iter/s, 0.947247s/100 iter), loss = 0.0718772
I0502 11:20:43.583570 26473 solver.cpp:261]     Train net output #0: loss = 0.0718772 (* 1 = 0.0718772 loss)
I0502 11:20:43.583577 26473 sgd_solver.cpp:106] Iteration 65600, lr = 2.62144e-05
I0502 11:20:44.526064 26473 solver.cpp:242] Iteration 65700 (105.556 iter/s, 0.947363s/100 iter), loss = 0.124295
I0502 11:20:44.526103 26473 solver.cpp:261]     Train net output #0: loss = 0.124295 (* 1 = 0.124295 loss)
I0502 11:20:44.526113 26473 sgd_solver.cpp:106] Iteration 65700, lr = 2.62144e-05
I0502 11:20:44.530901 26473 solver.cpp:242] Iteration 65700 (105.562 iter/s, 0.947315s/100 iter), loss = 0.0464337
I0502 11:20:44.530925 26473 solver.cpp:261]     Train net output #0: loss = 0.0464337 (* 1 = 0.0464337 loss)
I0502 11:20:44.530933 26473 sgd_solver.cpp:106] Iteration 65700, lr = 2.62144e-05
I0502 11:20:45.472939 26473 solver.cpp:242] Iteration 65800 (105.618 iter/s, 0.946808s/100 iter), loss = 0.432162
I0502 11:20:45.472970 26473 solver.cpp:261]     Train net output #0: loss = 0.432162 (* 1 = 0.432162 loss)
I0502 11:20:45.472978 26473 sgd_solver.cpp:106] Iteration 65800, lr = 2.62144e-05
I0502 11:20:45.477747 26473 solver.cpp:242] Iteration 65800 (105.618 iter/s, 0.946805s/100 iter), loss = 0.0949525
I0502 11:20:45.477782 26473 solver.cpp:261]     Train net output #0: loss = 0.0949525 (* 1 = 0.0949525 loss)
I0502 11:20:45.477790 26473 sgd_solver.cpp:106] Iteration 65800, lr = 2.62144e-05
I0502 11:20:46.421818 26473 solver.cpp:242] Iteration 65900 (105.394 iter/s, 0.948819s/100 iter), loss = 0.30587
I0502 11:20:46.421860 26473 solver.cpp:261]     Train net output #0: loss = 0.30587 (* 1 = 0.30587 loss)
I0502 11:20:46.421870 26473 sgd_solver.cpp:106] Iteration 65900, lr = 2.62144e-05
I0502 11:20:46.426656 26473 solver.cpp:242] Iteration 65900 (105.39 iter/s, 0.948856s/100 iter), loss = 0.0582234
I0502 11:20:46.426679 26473 solver.cpp:261]     Train net output #0: loss = 0.0582234 (* 1 = 0.0582234 loss)
I0502 11:20:46.426688 26473 sgd_solver.cpp:106] Iteration 65900, lr = 2.62144e-05
I0502 11:20:47.366042 26473 solver.cpp:362] Iteration 66000, Testing net (#0)
I0502 11:20:47.366071 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:47.490417 26473 solver.cpp:429]     Test net output #0: loss = 0.314637 (* 1 = 0.314637 loss)
I0502 11:20:47.493288 26473 solver.cpp:242] Iteration 66000 (93.3351 iter/s, 1.07141s/100 iter), loss = 0.232527
I0502 11:20:47.493309 26473 solver.cpp:261]     Train net output #0: loss = 0.232527 (* 1 = 0.232527 loss)
I0502 11:20:47.493317 26473 sgd_solver.cpp:106] Iteration 66000, lr = 2.62144e-05
I0502 11:20:47.494959 26473 solver.cpp:362] Iteration 66000, Testing net (#0)
I0502 11:20:47.494973 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:47.625536 26473 solver.cpp:429]     Test net output #0: accuracy = 0.942
I0502 11:20:47.625555 26473 solver.cpp:429]     Test net output #1: loss = 0.137464 (* 1 = 0.137464 loss)
I0502 11:20:47.628469 26473 solver.cpp:242] Iteration 66000 (83.2106 iter/s, 1.20177s/100 iter), loss = 0.0273611
I0502 11:20:47.628489 26473 solver.cpp:261]     Train net output #0: loss = 0.0273611 (* 1 = 0.0273611 loss)
I0502 11:20:47.628499 26473 sgd_solver.cpp:106] Iteration 66000, lr = 2.62144e-05
I0502 11:20:48.571640 26473 solver.cpp:242] Iteration 66100 (92.7384 iter/s, 1.0783s/100 iter), loss = 0.658786
I0502 11:20:48.571681 26473 solver.cpp:261]     Train net output #0: loss = 0.658786 (* 1 = 0.658786 loss)
I0502 11:20:48.571691 26473 sgd_solver.cpp:106] Iteration 66100, lr = 2.62144e-05
I0502 11:20:48.576594 26473 solver.cpp:242] Iteration 66100 (105.477 iter/s, 0.948077s/100 iter), loss = 0.0722121
I0502 11:20:48.576618 26473 solver.cpp:261]     Train net output #0: loss = 0.0722121 (* 1 = 0.0722121 loss)
I0502 11:20:48.576627 26473 sgd_solver.cpp:106] Iteration 66100, lr = 2.62144e-05
I0502 11:20:49.518503 26473 solver.cpp:242] Iteration 66200 (105.62 iter/s, 0.94679s/100 iter), loss = 0.209056
I0502 11:20:49.518545 26473 solver.cpp:261]     Train net output #0: loss = 0.209056 (* 1 = 0.209056 loss)
I0502 11:20:49.518554 26473 sgd_solver.cpp:106] Iteration 66200, lr = 2.62144e-05
I0502 11:20:49.523332 26473 solver.cpp:242] Iteration 66200 (105.631 iter/s, 0.946695s/100 iter), loss = 0.0367613
I0502 11:20:49.523356 26473 solver.cpp:261]     Train net output #0: loss = 0.0367613 (* 1 = 0.0367613 loss)
I0502 11:20:49.523365 26473 sgd_solver.cpp:106] Iteration 66200, lr = 2.62144e-05
I0502 11:20:50.466207 26473 solver.cpp:242] Iteration 66300 (105.526 iter/s, 0.94763s/100 iter), loss = 0.220474
I0502 11:20:50.466248 26473 solver.cpp:261]     Train net output #0: loss = 0.220474 (* 1 = 0.220474 loss)
I0502 11:20:50.466256 26473 sgd_solver.cpp:106] Iteration 66300, lr = 2.62144e-05
I0502 11:20:50.471036 26473 solver.cpp:242] Iteration 66300 (105.523 iter/s, 0.947662s/100 iter), loss = 0.16905
I0502 11:20:50.471060 26473 solver.cpp:261]     Train net output #0: loss = 0.16905 (* 1 = 0.16905 loss)
I0502 11:20:50.471067 26473 sgd_solver.cpp:106] Iteration 66300, lr = 2.62144e-05
I0502 11:20:51.413314 26473 solver.cpp:242] Iteration 66400 (105.592 iter/s, 0.94704s/100 iter), loss = 0.0617527
I0502 11:20:51.413357 26473 solver.cpp:261]     Train net output #0: loss = 0.0617527 (* 1 = 0.0617527 loss)
I0502 11:20:51.413365 26473 sgd_solver.cpp:106] Iteration 66400, lr = 2.62144e-05
I0502 11:20:51.418159 26473 solver.cpp:242] Iteration 66400 (105.588 iter/s, 0.94708s/100 iter), loss = 0.076178
I0502 11:20:51.418181 26473 solver.cpp:261]     Train net output #0: loss = 0.076178 (* 1 = 0.076178 loss)
I0502 11:20:51.418190 26473 sgd_solver.cpp:106] Iteration 66400, lr = 2.62144e-05
I0502 11:20:52.357570 26473 solver.cpp:362] Iteration 66500, Testing net (#0)
I0502 11:20:52.357597 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:52.482055 26473 solver.cpp:429]     Test net output #0: loss = 0.33917 (* 1 = 0.33917 loss)
I0502 11:20:52.484937 26473 solver.cpp:242] Iteration 66500 (93.3217 iter/s, 1.07156s/100 iter), loss = 0.560643
I0502 11:20:52.484957 26473 solver.cpp:261]     Train net output #0: loss = 0.560643 (* 1 = 0.560643 loss)
I0502 11:20:52.484966 26473 sgd_solver.cpp:106] Iteration 66500, lr = 2.62144e-05
I0502 11:20:52.486608 26473 solver.cpp:362] Iteration 66500, Testing net (#0)
I0502 11:20:52.486621 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:52.617128 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9365
I0502 11:20:52.617149 26473 solver.cpp:429]     Test net output #1: loss = 0.13468 (* 1 = 0.13468 loss)
I0502 11:20:52.620069 26473 solver.cpp:242] Iteration 66500 (83.2039 iter/s, 1.20187s/100 iter), loss = 0.00939138
I0502 11:20:52.620090 26473 solver.cpp:261]     Train net output #0: loss = 0.00939138 (* 1 = 0.00939138 loss)
I0502 11:20:52.620098 26473 sgd_solver.cpp:106] Iteration 66500, lr = 2.62144e-05
I0502 11:20:53.563328 26473 solver.cpp:242] Iteration 66600 (92.735 iter/s, 1.07834s/100 iter), loss = 1.05744
I0502 11:20:53.563369 26473 solver.cpp:261]     Train net output #0: loss = 1.05744 (* 1 = 1.05744 loss)
I0502 11:20:53.563377 26473 sgd_solver.cpp:106] Iteration 66600, lr = 2.62144e-05
I0502 11:20:53.568241 26473 solver.cpp:242] Iteration 66600 (105.471 iter/s, 0.948124s/100 iter), loss = 0.335618
I0502 11:20:53.568265 26473 solver.cpp:261]     Train net output #0: loss = 0.335618 (* 1 = 0.335618 loss)
I0502 11:20:53.568274 26473 sgd_solver.cpp:106] Iteration 66600, lr = 2.62144e-05
I0502 11:20:54.510900 26473 solver.cpp:242] Iteration 66700 (105.541 iter/s, 0.947498s/100 iter), loss = 0.104506
I0502 11:20:54.510939 26473 solver.cpp:261]     Train net output #0: loss = 0.104506 (* 1 = 0.104506 loss)
I0502 11:20:54.510948 26473 sgd_solver.cpp:106] Iteration 66700, lr = 2.62144e-05
I0502 11:20:54.515725 26473 solver.cpp:242] Iteration 66700 (105.547 iter/s, 0.947442s/100 iter), loss = 0.119574
I0502 11:20:54.515748 26473 solver.cpp:261]     Train net output #0: loss = 0.119574 (* 1 = 0.119574 loss)
I0502 11:20:54.515756 26473 sgd_solver.cpp:106] Iteration 66700, lr = 2.62144e-05
I0502 11:20:55.458335 26473 solver.cpp:242] Iteration 66800 (105.556 iter/s, 0.947365s/100 iter), loss = 0.172277
I0502 11:20:55.458376 26473 solver.cpp:261]     Train net output #0: loss = 0.172277 (* 1 = 0.172277 loss)
I0502 11:20:55.458385 26473 sgd_solver.cpp:106] Iteration 66800, lr = 2.62144e-05
I0502 11:20:55.463172 26473 solver.cpp:242] Iteration 66800 (105.551 iter/s, 0.947407s/100 iter), loss = 0.125254
I0502 11:20:55.463196 26473 solver.cpp:261]     Train net output #0: loss = 0.125254 (* 1 = 0.125254 loss)
I0502 11:20:55.463204 26473 sgd_solver.cpp:106] Iteration 66800, lr = 2.62144e-05
I0502 11:20:56.407500 26473 solver.cpp:242] Iteration 66900 (105.364 iter/s, 0.949094s/100 iter), loss = 0.162707
I0502 11:20:56.407541 26473 solver.cpp:261]     Train net output #0: loss = 0.162707 (* 1 = 0.162707 loss)
I0502 11:20:56.407549 26473 sgd_solver.cpp:106] Iteration 66900, lr = 2.62144e-05
I0502 11:20:56.412317 26473 solver.cpp:242] Iteration 66900 (105.363 iter/s, 0.949104s/100 iter), loss = 0.197825
I0502 11:20:56.412343 26473 solver.cpp:261]     Train net output #0: loss = 0.197825 (* 1 = 0.197825 loss)
I0502 11:20:56.412351 26473 sgd_solver.cpp:106] Iteration 66900, lr = 2.62144e-05
I0502 11:20:57.352388 26473 solver.cpp:362] Iteration 67000, Testing net (#0)
I0502 11:20:57.352414 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:57.476847 26473 solver.cpp:429]     Test net output #0: loss = 0.290767 (* 1 = 0.290767 loss)
I0502 11:20:57.479730 26473 solver.cpp:242] Iteration 67000 (93.2687 iter/s, 1.07217s/100 iter), loss = 0.222913
I0502 11:20:57.479750 26473 solver.cpp:261]     Train net output #0: loss = 0.222913 (* 1 = 0.222913 loss)
I0502 11:20:57.479758 26473 sgd_solver.cpp:106] Iteration 67000, lr = 2.62144e-05
I0502 11:20:57.481426 26473 solver.cpp:362] Iteration 67000, Testing net (#0)
I0502 11:20:57.481441 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:20:57.612082 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9515
I0502 11:20:57.612103 26473 solver.cpp:429]     Test net output #1: loss = 0.110863 (* 1 = 0.110863 loss)
I0502 11:20:57.615042 26473 solver.cpp:242] Iteration 67000 (83.1477 iter/s, 1.20268s/100 iter), loss = 0.127979
I0502 11:20:57.615062 26473 solver.cpp:261]     Train net output #0: loss = 0.127979 (* 1 = 0.127979 loss)
I0502 11:20:57.615072 26473 sgd_solver.cpp:106] Iteration 67000, lr = 2.62144e-05
I0502 11:20:58.557343 26473 solver.cpp:242] Iteration 67100 (92.8019 iter/s, 1.07756s/100 iter), loss = 0.23139
I0502 11:20:58.557377 26473 solver.cpp:261]     Train net output #0: loss = 0.23139 (* 1 = 0.23139 loss)
I0502 11:20:58.557386 26473 sgd_solver.cpp:106] Iteration 67100, lr = 2.62144e-05
I0502 11:20:58.562268 26473 solver.cpp:242] Iteration 67100 (105.577 iter/s, 0.947176s/100 iter), loss = 0.151418
I0502 11:20:58.562291 26473 solver.cpp:261]     Train net output #0: loss = 0.151418 (* 1 = 0.151418 loss)
I0502 11:20:58.562300 26473 sgd_solver.cpp:106] Iteration 67100, lr = 2.62144e-05
I0502 11:20:59.505100 26473 solver.cpp:242] Iteration 67200 (105.519 iter/s, 0.947699s/100 iter), loss = 0.132902
I0502 11:20:59.505134 26473 solver.cpp:261]     Train net output #0: loss = 0.132902 (* 1 = 0.132902 loss)
I0502 11:20:59.505142 26473 sgd_solver.cpp:106] Iteration 67200, lr = 2.62144e-05
I0502 11:20:59.510017 26473 solver.cpp:242] Iteration 67200 (105.518 iter/s, 0.947702s/100 iter), loss = 0.0473928
I0502 11:20:59.510040 26473 solver.cpp:261]     Train net output #0: loss = 0.0473928 (* 1 = 0.0473928 loss)
I0502 11:20:59.510049 26473 sgd_solver.cpp:106] Iteration 67200, lr = 2.62144e-05
I0502 11:21:00.465137 26473 solver.cpp:242] Iteration 67300 (104.17 iter/s, 0.959971s/100 iter), loss = 0.704159
I0502 11:21:00.465170 26473 solver.cpp:261]     Train net output #0: loss = 0.704159 (* 1 = 0.704159 loss)
I0502 11:21:00.465179 26473 sgd_solver.cpp:106] Iteration 67300, lr = 2.62144e-05
I0502 11:21:00.469996 26473 solver.cpp:242] Iteration 67300 (104.173 iter/s, 0.959938s/100 iter), loss = 0.0698197
I0502 11:21:00.470021 26473 solver.cpp:261]     Train net output #0: loss = 0.0698197 (* 1 = 0.0698197 loss)
I0502 11:21:00.470029 26473 sgd_solver.cpp:106] Iteration 67300, lr = 2.62144e-05
I0502 11:21:01.418776 26473 solver.cpp:242] Iteration 67400 (104.868 iter/s, 0.953577s/100 iter), loss = 0.314582
I0502 11:21:01.418810 26473 solver.cpp:261]     Train net output #0: loss = 0.314582 (* 1 = 0.314582 loss)
I0502 11:21:01.418819 26473 sgd_solver.cpp:106] Iteration 67400, lr = 2.62144e-05
I0502 11:21:01.423640 26473 solver.cpp:242] Iteration 67400 (104.866 iter/s, 0.953601s/100 iter), loss = 0.0888292
I0502 11:21:01.423665 26473 solver.cpp:261]     Train net output #0: loss = 0.0888292 (* 1 = 0.0888292 loss)
I0502 11:21:01.423673 26473 sgd_solver.cpp:106] Iteration 67400, lr = 2.62144e-05
I0502 11:21:02.364392 26473 solver.cpp:362] Iteration 67500, Testing net (#0)
I0502 11:21:02.364410 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:02.488524 26473 solver.cpp:429]     Test net output #0: loss = 0.400079 (* 1 = 0.400079 loss)
I0502 11:21:02.491389 26473 solver.cpp:242] Iteration 67500 (93.2348 iter/s, 1.07256s/100 iter), loss = 0.0538909
I0502 11:21:02.491410 26473 solver.cpp:261]     Train net output #0: loss = 0.0538909 (* 1 = 0.0538909 loss)
I0502 11:21:02.491417 26473 sgd_solver.cpp:106] Iteration 67500, lr = 2.62144e-05
I0502 11:21:02.493067 26473 solver.cpp:362] Iteration 67500, Testing net (#0)
I0502 11:21:02.493088 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:02.623775 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9465
I0502 11:21:02.623805 26473 solver.cpp:429]     Test net output #1: loss = 0.122149 (* 1 = 0.122149 loss)
I0502 11:21:02.626744 26473 solver.cpp:242] Iteration 67500 (83.1215 iter/s, 1.20306s/100 iter), loss = 0.162068
I0502 11:21:02.626765 26473 solver.cpp:261]     Train net output #0: loss = 0.162068 (* 1 = 0.162068 loss)
I0502 11:21:02.626775 26473 sgd_solver.cpp:106] Iteration 67500, lr = 2.62144e-05
I0502 11:21:03.569175 26473 solver.cpp:242] Iteration 67600 (92.7869 iter/s, 1.07774s/100 iter), loss = 0.32498
I0502 11:21:03.569207 26473 solver.cpp:261]     Train net output #0: loss = 0.32498 (* 1 = 0.32498 loss)
I0502 11:21:03.569216 26473 sgd_solver.cpp:106] Iteration 67600, lr = 2.62144e-05
I0502 11:21:03.574105 26473 solver.cpp:242] Iteration 67600 (105.562 iter/s, 0.947312s/100 iter), loss = 0.108383
I0502 11:21:03.574127 26473 solver.cpp:261]     Train net output #0: loss = 0.108383 (* 1 = 0.108383 loss)
I0502 11:21:03.574136 26473 sgd_solver.cpp:106] Iteration 67600, lr = 2.62144e-05
I0502 11:21:04.516008 26473 solver.cpp:242] Iteration 67700 (105.622 iter/s, 0.946776s/100 iter), loss = 0.576805
I0502 11:21:04.516052 26473 solver.cpp:261]     Train net output #0: loss = 0.576805 (* 1 = 0.576805 loss)
I0502 11:21:04.516060 26473 sgd_solver.cpp:106] Iteration 67700, lr = 2.62144e-05
I0502 11:21:04.520937 26473 solver.cpp:242] Iteration 67700 (105.62 iter/s, 0.946786s/100 iter), loss = 0.275483
I0502 11:21:04.520961 26473 solver.cpp:261]     Train net output #0: loss = 0.275483 (* 1 = 0.275483 loss)
I0502 11:21:04.520969 26473 sgd_solver.cpp:106] Iteration 67700, lr = 2.62144e-05
I0502 11:21:05.463567 26473 solver.cpp:242] Iteration 67800 (105.543 iter/s, 0.947484s/100 iter), loss = 0.204856
I0502 11:21:05.463608 26473 solver.cpp:261]     Train net output #0: loss = 0.204856 (* 1 = 0.204856 loss)
I0502 11:21:05.463616 26473 sgd_solver.cpp:106] Iteration 67800, lr = 2.62144e-05
I0502 11:21:05.468389 26473 solver.cpp:242] Iteration 67800 (105.551 iter/s, 0.947409s/100 iter), loss = 0.146632
I0502 11:21:05.468410 26473 solver.cpp:261]     Train net output #0: loss = 0.146632 (* 1 = 0.146632 loss)
I0502 11:21:05.468420 26473 sgd_solver.cpp:106] Iteration 67800, lr = 2.62144e-05
I0502 11:21:06.413195 26473 solver.cpp:242] Iteration 67900 (105.312 iter/s, 0.949557s/100 iter), loss = 0.223129
I0502 11:21:06.413241 26473 solver.cpp:261]     Train net output #0: loss = 0.223129 (* 1 = 0.223129 loss)
I0502 11:21:06.413250 26473 sgd_solver.cpp:106] Iteration 67900, lr = 2.62144e-05
I0502 11:21:06.418026 26473 solver.cpp:242] Iteration 67900 (105.308 iter/s, 0.949597s/100 iter), loss = 0.220488
I0502 11:21:06.418051 26473 solver.cpp:261]     Train net output #0: loss = 0.220488 (* 1 = 0.220488 loss)
I0502 11:21:06.418061 26473 sgd_solver.cpp:106] Iteration 67900, lr = 2.62144e-05
I0502 11:21:07.357723 26473 solver.cpp:362] Iteration 68000, Testing net (#0)
I0502 11:21:07.357762 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:07.481977 26473 solver.cpp:429]     Test net output #0: loss = 0.276843 (* 1 = 0.276843 loss)
I0502 11:21:07.484858 26473 solver.cpp:242] Iteration 68000 (93.3185 iter/s, 1.0716s/100 iter), loss = 1.11639
I0502 11:21:07.484889 26473 solver.cpp:261]     Train net output #0: loss = 1.11639 (* 1 = 1.11639 loss)
I0502 11:21:07.484897 26473 sgd_solver.cpp:106] Iteration 68000, lr = 2.62144e-05
I0502 11:21:07.486539 26473 solver.cpp:362] Iteration 68000, Testing net (#0)
I0502 11:21:07.486552 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:07.616948 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9385
I0502 11:21:07.616971 26473 solver.cpp:429]     Test net output #1: loss = 0.127742 (* 1 = 0.127742 loss)
I0502 11:21:07.619897 26473 solver.cpp:242] Iteration 68000 (83.2068 iter/s, 1.20182s/100 iter), loss = 0.117124
I0502 11:21:07.619917 26473 solver.cpp:261]     Train net output #0: loss = 0.117124 (* 1 = 0.117124 loss)
I0502 11:21:07.619935 26473 sgd_solver.cpp:106] Iteration 68000, lr = 2.62144e-05
I0502 11:21:08.562219 26473 solver.cpp:242] Iteration 68100 (92.8245 iter/s, 1.0773s/100 iter), loss = 0.24866
I0502 11:21:08.562261 26473 solver.cpp:261]     Train net output #0: loss = 0.24866 (* 1 = 0.24866 loss)
I0502 11:21:08.562270 26473 sgd_solver.cpp:106] Iteration 68100, lr = 2.62144e-05
I0502 11:21:08.567034 26473 solver.cpp:242] Iteration 68100 (105.586 iter/s, 0.947099s/100 iter), loss = 0.0357333
I0502 11:21:08.567057 26473 solver.cpp:261]     Train net output #0: loss = 0.0357333 (* 1 = 0.0357333 loss)
I0502 11:21:08.567066 26473 sgd_solver.cpp:106] Iteration 68100, lr = 2.62144e-05
I0502 11:21:09.509161 26473 solver.cpp:242] Iteration 68200 (105.611 iter/s, 0.946873s/100 iter), loss = 1.25673
I0502 11:21:09.509203 26473 solver.cpp:261]     Train net output #0: loss = 1.25673 (* 1 = 1.25673 loss)
I0502 11:21:09.509212 26473 sgd_solver.cpp:106] Iteration 68200, lr = 2.62144e-05
I0502 11:21:09.514050 26473 solver.cpp:242] Iteration 68200 (105.6 iter/s, 0.946967s/100 iter), loss = 0.30125
I0502 11:21:09.514073 26473 solver.cpp:261]     Train net output #0: loss = 0.30125 (* 1 = 0.30125 loss)
I0502 11:21:09.514082 26473 sgd_solver.cpp:106] Iteration 68200, lr = 2.62144e-05
I0502 11:21:10.456271 26473 solver.cpp:242] Iteration 68300 (105.593 iter/s, 0.947036s/100 iter), loss = 0.130385
I0502 11:21:10.456313 26473 solver.cpp:261]     Train net output #0: loss = 0.130385 (* 1 = 0.130385 loss)
I0502 11:21:10.456322 26473 sgd_solver.cpp:106] Iteration 68300, lr = 2.62144e-05
I0502 11:21:10.461093 26473 solver.cpp:242] Iteration 68300 (105.596 iter/s, 0.947001s/100 iter), loss = 0.0714187
I0502 11:21:10.461117 26473 solver.cpp:261]     Train net output #0: loss = 0.0714187 (* 1 = 0.0714187 loss)
I0502 11:21:10.461125 26473 sgd_solver.cpp:106] Iteration 68300, lr = 2.62144e-05
I0502 11:21:11.402974 26473 solver.cpp:242] Iteration 68400 (105.638 iter/s, 0.946634s/100 iter), loss = 0.0833021
I0502 11:21:11.403015 26473 solver.cpp:261]     Train net output #0: loss = 0.0833021 (* 1 = 0.0833021 loss)
I0502 11:21:11.403024 26473 sgd_solver.cpp:106] Iteration 68400, lr = 2.62144e-05
I0502 11:21:11.407800 26473 solver.cpp:242] Iteration 68400 (105.634 iter/s, 0.946666s/100 iter), loss = 0.0364807
I0502 11:21:11.407824 26473 solver.cpp:261]     Train net output #0: loss = 0.0364807 (* 1 = 0.0364807 loss)
I0502 11:21:11.407832 26473 sgd_solver.cpp:106] Iteration 68400, lr = 2.62144e-05
I0502 11:21:12.348119 26473 solver.cpp:362] Iteration 68500, Testing net (#0)
I0502 11:21:12.348145 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:12.472316 26473 solver.cpp:429]     Test net output #0: loss = 0.347341 (* 1 = 0.347341 loss)
I0502 11:21:12.475188 26473 solver.cpp:242] Iteration 68500 (93.2702 iter/s, 1.07215s/100 iter), loss = 0.246822
I0502 11:21:12.475208 26473 solver.cpp:261]     Train net output #0: loss = 0.246822 (* 1 = 0.246822 loss)
I0502 11:21:12.475216 26473 sgd_solver.cpp:106] Iteration 68500, lr = 2.62144e-05
I0502 11:21:12.476861 26473 solver.cpp:362] Iteration 68500, Testing net (#0)
I0502 11:21:12.476874 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:12.607301 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9535
I0502 11:21:12.607336 26473 solver.cpp:429]     Test net output #1: loss = 0.106703 (* 1 = 0.106703 loss)
I0502 11:21:12.610286 26473 solver.cpp:242] Iteration 68500 (83.1641 iter/s, 1.20244s/100 iter), loss = 0.075571
I0502 11:21:12.610309 26473 solver.cpp:261]     Train net output #0: loss = 0.075571 (* 1 = 0.075571 loss)
I0502 11:21:12.610318 26473 sgd_solver.cpp:106] Iteration 68500, lr = 2.62144e-05
I0502 11:21:13.552160 26473 solver.cpp:242] Iteration 68600 (92.8572 iter/s, 1.07692s/100 iter), loss = 0.503296
I0502 11:21:13.552202 26473 solver.cpp:261]     Train net output #0: loss = 0.503296 (* 1 = 0.503296 loss)
I0502 11:21:13.552211 26473 sgd_solver.cpp:106] Iteration 68600, lr = 2.62144e-05
I0502 11:21:13.556990 26473 solver.cpp:242] Iteration 68600 (105.634 iter/s, 0.946662s/100 iter), loss = 0.233102
I0502 11:21:13.557021 26473 solver.cpp:261]     Train net output #0: loss = 0.233102 (* 1 = 0.233102 loss)
I0502 11:21:13.557031 26473 sgd_solver.cpp:106] Iteration 68600, lr = 2.62144e-05
I0502 11:21:14.519860 26473 solver.cpp:242] Iteration 68700 (103.345 iter/s, 0.967632s/100 iter), loss = 0.234353
I0502 11:21:14.519901 26473 solver.cpp:261]     Train net output #0: loss = 0.234353 (* 1 = 0.234353 loss)
I0502 11:21:14.519909 26473 sgd_solver.cpp:106] Iteration 68700, lr = 2.62144e-05
I0502 11:21:14.524749 26473 solver.cpp:242] Iteration 68700 (103.338 iter/s, 0.967701s/100 iter), loss = 0.043567
I0502 11:21:14.524773 26473 solver.cpp:261]     Train net output #0: loss = 0.043567 (* 1 = 0.043567 loss)
I0502 11:21:14.524782 26473 sgd_solver.cpp:106] Iteration 68700, lr = 2.62144e-05
I0502 11:21:15.467265 26473 solver.cpp:242] Iteration 68800 (105.559 iter/s, 0.947335s/100 iter), loss = 0.128561
I0502 11:21:15.467303 26473 solver.cpp:261]     Train net output #0: loss = 0.128561 (* 1 = 0.128561 loss)
I0502 11:21:15.467310 26473 sgd_solver.cpp:106] Iteration 68800, lr = 2.62144e-05
I0502 11:21:15.472126 26473 solver.cpp:242] Iteration 68800 (105.559 iter/s, 0.947334s/100 iter), loss = 0.107154
I0502 11:21:15.472148 26473 solver.cpp:261]     Train net output #0: loss = 0.107154 (* 1 = 0.107154 loss)
I0502 11:21:15.472157 26473 sgd_solver.cpp:106] Iteration 68800, lr = 2.62144e-05
I0502 11:21:16.417596 26473 solver.cpp:242] Iteration 68900 (105.234 iter/s, 0.950264s/100 iter), loss = 0.194198
I0502 11:21:16.417636 26473 solver.cpp:261]     Train net output #0: loss = 0.194198 (* 1 = 0.194198 loss)
I0502 11:21:16.417646 26473 sgd_solver.cpp:106] Iteration 68900, lr = 2.62144e-05
I0502 11:21:16.422412 26473 solver.cpp:242] Iteration 68900 (105.236 iter/s, 0.950245s/100 iter), loss = 0.212937
I0502 11:21:16.422435 26473 solver.cpp:261]     Train net output #0: loss = 0.212937 (* 1 = 0.212937 loss)
I0502 11:21:16.422443 26473 sgd_solver.cpp:106] Iteration 68900, lr = 2.62144e-05
I0502 11:21:17.361212 26473 solver.cpp:362] Iteration 69000, Testing net (#0)
I0502 11:21:17.361233 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:17.485661 26473 solver.cpp:429]     Test net output #0: loss = 0.259171 (* 1 = 0.259171 loss)
I0502 11:21:17.488526 26473 solver.cpp:242] Iteration 69000 (93.3819 iter/s, 1.07087s/100 iter), loss = 0.520273
I0502 11:21:17.488545 26473 solver.cpp:261]     Train net output #0: loss = 0.520273 (* 1 = 0.520273 loss)
I0502 11:21:17.488559 26473 sgd_solver.cpp:106] Iteration 69000, lr = 2.62144e-05
I0502 11:21:17.490245 26473 solver.cpp:362] Iteration 69000, Testing net (#0)
I0502 11:21:17.490258 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:17.620862 26473 solver.cpp:429]     Test net output #0: accuracy = 0.94
I0502 11:21:17.620899 26473 solver.cpp:429]     Test net output #1: loss = 0.12519 (* 1 = 0.12519 loss)
I0502 11:21:17.623837 26473 solver.cpp:242] Iteration 69000 (83.2376 iter/s, 1.20138s/100 iter), loss = 0.213487
I0502 11:21:17.623858 26473 solver.cpp:261]     Train net output #0: loss = 0.213487 (* 1 = 0.213487 loss)
I0502 11:21:17.623867 26473 sgd_solver.cpp:106] Iteration 69000, lr = 2.62144e-05
I0502 11:21:18.567538 26473 solver.cpp:242] Iteration 69100 (92.6815 iter/s, 1.07896s/100 iter), loss = 0.0932118
I0502 11:21:18.567579 26473 solver.cpp:261]     Train net output #0: loss = 0.0932118 (* 1 = 0.0932118 loss)
I0502 11:21:18.567589 26473 sgd_solver.cpp:106] Iteration 69100, lr = 2.62144e-05
I0502 11:21:18.572369 26473 solver.cpp:242] Iteration 69100 (105.43 iter/s, 0.948492s/100 iter), loss = 0.0952946
I0502 11:21:18.572393 26473 solver.cpp:261]     Train net output #0: loss = 0.0952946 (* 1 = 0.0952946 loss)
I0502 11:21:18.572402 26473 sgd_solver.cpp:106] Iteration 69100, lr = 2.62144e-05
I0502 11:21:19.514482 26473 solver.cpp:242] Iteration 69200 (105.61 iter/s, 0.946878s/100 iter), loss = 0.412577
I0502 11:21:19.514513 26473 solver.cpp:261]     Train net output #0: loss = 0.412577 (* 1 = 0.412577 loss)
I0502 11:21:19.514530 26473 sgd_solver.cpp:106] Iteration 69200, lr = 2.62144e-05
I0502 11:21:19.519384 26473 solver.cpp:242] Iteration 69200 (105.601 iter/s, 0.946965s/100 iter), loss = 0.0158665
I0502 11:21:19.519408 26473 solver.cpp:261]     Train net output #0: loss = 0.0158665 (* 1 = 0.0158665 loss)
I0502 11:21:19.519418 26473 sgd_solver.cpp:106] Iteration 69200, lr = 2.62144e-05
I0502 11:21:20.462270 26473 solver.cpp:242] Iteration 69300 (105.516 iter/s, 0.947722s/100 iter), loss = 0.282183
I0502 11:21:20.462314 26473 solver.cpp:261]     Train net output #0: loss = 0.282183 (* 1 = 0.282183 loss)
I0502 11:21:20.462323 26473 sgd_solver.cpp:106] Iteration 69300, lr = 2.62144e-05
I0502 11:21:20.467180 26473 solver.cpp:242] Iteration 69300 (105.513 iter/s, 0.947754s/100 iter), loss = 0.0963532
I0502 11:21:20.467203 26473 solver.cpp:261]     Train net output #0: loss = 0.0963532 (* 1 = 0.0963532 loss)
I0502 11:21:20.467212 26473 sgd_solver.cpp:106] Iteration 69300, lr = 2.62144e-05
I0502 11:21:21.409677 26473 solver.cpp:242] Iteration 69400 (105.559 iter/s, 0.947333s/100 iter), loss = 0.0394113
I0502 11:21:21.409718 26473 solver.cpp:261]     Train net output #0: loss = 0.0394113 (* 1 = 0.0394113 loss)
I0502 11:21:21.409728 26473 sgd_solver.cpp:106] Iteration 69400, lr = 2.62144e-05
I0502 11:21:21.414494 26473 solver.cpp:242] Iteration 69400 (105.566 iter/s, 0.947274s/100 iter), loss = 0.396011
I0502 11:21:21.414517 26473 solver.cpp:261]     Train net output #0: loss = 0.396011 (* 1 = 0.396011 loss)
I0502 11:21:21.414525 26473 sgd_solver.cpp:106] Iteration 69400, lr = 2.62144e-05
I0502 11:21:22.354329 26473 solver.cpp:362] Iteration 69500, Testing net (#0)
I0502 11:21:22.354357 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:22.478556 26473 solver.cpp:429]     Test net output #0: loss = 0.304325 (* 1 = 0.304325 loss)
I0502 11:21:22.481422 26473 solver.cpp:242] Iteration 69500 (93.3109 iter/s, 1.07169s/100 iter), loss = 0.083657
I0502 11:21:22.481442 26473 solver.cpp:261]     Train net output #0: loss = 0.083657 (* 1 = 0.083657 loss)
I0502 11:21:22.481451 26473 sgd_solver.cpp:106] Iteration 69500, lr = 2.62144e-05
I0502 11:21:22.483093 26473 solver.cpp:362] Iteration 69500, Testing net (#0)
I0502 11:21:22.483106 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:22.613695 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9575
I0502 11:21:22.613716 26473 solver.cpp:429]     Test net output #1: loss = 0.117136 (* 1 = 0.117136 loss)
I0502 11:21:22.616654 26473 solver.cpp:242] Iteration 69500 (83.1866 iter/s, 1.20212s/100 iter), loss = 0.124872
I0502 11:21:22.616675 26473 solver.cpp:261]     Train net output #0: loss = 0.124872 (* 1 = 0.124872 loss)
I0502 11:21:22.616683 26473 sgd_solver.cpp:106] Iteration 69500, lr = 2.62144e-05
I0502 11:21:23.559630 26473 solver.cpp:242] Iteration 69600 (92.7515 iter/s, 1.07815s/100 iter), loss = 0.60699
I0502 11:21:23.559664 26473 solver.cpp:261]     Train net output #0: loss = 0.60699 (* 1 = 0.60699 loss)
I0502 11:21:23.559674 26473 sgd_solver.cpp:106] Iteration 69600, lr = 2.62144e-05
I0502 11:21:23.564507 26473 solver.cpp:242] Iteration 69600 (105.506 iter/s, 0.947813s/100 iter), loss = 0.277216
I0502 11:21:23.564530 26473 solver.cpp:261]     Train net output #0: loss = 0.277216 (* 1 = 0.277216 loss)
I0502 11:21:23.564538 26473 sgd_solver.cpp:106] Iteration 69600, lr = 2.62144e-05
I0502 11:21:24.507069 26473 solver.cpp:242] Iteration 69700 (105.554 iter/s, 0.947379s/100 iter), loss = 0.45903
I0502 11:21:24.507104 26473 solver.cpp:261]     Train net output #0: loss = 0.45903 (* 1 = 0.45903 loss)
I0502 11:21:24.507112 26473 sgd_solver.cpp:106] Iteration 69700, lr = 2.62144e-05
I0502 11:21:24.511996 26473 solver.cpp:242] Iteration 69700 (105.548 iter/s, 0.947438s/100 iter), loss = 0.161245
I0502 11:21:24.512017 26473 solver.cpp:261]     Train net output #0: loss = 0.161245 (* 1 = 0.161245 loss)
I0502 11:21:24.512027 26473 sgd_solver.cpp:106] Iteration 69700, lr = 2.62144e-05
I0502 11:21:25.453554 26473 solver.cpp:242] Iteration 69800 (105.662 iter/s, 0.946418s/100 iter), loss = 0.293354
I0502 11:21:25.453605 26473 solver.cpp:261]     Train net output #0: loss = 0.293354 (* 1 = 0.293354 loss)
I0502 11:21:25.453614 26473 sgd_solver.cpp:106] Iteration 69800, lr = 2.62144e-05
I0502 11:21:25.458374 26473 solver.cpp:242] Iteration 69800 (105.67 iter/s, 0.946339s/100 iter), loss = 0.112686
I0502 11:21:25.458397 26473 solver.cpp:261]     Train net output #0: loss = 0.112686 (* 1 = 0.112686 loss)
I0502 11:21:25.458406 26473 sgd_solver.cpp:106] Iteration 69800, lr = 2.62144e-05
I0502 11:21:26.403733 26473 solver.cpp:242] Iteration 69900 (105.252 iter/s, 0.950098s/100 iter), loss = 0.191746
I0502 11:21:26.403776 26473 solver.cpp:261]     Train net output #0: loss = 0.191746 (* 1 = 0.191746 loss)
I0502 11:21:26.403785 26473 sgd_solver.cpp:106] Iteration 69900, lr = 2.62144e-05
I0502 11:21:26.408617 26473 solver.cpp:242] Iteration 69900 (105.241 iter/s, 0.950201s/100 iter), loss = 0.0951105
I0502 11:21:26.408641 26473 solver.cpp:261]     Train net output #0: loss = 0.0951105 (* 1 = 0.0951105 loss)
I0502 11:21:26.408650 26473 sgd_solver.cpp:106] Iteration 69900, lr = 2.62144e-05
I0502 11:21:27.347506 26473 solver.cpp:362] Iteration 70000, Testing net (#0)
I0502 11:21:27.347533 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:27.471814 26473 solver.cpp:429]     Test net output #0: loss = 0.255427 (* 1 = 0.255427 loss)
I0502 11:21:27.474709 26473 solver.cpp:242] Iteration 70000 (93.378 iter/s, 1.07092s/100 iter), loss = 0.166407
I0502 11:21:27.474730 26473 solver.cpp:261]     Train net output #0: loss = 0.166407 (* 1 = 0.166407 loss)
I0502 11:21:27.474737 26473 sgd_solver.cpp:106] Iteration 70000, lr = 2.09715e-05
I0502 11:21:27.476387 26473 solver.cpp:362] Iteration 70000, Testing net (#0)
I0502 11:21:27.476400 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:27.606906 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9555
I0502 11:21:27.606927 26473 solver.cpp:429]     Test net output #1: loss = 0.106744 (* 1 = 0.106744 loss)
I0502 11:21:27.609861 26473 solver.cpp:242] Iteration 70000 (83.2502 iter/s, 1.2012s/100 iter), loss = 0.158289
I0502 11:21:27.609882 26473 solver.cpp:261]     Train net output #0: loss = 0.158289 (* 1 = 0.158289 loss)
I0502 11:21:27.609890 26473 sgd_solver.cpp:106] Iteration 70000, lr = 2.09715e-05
I0502 11:21:28.552819 26473 solver.cpp:242] Iteration 70100 (92.7595 iter/s, 1.07806s/100 iter), loss = 0.226573
I0502 11:21:28.552872 26473 solver.cpp:261]     Train net output #0: loss = 0.226573 (* 1 = 0.226573 loss)
I0502 11:21:28.552881 26473 sgd_solver.cpp:106] Iteration 70100, lr = 2.09715e-05
I0502 11:21:28.557687 26473 solver.cpp:242] Iteration 70100 (105.509 iter/s, 0.947785s/100 iter), loss = 0.0973907
I0502 11:21:28.557710 26473 solver.cpp:261]     Train net output #0: loss = 0.0973907 (* 1 = 0.0973907 loss)
I0502 11:21:28.557718 26473 sgd_solver.cpp:106] Iteration 70100, lr = 2.09715e-05
I0502 11:21:29.499732 26473 solver.cpp:242] Iteration 70200 (105.615 iter/s, 0.946833s/100 iter), loss = 0.207019
I0502 11:21:29.499774 26473 solver.cpp:261]     Train net output #0: loss = 0.207019 (* 1 = 0.207019 loss)
I0502 11:21:29.499783 26473 sgd_solver.cpp:106] Iteration 70200, lr = 2.09715e-05
I0502 11:21:29.504638 26473 solver.cpp:242] Iteration 70200 (105.608 iter/s, 0.946901s/100 iter), loss = 0.0223595
I0502 11:21:29.504662 26473 solver.cpp:261]     Train net output #0: loss = 0.0223595 (* 1 = 0.0223595 loss)
I0502 11:21:29.504672 26473 sgd_solver.cpp:106] Iteration 70200, lr = 2.09715e-05
I0502 11:21:30.447531 26473 solver.cpp:242] Iteration 70300 (105.515 iter/s, 0.947733s/100 iter), loss = 0.2227
I0502 11:21:30.447572 26473 solver.cpp:261]     Train net output #0: loss = 0.2227 (* 1 = 0.2227 loss)
I0502 11:21:30.447580 26473 sgd_solver.cpp:106] Iteration 70300, lr = 2.09715e-05
I0502 11:21:30.452406 26473 solver.cpp:242] Iteration 70300 (105.516 iter/s, 0.94772s/100 iter), loss = 0.0229008
I0502 11:21:30.452430 26473 solver.cpp:261]     Train net output #0: loss = 0.0229008 (* 1 = 0.0229008 loss)
I0502 11:21:30.452447 26473 sgd_solver.cpp:106] Iteration 70300, lr = 2.09715e-05
I0502 11:21:31.394840 26473 solver.cpp:242] Iteration 70400 (105.57 iter/s, 0.947239s/100 iter), loss = 2.10362
I0502 11:21:31.394878 26473 solver.cpp:261]     Train net output #0: loss = 2.10362 (* 1 = 2.10362 loss)
I0502 11:21:31.394887 26473 sgd_solver.cpp:106] Iteration 70400, lr = 2.09715e-05
I0502 11:21:31.399667 26473 solver.cpp:242] Iteration 70400 (105.572 iter/s, 0.947217s/100 iter), loss = 0.130601
I0502 11:21:31.399689 26473 solver.cpp:261]     Train net output #0: loss = 0.130601 (* 1 = 0.130601 loss)
I0502 11:21:31.399698 26473 sgd_solver.cpp:106] Iteration 70400, lr = 2.09715e-05
I0502 11:21:32.339737 26473 solver.cpp:362] Iteration 70500, Testing net (#0)
I0502 11:21:32.339766 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:32.464015 26473 solver.cpp:429]     Test net output #0: loss = 0.302052 (* 1 = 0.302052 loss)
I0502 11:21:32.466913 26473 solver.cpp:242] Iteration 70500 (93.2822 iter/s, 1.07202s/100 iter), loss = 0.0786199
I0502 11:21:32.466933 26473 solver.cpp:261]     Train net output #0: loss = 0.0786199 (* 1 = 0.0786199 loss)
I0502 11:21:32.466941 26473 sgd_solver.cpp:106] Iteration 70500, lr = 2.09715e-05
I0502 11:21:32.468591 26473 solver.cpp:362] Iteration 70500, Testing net (#0)
I0502 11:21:32.468605 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:32.599057 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9445
I0502 11:21:32.599078 26473 solver.cpp:429]     Test net output #1: loss = 0.112007 (* 1 = 0.112007 loss)
I0502 11:21:32.602005 26473 solver.cpp:242] Iteration 70500 (83.1743 iter/s, 1.20229s/100 iter), loss = 0.0948508
I0502 11:21:32.602025 26473 solver.cpp:261]     Train net output #0: loss = 0.0948508 (* 1 = 0.0948508 loss)
I0502 11:21:32.602033 26473 sgd_solver.cpp:106] Iteration 70500, lr = 2.09715e-05
I0502 11:21:33.544973 26473 solver.cpp:242] Iteration 70600 (92.7635 iter/s, 1.07801s/100 iter), loss = 0.10267
I0502 11:21:33.545012 26473 solver.cpp:261]     Train net output #0: loss = 0.10267 (* 1 = 0.10267 loss)
I0502 11:21:33.545020 26473 sgd_solver.cpp:106] Iteration 70600, lr = 2.09715e-05
I0502 11:21:33.549798 26473 solver.cpp:242] Iteration 70600 (105.513 iter/s, 0.947753s/100 iter), loss = 0.0457383
I0502 11:21:33.549821 26473 solver.cpp:261]     Train net output #0: loss = 0.0457383 (* 1 = 0.0457383 loss)
I0502 11:21:33.549830 26473 sgd_solver.cpp:106] Iteration 70600, lr = 2.09715e-05
I0502 11:21:34.493242 26473 solver.cpp:242] Iteration 70700 (105.463 iter/s, 0.948202s/100 iter), loss = 0.2529
I0502 11:21:34.493281 26473 solver.cpp:261]     Train net output #0: loss = 0.2529 (* 1 = 0.2529 loss)
I0502 11:21:34.493290 26473 sgd_solver.cpp:106] Iteration 70700, lr = 2.09715e-05
I0502 11:21:34.498064 26473 solver.cpp:242] Iteration 70700 (105.46 iter/s, 0.948224s/100 iter), loss = 0.0341792
I0502 11:21:34.498087 26473 solver.cpp:261]     Train net output #0: loss = 0.0341792 (* 1 = 0.0341792 loss)
I0502 11:21:34.498096 26473 sgd_solver.cpp:106] Iteration 70700, lr = 2.09715e-05
I0502 11:21:35.441113 26473 solver.cpp:242] Iteration 70800 (105.506 iter/s, 0.947809s/100 iter), loss = 0.584222
I0502 11:21:35.441148 26473 solver.cpp:261]     Train net output #0: loss = 0.584222 (* 1 = 0.584222 loss)
I0502 11:21:35.441156 26473 sgd_solver.cpp:106] Iteration 70800, lr = 2.09715e-05
I0502 11:21:35.445987 26473 solver.cpp:242] Iteration 70800 (105.499 iter/s, 0.947875s/100 iter), loss = 0.090852
I0502 11:21:35.446010 26473 solver.cpp:261]     Train net output #0: loss = 0.090852 (* 1 = 0.090852 loss)
I0502 11:21:35.446019 26473 sgd_solver.cpp:106] Iteration 70800, lr = 2.09715e-05
I0502 11:21:36.390269 26473 solver.cpp:242] Iteration 70900 (105.365 iter/s, 0.949086s/100 iter), loss = 0.458475
I0502 11:21:36.390310 26473 solver.cpp:261]     Train net output #0: loss = 0.458475 (* 1 = 0.458475 loss)
I0502 11:21:36.390318 26473 sgd_solver.cpp:106] Iteration 70900, lr = 2.09715e-05
I0502 11:21:36.395109 26473 solver.cpp:242] Iteration 70900 (105.365 iter/s, 0.949081s/100 iter), loss = 0.181997
I0502 11:21:36.395141 26473 solver.cpp:261]     Train net output #0: loss = 0.181997 (* 1 = 0.181997 loss)
I0502 11:21:36.395150 26473 sgd_solver.cpp:106] Iteration 70900, lr = 2.09715e-05
I0502 11:21:37.334273 26473 solver.cpp:362] Iteration 71000, Testing net (#0)
I0502 11:21:37.334291 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:37.458611 26473 solver.cpp:429]     Test net output #0: loss = 0.269064 (* 1 = 0.269064 loss)
I0502 11:21:37.461475 26473 solver.cpp:242] Iteration 71000 (93.3579 iter/s, 1.07115s/100 iter), loss = 0.520998
I0502 11:21:37.461495 26473 solver.cpp:261]     Train net output #0: loss = 0.520998 (* 1 = 0.520998 loss)
I0502 11:21:37.461503 26473 sgd_solver.cpp:106] Iteration 71000, lr = 2.09715e-05
I0502 11:21:37.463150 26473 solver.cpp:362] Iteration 71000, Testing net (#0)
I0502 11:21:37.463162 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:37.593809 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9515
I0502 11:21:37.593832 26473 solver.cpp:429]     Test net output #1: loss = 0.11597 (* 1 = 0.11597 loss)
I0502 11:21:37.596763 26473 solver.cpp:242] Iteration 71000 (83.2223 iter/s, 1.2016s/100 iter), loss = 0.0866103
I0502 11:21:37.596784 26473 solver.cpp:261]     Train net output #0: loss = 0.0866103 (* 1 = 0.0866103 loss)
I0502 11:21:37.596793 26473 sgd_solver.cpp:106] Iteration 71000, lr = 2.09715e-05
I0502 11:21:38.540307 26473 solver.cpp:242] Iteration 71100 (92.6972 iter/s, 1.07878s/100 iter), loss = 0.232649
I0502 11:21:38.540346 26473 solver.cpp:261]     Train net output #0: loss = 0.232649 (* 1 = 0.232649 loss)
I0502 11:21:38.540355 26473 sgd_solver.cpp:106] Iteration 71100, lr = 2.09715e-05
I0502 11:21:38.545152 26473 solver.cpp:242] Iteration 71100 (105.446 iter/s, 0.94835s/100 iter), loss = 0.141699
I0502 11:21:38.545176 26473 solver.cpp:261]     Train net output #0: loss = 0.141699 (* 1 = 0.141699 loss)
I0502 11:21:38.545184 26473 sgd_solver.cpp:106] Iteration 71100, lr = 2.09715e-05
I0502 11:21:39.488005 26473 solver.cpp:242] Iteration 71200 (105.526 iter/s, 0.947633s/100 iter), loss = 0.193771
I0502 11:21:39.488039 26473 solver.cpp:261]     Train net output #0: loss = 0.193771 (* 1 = 0.193771 loss)
I0502 11:21:39.488049 26473 sgd_solver.cpp:106] Iteration 71200, lr = 2.09715e-05
I0502 11:21:39.492830 26473 solver.cpp:242] Iteration 71200 (105.526 iter/s, 0.947635s/100 iter), loss = 0.163049
I0502 11:21:39.492853 26473 solver.cpp:261]     Train net output #0: loss = 0.163049 (* 1 = 0.163049 loss)
I0502 11:21:39.492861 26473 sgd_solver.cpp:106] Iteration 71200, lr = 2.09715e-05
I0502 11:21:40.434738 26473 solver.cpp:242] Iteration 71300 (105.633 iter/s, 0.946674s/100 iter), loss = 0.419508
I0502 11:21:40.434774 26473 solver.cpp:261]     Train net output #0: loss = 0.419508 (* 1 = 0.419508 loss)
I0502 11:21:40.434784 26473 sgd_solver.cpp:106] Iteration 71300, lr = 2.09715e-05
I0502 11:21:40.439626 26473 solver.cpp:242] Iteration 71300 (105.625 iter/s, 0.946746s/100 iter), loss = 0.146766
I0502 11:21:40.439649 26473 solver.cpp:261]     Train net output #0: loss = 0.146766 (* 1 = 0.146766 loss)
I0502 11:21:40.439658 26473 sgd_solver.cpp:106] Iteration 71300, lr = 2.09715e-05
I0502 11:21:41.381685 26473 solver.cpp:242] Iteration 71400 (105.61 iter/s, 0.946879s/100 iter), loss = 0.108082
I0502 11:21:41.381729 26473 solver.cpp:261]     Train net output #0: loss = 0.108082 (* 1 = 0.108082 loss)
I0502 11:21:41.381738 26473 sgd_solver.cpp:106] Iteration 71400, lr = 2.09715e-05
I0502 11:21:41.386520 26473 solver.cpp:242] Iteration 71400 (105.613 iter/s, 0.946853s/100 iter), loss = 0.0858735
I0502 11:21:41.386544 26473 solver.cpp:261]     Train net output #0: loss = 0.0858735 (* 1 = 0.0858735 loss)
I0502 11:21:41.386554 26473 sgd_solver.cpp:106] Iteration 71400, lr = 2.09715e-05
I0502 11:21:42.325675 26473 solver.cpp:362] Iteration 71500, Testing net (#0)
I0502 11:21:42.325703 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:42.449838 26473 solver.cpp:429]     Test net output #0: loss = 0.318009 (* 1 = 0.318009 loss)
I0502 11:21:42.452718 26473 solver.cpp:242] Iteration 71500 (93.3733 iter/s, 1.07097s/100 iter), loss = 0.276361
I0502 11:21:42.452739 26473 solver.cpp:261]     Train net output #0: loss = 0.276361 (* 1 = 0.276361 loss)
I0502 11:21:42.452746 26473 sgd_solver.cpp:106] Iteration 71500, lr = 2.09715e-05
I0502 11:21:42.454396 26473 solver.cpp:362] Iteration 71500, Testing net (#0)
I0502 11:21:42.454409 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:42.585031 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9365
I0502 11:21:42.585054 26473 solver.cpp:429]     Test net output #1: loss = 0.135633 (* 1 = 0.135633 loss)
I0502 11:21:42.587976 26473 solver.cpp:242] Iteration 71500 (83.2355 iter/s, 1.20141s/100 iter), loss = 0.231794
I0502 11:21:42.587996 26473 solver.cpp:261]     Train net output #0: loss = 0.231794 (* 1 = 0.231794 loss)
I0502 11:21:42.588004 26473 sgd_solver.cpp:106] Iteration 71500, lr = 2.09715e-05
I0502 11:21:43.531474 26473 solver.cpp:242] Iteration 71600 (92.7038 iter/s, 1.0787s/100 iter), loss = 0.137395
I0502 11:21:43.531518 26473 solver.cpp:261]     Train net output #0: loss = 0.137395 (* 1 = 0.137395 loss)
I0502 11:21:43.531527 26473 sgd_solver.cpp:106] Iteration 71600, lr = 2.09715e-05
I0502 11:21:43.536321 26473 solver.cpp:242] Iteration 71600 (105.451 iter/s, 0.948307s/100 iter), loss = 0.0925231
I0502 11:21:43.536346 26473 solver.cpp:261]     Train net output #0: loss = 0.0925231 (* 1 = 0.0925231 loss)
I0502 11:21:43.536355 26473 sgd_solver.cpp:106] Iteration 71600, lr = 2.09715e-05
I0502 11:21:44.478807 26473 solver.cpp:242] Iteration 71700 (105.567 iter/s, 0.947262s/100 iter), loss = 0.114437
I0502 11:21:44.478850 26473 solver.cpp:261]     Train net output #0: loss = 0.114437 (* 1 = 0.114437 loss)
I0502 11:21:44.478860 26473 sgd_solver.cpp:106] Iteration 71700, lr = 2.09715e-05
I0502 11:21:44.483640 26473 solver.cpp:242] Iteration 71700 (105.566 iter/s, 0.947276s/100 iter), loss = 0.027694
I0502 11:21:44.483664 26473 solver.cpp:261]     Train net output #0: loss = 0.027694 (* 1 = 0.027694 loss)
I0502 11:21:44.483674 26473 sgd_solver.cpp:106] Iteration 71700, lr = 2.09715e-05
I0502 11:21:45.426100 26473 solver.cpp:242] Iteration 71800 (105.572 iter/s, 0.947224s/100 iter), loss = 0.177772
I0502 11:21:45.426141 26473 solver.cpp:261]     Train net output #0: loss = 0.177772 (* 1 = 0.177772 loss)
I0502 11:21:45.426151 26473 sgd_solver.cpp:106] Iteration 71800, lr = 2.09715e-05
I0502 11:21:45.430986 26473 solver.cpp:242] Iteration 71800 (105.564 iter/s, 0.947295s/100 iter), loss = 0.0466503
I0502 11:21:45.431011 26473 solver.cpp:261]     Train net output #0: loss = 0.0466503 (* 1 = 0.0466503 loss)
I0502 11:21:45.431020 26473 sgd_solver.cpp:106] Iteration 71800, lr = 2.09715e-05
I0502 11:21:46.373329 26473 solver.cpp:242] Iteration 71900 (105.579 iter/s, 0.947157s/100 iter), loss = 0.156561
I0502 11:21:46.373370 26473 solver.cpp:261]     Train net output #0: loss = 0.156561 (* 1 = 0.156561 loss)
I0502 11:21:46.373379 26473 sgd_solver.cpp:106] Iteration 71900, lr = 2.09715e-05
I0502 11:21:46.378175 26473 solver.cpp:242] Iteration 71900 (105.58 iter/s, 0.947145s/100 iter), loss = 0.184894
I0502 11:21:46.378197 26473 solver.cpp:261]     Train net output #0: loss = 0.184894 (* 1 = 0.184894 loss)
I0502 11:21:46.378206 26473 sgd_solver.cpp:106] Iteration 71900, lr = 2.09715e-05
I0502 11:21:47.317909 26473 solver.cpp:362] Iteration 72000, Testing net (#0)
I0502 11:21:47.317934 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:47.442210 26473 solver.cpp:429]     Test net output #0: loss = 0.2928 (* 1 = 0.2928 loss)
I0502 11:21:47.445091 26473 solver.cpp:242] Iteration 72000 (93.3096 iter/s, 1.0717s/100 iter), loss = 0.189587
I0502 11:21:47.445111 26473 solver.cpp:261]     Train net output #0: loss = 0.189587 (* 1 = 0.189587 loss)
I0502 11:21:47.445119 26473 sgd_solver.cpp:106] Iteration 72000, lr = 2.09715e-05
I0502 11:21:47.446763 26473 solver.cpp:362] Iteration 72000, Testing net (#0)
I0502 11:21:47.446776 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:47.577410 26473 solver.cpp:429]     Test net output #0: accuracy = 0.942
I0502 11:21:47.577438 26473 solver.cpp:429]     Test net output #1: loss = 0.127206 (* 1 = 0.127206 loss)
I0502 11:21:47.580360 26473 solver.cpp:242] Iteration 72000 (83.1849 iter/s, 1.20214s/100 iter), loss = 0.328724
I0502 11:21:47.580380 26473 solver.cpp:261]     Train net output #0: loss = 0.328724 (* 1 = 0.328724 loss)
I0502 11:21:47.580389 26473 sgd_solver.cpp:106] Iteration 72000, lr = 2.09715e-05
I0502 11:21:48.522862 26473 solver.cpp:242] Iteration 72100 (92.7886 iter/s, 1.07772s/100 iter), loss = 0.146607
I0502 11:21:48.522903 26473 solver.cpp:261]     Train net output #0: loss = 0.146607 (* 1 = 0.146607 loss)
I0502 11:21:48.522912 26473 sgd_solver.cpp:106] Iteration 72100, lr = 2.09715e-05
I0502 11:21:48.527704 26473 solver.cpp:242] Iteration 72100 (105.563 iter/s, 0.947304s/100 iter), loss = 0.221787
I0502 11:21:48.527725 26473 solver.cpp:261]     Train net output #0: loss = 0.221787 (* 1 = 0.221787 loss)
I0502 11:21:48.527734 26473 sgd_solver.cpp:106] Iteration 72100, lr = 2.09715e-05
I0502 11:21:49.469820 26473 solver.cpp:242] Iteration 72200 (105.609 iter/s, 0.946889s/100 iter), loss = 0.118865
I0502 11:21:49.469858 26473 solver.cpp:261]     Train net output #0: loss = 0.118865 (* 1 = 0.118865 loss)
I0502 11:21:49.469867 26473 sgd_solver.cpp:106] Iteration 72200, lr = 2.09715e-05
I0502 11:21:49.474633 26473 solver.cpp:242] Iteration 72200 (105.609 iter/s, 0.946889s/100 iter), loss = 0.0257015
I0502 11:21:49.474656 26473 solver.cpp:261]     Train net output #0: loss = 0.0257015 (* 1 = 0.0257015 loss)
I0502 11:21:49.474664 26473 sgd_solver.cpp:106] Iteration 72200, lr = 2.09715e-05
I0502 11:21:50.417512 26473 solver.cpp:242] Iteration 72300 (105.527 iter/s, 0.947628s/100 iter), loss = 0.206679
I0502 11:21:50.417552 26473 solver.cpp:261]     Train net output #0: loss = 0.206679 (* 1 = 0.206679 loss)
I0502 11:21:50.417560 26473 sgd_solver.cpp:106] Iteration 72300, lr = 2.09715e-05
I0502 11:21:50.422420 26473 solver.cpp:242] Iteration 72300 (105.515 iter/s, 0.947736s/100 iter), loss = 0.136975
I0502 11:21:50.422442 26473 solver.cpp:261]     Train net output #0: loss = 0.136975 (* 1 = 0.136975 loss)
I0502 11:21:50.422451 26473 sgd_solver.cpp:106] Iteration 72300, lr = 2.09715e-05
I0502 11:21:51.363991 26473 solver.cpp:242] Iteration 72400 (105.663 iter/s, 0.946407s/100 iter), loss = 0.226761
I0502 11:21:51.364023 26473 solver.cpp:261]     Train net output #0: loss = 0.226761 (* 1 = 0.226761 loss)
I0502 11:21:51.364032 26473 sgd_solver.cpp:106] Iteration 72400, lr = 2.09715e-05
I0502 11:21:51.368835 26473 solver.cpp:242] Iteration 72400 (105.667 iter/s, 0.946374s/100 iter), loss = 0.00376692
I0502 11:21:51.368860 26473 solver.cpp:261]     Train net output #0: loss = 0.00376692 (* 1 = 0.00376692 loss)
I0502 11:21:51.368868 26473 sgd_solver.cpp:106] Iteration 72400, lr = 2.09715e-05
I0502 11:21:52.308537 26473 solver.cpp:362] Iteration 72500, Testing net (#0)
I0502 11:21:52.308562 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:52.432822 26473 solver.cpp:429]     Test net output #0: loss = 0.298911 (* 1 = 0.298911 loss)
I0502 11:21:52.435685 26473 solver.cpp:242] Iteration 72500 (93.3146 iter/s, 1.07164s/100 iter), loss = 0.390501
I0502 11:21:52.435705 26473 solver.cpp:261]     Train net output #0: loss = 0.390501 (* 1 = 0.390501 loss)
I0502 11:21:52.435714 26473 sgd_solver.cpp:106] Iteration 72500, lr = 2.09715e-05
I0502 11:21:52.437366 26473 solver.cpp:362] Iteration 72500, Testing net (#0)
I0502 11:21:52.437381 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:52.568037 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9555
I0502 11:21:52.568058 26473 solver.cpp:429]     Test net output #1: loss = 0.0983473 (* 1 = 0.0983473 loss)
I0502 11:21:52.570986 26473 solver.cpp:242] Iteration 72500 (83.1874 iter/s, 1.20211s/100 iter), loss = 0.115969
I0502 11:21:52.571005 26473 solver.cpp:261]     Train net output #0: loss = 0.115969 (* 1 = 0.115969 loss)
I0502 11:21:52.571013 26473 sgd_solver.cpp:106] Iteration 72500, lr = 2.09715e-05
I0502 11:21:53.513459 26473 solver.cpp:242] Iteration 72600 (92.7882 iter/s, 1.07772s/100 iter), loss = 0.0760724
I0502 11:21:53.513496 26473 solver.cpp:261]     Train net output #0: loss = 0.0760724 (* 1 = 0.0760724 loss)
I0502 11:21:53.513505 26473 sgd_solver.cpp:106] Iteration 72600, lr = 2.09715e-05
I0502 11:21:53.518280 26473 solver.cpp:242] Iteration 72600 (105.568 iter/s, 0.947256s/100 iter), loss = 0.0893969
I0502 11:21:53.518303 26473 solver.cpp:261]     Train net output #0: loss = 0.0893969 (* 1 = 0.0893969 loss)
I0502 11:21:53.518312 26473 sgd_solver.cpp:106] Iteration 72600, lr = 2.09715e-05
I0502 11:21:54.462134 26473 solver.cpp:242] Iteration 72700 (105.417 iter/s, 0.948611s/100 iter), loss = 0.379515
I0502 11:21:54.462170 26473 solver.cpp:261]     Train net output #0: loss = 0.379515 (* 1 = 0.379515 loss)
I0502 11:21:54.462179 26473 sgd_solver.cpp:106] Iteration 72700, lr = 2.09715e-05
I0502 11:21:54.466948 26473 solver.cpp:242] Iteration 72700 (105.416 iter/s, 0.948625s/100 iter), loss = 0.24453
I0502 11:21:54.466970 26473 solver.cpp:261]     Train net output #0: loss = 0.24453 (* 1 = 0.24453 loss)
I0502 11:21:54.466979 26473 sgd_solver.cpp:106] Iteration 72700, lr = 2.09715e-05
I0502 11:21:55.408854 26473 solver.cpp:242] Iteration 72800 (105.635 iter/s, 0.94666s/100 iter), loss = 0.0748874
I0502 11:21:55.408888 26473 solver.cpp:261]     Train net output #0: loss = 0.0748874 (* 1 = 0.0748874 loss)
I0502 11:21:55.408897 26473 sgd_solver.cpp:106] Iteration 72800, lr = 2.09715e-05
I0502 11:21:55.413761 26473 solver.cpp:242] Iteration 72800 (105.623 iter/s, 0.946764s/100 iter), loss = 0.128449
I0502 11:21:55.413784 26473 solver.cpp:261]     Train net output #0: loss = 0.128449 (* 1 = 0.128449 loss)
I0502 11:21:55.413794 26473 sgd_solver.cpp:106] Iteration 72800, lr = 2.09715e-05
I0502 11:21:56.355823 26473 solver.cpp:242] Iteration 72900 (105.606 iter/s, 0.946912s/100 iter), loss = 0.277452
I0502 11:21:56.355859 26473 solver.cpp:261]     Train net output #0: loss = 0.277452 (* 1 = 0.277452 loss)
I0502 11:21:56.355868 26473 sgd_solver.cpp:106] Iteration 72900, lr = 2.09715e-05
I0502 11:21:56.360733 26473 solver.cpp:242] Iteration 72900 (105.605 iter/s, 0.946923s/100 iter), loss = 0.152692
I0502 11:21:56.360754 26473 solver.cpp:261]     Train net output #0: loss = 0.152692 (* 1 = 0.152692 loss)
I0502 11:21:56.360764 26473 sgd_solver.cpp:106] Iteration 72900, lr = 2.09715e-05
I0502 11:21:57.300395 26473 solver.cpp:362] Iteration 73000, Testing net (#0)
I0502 11:21:57.300424 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:57.424774 26473 solver.cpp:429]     Test net output #0: loss = 0.286851 (* 1 = 0.286851 loss)
I0502 11:21:57.427644 26473 solver.cpp:242] Iteration 73000 (93.304 iter/s, 1.07177s/100 iter), loss = 0.406302
I0502 11:21:57.427664 26473 solver.cpp:261]     Train net output #0: loss = 0.406302 (* 1 = 0.406302 loss)
I0502 11:21:57.427671 26473 sgd_solver.cpp:106] Iteration 73000, lr = 2.09715e-05
I0502 11:21:57.429321 26473 solver.cpp:362] Iteration 73000, Testing net (#0)
I0502 11:21:57.429334 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:21:57.559950 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:21:57.559968 26473 solver.cpp:429]     Test net output #1: loss = 0.0965578 (* 1 = 0.0965578 loss)
I0502 11:21:57.562892 26473 solver.cpp:242] Iteration 73000 (83.1866 iter/s, 1.20212s/100 iter), loss = 0.128224
I0502 11:21:57.562913 26473 solver.cpp:261]     Train net output #0: loss = 0.128224 (* 1 = 0.128224 loss)
I0502 11:21:57.562922 26473 sgd_solver.cpp:106] Iteration 73000, lr = 2.09715e-05
I0502 11:21:58.505595 26473 solver.cpp:242] Iteration 73100 (92.773 iter/s, 1.0779s/100 iter), loss = 0.140304
I0502 11:21:58.505636 26473 solver.cpp:261]     Train net output #0: loss = 0.140304 (* 1 = 0.140304 loss)
I0502 11:21:58.505645 26473 sgd_solver.cpp:106] Iteration 73100, lr = 2.09715e-05
I0502 11:21:58.510438 26473 solver.cpp:242] Iteration 73100 (105.54 iter/s, 0.947507s/100 iter), loss = 0.207579
I0502 11:21:58.510462 26473 solver.cpp:261]     Train net output #0: loss = 0.207579 (* 1 = 0.207579 loss)
I0502 11:21:58.510478 26473 sgd_solver.cpp:106] Iteration 73100, lr = 2.09715e-05
I0502 11:21:59.452880 26473 solver.cpp:242] Iteration 73200 (105.573 iter/s, 0.947215s/100 iter), loss = 0.153972
I0502 11:21:59.452924 26473 solver.cpp:261]     Train net output #0: loss = 0.153972 (* 1 = 0.153972 loss)
I0502 11:21:59.452932 26473 sgd_solver.cpp:106] Iteration 73200, lr = 2.09715e-05
I0502 11:21:59.457710 26473 solver.cpp:242] Iteration 73200 (105.571 iter/s, 0.947231s/100 iter), loss = 0.0470021
I0502 11:21:59.457733 26473 solver.cpp:261]     Train net output #0: loss = 0.0470021 (* 1 = 0.0470021 loss)
I0502 11:21:59.457741 26473 sgd_solver.cpp:106] Iteration 73200, lr = 2.09715e-05
I0502 11:22:00.411339 26473 solver.cpp:242] Iteration 73300 (104.342 iter/s, 0.958387s/100 iter), loss = 0.0579545
I0502 11:22:00.411386 26473 solver.cpp:261]     Train net output #0: loss = 0.0579545 (* 1 = 0.0579545 loss)
I0502 11:22:00.411394 26473 sgd_solver.cpp:106] Iteration 73300, lr = 2.09715e-05
I0502 11:22:00.416152 26473 solver.cpp:242] Iteration 73300 (104.341 iter/s, 0.958401s/100 iter), loss = 0.0988974
I0502 11:22:00.416177 26473 solver.cpp:261]     Train net output #0: loss = 0.0988974 (* 1 = 0.0988974 loss)
I0502 11:22:00.416187 26473 sgd_solver.cpp:106] Iteration 73300, lr = 2.09715e-05
I0502 11:22:01.357743 26473 solver.cpp:242] Iteration 73400 (105.671 iter/s, 0.946333s/100 iter), loss = 0.263485
I0502 11:22:01.357795 26473 solver.cpp:261]     Train net output #0: loss = 0.263485 (* 1 = 0.263485 loss)
I0502 11:22:01.357805 26473 sgd_solver.cpp:106] Iteration 73400, lr = 2.09715e-05
I0502 11:22:01.362658 26473 solver.cpp:242] Iteration 73400 (105.657 iter/s, 0.946455s/100 iter), loss = 0.10635
I0502 11:22:01.362684 26473 solver.cpp:261]     Train net output #0: loss = 0.10635 (* 1 = 0.10635 loss)
I0502 11:22:01.362691 26473 sgd_solver.cpp:106] Iteration 73400, lr = 2.09715e-05
I0502 11:22:02.302675 26473 solver.cpp:362] Iteration 73500, Testing net (#0)
I0502 11:22:02.302700 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:02.426903 26473 solver.cpp:429]     Test net output #0: loss = 0.369888 (* 1 = 0.369888 loss)
I0502 11:22:02.429787 26473 solver.cpp:242] Iteration 73500 (93.2858 iter/s, 1.07197s/100 iter), loss = 0.310852
I0502 11:22:02.429808 26473 solver.cpp:261]     Train net output #0: loss = 0.310852 (* 1 = 0.310852 loss)
I0502 11:22:02.429816 26473 sgd_solver.cpp:106] Iteration 73500, lr = 2.09715e-05
I0502 11:22:02.431457 26473 solver.cpp:362] Iteration 73500, Testing net (#0)
I0502 11:22:02.431469 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:02.561825 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9335
I0502 11:22:02.561846 26473 solver.cpp:429]     Test net output #1: loss = 0.130172 (* 1 = 0.130172 loss)
I0502 11:22:02.564793 26473 solver.cpp:242] Iteration 73500 (83.1885 iter/s, 1.20209s/100 iter), loss = 0.146139
I0502 11:22:02.564813 26473 solver.cpp:261]     Train net output #0: loss = 0.146139 (* 1 = 0.146139 loss)
I0502 11:22:02.564821 26473 sgd_solver.cpp:106] Iteration 73500, lr = 2.09715e-05
I0502 11:22:03.507519 26473 solver.cpp:242] Iteration 73600 (92.7921 iter/s, 1.07768s/100 iter), loss = 0.313457
I0502 11:22:03.507558 26473 solver.cpp:261]     Train net output #0: loss = 0.313457 (* 1 = 0.313457 loss)
I0502 11:22:03.507567 26473 sgd_solver.cpp:106] Iteration 73600, lr = 2.09715e-05
I0502 11:22:03.512328 26473 solver.cpp:242] Iteration 73600 (105.541 iter/s, 0.947496s/100 iter), loss = 0.0641081
I0502 11:22:03.512351 26473 solver.cpp:261]     Train net output #0: loss = 0.0641081 (* 1 = 0.0641081 loss)
I0502 11:22:03.512361 26473 sgd_solver.cpp:106] Iteration 73600, lr = 2.09715e-05
I0502 11:22:04.453891 26473 solver.cpp:242] Iteration 73700 (105.674 iter/s, 0.946305s/100 iter), loss = 0.978058
I0502 11:22:04.453930 26473 solver.cpp:261]     Train net output #0: loss = 0.978058 (* 1 = 0.978058 loss)
I0502 11:22:04.453939 26473 sgd_solver.cpp:106] Iteration 73700, lr = 2.09715e-05
I0502 11:22:04.458720 26473 solver.cpp:242] Iteration 73700 (105.669 iter/s, 0.946351s/100 iter), loss = 0.191597
I0502 11:22:04.458745 26473 solver.cpp:261]     Train net output #0: loss = 0.191597 (* 1 = 0.191597 loss)
I0502 11:22:04.458753 26473 sgd_solver.cpp:106] Iteration 73700, lr = 2.09715e-05
I0502 11:22:05.400749 26473 solver.cpp:242] Iteration 73800 (105.62 iter/s, 0.946793s/100 iter), loss = 0.0572694
I0502 11:22:05.400789 26473 solver.cpp:261]     Train net output #0: loss = 0.0572694 (* 1 = 0.0572694 loss)
I0502 11:22:05.400797 26473 sgd_solver.cpp:106] Iteration 73800, lr = 2.09715e-05
I0502 11:22:05.405572 26473 solver.cpp:242] Iteration 73800 (105.618 iter/s, 0.94681s/100 iter), loss = 0.124996
I0502 11:22:05.405596 26473 solver.cpp:261]     Train net output #0: loss = 0.124996 (* 1 = 0.124996 loss)
I0502 11:22:05.405603 26473 sgd_solver.cpp:106] Iteration 73800, lr = 2.09715e-05
I0502 11:22:06.349243 26473 solver.cpp:242] Iteration 73900 (105.438 iter/s, 0.948428s/100 iter), loss = 0.197071
I0502 11:22:06.349284 26473 solver.cpp:261]     Train net output #0: loss = 0.197071 (* 1 = 0.197071 loss)
I0502 11:22:06.349293 26473 sgd_solver.cpp:106] Iteration 73900, lr = 2.09715e-05
I0502 11:22:06.354153 26473 solver.cpp:242] Iteration 73900 (105.426 iter/s, 0.948532s/100 iter), loss = 0.0912445
I0502 11:22:06.354178 26473 solver.cpp:261]     Train net output #0: loss = 0.0912445 (* 1 = 0.0912445 loss)
I0502 11:22:06.354187 26473 sgd_solver.cpp:106] Iteration 73900, lr = 2.09715e-05
I0502 11:22:07.292558 26473 solver.cpp:362] Iteration 74000, Testing net (#0)
I0502 11:22:07.292580 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:07.416791 26473 solver.cpp:429]     Test net output #0: loss = 0.276322 (* 1 = 0.276322 loss)
I0502 11:22:07.419667 26473 solver.cpp:242] Iteration 74000 (93.4261 iter/s, 1.07036s/100 iter), loss = 0.260731
I0502 11:22:07.419687 26473 solver.cpp:261]     Train net output #0: loss = 0.260731 (* 1 = 0.260731 loss)
I0502 11:22:07.419694 26473 sgd_solver.cpp:106] Iteration 74000, lr = 2.09715e-05
I0502 11:22:07.421339 26473 solver.cpp:362] Iteration 74000, Testing net (#0)
I0502 11:22:07.421352 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:07.551832 26473 solver.cpp:429]     Test net output #0: accuracy = 0.95
I0502 11:22:07.551852 26473 solver.cpp:429]     Test net output #1: loss = 0.104162 (* 1 = 0.104162 loss)
I0502 11:22:07.554776 26473 solver.cpp:242] Iteration 74000 (83.2933 iter/s, 1.20058s/100 iter), loss = 0.0467241
I0502 11:22:07.554796 26473 solver.cpp:261]     Train net output #0: loss = 0.0467241 (* 1 = 0.0467241 loss)
I0502 11:22:07.554805 26473 sgd_solver.cpp:106] Iteration 74000, lr = 2.09715e-05
I0502 11:22:08.496476 26473 solver.cpp:242] Iteration 74100 (92.8713 iter/s, 1.07676s/100 iter), loss = 0.177029
I0502 11:22:08.496511 26473 solver.cpp:261]     Train net output #0: loss = 0.177029 (* 1 = 0.177029 loss)
I0502 11:22:08.496520 26473 sgd_solver.cpp:106] Iteration 74100, lr = 2.09715e-05
I0502 11:22:08.501312 26473 solver.cpp:242] Iteration 74100 (105.653 iter/s, 0.946498s/100 iter), loss = 0.0186616
I0502 11:22:08.501335 26473 solver.cpp:261]     Train net output #0: loss = 0.0186616 (* 1 = 0.0186616 loss)
I0502 11:22:08.501343 26473 sgd_solver.cpp:106] Iteration 74100, lr = 2.09715e-05
I0502 11:22:09.443796 26473 solver.cpp:242] Iteration 74200 (105.568 iter/s, 0.947257s/100 iter), loss = 0.26768
I0502 11:22:09.443831 26473 solver.cpp:261]     Train net output #0: loss = 0.26768 (* 1 = 0.26768 loss)
I0502 11:22:09.443840 26473 sgd_solver.cpp:106] Iteration 74200, lr = 2.09715e-05
I0502 11:22:09.448614 26473 solver.cpp:242] Iteration 74200 (105.567 iter/s, 0.947261s/100 iter), loss = 0.139369
I0502 11:22:09.448637 26473 solver.cpp:261]     Train net output #0: loss = 0.139369 (* 1 = 0.139369 loss)
I0502 11:22:09.448645 26473 sgd_solver.cpp:106] Iteration 74200, lr = 2.09715e-05
I0502 11:22:10.390506 26473 solver.cpp:242] Iteration 74300 (105.636 iter/s, 0.946649s/100 iter), loss = 0.327127
I0502 11:22:10.390539 26473 solver.cpp:261]     Train net output #0: loss = 0.327127 (* 1 = 0.327127 loss)
I0502 11:22:10.390557 26473 sgd_solver.cpp:106] Iteration 74300, lr = 2.09715e-05
I0502 11:22:10.395337 26473 solver.cpp:242] Iteration 74300 (105.632 iter/s, 0.946682s/100 iter), loss = 0.141651
I0502 11:22:10.395360 26473 solver.cpp:261]     Train net output #0: loss = 0.141651 (* 1 = 0.141651 loss)
I0502 11:22:10.395368 26473 sgd_solver.cpp:106] Iteration 74300, lr = 2.09715e-05
I0502 11:22:11.338421 26473 solver.cpp:242] Iteration 74400 (105.501 iter/s, 0.947857s/100 iter), loss = 0.0808434
I0502 11:22:11.338455 26473 solver.cpp:261]     Train net output #0: loss = 0.0808434 (* 1 = 0.0808434 loss)
I0502 11:22:11.338464 26473 sgd_solver.cpp:106] Iteration 74400, lr = 2.09715e-05
I0502 11:22:11.343324 26473 solver.cpp:242] Iteration 74400 (105.492 iter/s, 0.947936s/100 iter), loss = 0.188179
I0502 11:22:11.343348 26473 solver.cpp:261]     Train net output #0: loss = 0.188179 (* 1 = 0.188179 loss)
I0502 11:22:11.343355 26473 sgd_solver.cpp:106] Iteration 74400, lr = 2.09715e-05
I0502 11:22:12.282091 26473 solver.cpp:362] Iteration 74500, Testing net (#0)
I0502 11:22:12.282114 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:12.406381 26473 solver.cpp:429]     Test net output #0: loss = 0.360764 (* 1 = 0.360764 loss)
I0502 11:22:12.409238 26473 solver.cpp:242] Iteration 74500 (93.3912 iter/s, 1.07077s/100 iter), loss = 0.171586
I0502 11:22:12.409258 26473 solver.cpp:261]     Train net output #0: loss = 0.171586 (* 1 = 0.171586 loss)
I0502 11:22:12.409267 26473 sgd_solver.cpp:106] Iteration 74500, lr = 2.09715e-05
I0502 11:22:12.410907 26473 solver.cpp:362] Iteration 74500, Testing net (#0)
I0502 11:22:12.410919 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:12.541332 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9495
I0502 11:22:12.541352 26473 solver.cpp:429]     Test net output #1: loss = 0.11599 (* 1 = 0.11599 loss)
I0502 11:22:12.544276 26473 solver.cpp:242] Iteration 74500 (83.2703 iter/s, 1.20091s/100 iter), loss = 0.204884
I0502 11:22:12.544296 26473 solver.cpp:261]     Train net output #0: loss = 0.204884 (* 1 = 0.204884 loss)
I0502 11:22:12.544304 26473 sgd_solver.cpp:106] Iteration 74500, lr = 2.09715e-05
I0502 11:22:13.486346 26473 solver.cpp:242] Iteration 74600 (92.8458 iter/s, 1.07705s/100 iter), loss = 0.16662
I0502 11:22:13.486388 26473 solver.cpp:261]     Train net output #0: loss = 0.16662 (* 1 = 0.16662 loss)
I0502 11:22:13.486397 26473 sgd_solver.cpp:106] Iteration 74600, lr = 2.09715e-05
I0502 11:22:13.491171 26473 solver.cpp:242] Iteration 74600 (105.612 iter/s, 0.946858s/100 iter), loss = 0.109429
I0502 11:22:13.491194 26473 solver.cpp:261]     Train net output #0: loss = 0.109429 (* 1 = 0.109429 loss)
I0502 11:22:13.491204 26473 sgd_solver.cpp:106] Iteration 74600, lr = 2.09715e-05
I0502 11:22:14.433161 26473 solver.cpp:242] Iteration 74700 (105.625 iter/s, 0.946744s/100 iter), loss = 0.24125
I0502 11:22:14.433207 26473 solver.cpp:261]     Train net output #0: loss = 0.24125 (* 1 = 0.24125 loss)
I0502 11:22:14.433217 26473 sgd_solver.cpp:106] Iteration 74700, lr = 2.09715e-05
I0502 11:22:14.437983 26473 solver.cpp:242] Iteration 74700 (105.622 iter/s, 0.946771s/100 iter), loss = 0.00771698
I0502 11:22:14.438007 26473 solver.cpp:261]     Train net output #0: loss = 0.00771698 (* 1 = 0.00771698 loss)
I0502 11:22:14.438016 26473 sgd_solver.cpp:106] Iteration 74700, lr = 2.09715e-05
I0502 11:22:15.380818 26473 solver.cpp:242] Iteration 74800 (105.532 iter/s, 0.947583s/100 iter), loss = 0.149674
I0502 11:22:15.380858 26473 solver.cpp:261]     Train net output #0: loss = 0.149674 (* 1 = 0.149674 loss)
I0502 11:22:15.380877 26473 sgd_solver.cpp:106] Iteration 74800, lr = 2.09715e-05
I0502 11:22:15.385651 26473 solver.cpp:242] Iteration 74800 (105.527 iter/s, 0.947627s/100 iter), loss = 0.137212
I0502 11:22:15.385675 26473 solver.cpp:261]     Train net output #0: loss = 0.137212 (* 1 = 0.137212 loss)
I0502 11:22:15.385684 26473 sgd_solver.cpp:106] Iteration 74800, lr = 2.09715e-05
I0502 11:22:16.328254 26473 solver.cpp:242] Iteration 74900 (105.555 iter/s, 0.94737s/100 iter), loss = 0.151701
I0502 11:22:16.328301 26473 solver.cpp:261]     Train net output #0: loss = 0.151701 (* 1 = 0.151701 loss)
I0502 11:22:16.328310 26473 sgd_solver.cpp:106] Iteration 74900, lr = 2.09715e-05
I0502 11:22:16.333184 26473 solver.cpp:242] Iteration 74900 (105.543 iter/s, 0.947483s/100 iter), loss = 0.0800831
I0502 11:22:16.333209 26473 solver.cpp:261]     Train net output #0: loss = 0.0800831 (* 1 = 0.0800831 loss)
I0502 11:22:16.333217 26473 sgd_solver.cpp:106] Iteration 74900, lr = 2.09715e-05
I0502 11:22:17.271806 26473 solver.cpp:362] Iteration 75000, Testing net (#0)
I0502 11:22:17.271834 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:17.396056 26473 solver.cpp:429]     Test net output #0: loss = 0.349609 (* 1 = 0.349609 loss)
I0502 11:22:17.398932 26473 solver.cpp:242] Iteration 75000 (93.4044 iter/s, 1.07061s/100 iter), loss = 0.853662
I0502 11:22:17.398953 26473 solver.cpp:261]     Train net output #0: loss = 0.853662 (* 1 = 0.853662 loss)
I0502 11:22:17.398962 26473 sgd_solver.cpp:106] Iteration 75000, lr = 2.09715e-05
I0502 11:22:17.400611 26473 solver.cpp:362] Iteration 75000, Testing net (#0)
I0502 11:22:17.400625 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:17.530951 26473 solver.cpp:429]     Test net output #0: accuracy = 0.955
I0502 11:22:17.530969 26473 solver.cpp:429]     Test net output #1: loss = 0.10298 (* 1 = 0.10298 loss)
I0502 11:22:17.533901 26473 solver.cpp:242] Iteration 75000 (83.2867 iter/s, 1.20067s/100 iter), loss = 0.113094
I0502 11:22:17.533922 26473 solver.cpp:261]     Train net output #0: loss = 0.113094 (* 1 = 0.113094 loss)
I0502 11:22:17.533931 26473 sgd_solver.cpp:106] Iteration 75000, lr = 2.09715e-05
I0502 11:22:18.476027 26473 solver.cpp:242] Iteration 75100 (92.847 iter/s, 1.07704s/100 iter), loss = 0.860806
I0502 11:22:18.476068 26473 solver.cpp:261]     Train net output #0: loss = 0.860806 (* 1 = 0.860806 loss)
I0502 11:22:18.476078 26473 sgd_solver.cpp:106] Iteration 75100, lr = 2.09715e-05
I0502 11:22:18.480854 26473 solver.cpp:242] Iteration 75100 (105.606 iter/s, 0.946913s/100 iter), loss = 0.0419562
I0502 11:22:18.480876 26473 solver.cpp:261]     Train net output #0: loss = 0.0419562 (* 1 = 0.0419562 loss)
I0502 11:22:18.480885 26473 sgd_solver.cpp:106] Iteration 75100, lr = 2.09715e-05
I0502 11:22:19.422695 26473 solver.cpp:242] Iteration 75200 (105.641 iter/s, 0.9466s/100 iter), loss = 0.125801
I0502 11:22:19.422737 26473 solver.cpp:261]     Train net output #0: loss = 0.125801 (* 1 = 0.125801 loss)
I0502 11:22:19.422746 26473 sgd_solver.cpp:106] Iteration 75200, lr = 2.09715e-05
I0502 11:22:19.427520 26473 solver.cpp:242] Iteration 75200 (105.639 iter/s, 0.946625s/100 iter), loss = 0.202531
I0502 11:22:19.427543 26473 solver.cpp:261]     Train net output #0: loss = 0.202531 (* 1 = 0.202531 loss)
I0502 11:22:19.427552 26473 sgd_solver.cpp:106] Iteration 75200, lr = 2.09715e-05
I0502 11:22:20.370452 26473 solver.cpp:242] Iteration 75300 (105.52 iter/s, 0.947686s/100 iter), loss = 0.169418
I0502 11:22:20.370494 26473 solver.cpp:261]     Train net output #0: loss = 0.169418 (* 1 = 0.169418 loss)
I0502 11:22:20.370503 26473 sgd_solver.cpp:106] Iteration 75300, lr = 2.09715e-05
I0502 11:22:20.375272 26473 solver.cpp:242] Iteration 75300 (105.517 iter/s, 0.947711s/100 iter), loss = 0.0576541
I0502 11:22:20.375295 26473 solver.cpp:261]     Train net output #0: loss = 0.0576541 (* 1 = 0.0576541 loss)
I0502 11:22:20.375304 26473 sgd_solver.cpp:106] Iteration 75300, lr = 2.09715e-05
I0502 11:22:21.317109 26473 solver.cpp:242] Iteration 75400 (105.642 iter/s, 0.94659s/100 iter), loss = 0.186056
I0502 11:22:21.317149 26473 solver.cpp:261]     Train net output #0: loss = 0.186056 (* 1 = 0.186056 loss)
I0502 11:22:21.317158 26473 sgd_solver.cpp:106] Iteration 75400, lr = 2.09715e-05
I0502 11:22:21.322013 26473 solver.cpp:242] Iteration 75400 (105.631 iter/s, 0.94669s/100 iter), loss = 0.039089
I0502 11:22:21.322036 26473 solver.cpp:261]     Train net output #0: loss = 0.039089 (* 1 = 0.039089 loss)
I0502 11:22:21.322054 26473 sgd_solver.cpp:106] Iteration 75400, lr = 2.09715e-05
I0502 11:22:22.282091 26473 solver.cpp:362] Iteration 75500, Testing net (#0)
I0502 11:22:22.282119 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:22.406482 26473 solver.cpp:429]     Test net output #0: loss = 0.301108 (* 1 = 0.301108 loss)
I0502 11:22:22.409349 26473 solver.cpp:242] Iteration 75500 (91.56 iter/s, 1.09218s/100 iter), loss = 0.21219
I0502 11:22:22.409370 26473 solver.cpp:261]     Train net output #0: loss = 0.21219 (* 1 = 0.21219 loss)
I0502 11:22:22.409379 26473 sgd_solver.cpp:106] Iteration 75500, lr = 2.09715e-05
I0502 11:22:22.411111 26473 solver.cpp:362] Iteration 75500, Testing net (#0)
I0502 11:22:22.411124 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:22.541790 26473 solver.cpp:429]     Test net output #0: accuracy = 0.948
I0502 11:22:22.541812 26473 solver.cpp:429]     Test net output #1: loss = 0.114188 (* 1 = 0.114188 loss)
I0502 11:22:22.544721 26473 solver.cpp:242] Iteration 75500 (81.7886 iter/s, 1.22266s/100 iter), loss = 0.0594141
I0502 11:22:22.544742 26473 solver.cpp:261]     Train net output #0: loss = 0.0594141 (* 1 = 0.0594141 loss)
I0502 11:22:22.544750 26473 sgd_solver.cpp:106] Iteration 75500, lr = 2.09715e-05
I0502 11:22:23.486423 26473 solver.cpp:242] Iteration 75600 (92.8488 iter/s, 1.07702s/100 iter), loss = 0.793408
I0502 11:22:23.486459 26473 solver.cpp:261]     Train net output #0: loss = 0.793408 (* 1 = 0.793408 loss)
I0502 11:22:23.486469 26473 sgd_solver.cpp:106] Iteration 75600, lr = 2.09715e-05
I0502 11:22:23.491267 26473 solver.cpp:242] Iteration 75600 (105.652 iter/s, 0.946507s/100 iter), loss = 0.0603261
I0502 11:22:23.491291 26473 solver.cpp:261]     Train net output #0: loss = 0.0603261 (* 1 = 0.0603261 loss)
I0502 11:22:23.491299 26473 sgd_solver.cpp:106] Iteration 75600, lr = 2.09715e-05
I0502 11:22:24.432469 26473 solver.cpp:242] Iteration 75700 (105.71 iter/s, 0.945983s/100 iter), loss = 0.115847
I0502 11:22:24.432505 26473 solver.cpp:261]     Train net output #0: loss = 0.115847 (* 1 = 0.115847 loss)
I0502 11:22:24.432514 26473 sgd_solver.cpp:106] Iteration 75700, lr = 2.09715e-05
I0502 11:22:24.437296 26473 solver.cpp:242] Iteration 75700 (105.71 iter/s, 0.945987s/100 iter), loss = 0.0346748
I0502 11:22:24.437319 26473 solver.cpp:261]     Train net output #0: loss = 0.0346748 (* 1 = 0.0346748 loss)
I0502 11:22:24.437328 26473 sgd_solver.cpp:106] Iteration 75700, lr = 2.09715e-05
I0502 11:22:25.380733 26473 solver.cpp:242] Iteration 75800 (105.463 iter/s, 0.9482s/100 iter), loss = 0.441436
I0502 11:22:25.380770 26473 solver.cpp:261]     Train net output #0: loss = 0.441436 (* 1 = 0.441436 loss)
I0502 11:22:25.380779 26473 sgd_solver.cpp:106] Iteration 75800, lr = 2.09715e-05
I0502 11:22:25.385556 26473 solver.cpp:242] Iteration 75800 (105.461 iter/s, 0.948219s/100 iter), loss = 0.151083
I0502 11:22:25.385579 26473 solver.cpp:261]     Train net output #0: loss = 0.151083 (* 1 = 0.151083 loss)
I0502 11:22:25.385587 26473 sgd_solver.cpp:106] Iteration 75800, lr = 2.09715e-05
I0502 11:22:26.328410 26473 solver.cpp:242] Iteration 75900 (105.528 iter/s, 0.947614s/100 iter), loss = 0.431913
I0502 11:22:26.328446 26473 solver.cpp:261]     Train net output #0: loss = 0.431913 (* 1 = 0.431913 loss)
I0502 11:22:26.328456 26473 sgd_solver.cpp:106] Iteration 75900, lr = 2.09715e-05
I0502 11:22:26.333335 26473 solver.cpp:242] Iteration 75900 (105.515 iter/s, 0.947728s/100 iter), loss = 0.0396692
I0502 11:22:26.333360 26473 solver.cpp:261]     Train net output #0: loss = 0.0396692 (* 1 = 0.0396692 loss)
I0502 11:22:26.333369 26473 sgd_solver.cpp:106] Iteration 75900, lr = 2.09715e-05
I0502 11:22:27.272322 26473 solver.cpp:362] Iteration 76000, Testing net (#0)
I0502 11:22:27.272348 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:27.396617 26473 solver.cpp:429]     Test net output #0: loss = 0.270315 (* 1 = 0.270315 loss)
I0502 11:22:27.399492 26473 solver.cpp:242] Iteration 76000 (93.3684 iter/s, 1.07103s/100 iter), loss = 0.202157
I0502 11:22:27.399521 26473 solver.cpp:261]     Train net output #0: loss = 0.202157 (* 1 = 0.202157 loss)
I0502 11:22:27.399531 26473 sgd_solver.cpp:106] Iteration 76000, lr = 2.09715e-05
I0502 11:22:27.401257 26473 solver.cpp:362] Iteration 76000, Testing net (#0)
I0502 11:22:27.401270 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:27.531693 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9475
I0502 11:22:27.531715 26473 solver.cpp:429]     Test net output #1: loss = 0.116191 (* 1 = 0.116191 loss)
I0502 11:22:27.534638 26473 solver.cpp:242] Iteration 76000 (83.2462 iter/s, 1.20126s/100 iter), loss = 0.036961
I0502 11:22:27.534658 26473 solver.cpp:261]     Train net output #0: loss = 0.036961 (* 1 = 0.036961 loss)
I0502 11:22:27.534667 26473 sgd_solver.cpp:106] Iteration 76000, lr = 2.09715e-05
I0502 11:22:28.476238 26473 solver.cpp:242] Iteration 76100 (92.8777 iter/s, 1.07668s/100 iter), loss = 0.132446
I0502 11:22:28.476271 26473 solver.cpp:261]     Train net output #0: loss = 0.132446 (* 1 = 0.132446 loss)
I0502 11:22:28.476280 26473 sgd_solver.cpp:106] Iteration 76100, lr = 2.09715e-05
I0502 11:22:28.481091 26473 solver.cpp:242] Iteration 76100 (105.662 iter/s, 0.946414s/100 iter), loss = 0.177254
I0502 11:22:28.481114 26473 solver.cpp:261]     Train net output #0: loss = 0.177254 (* 1 = 0.177254 loss)
I0502 11:22:28.481122 26473 sgd_solver.cpp:106] Iteration 76100, lr = 2.09715e-05
I0502 11:22:29.422580 26473 solver.cpp:242] Iteration 76200 (105.677 iter/s, 0.946281s/100 iter), loss = 0.209025
I0502 11:22:29.422613 26473 solver.cpp:261]     Train net output #0: loss = 0.209025 (* 1 = 0.209025 loss)
I0502 11:22:29.422622 26473 sgd_solver.cpp:106] Iteration 76200, lr = 2.09715e-05
I0502 11:22:29.427397 26473 solver.cpp:242] Iteration 76200 (105.679 iter/s, 0.946265s/100 iter), loss = 0.00264355
I0502 11:22:29.427420 26473 solver.cpp:261]     Train net output #0: loss = 0.00264355 (* 1 = 0.00264355 loss)
I0502 11:22:29.427429 26473 sgd_solver.cpp:106] Iteration 76200, lr = 2.09715e-05
I0502 11:22:30.369940 26473 solver.cpp:242] Iteration 76300 (105.563 iter/s, 0.947301s/100 iter), loss = 0.40121
I0502 11:22:30.369968 26473 solver.cpp:261]     Train net output #0: loss = 0.40121 (* 1 = 0.40121 loss)
I0502 11:22:30.369977 26473 sgd_solver.cpp:106] Iteration 76300, lr = 2.09715e-05
I0502 11:22:30.374761 26473 solver.cpp:242] Iteration 76300 (105.561 iter/s, 0.947323s/100 iter), loss = 0.0993468
I0502 11:22:30.374784 26473 solver.cpp:261]     Train net output #0: loss = 0.0993468 (* 1 = 0.0993468 loss)
I0502 11:22:30.374794 26473 sgd_solver.cpp:106] Iteration 76300, lr = 2.09715e-05
I0502 11:22:31.316218 26473 solver.cpp:242] Iteration 76400 (105.683 iter/s, 0.946222s/100 iter), loss = 0.164628
I0502 11:22:31.316262 26473 solver.cpp:261]     Train net output #0: loss = 0.164628 (* 1 = 0.164628 loss)
I0502 11:22:31.316269 26473 sgd_solver.cpp:106] Iteration 76400, lr = 2.09715e-05
I0502 11:22:31.321089 26473 solver.cpp:242] Iteration 76400 (105.676 iter/s, 0.946286s/100 iter), loss = 0.0830983
I0502 11:22:31.321111 26473 solver.cpp:261]     Train net output #0: loss = 0.0830983 (* 1 = 0.0830983 loss)
I0502 11:22:31.321120 26473 sgd_solver.cpp:106] Iteration 76400, lr = 2.09715e-05
I0502 11:22:32.260182 26473 solver.cpp:362] Iteration 76500, Testing net (#0)
I0502 11:22:32.260223 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:32.384451 26473 solver.cpp:429]     Test net output #0: loss = 0.274861 (* 1 = 0.274861 loss)
I0502 11:22:32.387311 26473 solver.cpp:242] Iteration 76500 (93.368 iter/s, 1.07103s/100 iter), loss = 0.113321
I0502 11:22:32.387331 26473 solver.cpp:261]     Train net output #0: loss = 0.113321 (* 1 = 0.113321 loss)
I0502 11:22:32.387341 26473 sgd_solver.cpp:106] Iteration 76500, lr = 2.09715e-05
I0502 11:22:32.389088 26473 solver.cpp:362] Iteration 76500, Testing net (#0)
I0502 11:22:32.389103 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:32.519611 26473 solver.cpp:429]     Test net output #0: accuracy = 0.946
I0502 11:22:32.519642 26473 solver.cpp:429]     Test net output #1: loss = 0.129524 (* 1 = 0.129524 loss)
I0502 11:22:32.522585 26473 solver.cpp:242] Iteration 76500 (83.2325 iter/s, 1.20145s/100 iter), loss = 0.120187
I0502 11:22:32.522605 26473 solver.cpp:261]     Train net output #0: loss = 0.120187 (* 1 = 0.120187 loss)
I0502 11:22:32.522614 26473 sgd_solver.cpp:106] Iteration 76500, lr = 2.09715e-05
I0502 11:22:33.464191 26473 solver.cpp:242] Iteration 76600 (92.8655 iter/s, 1.07683s/100 iter), loss = 0.288334
I0502 11:22:33.464231 26473 solver.cpp:261]     Train net output #0: loss = 0.288334 (* 1 = 0.288334 loss)
I0502 11:22:33.464239 26473 sgd_solver.cpp:106] Iteration 76600, lr = 2.09715e-05
I0502 11:22:33.469033 26473 solver.cpp:242] Iteration 76600 (105.663 iter/s, 0.946409s/100 iter), loss = 0.0699073
I0502 11:22:33.469054 26473 solver.cpp:261]     Train net output #0: loss = 0.0699073 (* 1 = 0.0699073 loss)
I0502 11:22:33.469063 26473 sgd_solver.cpp:106] Iteration 76600, lr = 2.09715e-05
I0502 11:22:34.411203 26473 solver.cpp:242] Iteration 76700 (105.603 iter/s, 0.946942s/100 iter), loss = 0.20059
I0502 11:22:34.411243 26473 solver.cpp:261]     Train net output #0: loss = 0.20059 (* 1 = 0.20059 loss)
I0502 11:22:34.411253 26473 sgd_solver.cpp:106] Iteration 76700, lr = 2.09715e-05
I0502 11:22:34.416033 26473 solver.cpp:242] Iteration 76700 (105.601 iter/s, 0.94696s/100 iter), loss = 0.0251901
I0502 11:22:34.416057 26473 solver.cpp:261]     Train net output #0: loss = 0.0251901 (* 1 = 0.0251901 loss)
I0502 11:22:34.416065 26473 sgd_solver.cpp:106] Iteration 76700, lr = 2.09715e-05
I0502 11:22:35.358065 26473 solver.cpp:242] Iteration 76800 (105.62 iter/s, 0.946795s/100 iter), loss = 0.40135
I0502 11:22:35.358108 26473 solver.cpp:261]     Train net output #0: loss = 0.40135 (* 1 = 0.40135 loss)
I0502 11:22:35.358116 26473 sgd_solver.cpp:106] Iteration 76800, lr = 2.09715e-05
I0502 11:22:35.362902 26473 solver.cpp:242] Iteration 76800 (105.616 iter/s, 0.946827s/100 iter), loss = 0.143374
I0502 11:22:35.362926 26473 solver.cpp:261]     Train net output #0: loss = 0.143374 (* 1 = 0.143374 loss)
I0502 11:22:35.362934 26473 sgd_solver.cpp:106] Iteration 76800, lr = 2.09715e-05
I0502 11:22:36.309101 26473 solver.cpp:242] Iteration 76900 (105.156 iter/s, 0.950964s/100 iter), loss = 0.0819998
I0502 11:22:36.309149 26473 solver.cpp:261]     Train net output #0: loss = 0.0819998 (* 1 = 0.0819998 loss)
I0502 11:22:36.309159 26473 sgd_solver.cpp:106] Iteration 76900, lr = 2.09715e-05
I0502 11:22:36.313969 26473 solver.cpp:242] Iteration 76900 (105.15 iter/s, 0.951025s/100 iter), loss = 0.0596924
I0502 11:22:36.313995 26473 solver.cpp:261]     Train net output #0: loss = 0.0596924 (* 1 = 0.0596924 loss)
I0502 11:22:36.314003 26473 sgd_solver.cpp:106] Iteration 76900, lr = 2.09715e-05
I0502 11:22:37.254314 26473 solver.cpp:362] Iteration 77000, Testing net (#0)
I0502 11:22:37.254343 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:37.378729 26473 solver.cpp:429]     Test net output #0: loss = 0.310236 (* 1 = 0.310236 loss)
I0502 11:22:37.381618 26473 solver.cpp:242] Iteration 77000 (93.2444 iter/s, 1.07245s/100 iter), loss = 0.16449
I0502 11:22:37.381640 26473 solver.cpp:261]     Train net output #0: loss = 0.16449 (* 1 = 0.16449 loss)
I0502 11:22:37.381649 26473 sgd_solver.cpp:106] Iteration 77000, lr = 2.09715e-05
I0502 11:22:37.383386 26473 solver.cpp:362] Iteration 77000, Testing net (#0)
I0502 11:22:37.383400 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:37.513837 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9535
I0502 11:22:37.513859 26473 solver.cpp:429]     Test net output #1: loss = 0.102795 (* 1 = 0.102795 loss)
I0502 11:22:37.516793 26473 solver.cpp:242] Iteration 77000 (83.1409 iter/s, 1.20278s/100 iter), loss = 0.0961957
I0502 11:22:37.516813 26473 solver.cpp:261]     Train net output #0: loss = 0.0961957 (* 1 = 0.0961957 loss)
I0502 11:22:37.516822 26473 sgd_solver.cpp:106] Iteration 77000, lr = 2.09715e-05
I0502 11:22:38.458771 26473 solver.cpp:242] Iteration 77100 (92.8424 iter/s, 1.07709s/100 iter), loss = 0.0536573
I0502 11:22:38.458820 26473 solver.cpp:261]     Train net output #0: loss = 0.0536573 (* 1 = 0.0536573 loss)
I0502 11:22:38.458829 26473 sgd_solver.cpp:106] Iteration 77100, lr = 2.09715e-05
I0502 11:22:38.463616 26473 solver.cpp:242] Iteration 77100 (105.621 iter/s, 0.946783s/100 iter), loss = 0.0347521
I0502 11:22:38.463639 26473 solver.cpp:261]     Train net output #0: loss = 0.0347521 (* 1 = 0.0347521 loss)
I0502 11:22:38.463649 26473 sgd_solver.cpp:106] Iteration 77100, lr = 2.09715e-05
I0502 11:22:39.405333 26473 solver.cpp:242] Iteration 77200 (105.654 iter/s, 0.946483s/100 iter), loss = 0.0811857
I0502 11:22:39.405371 26473 solver.cpp:261]     Train net output #0: loss = 0.0811857 (* 1 = 0.0811857 loss)
I0502 11:22:39.405380 26473 sgd_solver.cpp:106] Iteration 77200, lr = 2.09715e-05
I0502 11:22:39.410166 26473 solver.cpp:242] Iteration 77200 (105.651 iter/s, 0.946509s/100 iter), loss = 0.149225
I0502 11:22:39.410189 26473 solver.cpp:261]     Train net output #0: loss = 0.149225 (* 1 = 0.149225 loss)
I0502 11:22:39.410197 26473 sgd_solver.cpp:106] Iteration 77200, lr = 2.09715e-05
I0502 11:22:40.351320 26473 solver.cpp:242] Iteration 77300 (105.717 iter/s, 0.945921s/100 iter), loss = 0.266822
I0502 11:22:40.351361 26473 solver.cpp:261]     Train net output #0: loss = 0.266822 (* 1 = 0.266822 loss)
I0502 11:22:40.351369 26473 sgd_solver.cpp:106] Iteration 77300, lr = 2.09715e-05
I0502 11:22:40.356187 26473 solver.cpp:242] Iteration 77300 (105.71 iter/s, 0.94598s/100 iter), loss = 0.0565981
I0502 11:22:40.356210 26473 solver.cpp:261]     Train net output #0: loss = 0.0565981 (* 1 = 0.0565981 loss)
I0502 11:22:40.356220 26473 sgd_solver.cpp:106] Iteration 77300, lr = 2.09715e-05
I0502 11:22:41.298043 26473 solver.cpp:242] Iteration 77400 (105.635 iter/s, 0.946655s/100 iter), loss = 0.409069
I0502 11:22:41.298084 26473 solver.cpp:261]     Train net output #0: loss = 0.409069 (* 1 = 0.409069 loss)
I0502 11:22:41.298092 26473 sgd_solver.cpp:106] Iteration 77400, lr = 2.09715e-05
I0502 11:22:41.302856 26473 solver.cpp:242] Iteration 77400 (105.638 iter/s, 0.946628s/100 iter), loss = 0.0519639
I0502 11:22:41.302881 26473 solver.cpp:261]     Train net output #0: loss = 0.0519639 (* 1 = 0.0519639 loss)
I0502 11:22:41.302889 26473 sgd_solver.cpp:106] Iteration 77400, lr = 2.09715e-05
I0502 11:22:42.241396 26473 solver.cpp:362] Iteration 77500, Testing net (#0)
I0502 11:22:42.241420 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:42.365663 26473 solver.cpp:429]     Test net output #0: loss = 0.416654 (* 1 = 0.416654 loss)
I0502 11:22:42.368537 26473 solver.cpp:242] Iteration 77500 (93.4199 iter/s, 1.07044s/100 iter), loss = 0.326242
I0502 11:22:42.368561 26473 solver.cpp:261]     Train net output #0: loss = 0.326242 (* 1 = 0.326242 loss)
I0502 11:22:42.368571 26473 sgd_solver.cpp:106] Iteration 77500, lr = 2.09715e-05
I0502 11:22:42.370280 26473 solver.cpp:362] Iteration 77500, Testing net (#0)
I0502 11:22:42.370295 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:42.500685 26473 solver.cpp:429]     Test net output #0: accuracy = 0.926
I0502 11:22:42.500720 26473 solver.cpp:429]     Test net output #1: loss = 0.143289 (* 1 = 0.143289 loss)
I0502 11:22:42.503646 26473 solver.cpp:242] Iteration 77500 (83.2816 iter/s, 1.20075s/100 iter), loss = 0.14896
I0502 11:22:42.503669 26473 solver.cpp:261]     Train net output #0: loss = 0.14896 (* 1 = 0.14896 loss)
I0502 11:22:42.503677 26473 sgd_solver.cpp:106] Iteration 77500, lr = 2.09715e-05
I0502 11:22:43.446135 26473 solver.cpp:242] Iteration 77600 (92.8041 iter/s, 1.07754s/100 iter), loss = 0.164262
I0502 11:22:43.446177 26473 solver.cpp:261]     Train net output #0: loss = 0.164262 (* 1 = 0.164262 loss)
I0502 11:22:43.446185 26473 sgd_solver.cpp:106] Iteration 77600, lr = 2.09715e-05
I0502 11:22:43.450951 26473 solver.cpp:242] Iteration 77600 (105.567 iter/s, 0.947265s/100 iter), loss = 0.117884
I0502 11:22:43.450974 26473 solver.cpp:261]     Train net output #0: loss = 0.117884 (* 1 = 0.117884 loss)
I0502 11:22:43.450991 26473 sgd_solver.cpp:106] Iteration 77600, lr = 2.09715e-05
I0502 11:22:44.392715 26473 solver.cpp:242] Iteration 77700 (105.651 iter/s, 0.94651s/100 iter), loss = 0.240994
I0502 11:22:44.392750 26473 solver.cpp:261]     Train net output #0: loss = 0.240994 (* 1 = 0.240994 loss)
I0502 11:22:44.392758 26473 sgd_solver.cpp:106] Iteration 77700, lr = 2.09715e-05
I0502 11:22:44.397547 26473 solver.cpp:242] Iteration 77700 (105.646 iter/s, 0.946554s/100 iter), loss = 0.207125
I0502 11:22:44.397569 26473 solver.cpp:261]     Train net output #0: loss = 0.207125 (* 1 = 0.207125 loss)
I0502 11:22:44.397578 26473 sgd_solver.cpp:106] Iteration 77700, lr = 2.09715e-05
I0502 11:22:45.339407 26473 solver.cpp:242] Iteration 77800 (105.638 iter/s, 0.94663s/100 iter), loss = 0.380156
I0502 11:22:45.339442 26473 solver.cpp:261]     Train net output #0: loss = 0.380156 (* 1 = 0.380156 loss)
I0502 11:22:45.339450 26473 sgd_solver.cpp:106] Iteration 77800, lr = 2.09715e-05
I0502 11:22:45.344269 26473 solver.cpp:242] Iteration 77800 (105.632 iter/s, 0.946682s/100 iter), loss = 0.0784719
I0502 11:22:45.344293 26473 solver.cpp:261]     Train net output #0: loss = 0.0784719 (* 1 = 0.0784719 loss)
I0502 11:22:45.344302 26473 sgd_solver.cpp:106] Iteration 77800, lr = 2.09715e-05
I0502 11:22:46.289204 26473 solver.cpp:242] Iteration 77900 (105.292 iter/s, 0.949736s/100 iter), loss = 0.384899
I0502 11:22:46.289237 26473 solver.cpp:261]     Train net output #0: loss = 0.384899 (* 1 = 0.384899 loss)
I0502 11:22:46.289247 26473 sgd_solver.cpp:106] Iteration 77900, lr = 2.09715e-05
I0502 11:22:46.294025 26473 solver.cpp:242] Iteration 77900 (105.295 iter/s, 0.949714s/100 iter), loss = 0.0197976
I0502 11:22:46.294049 26473 solver.cpp:261]     Train net output #0: loss = 0.0197976 (* 1 = 0.0197976 loss)
I0502 11:22:46.294059 26473 sgd_solver.cpp:106] Iteration 77900, lr = 2.09715e-05
I0502 11:22:47.231436 26473 solver.cpp:362] Iteration 78000, Testing net (#0)
I0502 11:22:47.231464 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:47.355603 26473 solver.cpp:429]     Test net output #0: loss = 0.362257 (* 1 = 0.362257 loss)
I0502 11:22:47.358481 26473 solver.cpp:242] Iteration 78000 (93.5256 iter/s, 1.06923s/100 iter), loss = 0.348696
I0502 11:22:47.358501 26473 solver.cpp:261]     Train net output #0: loss = 0.348696 (* 1 = 0.348696 loss)
I0502 11:22:47.358510 26473 sgd_solver.cpp:106] Iteration 78000, lr = 2.09715e-05
I0502 11:22:47.360216 26473 solver.cpp:362] Iteration 78000, Testing net (#0)
I0502 11:22:47.360229 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:47.490515 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9515
I0502 11:22:47.490536 26473 solver.cpp:429]     Test net output #1: loss = 0.113076 (* 1 = 0.113076 loss)
I0502 11:22:47.493446 26473 solver.cpp:242] Iteration 78000 (83.3767 iter/s, 1.19938s/100 iter), loss = 0.179179
I0502 11:22:47.493466 26473 solver.cpp:261]     Train net output #0: loss = 0.179179 (* 1 = 0.179179 loss)
I0502 11:22:47.493474 26473 sgd_solver.cpp:106] Iteration 78000, lr = 2.09715e-05
I0502 11:22:48.435047 26473 solver.cpp:242] Iteration 78100 (92.8925 iter/s, 1.07651s/100 iter), loss = 0.286242
I0502 11:22:48.435083 26473 solver.cpp:261]     Train net output #0: loss = 0.286242 (* 1 = 0.286242 loss)
I0502 11:22:48.435092 26473 sgd_solver.cpp:106] Iteration 78100, lr = 2.09715e-05
I0502 11:22:48.439860 26473 solver.cpp:242] Iteration 78100 (105.666 iter/s, 0.946376s/100 iter), loss = 0.0227857
I0502 11:22:48.439883 26473 solver.cpp:261]     Train net output #0: loss = 0.0227857 (* 1 = 0.0227857 loss)
I0502 11:22:48.439893 26473 sgd_solver.cpp:106] Iteration 78100, lr = 2.09715e-05
I0502 11:22:49.381340 26473 solver.cpp:242] Iteration 78200 (105.683 iter/s, 0.946227s/100 iter), loss = 0.124314
I0502 11:22:49.381368 26473 solver.cpp:261]     Train net output #0: loss = 0.124314 (* 1 = 0.124314 loss)
I0502 11:22:49.381377 26473 sgd_solver.cpp:106] Iteration 78200, lr = 2.09715e-05
I0502 11:22:49.386152 26473 solver.cpp:242] Iteration 78200 (105.68 iter/s, 0.946251s/100 iter), loss = 0.00986173
I0502 11:22:49.386183 26473 solver.cpp:261]     Train net output #0: loss = 0.00986173 (* 1 = 0.00986173 loss)
I0502 11:22:49.386191 26473 sgd_solver.cpp:106] Iteration 78200, lr = 2.09715e-05
I0502 11:22:50.327178 26473 solver.cpp:242] Iteration 78300 (105.733 iter/s, 0.94578s/100 iter), loss = 0.165767
I0502 11:22:50.327221 26473 solver.cpp:261]     Train net output #0: loss = 0.165767 (* 1 = 0.165767 loss)
I0502 11:22:50.327230 26473 sgd_solver.cpp:106] Iteration 78300, lr = 2.09715e-05
I0502 11:22:50.332032 26473 solver.cpp:242] Iteration 78300 (105.727 iter/s, 0.945833s/100 iter), loss = 0.0692969
I0502 11:22:50.332056 26473 solver.cpp:261]     Train net output #0: loss = 0.0692969 (* 1 = 0.0692969 loss)
I0502 11:22:50.332064 26473 sgd_solver.cpp:106] Iteration 78300, lr = 2.09715e-05
I0502 11:22:51.272771 26473 solver.cpp:242] Iteration 78400 (105.761 iter/s, 0.945524s/100 iter), loss = 0.0533582
I0502 11:22:51.272814 26473 solver.cpp:261]     Train net output #0: loss = 0.0533582 (* 1 = 0.0533582 loss)
I0502 11:22:51.272824 26473 sgd_solver.cpp:106] Iteration 78400, lr = 2.09715e-05
I0502 11:22:51.277590 26473 solver.cpp:242] Iteration 78400 (105.762 iter/s, 0.945516s/100 iter), loss = 0.103656
I0502 11:22:51.277612 26473 solver.cpp:261]     Train net output #0: loss = 0.103656 (* 1 = 0.103656 loss)
I0502 11:22:51.277621 26473 sgd_solver.cpp:106] Iteration 78400, lr = 2.09715e-05
I0502 11:22:52.214972 26473 solver.cpp:362] Iteration 78500, Testing net (#0)
I0502 11:22:52.214999 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:52.339342 26473 solver.cpp:429]     Test net output #0: loss = 0.290613 (* 1 = 0.290613 loss)
I0502 11:22:52.342257 26473 solver.cpp:242] Iteration 78500 (93.5082 iter/s, 1.06942s/100 iter), loss = 0.201028
I0502 11:22:52.342278 26473 solver.cpp:261]     Train net output #0: loss = 0.201028 (* 1 = 0.201028 loss)
I0502 11:22:52.342288 26473 sgd_solver.cpp:106] Iteration 78500, lr = 2.09715e-05
I0502 11:22:52.344120 26473 solver.cpp:362] Iteration 78500, Testing net (#0)
I0502 11:22:52.344135 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:52.474731 26473 solver.cpp:429]     Test net output #0: accuracy = 0.952
I0502 11:22:52.474756 26473 solver.cpp:429]     Test net output #1: loss = 0.099546 (* 1 = 0.099546 loss)
I0502 11:22:52.477669 26473 solver.cpp:242] Iteration 78500 (83.3308 iter/s, 1.20004s/100 iter), loss = 0.129018
I0502 11:22:52.477689 26473 solver.cpp:261]     Train net output #0: loss = 0.129018 (* 1 = 0.129018 loss)
I0502 11:22:52.477697 26473 sgd_solver.cpp:106] Iteration 78500, lr = 2.09715e-05
I0502 11:22:53.418191 26473 solver.cpp:242] Iteration 78600 (92.9466 iter/s, 1.07589s/100 iter), loss = 0.195749
I0502 11:22:53.418236 26473 solver.cpp:261]     Train net output #0: loss = 0.195749 (* 1 = 0.195749 loss)
I0502 11:22:53.418243 26473 sgd_solver.cpp:106] Iteration 78600, lr = 2.09715e-05
I0502 11:22:53.423072 26473 solver.cpp:242] Iteration 78600 (105.78 iter/s, 0.945359s/100 iter), loss = 0.191203
I0502 11:22:53.423095 26473 solver.cpp:261]     Train net output #0: loss = 0.191203 (* 1 = 0.191203 loss)
I0502 11:22:53.423105 26473 sgd_solver.cpp:106] Iteration 78600, lr = 2.09715e-05
I0502 11:22:54.363723 26473 solver.cpp:242] Iteration 78700 (105.769 iter/s, 0.945456s/100 iter), loss = 0.17009
I0502 11:22:54.363765 26473 solver.cpp:261]     Train net output #0: loss = 0.17009 (* 1 = 0.17009 loss)
I0502 11:22:54.363773 26473 sgd_solver.cpp:106] Iteration 78700, lr = 2.09715e-05
I0502 11:22:54.368548 26473 solver.cpp:242] Iteration 78700 (105.772 iter/s, 0.945434s/100 iter), loss = 0.17914
I0502 11:22:54.368583 26473 solver.cpp:261]     Train net output #0: loss = 0.17914 (* 1 = 0.17914 loss)
I0502 11:22:54.368592 26473 sgd_solver.cpp:106] Iteration 78700, lr = 2.09715e-05
I0502 11:22:55.309881 26473 solver.cpp:242] Iteration 78800 (105.699 iter/s, 0.946087s/100 iter), loss = 0.178966
I0502 11:22:55.309921 26473 solver.cpp:261]     Train net output #0: loss = 0.178966 (* 1 = 0.178966 loss)
I0502 11:22:55.309937 26473 sgd_solver.cpp:106] Iteration 78800, lr = 2.09715e-05
I0502 11:22:55.314713 26473 solver.cpp:242] Iteration 78800 (105.696 iter/s, 0.946112s/100 iter), loss = 0.0778829
I0502 11:22:55.314735 26473 solver.cpp:261]     Train net output #0: loss = 0.0778829 (* 1 = 0.0778829 loss)
I0502 11:22:55.314744 26473 sgd_solver.cpp:106] Iteration 78800, lr = 2.09715e-05
I0502 11:22:56.259583 26473 solver.cpp:242] Iteration 78900 (105.304 iter/s, 0.949635s/100 iter), loss = 0.351833
I0502 11:22:56.259624 26473 solver.cpp:261]     Train net output #0: loss = 0.351833 (* 1 = 0.351833 loss)
I0502 11:22:56.259632 26473 sgd_solver.cpp:106] Iteration 78900, lr = 2.09715e-05
I0502 11:22:56.264405 26473 solver.cpp:242] Iteration 78900 (105.302 iter/s, 0.949651s/100 iter), loss = 0.136367
I0502 11:22:56.264430 26473 solver.cpp:261]     Train net output #0: loss = 0.136367 (* 1 = 0.136367 loss)
I0502 11:22:56.264437 26473 sgd_solver.cpp:106] Iteration 78900, lr = 2.09715e-05
I0502 11:22:57.200755 26473 solver.cpp:362] Iteration 79000, Testing net (#0)
I0502 11:22:57.200779 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:57.325101 26473 solver.cpp:429]     Test net output #0: loss = 0.275807 (* 1 = 0.275807 loss)
I0502 11:22:57.327972 26473 solver.cpp:242] Iteration 79000 (93.604 iter/s, 1.06833s/100 iter), loss = 0.354379
I0502 11:22:57.327991 26473 solver.cpp:261]     Train net output #0: loss = 0.354379 (* 1 = 0.354379 loss)
I0502 11:22:57.328001 26473 sgd_solver.cpp:106] Iteration 79000, lr = 2.09715e-05
I0502 11:22:57.329669 26473 solver.cpp:362] Iteration 79000, Testing net (#0)
I0502 11:22:57.329682 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:22:57.460156 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9485
I0502 11:22:57.460177 26473 solver.cpp:429]     Test net output #1: loss = 0.112495 (* 1 = 0.112495 loss)
I0502 11:22:57.463098 26473 solver.cpp:242] Iteration 79000 (83.4274 iter/s, 1.19865s/100 iter), loss = 0.121877
I0502 11:22:57.463117 26473 solver.cpp:261]     Train net output #0: loss = 0.121877 (* 1 = 0.121877 loss)
I0502 11:22:57.463125 26473 sgd_solver.cpp:106] Iteration 79000, lr = 2.09715e-05
I0502 11:22:58.403087 26473 solver.cpp:242] Iteration 79100 (93.0172 iter/s, 1.07507s/100 iter), loss = 0.738685
I0502 11:22:58.403128 26473 solver.cpp:261]     Train net output #0: loss = 0.738685 (* 1 = 0.738685 loss)
I0502 11:22:58.403137 26473 sgd_solver.cpp:106] Iteration 79100, lr = 2.09715e-05
I0502 11:22:58.407974 26473 solver.cpp:242] Iteration 79100 (105.839 iter/s, 0.944831s/100 iter), loss = 0.218055
I0502 11:22:58.407999 26473 solver.cpp:261]     Train net output #0: loss = 0.218055 (* 1 = 0.218055 loss)
I0502 11:22:58.408006 26473 sgd_solver.cpp:106] Iteration 79100, lr = 2.09715e-05
I0502 11:22:59.346995 26473 solver.cpp:242] Iteration 79200 (105.95 iter/s, 0.943837s/100 iter), loss = 0.172
I0502 11:22:59.347034 26473 solver.cpp:261]     Train net output #0: loss = 0.172 (* 1 = 0.172 loss)
I0502 11:22:59.347043 26473 sgd_solver.cpp:106] Iteration 79200, lr = 2.09715e-05
I0502 11:22:59.351825 26473 solver.cpp:242] Iteration 79200 (105.954 iter/s, 0.943809s/100 iter), loss = 0.0517341
I0502 11:22:59.351848 26473 solver.cpp:261]     Train net output #0: loss = 0.0517341 (* 1 = 0.0517341 loss)
I0502 11:22:59.351856 26473 sgd_solver.cpp:106] Iteration 79200, lr = 2.09715e-05
I0502 11:23:00.362880 26473 solver.cpp:242] Iteration 79300 (98.443 iter/s, 1.01582s/100 iter), loss = 0.113445
I0502 11:23:00.362924 26473 solver.cpp:261]     Train net output #0: loss = 0.113445 (* 1 = 0.113445 loss)
I0502 11:23:00.362933 26473 sgd_solver.cpp:106] Iteration 79300, lr = 2.09715e-05
I0502 11:23:00.367723 26473 solver.cpp:242] Iteration 79300 (98.439 iter/s, 1.01586s/100 iter), loss = 0.109244
I0502 11:23:00.367748 26473 solver.cpp:261]     Train net output #0: loss = 0.109244 (* 1 = 0.109244 loss)
I0502 11:23:00.367756 26473 sgd_solver.cpp:106] Iteration 79300, lr = 2.09715e-05
I0502 11:23:01.313591 26473 solver.cpp:242] Iteration 79400 (105.192 iter/s, 0.950642s/100 iter), loss = 0.334207
I0502 11:23:01.313634 26473 solver.cpp:261]     Train net output #0: loss = 0.334207 (* 1 = 0.334207 loss)
I0502 11:23:01.313644 26473 sgd_solver.cpp:106] Iteration 79400, lr = 2.09715e-05
I0502 11:23:01.318419 26473 solver.cpp:242] Iteration 79400 (105.191 iter/s, 0.950653s/100 iter), loss = 0.100661
I0502 11:23:01.318442 26473 solver.cpp:261]     Train net output #0: loss = 0.100661 (* 1 = 0.100661 loss)
I0502 11:23:01.318451 26473 sgd_solver.cpp:106] Iteration 79400, lr = 2.09715e-05
I0502 11:23:02.260929 26473 solver.cpp:362] Iteration 79500, Testing net (#0)
I0502 11:23:02.260951 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:02.385154 26473 solver.cpp:429]     Test net output #0: loss = 0.257711 (* 1 = 0.257711 loss)
I0502 11:23:02.388023 26473 solver.cpp:242] Iteration 79500 (93.0777 iter/s, 1.07437s/100 iter), loss = 0.246795
I0502 11:23:02.388043 26473 solver.cpp:261]     Train net output #0: loss = 0.246795 (* 1 = 0.246795 loss)
I0502 11:23:02.388051 26473 sgd_solver.cpp:106] Iteration 79500, lr = 2.09715e-05
I0502 11:23:02.389709 26473 solver.cpp:362] Iteration 79500, Testing net (#0)
I0502 11:23:02.389724 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:02.519938 26473 solver.cpp:429]     Test net output #0: accuracy = 0.955
I0502 11:23:02.519959 26473 solver.cpp:429]     Test net output #1: loss = 0.101443 (* 1 = 0.101443 loss)
I0502 11:23:02.522879 26473 solver.cpp:242] Iteration 79500 (83.0278 iter/s, 1.20442s/100 iter), loss = 0.261542
I0502 11:23:02.522899 26473 solver.cpp:261]     Train net output #0: loss = 0.261542 (* 1 = 0.261542 loss)
I0502 11:23:02.522907 26473 sgd_solver.cpp:106] Iteration 79500, lr = 2.09715e-05
I0502 11:23:03.462587 26473 solver.cpp:242] Iteration 79600 (93.065 iter/s, 1.07452s/100 iter), loss = 0.347342
I0502 11:23:03.462626 26473 solver.cpp:261]     Train net output #0: loss = 0.347342 (* 1 = 0.347342 loss)
I0502 11:23:03.462635 26473 sgd_solver.cpp:106] Iteration 79600, lr = 2.09715e-05
I0502 11:23:03.467449 26473 solver.cpp:242] Iteration 79600 (105.873 iter/s, 0.944523s/100 iter), loss = 0.0272078
I0502 11:23:03.467473 26473 solver.cpp:261]     Train net output #0: loss = 0.0272078 (* 1 = 0.0272078 loss)
I0502 11:23:03.467481 26473 sgd_solver.cpp:106] Iteration 79600, lr = 2.09715e-05
I0502 11:23:04.406220 26473 solver.cpp:242] Iteration 79700 (105.981 iter/s, 0.943564s/100 iter), loss = 0.407965
I0502 11:23:04.406260 26473 solver.cpp:261]     Train net output #0: loss = 0.407965 (* 1 = 0.407965 loss)
I0502 11:23:04.406268 26473 sgd_solver.cpp:106] Iteration 79700, lr = 2.09715e-05
I0502 11:23:04.411016 26473 solver.cpp:242] Iteration 79700 (105.986 iter/s, 0.943525s/100 iter), loss = 0.0636033
I0502 11:23:04.411039 26473 solver.cpp:261]     Train net output #0: loss = 0.0636033 (* 1 = 0.0636033 loss)
I0502 11:23:04.411047 26473 sgd_solver.cpp:106] Iteration 79700, lr = 2.09715e-05
I0502 11:23:05.350639 26473 solver.cpp:242] Iteration 79800 (105.893 iter/s, 0.944353s/100 iter), loss = 0.350194
I0502 11:23:05.350672 26473 solver.cpp:261]     Train net output #0: loss = 0.350194 (* 1 = 0.350194 loss)
I0502 11:23:05.350679 26473 sgd_solver.cpp:106] Iteration 79800, lr = 2.09715e-05
I0502 11:23:05.355456 26473 solver.cpp:242] Iteration 79800 (105.887 iter/s, 0.944399s/100 iter), loss = 0.207301
I0502 11:23:05.355479 26473 solver.cpp:261]     Train net output #0: loss = 0.207301 (* 1 = 0.207301 loss)
I0502 11:23:05.355486 26473 sgd_solver.cpp:106] Iteration 79800, lr = 2.09715e-05
I0502 11:23:06.294904 26473 solver.cpp:242] Iteration 79900 (105.909 iter/s, 0.944205s/100 iter), loss = 1.03142
I0502 11:23:06.294951 26473 solver.cpp:261]     Train net output #0: loss = 1.03142 (* 1 = 1.03142 loss)
I0502 11:23:06.294960 26473 sgd_solver.cpp:106] Iteration 79900, lr = 2.09715e-05
I0502 11:23:06.299721 26473 solver.cpp:242] Iteration 79900 (105.907 iter/s, 0.944224s/100 iter), loss = 0.23534
I0502 11:23:06.299744 26473 solver.cpp:261]     Train net output #0: loss = 0.23534 (* 1 = 0.23534 loss)
I0502 11:23:06.299753 26473 sgd_solver.cpp:106] Iteration 79900, lr = 2.09715e-05
I0502 11:23:07.236295 26473 solver.cpp:362] Iteration 80000, Testing net (#0)
I0502 11:23:07.236322 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:07.360530 26473 solver.cpp:429]     Test net output #0: loss = 0.264649 (* 1 = 0.264649 loss)
I0502 11:23:07.363402 26473 solver.cpp:242] Iteration 80000 (93.5951 iter/s, 1.06843s/100 iter), loss = 0.0685644
I0502 11:23:07.363423 26473 solver.cpp:261]     Train net output #0: loss = 0.0685644 (* 1 = 0.0685644 loss)
I0502 11:23:07.363432 26473 sgd_solver.cpp:106] Iteration 80000, lr = 1.67772e-05
I0502 11:23:07.365068 26473 solver.cpp:362] Iteration 80000, Testing net (#0)
I0502 11:23:07.365082 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:07.495594 26473 solver.cpp:429]     Test net output #0: accuracy = 0.942
I0502 11:23:07.495611 26473 solver.cpp:429]     Test net output #1: loss = 0.110653 (* 1 = 0.110653 loss)
I0502 11:23:07.498528 26473 solver.cpp:242] Iteration 80000 (83.4193 iter/s, 1.19876s/100 iter), loss = 0.0479417
I0502 11:23:07.498548 26473 solver.cpp:261]     Train net output #0: loss = 0.0479417 (* 1 = 0.0479417 loss)
I0502 11:23:07.498556 26473 sgd_solver.cpp:106] Iteration 80000, lr = 1.67772e-05
I0502 11:23:08.437192 26473 solver.cpp:242] Iteration 80100 (93.1324 iter/s, 1.07374s/100 iter), loss = 0.187841
I0502 11:23:08.437234 26473 solver.cpp:261]     Train net output #0: loss = 0.187841 (* 1 = 0.187841 loss)
I0502 11:23:08.437243 26473 sgd_solver.cpp:106] Iteration 80100, lr = 1.67772e-05
I0502 11:23:08.442049 26473 solver.cpp:242] Iteration 80100 (105.991 iter/s, 0.943474s/100 iter), loss = 0.0882325
I0502 11:23:08.442072 26473 solver.cpp:261]     Train net output #0: loss = 0.0882325 (* 1 = 0.0882325 loss)
I0502 11:23:08.442080 26473 sgd_solver.cpp:106] Iteration 80100, lr = 1.67772e-05
I0502 11:23:09.380607 26473 solver.cpp:242] Iteration 80200 (106.006 iter/s, 0.943341s/100 iter), loss = 0.0933521
I0502 11:23:09.380736 26473 solver.cpp:261]     Train net output #0: loss = 0.0933521 (* 1 = 0.0933521 loss)
I0502 11:23:09.380781 26473 sgd_solver.cpp:106] Iteration 80200, lr = 1.67772e-05
I0502 11:23:09.388795 26473 solver.cpp:242] Iteration 80200 (105.63 iter/s, 0.946698s/100 iter), loss = 0.116619
I0502 11:23:09.388854 26473 solver.cpp:261]     Train net output #0: loss = 0.116619 (* 1 = 0.116619 loss)
I0502 11:23:09.388877 26473 sgd_solver.cpp:106] Iteration 80200, lr = 1.67772e-05
I0502 11:23:10.392828 26473 solver.cpp:242] Iteration 80300 (98.8067 iter/s, 1.01208s/100 iter), loss = 0.194263
I0502 11:23:10.392871 26473 solver.cpp:261]     Train net output #0: loss = 0.194263 (* 1 = 0.194263 loss)
I0502 11:23:10.392881 26473 sgd_solver.cpp:106] Iteration 80300, lr = 1.67772e-05
I0502 11:23:10.397727 26473 solver.cpp:242] Iteration 80300 (99.1217 iter/s, 1.00886s/100 iter), loss = 0.0539842
I0502 11:23:10.397750 26473 solver.cpp:261]     Train net output #0: loss = 0.0539842 (* 1 = 0.0539842 loss)
I0502 11:23:10.397759 26473 sgd_solver.cpp:106] Iteration 80300, lr = 1.67772e-05
I0502 11:23:11.338237 26473 solver.cpp:242] Iteration 80400 (105.782 iter/s, 0.945336s/100 iter), loss = 0.159648
I0502 11:23:11.338276 26473 solver.cpp:261]     Train net output #0: loss = 0.159648 (* 1 = 0.159648 loss)
I0502 11:23:11.338284 26473 sgd_solver.cpp:106] Iteration 80400, lr = 1.67772e-05
I0502 11:23:11.343042 26473 solver.cpp:242] Iteration 80400 (105.789 iter/s, 0.945274s/100 iter), loss = 0.144055
I0502 11:23:11.343065 26473 solver.cpp:261]     Train net output #0: loss = 0.144055 (* 1 = 0.144055 loss)
I0502 11:23:11.343073 26473 sgd_solver.cpp:106] Iteration 80400, lr = 1.67772e-05
I0502 11:23:12.279440 26473 solver.cpp:362] Iteration 80500, Testing net (#0)
I0502 11:23:12.279467 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:12.403641 26473 solver.cpp:429]     Test net output #0: loss = 0.238614 (* 1 = 0.238614 loss)
I0502 11:23:12.406524 26473 solver.cpp:242] Iteration 80500 (93.6127 iter/s, 1.06823s/100 iter), loss = 0.407934
I0502 11:23:12.406545 26473 solver.cpp:261]     Train net output #0: loss = 0.407934 (* 1 = 0.407934 loss)
I0502 11:23:12.406563 26473 sgd_solver.cpp:106] Iteration 80500, lr = 1.67772e-05
I0502 11:23:12.408190 26473 solver.cpp:362] Iteration 80500, Testing net (#0)
I0502 11:23:12.408202 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:12.538925 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:23:12.538946 26473 solver.cpp:429]     Test net output #1: loss = 0.096449 (* 1 = 0.096449 loss)
I0502 11:23:12.541858 26473 solver.cpp:242] Iteration 80500 (83.4186 iter/s, 1.19877s/100 iter), loss = 0.0838984
I0502 11:23:12.541878 26473 solver.cpp:261]     Train net output #0: loss = 0.0838984 (* 1 = 0.0838984 loss)
I0502 11:23:12.541887 26473 sgd_solver.cpp:106] Iteration 80500, lr = 1.67772e-05
I0502 11:23:13.481909 26473 solver.cpp:242] Iteration 80600 (92.9942 iter/s, 1.07534s/100 iter), loss = 0.525002
I0502 11:23:13.481952 26473 solver.cpp:261]     Train net output #0: loss = 0.525002 (* 1 = 0.525002 loss)
I0502 11:23:13.481961 26473 sgd_solver.cpp:106] Iteration 80600, lr = 1.67772e-05
I0502 11:23:13.486793 26473 solver.cpp:242] Iteration 80600 (105.833 iter/s, 0.944889s/100 iter), loss = 0.0730615
I0502 11:23:13.486816 26473 solver.cpp:261]     Train net output #0: loss = 0.0730615 (* 1 = 0.0730615 loss)
I0502 11:23:13.486824 26473 sgd_solver.cpp:106] Iteration 80600, lr = 1.67772e-05
I0502 11:23:14.425935 26473 solver.cpp:242] Iteration 80700 (105.937 iter/s, 0.943954s/100 iter), loss = 0.50375
I0502 11:23:14.425990 26473 solver.cpp:261]     Train net output #0: loss = 0.50375 (* 1 = 0.50375 loss)
I0502 11:23:14.425999 26473 sgd_solver.cpp:106] Iteration 80700, lr = 1.67772e-05
I0502 11:23:14.430814 26473 solver.cpp:242] Iteration 80700 (105.935 iter/s, 0.943978s/100 iter), loss = 0.06654
I0502 11:23:14.430836 26473 solver.cpp:261]     Train net output #0: loss = 0.06654 (* 1 = 0.06654 loss)
I0502 11:23:14.430845 26473 sgd_solver.cpp:106] Iteration 80700, lr = 1.67772e-05
I0502 11:23:15.369848 26473 solver.cpp:242] Iteration 80800 (105.952 iter/s, 0.943827s/100 iter), loss = 0.366808
I0502 11:23:15.369887 26473 solver.cpp:261]     Train net output #0: loss = 0.366808 (* 1 = 0.366808 loss)
I0502 11:23:15.369896 26473 sgd_solver.cpp:106] Iteration 80800, lr = 1.67772e-05
I0502 11:23:15.374660 26473 solver.cpp:242] Iteration 80800 (105.954 iter/s, 0.943804s/100 iter), loss = 0.0861435
I0502 11:23:15.374682 26473 solver.cpp:261]     Train net output #0: loss = 0.0861435 (* 1 = 0.0861435 loss)
I0502 11:23:15.374691 26473 sgd_solver.cpp:106] Iteration 80800, lr = 1.67772e-05
I0502 11:23:16.317785 26473 solver.cpp:242] Iteration 80900 (105.5 iter/s, 0.947868s/100 iter), loss = 0.0572382
I0502 11:23:16.317823 26473 solver.cpp:261]     Train net output #0: loss = 0.0572382 (* 1 = 0.0572382 loss)
I0502 11:23:16.317833 26473 sgd_solver.cpp:106] Iteration 80900, lr = 1.67772e-05
I0502 11:23:16.322592 26473 solver.cpp:242] Iteration 80900 (105.497 iter/s, 0.947892s/100 iter), loss = 0.0760171
I0502 11:23:16.322615 26473 solver.cpp:261]     Train net output #0: loss = 0.0760171 (* 1 = 0.0760171 loss)
I0502 11:23:16.322624 26473 sgd_solver.cpp:106] Iteration 80900, lr = 1.67772e-05
I0502 11:23:17.258137 26473 solver.cpp:362] Iteration 81000, Testing net (#0)
I0502 11:23:17.258160 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:17.382484 26473 solver.cpp:429]     Test net output #0: loss = 0.343524 (* 1 = 0.343524 loss)
I0502 11:23:17.385365 26473 solver.cpp:242] Iteration 81000 (93.6749 iter/s, 1.06752s/100 iter), loss = 0.506106
I0502 11:23:17.385385 26473 solver.cpp:261]     Train net output #0: loss = 0.506106 (* 1 = 0.506106 loss)
I0502 11:23:17.385392 26473 sgd_solver.cpp:106] Iteration 81000, lr = 1.67772e-05
I0502 11:23:17.387014 26473 solver.cpp:362] Iteration 81000, Testing net (#0)
I0502 11:23:17.387028 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:17.517627 26473 solver.cpp:429]     Test net output #0: accuracy = 0.959
I0502 11:23:17.517647 26473 solver.cpp:429]     Test net output #1: loss = 0.100968 (* 1 = 0.100968 loss)
I0502 11:23:17.520589 26473 solver.cpp:242] Iteration 81000 (83.4757 iter/s, 1.19795s/100 iter), loss = 0.0897637
I0502 11:23:17.520611 26473 solver.cpp:261]     Train net output #0: loss = 0.0897637 (* 1 = 0.0897637 loss)
I0502 11:23:17.520619 26473 sgd_solver.cpp:106] Iteration 81000, lr = 1.67772e-05
I0502 11:23:18.459975 26473 solver.cpp:242] Iteration 81100 (93.0611 iter/s, 1.07456s/100 iter), loss = 0.314987
I0502 11:23:18.460018 26473 solver.cpp:261]     Train net output #0: loss = 0.314987 (* 1 = 0.314987 loss)
I0502 11:23:18.460027 26473 sgd_solver.cpp:106] Iteration 81100, lr = 1.67772e-05
I0502 11:23:18.464886 26473 solver.cpp:242] Iteration 81100 (105.904 iter/s, 0.944248s/100 iter), loss = 0.0529166
I0502 11:23:18.464910 26473 solver.cpp:261]     Train net output #0: loss = 0.0529166 (* 1 = 0.0529166 loss)
I0502 11:23:18.464918 26473 sgd_solver.cpp:106] Iteration 81100, lr = 1.67772e-05
I0502 11:23:19.403404 26473 solver.cpp:242] Iteration 81200 (106.004 iter/s, 0.943363s/100 iter), loss = 1.06011
I0502 11:23:19.403441 26473 solver.cpp:261]     Train net output #0: loss = 1.06011 (* 1 = 1.06011 loss)
I0502 11:23:19.403450 26473 sgd_solver.cpp:106] Iteration 81200, lr = 1.67772e-05
I0502 11:23:19.408253 26473 solver.cpp:242] Iteration 81200 (106.009 iter/s, 0.94332s/100 iter), loss = 0.126358
I0502 11:23:19.408275 26473 solver.cpp:261]     Train net output #0: loss = 0.126358 (* 1 = 0.126358 loss)
I0502 11:23:19.408284 26473 sgd_solver.cpp:106] Iteration 81200, lr = 1.67772e-05
I0502 11:23:20.347160 26473 solver.cpp:242] Iteration 81300 (105.967 iter/s, 0.94369s/100 iter), loss = 0.0811385
I0502 11:23:20.347199 26473 solver.cpp:261]     Train net output #0: loss = 0.0811385 (* 1 = 0.0811385 loss)
I0502 11:23:20.347208 26473 sgd_solver.cpp:106] Iteration 81300, lr = 1.67772e-05
I0502 11:23:20.351972 26473 solver.cpp:242] Iteration 81300 (105.968 iter/s, 0.94368s/100 iter), loss = 0.0946807
I0502 11:23:20.351995 26473 solver.cpp:261]     Train net output #0: loss = 0.0946807 (* 1 = 0.0946807 loss)
I0502 11:23:20.352005 26473 sgd_solver.cpp:106] Iteration 81300, lr = 1.67772e-05
I0502 11:23:21.291237 26473 solver.cpp:242] Iteration 81400 (105.931 iter/s, 0.944011s/100 iter), loss = 0.0956068
I0502 11:23:21.291270 26473 solver.cpp:261]     Train net output #0: loss = 0.0956068 (* 1 = 0.0956068 loss)
I0502 11:23:21.291280 26473 sgd_solver.cpp:106] Iteration 81400, lr = 1.67772e-05
I0502 11:23:21.296057 26473 solver.cpp:242] Iteration 81400 (105.927 iter/s, 0.944043s/100 iter), loss = 0.0742182
I0502 11:23:21.296079 26473 solver.cpp:261]     Train net output #0: loss = 0.0742182 (* 1 = 0.0742182 loss)
I0502 11:23:21.296087 26473 sgd_solver.cpp:106] Iteration 81400, lr = 1.67772e-05
I0502 11:23:22.231860 26473 solver.cpp:362] Iteration 81500, Testing net (#0)
I0502 11:23:22.231889 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:22.356184 26473 solver.cpp:429]     Test net output #0: loss = 0.253568 (* 1 = 0.253568 loss)
I0502 11:23:22.359050 26473 solver.cpp:242] Iteration 81500 (93.654 iter/s, 1.06776s/100 iter), loss = 0.438394
I0502 11:23:22.359068 26473 solver.cpp:261]     Train net output #0: loss = 0.438394 (* 1 = 0.438394 loss)
I0502 11:23:22.359077 26473 sgd_solver.cpp:106] Iteration 81500, lr = 1.67772e-05
I0502 11:23:22.360705 26473 solver.cpp:362] Iteration 81500, Testing net (#0)
I0502 11:23:22.360718 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:22.491447 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:23:22.491472 26473 solver.cpp:429]     Test net output #1: loss = 0.100079 (* 1 = 0.100079 loss)
I0502 11:23:22.494396 26473 solver.cpp:242] Iteration 81500 (83.4519 iter/s, 1.19829s/100 iter), loss = 0.168944
I0502 11:23:22.494416 26473 solver.cpp:261]     Train net output #0: loss = 0.168944 (* 1 = 0.168944 loss)
I0502 11:23:22.494424 26473 sgd_solver.cpp:106] Iteration 81500, lr = 1.67772e-05
I0502 11:23:23.433306 26473 solver.cpp:242] Iteration 81600 (93.0916 iter/s, 1.07421s/100 iter), loss = 0.123681
I0502 11:23:23.433348 26473 solver.cpp:261]     Train net output #0: loss = 0.123681 (* 1 = 0.123681 loss)
I0502 11:23:23.433358 26473 sgd_solver.cpp:106] Iteration 81600, lr = 1.67772e-05
I0502 11:23:23.438123 26473 solver.cpp:242] Iteration 81600 (105.967 iter/s, 0.943689s/100 iter), loss = 0.0478489
I0502 11:23:23.438146 26473 solver.cpp:261]     Train net output #0: loss = 0.0478489 (* 1 = 0.0478489 loss)
I0502 11:23:23.438155 26473 sgd_solver.cpp:106] Iteration 81600, lr = 1.67772e-05
I0502 11:23:24.376850 26473 solver.cpp:242] Iteration 81700 (105.991 iter/s, 0.943479s/100 iter), loss = 0.0392876
I0502 11:23:24.376883 26473 solver.cpp:261]     Train net output #0: loss = 0.0392876 (* 1 = 0.0392876 loss)
I0502 11:23:24.376902 26473 sgd_solver.cpp:106] Iteration 81700, lr = 1.67772e-05
I0502 11:23:24.381729 26473 solver.cpp:242] Iteration 81700 (105.982 iter/s, 0.943557s/100 iter), loss = 0.293495
I0502 11:23:24.381752 26473 solver.cpp:261]     Train net output #0: loss = 0.293495 (* 1 = 0.293495 loss)
I0502 11:23:24.381760 26473 sgd_solver.cpp:106] Iteration 81700, lr = 1.67772e-05
I0502 11:23:25.320559 26473 solver.cpp:242] Iteration 81800 (105.973 iter/s, 0.943639s/100 iter), loss = 0.121735
I0502 11:23:25.320616 26473 solver.cpp:261]     Train net output #0: loss = 0.121735 (* 1 = 0.121735 loss)
I0502 11:23:25.320626 26473 sgd_solver.cpp:106] Iteration 81800, lr = 1.67772e-05
I0502 11:23:25.325453 26473 solver.cpp:242] Iteration 81800 (105.968 iter/s, 0.943684s/100 iter), loss = 0.146134
I0502 11:23:25.325476 26473 solver.cpp:261]     Train net output #0: loss = 0.146134 (* 1 = 0.146134 loss)
I0502 11:23:25.325485 26473 sgd_solver.cpp:106] Iteration 81800, lr = 1.67772e-05
I0502 11:23:26.263558 26473 solver.cpp:242] Iteration 81900 (106.054 iter/s, 0.942914s/100 iter), loss = 0.391643
I0502 11:23:26.263603 26473 solver.cpp:261]     Train net output #0: loss = 0.391643 (* 1 = 0.391643 loss)
I0502 11:23:26.263612 26473 sgd_solver.cpp:106] Iteration 81900, lr = 1.67772e-05
I0502 11:23:26.268380 26473 solver.cpp:242] Iteration 81900 (106.057 iter/s, 0.942886s/100 iter), loss = 0.0977529
I0502 11:23:26.268404 26473 solver.cpp:261]     Train net output #0: loss = 0.0977529 (* 1 = 0.0977529 loss)
I0502 11:23:26.268412 26473 sgd_solver.cpp:106] Iteration 81900, lr = 1.67772e-05
I0502 11:23:27.204489 26473 solver.cpp:362] Iteration 82000, Testing net (#0)
I0502 11:23:27.204519 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:27.329047 26473 solver.cpp:429]     Test net output #0: loss = 0.275904 (* 1 = 0.275904 loss)
I0502 11:23:27.331920 26473 solver.cpp:242] Iteration 82000 (93.6067 iter/s, 1.0683s/100 iter), loss = 0.214415
I0502 11:23:27.331940 26473 solver.cpp:261]     Train net output #0: loss = 0.214415 (* 1 = 0.214415 loss)
I0502 11:23:27.331948 26473 sgd_solver.cpp:106] Iteration 82000, lr = 1.67772e-05
I0502 11:23:27.333580 26473 solver.cpp:362] Iteration 82000, Testing net (#0)
I0502 11:23:27.333595 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:27.464188 26473 solver.cpp:429]     Test net output #0: accuracy = 0.955
I0502 11:23:27.464208 26473 solver.cpp:429]     Test net output #1: loss = 0.110028 (* 1 = 0.110028 loss)
I0502 11:23:27.467128 26473 solver.cpp:242] Iteration 82000 (83.4235 iter/s, 1.1987s/100 iter), loss = 0.0330057
I0502 11:23:27.467149 26473 solver.cpp:261]     Train net output #0: loss = 0.0330057 (* 1 = 0.0330057 loss)
I0502 11:23:27.467157 26473 sgd_solver.cpp:106] Iteration 82000, lr = 1.67772e-05
I0502 11:23:28.405661 26473 solver.cpp:242] Iteration 82100 (93.1365 iter/s, 1.07369s/100 iter), loss = 0.502064
I0502 11:23:28.405705 26473 solver.cpp:261]     Train net output #0: loss = 0.502064 (* 1 = 0.502064 loss)
I0502 11:23:28.405714 26473 sgd_solver.cpp:106] Iteration 82100, lr = 1.67772e-05
I0502 11:23:28.410471 26473 solver.cpp:242] Iteration 82100 (106.01 iter/s, 0.943304s/100 iter), loss = 0.117893
I0502 11:23:28.410495 26473 solver.cpp:261]     Train net output #0: loss = 0.117893 (* 1 = 0.117893 loss)
I0502 11:23:28.410503 26473 sgd_solver.cpp:106] Iteration 82100, lr = 1.67772e-05
I0502 11:23:29.349169 26473 solver.cpp:242] Iteration 82200 (105.995 iter/s, 0.943439s/100 iter), loss = 0.0884272
I0502 11:23:29.349212 26473 solver.cpp:261]     Train net output #0: loss = 0.0884272 (* 1 = 0.0884272 loss)
I0502 11:23:29.349221 26473 sgd_solver.cpp:106] Iteration 82200, lr = 1.67772e-05
I0502 11:23:29.354044 26473 solver.cpp:242] Iteration 82200 (105.986 iter/s, 0.943524s/100 iter), loss = 0.053417
I0502 11:23:29.354068 26473 solver.cpp:261]     Train net output #0: loss = 0.053417 (* 1 = 0.053417 loss)
I0502 11:23:29.354076 26473 sgd_solver.cpp:106] Iteration 82200, lr = 1.67772e-05
I0502 11:23:30.292482 26473 solver.cpp:242] Iteration 82300 (106.018 iter/s, 0.94324s/100 iter), loss = 0.362638
I0502 11:23:30.292526 26473 solver.cpp:261]     Train net output #0: loss = 0.362638 (* 1 = 0.362638 loss)
I0502 11:23:30.292536 26473 sgd_solver.cpp:106] Iteration 82300, lr = 1.67772e-05
I0502 11:23:30.297297 26473 solver.cpp:242] Iteration 82300 (106.021 iter/s, 0.94321s/100 iter), loss = 0.0857451
I0502 11:23:30.297320 26473 solver.cpp:261]     Train net output #0: loss = 0.0857451 (* 1 = 0.0857451 loss)
I0502 11:23:30.297329 26473 sgd_solver.cpp:106] Iteration 82300, lr = 1.67772e-05
I0502 11:23:31.256266 26473 solver.cpp:242] Iteration 82400 (103.766 iter/s, 0.963711s/100 iter), loss = 0.106213
I0502 11:23:31.256307 26473 solver.cpp:261]     Train net output #0: loss = 0.106213 (* 1 = 0.106213 loss)
I0502 11:23:31.256316 26473 sgd_solver.cpp:106] Iteration 82400, lr = 1.67772e-05
I0502 11:23:31.261114 26473 solver.cpp:242] Iteration 82400 (103.759 iter/s, 0.963776s/100 iter), loss = 0.217782
I0502 11:23:31.261138 26473 solver.cpp:261]     Train net output #0: loss = 0.217782 (* 1 = 0.217782 loss)
I0502 11:23:31.261147 26473 sgd_solver.cpp:106] Iteration 82400, lr = 1.67772e-05
I0502 11:23:32.196234 26473 solver.cpp:362] Iteration 82500, Testing net (#0)
I0502 11:23:32.196260 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:32.320552 26473 solver.cpp:429]     Test net output #0: loss = 0.274659 (* 1 = 0.274659 loss)
I0502 11:23:32.323420 26473 solver.cpp:242] Iteration 82500 (93.7124 iter/s, 1.06709s/100 iter), loss = 0.206578
I0502 11:23:32.323439 26473 solver.cpp:261]     Train net output #0: loss = 0.206578 (* 1 = 0.206578 loss)
I0502 11:23:32.323448 26473 sgd_solver.cpp:106] Iteration 82500, lr = 1.67772e-05
I0502 11:23:32.325083 26473 solver.cpp:362] Iteration 82500, Testing net (#0)
I0502 11:23:32.325095 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:32.455793 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9265
I0502 11:23:32.455814 26473 solver.cpp:429]     Test net output #1: loss = 0.142165 (* 1 = 0.142165 loss)
I0502 11:23:32.458726 26473 solver.cpp:242] Iteration 82500 (83.5026 iter/s, 1.19757s/100 iter), loss = 0.120854
I0502 11:23:32.458746 26473 solver.cpp:261]     Train net output #0: loss = 0.120854 (* 1 = 0.120854 loss)
I0502 11:23:32.458755 26473 sgd_solver.cpp:106] Iteration 82500, lr = 1.67772e-05
I0502 11:23:33.397644 26473 solver.cpp:242] Iteration 82600 (93.0949 iter/s, 1.07417s/100 iter), loss = 0.124307
I0502 11:23:33.397685 26473 solver.cpp:261]     Train net output #0: loss = 0.124307 (* 1 = 0.124307 loss)
I0502 11:23:33.397693 26473 sgd_solver.cpp:106] Iteration 82600, lr = 1.67772e-05
I0502 11:23:33.402453 26473 solver.cpp:242] Iteration 82600 (105.967 iter/s, 0.943688s/100 iter), loss = 0.0593464
I0502 11:23:33.402477 26473 solver.cpp:261]     Train net output #0: loss = 0.0593464 (* 1 = 0.0593464 loss)
I0502 11:23:33.402485 26473 sgd_solver.cpp:106] Iteration 82600, lr = 1.67772e-05
I0502 11:23:34.341267 26473 solver.cpp:242] Iteration 82700 (105.982 iter/s, 0.94356s/100 iter), loss = 0.130124
I0502 11:23:34.341306 26473 solver.cpp:261]     Train net output #0: loss = 0.130124 (* 1 = 0.130124 loss)
I0502 11:23:34.341315 26473 sgd_solver.cpp:106] Iteration 82700, lr = 1.67772e-05
I0502 11:23:34.346138 26473 solver.cpp:242] Iteration 82700 (105.973 iter/s, 0.943635s/100 iter), loss = 0.105864
I0502 11:23:34.346163 26473 solver.cpp:261]     Train net output #0: loss = 0.105864 (* 1 = 0.105864 loss)
I0502 11:23:34.346180 26473 sgd_solver.cpp:106] Iteration 82700, lr = 1.67772e-05
I0502 11:23:35.285317 26473 solver.cpp:242] Iteration 82800 (105.935 iter/s, 0.943979s/100 iter), loss = 0.171875
I0502 11:23:35.285358 26473 solver.cpp:261]     Train net output #0: loss = 0.171875 (* 1 = 0.171875 loss)
I0502 11:23:35.285367 26473 sgd_solver.cpp:106] Iteration 82800, lr = 1.67772e-05
I0502 11:23:35.290107 26473 solver.cpp:242] Iteration 82800 (105.94 iter/s, 0.943928s/100 iter), loss = 0.0888076
I0502 11:23:35.290129 26473 solver.cpp:261]     Train net output #0: loss = 0.0888076 (* 1 = 0.0888076 loss)
I0502 11:23:35.290138 26473 sgd_solver.cpp:106] Iteration 82800, lr = 1.67772e-05
I0502 11:23:36.228983 26473 solver.cpp:242] Iteration 82900 (105.977 iter/s, 0.943598s/100 iter), loss = 0.185411
I0502 11:23:36.229020 26473 solver.cpp:261]     Train net output #0: loss = 0.185411 (* 1 = 0.185411 loss)
I0502 11:23:36.229029 26473 sgd_solver.cpp:106] Iteration 82900, lr = 1.67772e-05
I0502 11:23:36.233775 26473 solver.cpp:242] Iteration 82900 (105.974 iter/s, 0.943628s/100 iter), loss = 0.0555523
I0502 11:23:36.233799 26473 solver.cpp:261]     Train net output #0: loss = 0.0555523 (* 1 = 0.0555523 loss)
I0502 11:23:36.233808 26473 sgd_solver.cpp:106] Iteration 82900, lr = 1.67772e-05
I0502 11:23:37.169766 26473 solver.cpp:362] Iteration 83000, Testing net (#0)
I0502 11:23:37.169787 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:37.294229 26473 solver.cpp:429]     Test net output #0: loss = 0.327269 (* 1 = 0.327269 loss)
I0502 11:23:37.297094 26473 solver.cpp:242] Iteration 83000 (93.6281 iter/s, 1.06806s/100 iter), loss = 0.195443
I0502 11:23:37.297113 26473 solver.cpp:261]     Train net output #0: loss = 0.195443 (* 1 = 0.195443 loss)
I0502 11:23:37.297122 26473 sgd_solver.cpp:106] Iteration 83000, lr = 1.67772e-05
I0502 11:23:37.298786 26473 solver.cpp:362] Iteration 83000, Testing net (#0)
I0502 11:23:37.298799 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:37.429482 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9335
I0502 11:23:37.429502 26473 solver.cpp:429]     Test net output #1: loss = 0.137455 (* 1 = 0.137455 loss)
I0502 11:23:37.432415 26473 solver.cpp:242] Iteration 83000 (83.431 iter/s, 1.1986s/100 iter), loss = 0.0025507
I0502 11:23:37.432435 26473 solver.cpp:261]     Train net output #0: loss = 0.0025507 (* 1 = 0.0025507 loss)
I0502 11:23:37.432442 26473 sgd_solver.cpp:106] Iteration 83000, lr = 1.67772e-05
I0502 11:23:38.371832 26473 solver.cpp:242] Iteration 83100 (93.0501 iter/s, 1.07469s/100 iter), loss = 0.105214
I0502 11:23:38.371866 26473 solver.cpp:261]     Train net output #0: loss = 0.105214 (* 1 = 0.105214 loss)
I0502 11:23:38.371876 26473 sgd_solver.cpp:106] Iteration 83100, lr = 1.67772e-05
I0502 11:23:38.376652 26473 solver.cpp:242] Iteration 83100 (105.91 iter/s, 0.9442s/100 iter), loss = 0.0863291
I0502 11:23:38.376677 26473 solver.cpp:261]     Train net output #0: loss = 0.0863291 (* 1 = 0.0863291 loss)
I0502 11:23:38.376684 26473 sgd_solver.cpp:106] Iteration 83100, lr = 1.67772e-05
I0502 11:23:39.316287 26473 solver.cpp:242] Iteration 83200 (105.888 iter/s, 0.944397s/100 iter), loss = 0.207473
I0502 11:23:39.316319 26473 solver.cpp:261]     Train net output #0: loss = 0.207473 (* 1 = 0.207473 loss)
I0502 11:23:39.316329 26473 sgd_solver.cpp:106] Iteration 83200, lr = 1.67772e-05
I0502 11:23:39.321167 26473 solver.cpp:242] Iteration 83200 (105.88 iter/s, 0.944465s/100 iter), loss = 0.154915
I0502 11:23:39.321189 26473 solver.cpp:261]     Train net output #0: loss = 0.154915 (* 1 = 0.154915 loss)
I0502 11:23:39.321198 26473 sgd_solver.cpp:106] Iteration 83200, lr = 1.67772e-05
I0502 11:23:40.259598 26473 solver.cpp:242] Iteration 83300 (106.017 iter/s, 0.943246s/100 iter), loss = 0.26515
I0502 11:23:40.259629 26473 solver.cpp:261]     Train net output #0: loss = 0.26515 (* 1 = 0.26515 loss)
I0502 11:23:40.259639 26473 sgd_solver.cpp:106] Iteration 83300, lr = 1.67772e-05
I0502 11:23:40.264408 26473 solver.cpp:242] Iteration 83300 (106.022 iter/s, 0.9432s/100 iter), loss = 0.187087
I0502 11:23:40.264431 26473 solver.cpp:261]     Train net output #0: loss = 0.187087 (* 1 = 0.187087 loss)
I0502 11:23:40.264441 26473 sgd_solver.cpp:106] Iteration 83300, lr = 1.67772e-05
I0502 11:23:41.202972 26473 solver.cpp:242] Iteration 83400 (106.009 iter/s, 0.943316s/100 iter), loss = 0.131424
I0502 11:23:41.203002 26473 solver.cpp:261]     Train net output #0: loss = 0.131424 (* 1 = 0.131424 loss)
I0502 11:23:41.203011 26473 sgd_solver.cpp:106] Iteration 83400, lr = 1.67772e-05
I0502 11:23:41.207792 26473 solver.cpp:242] Iteration 83400 (106.006 iter/s, 0.943342s/100 iter), loss = 0.165728
I0502 11:23:41.207813 26473 solver.cpp:261]     Train net output #0: loss = 0.165728 (* 1 = 0.165728 loss)
I0502 11:23:41.207823 26473 sgd_solver.cpp:106] Iteration 83400, lr = 1.67772e-05
I0502 11:23:42.143080 26473 solver.cpp:362] Iteration 83500, Testing net (#0)
I0502 11:23:42.143108 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:42.267390 26473 solver.cpp:429]     Test net output #0: loss = 0.272896 (* 1 = 0.272896 loss)
I0502 11:23:42.270252 26473 solver.cpp:242] Iteration 83500 (93.7004 iter/s, 1.06723s/100 iter), loss = 0.12893
I0502 11:23:42.270272 26473 solver.cpp:261]     Train net output #0: loss = 0.12893 (* 1 = 0.12893 loss)
I0502 11:23:42.270282 26473 sgd_solver.cpp:106] Iteration 83500, lr = 1.67772e-05
I0502 11:23:42.271940 26473 solver.cpp:362] Iteration 83500, Testing net (#0)
I0502 11:23:42.271955 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:42.402664 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:23:42.402685 26473 solver.cpp:429]     Test net output #1: loss = 0.094437 (* 1 = 0.094437 loss)
I0502 11:23:42.405625 26473 solver.cpp:242] Iteration 83500 (83.487 iter/s, 1.19779s/100 iter), loss = 0.0935116
I0502 11:23:42.405647 26473 solver.cpp:261]     Train net output #0: loss = 0.0935116 (* 1 = 0.0935116 loss)
I0502 11:23:42.405655 26473 sgd_solver.cpp:106] Iteration 83500, lr = 1.67772e-05
I0502 11:23:43.345347 26473 solver.cpp:242] Iteration 83600 (93.0195 iter/s, 1.07504s/100 iter), loss = 0.259825
I0502 11:23:43.345391 26473 solver.cpp:261]     Train net output #0: loss = 0.259825 (* 1 = 0.259825 loss)
I0502 11:23:43.345401 26473 sgd_solver.cpp:106] Iteration 83600, lr = 1.67772e-05
I0502 11:23:43.350155 26473 solver.cpp:242] Iteration 83600 (105.877 iter/s, 0.944492s/100 iter), loss = 0.252938
I0502 11:23:43.350178 26473 solver.cpp:261]     Train net output #0: loss = 0.252938 (* 1 = 0.252938 loss)
I0502 11:23:43.350188 26473 sgd_solver.cpp:106] Iteration 83600, lr = 1.67772e-05
I0502 11:23:44.288913 26473 solver.cpp:242] Iteration 83700 (105.989 iter/s, 0.943497s/100 iter), loss = 0.175366
I0502 11:23:44.288954 26473 solver.cpp:261]     Train net output #0: loss = 0.175366 (* 1 = 0.175366 loss)
I0502 11:23:44.288964 26473 sgd_solver.cpp:106] Iteration 83700, lr = 1.67772e-05
I0502 11:23:44.293792 26473 solver.cpp:242] Iteration 83700 (105.979 iter/s, 0.943586s/100 iter), loss = 0.05412
I0502 11:23:44.293817 26473 solver.cpp:261]     Train net output #0: loss = 0.05412 (* 1 = 0.05412 loss)
I0502 11:23:44.293824 26473 sgd_solver.cpp:106] Iteration 83700, lr = 1.67772e-05
I0502 11:23:45.233327 26473 solver.cpp:242] Iteration 83800 (105.893 iter/s, 0.944349s/100 iter), loss = 0.244836
I0502 11:23:45.233371 26473 solver.cpp:261]     Train net output #0: loss = 0.244836 (* 1 = 0.244836 loss)
I0502 11:23:45.233381 26473 sgd_solver.cpp:106] Iteration 83800, lr = 1.67772e-05
I0502 11:23:45.238196 26473 solver.cpp:242] Iteration 83800 (105.892 iter/s, 0.944355s/100 iter), loss = 0.121482
I0502 11:23:45.238219 26473 solver.cpp:261]     Train net output #0: loss = 0.121482 (* 1 = 0.121482 loss)
I0502 11:23:45.238229 26473 sgd_solver.cpp:106] Iteration 83800, lr = 1.67772e-05
I0502 11:23:46.177384 26473 solver.cpp:242] Iteration 83900 (105.934 iter/s, 0.943983s/100 iter), loss = 0.144138
I0502 11:23:46.177430 26473 solver.cpp:261]     Train net output #0: loss = 0.144138 (* 1 = 0.144138 loss)
I0502 11:23:46.177459 26473 sgd_solver.cpp:106] Iteration 83900, lr = 1.67772e-05
I0502 11:23:46.182241 26473 solver.cpp:242] Iteration 83900 (105.932 iter/s, 0.944004s/100 iter), loss = 0.015063
I0502 11:23:46.182266 26473 solver.cpp:261]     Train net output #0: loss = 0.015063 (* 1 = 0.015063 loss)
I0502 11:23:46.182274 26473 sgd_solver.cpp:106] Iteration 83900, lr = 1.67772e-05
I0502 11:23:47.118878 26473 solver.cpp:362] Iteration 84000, Testing net (#0)
I0502 11:23:47.118909 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:47.243182 26473 solver.cpp:429]     Test net output #0: loss = 0.267928 (* 1 = 0.267928 loss)
I0502 11:23:47.246049 26473 solver.cpp:242] Iteration 84000 (93.5802 iter/s, 1.0686s/100 iter), loss = 0.232327
I0502 11:23:47.246070 26473 solver.cpp:261]     Train net output #0: loss = 0.232327 (* 1 = 0.232327 loss)
I0502 11:23:47.246078 26473 sgd_solver.cpp:106] Iteration 84000, lr = 1.67772e-05
I0502 11:23:47.247704 26473 solver.cpp:362] Iteration 84000, Testing net (#0)
I0502 11:23:47.247716 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:47.378198 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:23:47.378221 26473 solver.cpp:429]     Test net output #1: loss = 0.0982298 (* 1 = 0.0982298 loss)
I0502 11:23:47.381156 26473 solver.cpp:242] Iteration 84000 (83.4119 iter/s, 1.19887s/100 iter), loss = 0.113424
I0502 11:23:47.381176 26473 solver.cpp:261]     Train net output #0: loss = 0.113424 (* 1 = 0.113424 loss)
I0502 11:23:47.381186 26473 sgd_solver.cpp:106] Iteration 84000, lr = 1.67772e-05
I0502 11:23:48.319825 26473 solver.cpp:242] Iteration 84100 (93.1337 iter/s, 1.07373s/100 iter), loss = 0.247096
I0502 11:23:48.319865 26473 solver.cpp:261]     Train net output #0: loss = 0.247096 (* 1 = 0.247096 loss)
I0502 11:23:48.319875 26473 sgd_solver.cpp:106] Iteration 84100, lr = 1.67772e-05
I0502 11:23:48.324650 26473 solver.cpp:242] Iteration 84100 (105.993 iter/s, 0.943455s/100 iter), loss = 0.038955
I0502 11:23:48.324672 26473 solver.cpp:261]     Train net output #0: loss = 0.038955 (* 1 = 0.038955 loss)
I0502 11:23:48.324681 26473 sgd_solver.cpp:106] Iteration 84100, lr = 1.67772e-05
I0502 11:23:49.263742 26473 solver.cpp:242] Iteration 84200 (105.949 iter/s, 0.943851s/100 iter), loss = 0.0757793
I0502 11:23:49.263782 26473 solver.cpp:261]     Train net output #0: loss = 0.0757793 (* 1 = 0.0757793 loss)
I0502 11:23:49.263792 26473 sgd_solver.cpp:106] Iteration 84200, lr = 1.67772e-05
I0502 11:23:49.268631 26473 solver.cpp:242] Iteration 84200 (105.94 iter/s, 0.943932s/100 iter), loss = 0.126116
I0502 11:23:49.268654 26473 solver.cpp:261]     Train net output #0: loss = 0.126116 (* 1 = 0.126116 loss)
I0502 11:23:49.268663 26473 sgd_solver.cpp:106] Iteration 84200, lr = 1.67772e-05
I0502 11:23:50.206984 26473 solver.cpp:242] Iteration 84300 (106.024 iter/s, 0.943179s/100 iter), loss = 0.0956932
I0502 11:23:50.207023 26473 solver.cpp:261]     Train net output #0: loss = 0.0956932 (* 1 = 0.0956932 loss)
I0502 11:23:50.207032 26473 sgd_solver.cpp:106] Iteration 84300, lr = 1.67772e-05
I0502 11:23:50.211848 26473 solver.cpp:242] Iteration 84300 (106.025 iter/s, 0.94317s/100 iter), loss = 0.0820587
I0502 11:23:50.211870 26473 solver.cpp:261]     Train net output #0: loss = 0.0820587 (* 1 = 0.0820587 loss)
I0502 11:23:50.211879 26473 sgd_solver.cpp:106] Iteration 84300, lr = 1.67772e-05
I0502 11:23:51.152372 26473 solver.cpp:242] Iteration 84400 (105.784 iter/s, 0.945319s/100 iter), loss = 0.225041
I0502 11:23:51.152415 26473 solver.cpp:261]     Train net output #0: loss = 0.225041 (* 1 = 0.225041 loss)
I0502 11:23:51.152423 26473 sgd_solver.cpp:106] Iteration 84400, lr = 1.67772e-05
I0502 11:23:51.157186 26473 solver.cpp:242] Iteration 84400 (105.787 iter/s, 0.945297s/100 iter), loss = 0.131361
I0502 11:23:51.157208 26473 solver.cpp:261]     Train net output #0: loss = 0.131361 (* 1 = 0.131361 loss)
I0502 11:23:51.157217 26473 sgd_solver.cpp:106] Iteration 84400, lr = 1.67772e-05
I0502 11:23:52.093688 26473 solver.cpp:362] Iteration 84500, Testing net (#0)
I0502 11:23:52.093713 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:52.218020 26473 solver.cpp:429]     Test net output #0: loss = 0.286034 (* 1 = 0.286034 loss)
I0502 11:23:52.220907 26473 solver.cpp:242] Iteration 84500 (93.5913 iter/s, 1.06848s/100 iter), loss = 0.120574
I0502 11:23:52.220927 26473 solver.cpp:261]     Train net output #0: loss = 0.120574 (* 1 = 0.120574 loss)
I0502 11:23:52.220937 26473 sgd_solver.cpp:106] Iteration 84500, lr = 1.67772e-05
I0502 11:23:52.222556 26473 solver.cpp:362] Iteration 84500, Testing net (#0)
I0502 11:23:52.222570 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:52.353066 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:23:52.353088 26473 solver.cpp:429]     Test net output #1: loss = 0.0879029 (* 1 = 0.0879029 loss)
I0502 11:23:52.356015 26473 solver.cpp:242] Iteration 84500 (83.4177 iter/s, 1.19879s/100 iter), loss = 0.0479362
I0502 11:23:52.356035 26473 solver.cpp:261]     Train net output #0: loss = 0.0479362 (* 1 = 0.0479362 loss)
I0502 11:23:52.356043 26473 sgd_solver.cpp:106] Iteration 84500, lr = 1.67772e-05
I0502 11:23:53.296489 26473 solver.cpp:242] Iteration 84600 (92.9773 iter/s, 1.07553s/100 iter), loss = 0.0895419
I0502 11:23:53.296530 26473 solver.cpp:261]     Train net output #0: loss = 0.0895419 (* 1 = 0.0895419 loss)
I0502 11:23:53.296538 26473 sgd_solver.cpp:106] Iteration 84600, lr = 1.67772e-05
I0502 11:23:53.301311 26473 solver.cpp:242] Iteration 84600 (105.791 iter/s, 0.945258s/100 iter), loss = 0.205072
I0502 11:23:53.301334 26473 solver.cpp:261]     Train net output #0: loss = 0.205072 (* 1 = 0.205072 loss)
I0502 11:23:53.301343 26473 sgd_solver.cpp:106] Iteration 84600, lr = 1.67772e-05
I0502 11:23:54.239748 26473 solver.cpp:242] Iteration 84700 (106.023 iter/s, 0.943195s/100 iter), loss = 0.377579
I0502 11:23:54.239784 26473 solver.cpp:261]     Train net output #0: loss = 0.377579 (* 1 = 0.377579 loss)
I0502 11:23:54.239794 26473 sgd_solver.cpp:106] Iteration 84700, lr = 1.67772e-05
I0502 11:23:54.244542 26473 solver.cpp:242] Iteration 84700 (106.023 iter/s, 0.943188s/100 iter), loss = 0.00847368
I0502 11:23:54.244570 26473 solver.cpp:261]     Train net output #0: loss = 0.00847368 (* 1 = 0.00847368 loss)
I0502 11:23:54.244580 26473 sgd_solver.cpp:106] Iteration 84700, lr = 1.67772e-05
I0502 11:23:55.183053 26473 solver.cpp:242] Iteration 84800 (106.017 iter/s, 0.943243s/100 iter), loss = 0.271099
I0502 11:23:55.183092 26473 solver.cpp:261]     Train net output #0: loss = 0.271099 (* 1 = 0.271099 loss)
I0502 11:23:55.183101 26473 sgd_solver.cpp:106] Iteration 84800, lr = 1.67772e-05
I0502 11:23:55.187929 26473 solver.cpp:242] Iteration 84800 (106.007 iter/s, 0.943334s/100 iter), loss = 0.0783471
I0502 11:23:55.187952 26473 solver.cpp:261]     Train net output #0: loss = 0.0783471 (* 1 = 0.0783471 loss)
I0502 11:23:55.187961 26473 sgd_solver.cpp:106] Iteration 84800, lr = 1.67772e-05
I0502 11:23:56.129111 26473 solver.cpp:242] Iteration 84900 (105.71 iter/s, 0.945988s/100 iter), loss = 0.353998
I0502 11:23:56.129142 26473 solver.cpp:261]     Train net output #0: loss = 0.353998 (* 1 = 0.353998 loss)
I0502 11:23:56.129151 26473 sgd_solver.cpp:106] Iteration 84900, lr = 1.67772e-05
I0502 11:23:56.133960 26473 solver.cpp:242] Iteration 84900 (105.71 iter/s, 0.945988s/100 iter), loss = 0.116413
I0502 11:23:56.133982 26473 solver.cpp:261]     Train net output #0: loss = 0.116413 (* 1 = 0.116413 loss)
I0502 11:23:56.133991 26473 sgd_solver.cpp:106] Iteration 84900, lr = 1.67772e-05
I0502 11:23:57.070777 26473 solver.cpp:362] Iteration 85000, Testing net (#0)
I0502 11:23:57.070799 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:57.195071 26473 solver.cpp:429]     Test net output #0: loss = 0.293545 (* 1 = 0.293545 loss)
I0502 11:23:57.197947 26473 solver.cpp:242] Iteration 85000 (93.5642 iter/s, 1.06878s/100 iter), loss = 0.563698
I0502 11:23:57.197965 26473 solver.cpp:261]     Train net output #0: loss = 0.563698 (* 1 = 0.563698 loss)
I0502 11:23:57.197981 26473 sgd_solver.cpp:106] Iteration 85000, lr = 1.67772e-05
I0502 11:23:57.199596 26473 solver.cpp:362] Iteration 85000, Testing net (#0)
I0502 11:23:57.199609 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:23:57.330376 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:23:57.330399 26473 solver.cpp:429]     Test net output #1: loss = 0.0938599 (* 1 = 0.0938599 loss)
I0502 11:23:57.333341 26473 solver.cpp:242] Iteration 85000 (83.3793 iter/s, 1.19934s/100 iter), loss = 0.067009
I0502 11:23:57.333362 26473 solver.cpp:261]     Train net output #0: loss = 0.067009 (* 1 = 0.067009 loss)
I0502 11:23:57.333370 26473 sgd_solver.cpp:106] Iteration 85000, lr = 1.67772e-05
I0502 11:23:58.273200 26473 solver.cpp:242] Iteration 85100 (93.0055 iter/s, 1.07521s/100 iter), loss = 0.20456
I0502 11:23:58.273229 26473 solver.cpp:261]     Train net output #0: loss = 0.20456 (* 1 = 0.20456 loss)
I0502 11:23:58.273238 26473 sgd_solver.cpp:106] Iteration 85100, lr = 1.67772e-05
I0502 11:23:58.277990 26473 solver.cpp:242] Iteration 85100 (105.864 iter/s, 0.94461s/100 iter), loss = 0.0755973
I0502 11:23:58.278012 26473 solver.cpp:261]     Train net output #0: loss = 0.0755973 (* 1 = 0.0755973 loss)
I0502 11:23:58.278022 26473 sgd_solver.cpp:106] Iteration 85100, lr = 1.67772e-05
I0502 11:23:59.217011 26473 solver.cpp:242] Iteration 85200 (105.96 iter/s, 0.943754s/100 iter), loss = 0.355894
I0502 11:23:59.217056 26473 solver.cpp:261]     Train net output #0: loss = 0.355894 (* 1 = 0.355894 loss)
I0502 11:23:59.217064 26473 sgd_solver.cpp:106] Iteration 85200, lr = 1.67772e-05
I0502 11:23:59.221817 26473 solver.cpp:242] Iteration 85200 (105.956 iter/s, 0.943786s/100 iter), loss = 0.0489137
I0502 11:23:59.221840 26473 solver.cpp:261]     Train net output #0: loss = 0.0489137 (* 1 = 0.0489137 loss)
I0502 11:23:59.221848 26473 sgd_solver.cpp:106] Iteration 85200, lr = 1.67772e-05
I0502 11:24:00.160070 26473 solver.cpp:242] Iteration 85300 (106.046 iter/s, 0.942991s/100 iter), loss = 0.181248
I0502 11:24:00.160114 26473 solver.cpp:261]     Train net output #0: loss = 0.181248 (* 1 = 0.181248 loss)
I0502 11:24:00.160122 26473 sgd_solver.cpp:106] Iteration 85300, lr = 1.67772e-05
I0502 11:24:00.164955 26473 solver.cpp:242] Iteration 85300 (106.035 iter/s, 0.943089s/100 iter), loss = 0.079359
I0502 11:24:00.164978 26473 solver.cpp:261]     Train net output #0: loss = 0.079359 (* 1 = 0.079359 loss)
I0502 11:24:00.164986 26473 sgd_solver.cpp:106] Iteration 85300, lr = 1.67772e-05
I0502 11:24:01.117497 26473 solver.cpp:242] Iteration 85400 (104.455 iter/s, 0.957352s/100 iter), loss = 0.189018
I0502 11:24:01.117539 26473 solver.cpp:261]     Train net output #0: loss = 0.189018 (* 1 = 0.189018 loss)
I0502 11:24:01.117549 26473 sgd_solver.cpp:106] Iteration 85400, lr = 1.67772e-05
I0502 11:24:01.122324 26473 solver.cpp:242] Iteration 85400 (104.457 iter/s, 0.957328s/100 iter), loss = 0.00354063
I0502 11:24:01.122349 26473 solver.cpp:261]     Train net output #0: loss = 0.00354063 (* 1 = 0.00354063 loss)
I0502 11:24:01.122357 26473 sgd_solver.cpp:106] Iteration 85400, lr = 1.67772e-05
I0502 11:24:02.058097 26473 solver.cpp:362] Iteration 85500, Testing net (#0)
I0502 11:24:02.058140 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:02.182422 26473 solver.cpp:429]     Test net output #0: loss = 0.275479 (* 1 = 0.275479 loss)
I0502 11:24:02.185290 26473 solver.cpp:242] Iteration 85500 (93.6564 iter/s, 1.06773s/100 iter), loss = 0.143295
I0502 11:24:02.185310 26473 solver.cpp:261]     Train net output #0: loss = 0.143295 (* 1 = 0.143295 loss)
I0502 11:24:02.185319 26473 sgd_solver.cpp:106] Iteration 85500, lr = 1.67772e-05
I0502 11:24:02.186944 26473 solver.cpp:362] Iteration 85500, Testing net (#0)
I0502 11:24:02.186956 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:02.317615 26473 solver.cpp:429]     Test net output #0: accuracy = 0.956
I0502 11:24:02.317633 26473 solver.cpp:429]     Test net output #1: loss = 0.0965225 (* 1 = 0.0965225 loss)
I0502 11:24:02.320560 26473 solver.cpp:242] Iteration 85500 (83.4598 iter/s, 1.19818s/100 iter), loss = 0.0172519
I0502 11:24:02.320590 26473 solver.cpp:261]     Train net output #0: loss = 0.0172519 (* 1 = 0.0172519 loss)
I0502 11:24:02.320600 26473 sgd_solver.cpp:106] Iteration 85500, lr = 1.67772e-05
I0502 11:24:03.260741 26473 solver.cpp:242] Iteration 85600 (92.9887 iter/s, 1.0754s/100 iter), loss = 0.115952
I0502 11:24:03.260782 26473 solver.cpp:261]     Train net output #0: loss = 0.115952 (* 1 = 0.115952 loss)
I0502 11:24:03.260792 26473 sgd_solver.cpp:106] Iteration 85600, lr = 1.67772e-05
I0502 11:24:03.265552 26473 solver.cpp:242] Iteration 85600 (105.826 iter/s, 0.944943s/100 iter), loss = 0.188584
I0502 11:24:03.265574 26473 solver.cpp:261]     Train net output #0: loss = 0.188584 (* 1 = 0.188584 loss)
I0502 11:24:03.265583 26473 sgd_solver.cpp:106] Iteration 85600, lr = 1.67772e-05
I0502 11:24:04.204020 26473 solver.cpp:242] Iteration 85700 (106.021 iter/s, 0.943211s/100 iter), loss = 0.161847
I0502 11:24:04.204062 26473 solver.cpp:261]     Train net output #0: loss = 0.161847 (* 1 = 0.161847 loss)
I0502 11:24:04.204071 26473 sgd_solver.cpp:106] Iteration 85700, lr = 1.67772e-05
I0502 11:24:04.208832 26473 solver.cpp:242] Iteration 85700 (106.018 iter/s, 0.943239s/100 iter), loss = 0.0138361
I0502 11:24:04.208855 26473 solver.cpp:261]     Train net output #0: loss = 0.0138361 (* 1 = 0.0138361 loss)
I0502 11:24:04.208864 26473 sgd_solver.cpp:106] Iteration 85700, lr = 1.67772e-05
I0502 11:24:05.147670 26473 solver.cpp:242] Iteration 85800 (105.979 iter/s, 0.943583s/100 iter), loss = 0.14986
I0502 11:24:05.147711 26473 solver.cpp:261]     Train net output #0: loss = 0.14986 (* 1 = 0.14986 loss)
I0502 11:24:05.147718 26473 sgd_solver.cpp:106] Iteration 85800, lr = 1.67772e-05
I0502 11:24:05.152559 26473 solver.cpp:242] Iteration 85800 (105.969 iter/s, 0.943672s/100 iter), loss = 0.0431461
I0502 11:24:05.152582 26473 solver.cpp:261]     Train net output #0: loss = 0.0431461 (* 1 = 0.0431461 loss)
I0502 11:24:05.152591 26473 sgd_solver.cpp:106] Iteration 85800, lr = 1.67772e-05
I0502 11:24:06.092109 26473 solver.cpp:242] Iteration 85900 (105.891 iter/s, 0.944367s/100 iter), loss = 0.375056
I0502 11:24:06.092155 26473 solver.cpp:261]     Train net output #0: loss = 0.375056 (* 1 = 0.375056 loss)
I0502 11:24:06.092164 26473 sgd_solver.cpp:106] Iteration 85900, lr = 1.67772e-05
I0502 11:24:06.096935 26473 solver.cpp:242] Iteration 85900 (105.895 iter/s, 0.944335s/100 iter), loss = 0.0604093
I0502 11:24:06.096959 26473 solver.cpp:261]     Train net output #0: loss = 0.0604093 (* 1 = 0.0604093 loss)
I0502 11:24:06.096967 26473 sgd_solver.cpp:106] Iteration 85900, lr = 1.67772e-05
I0502 11:24:07.033200 26473 solver.cpp:362] Iteration 86000, Testing net (#0)
I0502 11:24:07.033226 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:07.157583 26473 solver.cpp:429]     Test net output #0: loss = 0.424174 (* 1 = 0.424174 loss)
I0502 11:24:07.160451 26473 solver.cpp:242] Iteration 86000 (93.6085 iter/s, 1.06828s/100 iter), loss = 0.172462
I0502 11:24:07.160470 26473 solver.cpp:261]     Train net output #0: loss = 0.172462 (* 1 = 0.172462 loss)
I0502 11:24:07.160480 26473 sgd_solver.cpp:106] Iteration 86000, lr = 1.67772e-05
I0502 11:24:07.162098 26473 solver.cpp:362] Iteration 86000, Testing net (#0)
I0502 11:24:07.162111 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:07.292644 26473 solver.cpp:429]     Test net output #0: accuracy = 0.954
I0502 11:24:07.292677 26473 solver.cpp:429]     Test net output #1: loss = 0.113492 (* 1 = 0.113492 loss)
I0502 11:24:07.295608 26473 solver.cpp:242] Iteration 86000 (83.4288 iter/s, 1.19863s/100 iter), loss = 0.0639611
I0502 11:24:07.295629 26473 solver.cpp:261]     Train net output #0: loss = 0.0639611 (* 1 = 0.0639611 loss)
I0502 11:24:07.295637 26473 sgd_solver.cpp:106] Iteration 86000, lr = 1.67772e-05
I0502 11:24:08.235208 26473 solver.cpp:242] Iteration 86100 (93.0488 iter/s, 1.07471s/100 iter), loss = 0.11649
I0502 11:24:08.235251 26473 solver.cpp:261]     Train net output #0: loss = 0.11649 (* 1 = 0.11649 loss)
I0502 11:24:08.235268 26473 sgd_solver.cpp:106] Iteration 86100, lr = 1.67772e-05
I0502 11:24:08.240033 26473 solver.cpp:242] Iteration 86100 (105.889 iter/s, 0.944388s/100 iter), loss = 0.0717458
I0502 11:24:08.240057 26473 solver.cpp:261]     Train net output #0: loss = 0.0717458 (* 1 = 0.0717458 loss)
I0502 11:24:08.240066 26473 sgd_solver.cpp:106] Iteration 86100, lr = 1.67772e-05
I0502 11:24:09.178673 26473 solver.cpp:242] Iteration 86200 (106 iter/s, 0.943397s/100 iter), loss = 0.356159
I0502 11:24:09.178711 26473 solver.cpp:261]     Train net output #0: loss = 0.356159 (* 1 = 0.356159 loss)
I0502 11:24:09.178720 26473 sgd_solver.cpp:106] Iteration 86200, lr = 1.67772e-05
I0502 11:24:09.183475 26473 solver.cpp:242] Iteration 86200 (106 iter/s, 0.9434s/100 iter), loss = 0.114578
I0502 11:24:09.183497 26473 solver.cpp:261]     Train net output #0: loss = 0.114578 (* 1 = 0.114578 loss)
I0502 11:24:09.183506 26473 sgd_solver.cpp:106] Iteration 86200, lr = 1.67772e-05
I0502 11:24:10.123504 26473 solver.cpp:242] Iteration 86300 (105.846 iter/s, 0.944768s/100 iter), loss = 0.100418
I0502 11:24:10.123541 26473 solver.cpp:261]     Train net output #0: loss = 0.100418 (* 1 = 0.100418 loss)
I0502 11:24:10.123550 26473 sgd_solver.cpp:106] Iteration 86300, lr = 1.67772e-05
I0502 11:24:10.128382 26473 solver.cpp:242] Iteration 86300 (105.836 iter/s, 0.944859s/100 iter), loss = 0.087591
I0502 11:24:10.128407 26473 solver.cpp:261]     Train net output #0: loss = 0.087591 (* 1 = 0.087591 loss)
I0502 11:24:10.128415 26473 sgd_solver.cpp:106] Iteration 86300, lr = 1.67772e-05
I0502 11:24:11.066545 26473 solver.cpp:242] Iteration 86400 (106.048 iter/s, 0.942972s/100 iter), loss = 0.158034
I0502 11:24:11.066581 26473 solver.cpp:261]     Train net output #0: loss = 0.158034 (* 1 = 0.158034 loss)
I0502 11:24:11.066589 26473 sgd_solver.cpp:106] Iteration 86400, lr = 1.67772e-05
I0502 11:24:11.071373 26473 solver.cpp:242] Iteration 86400 (106.05 iter/s, 0.942949s/100 iter), loss = 0.0530725
I0502 11:24:11.071396 26473 solver.cpp:261]     Train net output #0: loss = 0.0530725 (* 1 = 0.0530725 loss)
I0502 11:24:11.071404 26473 sgd_solver.cpp:106] Iteration 86400, lr = 1.67772e-05
I0502 11:24:12.007153 26473 solver.cpp:362] Iteration 86500, Testing net (#0)
I0502 11:24:12.007177 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:12.131475 26473 solver.cpp:429]     Test net output #0: loss = 0.240073 (* 1 = 0.240073 loss)
I0502 11:24:12.134343 26473 solver.cpp:242] Iteration 86500 (93.6555 iter/s, 1.06774s/100 iter), loss = 0.774274
I0502 11:24:12.134363 26473 solver.cpp:261]     Train net output #0: loss = 0.774274 (* 1 = 0.774274 loss)
I0502 11:24:12.134371 26473 sgd_solver.cpp:106] Iteration 86500, lr = 1.67772e-05
I0502 11:24:12.135984 26473 solver.cpp:362] Iteration 86500, Testing net (#0)
I0502 11:24:12.135996 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:12.266510 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9535
I0502 11:24:12.266531 26473 solver.cpp:429]     Test net output #1: loss = 0.104758 (* 1 = 0.104758 loss)
I0502 11:24:12.269445 26473 solver.cpp:242] Iteration 86500 (83.4704 iter/s, 1.19803s/100 iter), loss = 0.245163
I0502 11:24:12.269465 26473 solver.cpp:261]     Train net output #0: loss = 0.245163 (* 1 = 0.245163 loss)
I0502 11:24:12.269474 26473 sgd_solver.cpp:106] Iteration 86500, lr = 1.67772e-05
I0502 11:24:13.208026 26473 solver.cpp:242] Iteration 86600 (93.1418 iter/s, 1.07363s/100 iter), loss = 0.384357
I0502 11:24:13.208065 26473 solver.cpp:261]     Train net output #0: loss = 0.384357 (* 1 = 0.384357 loss)
I0502 11:24:13.208075 26473 sgd_solver.cpp:106] Iteration 86600, lr = 1.67772e-05
I0502 11:24:13.212869 26473 solver.cpp:242] Iteration 86600 (106.001 iter/s, 0.943385s/100 iter), loss = 0.0716753
I0502 11:24:13.212893 26473 solver.cpp:261]     Train net output #0: loss = 0.0716753 (* 1 = 0.0716753 loss)
I0502 11:24:13.212900 26473 sgd_solver.cpp:106] Iteration 86600, lr = 1.67772e-05
I0502 11:24:14.153748 26473 solver.cpp:242] Iteration 86700 (105.747 iter/s, 0.945656s/100 iter), loss = 0.248459
I0502 11:24:14.153790 26473 solver.cpp:261]     Train net output #0: loss = 0.248459 (* 1 = 0.248459 loss)
I0502 11:24:14.153800 26473 sgd_solver.cpp:106] Iteration 86700, lr = 1.67772e-05
I0502 11:24:14.158551 26473 solver.cpp:242] Iteration 86700 (105.748 iter/s, 0.945641s/100 iter), loss = 0.109318
I0502 11:24:14.158576 26473 solver.cpp:261]     Train net output #0: loss = 0.109318 (* 1 = 0.109318 loss)
I0502 11:24:14.158583 26473 sgd_solver.cpp:106] Iteration 86700, lr = 1.67772e-05
I0502 11:24:15.097800 26473 solver.cpp:242] Iteration 86800 (105.934 iter/s, 0.943986s/100 iter), loss = 0.680386
I0502 11:24:15.097828 26473 solver.cpp:261]     Train net output #0: loss = 0.680386 (* 1 = 0.680386 loss)
I0502 11:24:15.097837 26473 sgd_solver.cpp:106] Iteration 86800, lr = 1.67772e-05
I0502 11:24:15.102684 26473 solver.cpp:242] Iteration 86800 (105.923 iter/s, 0.944081s/100 iter), loss = 0.0646184
I0502 11:24:15.102706 26473 solver.cpp:261]     Train net output #0: loss = 0.0646184 (* 1 = 0.0646184 loss)
I0502 11:24:15.102715 26473 sgd_solver.cpp:106] Iteration 86800, lr = 1.67772e-05
I0502 11:24:16.042698 26473 solver.cpp:242] Iteration 86900 (105.837 iter/s, 0.944845s/100 iter), loss = 0.0567808
I0502 11:24:16.042740 26473 solver.cpp:261]     Train net output #0: loss = 0.0567808 (* 1 = 0.0567808 loss)
I0502 11:24:16.042749 26473 sgd_solver.cpp:106] Iteration 86900, lr = 1.67772e-05
I0502 11:24:16.047580 26473 solver.cpp:242] Iteration 86900 (105.837 iter/s, 0.944851s/100 iter), loss = 0.137316
I0502 11:24:16.047603 26473 solver.cpp:261]     Train net output #0: loss = 0.137316 (* 1 = 0.137316 loss)
I0502 11:24:16.047612 26473 sgd_solver.cpp:106] Iteration 86900, lr = 1.67772e-05
I0502 11:24:16.982939 26473 solver.cpp:362] Iteration 87000, Testing net (#0)
I0502 11:24:16.982969 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:17.107095 26473 solver.cpp:429]     Test net output #0: loss = 0.265171 (* 1 = 0.265171 loss)
I0502 11:24:17.109958 26473 solver.cpp:242] Iteration 87000 (93.703 iter/s, 1.0672s/100 iter), loss = 0.230836
I0502 11:24:17.109978 26473 solver.cpp:261]     Train net output #0: loss = 0.230836 (* 1 = 0.230836 loss)
I0502 11:24:17.109987 26473 sgd_solver.cpp:106] Iteration 87000, lr = 1.67772e-05
I0502 11:24:17.111613 26473 solver.cpp:362] Iteration 87000, Testing net (#0)
I0502 11:24:17.111625 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:17.242214 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9475
I0502 11:24:17.242236 26473 solver.cpp:429]     Test net output #1: loss = 0.105708 (* 1 = 0.105708 loss)
I0502 11:24:17.245169 26473 solver.cpp:242] Iteration 87000 (83.5041 iter/s, 1.19755s/100 iter), loss = 0.252807
I0502 11:24:17.245189 26473 solver.cpp:261]     Train net output #0: loss = 0.252807 (* 1 = 0.252807 loss)
I0502 11:24:17.245198 26473 sgd_solver.cpp:106] Iteration 87000, lr = 1.67772e-05
I0502 11:24:18.185637 26473 solver.cpp:242] Iteration 87100 (92.9688 iter/s, 1.07563s/100 iter), loss = 0.124941
I0502 11:24:18.185670 26473 solver.cpp:261]     Train net output #0: loss = 0.124941 (* 1 = 0.124941 loss)
I0502 11:24:18.185679 26473 sgd_solver.cpp:106] Iteration 87100, lr = 1.67772e-05
I0502 11:24:18.190438 26473 solver.cpp:242] Iteration 87100 (105.794 iter/s, 0.945229s/100 iter), loss = 0.171705
I0502 11:24:18.190460 26473 solver.cpp:261]     Train net output #0: loss = 0.171705 (* 1 = 0.171705 loss)
I0502 11:24:18.190469 26473 sgd_solver.cpp:106] Iteration 87100, lr = 1.67772e-05
I0502 11:24:19.130259 26473 solver.cpp:242] Iteration 87200 (105.869 iter/s, 0.944561s/100 iter), loss = 0.173837
I0502 11:24:19.130293 26473 solver.cpp:261]     Train net output #0: loss = 0.173837 (* 1 = 0.173837 loss)
I0502 11:24:19.130302 26473 sgd_solver.cpp:106] Iteration 87200, lr = 1.67772e-05
I0502 11:24:19.135088 26473 solver.cpp:242] Iteration 87200 (105.864 iter/s, 0.94461s/100 iter), loss = 0.0371517
I0502 11:24:19.135112 26473 solver.cpp:261]     Train net output #0: loss = 0.0371517 (* 1 = 0.0371517 loss)
I0502 11:24:19.135128 26473 sgd_solver.cpp:106] Iteration 87200, lr = 1.67772e-05
I0502 11:24:20.074185 26473 solver.cpp:242] Iteration 87300 (105.947 iter/s, 0.943866s/100 iter), loss = 0.0900444
I0502 11:24:20.074229 26473 solver.cpp:261]     Train net output #0: loss = 0.0900444 (* 1 = 0.0900444 loss)
I0502 11:24:20.074239 26473 sgd_solver.cpp:106] Iteration 87300, lr = 1.67772e-05
I0502 11:24:20.078985 26473 solver.cpp:242] Iteration 87300 (105.948 iter/s, 0.943857s/100 iter), loss = 0.111483
I0502 11:24:20.079010 26473 solver.cpp:261]     Train net output #0: loss = 0.111483 (* 1 = 0.111483 loss)
I0502 11:24:20.079017 26473 sgd_solver.cpp:106] Iteration 87300, lr = 1.67772e-05
I0502 11:24:21.017328 26473 solver.cpp:242] Iteration 87400 (106.036 iter/s, 0.943074s/100 iter), loss = 0.233516
I0502 11:24:21.017369 26473 solver.cpp:261]     Train net output #0: loss = 0.233516 (* 1 = 0.233516 loss)
I0502 11:24:21.017379 26473 sgd_solver.cpp:106] Iteration 87400, lr = 1.67772e-05
I0502 11:24:21.022205 26473 solver.cpp:242] Iteration 87400 (106.025 iter/s, 0.943171s/100 iter), loss = 0.167512
I0502 11:24:21.022228 26473 solver.cpp:261]     Train net output #0: loss = 0.167512 (* 1 = 0.167512 loss)
I0502 11:24:21.022236 26473 sgd_solver.cpp:106] Iteration 87400, lr = 1.67772e-05
I0502 11:24:21.958318 26473 solver.cpp:362] Iteration 87500, Testing net (#0)
I0502 11:24:21.958348 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:22.082597 26473 solver.cpp:429]     Test net output #0: loss = 0.31988 (* 1 = 0.31988 loss)
I0502 11:24:22.085471 26473 solver.cpp:242] Iteration 87500 (93.6257 iter/s, 1.06808s/100 iter), loss = 0.347379
I0502 11:24:22.085490 26473 solver.cpp:261]     Train net output #0: loss = 0.347379 (* 1 = 0.347379 loss)
I0502 11:24:22.085500 26473 sgd_solver.cpp:106] Iteration 87500, lr = 1.67772e-05
I0502 11:24:22.087142 26473 solver.cpp:362] Iteration 87500, Testing net (#0)
I0502 11:24:22.087155 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:22.217813 26473 solver.cpp:429]     Test net output #0: accuracy = 0.945
I0502 11:24:22.217835 26473 solver.cpp:429]     Test net output #1: loss = 0.118768 (* 1 = 0.118768 loss)
I0502 11:24:22.220752 26473 solver.cpp:242] Iteration 87500 (83.4374 iter/s, 1.1985s/100 iter), loss = 0.231588
I0502 11:24:22.220772 26473 solver.cpp:261]     Train net output #0: loss = 0.231588 (* 1 = 0.231588 loss)
I0502 11:24:22.220780 26473 sgd_solver.cpp:106] Iteration 87500, lr = 1.67772e-05
I0502 11:24:23.159386 26473 solver.cpp:242] Iteration 87600 (93.1216 iter/s, 1.07386s/100 iter), loss = 0.262381
I0502 11:24:23.159443 26473 solver.cpp:261]     Train net output #0: loss = 0.262381 (* 1 = 0.262381 loss)
I0502 11:24:23.159452 26473 sgd_solver.cpp:106] Iteration 87600, lr = 1.67772e-05
I0502 11:24:23.164271 26473 solver.cpp:242] Iteration 87600 (105.99 iter/s, 0.943482s/100 iter), loss = 0.0855462
I0502 11:24:23.164295 26473 solver.cpp:261]     Train net output #0: loss = 0.0855462 (* 1 = 0.0855462 loss)
I0502 11:24:23.164304 26473 sgd_solver.cpp:106] Iteration 87600, lr = 1.67772e-05
I0502 11:24:24.103667 26473 solver.cpp:242] Iteration 87700 (105.91 iter/s, 0.944194s/100 iter), loss = 0.41998
I0502 11:24:24.103709 26473 solver.cpp:261]     Train net output #0: loss = 0.41998 (* 1 = 0.41998 loss)
I0502 11:24:24.103718 26473 sgd_solver.cpp:106] Iteration 87700, lr = 1.67772e-05
I0502 11:24:24.108480 26473 solver.cpp:242] Iteration 87700 (105.913 iter/s, 0.944167s/100 iter), loss = 0.0413188
I0502 11:24:24.108502 26473 solver.cpp:261]     Train net output #0: loss = 0.0413188 (* 1 = 0.0413188 loss)
I0502 11:24:24.108511 26473 sgd_solver.cpp:106] Iteration 87700, lr = 1.67772e-05
I0502 11:24:25.047255 26473 solver.cpp:242] Iteration 87800 (105.986 iter/s, 0.943522s/100 iter), loss = 0.136303
I0502 11:24:25.047294 26473 solver.cpp:261]     Train net output #0: loss = 0.136303 (* 1 = 0.136303 loss)
I0502 11:24:25.047303 26473 sgd_solver.cpp:106] Iteration 87800, lr = 1.67772e-05
I0502 11:24:25.052068 26473 solver.cpp:242] Iteration 87800 (105.983 iter/s, 0.943547s/100 iter), loss = 0.263089
I0502 11:24:25.052099 26473 solver.cpp:261]     Train net output #0: loss = 0.263089 (* 1 = 0.263089 loss)
I0502 11:24:25.052109 26473 sgd_solver.cpp:106] Iteration 87800, lr = 1.67772e-05
I0502 11:24:25.991315 26473 solver.cpp:242] Iteration 87900 (105.933 iter/s, 0.943996s/100 iter), loss = 0.371897
I0502 11:24:25.991363 26473 solver.cpp:261]     Train net output #0: loss = 0.371897 (* 1 = 0.371897 loss)
I0502 11:24:25.991371 26473 sgd_solver.cpp:106] Iteration 87900, lr = 1.67772e-05
I0502 11:24:25.996215 26473 solver.cpp:242] Iteration 87900 (105.922 iter/s, 0.944089s/100 iter), loss = 0.0966467
I0502 11:24:25.996239 26473 solver.cpp:261]     Train net output #0: loss = 0.0966467 (* 1 = 0.0966467 loss)
I0502 11:24:25.996248 26473 sgd_solver.cpp:106] Iteration 87900, lr = 1.67772e-05
I0502 11:24:26.931550 26473 solver.cpp:362] Iteration 88000, Testing net (#0)
I0502 11:24:26.931572 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:27.055768 26473 solver.cpp:429]     Test net output #0: loss = 0.417785 (* 1 = 0.417785 loss)
I0502 11:24:27.058639 26473 solver.cpp:242] Iteration 88000 (93.698 iter/s, 1.06726s/100 iter), loss = 0.212829
I0502 11:24:27.058660 26473 solver.cpp:261]     Train net output #0: loss = 0.212829 (* 1 = 0.212829 loss)
I0502 11:24:27.058670 26473 sgd_solver.cpp:106] Iteration 88000, lr = 1.67772e-05
I0502 11:24:27.060298 26473 solver.cpp:362] Iteration 88000, Testing net (#0)
I0502 11:24:27.060312 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:27.190986 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9235
I0502 11:24:27.191005 26473 solver.cpp:429]     Test net output #1: loss = 0.162915 (* 1 = 0.162915 loss)
I0502 11:24:27.193933 26473 solver.cpp:242] Iteration 88000 (83.4953 iter/s, 1.19767s/100 iter), loss = 0.114725
I0502 11:24:27.193953 26473 solver.cpp:261]     Train net output #0: loss = 0.114725 (* 1 = 0.114725 loss)
I0502 11:24:27.193963 26473 sgd_solver.cpp:106] Iteration 88000, lr = 1.67772e-05
I0502 11:24:28.133091 26473 solver.cpp:242] Iteration 88100 (93.0753 iter/s, 1.0744s/100 iter), loss = 0.115386
I0502 11:24:28.133133 26473 solver.cpp:261]     Train net output #0: loss = 0.115386 (* 1 = 0.115386 loss)
I0502 11:24:28.133142 26473 sgd_solver.cpp:106] Iteration 88100, lr = 1.67772e-05
I0502 11:24:28.137888 26473 solver.cpp:242] Iteration 88100 (105.942 iter/s, 0.943916s/100 iter), loss = 0.0791036
I0502 11:24:28.137912 26473 solver.cpp:261]     Train net output #0: loss = 0.0791036 (* 1 = 0.0791036 loss)
I0502 11:24:28.137919 26473 sgd_solver.cpp:106] Iteration 88100, lr = 1.67772e-05
I0502 11:24:29.076722 26473 solver.cpp:242] Iteration 88200 (105.982 iter/s, 0.943561s/100 iter), loss = 0.170721
I0502 11:24:29.076762 26473 solver.cpp:261]     Train net output #0: loss = 0.170721 (* 1 = 0.170721 loss)
I0502 11:24:29.076771 26473 sgd_solver.cpp:106] Iteration 88200, lr = 1.67772e-05
I0502 11:24:29.081543 26473 solver.cpp:242] Iteration 88200 (105.975 iter/s, 0.943615s/100 iter), loss = 0.0495377
I0502 11:24:29.081567 26473 solver.cpp:261]     Train net output #0: loss = 0.0495377 (* 1 = 0.0495377 loss)
I0502 11:24:29.081574 26473 sgd_solver.cpp:106] Iteration 88200, lr = 1.67772e-05
I0502 11:24:30.020591 26473 solver.cpp:242] Iteration 88300 (105.954 iter/s, 0.943802s/100 iter), loss = 0.390974
I0502 11:24:30.020624 26473 solver.cpp:261]     Train net output #0: loss = 0.390974 (* 1 = 0.390974 loss)
I0502 11:24:30.020632 26473 sgd_solver.cpp:106] Iteration 88300, lr = 1.67772e-05
I0502 11:24:30.025405 26473 solver.cpp:242] Iteration 88300 (105.952 iter/s, 0.943823s/100 iter), loss = 0.0888342
I0502 11:24:30.025429 26473 solver.cpp:261]     Train net output #0: loss = 0.0888342 (* 1 = 0.0888342 loss)
I0502 11:24:30.025437 26473 sgd_solver.cpp:106] Iteration 88300, lr = 1.67772e-05
I0502 11:24:30.965093 26473 solver.cpp:242] Iteration 88400 (105.882 iter/s, 0.944446s/100 iter), loss = 0.184797
I0502 11:24:30.965124 26473 solver.cpp:261]     Train net output #0: loss = 0.184797 (* 1 = 0.184797 loss)
I0502 11:24:30.965142 26473 sgd_solver.cpp:106] Iteration 88400, lr = 1.67772e-05
I0502 11:24:30.969965 26473 solver.cpp:242] Iteration 88400 (105.875 iter/s, 0.944512s/100 iter), loss = 0.0593161
I0502 11:24:30.969990 26473 solver.cpp:261]     Train net output #0: loss = 0.0593161 (* 1 = 0.0593161 loss)
I0502 11:24:30.969998 26473 sgd_solver.cpp:106] Iteration 88400, lr = 1.67772e-05
I0502 11:24:31.906306 26473 solver.cpp:362] Iteration 88500, Testing net (#0)
I0502 11:24:31.906324 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:32.030668 26473 solver.cpp:429]     Test net output #0: loss = 0.318752 (* 1 = 0.318752 loss)
I0502 11:24:32.033542 26473 solver.cpp:242] Iteration 88500 (93.598 iter/s, 1.0684s/100 iter), loss = 0.055647
I0502 11:24:32.033562 26473 solver.cpp:261]     Train net output #0: loss = 0.055647 (* 1 = 0.055647 loss)
I0502 11:24:32.033571 26473 sgd_solver.cpp:106] Iteration 88500, lr = 1.67772e-05
I0502 11:24:32.035188 26473 solver.cpp:362] Iteration 88500, Testing net (#0)
I0502 11:24:32.035202 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:32.165930 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:24:32.165951 26473 solver.cpp:429]     Test net output #1: loss = 0.0975547 (* 1 = 0.0975547 loss)
I0502 11:24:32.168867 26473 solver.cpp:242] Iteration 88500 (83.4128 iter/s, 1.19886s/100 iter), loss = 0.0500736
I0502 11:24:32.168887 26473 solver.cpp:261]     Train net output #0: loss = 0.0500736 (* 1 = 0.0500736 loss)
I0502 11:24:32.168895 26473 sgd_solver.cpp:106] Iteration 88500, lr = 1.67772e-05
I0502 11:24:33.107486 26473 solver.cpp:242] Iteration 88600 (93.1193 iter/s, 1.07389s/100 iter), loss = 0.176856
I0502 11:24:33.107522 26473 solver.cpp:261]     Train net output #0: loss = 0.176856 (* 1 = 0.176856 loss)
I0502 11:24:33.107530 26473 sgd_solver.cpp:106] Iteration 88600, lr = 1.67772e-05
I0502 11:24:33.112304 26473 solver.cpp:242] Iteration 88600 (106 iter/s, 0.943399s/100 iter), loss = 0.0925882
I0502 11:24:33.112329 26473 solver.cpp:261]     Train net output #0: loss = 0.0925882 (* 1 = 0.0925882 loss)
I0502 11:24:33.112336 26473 sgd_solver.cpp:106] Iteration 88600, lr = 1.67772e-05
I0502 11:24:34.052330 26473 solver.cpp:242] Iteration 88700 (105.845 iter/s, 0.944781s/100 iter), loss = 0.399021
I0502 11:24:34.052366 26473 solver.cpp:261]     Train net output #0: loss = 0.399021 (* 1 = 0.399021 loss)
I0502 11:24:34.052374 26473 sgd_solver.cpp:106] Iteration 88700, lr = 1.67772e-05
I0502 11:24:34.057142 26473 solver.cpp:242] Iteration 88700 (105.843 iter/s, 0.944796s/100 iter), loss = 0.178947
I0502 11:24:34.057164 26473 solver.cpp:261]     Train net output #0: loss = 0.178947 (* 1 = 0.178947 loss)
I0502 11:24:34.057173 26473 sgd_solver.cpp:106] Iteration 88700, lr = 1.67772e-05
I0502 11:24:34.995919 26473 solver.cpp:242] Iteration 88800 (105.985 iter/s, 0.943528s/100 iter), loss = 0.137395
I0502 11:24:34.995959 26473 solver.cpp:261]     Train net output #0: loss = 0.137395 (* 1 = 0.137395 loss)
I0502 11:24:34.995968 26473 sgd_solver.cpp:106] Iteration 88800, lr = 1.67772e-05
I0502 11:24:35.000730 26473 solver.cpp:242] Iteration 88800 (105.983 iter/s, 0.943548s/100 iter), loss = 0.0848976
I0502 11:24:35.000751 26473 solver.cpp:261]     Train net output #0: loss = 0.0848976 (* 1 = 0.0848976 loss)
I0502 11:24:35.000761 26473 sgd_solver.cpp:106] Iteration 88800, lr = 1.67772e-05
I0502 11:24:35.941203 26473 solver.cpp:242] Iteration 88900 (105.796 iter/s, 0.945217s/100 iter), loss = 0.353202
I0502 11:24:35.941251 26473 solver.cpp:261]     Train net output #0: loss = 0.353202 (* 1 = 0.353202 loss)
I0502 11:24:35.941259 26473 sgd_solver.cpp:106] Iteration 88900, lr = 1.67772e-05
I0502 11:24:35.946084 26473 solver.cpp:242] Iteration 88900 (105.786 iter/s, 0.945306s/100 iter), loss = 0.189419
I0502 11:24:35.946108 26473 solver.cpp:261]     Train net output #0: loss = 0.189419 (* 1 = 0.189419 loss)
I0502 11:24:35.946117 26473 sgd_solver.cpp:106] Iteration 88900, lr = 1.67772e-05
I0502 11:24:36.881547 26473 solver.cpp:362] Iteration 89000, Testing net (#0)
I0502 11:24:36.881584 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:37.005853 26473 solver.cpp:429]     Test net output #0: loss = 0.263786 (* 1 = 0.263786 loss)
I0502 11:24:37.008723 26473 solver.cpp:242] Iteration 89000 (93.6807 iter/s, 1.06746s/100 iter), loss = 0.338137
I0502 11:24:37.008744 26473 solver.cpp:261]     Train net output #0: loss = 0.338137 (* 1 = 0.338137 loss)
I0502 11:24:37.008752 26473 sgd_solver.cpp:106] Iteration 89000, lr = 1.67772e-05
I0502 11:24:37.010378 26473 solver.cpp:362] Iteration 89000, Testing net (#0)
I0502 11:24:37.010391 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:37.141055 26473 solver.cpp:429]     Test net output #0: accuracy = 0.954
I0502 11:24:37.141072 26473 solver.cpp:429]     Test net output #1: loss = 0.10524 (* 1 = 0.10524 loss)
I0502 11:24:37.143981 26473 solver.cpp:242] Iteration 89000 (83.4827 iter/s, 1.19785s/100 iter), loss = 0.0766187
I0502 11:24:37.144001 26473 solver.cpp:261]     Train net output #0: loss = 0.0766187 (* 1 = 0.0766187 loss)
I0502 11:24:37.144009 26473 sgd_solver.cpp:106] Iteration 89000, lr = 1.67772e-05
I0502 11:24:38.084375 26473 solver.cpp:242] Iteration 89100 (92.9715 iter/s, 1.0756s/100 iter), loss = 0.706802
I0502 11:24:38.084421 26473 solver.cpp:261]     Train net output #0: loss = 0.706802 (* 1 = 0.706802 loss)
I0502 11:24:38.084430 26473 sgd_solver.cpp:106] Iteration 89100, lr = 1.67772e-05
I0502 11:24:38.089180 26473 solver.cpp:242] Iteration 89100 (105.802 iter/s, 0.945161s/100 iter), loss = 0.0268024
I0502 11:24:38.089203 26473 solver.cpp:261]     Train net output #0: loss = 0.0268024 (* 1 = 0.0268024 loss)
I0502 11:24:38.089212 26473 sgd_solver.cpp:106] Iteration 89100, lr = 1.67772e-05
I0502 11:24:39.047176 26473 solver.cpp:242] Iteration 89200 (103.872 iter/s, 0.962727s/100 iter), loss = 0.304718
I0502 11:24:39.047237 26473 solver.cpp:261]     Train net output #0: loss = 0.304718 (* 1 = 0.304718 loss)
I0502 11:24:39.047247 26473 sgd_solver.cpp:106] Iteration 89200, lr = 1.67772e-05
I0502 11:24:39.052078 26473 solver.cpp:242] Iteration 89200 (103.858 iter/s, 0.962856s/100 iter), loss = 0.0231512
I0502 11:24:39.052104 26473 solver.cpp:261]     Train net output #0: loss = 0.0231512 (* 1 = 0.0231512 loss)
I0502 11:24:39.052112 26473 sgd_solver.cpp:106] Iteration 89200, lr = 1.67772e-05
I0502 11:24:39.991873 26473 solver.cpp:242] Iteration 89300 (105.864 iter/s, 0.944608s/100 iter), loss = 0.101844
I0502 11:24:39.991919 26473 solver.cpp:261]     Train net output #0: loss = 0.101844 (* 1 = 0.101844 loss)
I0502 11:24:39.991928 26473 sgd_solver.cpp:106] Iteration 89300, lr = 1.67772e-05
I0502 11:24:39.996704 26473 solver.cpp:242] Iteration 89300 (105.867 iter/s, 0.944582s/100 iter), loss = 0.0870823
I0502 11:24:39.996727 26473 solver.cpp:261]     Train net output #0: loss = 0.0870823 (* 1 = 0.0870823 loss)
I0502 11:24:39.996737 26473 sgd_solver.cpp:106] Iteration 89300, lr = 1.67772e-05
I0502 11:24:40.935783 26473 solver.cpp:242] Iteration 89400 (105.95 iter/s, 0.943839s/100 iter), loss = 0.947491
I0502 11:24:40.935824 26473 solver.cpp:261]     Train net output #0: loss = 0.947491 (* 1 = 0.947491 loss)
I0502 11:24:40.935833 26473 sgd_solver.cpp:106] Iteration 89400, lr = 1.67772e-05
I0502 11:24:40.940698 26473 solver.cpp:242] Iteration 89400 (105.939 iter/s, 0.943944s/100 iter), loss = 0.148283
I0502 11:24:40.940721 26473 solver.cpp:261]     Train net output #0: loss = 0.148283 (* 1 = 0.148283 loss)
I0502 11:24:40.940731 26473 sgd_solver.cpp:106] Iteration 89400, lr = 1.67772e-05
I0502 11:24:41.877246 26473 solver.cpp:362] Iteration 89500, Testing net (#0)
I0502 11:24:41.877274 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:42.001592 26473 solver.cpp:429]     Test net output #0: loss = 0.310121 (* 1 = 0.310121 loss)
I0502 11:24:42.004462 26473 solver.cpp:242] Iteration 89500 (93.5787 iter/s, 1.06862s/100 iter), loss = 0.335248
I0502 11:24:42.004482 26473 solver.cpp:261]     Train net output #0: loss = 0.335248 (* 1 = 0.335248 loss)
I0502 11:24:42.004490 26473 sgd_solver.cpp:106] Iteration 89500, lr = 1.67772e-05
I0502 11:24:42.006191 26473 solver.cpp:362] Iteration 89500, Testing net (#0)
I0502 11:24:42.006206 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:42.137032 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9395
I0502 11:24:42.137054 26473 solver.cpp:429]     Test net output #1: loss = 0.106956 (* 1 = 0.106956 loss)
I0502 11:24:42.139978 26473 solver.cpp:242] Iteration 89500 (83.3864 iter/s, 1.19924s/100 iter), loss = 0.0699642
I0502 11:24:42.139998 26473 solver.cpp:261]     Train net output #0: loss = 0.0699642 (* 1 = 0.0699642 loss)
I0502 11:24:42.140007 26473 sgd_solver.cpp:106] Iteration 89500, lr = 1.67772e-05
I0502 11:24:43.079216 26473 solver.cpp:242] Iteration 89600 (93.0491 iter/s, 1.0747s/100 iter), loss = 0.31254
I0502 11:24:43.079258 26473 solver.cpp:261]     Train net output #0: loss = 0.31254 (* 1 = 0.31254 loss)
I0502 11:24:43.079267 26473 sgd_solver.cpp:106] Iteration 89600, lr = 1.67772e-05
I0502 11:24:43.084029 26473 solver.cpp:242] Iteration 89600 (105.931 iter/s, 0.944012s/100 iter), loss = 0.0775352
I0502 11:24:43.084053 26473 solver.cpp:261]     Train net output #0: loss = 0.0775352 (* 1 = 0.0775352 loss)
I0502 11:24:43.084060 26473 sgd_solver.cpp:106] Iteration 89600, lr = 1.67772e-05
I0502 11:24:44.022481 26473 solver.cpp:242] Iteration 89700 (106.023 iter/s, 0.943194s/100 iter), loss = 0.127322
I0502 11:24:44.022521 26473 solver.cpp:261]     Train net output #0: loss = 0.127322 (* 1 = 0.127322 loss)
I0502 11:24:44.022529 26473 sgd_solver.cpp:106] Iteration 89700, lr = 1.67772e-05
I0502 11:24:44.027282 26473 solver.cpp:242] Iteration 89700 (106.021 iter/s, 0.943213s/100 iter), loss = 0.0199797
I0502 11:24:44.027305 26473 solver.cpp:261]     Train net output #0: loss = 0.0199797 (* 1 = 0.0199797 loss)
I0502 11:24:44.027314 26473 sgd_solver.cpp:106] Iteration 89700, lr = 1.67772e-05
I0502 11:24:44.967026 26473 solver.cpp:242] Iteration 89800 (105.879 iter/s, 0.944477s/100 iter), loss = 0.203549
I0502 11:24:44.967068 26473 solver.cpp:261]     Train net output #0: loss = 0.203549 (* 1 = 0.203549 loss)
I0502 11:24:44.967077 26473 sgd_solver.cpp:106] Iteration 89800, lr = 1.67772e-05
I0502 11:24:44.971827 26473 solver.cpp:242] Iteration 89800 (105.876 iter/s, 0.944504s/100 iter), loss = 0.0932985
I0502 11:24:44.971849 26473 solver.cpp:261]     Train net output #0: loss = 0.0932985 (* 1 = 0.0932985 loss)
I0502 11:24:44.971858 26473 sgd_solver.cpp:106] Iteration 89800, lr = 1.67772e-05
I0502 11:24:45.910646 26473 solver.cpp:242] Iteration 89900 (105.983 iter/s, 0.943552s/100 iter), loss = 0.19626
I0502 11:24:45.910691 26473 solver.cpp:261]     Train net output #0: loss = 0.19626 (* 1 = 0.19626 loss)
I0502 11:24:45.910701 26473 sgd_solver.cpp:106] Iteration 89900, lr = 1.67772e-05
I0502 11:24:45.915447 26473 solver.cpp:242] Iteration 89900 (105.979 iter/s, 0.94358s/100 iter), loss = 0.0997592
I0502 11:24:45.915472 26473 solver.cpp:261]     Train net output #0: loss = 0.0997592 (* 1 = 0.0997592 loss)
I0502 11:24:45.915482 26473 sgd_solver.cpp:106] Iteration 89900, lr = 1.67772e-05
I0502 11:24:46.852532 26473 solver.cpp:362] Iteration 90000, Testing net (#0)
I0502 11:24:46.852560 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:46.976696 26473 solver.cpp:429]     Test net output #0: loss = 0.263162 (* 1 = 0.263162 loss)
I0502 11:24:46.979589 26473 solver.cpp:242] Iteration 90000 (93.5559 iter/s, 1.06888s/100 iter), loss = 0.056204
I0502 11:24:46.979609 26473 solver.cpp:261]     Train net output #0: loss = 0.056204 (* 1 = 0.056204 loss)
I0502 11:24:46.979617 26473 sgd_solver.cpp:106] Iteration 90000, lr = 1.34218e-05
I0502 11:24:46.981348 26473 solver.cpp:362] Iteration 90000, Testing net (#0)
I0502 11:24:46.981361 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:47.112082 26473 solver.cpp:429]     Test net output #0: accuracy = 0.956
I0502 11:24:47.112102 26473 solver.cpp:429]     Test net output #1: loss = 0.0970227 (* 1 = 0.0970227 loss)
I0502 11:24:47.115032 26473 solver.cpp:242] Iteration 90000 (83.3653 iter/s, 1.19954s/100 iter), loss = 0.0773126
I0502 11:24:47.115061 26473 solver.cpp:261]     Train net output #0: loss = 0.0773126 (* 1 = 0.0773126 loss)
I0502 11:24:47.115070 26473 sgd_solver.cpp:106] Iteration 90000, lr = 1.34218e-05
I0502 11:24:48.054179 26473 solver.cpp:242] Iteration 90100 (93.0632 iter/s, 1.07454s/100 iter), loss = 0.349695
I0502 11:24:48.054216 26473 solver.cpp:261]     Train net output #0: loss = 0.349695 (* 1 = 0.349695 loss)
I0502 11:24:48.054225 26473 sgd_solver.cpp:106] Iteration 90100, lr = 1.34218e-05
I0502 11:24:48.059005 26473 solver.cpp:242] Iteration 90100 (105.94 iter/s, 0.943926s/100 iter), loss = 0.072693
I0502 11:24:48.059028 26473 solver.cpp:261]     Train net output #0: loss = 0.072693 (* 1 = 0.072693 loss)
I0502 11:24:48.059036 26473 sgd_solver.cpp:106] Iteration 90100, lr = 1.34218e-05
I0502 11:24:48.998690 26473 solver.cpp:242] Iteration 90200 (105.882 iter/s, 0.944447s/100 iter), loss = 0.106831
I0502 11:24:48.998728 26473 solver.cpp:261]     Train net output #0: loss = 0.106831 (* 1 = 0.106831 loss)
I0502 11:24:48.998736 26473 sgd_solver.cpp:106] Iteration 90200, lr = 1.34218e-05
I0502 11:24:49.003494 26473 solver.cpp:242] Iteration 90200 (105.882 iter/s, 0.944448s/100 iter), loss = 0.251046
I0502 11:24:49.003516 26473 solver.cpp:261]     Train net output #0: loss = 0.251046 (* 1 = 0.251046 loss)
I0502 11:24:49.003525 26473 sgd_solver.cpp:106] Iteration 90200, lr = 1.34218e-05
I0502 11:24:49.942181 26473 solver.cpp:242] Iteration 90300 (105.996 iter/s, 0.943429s/100 iter), loss = 0.109715
I0502 11:24:49.942217 26473 solver.cpp:261]     Train net output #0: loss = 0.109715 (* 1 = 0.109715 loss)
I0502 11:24:49.942225 26473 sgd_solver.cpp:106] Iteration 90300, lr = 1.34218e-05
I0502 11:24:49.946991 26473 solver.cpp:242] Iteration 90300 (105.993 iter/s, 0.943457s/100 iter), loss = 0.0383578
I0502 11:24:49.947015 26473 solver.cpp:261]     Train net output #0: loss = 0.0383578 (* 1 = 0.0383578 loss)
I0502 11:24:49.947022 26473 sgd_solver.cpp:106] Iteration 90300, lr = 1.34218e-05
I0502 11:24:50.886061 26473 solver.cpp:242] Iteration 90400 (105.953 iter/s, 0.943819s/100 iter), loss = 0.443009
I0502 11:24:50.886101 26473 solver.cpp:261]     Train net output #0: loss = 0.443009 (* 1 = 0.443009 loss)
I0502 11:24:50.886109 26473 sgd_solver.cpp:106] Iteration 90400, lr = 1.34218e-05
I0502 11:24:50.890872 26473 solver.cpp:242] Iteration 90400 (105.95 iter/s, 0.94384s/100 iter), loss = 0.00123339
I0502 11:24:50.890893 26473 solver.cpp:261]     Train net output #0: loss = 0.00123339 (* 1 = 0.00123339 loss)
I0502 11:24:50.890902 26473 sgd_solver.cpp:106] Iteration 90400, lr = 1.34218e-05
I0502 11:24:51.826622 26473 solver.cpp:362] Iteration 90500, Testing net (#0)
I0502 11:24:51.826652 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:51.951050 26473 solver.cpp:429]     Test net output #0: loss = 0.24227 (* 1 = 0.24227 loss)
I0502 11:24:51.953918 26473 solver.cpp:242] Iteration 90500 (93.6505 iter/s, 1.0678s/100 iter), loss = 0.0712199
I0502 11:24:51.953938 26473 solver.cpp:261]     Train net output #0: loss = 0.0712199 (* 1 = 0.0712199 loss)
I0502 11:24:51.953948 26473 sgd_solver.cpp:106] Iteration 90500, lr = 1.34218e-05
I0502 11:24:51.955636 26473 solver.cpp:362] Iteration 90500, Testing net (#0)
I0502 11:24:51.955649 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:52.086315 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:24:52.086333 26473 solver.cpp:429]     Test net output #1: loss = 0.0994252 (* 1 = 0.0994252 loss)
I0502 11:24:52.089251 26473 solver.cpp:242] Iteration 90500 (83.449 iter/s, 1.19834s/100 iter), loss = 0.00615173
I0502 11:24:52.089272 26473 solver.cpp:261]     Train net output #0: loss = 0.00615173 (* 1 = 0.00615173 loss)
I0502 11:24:52.089280 26473 sgd_solver.cpp:106] Iteration 90500, lr = 1.34218e-05
I0502 11:24:53.029356 26473 solver.cpp:242] Iteration 90600 (92.9902 iter/s, 1.07538s/100 iter), loss = 1.05299
I0502 11:24:53.029397 26473 solver.cpp:261]     Train net output #0: loss = 1.05299 (* 1 = 1.05299 loss)
I0502 11:24:53.029405 26473 sgd_solver.cpp:106] Iteration 90600, lr = 1.34218e-05
I0502 11:24:53.034185 26473 solver.cpp:242] Iteration 90600 (105.832 iter/s, 0.944896s/100 iter), loss = 0.0270732
I0502 11:24:53.034209 26473 solver.cpp:261]     Train net output #0: loss = 0.0270732 (* 1 = 0.0270732 loss)
I0502 11:24:53.034217 26473 sgd_solver.cpp:106] Iteration 90600, lr = 1.34218e-05
I0502 11:24:53.974113 26473 solver.cpp:242] Iteration 90700 (105.855 iter/s, 0.944686s/100 iter), loss = 0.649416
I0502 11:24:53.974158 26473 solver.cpp:261]     Train net output #0: loss = 0.649416 (* 1 = 0.649416 loss)
I0502 11:24:53.974166 26473 sgd_solver.cpp:106] Iteration 90700, lr = 1.34218e-05
I0502 11:24:53.978919 26473 solver.cpp:242] Iteration 90700 (105.854 iter/s, 0.944694s/100 iter), loss = 0.148684
I0502 11:24:53.978943 26473 solver.cpp:261]     Train net output #0: loss = 0.148684 (* 1 = 0.148684 loss)
I0502 11:24:53.978951 26473 sgd_solver.cpp:106] Iteration 90700, lr = 1.34218e-05
I0502 11:24:54.919009 26473 solver.cpp:242] Iteration 90800 (105.84 iter/s, 0.944824s/100 iter), loss = 0.322372
I0502 11:24:54.919065 26473 solver.cpp:261]     Train net output #0: loss = 0.322372 (* 1 = 0.322372 loss)
I0502 11:24:54.919078 26473 sgd_solver.cpp:106] Iteration 90800, lr = 1.34218e-05
I0502 11:24:54.923882 26473 solver.cpp:242] Iteration 90800 (105.829 iter/s, 0.94492s/100 iter), loss = 0.295398
I0502 11:24:54.923904 26473 solver.cpp:261]     Train net output #0: loss = 0.295398 (* 1 = 0.295398 loss)
I0502 11:24:54.923913 26473 sgd_solver.cpp:106] Iteration 90800, lr = 1.34218e-05
I0502 11:24:55.863778 26473 solver.cpp:242] Iteration 90900 (105.855 iter/s, 0.944686s/100 iter), loss = 1.04996
I0502 11:24:55.863826 26473 solver.cpp:261]     Train net output #0: loss = 1.04996 (* 1 = 1.04996 loss)
I0502 11:24:55.863834 26473 sgd_solver.cpp:106] Iteration 90900, lr = 1.34218e-05
I0502 11:24:55.868602 26473 solver.cpp:242] Iteration 90900 (105.856 iter/s, 0.94468s/100 iter), loss = 0.227572
I0502 11:24:55.868628 26473 solver.cpp:261]     Train net output #0: loss = 0.227572 (* 1 = 0.227572 loss)
I0502 11:24:55.868636 26473 sgd_solver.cpp:106] Iteration 90900, lr = 1.34218e-05
I0502 11:24:56.804930 26473 solver.cpp:362] Iteration 91000, Testing net (#0)
I0502 11:24:56.804960 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:56.929275 26473 solver.cpp:429]     Test net output #0: loss = 0.264289 (* 1 = 0.264289 loss)
I0502 11:24:56.932150 26473 solver.cpp:242] Iteration 91000 (93.6061 iter/s, 1.06831s/100 iter), loss = 0.0787784
I0502 11:24:56.932169 26473 solver.cpp:261]     Train net output #0: loss = 0.0787784 (* 1 = 0.0787784 loss)
I0502 11:24:56.932178 26473 sgd_solver.cpp:106] Iteration 91000, lr = 1.34218e-05
I0502 11:24:56.933882 26473 solver.cpp:362] Iteration 91000, Testing net (#0)
I0502 11:24:56.933897 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:24:57.064478 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:24:57.064501 26473 solver.cpp:429]     Test net output #1: loss = 0.0853474 (* 1 = 0.0853474 loss)
I0502 11:24:57.067425 26473 solver.cpp:242] Iteration 91000 (83.4183 iter/s, 1.19878s/100 iter), loss = 0.175754
I0502 11:24:57.067445 26473 solver.cpp:261]     Train net output #0: loss = 0.175754 (* 1 = 0.175754 loss)
I0502 11:24:57.067454 26473 sgd_solver.cpp:106] Iteration 91000, lr = 1.34218e-05
I0502 11:24:58.006850 26473 solver.cpp:242] Iteration 91100 (93.0539 iter/s, 1.07465s/100 iter), loss = 0.153196
I0502 11:24:58.006891 26473 solver.cpp:261]     Train net output #0: loss = 0.153196 (* 1 = 0.153196 loss)
I0502 11:24:58.006901 26473 sgd_solver.cpp:106] Iteration 91100, lr = 1.34218e-05
I0502 11:24:58.011662 26473 solver.cpp:242] Iteration 91100 (105.91 iter/s, 0.944199s/100 iter), loss = 0.0357637
I0502 11:24:58.011685 26473 solver.cpp:261]     Train net output #0: loss = 0.0357637 (* 1 = 0.0357637 loss)
I0502 11:24:58.011694 26473 sgd_solver.cpp:106] Iteration 91100, lr = 1.34218e-05
I0502 11:24:58.950599 26473 solver.cpp:242] Iteration 91200 (105.968 iter/s, 0.94368s/100 iter), loss = 0.111425
I0502 11:24:58.950650 26473 solver.cpp:261]     Train net output #0: loss = 0.111425 (* 1 = 0.111425 loss)
I0502 11:24:58.950660 26473 sgd_solver.cpp:106] Iteration 91200, lr = 1.34218e-05
I0502 11:24:58.955430 26473 solver.cpp:242] Iteration 91200 (105.963 iter/s, 0.943726s/100 iter), loss = 0.0538981
I0502 11:24:58.955451 26473 solver.cpp:261]     Train net output #0: loss = 0.0538981 (* 1 = 0.0538981 loss)
I0502 11:24:58.955461 26473 sgd_solver.cpp:106] Iteration 91200, lr = 1.34218e-05
I0502 11:24:59.894335 26473 solver.cpp:242] Iteration 91300 (105.971 iter/s, 0.943657s/100 iter), loss = 0.156286
I0502 11:24:59.894376 26473 solver.cpp:261]     Train net output #0: loss = 0.156286 (* 1 = 0.156286 loss)
I0502 11:24:59.894385 26473 sgd_solver.cpp:106] Iteration 91300, lr = 1.34218e-05
I0502 11:24:59.899142 26473 solver.cpp:242] Iteration 91300 (105.969 iter/s, 0.943672s/100 iter), loss = 0.0669906
I0502 11:24:59.899165 26473 solver.cpp:261]     Train net output #0: loss = 0.0669906 (* 1 = 0.0669906 loss)
I0502 11:24:59.899174 26473 sgd_solver.cpp:106] Iteration 91300, lr = 1.34218e-05
I0502 11:25:00.852623 26473 solver.cpp:242] Iteration 91400 (104.36 iter/s, 0.958219s/100 iter), loss = 0.384632
I0502 11:25:00.852669 26473 solver.cpp:261]     Train net output #0: loss = 0.384632 (* 1 = 0.384632 loss)
I0502 11:25:00.852677 26473 sgd_solver.cpp:106] Iteration 91400, lr = 1.34218e-05
I0502 11:25:00.857439 26473 solver.cpp:242] Iteration 91400 (104.356 iter/s, 0.958255s/100 iter), loss = 0.115961
I0502 11:25:00.857461 26473 solver.cpp:261]     Train net output #0: loss = 0.115961 (* 1 = 0.115961 loss)
I0502 11:25:00.857470 26473 sgd_solver.cpp:106] Iteration 91400, lr = 1.34218e-05
I0502 11:25:01.792914 26473 solver.cpp:362] Iteration 91500, Testing net (#0)
I0502 11:25:01.792938 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:01.917223 26473 solver.cpp:429]     Test net output #0: loss = 0.268306 (* 1 = 0.268306 loss)
I0502 11:25:01.920081 26473 solver.cpp:242] Iteration 91500 (93.686 iter/s, 1.06739s/100 iter), loss = 0.277621
I0502 11:25:01.920100 26473 solver.cpp:261]     Train net output #0: loss = 0.277621 (* 1 = 0.277621 loss)
I0502 11:25:01.920109 26473 sgd_solver.cpp:106] Iteration 91500, lr = 1.34218e-05
I0502 11:25:01.921811 26473 solver.cpp:362] Iteration 91500, Testing net (#0)
I0502 11:25:01.921824 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:02.052301 26473 solver.cpp:429]     Test net output #0: accuracy = 0.948
I0502 11:25:02.052322 26473 solver.cpp:429]     Test net output #1: loss = 0.117883 (* 1 = 0.117883 loss)
I0502 11:25:02.055246 26473 solver.cpp:242] Iteration 91500 (83.4889 iter/s, 1.19776s/100 iter), loss = 0.191703
I0502 11:25:02.055266 26473 solver.cpp:261]     Train net output #0: loss = 0.191703 (* 1 = 0.191703 loss)
I0502 11:25:02.055274 26473 sgd_solver.cpp:106] Iteration 91500, lr = 1.34218e-05
I0502 11:25:02.996429 26473 solver.cpp:242] Iteration 91600 (92.9115 iter/s, 1.07629s/100 iter), loss = 0.0555666
I0502 11:25:02.996469 26473 solver.cpp:261]     Train net output #0: loss = 0.0555666 (* 1 = 0.0555666 loss)
I0502 11:25:02.996479 26473 sgd_solver.cpp:106] Iteration 91600, lr = 1.34218e-05
I0502 11:25:03.001281 26473 solver.cpp:242] Iteration 91600 (105.709 iter/s, 0.945996s/100 iter), loss = 0.145437
I0502 11:25:03.001305 26473 solver.cpp:261]     Train net output #0: loss = 0.145437 (* 1 = 0.145437 loss)
I0502 11:25:03.001314 26473 sgd_solver.cpp:106] Iteration 91600, lr = 1.34218e-05
I0502 11:25:03.939625 26473 solver.cpp:242] Iteration 91700 (106.03 iter/s, 0.943126s/100 iter), loss = 0.30141
I0502 11:25:03.939663 26473 solver.cpp:261]     Train net output #0: loss = 0.30141 (* 1 = 0.30141 loss)
I0502 11:25:03.939672 26473 sgd_solver.cpp:106] Iteration 91700, lr = 1.34218e-05
I0502 11:25:03.944450 26473 solver.cpp:242] Iteration 91700 (106.03 iter/s, 0.943128s/100 iter), loss = 0.171384
I0502 11:25:03.944474 26473 solver.cpp:261]     Train net output #0: loss = 0.171384 (* 1 = 0.171384 loss)
I0502 11:25:03.944483 26473 sgd_solver.cpp:106] Iteration 91700, lr = 1.34218e-05
I0502 11:25:04.884383 26473 solver.cpp:242] Iteration 91800 (105.855 iter/s, 0.944692s/100 iter), loss = 0.171766
I0502 11:25:04.884421 26473 solver.cpp:261]     Train net output #0: loss = 0.171766 (* 1 = 0.171766 loss)
I0502 11:25:04.884429 26473 sgd_solver.cpp:106] Iteration 91800, lr = 1.34218e-05
I0502 11:25:04.889191 26473 solver.cpp:242] Iteration 91800 (105.854 iter/s, 0.944699s/100 iter), loss = 0.0682888
I0502 11:25:04.889214 26473 solver.cpp:261]     Train net output #0: loss = 0.0682888 (* 1 = 0.0682888 loss)
I0502 11:25:04.889222 26473 sgd_solver.cpp:106] Iteration 91800, lr = 1.34218e-05
I0502 11:25:05.828490 26473 solver.cpp:242] Iteration 91900 (105.928 iter/s, 0.944041s/100 iter), loss = 0.14327
I0502 11:25:05.828536 26473 solver.cpp:261]     Train net output #0: loss = 0.14327 (* 1 = 0.14327 loss)
I0502 11:25:05.828546 26473 sgd_solver.cpp:106] Iteration 91900, lr = 1.34218e-05
I0502 11:25:05.833317 26473 solver.cpp:242] Iteration 91900 (105.923 iter/s, 0.944084s/100 iter), loss = 0.14564
I0502 11:25:05.833340 26473 solver.cpp:261]     Train net output #0: loss = 0.14564 (* 1 = 0.14564 loss)
I0502 11:25:05.833349 26473 sgd_solver.cpp:106] Iteration 91900, lr = 1.34218e-05
I0502 11:25:06.768970 26473 solver.cpp:362] Iteration 92000, Testing net (#0)
I0502 11:25:06.768990 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:06.893393 26473 solver.cpp:429]     Test net output #0: loss = 0.242862 (* 1 = 0.242862 loss)
I0502 11:25:06.896255 26473 solver.cpp:242] Iteration 92000 (93.6593 iter/s, 1.0677s/100 iter), loss = 0.340563
I0502 11:25:06.896273 26473 solver.cpp:261]     Train net output #0: loss = 0.340563 (* 1 = 0.340563 loss)
I0502 11:25:06.896281 26473 sgd_solver.cpp:106] Iteration 92000, lr = 1.34218e-05
I0502 11:25:06.898035 26473 solver.cpp:362] Iteration 92000, Testing net (#0)
I0502 11:25:06.898047 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:07.028563 26473 solver.cpp:429]     Test net output #0: accuracy = 0.951
I0502 11:25:07.028583 26473 solver.cpp:429]     Test net output #1: loss = 0.0985111 (* 1 = 0.0985111 loss)
I0502 11:25:07.031504 26473 solver.cpp:242] Iteration 92000 (83.4625 iter/s, 1.19814s/100 iter), loss = 0.0535711
I0502 11:25:07.031523 26473 solver.cpp:261]     Train net output #0: loss = 0.0535711 (* 1 = 0.0535711 loss)
I0502 11:25:07.031533 26473 sgd_solver.cpp:106] Iteration 92000, lr = 1.34218e-05
I0502 11:25:07.969808 26473 solver.cpp:242] Iteration 92100 (93.1526 iter/s, 1.07351s/100 iter), loss = 0.226871
I0502 11:25:07.969851 26473 solver.cpp:261]     Train net output #0: loss = 0.226871 (* 1 = 0.226871 loss)
I0502 11:25:07.969858 26473 sgd_solver.cpp:106] Iteration 92100, lr = 1.34218e-05
I0502 11:25:07.974673 26473 solver.cpp:242] Iteration 92100 (106.03 iter/s, 0.943125s/100 iter), loss = 0.124203
I0502 11:25:07.974697 26473 solver.cpp:261]     Train net output #0: loss = 0.124203 (* 1 = 0.124203 loss)
I0502 11:25:07.974706 26473 sgd_solver.cpp:106] Iteration 92100, lr = 1.34218e-05
I0502 11:25:08.914899 26473 solver.cpp:242] Iteration 92200 (105.818 iter/s, 0.945018s/100 iter), loss = 0.140639
I0502 11:25:08.914942 26473 solver.cpp:261]     Train net output #0: loss = 0.140639 (* 1 = 0.140639 loss)
I0502 11:25:08.914950 26473 sgd_solver.cpp:106] Iteration 92200, lr = 1.34218e-05
I0502 11:25:08.919729 26473 solver.cpp:242] Iteration 92200 (105.819 iter/s, 0.945013s/100 iter), loss = 0.0451745
I0502 11:25:08.919752 26473 solver.cpp:261]     Train net output #0: loss = 0.0451745 (* 1 = 0.0451745 loss)
I0502 11:25:08.919761 26473 sgd_solver.cpp:106] Iteration 92200, lr = 1.34218e-05
I0502 11:25:09.858619 26473 solver.cpp:242] Iteration 92300 (105.972 iter/s, 0.943648s/100 iter), loss = 0.502392
I0502 11:25:09.858661 26473 solver.cpp:261]     Train net output #0: loss = 0.502392 (* 1 = 0.502392 loss)
I0502 11:25:09.858680 26473 sgd_solver.cpp:106] Iteration 92300, lr = 1.34218e-05
I0502 11:25:09.863428 26473 solver.cpp:242] Iteration 92300 (105.971 iter/s, 0.943658s/100 iter), loss = 0.16076
I0502 11:25:09.863462 26473 solver.cpp:261]     Train net output #0: loss = 0.16076 (* 1 = 0.16076 loss)
I0502 11:25:09.863472 26473 sgd_solver.cpp:106] Iteration 92300, lr = 1.34218e-05
I0502 11:25:10.802671 26473 solver.cpp:242] Iteration 92400 (105.934 iter/s, 0.943983s/100 iter), loss = 0.237324
I0502 11:25:10.802729 26473 solver.cpp:261]     Train net output #0: loss = 0.237324 (* 1 = 0.237324 loss)
I0502 11:25:10.802742 26473 sgd_solver.cpp:106] Iteration 92400, lr = 1.34218e-05
I0502 11:25:10.807545 26473 solver.cpp:242] Iteration 92400 (105.925 iter/s, 0.944065s/100 iter), loss = 0.0649151
I0502 11:25:10.807569 26473 solver.cpp:261]     Train net output #0: loss = 0.0649151 (* 1 = 0.0649151 loss)
I0502 11:25:10.807577 26473 sgd_solver.cpp:106] Iteration 92400, lr = 1.34218e-05
I0502 11:25:11.743963 26473 solver.cpp:362] Iteration 92500, Testing net (#0)
I0502 11:25:11.743991 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:11.868311 26473 solver.cpp:429]     Test net output #0: loss = 0.233541 (* 1 = 0.233541 loss)
I0502 11:25:11.871202 26473 solver.cpp:242] Iteration 92500 (93.5931 iter/s, 1.06845s/100 iter), loss = 0.171979
I0502 11:25:11.871222 26473 solver.cpp:261]     Train net output #0: loss = 0.171979 (* 1 = 0.171979 loss)
I0502 11:25:11.871230 26473 sgd_solver.cpp:106] Iteration 92500, lr = 1.34218e-05
I0502 11:25:11.872931 26473 solver.cpp:362] Iteration 92500, Testing net (#0)
I0502 11:25:11.872946 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:12.003497 26473 solver.cpp:429]     Test net output #0: accuracy = 0.952
I0502 11:25:12.003517 26473 solver.cpp:429]     Test net output #1: loss = 0.0995772 (* 1 = 0.0995772 loss)
I0502 11:25:12.006448 26473 solver.cpp:242] Iteration 92500 (83.4127 iter/s, 1.19886s/100 iter), loss = 0.00733825
I0502 11:25:12.006467 26473 solver.cpp:261]     Train net output #0: loss = 0.00733825 (* 1 = 0.00733825 loss)
I0502 11:25:12.006476 26473 sgd_solver.cpp:106] Iteration 92500, lr = 1.34218e-05
I0502 11:25:12.946154 26473 solver.cpp:242] Iteration 92600 (93.0315 iter/s, 1.07491s/100 iter), loss = 0.0455964
I0502 11:25:12.946197 26473 solver.cpp:261]     Train net output #0: loss = 0.0455964 (* 1 = 0.0455964 loss)
I0502 11:25:12.946205 26473 sgd_solver.cpp:106] Iteration 92600, lr = 1.34218e-05
I0502 11:25:12.951045 26473 solver.cpp:242] Iteration 92600 (105.87 iter/s, 0.944554s/100 iter), loss = 0.0872954
I0502 11:25:12.951068 26473 solver.cpp:261]     Train net output #0: loss = 0.0872954 (* 1 = 0.0872954 loss)
I0502 11:25:12.951076 26473 sgd_solver.cpp:106] Iteration 92600, lr = 1.34218e-05
I0502 11:25:13.890080 26473 solver.cpp:242] Iteration 92700 (105.949 iter/s, 0.943854s/100 iter), loss = 0.103963
I0502 11:25:13.890120 26473 solver.cpp:261]     Train net output #0: loss = 0.103963 (* 1 = 0.103963 loss)
I0502 11:25:13.890128 26473 sgd_solver.cpp:106] Iteration 92700, lr = 1.34218e-05
I0502 11:25:13.894882 26473 solver.cpp:242] Iteration 92700 (105.955 iter/s, 0.943796s/100 iter), loss = 0.00729705
I0502 11:25:13.894906 26473 solver.cpp:261]     Train net output #0: loss = 0.00729705 (* 1 = 0.00729705 loss)
I0502 11:25:13.894914 26473 sgd_solver.cpp:106] Iteration 92700, lr = 1.34218e-05
I0502 11:25:14.837069 26473 solver.cpp:242] Iteration 92800 (105.606 iter/s, 0.946919s/100 iter), loss = 0.183746
I0502 11:25:14.837105 26473 solver.cpp:261]     Train net output #0: loss = 0.183746 (* 1 = 0.183746 loss)
I0502 11:25:14.837115 26473 sgd_solver.cpp:106] Iteration 92800, lr = 1.34218e-05
I0502 11:25:14.841855 26473 solver.cpp:242] Iteration 92800 (105.604 iter/s, 0.94693s/100 iter), loss = 0.0912585
I0502 11:25:14.841876 26473 solver.cpp:261]     Train net output #0: loss = 0.0912585 (* 1 = 0.0912585 loss)
I0502 11:25:14.841886 26473 sgd_solver.cpp:106] Iteration 92800, lr = 1.34218e-05
I0502 11:25:15.781193 26473 solver.cpp:242] Iteration 92900 (105.926 iter/s, 0.944058s/100 iter), loss = 0.0776537
I0502 11:25:15.781241 26473 solver.cpp:261]     Train net output #0: loss = 0.0776537 (* 1 = 0.0776537 loss)
I0502 11:25:15.781250 26473 sgd_solver.cpp:106] Iteration 92900, lr = 1.34218e-05
I0502 11:25:15.786000 26473 solver.cpp:242] Iteration 92900 (105.92 iter/s, 0.944105s/100 iter), loss = 0.0780792
I0502 11:25:15.786023 26473 solver.cpp:261]     Train net output #0: loss = 0.0780792 (* 1 = 0.0780792 loss)
I0502 11:25:15.786032 26473 sgd_solver.cpp:106] Iteration 92900, lr = 1.34218e-05
I0502 11:25:16.723141 26473 solver.cpp:362] Iteration 93000, Testing net (#0)
I0502 11:25:16.723166 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:16.847518 26473 solver.cpp:429]     Test net output #0: loss = 0.258968 (* 1 = 0.258968 loss)
I0502 11:25:16.850385 26473 solver.cpp:242] Iteration 93000 (93.5344 iter/s, 1.06913s/100 iter), loss = 0.226683
I0502 11:25:16.850406 26473 solver.cpp:261]     Train net output #0: loss = 0.226683 (* 1 = 0.226683 loss)
I0502 11:25:16.850414 26473 sgd_solver.cpp:106] Iteration 93000, lr = 1.34218e-05
I0502 11:25:16.852090 26473 solver.cpp:362] Iteration 93000, Testing net (#0)
I0502 11:25:16.852103 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:16.982887 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9555
I0502 11:25:16.982908 26473 solver.cpp:429]     Test net output #1: loss = 0.100939 (* 1 = 0.100939 loss)
I0502 11:25:16.985852 26473 solver.cpp:242] Iteration 93000 (83.3467 iter/s, 1.19981s/100 iter), loss = 0.0677508
I0502 11:25:16.985872 26473 solver.cpp:261]     Train net output #0: loss = 0.0677508 (* 1 = 0.0677508 loss)
I0502 11:25:16.985882 26473 sgd_solver.cpp:106] Iteration 93000, lr = 1.34218e-05
I0502 11:25:17.925163 26473 solver.cpp:242] Iteration 93100 (93.0466 iter/s, 1.07473s/100 iter), loss = 0.268138
I0502 11:25:17.925195 26473 solver.cpp:261]     Train net output #0: loss = 0.268138 (* 1 = 0.268138 loss)
I0502 11:25:17.925204 26473 sgd_solver.cpp:106] Iteration 93100, lr = 1.34218e-05
I0502 11:25:17.930024 26473 solver.cpp:242] Iteration 93100 (105.918 iter/s, 0.944126s/100 iter), loss = 0.0481869
I0502 11:25:17.930048 26473 solver.cpp:261]     Train net output #0: loss = 0.0481869 (* 1 = 0.0481869 loss)
I0502 11:25:17.930057 26473 sgd_solver.cpp:106] Iteration 93100, lr = 1.34218e-05
I0502 11:25:18.869685 26473 solver.cpp:242] Iteration 93200 (105.881 iter/s, 0.94446s/100 iter), loss = 0.275938
I0502 11:25:18.869714 26473 solver.cpp:261]     Train net output #0: loss = 0.275938 (* 1 = 0.275938 loss)
I0502 11:25:18.869724 26473 sgd_solver.cpp:106] Iteration 93200, lr = 1.34218e-05
I0502 11:25:18.874492 26473 solver.cpp:242] Iteration 93200 (105.884 iter/s, 0.944427s/100 iter), loss = 0.0470422
I0502 11:25:18.874516 26473 solver.cpp:261]     Train net output #0: loss = 0.0470422 (* 1 = 0.0470422 loss)
I0502 11:25:18.874523 26473 sgd_solver.cpp:106] Iteration 93200, lr = 1.34218e-05
I0502 11:25:19.814965 26473 solver.cpp:242] Iteration 93300 (105.796 iter/s, 0.94522s/100 iter), loss = 0.126699
I0502 11:25:19.815011 26473 solver.cpp:261]     Train net output #0: loss = 0.126699 (* 1 = 0.126699 loss)
I0502 11:25:19.815019 26473 sgd_solver.cpp:106] Iteration 93300, lr = 1.34218e-05
I0502 11:25:19.819774 26473 solver.cpp:242] Iteration 93300 (105.793 iter/s, 0.945241s/100 iter), loss = 0.166934
I0502 11:25:19.819797 26473 solver.cpp:261]     Train net output #0: loss = 0.166934 (* 1 = 0.166934 loss)
I0502 11:25:19.819805 26473 sgd_solver.cpp:106] Iteration 93300, lr = 1.34218e-05
I0502 11:25:20.759026 26473 solver.cpp:242] Iteration 93400 (105.934 iter/s, 0.943985s/100 iter), loss = 0.366071
I0502 11:25:20.759065 26473 solver.cpp:261]     Train net output #0: loss = 0.366071 (* 1 = 0.366071 loss)
I0502 11:25:20.759074 26473 sgd_solver.cpp:106] Iteration 93400, lr = 1.34218e-05
I0502 11:25:20.763921 26473 solver.cpp:242] Iteration 93400 (105.92 iter/s, 0.944105s/100 iter), loss = 0.0128087
I0502 11:25:20.763943 26473 solver.cpp:261]     Train net output #0: loss = 0.0128087 (* 1 = 0.0128087 loss)
I0502 11:25:20.763952 26473 sgd_solver.cpp:106] Iteration 93400, lr = 1.34218e-05
I0502 11:25:21.700520 26473 solver.cpp:362] Iteration 93500, Testing net (#0)
I0502 11:25:21.700565 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:21.825017 26473 solver.cpp:429]     Test net output #0: loss = 0.224891 (* 1 = 0.224891 loss)
I0502 11:25:21.827893 26473 solver.cpp:242] Iteration 93500 (93.5621 iter/s, 1.06881s/100 iter), loss = 0.155482
I0502 11:25:21.827913 26473 solver.cpp:261]     Train net output #0: loss = 0.155482 (* 1 = 0.155482 loss)
I0502 11:25:21.827921 26473 sgd_solver.cpp:106] Iteration 93500, lr = 1.34218e-05
I0502 11:25:21.829556 26473 solver.cpp:362] Iteration 93500, Testing net (#0)
I0502 11:25:21.829571 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:21.960103 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9455
I0502 11:25:21.960124 26473 solver.cpp:429]     Test net output #1: loss = 0.107254 (* 1 = 0.107254 loss)
I0502 11:25:21.963037 26473 solver.cpp:242] Iteration 93500 (83.3978 iter/s, 1.19907s/100 iter), loss = 0.0105658
I0502 11:25:21.963057 26473 solver.cpp:261]     Train net output #0: loss = 0.0105658 (* 1 = 0.0105658 loss)
I0502 11:25:21.963064 26473 sgd_solver.cpp:106] Iteration 93500, lr = 1.34218e-05
I0502 11:25:22.903486 26473 solver.cpp:242] Iteration 93600 (92.9762 iter/s, 1.07554s/100 iter), loss = 0.0419565
I0502 11:25:22.903529 26473 solver.cpp:261]     Train net output #0: loss = 0.0419565 (* 1 = 0.0419565 loss)
I0502 11:25:22.903538 26473 sgd_solver.cpp:106] Iteration 93600, lr = 1.34218e-05
I0502 11:25:22.908351 26473 solver.cpp:242] Iteration 93600 (105.79 iter/s, 0.945268s/100 iter), loss = 0.109042
I0502 11:25:22.908375 26473 solver.cpp:261]     Train net output #0: loss = 0.109042 (* 1 = 0.109042 loss)
I0502 11:25:22.908385 26473 sgd_solver.cpp:106] Iteration 93600, lr = 1.34218e-05
I0502 11:25:23.846683 26473 solver.cpp:242] Iteration 93700 (106.031 iter/s, 0.943123s/100 iter), loss = 0.386547
I0502 11:25:23.846725 26473 solver.cpp:261]     Train net output #0: loss = 0.386547 (* 1 = 0.386547 loss)
I0502 11:25:23.846735 26473 sgd_solver.cpp:106] Iteration 93700, lr = 1.34218e-05
I0502 11:25:23.851503 26473 solver.cpp:242] Iteration 93700 (106.032 iter/s, 0.943109s/100 iter), loss = 0.0121448
I0502 11:25:23.851526 26473 solver.cpp:261]     Train net output #0: loss = 0.0121448 (* 1 = 0.0121448 loss)
I0502 11:25:23.851534 26473 sgd_solver.cpp:106] Iteration 93700, lr = 1.34218e-05
I0502 11:25:24.790653 26473 solver.cpp:242] Iteration 93800 (105.943 iter/s, 0.9439s/100 iter), loss = 0.365374
I0502 11:25:24.790693 26473 solver.cpp:261]     Train net output #0: loss = 0.365374 (* 1 = 0.365374 loss)
I0502 11:25:24.790701 26473 sgd_solver.cpp:106] Iteration 93800, lr = 1.34218e-05
I0502 11:25:24.795460 26473 solver.cpp:242] Iteration 93800 (105.942 iter/s, 0.943917s/100 iter), loss = 0.0311486
I0502 11:25:24.795482 26473 solver.cpp:261]     Train net output #0: loss = 0.0311486 (* 1 = 0.0311486 loss)
I0502 11:25:24.795490 26473 sgd_solver.cpp:106] Iteration 93800, lr = 1.34218e-05
I0502 11:25:25.734731 26473 solver.cpp:242] Iteration 93900 (105.931 iter/s, 0.94401s/100 iter), loss = 0.10144
I0502 11:25:25.734771 26473 solver.cpp:261]     Train net output #0: loss = 0.10144 (* 1 = 0.10144 loss)
I0502 11:25:25.734781 26473 sgd_solver.cpp:106] Iteration 93900, lr = 1.34218e-05
I0502 11:25:25.739531 26473 solver.cpp:242] Iteration 93900 (105.929 iter/s, 0.94403s/100 iter), loss = 0.0911007
I0502 11:25:25.739553 26473 solver.cpp:261]     Train net output #0: loss = 0.0911007 (* 1 = 0.0911007 loss)
I0502 11:25:25.739562 26473 sgd_solver.cpp:106] Iteration 93900, lr = 1.34218e-05
I0502 11:25:26.675710 26473 solver.cpp:362] Iteration 94000, Testing net (#0)
I0502 11:25:26.675735 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:26.800187 26473 solver.cpp:429]     Test net output #0: loss = 0.30004 (* 1 = 0.30004 loss)
I0502 11:25:26.803071 26473 solver.cpp:242] Iteration 94000 (93.6084 iter/s, 1.06828s/100 iter), loss = 0.114406
I0502 11:25:26.803092 26473 solver.cpp:261]     Train net output #0: loss = 0.114406 (* 1 = 0.114406 loss)
I0502 11:25:26.803100 26473 sgd_solver.cpp:106] Iteration 94000, lr = 1.34218e-05
I0502 11:25:26.804752 26473 solver.cpp:362] Iteration 94000, Testing net (#0)
I0502 11:25:26.804765 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:26.935477 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:25:26.935497 26473 solver.cpp:429]     Test net output #1: loss = 0.0950217 (* 1 = 0.0950217 loss)
I0502 11:25:26.938421 26473 solver.cpp:242] Iteration 94000 (83.4136 iter/s, 1.19885s/100 iter), loss = 0.224794
I0502 11:25:26.938441 26473 solver.cpp:261]     Train net output #0: loss = 0.224794 (* 1 = 0.224794 loss)
I0502 11:25:26.938449 26473 sgd_solver.cpp:106] Iteration 94000, lr = 1.34218e-05
I0502 11:25:27.878655 26473 solver.cpp:242] Iteration 94100 (92.9769 iter/s, 1.07554s/100 iter), loss = 0.255839
I0502 11:25:27.878696 26473 solver.cpp:261]     Train net output #0: loss = 0.255839 (* 1 = 0.255839 loss)
I0502 11:25:27.878705 26473 sgd_solver.cpp:106] Iteration 94100, lr = 1.34218e-05
I0502 11:25:27.883533 26473 solver.cpp:242] Iteration 94100 (105.813 iter/s, 0.945065s/100 iter), loss = 0.00333411
I0502 11:25:27.883555 26473 solver.cpp:261]     Train net output #0: loss = 0.00333411 (* 1 = 0.00333411 loss)
I0502 11:25:27.883564 26473 sgd_solver.cpp:106] Iteration 94100, lr = 1.34218e-05
I0502 11:25:28.822774 26473 solver.cpp:242] Iteration 94200 (105.927 iter/s, 0.944048s/100 iter), loss = 0.0704437
I0502 11:25:28.822809 26473 solver.cpp:261]     Train net output #0: loss = 0.0704437 (* 1 = 0.0704437 loss)
I0502 11:25:28.822818 26473 sgd_solver.cpp:106] Iteration 94200, lr = 1.34218e-05
I0502 11:25:28.827574 26473 solver.cpp:242] Iteration 94200 (105.932 iter/s, 0.944001s/100 iter), loss = 0.144146
I0502 11:25:28.827599 26473 solver.cpp:261]     Train net output #0: loss = 0.144146 (* 1 = 0.144146 loss)
I0502 11:25:28.827606 26473 sgd_solver.cpp:106] Iteration 94200, lr = 1.34218e-05
I0502 11:25:29.766858 26473 solver.cpp:242] Iteration 94300 (105.93 iter/s, 0.944019s/100 iter), loss = 0.349221
I0502 11:25:29.766891 26473 solver.cpp:261]     Train net output #0: loss = 0.349221 (* 1 = 0.349221 loss)
I0502 11:25:29.766901 26473 sgd_solver.cpp:106] Iteration 94300, lr = 1.34218e-05
I0502 11:25:29.771658 26473 solver.cpp:242] Iteration 94300 (105.928 iter/s, 0.944042s/100 iter), loss = 0.11664
I0502 11:25:29.771680 26473 solver.cpp:261]     Train net output #0: loss = 0.11664 (* 1 = 0.11664 loss)
I0502 11:25:29.771689 26473 sgd_solver.cpp:106] Iteration 94300, lr = 1.34218e-05
I0502 11:25:30.710520 26473 solver.cpp:242] Iteration 94400 (105.977 iter/s, 0.943601s/100 iter), loss = 0.0880643
I0502 11:25:30.710559 26473 solver.cpp:261]     Train net output #0: loss = 0.0880643 (* 1 = 0.0880643 loss)
I0502 11:25:30.710568 26473 sgd_solver.cpp:106] Iteration 94400, lr = 1.34218e-05
I0502 11:25:30.715337 26473 solver.cpp:242] Iteration 94400 (105.973 iter/s, 0.943638s/100 iter), loss = 0.233975
I0502 11:25:30.715359 26473 solver.cpp:261]     Train net output #0: loss = 0.233975 (* 1 = 0.233975 loss)
I0502 11:25:30.715368 26473 sgd_solver.cpp:106] Iteration 94400, lr = 1.34218e-05
I0502 11:25:31.651932 26473 solver.cpp:362] Iteration 94500, Testing net (#0)
I0502 11:25:31.651962 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:31.776307 26473 solver.cpp:429]     Test net output #0: loss = 0.295202 (* 1 = 0.295202 loss)
I0502 11:25:31.779199 26473 solver.cpp:242] Iteration 94500 (93.5785 iter/s, 1.06862s/100 iter), loss = 0.237047
I0502 11:25:31.779219 26473 solver.cpp:261]     Train net output #0: loss = 0.237047 (* 1 = 0.237047 loss)
I0502 11:25:31.779227 26473 sgd_solver.cpp:106] Iteration 94500, lr = 1.34218e-05
I0502 11:25:31.780858 26473 solver.cpp:362] Iteration 94500, Testing net (#0)
I0502 11:25:31.780871 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:31.911521 26473 solver.cpp:429]     Test net output #0: accuracy = 0.955
I0502 11:25:31.911556 26473 solver.cpp:429]     Test net output #1: loss = 0.108022 (* 1 = 0.108022 loss)
I0502 11:25:31.914515 26473 solver.cpp:242] Iteration 94500 (83.3935 iter/s, 1.19913s/100 iter), loss = 0.0700339
I0502 11:25:31.914544 26473 solver.cpp:261]     Train net output #0: loss = 0.0700339 (* 1 = 0.0700339 loss)
I0502 11:25:31.914553 26473 sgd_solver.cpp:106] Iteration 94500, lr = 1.34218e-05
I0502 11:25:32.854655 26473 solver.cpp:242] Iteration 94600 (92.9879 iter/s, 1.07541s/100 iter), loss = 0.220122
I0502 11:25:32.854686 26473 solver.cpp:261]     Train net output #0: loss = 0.220122 (* 1 = 0.220122 loss)
I0502 11:25:32.854694 26473 sgd_solver.cpp:106] Iteration 94600, lr = 1.34218e-05
I0502 11:25:32.859544 26473 solver.cpp:242] Iteration 94600 (105.823 iter/s, 0.944973s/100 iter), loss = 0.022567
I0502 11:25:32.859566 26473 solver.cpp:261]     Train net output #0: loss = 0.022567 (* 1 = 0.022567 loss)
I0502 11:25:32.859575 26473 sgd_solver.cpp:106] Iteration 94600, lr = 1.34218e-05
I0502 11:25:33.799134 26473 solver.cpp:242] Iteration 94700 (105.886 iter/s, 0.944416s/100 iter), loss = 0.388879
I0502 11:25:33.799175 26473 solver.cpp:261]     Train net output #0: loss = 0.388879 (* 1 = 0.388879 loss)
I0502 11:25:33.799185 26473 sgd_solver.cpp:106] Iteration 94700, lr = 1.34218e-05
I0502 11:25:33.803932 26473 solver.cpp:242] Iteration 94700 (105.893 iter/s, 0.944347s/100 iter), loss = 0.147323
I0502 11:25:33.803956 26473 solver.cpp:261]     Train net output #0: loss = 0.147323 (* 1 = 0.147323 loss)
I0502 11:25:33.803963 26473 sgd_solver.cpp:106] Iteration 94700, lr = 1.34218e-05
I0502 11:25:34.743446 26473 solver.cpp:242] Iteration 94800 (105.905 iter/s, 0.94424s/100 iter), loss = 0.0857758
I0502 11:25:34.743487 26473 solver.cpp:261]     Train net output #0: loss = 0.0857758 (* 1 = 0.0857758 loss)
I0502 11:25:34.743496 26473 sgd_solver.cpp:106] Iteration 94800, lr = 1.34218e-05
I0502 11:25:34.748291 26473 solver.cpp:242] Iteration 94800 (105.896 iter/s, 0.944319s/100 iter), loss = 0.0485913
I0502 11:25:34.748314 26473 solver.cpp:261]     Train net output #0: loss = 0.0485913 (* 1 = 0.0485913 loss)
I0502 11:25:34.748322 26473 sgd_solver.cpp:106] Iteration 94800, lr = 1.34218e-05
I0502 11:25:35.687316 26473 solver.cpp:242] Iteration 94900 (105.954 iter/s, 0.943801s/100 iter), loss = 0.186871
I0502 11:25:35.687356 26473 solver.cpp:261]     Train net output #0: loss = 0.186871 (* 1 = 0.186871 loss)
I0502 11:25:35.687366 26473 sgd_solver.cpp:106] Iteration 94900, lr = 1.34218e-05
I0502 11:25:35.692124 26473 solver.cpp:242] Iteration 94900 (105.956 iter/s, 0.943792s/100 iter), loss = 0.142379
I0502 11:25:35.692147 26473 solver.cpp:261]     Train net output #0: loss = 0.142379 (* 1 = 0.142379 loss)
I0502 11:25:35.692155 26473 sgd_solver.cpp:106] Iteration 94900, lr = 1.34218e-05
I0502 11:25:36.628921 26473 solver.cpp:362] Iteration 95000, Testing net (#0)
I0502 11:25:36.628947 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:36.753185 26473 solver.cpp:429]     Test net output #0: loss = 0.301124 (* 1 = 0.301124 loss)
I0502 11:25:36.756058 26473 solver.cpp:242] Iteration 95000 (93.5731 iter/s, 1.06868s/100 iter), loss = 0.162838
I0502 11:25:36.756078 26473 solver.cpp:261]     Train net output #0: loss = 0.162838 (* 1 = 0.162838 loss)
I0502 11:25:36.756086 26473 sgd_solver.cpp:106] Iteration 95000, lr = 1.34218e-05
I0502 11:25:36.757724 26473 solver.cpp:362] Iteration 95000, Testing net (#0)
I0502 11:25:36.757736 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:36.888556 26473 solver.cpp:429]     Test net output #0: accuracy = 0.959
I0502 11:25:36.888576 26473 solver.cpp:429]     Test net output #1: loss = 0.0958455 (* 1 = 0.0958455 loss)
I0502 11:25:36.891499 26473 solver.cpp:242] Iteration 95000 (83.3799 iter/s, 1.19933s/100 iter), loss = 0.0908614
I0502 11:25:36.891517 26473 solver.cpp:261]     Train net output #0: loss = 0.0908614 (* 1 = 0.0908614 loss)
I0502 11:25:36.891525 26473 sgd_solver.cpp:106] Iteration 95000, lr = 1.34218e-05
I0502 11:25:37.831995 26473 solver.cpp:242] Iteration 95100 (92.9466 iter/s, 1.07589s/100 iter), loss = 0.156959
I0502 11:25:37.832036 26473 solver.cpp:261]     Train net output #0: loss = 0.156959 (* 1 = 0.156959 loss)
I0502 11:25:37.832044 26473 sgd_solver.cpp:106] Iteration 95100, lr = 1.34218e-05
I0502 11:25:37.836905 26473 solver.cpp:242] Iteration 95100 (105.78 iter/s, 0.94536s/100 iter), loss = 0.184583
I0502 11:25:37.836928 26473 solver.cpp:261]     Train net output #0: loss = 0.184583 (* 1 = 0.184583 loss)
I0502 11:25:37.836936 26473 sgd_solver.cpp:106] Iteration 95100, lr = 1.34218e-05
I0502 11:25:38.776379 26473 solver.cpp:242] Iteration 95200 (105.896 iter/s, 0.944322s/100 iter), loss = 0.146871
I0502 11:25:38.776418 26473 solver.cpp:261]     Train net output #0: loss = 0.146871 (* 1 = 0.146871 loss)
I0502 11:25:38.776427 26473 sgd_solver.cpp:106] Iteration 95200, lr = 1.34218e-05
I0502 11:25:38.781249 26473 solver.cpp:242] Iteration 95200 (105.899 iter/s, 0.944296s/100 iter), loss = 0.127557
I0502 11:25:38.781271 26473 solver.cpp:261]     Train net output #0: loss = 0.127557 (* 1 = 0.127557 loss)
I0502 11:25:38.781280 26473 sgd_solver.cpp:106] Iteration 95200, lr = 1.34218e-05
I0502 11:25:39.720608 26473 solver.cpp:242] Iteration 95300 (105.914 iter/s, 0.94416s/100 iter), loss = 0.270554
I0502 11:25:39.720643 26473 solver.cpp:261]     Train net output #0: loss = 0.270554 (* 1 = 0.270554 loss)
I0502 11:25:39.720651 26473 sgd_solver.cpp:106] Iteration 95300, lr = 1.34218e-05
I0502 11:25:39.725426 26473 solver.cpp:242] Iteration 95300 (105.917 iter/s, 0.944136s/100 iter), loss = 0.0849623
I0502 11:25:39.725450 26473 solver.cpp:261]     Train net output #0: loss = 0.0849623 (* 1 = 0.0849623 loss)
I0502 11:25:39.725457 26473 sgd_solver.cpp:106] Iteration 95300, lr = 1.34218e-05
I0502 11:25:40.664997 26473 solver.cpp:242] Iteration 95400 (105.896 iter/s, 0.944326s/100 iter), loss = 0.781087
I0502 11:25:40.665030 26473 solver.cpp:261]     Train net output #0: loss = 0.781087 (* 1 = 0.781087 loss)
I0502 11:25:40.665038 26473 sgd_solver.cpp:106] Iteration 95400, lr = 1.34218e-05
I0502 11:25:40.669796 26473 solver.cpp:242] Iteration 95400 (105.895 iter/s, 0.94433s/100 iter), loss = 0.0879964
I0502 11:25:40.669819 26473 solver.cpp:261]     Train net output #0: loss = 0.0879964 (* 1 = 0.0879964 loss)
I0502 11:25:40.669828 26473 sgd_solver.cpp:106] Iteration 95400, lr = 1.34218e-05
I0502 11:25:41.605916 26473 solver.cpp:362] Iteration 95500, Testing net (#0)
I0502 11:25:41.605937 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:41.730288 26473 solver.cpp:429]     Test net output #0: loss = 0.335293 (* 1 = 0.335293 loss)
I0502 11:25:41.733155 26473 solver.cpp:242] Iteration 95500 (93.6236 iter/s, 1.06811s/100 iter), loss = 0.0784882
I0502 11:25:41.733175 26473 solver.cpp:261]     Train net output #0: loss = 0.0784882 (* 1 = 0.0784882 loss)
I0502 11:25:41.733183 26473 sgd_solver.cpp:106] Iteration 95500, lr = 1.34218e-05
I0502 11:25:41.734798 26473 solver.cpp:362] Iteration 95500, Testing net (#0)
I0502 11:25:41.734812 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:41.865413 26473 solver.cpp:429]     Test net output #0: accuracy = 0.953
I0502 11:25:41.865433 26473 solver.cpp:429]     Test net output #1: loss = 0.101133 (* 1 = 0.101133 loss)
I0502 11:25:41.868347 26473 solver.cpp:242] Iteration 95500 (83.4371 iter/s, 1.19851s/100 iter), loss = 0.221103
I0502 11:25:41.868366 26473 solver.cpp:261]     Train net output #0: loss = 0.221103 (* 1 = 0.221103 loss)
I0502 11:25:41.868374 26473 sgd_solver.cpp:106] Iteration 95500, lr = 1.34218e-05
I0502 11:25:42.807924 26473 solver.cpp:242] Iteration 95600 (93.0474 iter/s, 1.07472s/100 iter), loss = 0.149853
I0502 11:25:42.807960 26473 solver.cpp:261]     Train net output #0: loss = 0.149853 (* 1 = 0.149853 loss)
I0502 11:25:42.807968 26473 sgd_solver.cpp:106] Iteration 95600, lr = 1.34218e-05
I0502 11:25:42.812755 26473 solver.cpp:242] Iteration 95600 (105.891 iter/s, 0.94437s/100 iter), loss = 0.0330936
I0502 11:25:42.812778 26473 solver.cpp:261]     Train net output #0: loss = 0.0330936 (* 1 = 0.0330936 loss)
I0502 11:25:42.812788 26473 sgd_solver.cpp:106] Iteration 95600, lr = 1.34218e-05
I0502 11:25:43.752043 26473 solver.cpp:242] Iteration 95700 (105.926 iter/s, 0.944058s/100 iter), loss = 0.381848
I0502 11:25:43.752079 26473 solver.cpp:261]     Train net output #0: loss = 0.381848 (* 1 = 0.381848 loss)
I0502 11:25:43.752095 26473 sgd_solver.cpp:106] Iteration 95700, lr = 1.34218e-05
I0502 11:25:43.756911 26473 solver.cpp:242] Iteration 95700 (105.92 iter/s, 0.944105s/100 iter), loss = 0.10896
I0502 11:25:43.756933 26473 solver.cpp:261]     Train net output #0: loss = 0.10896 (* 1 = 0.10896 loss)
I0502 11:25:43.756942 26473 sgd_solver.cpp:106] Iteration 95700, lr = 1.34218e-05
I0502 11:25:44.695297 26473 solver.cpp:242] Iteration 95800 (106.023 iter/s, 0.943189s/100 iter), loss = 0.264093
I0502 11:25:44.695327 26473 solver.cpp:261]     Train net output #0: loss = 0.264093 (* 1 = 0.264093 loss)
I0502 11:25:44.695334 26473 sgd_solver.cpp:106] Iteration 95800, lr = 1.34218e-05
I0502 11:25:44.700119 26473 solver.cpp:242] Iteration 95800 (106.026 iter/s, 0.943169s/100 iter), loss = 0.148393
I0502 11:25:44.700141 26473 solver.cpp:261]     Train net output #0: loss = 0.148393 (* 1 = 0.148393 loss)
I0502 11:25:44.700150 26473 sgd_solver.cpp:106] Iteration 95800, lr = 1.34218e-05
I0502 11:25:45.640087 26473 solver.cpp:242] Iteration 95900 (105.85 iter/s, 0.944729s/100 iter), loss = 0.583206
I0502 11:25:45.640130 26473 solver.cpp:261]     Train net output #0: loss = 0.583206 (* 1 = 0.583206 loss)
I0502 11:25:45.640138 26473 sgd_solver.cpp:106] Iteration 95900, lr = 1.34218e-05
I0502 11:25:45.645012 26473 solver.cpp:242] Iteration 95900 (105.837 iter/s, 0.944852s/100 iter), loss = 0.0662836
I0502 11:25:45.645035 26473 solver.cpp:261]     Train net output #0: loss = 0.0662836 (* 1 = 0.0662836 loss)
I0502 11:25:45.645045 26473 sgd_solver.cpp:106] Iteration 95900, lr = 1.34218e-05
I0502 11:25:46.581501 26473 solver.cpp:362] Iteration 96000, Testing net (#0)
I0502 11:25:46.581531 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:46.705989 26473 solver.cpp:429]     Test net output #0: loss = 0.310374 (* 1 = 0.310374 loss)
I0502 11:25:46.708864 26473 solver.cpp:242] Iteration 96000 (93.5701 iter/s, 1.06872s/100 iter), loss = 0.11551
I0502 11:25:46.708884 26473 solver.cpp:261]     Train net output #0: loss = 0.11551 (* 1 = 0.11551 loss)
I0502 11:25:46.708894 26473 sgd_solver.cpp:106] Iteration 96000, lr = 1.34218e-05
I0502 11:25:46.710513 26473 solver.cpp:362] Iteration 96000, Testing net (#0)
I0502 11:25:46.710526 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:46.841032 26473 solver.cpp:429]     Test net output #0: accuracy = 0.947
I0502 11:25:46.841053 26473 solver.cpp:429]     Test net output #1: loss = 0.107052 (* 1 = 0.107052 loss)
I0502 11:25:46.843972 26473 solver.cpp:242] Iteration 96000 (83.4086 iter/s, 1.19892s/100 iter), loss = 0.0222564
I0502 11:25:46.843992 26473 solver.cpp:261]     Train net output #0: loss = 0.0222564 (* 1 = 0.0222564 loss)
I0502 11:25:46.844002 26473 sgd_solver.cpp:106] Iteration 96000, lr = 1.34218e-05
I0502 11:25:47.803351 26473 solver.cpp:242] Iteration 96100 (91.3713 iter/s, 1.09444s/100 iter), loss = 0.164916
I0502 11:25:47.803406 26473 solver.cpp:261]     Train net output #0: loss = 0.164916 (* 1 = 0.164916 loss)
I0502 11:25:47.803421 26473 sgd_solver.cpp:106] Iteration 96100, lr = 1.34218e-05
I0502 11:25:47.808221 26473 solver.cpp:242] Iteration 96100 (103.712 iter/s, 0.964211s/100 iter), loss = 0.064949
I0502 11:25:47.808245 26473 solver.cpp:261]     Train net output #0: loss = 0.064949 (* 1 = 0.064949 loss)
I0502 11:25:47.808254 26473 sgd_solver.cpp:106] Iteration 96100, lr = 1.34218e-05
I0502 11:25:48.748083 26473 solver.cpp:242] Iteration 96200 (105.859 iter/s, 0.944653s/100 iter), loss = 0.258056
I0502 11:25:48.748126 26473 solver.cpp:261]     Train net output #0: loss = 0.258056 (* 1 = 0.258056 loss)
I0502 11:25:48.748136 26473 sgd_solver.cpp:106] Iteration 96200, lr = 1.34218e-05
I0502 11:25:48.752970 26473 solver.cpp:242] Iteration 96200 (105.854 iter/s, 0.944698s/100 iter), loss = 0.051056
I0502 11:25:48.752993 26473 solver.cpp:261]     Train net output #0: loss = 0.051056 (* 1 = 0.051056 loss)
I0502 11:25:48.753002 26473 sgd_solver.cpp:106] Iteration 96200, lr = 1.34218e-05
I0502 11:25:49.692256 26473 solver.cpp:242] Iteration 96300 (105.921 iter/s, 0.944097s/100 iter), loss = 0.271609
I0502 11:25:49.692299 26473 solver.cpp:261]     Train net output #0: loss = 0.271609 (* 1 = 0.271609 loss)
I0502 11:25:49.692308 26473 sgd_solver.cpp:106] Iteration 96300, lr = 1.34218e-05
I0502 11:25:49.697080 26473 solver.cpp:242] Iteration 96300 (105.924 iter/s, 0.944069s/100 iter), loss = 0.127698
I0502 11:25:49.697103 26473 solver.cpp:261]     Train net output #0: loss = 0.127698 (* 1 = 0.127698 loss)
I0502 11:25:49.697111 26473 sgd_solver.cpp:106] Iteration 96300, lr = 1.34218e-05
I0502 11:25:50.635989 26473 solver.cpp:242] Iteration 96400 (105.97 iter/s, 0.943663s/100 iter), loss = 0.0979819
I0502 11:25:50.636025 26473 solver.cpp:261]     Train net output #0: loss = 0.0979819 (* 1 = 0.0979819 loss)
I0502 11:25:50.636034 26473 sgd_solver.cpp:106] Iteration 96400, lr = 1.34218e-05
I0502 11:25:50.640799 26473 solver.cpp:242] Iteration 96400 (105.968 iter/s, 0.943679s/100 iter), loss = 0.00154672
I0502 11:25:50.640822 26473 solver.cpp:261]     Train net output #0: loss = 0.00154672 (* 1 = 0.00154672 loss)
I0502 11:25:50.640831 26473 sgd_solver.cpp:106] Iteration 96400, lr = 1.34218e-05
I0502 11:25:51.577216 26473 solver.cpp:362] Iteration 96500, Testing net (#0)
I0502 11:25:51.577239 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:51.701479 26473 solver.cpp:429]     Test net output #0: loss = 0.541331 (* 1 = 0.541331 loss)
I0502 11:25:51.704334 26473 solver.cpp:242] Iteration 96500 (93.6076 iter/s, 1.06829s/100 iter), loss = 2.89712
I0502 11:25:51.704352 26473 solver.cpp:261]     Train net output #0: loss = 2.89712 (* 1 = 2.89712 loss)
I0502 11:25:51.704360 26473 sgd_solver.cpp:106] Iteration 96500, lr = 1.34218e-05
I0502 11:25:51.706012 26473 solver.cpp:362] Iteration 96500, Testing net (#0)
I0502 11:25:51.706027 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:51.836747 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9555
I0502 11:25:51.836767 26473 solver.cpp:429]     Test net output #1: loss = 0.115919 (* 1 = 0.115919 loss)
I0502 11:25:51.839694 26473 solver.cpp:242] Iteration 96500 (83.4132 iter/s, 1.19885s/100 iter), loss = 0.234313
I0502 11:25:51.839715 26473 solver.cpp:261]     Train net output #0: loss = 0.234313 (* 1 = 0.234313 loss)
I0502 11:25:51.839722 26473 sgd_solver.cpp:106] Iteration 96500, lr = 1.34218e-05
I0502 11:25:52.778499 26473 solver.cpp:242] Iteration 96600 (93.0996 iter/s, 1.07412s/100 iter), loss = 0.184705
I0502 11:25:52.778537 26473 solver.cpp:261]     Train net output #0: loss = 0.184705 (* 1 = 0.184705 loss)
I0502 11:25:52.778545 26473 sgd_solver.cpp:106] Iteration 96600, lr = 1.34218e-05
I0502 11:25:52.783308 26473 solver.cpp:242] Iteration 96600 (105.98 iter/s, 0.943576s/100 iter), loss = 0.057759
I0502 11:25:52.783331 26473 solver.cpp:261]     Train net output #0: loss = 0.057759 (* 1 = 0.057759 loss)
I0502 11:25:52.783339 26473 sgd_solver.cpp:106] Iteration 96600, lr = 1.34218e-05
I0502 11:25:53.723784 26473 solver.cpp:242] Iteration 96700 (105.795 iter/s, 0.945224s/100 iter), loss = 0.15065
I0502 11:25:53.723824 26473 solver.cpp:261]     Train net output #0: loss = 0.15065 (* 1 = 0.15065 loss)
I0502 11:25:53.723834 26473 sgd_solver.cpp:106] Iteration 96700, lr = 1.34218e-05
I0502 11:25:53.728684 26473 solver.cpp:242] Iteration 96700 (105.784 iter/s, 0.945326s/100 iter), loss = 0.0055411
I0502 11:25:53.728708 26473 solver.cpp:261]     Train net output #0: loss = 0.0055411 (* 1 = 0.0055411 loss)
I0502 11:25:53.728715 26473 sgd_solver.cpp:106] Iteration 96700, lr = 1.34218e-05
I0502 11:25:54.668081 26473 solver.cpp:242] Iteration 96800 (105.907 iter/s, 0.944225s/100 iter), loss = 0.0832986
I0502 11:25:54.668118 26473 solver.cpp:261]     Train net output #0: loss = 0.0832986 (* 1 = 0.0832986 loss)
I0502 11:25:54.668126 26473 sgd_solver.cpp:106] Iteration 96800, lr = 1.34218e-05
I0502 11:25:54.672896 26473 solver.cpp:242] Iteration 96800 (105.913 iter/s, 0.944172s/100 iter), loss = 0.125713
I0502 11:25:54.672919 26473 solver.cpp:261]     Train net output #0: loss = 0.125713 (* 1 = 0.125713 loss)
I0502 11:25:54.672935 26473 sgd_solver.cpp:106] Iteration 96800, lr = 1.34218e-05
I0502 11:25:55.611904 26473 solver.cpp:242] Iteration 96900 (105.959 iter/s, 0.943759s/100 iter), loss = 0.308084
I0502 11:25:55.611937 26473 solver.cpp:261]     Train net output #0: loss = 0.308084 (* 1 = 0.308084 loss)
I0502 11:25:55.611944 26473 sgd_solver.cpp:106] Iteration 96900, lr = 1.34218e-05
I0502 11:25:55.616735 26473 solver.cpp:242] Iteration 96900 (105.955 iter/s, 0.943799s/100 iter), loss = 0.138643
I0502 11:25:55.616757 26473 solver.cpp:261]     Train net output #0: loss = 0.138643 (* 1 = 0.138643 loss)
I0502 11:25:55.616766 26473 sgd_solver.cpp:106] Iteration 96900, lr = 1.34218e-05
I0502 11:25:56.552916 26473 solver.cpp:362] Iteration 97000, Testing net (#0)
I0502 11:25:56.552947 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:56.677165 26473 solver.cpp:429]     Test net output #0: loss = 0.252504 (* 1 = 0.252504 loss)
I0502 11:25:56.680039 26473 solver.cpp:242] Iteration 97000 (93.6255 iter/s, 1.06809s/100 iter), loss = 0.0634658
I0502 11:25:56.680060 26473 solver.cpp:261]     Train net output #0: loss = 0.0634658 (* 1 = 0.0634658 loss)
I0502 11:25:56.680080 26473 sgd_solver.cpp:106] Iteration 97000, lr = 1.34218e-05
I0502 11:25:56.681732 26473 solver.cpp:362] Iteration 97000, Testing net (#0)
I0502 11:25:56.681746 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:25:56.812888 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:25:56.812917 26473 solver.cpp:429]     Test net output #1: loss = 0.100908 (* 1 = 0.100908 loss)
I0502 11:25:56.815836 26473 solver.cpp:242] Iteration 97000 (83.3988 iter/s, 1.19906s/100 iter), loss = 0.149403
I0502 11:25:56.815855 26473 solver.cpp:261]     Train net output #0: loss = 0.149403 (* 1 = 0.149403 loss)
I0502 11:25:56.815865 26473 sgd_solver.cpp:106] Iteration 97000, lr = 1.34218e-05
I0502 11:25:57.754990 26473 solver.cpp:242] Iteration 97100 (93.0319 iter/s, 1.0749s/100 iter), loss = 0.113023
I0502 11:25:57.755033 26473 solver.cpp:261]     Train net output #0: loss = 0.113023 (* 1 = 0.113023 loss)
I0502 11:25:57.755043 26473 sgd_solver.cpp:106] Iteration 97100, lr = 1.34218e-05
I0502 11:25:57.759806 26473 solver.cpp:242] Iteration 97100 (105.94 iter/s, 0.943932s/100 iter), loss = 0.0135526
I0502 11:25:57.759830 26473 solver.cpp:261]     Train net output #0: loss = 0.0135526 (* 1 = 0.0135526 loss)
I0502 11:25:57.759838 26473 sgd_solver.cpp:106] Iteration 97100, lr = 1.34218e-05
I0502 11:25:58.698698 26473 solver.cpp:242] Iteration 97200 (105.973 iter/s, 0.943641s/100 iter), loss = 0.215106
I0502 11:25:58.698743 26473 solver.cpp:261]     Train net output #0: loss = 0.215106 (* 1 = 0.215106 loss)
I0502 11:25:58.698752 26473 sgd_solver.cpp:106] Iteration 97200, lr = 1.34218e-05
I0502 11:25:58.703572 26473 solver.cpp:242] Iteration 97200 (105.964 iter/s, 0.943715s/100 iter), loss = 0.0673023
I0502 11:25:58.703596 26473 solver.cpp:261]     Train net output #0: loss = 0.0673023 (* 1 = 0.0673023 loss)
I0502 11:25:58.703605 26473 sgd_solver.cpp:106] Iteration 97200, lr = 1.34218e-05
I0502 11:25:59.643113 26473 solver.cpp:242] Iteration 97300 (105.894 iter/s, 0.944338s/100 iter), loss = 0.111697
I0502 11:25:59.643158 26473 solver.cpp:261]     Train net output #0: loss = 0.111697 (* 1 = 0.111697 loss)
I0502 11:25:59.643167 26473 sgd_solver.cpp:106] Iteration 97300, lr = 1.34218e-05
I0502 11:25:59.647922 26473 solver.cpp:242] Iteration 97300 (105.898 iter/s, 0.944308s/100 iter), loss = 0.21217
I0502 11:25:59.647945 26473 solver.cpp:261]     Train net output #0: loss = 0.21217 (* 1 = 0.21217 loss)
I0502 11:25:59.647954 26473 sgd_solver.cpp:106] Iteration 97300, lr = 1.34218e-05
I0502 11:26:00.599210 26473 solver.cpp:242] Iteration 97400 (104.6 iter/s, 0.956024s/100 iter), loss = 0.604705
I0502 11:26:00.599258 26473 solver.cpp:261]     Train net output #0: loss = 0.604705 (* 1 = 0.604705 loss)
I0502 11:26:00.599267 26473 sgd_solver.cpp:106] Iteration 97400, lr = 1.34218e-05
I0502 11:26:00.604034 26473 solver.cpp:242] Iteration 97400 (104.595 iter/s, 0.956071s/100 iter), loss = 0.0288908
I0502 11:26:00.604059 26473 solver.cpp:261]     Train net output #0: loss = 0.0288908 (* 1 = 0.0288908 loss)
I0502 11:26:00.604068 26473 sgd_solver.cpp:106] Iteration 97400, lr = 1.34218e-05
I0502 11:26:01.540448 26473 solver.cpp:362] Iteration 97500, Testing net (#0)
I0502 11:26:01.540477 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:01.665035 26473 solver.cpp:429]     Test net output #0: loss = 0.198613 (* 1 = 0.198613 loss)
I0502 11:26:01.667908 26473 solver.cpp:242] Iteration 97500 (93.5776 iter/s, 1.06863s/100 iter), loss = 0.362226
I0502 11:26:01.667928 26473 solver.cpp:261]     Train net output #0: loss = 0.362226 (* 1 = 0.362226 loss)
I0502 11:26:01.667937 26473 sgd_solver.cpp:106] Iteration 97500, lr = 1.34218e-05
I0502 11:26:01.669572 26473 solver.cpp:362] Iteration 97500, Testing net (#0)
I0502 11:26:01.669585 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:01.800200 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9675
I0502 11:26:01.800222 26473 solver.cpp:429]     Test net output #1: loss = 0.086439 (* 1 = 0.086439 loss)
I0502 11:26:01.803148 26473 solver.cpp:242] Iteration 97500 (83.3981 iter/s, 1.19907s/100 iter), loss = 0.13226
I0502 11:26:01.803167 26473 solver.cpp:261]     Train net output #0: loss = 0.13226 (* 1 = 0.13226 loss)
I0502 11:26:01.803176 26473 sgd_solver.cpp:106] Iteration 97500, lr = 1.34218e-05
I0502 11:26:02.743456 26473 solver.cpp:242] Iteration 97600 (92.9802 iter/s, 1.0755s/100 iter), loss = 0.071842
I0502 11:26:02.743496 26473 solver.cpp:261]     Train net output #0: loss = 0.071842 (* 1 = 0.071842 loss)
I0502 11:26:02.743505 26473 sgd_solver.cpp:106] Iteration 97600, lr = 1.34218e-05
I0502 11:26:02.748281 26473 solver.cpp:242] Iteration 97600 (105.81 iter/s, 0.945095s/100 iter), loss = 0.0434959
I0502 11:26:02.748304 26473 solver.cpp:261]     Train net output #0: loss = 0.0434959 (* 1 = 0.0434959 loss)
I0502 11:26:02.748312 26473 sgd_solver.cpp:106] Iteration 97600, lr = 1.34218e-05
I0502 11:26:03.687297 26473 solver.cpp:242] Iteration 97700 (105.957 iter/s, 0.943777s/100 iter), loss = 0.0774767
I0502 11:26:03.687338 26473 solver.cpp:261]     Train net output #0: loss = 0.0774767 (* 1 = 0.0774767 loss)
I0502 11:26:03.687347 26473 sgd_solver.cpp:106] Iteration 97700, lr = 1.34218e-05
I0502 11:26:03.692157 26473 solver.cpp:242] Iteration 97700 (105.952 iter/s, 0.943826s/100 iter), loss = 0.186598
I0502 11:26:03.692179 26473 solver.cpp:261]     Train net output #0: loss = 0.186598 (* 1 = 0.186598 loss)
I0502 11:26:03.692188 26473 sgd_solver.cpp:106] Iteration 97700, lr = 1.34218e-05
I0502 11:26:04.631767 26473 solver.cpp:242] Iteration 97800 (105.887 iter/s, 0.944403s/100 iter), loss = 0.198076
I0502 11:26:04.631806 26473 solver.cpp:261]     Train net output #0: loss = 0.198076 (* 1 = 0.198076 loss)
I0502 11:26:04.631815 26473 sgd_solver.cpp:106] Iteration 97800, lr = 1.34218e-05
I0502 11:26:04.636662 26473 solver.cpp:242] Iteration 97800 (105.881 iter/s, 0.944458s/100 iter), loss = 0.0340924
I0502 11:26:04.636685 26473 solver.cpp:261]     Train net output #0: loss = 0.0340924 (* 1 = 0.0340924 loss)
I0502 11:26:04.636693 26473 sgd_solver.cpp:106] Iteration 97800, lr = 1.34218e-05
I0502 11:26:05.575606 26473 solver.cpp:242] Iteration 97900 (105.958 iter/s, 0.943771s/100 iter), loss = 0.216245
I0502 11:26:05.575645 26473 solver.cpp:261]     Train net output #0: loss = 0.216245 (* 1 = 0.216245 loss)
I0502 11:26:05.575654 26473 sgd_solver.cpp:106] Iteration 97900, lr = 1.34218e-05
I0502 11:26:05.580417 26473 solver.cpp:242] Iteration 97900 (105.964 iter/s, 0.943714s/100 iter), loss = 0.221193
I0502 11:26:05.580440 26473 solver.cpp:261]     Train net output #0: loss = 0.221193 (* 1 = 0.221193 loss)
I0502 11:26:05.580448 26473 sgd_solver.cpp:106] Iteration 97900, lr = 1.34218e-05
I0502 11:26:06.516759 26473 solver.cpp:362] Iteration 98000, Testing net (#0)
I0502 11:26:06.516783 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:06.641203 26473 solver.cpp:429]     Test net output #0: loss = 0.322763 (* 1 = 0.322763 loss)
I0502 11:26:06.644091 26473 solver.cpp:242] Iteration 98000 (93.5955 iter/s, 1.06843s/100 iter), loss = 0.130246
I0502 11:26:06.644111 26473 solver.cpp:261]     Train net output #0: loss = 0.130246 (* 1 = 0.130246 loss)
I0502 11:26:06.644120 26473 sgd_solver.cpp:106] Iteration 98000, lr = 1.34218e-05
I0502 11:26:06.645786 26473 solver.cpp:362] Iteration 98000, Testing net (#0)
I0502 11:26:06.645798 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:06.776547 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9485
I0502 11:26:06.776568 26473 solver.cpp:429]     Test net output #1: loss = 0.122814 (* 1 = 0.122814 loss)
I0502 11:26:06.779498 26473 solver.cpp:242] Iteration 98000 (83.4002 iter/s, 1.19904s/100 iter), loss = 0.0335222
I0502 11:26:06.779518 26473 solver.cpp:261]     Train net output #0: loss = 0.0335222 (* 1 = 0.0335222 loss)
I0502 11:26:06.779527 26473 sgd_solver.cpp:106] Iteration 98000, lr = 1.34218e-05
I0502 11:26:07.718209 26473 solver.cpp:242] Iteration 98100 (93.104 iter/s, 1.07407s/100 iter), loss = 0.331709
I0502 11:26:07.718242 26473 solver.cpp:261]     Train net output #0: loss = 0.331709 (* 1 = 0.331709 loss)
I0502 11:26:07.718250 26473 sgd_solver.cpp:106] Iteration 98100, lr = 1.34218e-05
I0502 11:26:07.723006 26473 solver.cpp:242] Iteration 98100 (105.992 iter/s, 0.94347s/100 iter), loss = 0.135125
I0502 11:26:07.723029 26473 solver.cpp:261]     Train net output #0: loss = 0.135125 (* 1 = 0.135125 loss)
I0502 11:26:07.723037 26473 sgd_solver.cpp:106] Iteration 98100, lr = 1.34218e-05
I0502 11:26:08.661867 26473 solver.cpp:242] Iteration 98200 (105.977 iter/s, 0.9436s/100 iter), loss = 0.163637
I0502 11:26:08.661897 26473 solver.cpp:261]     Train net output #0: loss = 0.163637 (* 1 = 0.163637 loss)
I0502 11:26:08.661906 26473 sgd_solver.cpp:106] Iteration 98200, lr = 1.34218e-05
I0502 11:26:08.666672 26473 solver.cpp:242] Iteration 98200 (105.974 iter/s, 0.943625s/100 iter), loss = 0.0618938
I0502 11:26:08.666695 26473 solver.cpp:261]     Train net output #0: loss = 0.0618938 (* 1 = 0.0618938 loss)
I0502 11:26:08.666703 26473 sgd_solver.cpp:106] Iteration 98200, lr = 1.34218e-05
I0502 11:26:09.605332 26473 solver.cpp:242] Iteration 98300 (105.998 iter/s, 0.943412s/100 iter), loss = 0.179967
I0502 11:26:09.605361 26473 solver.cpp:261]     Train net output #0: loss = 0.179967 (* 1 = 0.179967 loss)
I0502 11:26:09.605370 26473 sgd_solver.cpp:106] Iteration 98300, lr = 1.34218e-05
I0502 11:26:09.610198 26473 solver.cpp:242] Iteration 98300 (105.991 iter/s, 0.943477s/100 iter), loss = 0.0380597
I0502 11:26:09.610220 26473 solver.cpp:261]     Train net output #0: loss = 0.0380597 (* 1 = 0.0380597 loss)
I0502 11:26:09.610229 26473 sgd_solver.cpp:106] Iteration 98300, lr = 1.34218e-05
I0502 11:26:10.549151 26473 solver.cpp:242] Iteration 98400 (105.96 iter/s, 0.943756s/100 iter), loss = 0.128958
I0502 11:26:10.549188 26473 solver.cpp:261]     Train net output #0: loss = 0.128958 (* 1 = 0.128958 loss)
I0502 11:26:10.549197 26473 sgd_solver.cpp:106] Iteration 98400, lr = 1.34218e-05
I0502 11:26:10.554008 26473 solver.cpp:242] Iteration 98400 (105.958 iter/s, 0.943768s/100 iter), loss = 0.0211751
I0502 11:26:10.554033 26473 solver.cpp:261]     Train net output #0: loss = 0.0211751 (* 1 = 0.0211751 loss)
I0502 11:26:10.554041 26473 sgd_solver.cpp:106] Iteration 98400, lr = 1.34218e-05
I0502 11:26:11.490967 26473 solver.cpp:362] Iteration 98500, Testing net (#0)
I0502 11:26:11.490996 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:11.615250 26473 solver.cpp:429]     Test net output #0: loss = 0.366756 (* 1 = 0.366756 loss)
I0502 11:26:11.618124 26473 solver.cpp:242] Iteration 98500 (93.5526 iter/s, 1.06892s/100 iter), loss = 0.211911
I0502 11:26:11.618144 26473 solver.cpp:261]     Train net output #0: loss = 0.211911 (* 1 = 0.211911 loss)
I0502 11:26:11.618152 26473 sgd_solver.cpp:106] Iteration 98500, lr = 1.34218e-05
I0502 11:26:11.619768 26473 solver.cpp:362] Iteration 98500, Testing net (#0)
I0502 11:26:11.619791 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:11.750167 26473 solver.cpp:429]     Test net output #0: accuracy = 0.948
I0502 11:26:11.750186 26473 solver.cpp:429]     Test net output #1: loss = 0.113963 (* 1 = 0.113963 loss)
I0502 11:26:11.753109 26473 solver.cpp:242] Iteration 98500 (83.399 iter/s, 1.19906s/100 iter), loss = 0.105765
I0502 11:26:11.753129 26473 solver.cpp:261]     Train net output #0: loss = 0.105765 (* 1 = 0.105765 loss)
I0502 11:26:11.753137 26473 sgd_solver.cpp:106] Iteration 98500, lr = 1.34218e-05
I0502 11:26:12.691577 26473 solver.cpp:242] Iteration 98600 (93.1617 iter/s, 1.0734s/100 iter), loss = 0.146468
I0502 11:26:12.691618 26473 solver.cpp:261]     Train net output #0: loss = 0.146468 (* 1 = 0.146468 loss)
I0502 11:26:12.691627 26473 sgd_solver.cpp:106] Iteration 98600, lr = 1.34218e-05
I0502 11:26:12.696386 26473 solver.cpp:242] Iteration 98600 (106.018 iter/s, 0.943239s/100 iter), loss = 0.0963322
I0502 11:26:12.696409 26473 solver.cpp:261]     Train net output #0: loss = 0.0963322 (* 1 = 0.0963322 loss)
I0502 11:26:12.696419 26473 sgd_solver.cpp:106] Iteration 98600, lr = 1.34218e-05
I0502 11:26:13.635901 26473 solver.cpp:242] Iteration 98700 (105.903 iter/s, 0.944258s/100 iter), loss = 0.204195
I0502 11:26:13.635943 26473 solver.cpp:261]     Train net output #0: loss = 0.204195 (* 1 = 0.204195 loss)
I0502 11:26:13.635952 26473 sgd_solver.cpp:106] Iteration 98700, lr = 1.34218e-05
I0502 11:26:13.640705 26473 solver.cpp:242] Iteration 98700 (105.901 iter/s, 0.944278s/100 iter), loss = 0.0965076
I0502 11:26:13.640728 26473 solver.cpp:261]     Train net output #0: loss = 0.0965076 (* 1 = 0.0965076 loss)
I0502 11:26:13.640736 26473 sgd_solver.cpp:106] Iteration 98700, lr = 1.34218e-05
I0502 11:26:14.579543 26473 solver.cpp:242] Iteration 98800 (105.98 iter/s, 0.943577s/100 iter), loss = 0.318121
I0502 11:26:14.579583 26473 solver.cpp:261]     Train net output #0: loss = 0.318121 (* 1 = 0.318121 loss)
I0502 11:26:14.579592 26473 sgd_solver.cpp:106] Iteration 98800, lr = 1.34218e-05
I0502 11:26:14.584426 26473 solver.cpp:242] Iteration 98800 (105.969 iter/s, 0.943672s/100 iter), loss = 0.0979872
I0502 11:26:14.584450 26473 solver.cpp:261]     Train net output #0: loss = 0.0979872 (* 1 = 0.0979872 loss)
I0502 11:26:14.584458 26473 sgd_solver.cpp:106] Iteration 98800, lr = 1.34218e-05
I0502 11:26:15.523550 26473 solver.cpp:242] Iteration 98900 (105.939 iter/s, 0.943936s/100 iter), loss = 0.172652
I0502 11:26:15.523594 26473 solver.cpp:261]     Train net output #0: loss = 0.172652 (* 1 = 0.172652 loss)
I0502 11:26:15.523602 26473 sgd_solver.cpp:106] Iteration 98900, lr = 1.34218e-05
I0502 11:26:15.528376 26473 solver.cpp:242] Iteration 98900 (105.942 iter/s, 0.94391s/100 iter), loss = 0.00777124
I0502 11:26:15.528399 26473 solver.cpp:261]     Train net output #0: loss = 0.00777124 (* 1 = 0.00777124 loss)
I0502 11:26:15.528408 26473 sgd_solver.cpp:106] Iteration 98900, lr = 1.34218e-05
I0502 11:26:16.464704 26473 solver.cpp:362] Iteration 99000, Testing net (#0)
I0502 11:26:16.464730 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:16.589011 26473 solver.cpp:429]     Test net output #0: loss = 0.25382 (* 1 = 0.25382 loss)
I0502 11:26:16.591871 26473 solver.cpp:242] Iteration 99000 (93.6102 iter/s, 1.06826s/100 iter), loss = 0.624293
I0502 11:26:16.591892 26473 solver.cpp:261]     Train net output #0: loss = 0.624293 (* 1 = 0.624293 loss)
I0502 11:26:16.591900 26473 sgd_solver.cpp:106] Iteration 99000, lr = 1.34218e-05
I0502 11:26:16.593576 26473 solver.cpp:362] Iteration 99000, Testing net (#0)
I0502 11:26:16.593590 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:16.724316 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:26:16.724336 26473 solver.cpp:429]     Test net output #1: loss = 0.0924226 (* 1 = 0.0924226 loss)
I0502 11:26:16.727259 26473 solver.cpp:242] Iteration 99000 (83.414 iter/s, 1.19884s/100 iter), loss = 0.0762616
I0502 11:26:16.727279 26473 solver.cpp:261]     Train net output #0: loss = 0.0762616 (* 1 = 0.0762616 loss)
I0502 11:26:16.727298 26473 sgd_solver.cpp:106] Iteration 99000, lr = 1.34218e-05
I0502 11:26:17.666286 26473 solver.cpp:242] Iteration 99100 (93.0783 iter/s, 1.07436s/100 iter), loss = 0.22611
I0502 11:26:17.666323 26473 solver.cpp:261]     Train net output #0: loss = 0.22611 (* 1 = 0.22611 loss)
I0502 11:26:17.666332 26473 sgd_solver.cpp:106] Iteration 99100, lr = 1.34218e-05
I0502 11:26:17.671074 26473 solver.cpp:242] Iteration 99100 (105.957 iter/s, 0.943776s/100 iter), loss = 0.127654
I0502 11:26:17.671098 26473 solver.cpp:261]     Train net output #0: loss = 0.127654 (* 1 = 0.127654 loss)
I0502 11:26:17.671106 26473 sgd_solver.cpp:106] Iteration 99100, lr = 1.34218e-05
I0502 11:26:18.609683 26473 solver.cpp:242] Iteration 99200 (106.007 iter/s, 0.943334s/100 iter), loss = 0.230649
I0502 11:26:18.609716 26473 solver.cpp:261]     Train net output #0: loss = 0.230649 (* 1 = 0.230649 loss)
I0502 11:26:18.609725 26473 sgd_solver.cpp:106] Iteration 99200, lr = 1.34218e-05
I0502 11:26:18.614473 26473 solver.cpp:242] Iteration 99200 (106.004 iter/s, 0.943357s/100 iter), loss = 0.00333841
I0502 11:26:18.614496 26473 solver.cpp:261]     Train net output #0: loss = 0.00333841 (* 1 = 0.00333841 loss)
I0502 11:26:18.614504 26473 sgd_solver.cpp:106] Iteration 99200, lr = 1.34218e-05
I0502 11:26:19.554625 26473 solver.cpp:242] Iteration 99300 (105.833 iter/s, 0.944885s/100 iter), loss = 0.118148
I0502 11:26:19.554658 26473 solver.cpp:261]     Train net output #0: loss = 0.118148 (* 1 = 0.118148 loss)
I0502 11:26:19.554667 26473 sgd_solver.cpp:106] Iteration 99300, lr = 1.34218e-05
I0502 11:26:19.559495 26473 solver.cpp:242] Iteration 99300 (105.823 iter/s, 0.944973s/100 iter), loss = 0.145297
I0502 11:26:19.559518 26473 solver.cpp:261]     Train net output #0: loss = 0.145297 (* 1 = 0.145297 loss)
I0502 11:26:19.559527 26473 sgd_solver.cpp:106] Iteration 99300, lr = 1.34218e-05
I0502 11:26:20.498383 26473 solver.cpp:242] Iteration 99400 (105.966 iter/s, 0.943695s/100 iter), loss = 0.153794
I0502 11:26:20.498414 26473 solver.cpp:261]     Train net output #0: loss = 0.153794 (* 1 = 0.153794 loss)
I0502 11:26:20.498423 26473 sgd_solver.cpp:106] Iteration 99400, lr = 1.34218e-05
I0502 11:26:20.503186 26473 solver.cpp:242] Iteration 99400 (105.971 iter/s, 0.943651s/100 iter), loss = 0.124012
I0502 11:26:20.503209 26473 solver.cpp:261]     Train net output #0: loss = 0.124012 (* 1 = 0.124012 loss)
I0502 11:26:20.503218 26473 sgd_solver.cpp:106] Iteration 99400, lr = 1.34218e-05
I0502 11:26:21.439041 26473 solver.cpp:362] Iteration 99500, Testing net (#0)
I0502 11:26:21.439062 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:21.563675 26473 solver.cpp:429]     Test net output #0: loss = 0.310415 (* 1 = 0.310415 loss)
I0502 11:26:21.566541 26473 solver.cpp:242] Iteration 99500 (93.6235 iter/s, 1.06811s/100 iter), loss = 0.150823
I0502 11:26:21.566561 26473 solver.cpp:261]     Train net output #0: loss = 0.150823 (* 1 = 0.150823 loss)
I0502 11:26:21.566570 26473 sgd_solver.cpp:106] Iteration 99500, lr = 1.34218e-05
I0502 11:26:21.568292 26473 solver.cpp:362] Iteration 99500, Testing net (#0)
I0502 11:26:21.568307 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:21.699350 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:26:21.699373 26473 solver.cpp:429]     Test net output #1: loss = 0.0911164 (* 1 = 0.0911164 loss)
I0502 11:26:21.702294 26473 solver.cpp:242] Iteration 99500 (83.3984 iter/s, 1.19906s/100 iter), loss = 0.121879
I0502 11:26:21.702316 26473 solver.cpp:261]     Train net output #0: loss = 0.121879 (* 1 = 0.121879 loss)
I0502 11:26:21.702324 26473 sgd_solver.cpp:106] Iteration 99500, lr = 1.34218e-05
I0502 11:26:22.641481 26473 solver.cpp:242] Iteration 99600 (93.0326 iter/s, 1.07489s/100 iter), loss = 0.098895
I0502 11:26:22.641513 26473 solver.cpp:261]     Train net output #0: loss = 0.098895 (* 1 = 0.098895 loss)
I0502 11:26:22.641522 26473 sgd_solver.cpp:106] Iteration 99600, lr = 1.34218e-05
I0502 11:26:22.646270 26473 solver.cpp:242] Iteration 99600 (105.939 iter/s, 0.943936s/100 iter), loss = 0.109995
I0502 11:26:22.646298 26473 solver.cpp:261]     Train net output #0: loss = 0.109995 (* 1 = 0.109995 loss)
I0502 11:26:22.646307 26473 sgd_solver.cpp:106] Iteration 99600, lr = 1.34218e-05
I0502 11:26:23.584841 26473 solver.cpp:242] Iteration 99700 (106.011 iter/s, 0.943301s/100 iter), loss = 0.145668
I0502 11:26:23.584894 26473 solver.cpp:261]     Train net output #0: loss = 0.145668 (* 1 = 0.145668 loss)
I0502 11:26:23.584903 26473 sgd_solver.cpp:106] Iteration 99700, lr = 1.34218e-05
I0502 11:26:23.589669 26473 solver.cpp:242] Iteration 99700 (106.005 iter/s, 0.943353s/100 iter), loss = 0.0220973
I0502 11:26:23.589692 26473 solver.cpp:261]     Train net output #0: loss = 0.0220973 (* 1 = 0.0220973 loss)
I0502 11:26:23.589701 26473 sgd_solver.cpp:106] Iteration 99700, lr = 1.34218e-05
I0502 11:26:24.528939 26473 solver.cpp:242] Iteration 99800 (105.93 iter/s, 0.944019s/100 iter), loss = 0.108651
I0502 11:26:24.528982 26473 solver.cpp:261]     Train net output #0: loss = 0.108651 (* 1 = 0.108651 loss)
I0502 11:26:24.528992 26473 sgd_solver.cpp:106] Iteration 99800, lr = 1.34218e-05
I0502 11:26:24.533824 26473 solver.cpp:242] Iteration 99800 (105.92 iter/s, 0.944105s/100 iter), loss = 0.109326
I0502 11:26:24.533846 26473 solver.cpp:261]     Train net output #0: loss = 0.109326 (* 1 = 0.109326 loss)
I0502 11:26:24.533855 26473 sgd_solver.cpp:106] Iteration 99800, lr = 1.34218e-05
I0502 11:26:25.473428 26473 solver.cpp:242] Iteration 99900 (105.886 iter/s, 0.944413s/100 iter), loss = 0.232469
I0502 11:26:25.473492 26473 solver.cpp:261]     Train net output #0: loss = 0.232469 (* 1 = 0.232469 loss)
I0502 11:26:25.473505 26473 sgd_solver.cpp:106] Iteration 99900, lr = 1.34218e-05
I0502 11:26:25.478314 26473 solver.cpp:242] Iteration 99900 (105.882 iter/s, 0.944449s/100 iter), loss = 0.112917
I0502 11:26:25.478338 26473 solver.cpp:261]     Train net output #0: loss = 0.112917 (* 1 = 0.112917 loss)
I0502 11:26:25.478345 26473 sgd_solver.cpp:106] Iteration 99900, lr = 1.34218e-05
I0502 11:26:26.408610 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_100000.caffemodel
I0502 11:26:26.412854 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_100000.solverstate
I0502 11:26:26.419720 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_100000.caffemodel
I0502 11:26:26.423887 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_100000.solverstate
I0502 11:26:26.427520 26473 solver.cpp:362] Iteration 100000, Testing net (#0)
I0502 11:26:26.427534 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:26.551846 26473 solver.cpp:429]     Test net output #0: loss = 0.25964 (* 1 = 0.25964 loss)
I0502 11:26:26.554713 26473 solver.cpp:242] Iteration 100000 (92.4895 iter/s, 1.0812s/100 iter), loss = 0.586898
I0502 11:26:26.554734 26473 solver.cpp:261]     Train net output #0: loss = 0.586898 (* 1 = 0.586898 loss)
I0502 11:26:26.554744 26473 sgd_solver.cpp:106] Iteration 100000, lr = 1.07374e-05
I0502 11:26:26.556380 26473 solver.cpp:362] Iteration 100000, Testing net (#0)
I0502 11:26:26.556391 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:26.687055 26473 solver.cpp:429]     Test net output #0: accuracy = 0.953
I0502 11:26:26.687084 26473 solver.cpp:429]     Test net output #1: loss = 0.105994 (* 1 = 0.105994 loss)
I0502 11:26:26.690018 26473 solver.cpp:242] Iteration 100000 (82.5314 iter/s, 1.21166s/100 iter), loss = 0.0968971
I0502 11:26:26.690037 26473 solver.cpp:261]     Train net output #0: loss = 0.0968971 (* 1 = 0.0968971 loss)
I0502 11:26:26.690047 26473 sgd_solver.cpp:106] Iteration 100000, lr = 1.07374e-05
I0502 11:26:27.630257 26473 solver.cpp:242] Iteration 100100 (92.9807 iter/s, 1.07549s/100 iter), loss = 0.156982
I0502 11:26:27.630298 26473 solver.cpp:261]     Train net output #0: loss = 0.156982 (* 1 = 0.156982 loss)
I0502 11:26:27.630307 26473 sgd_solver.cpp:106] Iteration 100100, lr = 1.07374e-05
I0502 11:26:27.635072 26473 solver.cpp:242] Iteration 100100 (105.818 iter/s, 0.945017s/100 iter), loss = 0.0296757
I0502 11:26:27.635097 26473 solver.cpp:261]     Train net output #0: loss = 0.0296757 (* 1 = 0.0296757 loss)
I0502 11:26:27.635104 26473 sgd_solver.cpp:106] Iteration 100100, lr = 1.07374e-05
I0502 11:26:28.573423 26473 solver.cpp:242] Iteration 100200 (106.034 iter/s, 0.943098s/100 iter), loss = 0.163149
I0502 11:26:28.573460 26473 solver.cpp:261]     Train net output #0: loss = 0.163149 (* 1 = 0.163149 loss)
I0502 11:26:28.573469 26473 sgd_solver.cpp:106] Iteration 100200, lr = 1.07374e-05
I0502 11:26:28.578209 26473 solver.cpp:242] Iteration 100200 (106.034 iter/s, 0.943096s/100 iter), loss = 0.126873
I0502 11:26:28.578233 26473 solver.cpp:261]     Train net output #0: loss = 0.126873 (* 1 = 0.126873 loss)
I0502 11:26:28.578240 26473 sgd_solver.cpp:106] Iteration 100200, lr = 1.07374e-05
I0502 11:26:29.517462 26473 solver.cpp:242] Iteration 100300 (105.935 iter/s, 0.943975s/100 iter), loss = 0.203528
I0502 11:26:29.517496 26473 solver.cpp:261]     Train net output #0: loss = 0.203528 (* 1 = 0.203528 loss)
I0502 11:26:29.517505 26473 sgd_solver.cpp:106] Iteration 100300, lr = 1.07374e-05
I0502 11:26:29.522332 26473 solver.cpp:242] Iteration 100300 (105.924 iter/s, 0.944074s/100 iter), loss = 0.0634169
I0502 11:26:29.522356 26473 solver.cpp:261]     Train net output #0: loss = 0.0634169 (* 1 = 0.0634169 loss)
I0502 11:26:29.522364 26473 sgd_solver.cpp:106] Iteration 100300, lr = 1.07374e-05
I0502 11:26:30.461385 26473 solver.cpp:242] Iteration 100400 (105.947 iter/s, 0.943865s/100 iter), loss = 0.225725
I0502 11:26:30.461419 26473 solver.cpp:261]     Train net output #0: loss = 0.225725 (* 1 = 0.225725 loss)
I0502 11:26:30.461428 26473 sgd_solver.cpp:106] Iteration 100400, lr = 1.07374e-05
I0502 11:26:30.466267 26473 solver.cpp:242] Iteration 100400 (105.945 iter/s, 0.943887s/100 iter), loss = 0.155256
I0502 11:26:30.466290 26473 solver.cpp:261]     Train net output #0: loss = 0.155256 (* 1 = 0.155256 loss)
I0502 11:26:30.466298 26473 sgd_solver.cpp:106] Iteration 100400, lr = 1.07374e-05
I0502 11:26:31.406574 26473 solver.cpp:362] Iteration 100500, Testing net (#0)
I0502 11:26:31.406599 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:31.530962 26473 solver.cpp:429]     Test net output #0: loss = 0.270349 (* 1 = 0.270349 loss)
I0502 11:26:31.533852 26473 solver.cpp:242] Iteration 100500 (93.2476 iter/s, 1.07241s/100 iter), loss = 0.24652
I0502 11:26:31.533874 26473 solver.cpp:261]     Train net output #0: loss = 0.24652 (* 1 = 0.24652 loss)
I0502 11:26:31.533881 26473 sgd_solver.cpp:106] Iteration 100500, lr = 1.07374e-05
I0502 11:26:31.535497 26473 solver.cpp:362] Iteration 100500, Testing net (#0)
I0502 11:26:31.535511 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:31.666230 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:26:31.666251 26473 solver.cpp:429]     Test net output #1: loss = 0.0930058 (* 1 = 0.0930058 loss)
I0502 11:26:31.669167 26473 solver.cpp:242] Iteration 100500 (83.1355 iter/s, 1.20286s/100 iter), loss = 0.159847
I0502 11:26:31.669188 26473 solver.cpp:261]     Train net output #0: loss = 0.159847 (* 1 = 0.159847 loss)
I0502 11:26:31.669196 26473 sgd_solver.cpp:106] Iteration 100500, lr = 1.07374e-05
I0502 11:26:32.607921 26473 solver.cpp:242] Iteration 100600 (93.1083 iter/s, 1.07402s/100 iter), loss = 0.0686572
I0502 11:26:32.607960 26473 solver.cpp:261]     Train net output #0: loss = 0.0686572 (* 1 = 0.0686572 loss)
I0502 11:26:32.607969 26473 sgd_solver.cpp:106] Iteration 100600, lr = 1.07374e-05
I0502 11:26:32.612725 26473 solver.cpp:242] Iteration 100600 (105.986 iter/s, 0.943519s/100 iter), loss = 0.0913482
I0502 11:26:32.612748 26473 solver.cpp:261]     Train net output #0: loss = 0.0913482 (* 1 = 0.0913482 loss)
I0502 11:26:32.612756 26473 sgd_solver.cpp:106] Iteration 100600, lr = 1.07374e-05
I0502 11:26:33.551782 26473 solver.cpp:242] Iteration 100700 (105.955 iter/s, 0.943794s/100 iter), loss = 0.451632
I0502 11:26:33.551817 26473 solver.cpp:261]     Train net output #0: loss = 0.451632 (* 1 = 0.451632 loss)
I0502 11:26:33.551826 26473 sgd_solver.cpp:106] Iteration 100700, lr = 1.07374e-05
I0502 11:26:33.556634 26473 solver.cpp:242] Iteration 100700 (105.947 iter/s, 0.943868s/100 iter), loss = 0.116764
I0502 11:26:33.556658 26473 solver.cpp:261]     Train net output #0: loss = 0.116764 (* 1 = 0.116764 loss)
I0502 11:26:33.556666 26473 sgd_solver.cpp:106] Iteration 100700, lr = 1.07374e-05
I0502 11:26:34.495250 26473 solver.cpp:242] Iteration 100800 (105.999 iter/s, 0.943407s/100 iter), loss = 0.246034
I0502 11:26:34.495293 26473 solver.cpp:261]     Train net output #0: loss = 0.246034 (* 1 = 0.246034 loss)
I0502 11:26:34.495302 26473 sgd_solver.cpp:106] Iteration 100800, lr = 1.07374e-05
I0502 11:26:34.500120 26473 solver.cpp:242] Iteration 100800 (105.996 iter/s, 0.943436s/100 iter), loss = 0.0222431
I0502 11:26:34.500144 26473 solver.cpp:261]     Train net output #0: loss = 0.0222431 (* 1 = 0.0222431 loss)
I0502 11:26:34.500152 26473 sgd_solver.cpp:106] Iteration 100800, lr = 1.07374e-05
I0502 11:26:35.438688 26473 solver.cpp:242] Iteration 100900 (106.003 iter/s, 0.94337s/100 iter), loss = 0.0351097
I0502 11:26:35.438731 26473 solver.cpp:261]     Train net output #0: loss = 0.0351097 (* 1 = 0.0351097 loss)
I0502 11:26:35.438740 26473 sgd_solver.cpp:106] Iteration 100900, lr = 1.07374e-05
I0502 11:26:35.443593 26473 solver.cpp:242] Iteration 100900 (105.997 iter/s, 0.943426s/100 iter), loss = 0.0259904
I0502 11:26:35.443617 26473 solver.cpp:261]     Train net output #0: loss = 0.0259904 (* 1 = 0.0259904 loss)
I0502 11:26:35.443626 26473 sgd_solver.cpp:106] Iteration 100900, lr = 1.07374e-05
I0502 11:26:36.380421 26473 solver.cpp:362] Iteration 101000, Testing net (#0)
I0502 11:26:36.380453 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:36.504729 26473 solver.cpp:429]     Test net output #0: loss = 0.23102 (* 1 = 0.23102 loss)
I0502 11:26:36.507609 26473 solver.cpp:242] Iteration 101000 (93.5576 iter/s, 1.06886s/100 iter), loss = 0.136745
I0502 11:26:36.507628 26473 solver.cpp:261]     Train net output #0: loss = 0.136745 (* 1 = 0.136745 loss)
I0502 11:26:36.507637 26473 sgd_solver.cpp:106] Iteration 101000, lr = 1.07374e-05
I0502 11:26:36.509279 26473 solver.cpp:362] Iteration 101000, Testing net (#0)
I0502 11:26:36.509292 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:36.639742 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:26:36.639763 26473 solver.cpp:429]     Test net output #1: loss = 0.0960144 (* 1 = 0.0960144 loss)
I0502 11:26:36.642691 26473 solver.cpp:242] Iteration 101000 (83.3992 iter/s, 1.19905s/100 iter), loss = 0.08167
I0502 11:26:36.642711 26473 solver.cpp:261]     Train net output #0: loss = 0.08167 (* 1 = 0.08167 loss)
I0502 11:26:36.642719 26473 sgd_solver.cpp:106] Iteration 101000, lr = 1.07374e-05
I0502 11:26:37.582049 26473 solver.cpp:242] Iteration 101100 (93.0763 iter/s, 1.07439s/100 iter), loss = 0.249684
I0502 11:26:37.582090 26473 solver.cpp:261]     Train net output #0: loss = 0.249684 (* 1 = 0.249684 loss)
I0502 11:26:37.582099 26473 sgd_solver.cpp:106] Iteration 101100, lr = 1.07374e-05
I0502 11:26:37.586853 26473 solver.cpp:242] Iteration 101100 (105.918 iter/s, 0.944124s/100 iter), loss = 0.017849
I0502 11:26:37.586884 26473 solver.cpp:261]     Train net output #0: loss = 0.017849 (* 1 = 0.017849 loss)
I0502 11:26:37.586894 26473 sgd_solver.cpp:106] Iteration 101100, lr = 1.07374e-05
I0502 11:26:38.525391 26473 solver.cpp:242] Iteration 101200 (106.014 iter/s, 0.943274s/100 iter), loss = 0.0783521
I0502 11:26:38.525434 26473 solver.cpp:261]     Train net output #0: loss = 0.0783521 (* 1 = 0.0783521 loss)
I0502 11:26:38.525444 26473 sgd_solver.cpp:106] Iteration 101200, lr = 1.07374e-05
I0502 11:26:38.530213 26473 solver.cpp:242] Iteration 101200 (106.009 iter/s, 0.943312s/100 iter), loss = 0.078441
I0502 11:26:38.530237 26473 solver.cpp:261]     Train net output #0: loss = 0.078441 (* 1 = 0.078441 loss)
I0502 11:26:38.530246 26473 sgd_solver.cpp:106] Iteration 101200, lr = 1.07374e-05
I0502 11:26:39.469468 26473 solver.cpp:242] Iteration 101300 (105.931 iter/s, 0.944007s/100 iter), loss = 0.201582
I0502 11:26:39.469511 26473 solver.cpp:261]     Train net output #0: loss = 0.201582 (* 1 = 0.201582 loss)
I0502 11:26:39.469521 26473 sgd_solver.cpp:106] Iteration 101300, lr = 1.07374e-05
I0502 11:26:39.474274 26473 solver.cpp:242] Iteration 101300 (105.93 iter/s, 0.944019s/100 iter), loss = 0.0538585
I0502 11:26:39.474298 26473 solver.cpp:261]     Train net output #0: loss = 0.0538585 (* 1 = 0.0538585 loss)
I0502 11:26:39.474305 26473 sgd_solver.cpp:106] Iteration 101300, lr = 1.07374e-05
I0502 11:26:40.412590 26473 solver.cpp:242] Iteration 101400 (106.038 iter/s, 0.943054s/100 iter), loss = 0.193061
I0502 11:26:40.412629 26473 solver.cpp:261]     Train net output #0: loss = 0.193061 (* 1 = 0.193061 loss)
I0502 11:26:40.412638 26473 sgd_solver.cpp:106] Iteration 101400, lr = 1.07374e-05
I0502 11:26:40.417434 26473 solver.cpp:242] Iteration 101400 (106.032 iter/s, 0.943111s/100 iter), loss = 0.0841821
I0502 11:26:40.417457 26473 solver.cpp:261]     Train net output #0: loss = 0.0841821 (* 1 = 0.0841821 loss)
I0502 11:26:40.417465 26473 sgd_solver.cpp:106] Iteration 101400, lr = 1.07374e-05
I0502 11:26:41.352313 26473 solver.cpp:362] Iteration 101500, Testing net (#0)
I0502 11:26:41.352339 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:41.476773 26473 solver.cpp:429]     Test net output #0: loss = 0.324796 (* 1 = 0.324796 loss)
I0502 11:26:41.479671 26473 solver.cpp:242] Iteration 101500 (93.7188 iter/s, 1.06702s/100 iter), loss = 0.180368
I0502 11:26:41.479691 26473 solver.cpp:261]     Train net output #0: loss = 0.180368 (* 1 = 0.180368 loss)
I0502 11:26:41.479701 26473 sgd_solver.cpp:106] Iteration 101500, lr = 1.07374e-05
I0502 11:26:41.481360 26473 solver.cpp:362] Iteration 101500, Testing net (#0)
I0502 11:26:41.481374 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:41.612038 26473 solver.cpp:429]     Test net output #0: accuracy = 0.951
I0502 11:26:41.612061 26473 solver.cpp:429]     Test net output #1: loss = 0.0994044 (* 1 = 0.0994044 loss)
I0502 11:26:41.614987 26473 solver.cpp:242] Iteration 101500 (83.5066 iter/s, 1.19751s/100 iter), loss = 0.0437513
I0502 11:26:41.615007 26473 solver.cpp:261]     Train net output #0: loss = 0.0437513 (* 1 = 0.0437513 loss)
I0502 11:26:41.615016 26473 sgd_solver.cpp:106] Iteration 101500, lr = 1.07374e-05
I0502 11:26:42.554685 26473 solver.cpp:242] Iteration 101600 (93.0266 iter/s, 1.07496s/100 iter), loss = 0.200803
I0502 11:26:42.554728 26473 solver.cpp:261]     Train net output #0: loss = 0.200803 (* 1 = 0.200803 loss)
I0502 11:26:42.554738 26473 sgd_solver.cpp:106] Iteration 101600, lr = 1.07374e-05
I0502 11:26:42.559484 26473 solver.cpp:242] Iteration 101600 (105.881 iter/s, 0.944459s/100 iter), loss = 0.0243011
I0502 11:26:42.559507 26473 solver.cpp:261]     Train net output #0: loss = 0.0243011 (* 1 = 0.0243011 loss)
I0502 11:26:42.559515 26473 sgd_solver.cpp:106] Iteration 101600, lr = 1.07374e-05
I0502 11:26:43.498510 26473 solver.cpp:242] Iteration 101700 (105.96 iter/s, 0.943754s/100 iter), loss = 0.140085
I0502 11:26:43.498550 26473 solver.cpp:261]     Train net output #0: loss = 0.140085 (* 1 = 0.140085 loss)
I0502 11:26:43.498566 26473 sgd_solver.cpp:106] Iteration 101700, lr = 1.07374e-05
I0502 11:26:43.503343 26473 solver.cpp:242] Iteration 101700 (105.953 iter/s, 0.943819s/100 iter), loss = 0.0905289
I0502 11:26:43.503365 26473 solver.cpp:261]     Train net output #0: loss = 0.0905289 (* 1 = 0.0905289 loss)
I0502 11:26:43.503374 26473 sgd_solver.cpp:106] Iteration 101700, lr = 1.07374e-05
I0502 11:26:44.441022 26473 solver.cpp:242] Iteration 101800 (106.107 iter/s, 0.942448s/100 iter), loss = 0.0613951
I0502 11:26:44.441056 26473 solver.cpp:261]     Train net output #0: loss = 0.0613951 (* 1 = 0.0613951 loss)
I0502 11:26:44.441064 26473 sgd_solver.cpp:106] Iteration 101800, lr = 1.07374e-05
I0502 11:26:44.445799 26473 solver.cpp:242] Iteration 101800 (106.11 iter/s, 0.942416s/100 iter), loss = 0.187053
I0502 11:26:44.445822 26473 solver.cpp:261]     Train net output #0: loss = 0.187053 (* 1 = 0.187053 loss)
I0502 11:26:44.445830 26473 sgd_solver.cpp:106] Iteration 101800, lr = 1.07374e-05
I0502 11:26:45.385792 26473 solver.cpp:242] Iteration 101900 (105.852 iter/s, 0.944712s/100 iter), loss = 0.0990377
I0502 11:26:45.385821 26473 solver.cpp:261]     Train net output #0: loss = 0.0990377 (* 1 = 0.0990377 loss)
I0502 11:26:45.385829 26473 sgd_solver.cpp:106] Iteration 101900, lr = 1.07374e-05
I0502 11:26:45.390677 26473 solver.cpp:242] Iteration 101900 (105.839 iter/s, 0.944829s/100 iter), loss = 0.119293
I0502 11:26:45.390702 26473 solver.cpp:261]     Train net output #0: loss = 0.119293 (* 1 = 0.119293 loss)
I0502 11:26:45.390709 26473 sgd_solver.cpp:106] Iteration 101900, lr = 1.07374e-05
I0502 11:26:46.328088 26473 solver.cpp:362] Iteration 102000, Testing net (#0)
I0502 11:26:46.328119 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:46.452409 26473 solver.cpp:429]     Test net output #0: loss = 0.257368 (* 1 = 0.257368 loss)
I0502 11:26:46.455268 26473 solver.cpp:242] Iteration 102000 (93.5078 iter/s, 1.06943s/100 iter), loss = 0.466926
I0502 11:26:46.455288 26473 solver.cpp:261]     Train net output #0: loss = 0.466926 (* 1 = 0.466926 loss)
I0502 11:26:46.455296 26473 sgd_solver.cpp:106] Iteration 102000, lr = 1.07374e-05
I0502 11:26:46.456962 26473 solver.cpp:362] Iteration 102000, Testing net (#0)
I0502 11:26:46.456975 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:46.587731 26473 solver.cpp:429]     Test net output #0: accuracy = 0.954
I0502 11:26:46.587755 26473 solver.cpp:429]     Test net output #1: loss = 0.0995875 (* 1 = 0.0995875 loss)
I0502 11:26:46.590693 26473 solver.cpp:242] Iteration 102000 (83.3353 iter/s, 1.19997s/100 iter), loss = 0.0343848
I0502 11:26:46.590715 26473 solver.cpp:261]     Train net output #0: loss = 0.0343848 (* 1 = 0.0343848 loss)
I0502 11:26:46.590724 26473 sgd_solver.cpp:106] Iteration 102000, lr = 1.07374e-05
I0502 11:26:47.529091 26473 solver.cpp:242] Iteration 102100 (93.1296 iter/s, 1.07377s/100 iter), loss = 0.146077
I0502 11:26:47.529121 26473 solver.cpp:261]     Train net output #0: loss = 0.146077 (* 1 = 0.146077 loss)
I0502 11:26:47.529129 26473 sgd_solver.cpp:106] Iteration 102100, lr = 1.07374e-05
I0502 11:26:47.533898 26473 solver.cpp:242] Iteration 102100 (106.026 iter/s, 0.943164s/100 iter), loss = 0.131663
I0502 11:26:47.533921 26473 solver.cpp:261]     Train net output #0: loss = 0.131663 (* 1 = 0.131663 loss)
I0502 11:26:47.533929 26473 sgd_solver.cpp:106] Iteration 102100, lr = 1.07374e-05
I0502 11:26:48.473131 26473 solver.cpp:242] Iteration 102200 (105.934 iter/s, 0.943983s/100 iter), loss = 0.130024
I0502 11:26:48.473177 26473 solver.cpp:261]     Train net output #0: loss = 0.130024 (* 1 = 0.130024 loss)
I0502 11:26:48.473186 26473 sgd_solver.cpp:106] Iteration 102200, lr = 1.07374e-05
I0502 11:26:48.477948 26473 solver.cpp:242] Iteration 102200 (105.931 iter/s, 0.944009s/100 iter), loss = 0.170638
I0502 11:26:48.477972 26473 solver.cpp:261]     Train net output #0: loss = 0.170638 (* 1 = 0.170638 loss)
I0502 11:26:48.477980 26473 sgd_solver.cpp:106] Iteration 102200, lr = 1.07374e-05
I0502 11:26:49.416375 26473 solver.cpp:242] Iteration 102300 (106.025 iter/s, 0.943173s/100 iter), loss = 0.288745
I0502 11:26:49.416425 26473 solver.cpp:261]     Train net output #0: loss = 0.288745 (* 1 = 0.288745 loss)
I0502 11:26:49.416435 26473 sgd_solver.cpp:106] Iteration 102300, lr = 1.07374e-05
I0502 11:26:49.421196 26473 solver.cpp:242] Iteration 102300 (106.021 iter/s, 0.943206s/100 iter), loss = 0.100478
I0502 11:26:49.421219 26473 solver.cpp:261]     Train net output #0: loss = 0.100478 (* 1 = 0.100478 loss)
I0502 11:26:49.421227 26473 sgd_solver.cpp:106] Iteration 102300, lr = 1.07374e-05
I0502 11:26:50.361014 26473 solver.cpp:242] Iteration 102400 (105.869 iter/s, 0.944563s/100 iter), loss = 0.293229
I0502 11:26:50.361054 26473 solver.cpp:261]     Train net output #0: loss = 0.293229 (* 1 = 0.293229 loss)
I0502 11:26:50.361063 26473 sgd_solver.cpp:106] Iteration 102400, lr = 1.07374e-05
I0502 11:26:50.365911 26473 solver.cpp:242] Iteration 102400 (105.858 iter/s, 0.944665s/100 iter), loss = 0.0582537
I0502 11:26:50.365934 26473 solver.cpp:261]     Train net output #0: loss = 0.0582537 (* 1 = 0.0582537 loss)
I0502 11:26:50.365943 26473 sgd_solver.cpp:106] Iteration 102400, lr = 1.07374e-05
I0502 11:26:51.301924 26473 solver.cpp:362] Iteration 102500, Testing net (#0)
I0502 11:26:51.301949 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:51.426287 26473 solver.cpp:429]     Test net output #0: loss = 0.234471 (* 1 = 0.234471 loss)
I0502 11:26:51.429157 26473 solver.cpp:242] Iteration 102500 (93.6257 iter/s, 1.06808s/100 iter), loss = 0.0968618
I0502 11:26:51.429177 26473 solver.cpp:261]     Train net output #0: loss = 0.0968618 (* 1 = 0.0968618 loss)
I0502 11:26:51.429185 26473 sgd_solver.cpp:106] Iteration 102500, lr = 1.07374e-05
I0502 11:26:51.430811 26473 solver.cpp:362] Iteration 102500, Testing net (#0)
I0502 11:26:51.430825 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:51.561560 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:26:51.561588 26473 solver.cpp:429]     Test net output #1: loss = 0.0789995 (* 1 = 0.0789995 loss)
I0502 11:26:51.564514 26473 solver.cpp:242] Iteration 102500 (83.4335 iter/s, 1.19856s/100 iter), loss = 0.120685
I0502 11:26:51.564533 26473 solver.cpp:261]     Train net output #0: loss = 0.120685 (* 1 = 0.120685 loss)
I0502 11:26:51.564543 26473 sgd_solver.cpp:106] Iteration 102500, lr = 1.07374e-05
I0502 11:26:52.503998 26473 solver.cpp:242] Iteration 102600 (93.0415 iter/s, 1.07479s/100 iter), loss = 0.0890675
I0502 11:26:52.504040 26473 solver.cpp:261]     Train net output #0: loss = 0.0890675 (* 1 = 0.0890675 loss)
I0502 11:26:52.504048 26473 sgd_solver.cpp:106] Iteration 102600, lr = 1.07374e-05
I0502 11:26:52.508844 26473 solver.cpp:242] Iteration 102600 (105.899 iter/s, 0.944293s/100 iter), loss = 0.0277223
I0502 11:26:52.508878 26473 solver.cpp:261]     Train net output #0: loss = 0.0277223 (* 1 = 0.0277223 loss)
I0502 11:26:52.508888 26473 sgd_solver.cpp:106] Iteration 102600, lr = 1.07374e-05
I0502 11:26:53.447669 26473 solver.cpp:242] Iteration 102700 (105.977 iter/s, 0.943602s/100 iter), loss = 0.263824
I0502 11:26:53.447708 26473 solver.cpp:261]     Train net output #0: loss = 0.263824 (* 1 = 0.263824 loss)
I0502 11:26:53.447717 26473 sgd_solver.cpp:106] Iteration 102700, lr = 1.07374e-05
I0502 11:26:53.452469 26473 solver.cpp:242] Iteration 102700 (105.98 iter/s, 0.943573s/100 iter), loss = 0.0875679
I0502 11:26:53.452493 26473 solver.cpp:261]     Train net output #0: loss = 0.0875679 (* 1 = 0.0875679 loss)
I0502 11:26:53.452502 26473 sgd_solver.cpp:106] Iteration 102700, lr = 1.07374e-05
I0502 11:26:54.392560 26473 solver.cpp:242] Iteration 102800 (105.84 iter/s, 0.944821s/100 iter), loss = 0.34189
I0502 11:26:54.392601 26473 solver.cpp:261]     Train net output #0: loss = 0.34189 (* 1 = 0.34189 loss)
I0502 11:26:54.392611 26473 sgd_solver.cpp:106] Iteration 102800, lr = 1.07374e-05
I0502 11:26:54.397361 26473 solver.cpp:242] Iteration 102800 (105.837 iter/s, 0.94485s/100 iter), loss = 0.0196313
I0502 11:26:54.397383 26473 solver.cpp:261]     Train net output #0: loss = 0.0196313 (* 1 = 0.0196313 loss)
I0502 11:26:54.397400 26473 sgd_solver.cpp:106] Iteration 102800, lr = 1.07374e-05
I0502 11:26:55.354982 26473 solver.cpp:242] Iteration 102900 (103.912 iter/s, 0.962357s/100 iter), loss = 0.218509
I0502 11:26:55.355016 26473 solver.cpp:261]     Train net output #0: loss = 0.218509 (* 1 = 0.218509 loss)
I0502 11:26:55.355026 26473 sgd_solver.cpp:106] Iteration 102900, lr = 1.07374e-05
I0502 11:26:55.359863 26473 solver.cpp:242] Iteration 102900 (103.901 iter/s, 0.962453s/100 iter), loss = 0.105464
I0502 11:26:55.359887 26473 solver.cpp:261]     Train net output #0: loss = 0.105464 (* 1 = 0.105464 loss)
I0502 11:26:55.359895 26473 sgd_solver.cpp:106] Iteration 102900, lr = 1.07374e-05
I0502 11:26:56.296442 26473 solver.cpp:362] Iteration 103000, Testing net (#0)
I0502 11:26:56.296473 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:56.420872 26473 solver.cpp:429]     Test net output #0: loss = 0.256215 (* 1 = 0.256215 loss)
I0502 11:26:56.423738 26473 solver.cpp:242] Iteration 103000 (93.5713 iter/s, 1.0687s/100 iter), loss = 0.533761
I0502 11:26:56.423758 26473 solver.cpp:261]     Train net output #0: loss = 0.533761 (* 1 = 0.533761 loss)
I0502 11:26:56.423766 26473 sgd_solver.cpp:106] Iteration 103000, lr = 1.07374e-05
I0502 11:26:56.425391 26473 solver.cpp:362] Iteration 103000, Testing net (#0)
I0502 11:26:56.425405 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:26:56.556097 26473 solver.cpp:429]     Test net output #0: accuracy = 0.951
I0502 11:26:56.556119 26473 solver.cpp:429]     Test net output #1: loss = 0.0976862 (* 1 = 0.0976862 loss)
I0502 11:26:56.559047 26473 solver.cpp:242] Iteration 103000 (83.3932 iter/s, 1.19914s/100 iter), loss = 0.126802
I0502 11:26:56.559067 26473 solver.cpp:261]     Train net output #0: loss = 0.126802 (* 1 = 0.126802 loss)
I0502 11:26:56.559075 26473 sgd_solver.cpp:106] Iteration 103000, lr = 1.07374e-05
I0502 11:26:57.498188 26473 solver.cpp:242] Iteration 103100 (93.0754 iter/s, 1.0744s/100 iter), loss = 0.109772
I0502 11:26:57.498222 26473 solver.cpp:261]     Train net output #0: loss = 0.109772 (* 1 = 0.109772 loss)
I0502 11:26:57.498231 26473 sgd_solver.cpp:106] Iteration 103100, lr = 1.07374e-05
I0502 11:26:57.503005 26473 solver.cpp:242] Iteration 103100 (105.941 iter/s, 0.943919s/100 iter), loss = 0.199591
I0502 11:26:57.503027 26473 solver.cpp:261]     Train net output #0: loss = 0.199591 (* 1 = 0.199591 loss)
I0502 11:26:57.503036 26473 sgd_solver.cpp:106] Iteration 103100, lr = 1.07374e-05
I0502 11:26:58.442445 26473 solver.cpp:242] Iteration 103200 (105.91 iter/s, 0.944195s/100 iter), loss = 0.0679987
I0502 11:26:58.442477 26473 solver.cpp:261]     Train net output #0: loss = 0.0679987 (* 1 = 0.0679987 loss)
I0502 11:26:58.442487 26473 sgd_solver.cpp:106] Iteration 103200, lr = 1.07374e-05
I0502 11:26:58.447238 26473 solver.cpp:242] Iteration 103200 (105.911 iter/s, 0.944193s/100 iter), loss = 0.115511
I0502 11:26:58.447262 26473 solver.cpp:261]     Train net output #0: loss = 0.115511 (* 1 = 0.115511 loss)
I0502 11:26:58.447270 26473 sgd_solver.cpp:106] Iteration 103200, lr = 1.07374e-05
I0502 11:26:59.386042 26473 solver.cpp:242] Iteration 103300 (105.984 iter/s, 0.943538s/100 iter), loss = 0.496548
I0502 11:26:59.386086 26473 solver.cpp:261]     Train net output #0: loss = 0.496548 (* 1 = 0.496548 loss)
I0502 11:26:59.386096 26473 sgd_solver.cpp:106] Iteration 103300, lr = 1.07374e-05
I0502 11:26:59.390841 26473 solver.cpp:242] Iteration 103300 (105.981 iter/s, 0.943563s/100 iter), loss = 0.0828157
I0502 11:26:59.390864 26473 solver.cpp:261]     Train net output #0: loss = 0.0828157 (* 1 = 0.0828157 loss)
I0502 11:26:59.390873 26473 sgd_solver.cpp:106] Iteration 103300, lr = 1.07374e-05
I0502 11:27:00.341339 26473 solver.cpp:242] Iteration 103400 (104.687 iter/s, 0.955226s/100 iter), loss = 0.0985225
I0502 11:27:00.341387 26473 solver.cpp:261]     Train net output #0: loss = 0.0985225 (* 1 = 0.0985225 loss)
I0502 11:27:00.341397 26473 sgd_solver.cpp:106] Iteration 103400, lr = 1.07374e-05
I0502 11:27:00.346258 26473 solver.cpp:242] Iteration 103400 (104.672 iter/s, 0.955366s/100 iter), loss = 0.116139
I0502 11:27:00.346283 26473 solver.cpp:261]     Train net output #0: loss = 0.116139 (* 1 = 0.116139 loss)
I0502 11:27:00.346292 26473 sgd_solver.cpp:106] Iteration 103400, lr = 1.07374e-05
I0502 11:27:01.281383 26473 solver.cpp:362] Iteration 103500, Testing net (#0)
I0502 11:27:01.281409 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:01.405766 26473 solver.cpp:429]     Test net output #0: loss = 0.256462 (* 1 = 0.256462 loss)
I0502 11:27:01.408640 26473 solver.cpp:242] Iteration 103500 (93.7 iter/s, 1.06724s/100 iter), loss = 0.381755
I0502 11:27:01.408659 26473 solver.cpp:261]     Train net output #0: loss = 0.381755 (* 1 = 0.381755 loss)
I0502 11:27:01.408668 26473 sgd_solver.cpp:106] Iteration 103500, lr = 1.07374e-05
I0502 11:27:01.410390 26473 solver.cpp:362] Iteration 103500, Testing net (#0)
I0502 11:27:01.410403 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:01.541134 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:27:01.541155 26473 solver.cpp:429]     Test net output #1: loss = 0.0967543 (* 1 = 0.0967543 loss)
I0502 11:27:01.544080 26473 solver.cpp:242] Iteration 103500 (83.4881 iter/s, 1.19778s/100 iter), loss = 0.147667
I0502 11:27:01.544100 26473 solver.cpp:261]     Train net output #0: loss = 0.147667 (* 1 = 0.147667 loss)
I0502 11:27:01.544108 26473 sgd_solver.cpp:106] Iteration 103500, lr = 1.07374e-05
I0502 11:27:02.483336 26473 solver.cpp:242] Iteration 103600 (93.0542 iter/s, 1.07464s/100 iter), loss = 0.591794
I0502 11:27:02.483394 26473 solver.cpp:261]     Train net output #0: loss = 0.591794 (* 1 = 0.591794 loss)
I0502 11:27:02.483407 26473 sgd_solver.cpp:106] Iteration 103600, lr = 1.07374e-05
I0502 11:27:02.488216 26473 solver.cpp:242] Iteration 103600 (105.921 iter/s, 0.944098s/100 iter), loss = 0.0513433
I0502 11:27:02.488251 26473 solver.cpp:261]     Train net output #0: loss = 0.0513433 (* 1 = 0.0513433 loss)
I0502 11:27:02.488260 26473 sgd_solver.cpp:106] Iteration 103600, lr = 1.07374e-05
I0502 11:27:03.427073 26473 solver.cpp:242] Iteration 103700 (105.971 iter/s, 0.943651s/100 iter), loss = 0.163114
I0502 11:27:03.427115 26473 solver.cpp:261]     Train net output #0: loss = 0.163114 (* 1 = 0.163114 loss)
I0502 11:27:03.427124 26473 sgd_solver.cpp:106] Iteration 103700, lr = 1.07374e-05
I0502 11:27:03.431879 26473 solver.cpp:242] Iteration 103700 (105.976 iter/s, 0.943611s/100 iter), loss = 0.11786
I0502 11:27:03.431902 26473 solver.cpp:261]     Train net output #0: loss = 0.11786 (* 1 = 0.11786 loss)
I0502 11:27:03.431910 26473 sgd_solver.cpp:106] Iteration 103700, lr = 1.07374e-05
I0502 11:27:04.370343 26473 solver.cpp:242] Iteration 103800 (106.022 iter/s, 0.9432s/100 iter), loss = 0.056184
I0502 11:27:04.370383 26473 solver.cpp:261]     Train net output #0: loss = 0.056184 (* 1 = 0.056184 loss)
I0502 11:27:04.370393 26473 sgd_solver.cpp:106] Iteration 103800, lr = 1.07374e-05
I0502 11:27:04.375159 26473 solver.cpp:242] Iteration 103800 (106.018 iter/s, 0.94324s/100 iter), loss = 0.0833903
I0502 11:27:04.375182 26473 solver.cpp:261]     Train net output #0: loss = 0.0833903 (* 1 = 0.0833903 loss)
I0502 11:27:04.375190 26473 sgd_solver.cpp:106] Iteration 103800, lr = 1.07374e-05
I0502 11:27:05.313992 26473 solver.cpp:242] Iteration 103900 (105.979 iter/s, 0.943582s/100 iter), loss = 0.103344
I0502 11:27:05.314031 26473 solver.cpp:261]     Train net output #0: loss = 0.103344 (* 1 = 0.103344 loss)
I0502 11:27:05.314040 26473 sgd_solver.cpp:106] Iteration 103900, lr = 1.07374e-05
I0502 11:27:05.318819 26473 solver.cpp:242] Iteration 103900 (105.975 iter/s, 0.943617s/100 iter), loss = 0.0813978
I0502 11:27:05.318841 26473 solver.cpp:261]     Train net output #0: loss = 0.0813978 (* 1 = 0.0813978 loss)
I0502 11:27:05.318850 26473 sgd_solver.cpp:106] Iteration 103900, lr = 1.07374e-05
I0502 11:27:06.254148 26473 solver.cpp:362] Iteration 104000, Testing net (#0)
I0502 11:27:06.254170 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:06.378626 26473 solver.cpp:429]     Test net output #0: loss = 0.210304 (* 1 = 0.210304 loss)
I0502 11:27:06.381494 26473 solver.cpp:242] Iteration 104000 (93.6817 iter/s, 1.06744s/100 iter), loss = 0.560373
I0502 11:27:06.381513 26473 solver.cpp:261]     Train net output #0: loss = 0.560373 (* 1 = 0.560373 loss)
I0502 11:27:06.381521 26473 sgd_solver.cpp:106] Iteration 104000, lr = 1.07374e-05
I0502 11:27:06.383219 26473 solver.cpp:362] Iteration 104000, Testing net (#0)
I0502 11:27:06.383231 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:06.513903 26473 solver.cpp:429]     Test net output #0: accuracy = 0.958
I0502 11:27:06.513924 26473 solver.cpp:429]     Test net output #1: loss = 0.0855408 (* 1 = 0.0855408 loss)
I0502 11:27:06.516837 26473 solver.cpp:242] Iteration 104000 (83.4741 iter/s, 1.19798s/100 iter), loss = 0.124251
I0502 11:27:06.516857 26473 solver.cpp:261]     Train net output #0: loss = 0.124251 (* 1 = 0.124251 loss)
I0502 11:27:06.516866 26473 sgd_solver.cpp:106] Iteration 104000, lr = 1.07374e-05
I0502 11:27:07.456646 26473 solver.cpp:242] Iteration 104100 (93.0145 iter/s, 1.0751s/100 iter), loss = 0.26449
I0502 11:27:07.456681 26473 solver.cpp:261]     Train net output #0: loss = 0.26449 (* 1 = 0.26449 loss)
I0502 11:27:07.456691 26473 sgd_solver.cpp:106] Iteration 104100, lr = 1.07374e-05
I0502 11:27:07.461459 26473 solver.cpp:242] Iteration 104100 (105.867 iter/s, 0.944584s/100 iter), loss = 0.283057
I0502 11:27:07.461483 26473 solver.cpp:261]     Train net output #0: loss = 0.283057 (* 1 = 0.283057 loss)
I0502 11:27:07.461491 26473 sgd_solver.cpp:106] Iteration 104100, lr = 1.07374e-05
I0502 11:27:08.400190 26473 solver.cpp:242] Iteration 104200 (105.99 iter/s, 0.943482s/100 iter), loss = 0.132644
I0502 11:27:08.400221 26473 solver.cpp:261]     Train net output #0: loss = 0.132644 (* 1 = 0.132644 loss)
I0502 11:27:08.400230 26473 sgd_solver.cpp:106] Iteration 104200, lr = 1.07374e-05
I0502 11:27:08.405027 26473 solver.cpp:242] Iteration 104200 (105.985 iter/s, 0.943526s/100 iter), loss = 0.115947
I0502 11:27:08.405050 26473 solver.cpp:261]     Train net output #0: loss = 0.115947 (* 1 = 0.115947 loss)
I0502 11:27:08.405058 26473 sgd_solver.cpp:106] Iteration 104200, lr = 1.07374e-05
I0502 11:27:09.345319 26473 solver.cpp:242] Iteration 104300 (105.812 iter/s, 0.945069s/100 iter), loss = 0.18429
I0502 11:27:09.345362 26473 solver.cpp:261]     Train net output #0: loss = 0.18429 (* 1 = 0.18429 loss)
I0502 11:27:09.345371 26473 sgd_solver.cpp:106] Iteration 104300, lr = 1.07374e-05
I0502 11:27:09.350136 26473 solver.cpp:242] Iteration 104300 (105.812 iter/s, 0.945068s/100 iter), loss = 0.0493074
I0502 11:27:09.350158 26473 solver.cpp:261]     Train net output #0: loss = 0.0493074 (* 1 = 0.0493074 loss)
I0502 11:27:09.350167 26473 sgd_solver.cpp:106] Iteration 104300, lr = 1.07374e-05
I0502 11:27:10.289613 26473 solver.cpp:242] Iteration 104400 (105.907 iter/s, 0.944225s/100 iter), loss = 0.0903548
I0502 11:27:10.289659 26473 solver.cpp:261]     Train net output #0: loss = 0.0903548 (* 1 = 0.0903548 loss)
I0502 11:27:10.289667 26473 sgd_solver.cpp:106] Iteration 104400, lr = 1.07374e-05
I0502 11:27:10.294464 26473 solver.cpp:242] Iteration 104400 (105.9 iter/s, 0.944289s/100 iter), loss = 0.078835
I0502 11:27:10.294488 26473 solver.cpp:261]     Train net output #0: loss = 0.078835 (* 1 = 0.078835 loss)
I0502 11:27:10.294497 26473 sgd_solver.cpp:106] Iteration 104400, lr = 1.07374e-05
I0502 11:27:11.230849 26473 solver.cpp:362] Iteration 104500, Testing net (#0)
I0502 11:27:11.230877 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:11.355340 26473 solver.cpp:429]     Test net output #0: loss = 0.261385 (* 1 = 0.261385 loss)
I0502 11:27:11.358214 26473 solver.cpp:242] Iteration 104500 (93.5859 iter/s, 1.06854s/100 iter), loss = 0.190131
I0502 11:27:11.358234 26473 solver.cpp:261]     Train net output #0: loss = 0.190131 (* 1 = 0.190131 loss)
I0502 11:27:11.358243 26473 sgd_solver.cpp:106] Iteration 104500, lr = 1.07374e-05
I0502 11:27:11.359939 26473 solver.cpp:362] Iteration 104500, Testing net (#0)
I0502 11:27:11.359961 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:11.490473 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:27:11.490496 26473 solver.cpp:429]     Test net output #1: loss = 0.0913036 (* 1 = 0.0913036 loss)
I0502 11:27:11.493418 26473 solver.cpp:242] Iteration 104500 (83.4092 iter/s, 1.19891s/100 iter), loss = 0.0241223
I0502 11:27:11.493438 26473 solver.cpp:261]     Train net output #0: loss = 0.0241223 (* 1 = 0.0241223 loss)
I0502 11:27:11.493448 26473 sgd_solver.cpp:106] Iteration 104500, lr = 1.07374e-05
I0502 11:27:12.432245 26473 solver.cpp:242] Iteration 104600 (93.1119 iter/s, 1.07398s/100 iter), loss = 0.178871
I0502 11:27:12.432287 26473 solver.cpp:261]     Train net output #0: loss = 0.178871 (* 1 = 0.178871 loss)
I0502 11:27:12.432296 26473 sgd_solver.cpp:106] Iteration 104600, lr = 1.07374e-05
I0502 11:27:12.437050 26473 solver.cpp:242] Iteration 104600 (105.978 iter/s, 0.943593s/100 iter), loss = 0.0596827
I0502 11:27:12.437073 26473 solver.cpp:261]     Train net output #0: loss = 0.0596827 (* 1 = 0.0596827 loss)
I0502 11:27:12.437083 26473 sgd_solver.cpp:106] Iteration 104600, lr = 1.07374e-05
I0502 11:27:13.377022 26473 solver.cpp:242] Iteration 104700 (105.853 iter/s, 0.944705s/100 iter), loss = 0.285513
I0502 11:27:13.377077 26473 solver.cpp:261]     Train net output #0: loss = 0.285513 (* 1 = 0.285513 loss)
I0502 11:27:13.377104 26473 sgd_solver.cpp:106] Iteration 104700, lr = 1.07374e-05
I0502 11:27:13.381922 26473 solver.cpp:242] Iteration 104700 (105.84 iter/s, 0.944819s/100 iter), loss = 0.0657459
I0502 11:27:13.381944 26473 solver.cpp:261]     Train net output #0: loss = 0.0657459 (* 1 = 0.0657459 loss)
I0502 11:27:13.381953 26473 sgd_solver.cpp:106] Iteration 104700, lr = 1.07374e-05
I0502 11:27:14.320448 26473 solver.cpp:242] Iteration 104800 (106.006 iter/s, 0.943345s/100 iter), loss = 0.180628
I0502 11:27:14.320490 26473 solver.cpp:261]     Train net output #0: loss = 0.180628 (* 1 = 0.180628 loss)
I0502 11:27:14.320499 26473 sgd_solver.cpp:106] Iteration 104800, lr = 1.07374e-05
I0502 11:27:14.325258 26473 solver.cpp:242] Iteration 104800 (106.011 iter/s, 0.943296s/100 iter), loss = 0.0502707
I0502 11:27:14.325281 26473 solver.cpp:261]     Train net output #0: loss = 0.0502707 (* 1 = 0.0502707 loss)
I0502 11:27:14.325289 26473 sgd_solver.cpp:106] Iteration 104800, lr = 1.07374e-05
I0502 11:27:15.263447 26473 solver.cpp:242] Iteration 104900 (106.052 iter/s, 0.94293s/100 iter), loss = 0.141447
I0502 11:27:15.263487 26473 solver.cpp:261]     Train net output #0: loss = 0.141447 (* 1 = 0.141447 loss)
I0502 11:27:15.263496 26473 sgd_solver.cpp:106] Iteration 104900, lr = 1.07374e-05
I0502 11:27:15.268293 26473 solver.cpp:242] Iteration 104900 (106.045 iter/s, 0.942994s/100 iter), loss = 0.0569618
I0502 11:27:15.268317 26473 solver.cpp:261]     Train net output #0: loss = 0.0569618 (* 1 = 0.0569618 loss)
I0502 11:27:15.268326 26473 sgd_solver.cpp:106] Iteration 104900, lr = 1.07374e-05
I0502 11:27:16.205004 26473 solver.cpp:362] Iteration 105000, Testing net (#0)
I0502 11:27:16.205036 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:16.329362 26473 solver.cpp:429]     Test net output #0: loss = 0.280596 (* 1 = 0.280596 loss)
I0502 11:27:16.332247 26473 solver.cpp:242] Iteration 105000 (93.5682 iter/s, 1.06874s/100 iter), loss = 0.0524507
I0502 11:27:16.332267 26473 solver.cpp:261]     Train net output #0: loss = 0.0524507 (* 1 = 0.0524507 loss)
I0502 11:27:16.332276 26473 sgd_solver.cpp:106] Iteration 105000, lr = 1.07374e-05
I0502 11:27:16.333992 26473 solver.cpp:362] Iteration 105000, Testing net (#0)
I0502 11:27:16.334005 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:16.464658 26473 solver.cpp:429]     Test net output #0: accuracy = 0.967
I0502 11:27:16.464679 26473 solver.cpp:429]     Test net output #1: loss = 0.0862176 (* 1 = 0.0862176 loss)
I0502 11:27:16.467615 26473 solver.cpp:242] Iteration 105000 (83.3836 iter/s, 1.19928s/100 iter), loss = 0.0705396
I0502 11:27:16.467644 26473 solver.cpp:261]     Train net output #0: loss = 0.0705396 (* 1 = 0.0705396 loss)
I0502 11:27:16.467653 26473 sgd_solver.cpp:106] Iteration 105000, lr = 1.07374e-05
I0502 11:27:17.406641 26473 solver.cpp:242] Iteration 105100 (93.0806 iter/s, 1.07434s/100 iter), loss = 0.219794
I0502 11:27:17.406680 26473 solver.cpp:261]     Train net output #0: loss = 0.219794 (* 1 = 0.219794 loss)
I0502 11:27:17.406689 26473 sgd_solver.cpp:106] Iteration 105100, lr = 1.07374e-05
I0502 11:27:17.411445 26473 solver.cpp:242] Iteration 105100 (105.956 iter/s, 0.943784s/100 iter), loss = 0.0179935
I0502 11:27:17.411469 26473 solver.cpp:261]     Train net output #0: loss = 0.0179935 (* 1 = 0.0179935 loss)
I0502 11:27:17.411478 26473 sgd_solver.cpp:106] Iteration 105100, lr = 1.07374e-05
I0502 11:27:18.350962 26473 solver.cpp:242] Iteration 105200 (105.904 iter/s, 0.944252s/100 iter), loss = 0.115354
I0502 11:27:18.351002 26473 solver.cpp:261]     Train net output #0: loss = 0.115354 (* 1 = 0.115354 loss)
I0502 11:27:18.351011 26473 sgd_solver.cpp:106] Iteration 105200, lr = 1.07374e-05
I0502 11:27:18.355777 26473 solver.cpp:242] Iteration 105200 (105.9 iter/s, 0.94429s/100 iter), loss = 0.0171777
I0502 11:27:18.355800 26473 solver.cpp:261]     Train net output #0: loss = 0.0171777 (* 1 = 0.0171777 loss)
I0502 11:27:18.355809 26473 sgd_solver.cpp:106] Iteration 105200, lr = 1.07374e-05
I0502 11:27:19.294857 26473 solver.cpp:242] Iteration 105300 (105.952 iter/s, 0.943826s/100 iter), loss = 0.0819227
I0502 11:27:19.294898 26473 solver.cpp:261]     Train net output #0: loss = 0.0819227 (* 1 = 0.0819227 loss)
I0502 11:27:19.294909 26473 sgd_solver.cpp:106] Iteration 105300, lr = 1.07374e-05
I0502 11:27:19.299713 26473 solver.cpp:242] Iteration 105300 (105.944 iter/s, 0.943895s/100 iter), loss = 0.165787
I0502 11:27:19.299738 26473 solver.cpp:261]     Train net output #0: loss = 0.165787 (* 1 = 0.165787 loss)
I0502 11:27:19.299747 26473 sgd_solver.cpp:106] Iteration 105300, lr = 1.07374e-05
I0502 11:27:20.237787 26473 solver.cpp:242] Iteration 105400 (106.06 iter/s, 0.942863s/100 iter), loss = 0.107629
I0502 11:27:20.237824 26473 solver.cpp:261]     Train net output #0: loss = 0.107629 (* 1 = 0.107629 loss)
I0502 11:27:20.237833 26473 sgd_solver.cpp:106] Iteration 105400, lr = 1.07374e-05
I0502 11:27:20.242625 26473 solver.cpp:242] Iteration 105400 (106.059 iter/s, 0.942869s/100 iter), loss = 0.00813746
I0502 11:27:20.242648 26473 solver.cpp:261]     Train net output #0: loss = 0.00813746 (* 1 = 0.00813746 loss)
I0502 11:27:20.242657 26473 sgd_solver.cpp:106] Iteration 105400, lr = 1.07374e-05
I0502 11:27:21.178880 26473 solver.cpp:362] Iteration 105500, Testing net (#0)
I0502 11:27:21.178905 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:21.303277 26473 solver.cpp:429]     Test net output #0: loss = 0.325008 (* 1 = 0.325008 loss)
I0502 11:27:21.306155 26473 solver.cpp:242] Iteration 105500 (93.6055 iter/s, 1.06831s/100 iter), loss = 0.280309
I0502 11:27:21.306176 26473 solver.cpp:261]     Train net output #0: loss = 0.280309 (* 1 = 0.280309 loss)
I0502 11:27:21.306185 26473 sgd_solver.cpp:106] Iteration 105500, lr = 1.07374e-05
I0502 11:27:21.307888 26473 solver.cpp:362] Iteration 105500, Testing net (#0)
I0502 11:27:21.307901 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:21.438608 26473 solver.cpp:429]     Test net output #0: accuracy = 0.956
I0502 11:27:21.438630 26473 solver.cpp:429]     Test net output #1: loss = 0.0949042 (* 1 = 0.0949042 loss)
I0502 11:27:21.441561 26473 solver.cpp:242] Iteration 105500 (83.4103 iter/s, 1.19889s/100 iter), loss = 0.0634036
I0502 11:27:21.441581 26473 solver.cpp:261]     Train net output #0: loss = 0.0634036 (* 1 = 0.0634036 loss)
I0502 11:27:21.441591 26473 sgd_solver.cpp:106] Iteration 105500, lr = 1.07374e-05
I0502 11:27:22.380688 26473 solver.cpp:242] Iteration 105600 (93.0684 iter/s, 1.07448s/100 iter), loss = 0.263434
I0502 11:27:22.380725 26473 solver.cpp:261]     Train net output #0: loss = 0.263434 (* 1 = 0.263434 loss)
I0502 11:27:22.380744 26473 sgd_solver.cpp:106] Iteration 105600, lr = 1.07374e-05
I0502 11:27:22.385534 26473 solver.cpp:242] Iteration 105600 (105.941 iter/s, 0.943922s/100 iter), loss = 0.0587564
I0502 11:27:22.385556 26473 solver.cpp:261]     Train net output #0: loss = 0.0587564 (* 1 = 0.0587564 loss)
I0502 11:27:22.385565 26473 sgd_solver.cpp:106] Iteration 105600, lr = 1.07374e-05
I0502 11:27:23.324440 26473 solver.cpp:242] Iteration 105700 (105.967 iter/s, 0.943686s/100 iter), loss = 0.148759
I0502 11:27:23.324471 26473 solver.cpp:261]     Train net output #0: loss = 0.148759 (* 1 = 0.148759 loss)
I0502 11:27:23.324479 26473 sgd_solver.cpp:106] Iteration 105700, lr = 1.07374e-05
I0502 11:27:23.329270 26473 solver.cpp:242] Iteration 105700 (105.966 iter/s, 0.943696s/100 iter), loss = 0.150491
I0502 11:27:23.329293 26473 solver.cpp:261]     Train net output #0: loss = 0.150491 (* 1 = 0.150491 loss)
I0502 11:27:23.329301 26473 sgd_solver.cpp:106] Iteration 105700, lr = 1.07374e-05
I0502 11:27:24.269217 26473 solver.cpp:242] Iteration 105800 (105.852 iter/s, 0.944717s/100 iter), loss = 0.115343
I0502 11:27:24.269276 26473 solver.cpp:261]     Train net output #0: loss = 0.115343 (* 1 = 0.115343 loss)
I0502 11:27:24.269286 26473 sgd_solver.cpp:106] Iteration 105800, lr = 1.07374e-05
I0502 11:27:24.274096 26473 solver.cpp:242] Iteration 105800 (105.844 iter/s, 0.944785s/100 iter), loss = 0.131257
I0502 11:27:24.274118 26473 solver.cpp:261]     Train net output #0: loss = 0.131257 (* 1 = 0.131257 loss)
I0502 11:27:24.274127 26473 sgd_solver.cpp:106] Iteration 105800, lr = 1.07374e-05
I0502 11:27:25.212884 26473 solver.cpp:242] Iteration 105900 (105.979 iter/s, 0.943581s/100 iter), loss = 0.115771
I0502 11:27:25.212927 26473 solver.cpp:261]     Train net output #0: loss = 0.115771 (* 1 = 0.115771 loss)
I0502 11:27:25.212936 26473 sgd_solver.cpp:106] Iteration 105900, lr = 1.07374e-05
I0502 11:27:25.217680 26473 solver.cpp:242] Iteration 105900 (105.983 iter/s, 0.943543s/100 iter), loss = 0.0740456
I0502 11:27:25.217703 26473 solver.cpp:261]     Train net output #0: loss = 0.0740456 (* 1 = 0.0740456 loss)
I0502 11:27:25.217712 26473 sgd_solver.cpp:106] Iteration 105900, lr = 1.07374e-05
I0502 11:27:26.155872 26473 solver.cpp:362] Iteration 106000, Testing net (#0)
I0502 11:27:26.155901 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:26.280125 26473 solver.cpp:429]     Test net output #0: loss = 0.227674 (* 1 = 0.227674 loss)
I0502 11:27:26.282992 26473 solver.cpp:242] Iteration 106000 (93.4537 iter/s, 1.07005s/100 iter), loss = 0.141463
I0502 11:27:26.283012 26473 solver.cpp:261]     Train net output #0: loss = 0.141463 (* 1 = 0.141463 loss)
I0502 11:27:26.283021 26473 sgd_solver.cpp:106] Iteration 106000, lr = 1.07374e-05
I0502 11:27:26.284759 26473 solver.cpp:362] Iteration 106000, Testing net (#0)
I0502 11:27:26.284773 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:26.415436 26473 solver.cpp:429]     Test net output #0: accuracy = 0.967
I0502 11:27:26.415457 26473 solver.cpp:429]     Test net output #1: loss = 0.0783252 (* 1 = 0.0783252 loss)
I0502 11:27:26.418392 26473 solver.cpp:242] Iteration 106000 (83.287 iter/s, 1.20067s/100 iter), loss = 0.0457473
I0502 11:27:26.418412 26473 solver.cpp:261]     Train net output #0: loss = 0.0457473 (* 1 = 0.0457473 loss)
I0502 11:27:26.418421 26473 sgd_solver.cpp:106] Iteration 106000, lr = 1.07374e-05
I0502 11:27:27.356901 26473 solver.cpp:242] Iteration 106100 (93.1218 iter/s, 1.07386s/100 iter), loss = 0.350255
I0502 11:27:27.356936 26473 solver.cpp:261]     Train net output #0: loss = 0.350255 (* 1 = 0.350255 loss)
I0502 11:27:27.356945 26473 sgd_solver.cpp:106] Iteration 106100, lr = 1.07374e-05
I0502 11:27:27.361748 26473 solver.cpp:242] Iteration 106100 (106.009 iter/s, 0.943312s/100 iter), loss = 0.00174819
I0502 11:27:27.361770 26473 solver.cpp:261]     Train net output #0: loss = 0.00174819 (* 1 = 0.00174819 loss)
I0502 11:27:27.361779 26473 sgd_solver.cpp:106] Iteration 106100, lr = 1.07374e-05
I0502 11:27:28.301218 26473 solver.cpp:242] Iteration 106200 (105.904 iter/s, 0.944249s/100 iter), loss = 0.119629
I0502 11:27:28.301270 26473 solver.cpp:261]     Train net output #0: loss = 0.119629 (* 1 = 0.119629 loss)
I0502 11:27:28.301280 26473 sgd_solver.cpp:106] Iteration 106200, lr = 1.07374e-05
I0502 11:27:28.306028 26473 solver.cpp:242] Iteration 106200 (105.905 iter/s, 0.944239s/100 iter), loss = 0.00641636
I0502 11:27:28.306051 26473 solver.cpp:261]     Train net output #0: loss = 0.00641636 (* 1 = 0.00641636 loss)
I0502 11:27:28.306059 26473 sgd_solver.cpp:106] Iteration 106200, lr = 1.07374e-05
I0502 11:27:29.245118 26473 solver.cpp:242] Iteration 106300 (105.952 iter/s, 0.943821s/100 iter), loss = 0.476065
I0502 11:27:29.245163 26473 solver.cpp:261]     Train net output #0: loss = 0.476065 (* 1 = 0.476065 loss)
I0502 11:27:29.245172 26473 sgd_solver.cpp:106] Iteration 106300, lr = 1.07374e-05
I0502 11:27:29.249915 26473 solver.cpp:242] Iteration 106300 (105.949 iter/s, 0.943846s/100 iter), loss = 0.194825
I0502 11:27:29.249938 26473 solver.cpp:261]     Train net output #0: loss = 0.194825 (* 1 = 0.194825 loss)
I0502 11:27:29.249946 26473 sgd_solver.cpp:106] Iteration 106300, lr = 1.07374e-05
I0502 11:27:30.189368 26473 solver.cpp:242] Iteration 106400 (105.912 iter/s, 0.944176s/100 iter), loss = 0.143027
I0502 11:27:30.189409 26473 solver.cpp:261]     Train net output #0: loss = 0.143027 (* 1 = 0.143027 loss)
I0502 11:27:30.189419 26473 sgd_solver.cpp:106] Iteration 106400, lr = 1.07374e-05
I0502 11:27:30.194170 26473 solver.cpp:242] Iteration 106400 (105.908 iter/s, 0.944214s/100 iter), loss = 0.0441947
I0502 11:27:30.194193 26473 solver.cpp:261]     Train net output #0: loss = 0.0441947 (* 1 = 0.0441947 loss)
I0502 11:27:30.194201 26473 sgd_solver.cpp:106] Iteration 106400, lr = 1.07374e-05
I0502 11:27:31.129559 26473 solver.cpp:362] Iteration 106500, Testing net (#0)
I0502 11:27:31.129585 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:31.253861 26473 solver.cpp:429]     Test net output #0: loss = 0.302093 (* 1 = 0.302093 loss)
I0502 11:27:31.256757 26473 solver.cpp:242] Iteration 106500 (93.6918 iter/s, 1.06733s/100 iter), loss = 0.16513
I0502 11:27:31.256777 26473 solver.cpp:261]     Train net output #0: loss = 0.16513 (* 1 = 0.16513 loss)
I0502 11:27:31.256784 26473 sgd_solver.cpp:106] Iteration 106500, lr = 1.07374e-05
I0502 11:27:31.258412 26473 solver.cpp:362] Iteration 106500, Testing net (#0)
I0502 11:27:31.258425 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:31.389134 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:27:31.389156 26473 solver.cpp:429]     Test net output #1: loss = 0.0964794 (* 1 = 0.0964794 loss)
I0502 11:27:31.392089 26473 solver.cpp:242] Iteration 106500 (83.4811 iter/s, 1.19788s/100 iter), loss = 0.0610313
I0502 11:27:31.392109 26473 solver.cpp:261]     Train net output #0: loss = 0.0610313 (* 1 = 0.0610313 loss)
I0502 11:27:31.392117 26473 sgd_solver.cpp:106] Iteration 106500, lr = 1.07374e-05
I0502 11:27:32.332381 26473 solver.cpp:242] Iteration 106600 (92.9735 iter/s, 1.07558s/100 iter), loss = 0.231217
I0502 11:27:32.332422 26473 solver.cpp:261]     Train net output #0: loss = 0.231217 (* 1 = 0.231217 loss)
I0502 11:27:32.332432 26473 sgd_solver.cpp:106] Iteration 106600, lr = 1.07374e-05
I0502 11:27:32.337257 26473 solver.cpp:242] Iteration 106600 (105.806 iter/s, 0.945122s/100 iter), loss = 0.0530244
I0502 11:27:32.337281 26473 solver.cpp:261]     Train net output #0: loss = 0.0530244 (* 1 = 0.0530244 loss)
I0502 11:27:32.337290 26473 sgd_solver.cpp:106] Iteration 106600, lr = 1.07374e-05
I0502 11:27:33.276146 26473 solver.cpp:242] Iteration 106700 (105.967 iter/s, 0.943693s/100 iter), loss = 0.165024
I0502 11:27:33.276187 26473 solver.cpp:261]     Train net output #0: loss = 0.165024 (* 1 = 0.165024 loss)
I0502 11:27:33.276196 26473 sgd_solver.cpp:106] Iteration 106700, lr = 1.07374e-05
I0502 11:27:33.280959 26473 solver.cpp:242] Iteration 106700 (105.97 iter/s, 0.94366s/100 iter), loss = 0.150204
I0502 11:27:33.280982 26473 solver.cpp:261]     Train net output #0: loss = 0.150204 (* 1 = 0.150204 loss)
I0502 11:27:33.280999 26473 sgd_solver.cpp:106] Iteration 106700, lr = 1.07374e-05
I0502 11:27:34.219318 26473 solver.cpp:242] Iteration 106800 (106.033 iter/s, 0.943103s/100 iter), loss = 0.0970286
I0502 11:27:34.219357 26473 solver.cpp:261]     Train net output #0: loss = 0.0970286 (* 1 = 0.0970286 loss)
I0502 11:27:34.219367 26473 sgd_solver.cpp:106] Iteration 106800, lr = 1.07374e-05
I0502 11:27:34.224153 26473 solver.cpp:242] Iteration 106800 (106.027 iter/s, 0.943152s/100 iter), loss = 0.1807
I0502 11:27:34.224176 26473 solver.cpp:261]     Train net output #0: loss = 0.1807 (* 1 = 0.1807 loss)
I0502 11:27:34.224184 26473 sgd_solver.cpp:106] Iteration 106800, lr = 1.07374e-05
I0502 11:27:35.163774 26473 solver.cpp:242] Iteration 106900 (105.889 iter/s, 0.944389s/100 iter), loss = 0.083586
I0502 11:27:35.163815 26473 solver.cpp:261]     Train net output #0: loss = 0.083586 (* 1 = 0.083586 loss)
I0502 11:27:35.163822 26473 sgd_solver.cpp:106] Iteration 106900, lr = 1.07374e-05
I0502 11:27:35.168592 26473 solver.cpp:242] Iteration 106900 (105.888 iter/s, 0.944397s/100 iter), loss = 0.0701779
I0502 11:27:35.168615 26473 solver.cpp:261]     Train net output #0: loss = 0.0701779 (* 1 = 0.0701779 loss)
I0502 11:27:35.168624 26473 sgd_solver.cpp:106] Iteration 106900, lr = 1.07374e-05
I0502 11:27:36.104363 26473 solver.cpp:362] Iteration 107000, Testing net (#0)
I0502 11:27:36.104385 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:36.228760 26473 solver.cpp:429]     Test net output #0: loss = 0.260583 (* 1 = 0.260583 loss)
I0502 11:27:36.231642 26473 solver.cpp:242] Iteration 107000 (93.6497 iter/s, 1.06781s/100 iter), loss = 0.150198
I0502 11:27:36.231660 26473 solver.cpp:261]     Train net output #0: loss = 0.150198 (* 1 = 0.150198 loss)
I0502 11:27:36.231669 26473 sgd_solver.cpp:106] Iteration 107000, lr = 1.07374e-05
I0502 11:27:36.233357 26473 solver.cpp:362] Iteration 107000, Testing net (#0)
I0502 11:27:36.233371 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:36.364078 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9675
I0502 11:27:36.364099 26473 solver.cpp:429]     Test net output #1: loss = 0.0789279 (* 1 = 0.0789279 loss)
I0502 11:27:36.367023 26473 solver.cpp:242] Iteration 107000 (83.4455 iter/s, 1.19839s/100 iter), loss = 0.0812757
I0502 11:27:36.367043 26473 solver.cpp:261]     Train net output #0: loss = 0.0812757 (* 1 = 0.0812757 loss)
I0502 11:27:36.367053 26473 sgd_solver.cpp:106] Iteration 107000, lr = 1.07374e-05
I0502 11:27:37.306908 26473 solver.cpp:242] Iteration 107100 (93.0041 iter/s, 1.07522s/100 iter), loss = 0.118464
I0502 11:27:37.306946 26473 solver.cpp:261]     Train net output #0: loss = 0.118464 (* 1 = 0.118464 loss)
I0502 11:27:37.306954 26473 sgd_solver.cpp:106] Iteration 107100, lr = 1.07374e-05
I0502 11:27:37.311801 26473 solver.cpp:242] Iteration 107100 (105.85 iter/s, 0.944732s/100 iter), loss = 0.0162015
I0502 11:27:37.311825 26473 solver.cpp:261]     Train net output #0: loss = 0.0162015 (* 1 = 0.0162015 loss)
I0502 11:27:37.311833 26473 sgd_solver.cpp:106] Iteration 107100, lr = 1.07374e-05
I0502 11:27:38.251516 26473 solver.cpp:242] Iteration 107200 (105.871 iter/s, 0.944543s/100 iter), loss = 0.802472
I0502 11:27:38.251554 26473 solver.cpp:261]     Train net output #0: loss = 0.802472 (* 1 = 0.802472 loss)
I0502 11:27:38.251564 26473 sgd_solver.cpp:106] Iteration 107200, lr = 1.07374e-05
I0502 11:27:38.256389 26473 solver.cpp:242] Iteration 107200 (105.871 iter/s, 0.944547s/100 iter), loss = 0.140597
I0502 11:27:38.256412 26473 solver.cpp:261]     Train net output #0: loss = 0.140597 (* 1 = 0.140597 loss)
I0502 11:27:38.256420 26473 sgd_solver.cpp:106] Iteration 107200, lr = 1.07374e-05
I0502 11:27:39.196207 26473 solver.cpp:242] Iteration 107300 (105.862 iter/s, 0.944624s/100 iter), loss = 0.373938
I0502 11:27:39.196249 26473 solver.cpp:261]     Train net output #0: loss = 0.373938 (* 1 = 0.373938 loss)
I0502 11:27:39.196259 26473 sgd_solver.cpp:106] Iteration 107300, lr = 1.07374e-05
I0502 11:27:39.201062 26473 solver.cpp:242] Iteration 107300 (105.861 iter/s, 0.944633s/100 iter), loss = 0.00579787
I0502 11:27:39.201086 26473 solver.cpp:261]     Train net output #0: loss = 0.00579787 (* 1 = 0.00579787 loss)
I0502 11:27:39.201094 26473 sgd_solver.cpp:106] Iteration 107300, lr = 1.07374e-05
I0502 11:27:40.140830 26473 solver.cpp:242] Iteration 107400 (105.87 iter/s, 0.944553s/100 iter), loss = 0.0593644
I0502 11:27:40.140884 26473 solver.cpp:261]     Train net output #0: loss = 0.0593644 (* 1 = 0.0593644 loss)
I0502 11:27:40.140894 26473 sgd_solver.cpp:106] Iteration 107400, lr = 1.07374e-05
I0502 11:27:40.145690 26473 solver.cpp:242] Iteration 107400 (105.866 iter/s, 0.944587s/100 iter), loss = 0.00591796
I0502 11:27:40.145714 26473 solver.cpp:261]     Train net output #0: loss = 0.00591796 (* 1 = 0.00591796 loss)
I0502 11:27:40.145721 26473 sgd_solver.cpp:106] Iteration 107400, lr = 1.07374e-05
I0502 11:27:41.082064 26473 solver.cpp:362] Iteration 107500, Testing net (#0)
I0502 11:27:41.082093 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:41.206447 26473 solver.cpp:429]     Test net output #0: loss = 0.304771 (* 1 = 0.304771 loss)
I0502 11:27:41.209316 26473 solver.cpp:242] Iteration 107500 (93.5968 iter/s, 1.06841s/100 iter), loss = 0.306507
I0502 11:27:41.209336 26473 solver.cpp:261]     Train net output #0: loss = 0.306507 (* 1 = 0.306507 loss)
I0502 11:27:41.209345 26473 sgd_solver.cpp:106] Iteration 107500, lr = 1.07374e-05
I0502 11:27:41.210963 26473 solver.cpp:362] Iteration 107500, Testing net (#0)
I0502 11:27:41.210976 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:41.341740 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:27:41.341763 26473 solver.cpp:429]     Test net output #1: loss = 0.101271 (* 1 = 0.101271 loss)
I0502 11:27:41.344678 26473 solver.cpp:242] Iteration 107500 (83.4067 iter/s, 1.19894s/100 iter), loss = 0.148365
I0502 11:27:41.344698 26473 solver.cpp:261]     Train net output #0: loss = 0.148365 (* 1 = 0.148365 loss)
I0502 11:27:41.344707 26473 sgd_solver.cpp:106] Iteration 107500, lr = 1.07374e-05
I0502 11:27:42.284077 26473 solver.cpp:242] Iteration 107600 (93.0481 iter/s, 1.07471s/100 iter), loss = 0.041236
I0502 11:27:42.284121 26473 solver.cpp:261]     Train net output #0: loss = 0.041236 (* 1 = 0.041236 loss)
I0502 11:27:42.284132 26473 sgd_solver.cpp:106] Iteration 107600, lr = 1.07374e-05
I0502 11:27:42.288988 26473 solver.cpp:242] Iteration 107600 (105.903 iter/s, 0.944263s/100 iter), loss = 0.150108
I0502 11:27:42.289013 26473 solver.cpp:261]     Train net output #0: loss = 0.150108 (* 1 = 0.150108 loss)
I0502 11:27:42.289021 26473 sgd_solver.cpp:106] Iteration 107600, lr = 1.07374e-05
I0502 11:27:43.228266 26473 solver.cpp:242] Iteration 107700 (105.919 iter/s, 0.944115s/100 iter), loss = 0.115219
I0502 11:27:43.228307 26473 solver.cpp:261]     Train net output #0: loss = 0.115219 (* 1 = 0.115219 loss)
I0502 11:27:43.228317 26473 sgd_solver.cpp:106] Iteration 107700, lr = 1.07374e-05
I0502 11:27:43.233083 26473 solver.cpp:242] Iteration 107700 (105.926 iter/s, 0.944051s/100 iter), loss = 0.143208
I0502 11:27:43.233105 26473 solver.cpp:261]     Train net output #0: loss = 0.143208 (* 1 = 0.143208 loss)
I0502 11:27:43.233114 26473 sgd_solver.cpp:106] Iteration 107700, lr = 1.07374e-05
I0502 11:27:44.172866 26473 solver.cpp:242] Iteration 107800 (105.873 iter/s, 0.944529s/100 iter), loss = 0.300941
I0502 11:27:44.172905 26473 solver.cpp:261]     Train net output #0: loss = 0.300941 (* 1 = 0.300941 loss)
I0502 11:27:44.172914 26473 sgd_solver.cpp:106] Iteration 107800, lr = 1.07374e-05
I0502 11:27:44.177701 26473 solver.cpp:242] Iteration 107800 (105.867 iter/s, 0.944579s/100 iter), loss = 0.086746
I0502 11:27:44.177726 26473 solver.cpp:261]     Train net output #0: loss = 0.086746 (* 1 = 0.086746 loss)
I0502 11:27:44.177734 26473 sgd_solver.cpp:106] Iteration 107800, lr = 1.07374e-05
I0502 11:27:45.117432 26473 solver.cpp:242] Iteration 107900 (105.876 iter/s, 0.9445s/100 iter), loss = 0.0641612
I0502 11:27:45.117470 26473 solver.cpp:261]     Train net output #0: loss = 0.0641612 (* 1 = 0.0641612 loss)
I0502 11:27:45.117486 26473 sgd_solver.cpp:106] Iteration 107900, lr = 1.07374e-05
I0502 11:27:45.122259 26473 solver.cpp:242] Iteration 107900 (105.874 iter/s, 0.944517s/100 iter), loss = 0.0612147
I0502 11:27:45.122283 26473 solver.cpp:261]     Train net output #0: loss = 0.0612147 (* 1 = 0.0612147 loss)
I0502 11:27:45.122292 26473 sgd_solver.cpp:106] Iteration 107900, lr = 1.07374e-05
I0502 11:27:46.059206 26473 solver.cpp:362] Iteration 108000, Testing net (#0)
I0502 11:27:46.059229 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:46.183501 26473 solver.cpp:429]     Test net output #0: loss = 0.305232 (* 1 = 0.305232 loss)
I0502 11:27:46.186378 26473 solver.cpp:242] Iteration 108000 (93.555 iter/s, 1.06889s/100 iter), loss = 0.141221
I0502 11:27:46.186398 26473 solver.cpp:261]     Train net output #0: loss = 0.141221 (* 1 = 0.141221 loss)
I0502 11:27:46.186406 26473 sgd_solver.cpp:106] Iteration 108000, lr = 1.07374e-05
I0502 11:27:46.188025 26473 solver.cpp:362] Iteration 108000, Testing net (#0)
I0502 11:27:46.188037 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:46.318759 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:27:46.318781 26473 solver.cpp:429]     Test net output #1: loss = 0.0988962 (* 1 = 0.0988962 loss)
I0502 11:27:46.321701 26473 solver.cpp:242] Iteration 108000 (83.3752 iter/s, 1.1994s/100 iter), loss = 0.0789133
I0502 11:27:46.321720 26473 solver.cpp:261]     Train net output #0: loss = 0.0789133 (* 1 = 0.0789133 loss)
I0502 11:27:46.321729 26473 sgd_solver.cpp:106] Iteration 108000, lr = 1.07374e-05
I0502 11:27:47.260818 26473 solver.cpp:242] Iteration 108100 (93.0759 iter/s, 1.07439s/100 iter), loss = 0.191795
I0502 11:27:47.260855 26473 solver.cpp:261]     Train net output #0: loss = 0.191795 (* 1 = 0.191795 loss)
I0502 11:27:47.260864 26473 sgd_solver.cpp:106] Iteration 108100, lr = 1.07374e-05
I0502 11:27:47.265681 26473 solver.cpp:242] Iteration 108100 (105.94 iter/s, 0.943933s/100 iter), loss = 0.0615726
I0502 11:27:47.265703 26473 solver.cpp:261]     Train net output #0: loss = 0.0615726 (* 1 = 0.0615726 loss)
I0502 11:27:47.265712 26473 sgd_solver.cpp:106] Iteration 108100, lr = 1.07374e-05
I0502 11:27:48.204712 26473 solver.cpp:242] Iteration 108200 (105.952 iter/s, 0.943827s/100 iter), loss = 0.672921
I0502 11:27:48.204746 26473 solver.cpp:261]     Train net output #0: loss = 0.672921 (* 1 = 0.672921 loss)
I0502 11:27:48.204756 26473 sgd_solver.cpp:106] Iteration 108200, lr = 1.07374e-05
I0502 11:27:48.209517 26473 solver.cpp:242] Iteration 108200 (105.955 iter/s, 0.943795s/100 iter), loss = 0.04562
I0502 11:27:48.209540 26473 solver.cpp:261]     Train net output #0: loss = 0.04562 (* 1 = 0.04562 loss)
I0502 11:27:48.209548 26473 sgd_solver.cpp:106] Iteration 108200, lr = 1.07374e-05
I0502 11:27:49.147680 26473 solver.cpp:242] Iteration 108300 (106.055 iter/s, 0.942905s/100 iter), loss = 0.142374
I0502 11:27:49.147713 26473 solver.cpp:261]     Train net output #0: loss = 0.142374 (* 1 = 0.142374 loss)
I0502 11:27:49.147722 26473 sgd_solver.cpp:106] Iteration 108300, lr = 1.07374e-05
I0502 11:27:49.152498 26473 solver.cpp:242] Iteration 108300 (106.051 iter/s, 0.94294s/100 iter), loss = 0.0525567
I0502 11:27:49.152520 26473 solver.cpp:261]     Train net output #0: loss = 0.0525567 (* 1 = 0.0525567 loss)
I0502 11:27:49.152529 26473 sgd_solver.cpp:106] Iteration 108300, lr = 1.07374e-05
I0502 11:27:50.092299 26473 solver.cpp:242] Iteration 108400 (105.87 iter/s, 0.944557s/100 iter), loss = 0.194956
I0502 11:27:50.092340 26473 solver.cpp:261]     Train net output #0: loss = 0.194956 (* 1 = 0.194956 loss)
I0502 11:27:50.092350 26473 sgd_solver.cpp:106] Iteration 108400, lr = 1.07374e-05
I0502 11:27:50.097116 26473 solver.cpp:242] Iteration 108400 (105.867 iter/s, 0.944578s/100 iter), loss = 0.101945
I0502 11:27:50.097139 26473 solver.cpp:261]     Train net output #0: loss = 0.101945 (* 1 = 0.101945 loss)
I0502 11:27:50.097148 26473 sgd_solver.cpp:106] Iteration 108400, lr = 1.07374e-05
I0502 11:27:51.033278 26473 solver.cpp:362] Iteration 108500, Testing net (#0)
I0502 11:27:51.033319 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:51.157569 26473 solver.cpp:429]     Test net output #0: loss = 0.291851 (* 1 = 0.291851 loss)
I0502 11:27:51.160440 26473 solver.cpp:242] Iteration 108500 (93.6258 iter/s, 1.06808s/100 iter), loss = 0.163881
I0502 11:27:51.160460 26473 solver.cpp:261]     Train net output #0: loss = 0.163881 (* 1 = 0.163881 loss)
I0502 11:27:51.160468 26473 sgd_solver.cpp:106] Iteration 108500, lr = 1.07374e-05
I0502 11:27:51.162091 26473 solver.cpp:362] Iteration 108500, Testing net (#0)
I0502 11:27:51.162104 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:51.292858 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9455
I0502 11:27:51.292891 26473 solver.cpp:429]     Test net output #1: loss = 0.11476 (* 1 = 0.11476 loss)
I0502 11:27:51.295812 26473 solver.cpp:242] Iteration 108500 (83.4271 iter/s, 1.19865s/100 iter), loss = 0.0477253
I0502 11:27:51.295831 26473 solver.cpp:261]     Train net output #0: loss = 0.0477253 (* 1 = 0.0477253 loss)
I0502 11:27:51.295840 26473 sgd_solver.cpp:106] Iteration 108500, lr = 1.07374e-05
I0502 11:27:52.235781 26473 solver.cpp:242] Iteration 108600 (92.9979 iter/s, 1.07529s/100 iter), loss = 0.197428
I0502 11:27:52.235823 26473 solver.cpp:261]     Train net output #0: loss = 0.197428 (* 1 = 0.197428 loss)
I0502 11:27:52.235832 26473 sgd_solver.cpp:106] Iteration 108600, lr = 1.07374e-05
I0502 11:27:52.240669 26473 solver.cpp:242] Iteration 108600 (105.841 iter/s, 0.944809s/100 iter), loss = 0.0261651
I0502 11:27:52.240691 26473 solver.cpp:261]     Train net output #0: loss = 0.0261651 (* 1 = 0.0261651 loss)
I0502 11:27:52.240700 26473 sgd_solver.cpp:106] Iteration 108600, lr = 1.07374e-05
I0502 11:27:53.180178 26473 solver.cpp:242] Iteration 108700 (105.895 iter/s, 0.944332s/100 iter), loss = 0.534824
I0502 11:27:53.180220 26473 solver.cpp:261]     Train net output #0: loss = 0.534824 (* 1 = 0.534824 loss)
I0502 11:27:53.180228 26473 sgd_solver.cpp:106] Iteration 108700, lr = 1.07374e-05
I0502 11:27:53.185055 26473 solver.cpp:242] Iteration 108700 (105.894 iter/s, 0.94434s/100 iter), loss = 0.0294
I0502 11:27:53.185078 26473 solver.cpp:261]     Train net output #0: loss = 0.0294 (* 1 = 0.0294 loss)
I0502 11:27:53.185086 26473 sgd_solver.cpp:106] Iteration 108700, lr = 1.07374e-05
I0502 11:27:54.123818 26473 solver.cpp:242] Iteration 108800 (105.981 iter/s, 0.943568s/100 iter), loss = 0.110731
I0502 11:27:54.123859 26473 solver.cpp:261]     Train net output #0: loss = 0.110731 (* 1 = 0.110731 loss)
I0502 11:27:54.123868 26473 sgd_solver.cpp:106] Iteration 108800, lr = 1.07374e-05
I0502 11:27:54.128682 26473 solver.cpp:242] Iteration 108800 (105.979 iter/s, 0.943586s/100 iter), loss = 0.0333618
I0502 11:27:54.128705 26473 solver.cpp:261]     Train net output #0: loss = 0.0333618 (* 1 = 0.0333618 loss)
I0502 11:27:54.128713 26473 sgd_solver.cpp:106] Iteration 108800, lr = 1.07374e-05
I0502 11:27:55.068330 26473 solver.cpp:242] Iteration 108900 (105.883 iter/s, 0.944439s/100 iter), loss = 0.104315
I0502 11:27:55.068370 26473 solver.cpp:261]     Train net output #0: loss = 0.104315 (* 1 = 0.104315 loss)
I0502 11:27:55.068379 26473 sgd_solver.cpp:106] Iteration 108900, lr = 1.07374e-05
I0502 11:27:55.073174 26473 solver.cpp:242] Iteration 108900 (105.882 iter/s, 0.944452s/100 iter), loss = 0.123318
I0502 11:27:55.073199 26473 solver.cpp:261]     Train net output #0: loss = 0.123318 (* 1 = 0.123318 loss)
I0502 11:27:55.073207 26473 sgd_solver.cpp:106] Iteration 108900, lr = 1.07374e-05
I0502 11:27:56.008931 26473 solver.cpp:362] Iteration 109000, Testing net (#0)
I0502 11:27:56.008954 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:56.133221 26473 solver.cpp:429]     Test net output #0: loss = 0.305646 (* 1 = 0.305646 loss)
I0502 11:27:56.136090 26473 solver.cpp:242] Iteration 109000 (93.6591 iter/s, 1.0677s/100 iter), loss = 0.0331787
I0502 11:27:56.136109 26473 solver.cpp:261]     Train net output #0: loss = 0.0331787 (* 1 = 0.0331787 loss)
I0502 11:27:56.136126 26473 sgd_solver.cpp:106] Iteration 109000, lr = 1.07374e-05
I0502 11:27:56.137755 26473 solver.cpp:362] Iteration 109000, Testing net (#0)
I0502 11:27:56.137768 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:27:56.268296 26473 solver.cpp:429]     Test net output #0: accuracy = 0.953
I0502 11:27:56.268332 26473 solver.cpp:429]     Test net output #1: loss = 0.102831 (* 1 = 0.102831 loss)
I0502 11:27:56.271257 26473 solver.cpp:242] Iteration 109000 (83.4698 iter/s, 1.19804s/100 iter), loss = 0.0531807
I0502 11:27:56.271280 26473 solver.cpp:261]     Train net output #0: loss = 0.0531807 (* 1 = 0.0531807 loss)
I0502 11:27:56.271288 26473 sgd_solver.cpp:106] Iteration 109000, lr = 1.07374e-05
I0502 11:27:57.210898 26473 solver.cpp:242] Iteration 109100 (93.0441 iter/s, 1.07476s/100 iter), loss = 0.658307
I0502 11:27:57.210934 26473 solver.cpp:261]     Train net output #0: loss = 0.658307 (* 1 = 0.658307 loss)
I0502 11:27:57.210943 26473 sgd_solver.cpp:106] Iteration 109100, lr = 1.07374e-05
I0502 11:27:57.215814 26473 solver.cpp:242] Iteration 109100 (105.875 iter/s, 0.944507s/100 iter), loss = 0.00584272
I0502 11:27:57.215837 26473 solver.cpp:261]     Train net output #0: loss = 0.00584272 (* 1 = 0.00584272 loss)
I0502 11:27:57.215847 26473 sgd_solver.cpp:106] Iteration 109100, lr = 1.07374e-05
I0502 11:27:58.155503 26473 solver.cpp:242] Iteration 109200 (105.871 iter/s, 0.944545s/100 iter), loss = 0.342694
I0502 11:27:58.155539 26473 solver.cpp:261]     Train net output #0: loss = 0.342694 (* 1 = 0.342694 loss)
I0502 11:27:58.155547 26473 sgd_solver.cpp:106] Iteration 109200, lr = 1.07374e-05
I0502 11:27:58.160490 26473 solver.cpp:242] Iteration 109200 (105.862 iter/s, 0.944629s/100 iter), loss = 0.268711
I0502 11:27:58.160513 26473 solver.cpp:261]     Train net output #0: loss = 0.268711 (* 1 = 0.268711 loss)
I0502 11:27:58.160521 26473 sgd_solver.cpp:106] Iteration 109200, lr = 1.07374e-05
I0502 11:27:59.101519 26473 solver.cpp:242] Iteration 109300 (105.714 iter/s, 0.945952s/100 iter), loss = 0.0383748
I0502 11:27:59.101557 26473 solver.cpp:261]     Train net output #0: loss = 0.0383748 (* 1 = 0.0383748 loss)
I0502 11:27:59.101567 26473 sgd_solver.cpp:106] Iteration 109300, lr = 1.07374e-05
I0502 11:27:59.106369 26473 solver.cpp:242] Iteration 109300 (105.726 iter/s, 0.945837s/100 iter), loss = 0.0355444
I0502 11:27:59.106390 26473 solver.cpp:261]     Train net output #0: loss = 0.0355444 (* 1 = 0.0355444 loss)
I0502 11:27:59.106400 26473 sgd_solver.cpp:106] Iteration 109300, lr = 1.07374e-05
I0502 11:28:00.046351 26473 solver.cpp:242] Iteration 109400 (105.846 iter/s, 0.944767s/100 iter), loss = 0.10053
I0502 11:28:00.046382 26473 solver.cpp:261]     Train net output #0: loss = 0.10053 (* 1 = 0.10053 loss)
I0502 11:28:00.046391 26473 sgd_solver.cpp:106] Iteration 109400, lr = 1.07374e-05
I0502 11:28:00.051259 26473 solver.cpp:242] Iteration 109400 (105.837 iter/s, 0.944851s/100 iter), loss = 0.0617571
I0502 11:28:00.051281 26473 solver.cpp:261]     Train net output #0: loss = 0.0617571 (* 1 = 0.0617571 loss)
I0502 11:28:00.051290 26473 sgd_solver.cpp:106] Iteration 109400, lr = 1.07374e-05
I0502 11:28:00.999083 26473 solver.cpp:362] Iteration 109500, Testing net (#0)
I0502 11:28:00.999114 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:01.123549 26473 solver.cpp:429]     Test net output #0: loss = 0.254299 (* 1 = 0.254299 loss)
I0502 11:28:01.126436 26473 solver.cpp:242] Iteration 109500 (92.5896 iter/s, 1.08004s/100 iter), loss = 0.111608
I0502 11:28:01.126457 26473 solver.cpp:261]     Train net output #0: loss = 0.111608 (* 1 = 0.111608 loss)
I0502 11:28:01.126466 26473 sgd_solver.cpp:106] Iteration 109500, lr = 1.07374e-05
I0502 11:28:01.128090 26473 solver.cpp:362] Iteration 109500, Testing net (#0)
I0502 11:28:01.128103 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:01.258673 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:28:01.258693 26473 solver.cpp:429]     Test net output #1: loss = 0.0818476 (* 1 = 0.0818476 loss)
I0502 11:28:01.261623 26473 solver.cpp:242] Iteration 109500 (82.6228 iter/s, 1.21032s/100 iter), loss = 0.177959
I0502 11:28:01.261643 26473 solver.cpp:261]     Train net output #0: loss = 0.177959 (* 1 = 0.177959 loss)
I0502 11:28:01.261651 26473 sgd_solver.cpp:106] Iteration 109500, lr = 1.07374e-05
I0502 11:28:02.201551 26473 solver.cpp:242] Iteration 109600 (93.0175 iter/s, 1.07507s/100 iter), loss = 0.147292
I0502 11:28:02.201583 26473 solver.cpp:261]     Train net output #0: loss = 0.147292 (* 1 = 0.147292 loss)
I0502 11:28:02.201591 26473 sgd_solver.cpp:106] Iteration 109600, lr = 1.07374e-05
I0502 11:28:02.206347 26473 solver.cpp:242] Iteration 109600 (105.855 iter/s, 0.944685s/100 iter), loss = 0.0806019
I0502 11:28:02.206370 26473 solver.cpp:261]     Train net output #0: loss = 0.0806019 (* 1 = 0.0806019 loss)
I0502 11:28:02.206379 26473 sgd_solver.cpp:106] Iteration 109600, lr = 1.07374e-05
I0502 11:28:03.145052 26473 solver.cpp:242] Iteration 109700 (105.995 iter/s, 0.943444s/100 iter), loss = 0.208817
I0502 11:28:03.145094 26473 solver.cpp:261]     Train net output #0: loss = 0.208817 (* 1 = 0.208817 loss)
I0502 11:28:03.145103 26473 sgd_solver.cpp:106] Iteration 109700, lr = 1.07374e-05
I0502 11:28:03.149919 26473 solver.cpp:242] Iteration 109700 (105.986 iter/s, 0.943522s/100 iter), loss = 0.0937995
I0502 11:28:03.149941 26473 solver.cpp:261]     Train net output #0: loss = 0.0937995 (* 1 = 0.0937995 loss)
I0502 11:28:03.149950 26473 sgd_solver.cpp:106] Iteration 109700, lr = 1.07374e-05
I0502 11:28:04.109576 26473 solver.cpp:242] Iteration 109800 (103.686 iter/s, 0.96445s/100 iter), loss = 0.134305
I0502 11:28:04.109621 26473 solver.cpp:261]     Train net output #0: loss = 0.134305 (* 1 = 0.134305 loss)
I0502 11:28:04.109630 26473 sgd_solver.cpp:106] Iteration 109800, lr = 1.07374e-05
I0502 11:28:04.114429 26473 solver.cpp:242] Iteration 109800 (103.684 iter/s, 0.96447s/100 iter), loss = 0.0220775
I0502 11:28:04.114452 26473 solver.cpp:261]     Train net output #0: loss = 0.0220775 (* 1 = 0.0220775 loss)
I0502 11:28:04.114461 26473 sgd_solver.cpp:106] Iteration 109800, lr = 1.07374e-05
I0502 11:28:05.053511 26473 solver.cpp:242] Iteration 109900 (105.948 iter/s, 0.943862s/100 iter), loss = 0.622429
I0502 11:28:05.053555 26473 solver.cpp:261]     Train net output #0: loss = 0.622429 (* 1 = 0.622429 loss)
I0502 11:28:05.053563 26473 sgd_solver.cpp:106] Iteration 109900, lr = 1.07374e-05
I0502 11:28:05.058305 26473 solver.cpp:242] Iteration 109900 (105.951 iter/s, 0.943835s/100 iter), loss = 0.0609627
I0502 11:28:05.058329 26473 solver.cpp:261]     Train net output #0: loss = 0.0609627 (* 1 = 0.0609627 loss)
I0502 11:28:05.058337 26473 sgd_solver.cpp:106] Iteration 109900, lr = 1.07374e-05
I0502 11:28:05.994601 26473 solver.cpp:362] Iteration 110000, Testing net (#0)
I0502 11:28:05.994632 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:06.119010 26473 solver.cpp:429]     Test net output #0: loss = 0.321125 (* 1 = 0.321125 loss)
I0502 11:28:06.121882 26473 solver.cpp:242] Iteration 110000 (93.6058 iter/s, 1.06831s/100 iter), loss = 0.105
I0502 11:28:06.121903 26473 solver.cpp:261]     Train net output #0: loss = 0.105 (* 1 = 0.105 loss)
I0502 11:28:06.121912 26473 sgd_solver.cpp:106] Iteration 110000, lr = 8.58994e-06
I0502 11:28:06.123530 26473 solver.cpp:362] Iteration 110000, Testing net (#0)
I0502 11:28:06.123543 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:06.254612 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:28:06.254642 26473 solver.cpp:429]     Test net output #1: loss = 0.0976905 (* 1 = 0.0976905 loss)
I0502 11:28:06.257571 26473 solver.cpp:242] Iteration 110000 (83.3875 iter/s, 1.19922s/100 iter), loss = 0.0460423
I0502 11:28:06.257592 26473 solver.cpp:261]     Train net output #0: loss = 0.0460423 (* 1 = 0.0460423 loss)
I0502 11:28:06.257601 26473 sgd_solver.cpp:106] Iteration 110000, lr = 8.58994e-06
I0502 11:28:07.196764 26473 solver.cpp:242] Iteration 110100 (93.0378 iter/s, 1.07483s/100 iter), loss = 0.0225163
I0502 11:28:07.196815 26473 solver.cpp:261]     Train net output #0: loss = 0.0225163 (* 1 = 0.0225163 loss)
I0502 11:28:07.196825 26473 sgd_solver.cpp:106] Iteration 110100, lr = 8.58994e-06
I0502 11:28:07.201623 26473 solver.cpp:242] Iteration 110100 (105.931 iter/s, 0.944012s/100 iter), loss = 0.100754
I0502 11:28:07.201648 26473 solver.cpp:261]     Train net output #0: loss = 0.100754 (* 1 = 0.100754 loss)
I0502 11:28:07.201656 26473 sgd_solver.cpp:106] Iteration 110100, lr = 8.58994e-06
I0502 11:28:08.140955 26473 solver.cpp:242] Iteration 110200 (105.919 iter/s, 0.944115s/100 iter), loss = 0.114598
I0502 11:28:08.140995 26473 solver.cpp:261]     Train net output #0: loss = 0.114598 (* 1 = 0.114598 loss)
I0502 11:28:08.141005 26473 sgd_solver.cpp:106] Iteration 110200, lr = 8.58994e-06
I0502 11:28:08.145825 26473 solver.cpp:242] Iteration 110200 (105.915 iter/s, 0.944152s/100 iter), loss = 0.0671194
I0502 11:28:08.145849 26473 solver.cpp:261]     Train net output #0: loss = 0.0671194 (* 1 = 0.0671194 loss)
I0502 11:28:08.145859 26473 sgd_solver.cpp:106] Iteration 110200, lr = 8.58994e-06
I0502 11:28:09.085532 26473 solver.cpp:242] Iteration 110300 (105.875 iter/s, 0.944507s/100 iter), loss = 0.331815
I0502 11:28:09.085571 26473 solver.cpp:261]     Train net output #0: loss = 0.331815 (* 1 = 0.331815 loss)
I0502 11:28:09.085579 26473 sgd_solver.cpp:106] Iteration 110300, lr = 8.58994e-06
I0502 11:28:09.090324 26473 solver.cpp:242] Iteration 110300 (105.881 iter/s, 0.944457s/100 iter), loss = 0.303516
I0502 11:28:09.090348 26473 solver.cpp:261]     Train net output #0: loss = 0.303516 (* 1 = 0.303516 loss)
I0502 11:28:09.090355 26473 sgd_solver.cpp:106] Iteration 110300, lr = 8.58994e-06
I0502 11:28:10.029580 26473 solver.cpp:242] Iteration 110400 (105.934 iter/s, 0.943981s/100 iter), loss = 0.109016
I0502 11:28:10.029619 26473 solver.cpp:261]     Train net output #0: loss = 0.109016 (* 1 = 0.109016 loss)
I0502 11:28:10.029628 26473 sgd_solver.cpp:106] Iteration 110400, lr = 8.58994e-06
I0502 11:28:10.034478 26473 solver.cpp:242] Iteration 110400 (105.919 iter/s, 0.944113s/100 iter), loss = 0.0566457
I0502 11:28:10.034502 26473 solver.cpp:261]     Train net output #0: loss = 0.0566457 (* 1 = 0.0566457 loss)
I0502 11:28:10.034509 26473 sgd_solver.cpp:106] Iteration 110400, lr = 8.58994e-06
I0502 11:28:10.970485 26473 solver.cpp:362] Iteration 110500, Testing net (#0)
I0502 11:28:10.970505 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:11.094816 26473 solver.cpp:429]     Test net output #0: loss = 0.249389 (* 1 = 0.249389 loss)
I0502 11:28:11.097687 26473 solver.cpp:242] Iteration 110500 (93.6286 iter/s, 1.06805s/100 iter), loss = 0.181217
I0502 11:28:11.097707 26473 solver.cpp:261]     Train net output #0: loss = 0.181217 (* 1 = 0.181217 loss)
I0502 11:28:11.097717 26473 sgd_solver.cpp:106] Iteration 110500, lr = 8.58994e-06
I0502 11:28:11.099328 26473 solver.cpp:362] Iteration 110500, Testing net (#0)
I0502 11:28:11.099340 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:11.229939 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:28:11.229960 26473 solver.cpp:429]     Test net output #1: loss = 0.0874404 (* 1 = 0.0874404 loss)
I0502 11:28:11.232888 26473 solver.cpp:242] Iteration 110500 (83.447 iter/s, 1.19837s/100 iter), loss = 0.155972
I0502 11:28:11.232908 26473 solver.cpp:261]     Train net output #0: loss = 0.155972 (* 1 = 0.155972 loss)
I0502 11:28:11.232918 26473 sgd_solver.cpp:106] Iteration 110500, lr = 8.58994e-06
I0502 11:28:12.171551 26473 solver.cpp:242] Iteration 110600 (93.1258 iter/s, 1.07382s/100 iter), loss = 1.09672
I0502 11:28:12.171583 26473 solver.cpp:261]     Train net output #0: loss = 1.09672 (* 1 = 1.09672 loss)
I0502 11:28:12.171593 26473 sgd_solver.cpp:106] Iteration 110600, lr = 8.58994e-06
I0502 11:28:12.176372 26473 solver.cpp:242] Iteration 110600 (105.995 iter/s, 0.943444s/100 iter), loss = 0.126337
I0502 11:28:12.176393 26473 solver.cpp:261]     Train net output #0: loss = 0.126337 (* 1 = 0.126337 loss)
I0502 11:28:12.176409 26473 sgd_solver.cpp:106] Iteration 110600, lr = 8.58994e-06
I0502 11:28:13.115227 26473 solver.cpp:242] Iteration 110700 (105.975 iter/s, 0.943619s/100 iter), loss = 0.146941
I0502 11:28:13.115270 26473 solver.cpp:261]     Train net output #0: loss = 0.146941 (* 1 = 0.146941 loss)
I0502 11:28:13.115279 26473 sgd_solver.cpp:106] Iteration 110700, lr = 8.58994e-06
I0502 11:28:13.120151 26473 solver.cpp:242] Iteration 110700 (105.962 iter/s, 0.943732s/100 iter), loss = 0.0240022
I0502 11:28:13.120175 26473 solver.cpp:261]     Train net output #0: loss = 0.0240022 (* 1 = 0.0240022 loss)
I0502 11:28:13.120183 26473 sgd_solver.cpp:106] Iteration 110700, lr = 8.58994e-06
I0502 11:28:14.059569 26473 solver.cpp:242] Iteration 110800 (105.902 iter/s, 0.944268s/100 iter), loss = 1.14224
I0502 11:28:14.059613 26473 solver.cpp:261]     Train net output #0: loss = 1.14224 (* 1 = 1.14224 loss)
I0502 11:28:14.059623 26473 sgd_solver.cpp:106] Iteration 110800, lr = 8.58994e-06
I0502 11:28:14.064385 26473 solver.cpp:242] Iteration 110800 (105.911 iter/s, 0.944193s/100 iter), loss = 0.280364
I0502 11:28:14.064409 26473 solver.cpp:261]     Train net output #0: loss = 0.280364 (* 1 = 0.280364 loss)
I0502 11:28:14.064417 26473 sgd_solver.cpp:106] Iteration 110800, lr = 8.58994e-06
I0502 11:28:15.003110 26473 solver.cpp:242] Iteration 110900 (105.992 iter/s, 0.943469s/100 iter), loss = 0.0870334
I0502 11:28:15.003155 26473 solver.cpp:261]     Train net output #0: loss = 0.0870334 (* 1 = 0.0870334 loss)
I0502 11:28:15.003165 26473 sgd_solver.cpp:106] Iteration 110900, lr = 8.58994e-06
I0502 11:28:15.007910 26473 solver.cpp:242] Iteration 110900 (105.99 iter/s, 0.943484s/100 iter), loss = 0.0473489
I0502 11:28:15.007933 26473 solver.cpp:261]     Train net output #0: loss = 0.0473489 (* 1 = 0.0473489 loss)
I0502 11:28:15.007941 26473 sgd_solver.cpp:106] Iteration 110900, lr = 8.58994e-06
I0502 11:28:15.944516 26473 solver.cpp:362] Iteration 111000, Testing net (#0)
I0502 11:28:15.944553 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:16.068755 26473 solver.cpp:429]     Test net output #0: loss = 0.248972 (* 1 = 0.248972 loss)
I0502 11:28:16.071626 26473 solver.cpp:242] Iteration 111000 (93.5933 iter/s, 1.06845s/100 iter), loss = 0.0541176
I0502 11:28:16.071647 26473 solver.cpp:261]     Train net output #0: loss = 0.0541176 (* 1 = 0.0541176 loss)
I0502 11:28:16.071655 26473 sgd_solver.cpp:106] Iteration 111000, lr = 8.58994e-06
I0502 11:28:16.073338 26473 solver.cpp:362] Iteration 111000, Testing net (#0)
I0502 11:28:16.073351 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:16.204151 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:28:16.204171 26473 solver.cpp:429]     Test net output #1: loss = 0.0863271 (* 1 = 0.0863271 loss)
I0502 11:28:16.207089 26473 solver.cpp:242] Iteration 111000 (83.3935 iter/s, 1.19913s/100 iter), loss = 0.0193526
I0502 11:28:16.207109 26473 solver.cpp:261]     Train net output #0: loss = 0.0193526 (* 1 = 0.0193526 loss)
I0502 11:28:16.207118 26473 sgd_solver.cpp:106] Iteration 111000, lr = 8.58994e-06
I0502 11:28:17.146211 26473 solver.cpp:242] Iteration 111100 (93.0636 iter/s, 1.07453s/100 iter), loss = 0.287624
I0502 11:28:17.146267 26473 solver.cpp:261]     Train net output #0: loss = 0.287624 (* 1 = 0.287624 loss)
I0502 11:28:17.146276 26473 sgd_solver.cpp:106] Iteration 111100, lr = 8.58994e-06
I0502 11:28:17.151082 26473 solver.cpp:242] Iteration 111100 (105.937 iter/s, 0.943954s/100 iter), loss = 0.0441917
I0502 11:28:17.151106 26473 solver.cpp:261]     Train net output #0: loss = 0.0441917 (* 1 = 0.0441917 loss)
I0502 11:28:17.151114 26473 sgd_solver.cpp:106] Iteration 111100, lr = 8.58994e-06
I0502 11:28:18.090956 26473 solver.cpp:242] Iteration 111200 (105.858 iter/s, 0.944665s/100 iter), loss = 0.39896
I0502 11:28:18.090998 26473 solver.cpp:261]     Train net output #0: loss = 0.39896 (* 1 = 0.39896 loss)
I0502 11:28:18.091007 26473 sgd_solver.cpp:106] Iteration 111200, lr = 8.58994e-06
I0502 11:28:18.095844 26473 solver.cpp:242] Iteration 111200 (105.853 iter/s, 0.944711s/100 iter), loss = 0.203992
I0502 11:28:18.095875 26473 solver.cpp:261]     Train net output #0: loss = 0.203992 (* 1 = 0.203992 loss)
I0502 11:28:18.095883 26473 sgd_solver.cpp:106] Iteration 111200, lr = 8.58994e-06
I0502 11:28:19.035280 26473 solver.cpp:242] Iteration 111300 (105.904 iter/s, 0.944252s/100 iter), loss = 0.144968
I0502 11:28:19.035320 26473 solver.cpp:261]     Train net output #0: loss = 0.144968 (* 1 = 0.144968 loss)
I0502 11:28:19.035329 26473 sgd_solver.cpp:106] Iteration 111300, lr = 8.58994e-06
I0502 11:28:19.040107 26473 solver.cpp:242] Iteration 111300 (105.908 iter/s, 0.944215s/100 iter), loss = 0.0394609
I0502 11:28:19.040129 26473 solver.cpp:261]     Train net output #0: loss = 0.0394609 (* 1 = 0.0394609 loss)
I0502 11:28:19.040138 26473 sgd_solver.cpp:106] Iteration 111300, lr = 8.58994e-06
I0502 11:28:19.980651 26473 solver.cpp:242] Iteration 111400 (105.786 iter/s, 0.945301s/100 iter), loss = 0.151081
I0502 11:28:19.980691 26473 solver.cpp:261]     Train net output #0: loss = 0.151081 (* 1 = 0.151081 loss)
I0502 11:28:19.980700 26473 sgd_solver.cpp:106] Iteration 111400, lr = 8.58994e-06
I0502 11:28:19.985509 26473 solver.cpp:242] Iteration 111400 (105.779 iter/s, 0.945363s/100 iter), loss = 0.0799001
I0502 11:28:19.985532 26473 solver.cpp:261]     Train net output #0: loss = 0.0799001 (* 1 = 0.0799001 loss)
I0502 11:28:19.985541 26473 sgd_solver.cpp:106] Iteration 111400, lr = 8.58994e-06
I0502 11:28:20.920884 26473 solver.cpp:362] Iteration 111500, Testing net (#0)
I0502 11:28:20.920910 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:21.045128 26473 solver.cpp:429]     Test net output #0: loss = 0.219968 (* 1 = 0.219968 loss)
I0502 11:28:21.048003 26473 solver.cpp:242] Iteration 111500 (93.6948 iter/s, 1.06729s/100 iter), loss = 0.0986508
I0502 11:28:21.048023 26473 solver.cpp:261]     Train net output #0: loss = 0.0986508 (* 1 = 0.0986508 loss)
I0502 11:28:21.048032 26473 sgd_solver.cpp:106] Iteration 111500, lr = 8.58994e-06
I0502 11:28:21.049681 26473 solver.cpp:362] Iteration 111500, Testing net (#0)
I0502 11:28:21.049695 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:21.180418 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9615
I0502 11:28:21.180438 26473 solver.cpp:429]     Test net output #1: loss = 0.0885031 (* 1 = 0.0885031 loss)
I0502 11:28:21.183347 26473 solver.cpp:242] Iteration 111500 (83.4869 iter/s, 1.19779s/100 iter), loss = 0.162336
I0502 11:28:21.183367 26473 solver.cpp:261]     Train net output #0: loss = 0.162336 (* 1 = 0.162336 loss)
I0502 11:28:21.183375 26473 sgd_solver.cpp:106] Iteration 111500, lr = 8.58994e-06
I0502 11:28:22.122179 26473 solver.cpp:242] Iteration 111600 (93.0989 iter/s, 1.07413s/100 iter), loss = 0.361794
I0502 11:28:22.122217 26473 solver.cpp:261]     Train net output #0: loss = 0.361794 (* 1 = 0.361794 loss)
I0502 11:28:22.122226 26473 sgd_solver.cpp:106] Iteration 111600, lr = 8.58994e-06
I0502 11:28:22.126999 26473 solver.cpp:242] Iteration 111600 (105.976 iter/s, 0.943614s/100 iter), loss = 0.158682
I0502 11:28:22.127023 26473 solver.cpp:261]     Train net output #0: loss = 0.158682 (* 1 = 0.158682 loss)
I0502 11:28:22.127032 26473 sgd_solver.cpp:106] Iteration 111600, lr = 8.58994e-06
I0502 11:28:23.066644 26473 solver.cpp:242] Iteration 111700 (105.887 iter/s, 0.944402s/100 iter), loss = 0.0706049
I0502 11:28:23.066682 26473 solver.cpp:261]     Train net output #0: loss = 0.0706049 (* 1 = 0.0706049 loss)
I0502 11:28:23.066691 26473 sgd_solver.cpp:106] Iteration 111700, lr = 8.58994e-06
I0502 11:28:23.071516 26473 solver.cpp:242] Iteration 111700 (105.88 iter/s, 0.944466s/100 iter), loss = 0.113544
I0502 11:28:23.071539 26473 solver.cpp:261]     Train net output #0: loss = 0.113544 (* 1 = 0.113544 loss)
I0502 11:28:23.071548 26473 sgd_solver.cpp:106] Iteration 111700, lr = 8.58994e-06
I0502 11:28:24.009680 26473 solver.cpp:242] Iteration 111800 (106.047 iter/s, 0.942976s/100 iter), loss = 0.313318
I0502 11:28:24.009711 26473 solver.cpp:261]     Train net output #0: loss = 0.313318 (* 1 = 0.313318 loss)
I0502 11:28:24.009727 26473 sgd_solver.cpp:106] Iteration 111800, lr = 8.58994e-06
I0502 11:28:24.014539 26473 solver.cpp:242] Iteration 111800 (106.047 iter/s, 0.942976s/100 iter), loss = 0.0137827
I0502 11:28:24.014562 26473 solver.cpp:261]     Train net output #0: loss = 0.0137827 (* 1 = 0.0137827 loss)
I0502 11:28:24.014571 26473 sgd_solver.cpp:106] Iteration 111800, lr = 8.58994e-06
I0502 11:28:24.953521 26473 solver.cpp:242] Iteration 111900 (105.957 iter/s, 0.943779s/100 iter), loss = 0.158193
I0502 11:28:24.953564 26473 solver.cpp:261]     Train net output #0: loss = 0.158193 (* 1 = 0.158193 loss)
I0502 11:28:24.953572 26473 sgd_solver.cpp:106] Iteration 111900, lr = 8.58994e-06
I0502 11:28:24.958349 26473 solver.cpp:242] Iteration 111900 (105.958 iter/s, 0.943769s/100 iter), loss = 0.0989672
I0502 11:28:24.958372 26473 solver.cpp:261]     Train net output #0: loss = 0.0989672 (* 1 = 0.0989672 loss)
I0502 11:28:24.958380 26473 sgd_solver.cpp:106] Iteration 111900, lr = 8.58994e-06
I0502 11:28:25.894618 26473 solver.cpp:362] Iteration 112000, Testing net (#0)
I0502 11:28:25.894647 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:26.019024 26473 solver.cpp:429]     Test net output #0: loss = 0.229058 (* 1 = 0.229058 loss)
I0502 11:28:26.021886 26473 solver.cpp:242] Iteration 112000 (93.6064 iter/s, 1.0683s/100 iter), loss = 0.0456016
I0502 11:28:26.021906 26473 solver.cpp:261]     Train net output #0: loss = 0.0456016 (* 1 = 0.0456016 loss)
I0502 11:28:26.021915 26473 sgd_solver.cpp:106] Iteration 112000, lr = 8.58994e-06
I0502 11:28:26.023532 26473 solver.cpp:362] Iteration 112000, Testing net (#0)
I0502 11:28:26.023545 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:26.154423 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:28:26.154443 26473 solver.cpp:429]     Test net output #1: loss = 0.081369 (* 1 = 0.081369 loss)
I0502 11:28:26.157368 26473 solver.cpp:242] Iteration 112000 (83.4045 iter/s, 1.19898s/100 iter), loss = 0.321106
I0502 11:28:26.157388 26473 solver.cpp:261]     Train net output #0: loss = 0.321106 (* 1 = 0.321106 loss)
I0502 11:28:26.157397 26473 sgd_solver.cpp:106] Iteration 112000, lr = 8.58994e-06
I0502 11:28:27.097201 26473 solver.cpp:242] Iteration 112100 (93.0002 iter/s, 1.07527s/100 iter), loss = 0.0448224
I0502 11:28:27.097235 26473 solver.cpp:261]     Train net output #0: loss = 0.0448224 (* 1 = 0.0448224 loss)
I0502 11:28:27.097244 26473 sgd_solver.cpp:106] Iteration 112100, lr = 8.58994e-06
I0502 11:28:27.102004 26473 solver.cpp:242] Iteration 112100 (105.865 iter/s, 0.944597s/100 iter), loss = 0.061837
I0502 11:28:27.102025 26473 solver.cpp:261]     Train net output #0: loss = 0.061837 (* 1 = 0.061837 loss)
I0502 11:28:27.102035 26473 sgd_solver.cpp:106] Iteration 112100, lr = 8.58994e-06
I0502 11:28:28.041851 26473 solver.cpp:242] Iteration 112200 (105.866 iter/s, 0.944589s/100 iter), loss = 0.322594
I0502 11:28:28.041906 26473 solver.cpp:261]     Train net output #0: loss = 0.322594 (* 1 = 0.322594 loss)
I0502 11:28:28.041915 26473 sgd_solver.cpp:106] Iteration 112200, lr = 8.58994e-06
I0502 11:28:28.046720 26473 solver.cpp:242] Iteration 112200 (105.856 iter/s, 0.944677s/100 iter), loss = 0.125512
I0502 11:28:28.046744 26473 solver.cpp:261]     Train net output #0: loss = 0.125512 (* 1 = 0.125512 loss)
I0502 11:28:28.046752 26473 sgd_solver.cpp:106] Iteration 112200, lr = 8.58994e-06
I0502 11:28:28.985679 26473 solver.cpp:242] Iteration 112300 (105.96 iter/s, 0.943749s/100 iter), loss = 0.276817
I0502 11:28:28.985721 26473 solver.cpp:261]     Train net output #0: loss = 0.276817 (* 1 = 0.276817 loss)
I0502 11:28:28.985730 26473 sgd_solver.cpp:106] Iteration 112300, lr = 8.58994e-06
I0502 11:28:28.990537 26473 solver.cpp:242] Iteration 112300 (105.958 iter/s, 0.943767s/100 iter), loss = 0.070809
I0502 11:28:28.990561 26473 solver.cpp:261]     Train net output #0: loss = 0.070809 (* 1 = 0.070809 loss)
I0502 11:28:28.990569 26473 sgd_solver.cpp:106] Iteration 112300, lr = 8.58994e-06
I0502 11:28:29.930179 26473 solver.cpp:242] Iteration 112400 (105.884 iter/s, 0.944427s/100 iter), loss = 0.151762
I0502 11:28:29.930222 26473 solver.cpp:261]     Train net output #0: loss = 0.151762 (* 1 = 0.151762 loss)
I0502 11:28:29.930230 26473 sgd_solver.cpp:106] Iteration 112400, lr = 8.58994e-06
I0502 11:28:29.934985 26473 solver.cpp:242] Iteration 112400 (105.887 iter/s, 0.944406s/100 iter), loss = 0.109479
I0502 11:28:29.935009 26473 solver.cpp:261]     Train net output #0: loss = 0.109479 (* 1 = 0.109479 loss)
I0502 11:28:29.935016 26473 sgd_solver.cpp:106] Iteration 112400, lr = 8.58994e-06
I0502 11:28:30.870440 26473 solver.cpp:362] Iteration 112500, Testing net (#0)
I0502 11:28:30.870466 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:30.994818 26473 solver.cpp:429]     Test net output #0: loss = 0.233306 (* 1 = 0.233306 loss)
I0502 11:28:30.997684 26473 solver.cpp:242] Iteration 112500 (93.6818 iter/s, 1.06744s/100 iter), loss = 0.155385
I0502 11:28:30.997704 26473 solver.cpp:261]     Train net output #0: loss = 0.155385 (* 1 = 0.155385 loss)
I0502 11:28:30.997711 26473 sgd_solver.cpp:106] Iteration 112500, lr = 8.58994e-06
I0502 11:28:30.999322 26473 solver.cpp:362] Iteration 112500, Testing net (#0)
I0502 11:28:30.999336 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:31.130091 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:28:31.130113 26473 solver.cpp:429]     Test net output #1: loss = 0.0862498 (* 1 = 0.0862498 loss)
I0502 11:28:31.133038 26473 solver.cpp:242] Iteration 112500 (83.4718 iter/s, 1.19801s/100 iter), loss = 0.0642021
I0502 11:28:31.133059 26473 solver.cpp:261]     Train net output #0: loss = 0.0642021 (* 1 = 0.0642021 loss)
I0502 11:28:31.133067 26473 sgd_solver.cpp:106] Iteration 112500, lr = 8.58994e-06
I0502 11:28:32.072491 26473 solver.cpp:242] Iteration 112600 (93.0443 iter/s, 1.07476s/100 iter), loss = 0.140511
I0502 11:28:32.072531 26473 solver.cpp:261]     Train net output #0: loss = 0.140511 (* 1 = 0.140511 loss)
I0502 11:28:32.072540 26473 sgd_solver.cpp:106] Iteration 112600, lr = 8.58994e-06
I0502 11:28:32.077339 26473 solver.cpp:242] Iteration 112600 (105.903 iter/s, 0.944261s/100 iter), loss = 0.109143
I0502 11:28:32.077363 26473 solver.cpp:261]     Train net output #0: loss = 0.109143 (* 1 = 0.109143 loss)
I0502 11:28:32.077370 26473 sgd_solver.cpp:106] Iteration 112600, lr = 8.58994e-06
I0502 11:28:33.016135 26473 solver.cpp:242] Iteration 112700 (105.979 iter/s, 0.943579s/100 iter), loss = 0.154094
I0502 11:28:33.016170 26473 solver.cpp:261]     Train net output #0: loss = 0.154094 (* 1 = 0.154094 loss)
I0502 11:28:33.016180 26473 sgd_solver.cpp:106] Iteration 112700, lr = 8.58994e-06
I0502 11:28:33.020978 26473 solver.cpp:242] Iteration 112700 (105.977 iter/s, 0.943598s/100 iter), loss = 0.0967928
I0502 11:28:33.021000 26473 solver.cpp:261]     Train net output #0: loss = 0.0967928 (* 1 = 0.0967928 loss)
I0502 11:28:33.021009 26473 sgd_solver.cpp:106] Iteration 112700, lr = 8.58994e-06
I0502 11:28:33.960719 26473 solver.cpp:242] Iteration 112800 (105.873 iter/s, 0.944526s/100 iter), loss = 0.123475
I0502 11:28:33.960753 26473 solver.cpp:261]     Train net output #0: loss = 0.123475 (* 1 = 0.123475 loss)
I0502 11:28:33.960762 26473 sgd_solver.cpp:106] Iteration 112800, lr = 8.58994e-06
I0502 11:28:33.965597 26473 solver.cpp:242] Iteration 112800 (105.868 iter/s, 0.944571s/100 iter), loss = 0.0294571
I0502 11:28:33.965620 26473 solver.cpp:261]     Train net output #0: loss = 0.0294571 (* 1 = 0.0294571 loss)
I0502 11:28:33.965629 26473 sgd_solver.cpp:106] Iteration 112800, lr = 8.58994e-06
I0502 11:28:34.905351 26473 solver.cpp:242] Iteration 112900 (105.868 iter/s, 0.944568s/100 iter), loss = 0.215688
I0502 11:28:34.905385 26473 solver.cpp:261]     Train net output #0: loss = 0.215688 (* 1 = 0.215688 loss)
I0502 11:28:34.905393 26473 sgd_solver.cpp:106] Iteration 112900, lr = 8.58994e-06
I0502 11:28:34.910177 26473 solver.cpp:242] Iteration 112900 (105.872 iter/s, 0.944539s/100 iter), loss = 0.0158755
I0502 11:28:34.910209 26473 solver.cpp:261]     Train net output #0: loss = 0.0158755 (* 1 = 0.0158755 loss)
I0502 11:28:34.910218 26473 sgd_solver.cpp:106] Iteration 112900, lr = 8.58994e-06
I0502 11:28:35.845785 26473 solver.cpp:362] Iteration 113000, Testing net (#0)
I0502 11:28:35.845815 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:35.970046 26473 solver.cpp:429]     Test net output #0: loss = 0.24772 (* 1 = 0.24772 loss)
I0502 11:28:35.972932 26473 solver.cpp:242] Iteration 113000 (93.6743 iter/s, 1.06753s/100 iter), loss = 0.593395
I0502 11:28:35.972952 26473 solver.cpp:261]     Train net output #0: loss = 0.593395 (* 1 = 0.593395 loss)
I0502 11:28:35.972960 26473 sgd_solver.cpp:106] Iteration 113000, lr = 8.58994e-06
I0502 11:28:35.974577 26473 solver.cpp:362] Iteration 113000, Testing net (#0)
I0502 11:28:35.974591 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:36.105197 26473 solver.cpp:429]     Test net output #0: accuracy = 0.958
I0502 11:28:36.105217 26473 solver.cpp:429]     Test net output #1: loss = 0.0881906 (* 1 = 0.0881906 loss)
I0502 11:28:36.108134 26473 solver.cpp:242] Iteration 113000 (83.4792 iter/s, 1.1979s/100 iter), loss = 0.0466253
I0502 11:28:36.108152 26473 solver.cpp:261]     Train net output #0: loss = 0.0466253 (* 1 = 0.0466253 loss)
I0502 11:28:36.108160 26473 sgd_solver.cpp:106] Iteration 113000, lr = 8.58994e-06
I0502 11:28:37.047475 26473 solver.cpp:242] Iteration 113100 (93.0672 iter/s, 1.07449s/100 iter), loss = 0.046532
I0502 11:28:37.047515 26473 solver.cpp:261]     Train net output #0: loss = 0.046532 (* 1 = 0.046532 loss)
I0502 11:28:37.047524 26473 sgd_solver.cpp:106] Iteration 113100, lr = 8.58994e-06
I0502 11:28:37.052284 26473 solver.cpp:242] Iteration 113100 (105.919 iter/s, 0.944114s/100 iter), loss = 0.0498201
I0502 11:28:37.052309 26473 solver.cpp:261]     Train net output #0: loss = 0.0498201 (* 1 = 0.0498201 loss)
I0502 11:28:37.052317 26473 sgd_solver.cpp:106] Iteration 113100, lr = 8.58994e-06
I0502 11:28:37.991566 26473 solver.cpp:242] Iteration 113200 (105.929 iter/s, 0.944029s/100 iter), loss = 0.0695359
I0502 11:28:37.991597 26473 solver.cpp:261]     Train net output #0: loss = 0.0695359 (* 1 = 0.0695359 loss)
I0502 11:28:37.991606 26473 sgd_solver.cpp:106] Iteration 113200, lr = 8.58994e-06
I0502 11:28:37.996379 26473 solver.cpp:242] Iteration 113200 (105.926 iter/s, 0.944052s/100 iter), loss = 0.0189861
I0502 11:28:37.996402 26473 solver.cpp:261]     Train net output #0: loss = 0.0189861 (* 1 = 0.0189861 loss)
I0502 11:28:37.996410 26473 sgd_solver.cpp:106] Iteration 113200, lr = 8.58994e-06
I0502 11:28:38.935531 26473 solver.cpp:242] Iteration 113300 (105.943 iter/s, 0.943907s/100 iter), loss = 0.245781
I0502 11:28:38.935573 26473 solver.cpp:261]     Train net output #0: loss = 0.245781 (* 1 = 0.245781 loss)
I0502 11:28:38.935582 26473 sgd_solver.cpp:106] Iteration 113300, lr = 8.58994e-06
I0502 11:28:38.940510 26473 solver.cpp:242] Iteration 113300 (105.923 iter/s, 0.944081s/100 iter), loss = 0.0280942
I0502 11:28:38.940536 26473 solver.cpp:261]     Train net output #0: loss = 0.0280942 (* 1 = 0.0280942 loss)
I0502 11:28:38.940544 26473 sgd_solver.cpp:106] Iteration 113300, lr = 8.58994e-06
I0502 11:28:39.879689 26473 solver.cpp:242] Iteration 113400 (105.923 iter/s, 0.944084s/100 iter), loss = 0.45871
I0502 11:28:39.879732 26473 solver.cpp:261]     Train net output #0: loss = 0.45871 (* 1 = 0.45871 loss)
I0502 11:28:39.879740 26473 sgd_solver.cpp:106] Iteration 113400, lr = 8.58994e-06
I0502 11:28:39.884497 26473 solver.cpp:242] Iteration 113400 (105.939 iter/s, 0.943944s/100 iter), loss = 0.0848
I0502 11:28:39.884521 26473 solver.cpp:261]     Train net output #0: loss = 0.0848 (* 1 = 0.0848 loss)
I0502 11:28:39.884529 26473 sgd_solver.cpp:106] Iteration 113400, lr = 8.58994e-06
I0502 11:28:40.821753 26473 solver.cpp:362] Iteration 113500, Testing net (#0)
I0502 11:28:40.821782 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:40.946238 26473 solver.cpp:429]     Test net output #0: loss = 0.293045 (* 1 = 0.293045 loss)
I0502 11:28:40.949142 26473 solver.cpp:242] Iteration 113500 (93.5111 iter/s, 1.06939s/100 iter), loss = 0.407067
I0502 11:28:40.949163 26473 solver.cpp:261]     Train net output #0: loss = 0.407067 (* 1 = 0.407067 loss)
I0502 11:28:40.949172 26473 sgd_solver.cpp:106] Iteration 113500, lr = 8.58994e-06
I0502 11:28:40.950827 26473 solver.cpp:362] Iteration 113500, Testing net (#0)
I0502 11:28:40.950842 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:41.081571 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9535
I0502 11:28:41.081589 26473 solver.cpp:429]     Test net output #1: loss = 0.0984801 (* 1 = 0.0984801 loss)
I0502 11:28:41.084509 26473 solver.cpp:242] Iteration 113500 (83.3356 iter/s, 1.19997s/100 iter), loss = 0.0927686
I0502 11:28:41.084529 26473 solver.cpp:261]     Train net output #0: loss = 0.0927686 (* 1 = 0.0927686 loss)
I0502 11:28:41.084538 26473 sgd_solver.cpp:106] Iteration 113500, lr = 8.58994e-06
I0502 11:28:42.024138 26473 solver.cpp:242] Iteration 113600 (93.0282 iter/s, 1.07494s/100 iter), loss = 0.431238
I0502 11:28:42.024181 26473 solver.cpp:261]     Train net output #0: loss = 0.431238 (* 1 = 0.431238 loss)
I0502 11:28:42.024190 26473 sgd_solver.cpp:106] Iteration 113600, lr = 8.58994e-06
I0502 11:28:42.028985 26473 solver.cpp:242] Iteration 113600 (105.883 iter/s, 0.944436s/100 iter), loss = 0.0565428
I0502 11:28:42.029006 26473 solver.cpp:261]     Train net output #0: loss = 0.0565428 (* 1 = 0.0565428 loss)
I0502 11:28:42.029016 26473 sgd_solver.cpp:106] Iteration 113600, lr = 8.58994e-06
I0502 11:28:42.967743 26473 solver.cpp:242] Iteration 113700 (105.984 iter/s, 0.943535s/100 iter), loss = 0.17775
I0502 11:28:42.967787 26473 solver.cpp:261]     Train net output #0: loss = 0.17775 (* 1 = 0.17775 loss)
I0502 11:28:42.967797 26473 sgd_solver.cpp:106] Iteration 113700, lr = 8.58994e-06
I0502 11:28:42.972540 26473 solver.cpp:242] Iteration 113700 (105.987 iter/s, 0.943516s/100 iter), loss = 0.0726489
I0502 11:28:42.972568 26473 solver.cpp:261]     Train net output #0: loss = 0.0726489 (* 1 = 0.0726489 loss)
I0502 11:28:42.972575 26473 sgd_solver.cpp:106] Iteration 113700, lr = 8.58994e-06
I0502 11:28:43.911468 26473 solver.cpp:242] Iteration 113800 (105.971 iter/s, 0.943655s/100 iter), loss = 0.187702
I0502 11:28:43.911509 26473 solver.cpp:261]     Train net output #0: loss = 0.187702 (* 1 = 0.187702 loss)
I0502 11:28:43.911519 26473 sgd_solver.cpp:106] Iteration 113800, lr = 8.58994e-06
I0502 11:28:43.916364 26473 solver.cpp:242] Iteration 113800 (105.958 iter/s, 0.943771s/100 iter), loss = 0.155853
I0502 11:28:43.916388 26473 solver.cpp:261]     Train net output #0: loss = 0.155853 (* 1 = 0.155853 loss)
I0502 11:28:43.916396 26473 sgd_solver.cpp:106] Iteration 113800, lr = 8.58994e-06
I0502 11:28:44.854691 26473 solver.cpp:242] Iteration 113900 (106.028 iter/s, 0.943151s/100 iter), loss = 0.35741
I0502 11:28:44.854730 26473 solver.cpp:261]     Train net output #0: loss = 0.35741 (* 1 = 0.35741 loss)
I0502 11:28:44.854740 26473 sgd_solver.cpp:106] Iteration 113900, lr = 8.58994e-06
I0502 11:28:44.859513 26473 solver.cpp:242] Iteration 113900 (106.033 iter/s, 0.943107s/100 iter), loss = 0.115393
I0502 11:28:44.859536 26473 solver.cpp:261]     Train net output #0: loss = 0.115393 (* 1 = 0.115393 loss)
I0502 11:28:44.859544 26473 sgd_solver.cpp:106] Iteration 113900, lr = 8.58994e-06
I0502 11:28:45.795455 26473 solver.cpp:362] Iteration 114000, Testing net (#0)
I0502 11:28:45.795480 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:45.919812 26473 solver.cpp:429]     Test net output #0: loss = 0.237527 (* 1 = 0.237527 loss)
I0502 11:28:45.922698 26473 solver.cpp:242] Iteration 114000 (93.6375 iter/s, 1.06795s/100 iter), loss = 0.101256
I0502 11:28:45.922718 26473 solver.cpp:261]     Train net output #0: loss = 0.101256 (* 1 = 0.101256 loss)
I0502 11:28:45.922726 26473 sgd_solver.cpp:106] Iteration 114000, lr = 8.58994e-06
I0502 11:28:45.924435 26473 solver.cpp:362] Iteration 114000, Testing net (#0)
I0502 11:28:45.924449 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:46.055403 26473 solver.cpp:429]     Test net output #0: accuracy = 0.94
I0502 11:28:46.055428 26473 solver.cpp:429]     Test net output #1: loss = 0.119342 (* 1 = 0.119342 loss)
I0502 11:28:46.058356 26473 solver.cpp:242] Iteration 114000 (83.417 iter/s, 1.1988s/100 iter), loss = 0.0376481
I0502 11:28:46.058375 26473 solver.cpp:261]     Train net output #0: loss = 0.0376481 (* 1 = 0.0376481 loss)
I0502 11:28:46.058384 26473 sgd_solver.cpp:106] Iteration 114000, lr = 8.58994e-06
I0502 11:28:46.997138 26473 solver.cpp:242] Iteration 114100 (93.0762 iter/s, 1.07439s/100 iter), loss = 0.192428
I0502 11:28:46.997177 26473 solver.cpp:261]     Train net output #0: loss = 0.192428 (* 1 = 0.192428 loss)
I0502 11:28:46.997185 26473 sgd_solver.cpp:106] Iteration 114100, lr = 8.58994e-06
I0502 11:28:47.001950 26473 solver.cpp:242] Iteration 114100 (105.982 iter/s, 0.943558s/100 iter), loss = 0.118967
I0502 11:28:47.001974 26473 solver.cpp:261]     Train net output #0: loss = 0.118967 (* 1 = 0.118967 loss)
I0502 11:28:47.001982 26473 sgd_solver.cpp:106] Iteration 114100, lr = 8.58994e-06
I0502 11:28:47.940995 26473 solver.cpp:242] Iteration 114200 (105.956 iter/s, 0.943792s/100 iter), loss = 0.0847127
I0502 11:28:47.941033 26473 solver.cpp:261]     Train net output #0: loss = 0.0847127 (* 1 = 0.0847127 loss)
I0502 11:28:47.941042 26473 sgd_solver.cpp:106] Iteration 114200, lr = 8.58994e-06
I0502 11:28:47.945797 26473 solver.cpp:242] Iteration 114200 (105.954 iter/s, 0.943806s/100 iter), loss = 0.0707118
I0502 11:28:47.945821 26473 solver.cpp:261]     Train net output #0: loss = 0.0707118 (* 1 = 0.0707118 loss)
I0502 11:28:47.945829 26473 sgd_solver.cpp:106] Iteration 114200, lr = 8.58994e-06
I0502 11:28:48.884896 26473 solver.cpp:242] Iteration 114300 (105.95 iter/s, 0.943838s/100 iter), loss = 0.10668
I0502 11:28:48.884928 26473 solver.cpp:261]     Train net output #0: loss = 0.10668 (* 1 = 0.10668 loss)
I0502 11:28:48.884938 26473 sgd_solver.cpp:106] Iteration 114300, lr = 8.58994e-06
I0502 11:28:48.889763 26473 solver.cpp:242] Iteration 114300 (105.942 iter/s, 0.943916s/100 iter), loss = 0.00794109
I0502 11:28:48.889786 26473 solver.cpp:261]     Train net output #0: loss = 0.00794109 (* 1 = 0.00794109 loss)
I0502 11:28:48.889794 26473 sgd_solver.cpp:106] Iteration 114300, lr = 8.58994e-06
I0502 11:28:49.828229 26473 solver.cpp:242] Iteration 114400 (106.013 iter/s, 0.943277s/100 iter), loss = 0.0951082
I0502 11:28:49.828287 26473 solver.cpp:261]     Train net output #0: loss = 0.0951082 (* 1 = 0.0951082 loss)
I0502 11:28:49.828296 26473 sgd_solver.cpp:106] Iteration 114400, lr = 8.58994e-06
I0502 11:28:49.833168 26473 solver.cpp:242] Iteration 114400 (106.004 iter/s, 0.943358s/100 iter), loss = 0.050963
I0502 11:28:49.833192 26473 solver.cpp:261]     Train net output #0: loss = 0.050963 (* 1 = 0.050963 loss)
I0502 11:28:49.833200 26473 sgd_solver.cpp:106] Iteration 114400, lr = 8.58994e-06
I0502 11:28:50.769547 26473 solver.cpp:362] Iteration 114500, Testing net (#0)
I0502 11:28:50.769575 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:50.893896 26473 solver.cpp:429]     Test net output #0: loss = 0.228241 (* 1 = 0.228241 loss)
I0502 11:28:50.896767 26473 solver.cpp:242] Iteration 114500 (93.5925 iter/s, 1.06846s/100 iter), loss = 0.207988
I0502 11:28:50.896786 26473 solver.cpp:261]     Train net output #0: loss = 0.207988 (* 1 = 0.207988 loss)
I0502 11:28:50.896795 26473 sgd_solver.cpp:106] Iteration 114500, lr = 8.58994e-06
I0502 11:28:50.898422 26473 solver.cpp:362] Iteration 114500, Testing net (#0)
I0502 11:28:50.898437 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:51.029017 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:28:51.029039 26473 solver.cpp:429]     Test net output #1: loss = 0.0923337 (* 1 = 0.0923337 loss)
I0502 11:28:51.031956 26473 solver.cpp:242] Iteration 114500 (83.4207 iter/s, 1.19874s/100 iter), loss = 0.129654
I0502 11:28:51.031976 26473 solver.cpp:261]     Train net output #0: loss = 0.129654 (* 1 = 0.129654 loss)
I0502 11:28:51.031992 26473 sgd_solver.cpp:106] Iteration 114500, lr = 8.58994e-06
I0502 11:28:51.970856 26473 solver.cpp:242] Iteration 114600 (93.1064 iter/s, 1.07404s/100 iter), loss = 0.143544
I0502 11:28:51.970886 26473 solver.cpp:261]     Train net output #0: loss = 0.143544 (* 1 = 0.143544 loss)
I0502 11:28:51.970896 26473 sgd_solver.cpp:106] Iteration 114600, lr = 8.58994e-06
I0502 11:28:51.975659 26473 solver.cpp:242] Iteration 114600 (105.97 iter/s, 0.943665s/100 iter), loss = 0.265645
I0502 11:28:51.975682 26473 solver.cpp:261]     Train net output #0: loss = 0.265645 (* 1 = 0.265645 loss)
I0502 11:28:51.975690 26473 sgd_solver.cpp:106] Iteration 114600, lr = 8.58994e-06
I0502 11:28:52.915438 26473 solver.cpp:242] Iteration 114700 (105.873 iter/s, 0.944525s/100 iter), loss = 0.102708
I0502 11:28:52.915469 26473 solver.cpp:261]     Train net output #0: loss = 0.102708 (* 1 = 0.102708 loss)
I0502 11:28:52.915478 26473 sgd_solver.cpp:106] Iteration 114700, lr = 8.58994e-06
I0502 11:28:52.920245 26473 solver.cpp:242] Iteration 114700 (105.871 iter/s, 0.944546s/100 iter), loss = 0.152942
I0502 11:28:52.920269 26473 solver.cpp:261]     Train net output #0: loss = 0.152942 (* 1 = 0.152942 loss)
I0502 11:28:52.920276 26473 sgd_solver.cpp:106] Iteration 114700, lr = 8.58994e-06
I0502 11:28:53.859429 26473 solver.cpp:242] Iteration 114800 (105.94 iter/s, 0.943933s/100 iter), loss = 0.0846367
I0502 11:28:53.859472 26473 solver.cpp:261]     Train net output #0: loss = 0.0846367 (* 1 = 0.0846367 loss)
I0502 11:28:53.859482 26473 sgd_solver.cpp:106] Iteration 114800, lr = 8.58994e-06
I0502 11:28:53.864234 26473 solver.cpp:242] Iteration 114800 (105.938 iter/s, 0.943949s/100 iter), loss = 0.0212109
I0502 11:28:53.864258 26473 solver.cpp:261]     Train net output #0: loss = 0.0212109 (* 1 = 0.0212109 loss)
I0502 11:28:53.864265 26473 sgd_solver.cpp:106] Iteration 114800, lr = 8.58994e-06
I0502 11:28:54.803577 26473 solver.cpp:242] Iteration 114900 (105.923 iter/s, 0.94408s/100 iter), loss = 0.092751
I0502 11:28:54.803619 26473 solver.cpp:261]     Train net output #0: loss = 0.092751 (* 1 = 0.092751 loss)
I0502 11:28:54.803628 26473 sgd_solver.cpp:106] Iteration 114900, lr = 8.58994e-06
I0502 11:28:54.808471 26473 solver.cpp:242] Iteration 114900 (105.911 iter/s, 0.944189s/100 iter), loss = 0.118947
I0502 11:28:54.808495 26473 solver.cpp:261]     Train net output #0: loss = 0.118947 (* 1 = 0.118947 loss)
I0502 11:28:54.808503 26473 sgd_solver.cpp:106] Iteration 114900, lr = 8.58994e-06
I0502 11:28:55.744666 26473 solver.cpp:362] Iteration 115000, Testing net (#0)
I0502 11:28:55.744695 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:55.869109 26473 solver.cpp:429]     Test net output #0: loss = 0.24081 (* 1 = 0.24081 loss)
I0502 11:28:55.871978 26473 solver.cpp:242] Iteration 115000 (93.6031 iter/s, 1.06834s/100 iter), loss = 0.165574
I0502 11:28:55.871999 26473 solver.cpp:261]     Train net output #0: loss = 0.165574 (* 1 = 0.165574 loss)
I0502 11:28:55.872006 26473 sgd_solver.cpp:106] Iteration 115000, lr = 8.58994e-06
I0502 11:28:55.873637 26473 solver.cpp:362] Iteration 115000, Testing net (#0)
I0502 11:28:55.873651 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:28:56.004153 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9575
I0502 11:28:56.004173 26473 solver.cpp:429]     Test net output #1: loss = 0.0906756 (* 1 = 0.0906756 loss)
I0502 11:28:56.007086 26473 solver.cpp:242] Iteration 115000 (83.4327 iter/s, 1.19857s/100 iter), loss = 0.00352201
I0502 11:28:56.007105 26473 solver.cpp:261]     Train net output #0: loss = 0.00352201 (* 1 = 0.00352201 loss)
I0502 11:28:56.007114 26473 sgd_solver.cpp:106] Iteration 115000, lr = 8.58994e-06
I0502 11:28:56.946004 26473 solver.cpp:242] Iteration 115100 (93.112 iter/s, 1.07398s/100 iter), loss = 0.420089
I0502 11:28:56.946045 26473 solver.cpp:261]     Train net output #0: loss = 0.420089 (* 1 = 0.420089 loss)
I0502 11:28:56.946054 26473 sgd_solver.cpp:106] Iteration 115100, lr = 8.58994e-06
I0502 11:28:56.950824 26473 solver.cpp:242] Iteration 115100 (105.966 iter/s, 0.9437s/100 iter), loss = 0.106266
I0502 11:28:56.950856 26473 solver.cpp:261]     Train net output #0: loss = 0.106266 (* 1 = 0.106266 loss)
I0502 11:28:56.950865 26473 sgd_solver.cpp:106] Iteration 115100, lr = 8.58994e-06
I0502 11:28:57.890221 26473 solver.cpp:242] Iteration 115200 (105.916 iter/s, 0.944147s/100 iter), loss = 0.0655426
I0502 11:28:57.890262 26473 solver.cpp:261]     Train net output #0: loss = 0.0655426 (* 1 = 0.0655426 loss)
I0502 11:28:57.890271 26473 sgd_solver.cpp:106] Iteration 115200, lr = 8.58994e-06
I0502 11:28:57.895035 26473 solver.cpp:242] Iteration 115200 (105.914 iter/s, 0.944161s/100 iter), loss = 0.0740651
I0502 11:28:57.895057 26473 solver.cpp:261]     Train net output #0: loss = 0.0740651 (* 1 = 0.0740651 loss)
I0502 11:28:57.895066 26473 sgd_solver.cpp:106] Iteration 115200, lr = 8.58994e-06
I0502 11:28:58.833730 26473 solver.cpp:242] Iteration 115300 (105.995 iter/s, 0.943443s/100 iter), loss = 0.171236
I0502 11:28:58.833770 26473 solver.cpp:261]     Train net output #0: loss = 0.171236 (* 1 = 0.171236 loss)
I0502 11:28:58.833780 26473 sgd_solver.cpp:106] Iteration 115300, lr = 8.58994e-06
I0502 11:28:58.838551 26473 solver.cpp:242] Iteration 115300 (105.991 iter/s, 0.943475s/100 iter), loss = 0.165851
I0502 11:28:58.838573 26473 solver.cpp:261]     Train net output #0: loss = 0.165851 (* 1 = 0.165851 loss)
I0502 11:28:58.838582 26473 sgd_solver.cpp:106] Iteration 115300, lr = 8.58994e-06
I0502 11:28:59.777464 26473 solver.cpp:242] Iteration 115400 (105.969 iter/s, 0.94367s/100 iter), loss = 0.0669473
I0502 11:28:59.777498 26473 solver.cpp:261]     Train net output #0: loss = 0.0669473 (* 1 = 0.0669473 loss)
I0502 11:28:59.777508 26473 sgd_solver.cpp:106] Iteration 115400, lr = 8.58994e-06
I0502 11:28:59.782328 26473 solver.cpp:242] Iteration 115400 (105.963 iter/s, 0.943729s/100 iter), loss = 0.0992475
I0502 11:28:59.782351 26473 solver.cpp:261]     Train net output #0: loss = 0.0992475 (* 1 = 0.0992475 loss)
I0502 11:28:59.782359 26473 sgd_solver.cpp:106] Iteration 115400, lr = 8.58994e-06
I0502 11:29:00.732317 26473 solver.cpp:362] Iteration 115500, Testing net (#0)
I0502 11:29:00.732341 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:00.857043 26473 solver.cpp:429]     Test net output #0: loss = 0.24082 (* 1 = 0.24082 loss)
I0502 11:29:00.859928 26473 solver.cpp:242] Iteration 115500 (92.3863 iter/s, 1.08241s/100 iter), loss = 0.222896
I0502 11:29:00.859948 26473 solver.cpp:261]     Train net output #0: loss = 0.222896 (* 1 = 0.222896 loss)
I0502 11:29:00.859956 26473 sgd_solver.cpp:106] Iteration 115500, lr = 8.58994e-06
I0502 11:29:00.861613 26473 solver.cpp:362] Iteration 115500, Testing net (#0)
I0502 11:29:00.861627 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:00.992424 26473 solver.cpp:429]     Test net output #0: accuracy = 0.969
I0502 11:29:00.992444 26473 solver.cpp:429]     Test net output #1: loss = 0.0781358 (* 1 = 0.0781358 loss)
I0502 11:29:00.995369 26473 solver.cpp:242] Iteration 115500 (82.4403 iter/s, 1.213s/100 iter), loss = 0.128826
I0502 11:29:00.995390 26473 solver.cpp:261]     Train net output #0: loss = 0.128826 (* 1 = 0.128826 loss)
I0502 11:29:00.995398 26473 sgd_solver.cpp:106] Iteration 115500, lr = 8.58994e-06
I0502 11:29:01.939146 26473 solver.cpp:242] Iteration 115600 (92.6641 iter/s, 1.07917s/100 iter), loss = 0.395017
I0502 11:29:01.939184 26473 solver.cpp:261]     Train net output #0: loss = 0.395017 (* 1 = 0.395017 loss)
I0502 11:29:01.939193 26473 sgd_solver.cpp:106] Iteration 115600, lr = 8.58994e-06
I0502 11:29:01.943954 26473 solver.cpp:242] Iteration 115600 (105.424 iter/s, 0.948547s/100 iter), loss = 0.133484
I0502 11:29:01.943977 26473 solver.cpp:261]     Train net output #0: loss = 0.133484 (* 1 = 0.133484 loss)
I0502 11:29:01.943986 26473 sgd_solver.cpp:106] Iteration 115600, lr = 8.58994e-06
I0502 11:29:02.882851 26473 solver.cpp:242] Iteration 115700 (105.973 iter/s, 0.943641s/100 iter), loss = 0.102464
I0502 11:29:02.882889 26473 solver.cpp:261]     Train net output #0: loss = 0.102464 (* 1 = 0.102464 loss)
I0502 11:29:02.882905 26473 sgd_solver.cpp:106] Iteration 115700, lr = 8.58994e-06
I0502 11:29:02.887673 26473 solver.cpp:242] Iteration 115700 (105.968 iter/s, 0.943678s/100 iter), loss = 0.161789
I0502 11:29:02.887697 26473 solver.cpp:261]     Train net output #0: loss = 0.161789 (* 1 = 0.161789 loss)
I0502 11:29:02.887706 26473 sgd_solver.cpp:106] Iteration 115700, lr = 8.58994e-06
I0502 11:29:03.826212 26473 solver.cpp:242] Iteration 115800 (106.011 iter/s, 0.943299s/100 iter), loss = 0.136478
I0502 11:29:03.826246 26473 solver.cpp:261]     Train net output #0: loss = 0.136478 (* 1 = 0.136478 loss)
I0502 11:29:03.826254 26473 sgd_solver.cpp:106] Iteration 115800, lr = 8.58994e-06
I0502 11:29:03.830996 26473 solver.cpp:242] Iteration 115800 (106.013 iter/s, 0.943281s/100 iter), loss = 0.0258566
I0502 11:29:03.831019 26473 solver.cpp:261]     Train net output #0: loss = 0.0258566 (* 1 = 0.0258566 loss)
I0502 11:29:03.831027 26473 sgd_solver.cpp:106] Iteration 115800, lr = 8.58994e-06
I0502 11:29:04.770092 26473 solver.cpp:242] Iteration 115900 (105.952 iter/s, 0.943822s/100 iter), loss = 0.043904
I0502 11:29:04.770128 26473 solver.cpp:261]     Train net output #0: loss = 0.043904 (* 1 = 0.043904 loss)
I0502 11:29:04.770138 26473 sgd_solver.cpp:106] Iteration 115900, lr = 8.58994e-06
I0502 11:29:04.774946 26473 solver.cpp:242] Iteration 115900 (105.943 iter/s, 0.943901s/100 iter), loss = 0.0965884
I0502 11:29:04.774969 26473 solver.cpp:261]     Train net output #0: loss = 0.0965884 (* 1 = 0.0965884 loss)
I0502 11:29:04.774977 26473 sgd_solver.cpp:106] Iteration 115900, lr = 8.58994e-06
I0502 11:29:05.710542 26473 solver.cpp:362] Iteration 116000, Testing net (#0)
I0502 11:29:05.710587 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:05.834965 26473 solver.cpp:429]     Test net output #0: loss = 0.288925 (* 1 = 0.288925 loss)
I0502 11:29:05.837846 26473 solver.cpp:242] Iteration 116000 (93.6593 iter/s, 1.0677s/100 iter), loss = 0.190732
I0502 11:29:05.837867 26473 solver.cpp:261]     Train net output #0: loss = 0.190732 (* 1 = 0.190732 loss)
I0502 11:29:05.837874 26473 sgd_solver.cpp:106] Iteration 116000, lr = 8.58994e-06
I0502 11:29:05.839503 26473 solver.cpp:362] Iteration 116000, Testing net (#0)
I0502 11:29:05.839515 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:05.970223 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:29:05.970242 26473 solver.cpp:429]     Test net output #1: loss = 0.0970605 (* 1 = 0.0970605 loss)
I0502 11:29:05.973148 26473 solver.cpp:242] Iteration 116000 (83.4615 iter/s, 1.19816s/100 iter), loss = 0.102171
I0502 11:29:05.973167 26473 solver.cpp:261]     Train net output #0: loss = 0.102171 (* 1 = 0.102171 loss)
I0502 11:29:05.973176 26473 sgd_solver.cpp:106] Iteration 116000, lr = 8.58994e-06
I0502 11:29:06.912047 26473 solver.cpp:242] Iteration 116100 (93.0971 iter/s, 1.07415s/100 iter), loss = 0.312679
I0502 11:29:06.912089 26473 solver.cpp:261]     Train net output #0: loss = 0.312679 (* 1 = 0.312679 loss)
I0502 11:29:06.912098 26473 sgd_solver.cpp:106] Iteration 116100, lr = 8.58994e-06
I0502 11:29:06.916847 26473 solver.cpp:242] Iteration 116100 (105.97 iter/s, 0.943662s/100 iter), loss = 0.107538
I0502 11:29:06.916870 26473 solver.cpp:261]     Train net output #0: loss = 0.107538 (* 1 = 0.107538 loss)
I0502 11:29:06.916890 26473 sgd_solver.cpp:106] Iteration 116100, lr = 8.58994e-06
I0502 11:29:07.856938 26473 solver.cpp:242] Iteration 116200 (105.84 iter/s, 0.944819s/100 iter), loss = 0.278085
I0502 11:29:07.856981 26473 solver.cpp:261]     Train net output #0: loss = 0.278085 (* 1 = 0.278085 loss)
I0502 11:29:07.856990 26473 sgd_solver.cpp:106] Iteration 116200, lr = 8.58994e-06
I0502 11:29:07.861721 26473 solver.cpp:242] Iteration 116200 (105.839 iter/s, 0.944832s/100 iter), loss = 0.02986
I0502 11:29:07.861743 26473 solver.cpp:261]     Train net output #0: loss = 0.02986 (* 1 = 0.02986 loss)
I0502 11:29:07.861752 26473 sgd_solver.cpp:106] Iteration 116200, lr = 8.58994e-06
I0502 11:29:08.800019 26473 solver.cpp:242] Iteration 116300 (106.043 iter/s, 0.943011s/100 iter), loss = 0.818465
I0502 11:29:08.800060 26473 solver.cpp:261]     Train net output #0: loss = 0.818465 (* 1 = 0.818465 loss)
I0502 11:29:08.800070 26473 sgd_solver.cpp:106] Iteration 116300, lr = 8.58994e-06
I0502 11:29:08.804910 26473 solver.cpp:242] Iteration 116300 (106.028 iter/s, 0.943149s/100 iter), loss = 0.124735
I0502 11:29:08.804934 26473 solver.cpp:261]     Train net output #0: loss = 0.124735 (* 1 = 0.124735 loss)
I0502 11:29:08.804942 26473 sgd_solver.cpp:106] Iteration 116300, lr = 8.58994e-06
I0502 11:29:09.744343 26473 solver.cpp:242] Iteration 116400 (105.903 iter/s, 0.944258s/100 iter), loss = 0.0535131
I0502 11:29:09.744386 26473 solver.cpp:261]     Train net output #0: loss = 0.0535131 (* 1 = 0.0535131 loss)
I0502 11:29:09.744395 26473 sgd_solver.cpp:106] Iteration 116400, lr = 8.58994e-06
I0502 11:29:09.749241 26473 solver.cpp:242] Iteration 116400 (105.901 iter/s, 0.944281s/100 iter), loss = 0.121476
I0502 11:29:09.749264 26473 solver.cpp:261]     Train net output #0: loss = 0.121476 (* 1 = 0.121476 loss)
I0502 11:29:09.749274 26473 sgd_solver.cpp:106] Iteration 116400, lr = 8.58994e-06
I0502 11:29:10.684798 26473 solver.cpp:362] Iteration 116500, Testing net (#0)
I0502 11:29:10.684823 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:10.809136 26473 solver.cpp:429]     Test net output #0: loss = 0.251979 (* 1 = 0.251979 loss)
I0502 11:29:10.812005 26473 solver.cpp:242] Iteration 116500 (93.6679 iter/s, 1.0676s/100 iter), loss = 0.12879
I0502 11:29:10.812024 26473 solver.cpp:261]     Train net output #0: loss = 0.12879 (* 1 = 0.12879 loss)
I0502 11:29:10.812032 26473 sgd_solver.cpp:106] Iteration 116500, lr = 8.58994e-06
I0502 11:29:10.813663 26473 solver.cpp:362] Iteration 116500, Testing net (#0)
I0502 11:29:10.813676 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:10.944155 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:29:10.944190 26473 solver.cpp:429]     Test net output #1: loss = 0.0839138 (* 1 = 0.0839138 loss)
I0502 11:29:10.947124 26473 solver.cpp:242] Iteration 116500 (83.4837 iter/s, 1.19784s/100 iter), loss = 0.0503363
I0502 11:29:10.947145 26473 solver.cpp:261]     Train net output #0: loss = 0.0503363 (* 1 = 0.0503363 loss)
I0502 11:29:10.947154 26473 sgd_solver.cpp:106] Iteration 116500, lr = 8.58994e-06
I0502 11:29:11.905661 26473 solver.cpp:242] Iteration 116600 (91.4409 iter/s, 1.0936s/100 iter), loss = 0.156829
I0502 11:29:11.905707 26473 solver.cpp:261]     Train net output #0: loss = 0.156829 (* 1 = 0.156829 loss)
I0502 11:29:11.905716 26473 sgd_solver.cpp:106] Iteration 116600, lr = 8.58994e-06
I0502 11:29:11.910533 26473 solver.cpp:242] Iteration 116600 (103.802 iter/s, 0.963369s/100 iter), loss = 0.017141
I0502 11:29:11.910557 26473 solver.cpp:261]     Train net output #0: loss = 0.017141 (* 1 = 0.017141 loss)
I0502 11:29:11.910567 26473 sgd_solver.cpp:106] Iteration 116600, lr = 8.58994e-06
I0502 11:29:12.850232 26473 solver.cpp:242] Iteration 116700 (105.876 iter/s, 0.944498s/100 iter), loss = 0.155425
I0502 11:29:12.850273 26473 solver.cpp:261]     Train net output #0: loss = 0.155425 (* 1 = 0.155425 loss)
I0502 11:29:12.850281 26473 sgd_solver.cpp:106] Iteration 116700, lr = 8.58994e-06
I0502 11:29:12.855026 26473 solver.cpp:242] Iteration 116700 (105.882 iter/s, 0.94445s/100 iter), loss = 0.0108502
I0502 11:29:12.855049 26473 solver.cpp:261]     Train net output #0: loss = 0.0108502 (* 1 = 0.0108502 loss)
I0502 11:29:12.855058 26473 sgd_solver.cpp:106] Iteration 116700, lr = 8.58994e-06
I0502 11:29:13.794327 26473 solver.cpp:242] Iteration 116800 (105.929 iter/s, 0.944027s/100 iter), loss = 0.166453
I0502 11:29:13.794364 26473 solver.cpp:261]     Train net output #0: loss = 0.166453 (* 1 = 0.166453 loss)
I0502 11:29:13.794373 26473 sgd_solver.cpp:106] Iteration 116800, lr = 8.58994e-06
I0502 11:29:13.799134 26473 solver.cpp:242] Iteration 116800 (105.925 iter/s, 0.944066s/100 iter), loss = 0.0206776
I0502 11:29:13.799165 26473 solver.cpp:261]     Train net output #0: loss = 0.0206776 (* 1 = 0.0206776 loss)
I0502 11:29:13.799173 26473 sgd_solver.cpp:106] Iteration 116800, lr = 8.58994e-06
I0502 11:29:14.739913 26473 solver.cpp:242] Iteration 116900 (105.762 iter/s, 0.945524s/100 iter), loss = 0.246941
I0502 11:29:14.739954 26473 solver.cpp:261]     Train net output #0: loss = 0.246941 (* 1 = 0.246941 loss)
I0502 11:29:14.739964 26473 sgd_solver.cpp:106] Iteration 116900, lr = 8.58994e-06
I0502 11:29:14.744819 26473 solver.cpp:242] Iteration 116900 (105.75 iter/s, 0.945628s/100 iter), loss = 0.124427
I0502 11:29:14.744843 26473 solver.cpp:261]     Train net output #0: loss = 0.124427 (* 1 = 0.124427 loss)
I0502 11:29:14.744853 26473 sgd_solver.cpp:106] Iteration 116900, lr = 8.58994e-06
I0502 11:29:15.680336 26473 solver.cpp:362] Iteration 117000, Testing net (#0)
I0502 11:29:15.680356 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:15.804702 26473 solver.cpp:429]     Test net output #0: loss = 0.277255 (* 1 = 0.277255 loss)
I0502 11:29:15.807586 26473 solver.cpp:242] Iteration 117000 (93.6668 iter/s, 1.06761s/100 iter), loss = 0.0540488
I0502 11:29:15.807606 26473 solver.cpp:261]     Train net output #0: loss = 0.0540488 (* 1 = 0.0540488 loss)
I0502 11:29:15.807615 26473 sgd_solver.cpp:106] Iteration 117000, lr = 8.58994e-06
I0502 11:29:15.809314 26473 solver.cpp:362] Iteration 117000, Testing net (#0)
I0502 11:29:15.809327 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:15.940062 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:29:15.940083 26473 solver.cpp:429]     Test net output #1: loss = 0.0956693 (* 1 = 0.0956693 loss)
I0502 11:29:15.942994 26473 solver.cpp:242] Iteration 117000 (83.4634 iter/s, 1.19813s/100 iter), loss = 0.137262
I0502 11:29:15.943014 26473 solver.cpp:261]     Train net output #0: loss = 0.137262 (* 1 = 0.137262 loss)
I0502 11:29:15.943022 26473 sgd_solver.cpp:106] Iteration 117000, lr = 8.58994e-06
I0502 11:29:16.882675 26473 solver.cpp:242] Iteration 117100 (93.02 iter/s, 1.07504s/100 iter), loss = 0.194359
I0502 11:29:16.882712 26473 solver.cpp:261]     Train net output #0: loss = 0.194359 (* 1 = 0.194359 loss)
I0502 11:29:16.882721 26473 sgd_solver.cpp:106] Iteration 117100, lr = 8.58994e-06
I0502 11:29:16.887482 26473 solver.cpp:242] Iteration 117100 (105.882 iter/s, 0.944449s/100 iter), loss = 0.20135
I0502 11:29:16.887506 26473 solver.cpp:261]     Train net output #0: loss = 0.20135 (* 1 = 0.20135 loss)
I0502 11:29:16.887513 26473 sgd_solver.cpp:106] Iteration 117100, lr = 8.58994e-06
I0502 11:29:17.826756 26473 solver.cpp:242] Iteration 117200 (105.93 iter/s, 0.944015s/100 iter), loss = 0.140122
I0502 11:29:17.826792 26473 solver.cpp:261]     Train net output #0: loss = 0.140122 (* 1 = 0.140122 loss)
I0502 11:29:17.826802 26473 sgd_solver.cpp:106] Iteration 117200, lr = 8.58994e-06
I0502 11:29:17.831557 26473 solver.cpp:242] Iteration 117200 (105.929 iter/s, 0.944033s/100 iter), loss = 0.0458687
I0502 11:29:17.831579 26473 solver.cpp:261]     Train net output #0: loss = 0.0458687 (* 1 = 0.0458687 loss)
I0502 11:29:17.831588 26473 sgd_solver.cpp:106] Iteration 117200, lr = 8.58994e-06
I0502 11:29:18.770419 26473 solver.cpp:242] Iteration 117300 (105.977 iter/s, 0.943601s/100 iter), loss = 0.239849
I0502 11:29:18.770452 26473 solver.cpp:261]     Train net output #0: loss = 0.239849 (* 1 = 0.239849 loss)
I0502 11:29:18.770462 26473 sgd_solver.cpp:106] Iteration 117300, lr = 8.58994e-06
I0502 11:29:18.775214 26473 solver.cpp:242] Iteration 117300 (105.975 iter/s, 0.943618s/100 iter), loss = 0.00455557
I0502 11:29:18.775238 26473 solver.cpp:261]     Train net output #0: loss = 0.00455557 (* 1 = 0.00455557 loss)
I0502 11:29:18.775245 26473 sgd_solver.cpp:106] Iteration 117300, lr = 8.58994e-06
I0502 11:29:19.714835 26473 solver.cpp:242] Iteration 117400 (105.892 iter/s, 0.944356s/100 iter), loss = 0.0649475
I0502 11:29:19.714881 26473 solver.cpp:261]     Train net output #0: loss = 0.0649475 (* 1 = 0.0649475 loss)
I0502 11:29:19.714890 26473 sgd_solver.cpp:106] Iteration 117400, lr = 8.58994e-06
I0502 11:29:19.719730 26473 solver.cpp:242] Iteration 117400 (105.88 iter/s, 0.944466s/100 iter), loss = 0.0861784
I0502 11:29:19.719754 26473 solver.cpp:261]     Train net output #0: loss = 0.0861784 (* 1 = 0.0861784 loss)
I0502 11:29:19.719763 26473 sgd_solver.cpp:106] Iteration 117400, lr = 8.58994e-06
I0502 11:29:20.655421 26473 solver.cpp:362] Iteration 117500, Testing net (#0)
I0502 11:29:20.655448 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:20.779870 26473 solver.cpp:429]     Test net output #0: loss = 0.278778 (* 1 = 0.278778 loss)
I0502 11:29:20.782747 26473 solver.cpp:242] Iteration 117500 (93.6463 iter/s, 1.06785s/100 iter), loss = 0.123394
I0502 11:29:20.782768 26473 solver.cpp:261]     Train net output #0: loss = 0.123394 (* 1 = 0.123394 loss)
I0502 11:29:20.782776 26473 sgd_solver.cpp:106] Iteration 117500, lr = 8.58994e-06
I0502 11:29:20.784464 26473 solver.cpp:362] Iteration 117500, Testing net (#0)
I0502 11:29:20.784479 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:20.915190 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9665
I0502 11:29:20.915211 26473 solver.cpp:429]     Test net output #1: loss = 0.0796486 (* 1 = 0.0796486 loss)
I0502 11:29:20.918160 26473 solver.cpp:242] Iteration 117500 (83.4456 iter/s, 1.19839s/100 iter), loss = 0.0598072
I0502 11:29:20.918180 26473 solver.cpp:261]     Train net output #0: loss = 0.0598072 (* 1 = 0.0598072 loss)
I0502 11:29:20.918189 26473 sgd_solver.cpp:106] Iteration 117500, lr = 8.58994e-06
I0502 11:29:21.858247 26473 solver.cpp:242] Iteration 117600 (92.9848 iter/s, 1.07544s/100 iter), loss = 0.418036
I0502 11:29:21.858304 26473 solver.cpp:261]     Train net output #0: loss = 0.418036 (* 1 = 0.418036 loss)
I0502 11:29:21.858316 26473 sgd_solver.cpp:106] Iteration 117600, lr = 8.58994e-06
I0502 11:29:21.863113 26473 solver.cpp:242] Iteration 117600 (105.83 iter/s, 0.944913s/100 iter), loss = 0.0456517
I0502 11:29:21.863147 26473 solver.cpp:261]     Train net output #0: loss = 0.0456517 (* 1 = 0.0456517 loss)
I0502 11:29:21.863155 26473 sgd_solver.cpp:106] Iteration 117600, lr = 8.58994e-06
I0502 11:29:22.802125 26473 solver.cpp:242] Iteration 117700 (105.955 iter/s, 0.943794s/100 iter), loss = 0.258674
I0502 11:29:22.802166 26473 solver.cpp:261]     Train net output #0: loss = 0.258674 (* 1 = 0.258674 loss)
I0502 11:29:22.802175 26473 sgd_solver.cpp:106] Iteration 117700, lr = 8.58994e-06
I0502 11:29:22.806915 26473 solver.cpp:242] Iteration 117700 (105.96 iter/s, 0.94375s/100 iter), loss = 0.0285934
I0502 11:29:22.806938 26473 solver.cpp:261]     Train net output #0: loss = 0.0285934 (* 1 = 0.0285934 loss)
I0502 11:29:22.806946 26473 sgd_solver.cpp:106] Iteration 117700, lr = 8.58994e-06
I0502 11:29:23.746314 26473 solver.cpp:242] Iteration 117800 (105.919 iter/s, 0.944117s/100 iter), loss = 0.10431
I0502 11:29:23.746353 26473 solver.cpp:261]     Train net output #0: loss = 0.10431 (* 1 = 0.10431 loss)
I0502 11:29:23.746363 26473 sgd_solver.cpp:106] Iteration 117800, lr = 8.58994e-06
I0502 11:29:23.751174 26473 solver.cpp:242] Iteration 117800 (105.908 iter/s, 0.944218s/100 iter), loss = 0.166585
I0502 11:29:23.751197 26473 solver.cpp:261]     Train net output #0: loss = 0.166585 (* 1 = 0.166585 loss)
I0502 11:29:23.751205 26473 sgd_solver.cpp:106] Iteration 117800, lr = 8.58994e-06
I0502 11:29:24.690402 26473 solver.cpp:242] Iteration 117900 (105.93 iter/s, 0.944022s/100 iter), loss = 0.088099
I0502 11:29:24.690441 26473 solver.cpp:261]     Train net output #0: loss = 0.088099 (* 1 = 0.088099 loss)
I0502 11:29:24.690450 26473 sgd_solver.cpp:106] Iteration 117900, lr = 8.58994e-06
I0502 11:29:24.695205 26473 solver.cpp:242] Iteration 117900 (105.933 iter/s, 0.94399s/100 iter), loss = 0.0600993
I0502 11:29:24.695227 26473 solver.cpp:261]     Train net output #0: loss = 0.0600993 (* 1 = 0.0600993 loss)
I0502 11:29:24.695236 26473 sgd_solver.cpp:106] Iteration 117900, lr = 8.58994e-06
I0502 11:29:25.630399 26473 solver.cpp:362] Iteration 118000, Testing net (#0)
I0502 11:29:25.630432 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:25.754752 26473 solver.cpp:429]     Test net output #0: loss = 0.286679 (* 1 = 0.286679 loss)
I0502 11:29:25.757625 26473 solver.cpp:242] Iteration 118000 (93.7063 iter/s, 1.06716s/100 iter), loss = 0.139789
I0502 11:29:25.757645 26473 solver.cpp:261]     Train net output #0: loss = 0.139789 (* 1 = 0.139789 loss)
I0502 11:29:25.757653 26473 sgd_solver.cpp:106] Iteration 118000, lr = 8.58994e-06
I0502 11:29:25.759348 26473 solver.cpp:362] Iteration 118000, Testing net (#0)
I0502 11:29:25.759362 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:25.890311 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:29:25.890337 26473 solver.cpp:429]     Test net output #1: loss = 0.0865123 (* 1 = 0.0865123 loss)
I0502 11:29:25.893255 26473 solver.cpp:242] Iteration 118000 (83.472 iter/s, 1.19801s/100 iter), loss = 0.0218058
I0502 11:29:25.893275 26473 solver.cpp:261]     Train net output #0: loss = 0.0218058 (* 1 = 0.0218058 loss)
I0502 11:29:25.893285 26473 sgd_solver.cpp:106] Iteration 118000, lr = 8.58994e-06
I0502 11:29:26.832572 26473 solver.cpp:242] Iteration 118100 (93.0327 iter/s, 1.07489s/100 iter), loss = 0.127857
I0502 11:29:26.832612 26473 solver.cpp:261]     Train net output #0: loss = 0.127857 (* 1 = 0.127857 loss)
I0502 11:29:26.832620 26473 sgd_solver.cpp:106] Iteration 118100, lr = 8.58994e-06
I0502 11:29:26.837379 26473 solver.cpp:242] Iteration 118100 (105.923 iter/s, 0.944085s/100 iter), loss = 0.0379849
I0502 11:29:26.837402 26473 solver.cpp:261]     Train net output #0: loss = 0.0379849 (* 1 = 0.0379849 loss)
I0502 11:29:26.837411 26473 sgd_solver.cpp:106] Iteration 118100, lr = 8.58994e-06
I0502 11:29:27.777323 26473 solver.cpp:242] Iteration 118200 (105.856 iter/s, 0.944683s/100 iter), loss = 0.546337
I0502 11:29:27.777364 26473 solver.cpp:261]     Train net output #0: loss = 0.546337 (* 1 = 0.546337 loss)
I0502 11:29:27.777374 26473 sgd_solver.cpp:106] Iteration 118200, lr = 8.58994e-06
I0502 11:29:27.782181 26473 solver.cpp:242] Iteration 118200 (105.847 iter/s, 0.94476s/100 iter), loss = 0.0359926
I0502 11:29:27.782205 26473 solver.cpp:261]     Train net output #0: loss = 0.0359926 (* 1 = 0.0359926 loss)
I0502 11:29:27.782214 26473 sgd_solver.cpp:106] Iteration 118200, lr = 8.58994e-06
I0502 11:29:28.721220 26473 solver.cpp:242] Iteration 118300 (105.951 iter/s, 0.94383s/100 iter), loss = 0.140167
I0502 11:29:28.721257 26473 solver.cpp:261]     Train net output #0: loss = 0.140167 (* 1 = 0.140167 loss)
I0502 11:29:28.721266 26473 sgd_solver.cpp:106] Iteration 118300, lr = 8.58994e-06
I0502 11:29:28.726027 26473 solver.cpp:242] Iteration 118300 (105.954 iter/s, 0.943803s/100 iter), loss = 0.0237244
I0502 11:29:28.726049 26473 solver.cpp:261]     Train net output #0: loss = 0.0237244 (* 1 = 0.0237244 loss)
I0502 11:29:28.726058 26473 sgd_solver.cpp:106] Iteration 118300, lr = 8.58994e-06
I0502 11:29:29.664890 26473 solver.cpp:242] Iteration 118400 (105.976 iter/s, 0.943608s/100 iter), loss = 0.27296
I0502 11:29:29.664925 26473 solver.cpp:261]     Train net output #0: loss = 0.27296 (* 1 = 0.27296 loss)
I0502 11:29:29.664934 26473 sgd_solver.cpp:106] Iteration 118400, lr = 8.58994e-06
I0502 11:29:29.669703 26473 solver.cpp:242] Iteration 118400 (105.973 iter/s, 0.943636s/100 iter), loss = 0.150356
I0502 11:29:29.669728 26473 solver.cpp:261]     Train net output #0: loss = 0.150356 (* 1 = 0.150356 loss)
I0502 11:29:29.669736 26473 sgd_solver.cpp:106] Iteration 118400, lr = 8.58994e-06
I0502 11:29:30.606516 26473 solver.cpp:362] Iteration 118500, Testing net (#0)
I0502 11:29:30.606539 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:30.731006 26473 solver.cpp:429]     Test net output #0: loss = 0.223451 (* 1 = 0.223451 loss)
I0502 11:29:30.733875 26473 solver.cpp:242] Iteration 118500 (93.5514 iter/s, 1.06893s/100 iter), loss = 0.171919
I0502 11:29:30.733896 26473 solver.cpp:261]     Train net output #0: loss = 0.171919 (* 1 = 0.171919 loss)
I0502 11:29:30.733904 26473 sgd_solver.cpp:106] Iteration 118500, lr = 8.58994e-06
I0502 11:29:30.735636 26473 solver.cpp:362] Iteration 118500, Testing net (#0)
I0502 11:29:30.735651 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:30.866338 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:29:30.866358 26473 solver.cpp:429]     Test net output #1: loss = 0.0864089 (* 1 = 0.0864089 loss)
I0502 11:29:30.869283 26473 solver.cpp:242] Iteration 118500 (83.3655 iter/s, 1.19954s/100 iter), loss = 0.0341648
I0502 11:29:30.869303 26473 solver.cpp:261]     Train net output #0: loss = 0.0341648 (* 1 = 0.0341648 loss)
I0502 11:29:30.869313 26473 sgd_solver.cpp:106] Iteration 118500, lr = 8.58994e-06
I0502 11:29:31.808342 26473 solver.cpp:242] Iteration 118600 (93.074 iter/s, 1.07441s/100 iter), loss = 0.194261
I0502 11:29:31.808377 26473 solver.cpp:261]     Train net output #0: loss = 0.194261 (* 1 = 0.194261 loss)
I0502 11:29:31.808385 26473 sgd_solver.cpp:106] Iteration 118600, lr = 8.58994e-06
I0502 11:29:31.813146 26473 solver.cpp:242] Iteration 118600 (105.952 iter/s, 0.943825s/100 iter), loss = 0.0366474
I0502 11:29:31.813169 26473 solver.cpp:261]     Train net output #0: loss = 0.0366474 (* 1 = 0.0366474 loss)
I0502 11:29:31.813179 26473 sgd_solver.cpp:106] Iteration 118600, lr = 8.58994e-06
I0502 11:29:32.752789 26473 solver.cpp:242] Iteration 118700 (105.889 iter/s, 0.944382s/100 iter), loss = 0.27693
I0502 11:29:32.752835 26473 solver.cpp:261]     Train net output #0: loss = 0.27693 (* 1 = 0.27693 loss)
I0502 11:29:32.752846 26473 sgd_solver.cpp:106] Iteration 118700, lr = 8.58994e-06
I0502 11:29:32.757661 26473 solver.cpp:242] Iteration 118700 (105.879 iter/s, 0.944474s/100 iter), loss = 0.156973
I0502 11:29:32.757686 26473 solver.cpp:261]     Train net output #0: loss = 0.156973 (* 1 = 0.156973 loss)
I0502 11:29:32.757695 26473 sgd_solver.cpp:106] Iteration 118700, lr = 8.58994e-06
I0502 11:29:33.696503 26473 solver.cpp:242] Iteration 118800 (105.973 iter/s, 0.943641s/100 iter), loss = 0.149646
I0502 11:29:33.696547 26473 solver.cpp:261]     Train net output #0: loss = 0.149646 (* 1 = 0.149646 loss)
I0502 11:29:33.696573 26473 sgd_solver.cpp:106] Iteration 118800, lr = 8.58994e-06
I0502 11:29:33.701355 26473 solver.cpp:242] Iteration 118800 (105.971 iter/s, 0.943651s/100 iter), loss = 0.00155331
I0502 11:29:33.701378 26473 solver.cpp:261]     Train net output #0: loss = 0.00155331 (* 1 = 0.00155331 loss)
I0502 11:29:33.701387 26473 sgd_solver.cpp:106] Iteration 118800, lr = 8.58994e-06
I0502 11:29:34.640156 26473 solver.cpp:242] Iteration 118900 (105.979 iter/s, 0.943582s/100 iter), loss = 0.259465
I0502 11:29:34.640195 26473 solver.cpp:261]     Train net output #0: loss = 0.259465 (* 1 = 0.259465 loss)
I0502 11:29:34.640204 26473 sgd_solver.cpp:106] Iteration 118900, lr = 8.58994e-06
I0502 11:29:34.645005 26473 solver.cpp:242] Iteration 118900 (105.976 iter/s, 0.943609s/100 iter), loss = 0.046752
I0502 11:29:34.645028 26473 solver.cpp:261]     Train net output #0: loss = 0.046752 (* 1 = 0.046752 loss)
I0502 11:29:34.645037 26473 sgd_solver.cpp:106] Iteration 118900, lr = 8.58994e-06
I0502 11:29:35.580421 26473 solver.cpp:362] Iteration 119000, Testing net (#0)
I0502 11:29:35.580451 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:35.704622 26473 solver.cpp:429]     Test net output #0: loss = 0.21593 (* 1 = 0.21593 loss)
I0502 11:29:35.707494 26473 solver.cpp:242] Iteration 119000 (93.6962 iter/s, 1.06728s/100 iter), loss = 0.14627
I0502 11:29:35.707512 26473 solver.cpp:261]     Train net output #0: loss = 0.14627 (* 1 = 0.14627 loss)
I0502 11:29:35.707520 26473 sgd_solver.cpp:106] Iteration 119000, lr = 8.58994e-06
I0502 11:29:35.709216 26473 solver.cpp:362] Iteration 119000, Testing net (#0)
I0502 11:29:35.709230 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:35.839901 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:29:35.839922 26473 solver.cpp:429]     Test net output #1: loss = 0.0965669 (* 1 = 0.0965669 loss)
I0502 11:29:35.842834 26473 solver.cpp:242] Iteration 119000 (83.4875 iter/s, 1.19778s/100 iter), loss = 0.0614862
I0502 11:29:35.842862 26473 solver.cpp:261]     Train net output #0: loss = 0.0614862 (* 1 = 0.0614862 loss)
I0502 11:29:35.842871 26473 sgd_solver.cpp:106] Iteration 119000, lr = 8.58994e-06
I0502 11:29:36.781669 26473 solver.cpp:242] Iteration 119100 (93.0992 iter/s, 1.07412s/100 iter), loss = 0.0748518
I0502 11:29:36.781713 26473 solver.cpp:261]     Train net output #0: loss = 0.0748518 (* 1 = 0.0748518 loss)
I0502 11:29:36.781723 26473 sgd_solver.cpp:106] Iteration 119100, lr = 8.58994e-06
I0502 11:29:36.786468 26473 solver.cpp:242] Iteration 119100 (105.979 iter/s, 0.943587s/100 iter), loss = 0.14673
I0502 11:29:36.786491 26473 solver.cpp:261]     Train net output #0: loss = 0.14673 (* 1 = 0.14673 loss)
I0502 11:29:36.786499 26473 sgd_solver.cpp:106] Iteration 119100, lr = 8.58994e-06
I0502 11:29:37.726992 26473 solver.cpp:242] Iteration 119200 (105.792 iter/s, 0.945251s/100 iter), loss = 0.212653
I0502 11:29:37.727032 26473 solver.cpp:261]     Train net output #0: loss = 0.212653 (* 1 = 0.212653 loss)
I0502 11:29:37.727041 26473 sgd_solver.cpp:106] Iteration 119200, lr = 8.58994e-06
I0502 11:29:37.731791 26473 solver.cpp:242] Iteration 119200 (105.789 iter/s, 0.945281s/100 iter), loss = 0.0513971
I0502 11:29:37.731813 26473 solver.cpp:261]     Train net output #0: loss = 0.0513971 (* 1 = 0.0513971 loss)
I0502 11:29:37.731822 26473 sgd_solver.cpp:106] Iteration 119200, lr = 8.58994e-06
I0502 11:29:38.671526 26473 solver.cpp:242] Iteration 119300 (105.88 iter/s, 0.944463s/100 iter), loss = 0.166487
I0502 11:29:38.671566 26473 solver.cpp:261]     Train net output #0: loss = 0.166487 (* 1 = 0.166487 loss)
I0502 11:29:38.671576 26473 sgd_solver.cpp:106] Iteration 119300, lr = 8.58994e-06
I0502 11:29:38.676342 26473 solver.cpp:242] Iteration 119300 (105.875 iter/s, 0.944511s/100 iter), loss = 0.0184424
I0502 11:29:38.676367 26473 solver.cpp:261]     Train net output #0: loss = 0.0184424 (* 1 = 0.0184424 loss)
I0502 11:29:38.676374 26473 sgd_solver.cpp:106] Iteration 119300, lr = 8.58994e-06
I0502 11:29:39.615371 26473 solver.cpp:242] Iteration 119400 (105.957 iter/s, 0.94378s/100 iter), loss = 0.271357
I0502 11:29:39.615409 26473 solver.cpp:261]     Train net output #0: loss = 0.271357 (* 1 = 0.271357 loss)
I0502 11:29:39.615418 26473 sgd_solver.cpp:106] Iteration 119400, lr = 8.58994e-06
I0502 11:29:39.620210 26473 solver.cpp:242] Iteration 119400 (105.952 iter/s, 0.943826s/100 iter), loss = 0.0376056
I0502 11:29:39.620234 26473 solver.cpp:261]     Train net output #0: loss = 0.0376056 (* 1 = 0.0376056 loss)
I0502 11:29:39.620242 26473 sgd_solver.cpp:106] Iteration 119400, lr = 8.58994e-06
I0502 11:29:40.556011 26473 solver.cpp:362] Iteration 119500, Testing net (#0)
I0502 11:29:40.556035 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:40.680714 26473 solver.cpp:429]     Test net output #0: loss = 0.269456 (* 1 = 0.269456 loss)
I0502 11:29:40.683588 26473 solver.cpp:242] Iteration 119500 (93.6189 iter/s, 1.06816s/100 iter), loss = 0.0484458
I0502 11:29:40.683609 26473 solver.cpp:261]     Train net output #0: loss = 0.0484458 (* 1 = 0.0484458 loss)
I0502 11:29:40.683616 26473 sgd_solver.cpp:106] Iteration 119500, lr = 8.58994e-06
I0502 11:29:40.685318 26473 solver.cpp:362] Iteration 119500, Testing net (#0)
I0502 11:29:40.685333 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:40.816305 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:29:40.816335 26473 solver.cpp:429]     Test net output #1: loss = 0.0947087 (* 1 = 0.0947087 loss)
I0502 11:29:40.819267 26473 solver.cpp:242] Iteration 119500 (83.402 iter/s, 1.19901s/100 iter), loss = 0.0441783
I0502 11:29:40.819286 26473 solver.cpp:261]     Train net output #0: loss = 0.0441783 (* 1 = 0.0441783 loss)
I0502 11:29:40.819295 26473 sgd_solver.cpp:106] Iteration 119500, lr = 8.58994e-06
I0502 11:29:41.758663 26473 solver.cpp:242] Iteration 119600 (93.0215 iter/s, 1.07502s/100 iter), loss = 0.140144
I0502 11:29:41.758700 26473 solver.cpp:261]     Train net output #0: loss = 0.140144 (* 1 = 0.140144 loss)
I0502 11:29:41.758718 26473 sgd_solver.cpp:106] Iteration 119600, lr = 8.58994e-06
I0502 11:29:41.763478 26473 solver.cpp:242] Iteration 119600 (105.913 iter/s, 0.944174s/100 iter), loss = 0.0636298
I0502 11:29:41.763501 26473 solver.cpp:261]     Train net output #0: loss = 0.0636298 (* 1 = 0.0636298 loss)
I0502 11:29:41.763509 26473 sgd_solver.cpp:106] Iteration 119600, lr = 8.58994e-06
I0502 11:29:42.702210 26473 solver.cpp:242] Iteration 119700 (105.991 iter/s, 0.943481s/100 iter), loss = 0.0677869
I0502 11:29:42.702244 26473 solver.cpp:261]     Train net output #0: loss = 0.0677869 (* 1 = 0.0677869 loss)
I0502 11:29:42.702252 26473 sgd_solver.cpp:106] Iteration 119700, lr = 8.58994e-06
I0502 11:29:42.707020 26473 solver.cpp:242] Iteration 119700 (105.988 iter/s, 0.943501s/100 iter), loss = 0.019803
I0502 11:29:42.707044 26473 solver.cpp:261]     Train net output #0: loss = 0.019803 (* 1 = 0.019803 loss)
I0502 11:29:42.707052 26473 sgd_solver.cpp:106] Iteration 119700, lr = 8.58994e-06
I0502 11:29:43.645648 26473 solver.cpp:242] Iteration 119800 (106.002 iter/s, 0.943375s/100 iter), loss = 0.0769005
I0502 11:29:43.645690 26473 solver.cpp:261]     Train net output #0: loss = 0.0769005 (* 1 = 0.0769005 loss)
I0502 11:29:43.645699 26473 sgd_solver.cpp:106] Iteration 119800, lr = 8.58994e-06
I0502 11:29:43.650454 26473 solver.cpp:242] Iteration 119800 (106.001 iter/s, 0.943392s/100 iter), loss = 0.143604
I0502 11:29:43.650477 26473 solver.cpp:261]     Train net output #0: loss = 0.143604 (* 1 = 0.143604 loss)
I0502 11:29:43.650485 26473 sgd_solver.cpp:106] Iteration 119800, lr = 8.58994e-06
I0502 11:29:44.589326 26473 solver.cpp:242] Iteration 119900 (105.976 iter/s, 0.943608s/100 iter), loss = 0.148707
I0502 11:29:44.589370 26473 solver.cpp:261]     Train net output #0: loss = 0.148707 (* 1 = 0.148707 loss)
I0502 11:29:44.589378 26473 sgd_solver.cpp:106] Iteration 119900, lr = 8.58994e-06
I0502 11:29:44.594130 26473 solver.cpp:242] Iteration 119900 (105.973 iter/s, 0.943635s/100 iter), loss = 0.02904
I0502 11:29:44.594153 26473 solver.cpp:261]     Train net output #0: loss = 0.02904 (* 1 = 0.02904 loss)
I0502 11:29:44.594162 26473 sgd_solver.cpp:106] Iteration 119900, lr = 8.58994e-06
I0502 11:29:45.529772 26473 solver.cpp:362] Iteration 120000, Testing net (#0)
I0502 11:29:45.529799 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:45.654336 26473 solver.cpp:429]     Test net output #0: loss = 0.282699 (* 1 = 0.282699 loss)
I0502 11:29:45.657208 26473 solver.cpp:242] Iteration 120000 (93.6488 iter/s, 1.06782s/100 iter), loss = 0.162517
I0502 11:29:45.657228 26473 solver.cpp:261]     Train net output #0: loss = 0.162517 (* 1 = 0.162517 loss)
I0502 11:29:45.657238 26473 sgd_solver.cpp:106] Iteration 120000, lr = 6.87195e-06
I0502 11:29:45.658990 26473 solver.cpp:362] Iteration 120000, Testing net (#0)
I0502 11:29:45.659004 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:45.789679 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:29:45.789700 26473 solver.cpp:429]     Test net output #1: loss = 0.0876411 (* 1 = 0.0876411 loss)
I0502 11:29:45.792629 26473 solver.cpp:242] Iteration 120000 (83.4408 iter/s, 1.19845s/100 iter), loss = 0.0270319
I0502 11:29:45.792649 26473 solver.cpp:261]     Train net output #0: loss = 0.0270319 (* 1 = 0.0270319 loss)
I0502 11:29:45.792657 26473 sgd_solver.cpp:106] Iteration 120000, lr = 6.87195e-06
I0502 11:29:46.730849 26473 solver.cpp:242] Iteration 120100 (93.1451 iter/s, 1.07359s/100 iter), loss = 0.0552354
I0502 11:29:46.730892 26473 solver.cpp:261]     Train net output #0: loss = 0.0552354 (* 1 = 0.0552354 loss)
I0502 11:29:46.730901 26473 sgd_solver.cpp:106] Iteration 120100, lr = 6.87195e-06
I0502 11:29:46.735730 26473 solver.cpp:242] Iteration 120100 (106.038 iter/s, 0.943058s/100 iter), loss = 0.0965872
I0502 11:29:46.735765 26473 solver.cpp:261]     Train net output #0: loss = 0.0965872 (* 1 = 0.0965872 loss)
I0502 11:29:46.735774 26473 sgd_solver.cpp:106] Iteration 120100, lr = 6.87195e-06
I0502 11:29:47.675179 26473 solver.cpp:242] Iteration 120200 (105.904 iter/s, 0.944255s/100 iter), loss = 0.0795656
I0502 11:29:47.675216 26473 solver.cpp:261]     Train net output #0: loss = 0.0795656 (* 1 = 0.0795656 loss)
I0502 11:29:47.675225 26473 sgd_solver.cpp:106] Iteration 120200, lr = 6.87195e-06
I0502 11:29:47.680069 26473 solver.cpp:242] Iteration 120200 (105.9 iter/s, 0.944285s/100 iter), loss = 0.0875816
I0502 11:29:47.680100 26473 solver.cpp:261]     Train net output #0: loss = 0.0875816 (* 1 = 0.0875816 loss)
I0502 11:29:47.680109 26473 sgd_solver.cpp:106] Iteration 120200, lr = 6.87195e-06
I0502 11:29:48.619014 26473 solver.cpp:242] Iteration 120300 (105.958 iter/s, 0.943768s/100 iter), loss = 0.25737
I0502 11:29:48.619068 26473 solver.cpp:261]     Train net output #0: loss = 0.25737 (* 1 = 0.25737 loss)
I0502 11:29:48.619078 26473 sgd_solver.cpp:106] Iteration 120300, lr = 6.87195e-06
I0502 11:29:48.623855 26473 solver.cpp:242] Iteration 120300 (105.962 iter/s, 0.943739s/100 iter), loss = 0.121245
I0502 11:29:48.623879 26473 solver.cpp:261]     Train net output #0: loss = 0.121245 (* 1 = 0.121245 loss)
I0502 11:29:48.623888 26473 sgd_solver.cpp:106] Iteration 120300, lr = 6.87195e-06
I0502 11:29:49.563226 26473 solver.cpp:242] Iteration 120400 (105.918 iter/s, 0.944131s/100 iter), loss = 0.257198
I0502 11:29:49.563268 26473 solver.cpp:261]     Train net output #0: loss = 0.257198 (* 1 = 0.257198 loss)
I0502 11:29:49.563277 26473 sgd_solver.cpp:106] Iteration 120400, lr = 6.87195e-06
I0502 11:29:49.568073 26473 solver.cpp:242] Iteration 120400 (105.912 iter/s, 0.944176s/100 iter), loss = 0.059255
I0502 11:29:49.568096 26473 solver.cpp:261]     Train net output #0: loss = 0.059255 (* 1 = 0.059255 loss)
I0502 11:29:49.568104 26473 sgd_solver.cpp:106] Iteration 120400, lr = 6.87195e-06
I0502 11:29:50.504959 26473 solver.cpp:362] Iteration 120500, Testing net (#0)
I0502 11:29:50.504987 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:50.629436 26473 solver.cpp:429]     Test net output #0: loss = 0.265572 (* 1 = 0.265572 loss)
I0502 11:29:50.632299 26473 solver.cpp:242] Iteration 120500 (93.5442 iter/s, 1.06901s/100 iter), loss = 0.433766
I0502 11:29:50.632319 26473 solver.cpp:261]     Train net output #0: loss = 0.433766 (* 1 = 0.433766 loss)
I0502 11:29:50.632328 26473 sgd_solver.cpp:106] Iteration 120500, lr = 6.87195e-06
I0502 11:29:50.633955 26473 solver.cpp:362] Iteration 120500, Testing net (#0)
I0502 11:29:50.633968 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:50.764842 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:29:50.764873 26473 solver.cpp:429]     Test net output #1: loss = 0.0867387 (* 1 = 0.0867387 loss)
I0502 11:29:50.767791 26473 solver.cpp:242] Iteration 120500 (83.3559 iter/s, 1.19967s/100 iter), loss = 0.0197078
I0502 11:29:50.767812 26473 solver.cpp:261]     Train net output #0: loss = 0.0197078 (* 1 = 0.0197078 loss)
I0502 11:29:50.767819 26473 sgd_solver.cpp:106] Iteration 120500, lr = 6.87195e-06
I0502 11:29:51.708849 26473 solver.cpp:242] Iteration 120600 (92.8934 iter/s, 1.0765s/100 iter), loss = 0.316799
I0502 11:29:51.708892 26473 solver.cpp:261]     Train net output #0: loss = 0.316799 (* 1 = 0.316799 loss)
I0502 11:29:51.708901 26473 sgd_solver.cpp:106] Iteration 120600, lr = 6.87195e-06
I0502 11:29:51.713768 26473 solver.cpp:242] Iteration 120600 (105.716 iter/s, 0.945931s/100 iter), loss = 0.1289
I0502 11:29:51.713791 26473 solver.cpp:261]     Train net output #0: loss = 0.1289 (* 1 = 0.1289 loss)
I0502 11:29:51.713799 26473 sgd_solver.cpp:106] Iteration 120600, lr = 6.87195e-06
I0502 11:29:52.652921 26473 solver.cpp:242] Iteration 120700 (105.932 iter/s, 0.943998s/100 iter), loss = 0.219732
I0502 11:29:52.652963 26473 solver.cpp:261]     Train net output #0: loss = 0.219732 (* 1 = 0.219732 loss)
I0502 11:29:52.652972 26473 sgd_solver.cpp:106] Iteration 120700, lr = 6.87195e-06
I0502 11:29:52.657742 26473 solver.cpp:242] Iteration 120700 (105.94 iter/s, 0.943932s/100 iter), loss = 0.00795969
I0502 11:29:52.657764 26473 solver.cpp:261]     Train net output #0: loss = 0.00795969 (* 1 = 0.00795969 loss)
I0502 11:29:52.657781 26473 sgd_solver.cpp:106] Iteration 120700, lr = 6.87195e-06
I0502 11:29:53.597014 26473 solver.cpp:242] Iteration 120800 (105.93 iter/s, 0.944024s/100 iter), loss = 0.129356
I0502 11:29:53.597051 26473 solver.cpp:261]     Train net output #0: loss = 0.129356 (* 1 = 0.129356 loss)
I0502 11:29:53.597059 26473 sgd_solver.cpp:106] Iteration 120800, lr = 6.87195e-06
I0502 11:29:53.601814 26473 solver.cpp:242] Iteration 120800 (105.929 iter/s, 0.94403s/100 iter), loss = 0.00766979
I0502 11:29:53.601836 26473 solver.cpp:261]     Train net output #0: loss = 0.00766979 (* 1 = 0.00766979 loss)
I0502 11:29:53.601845 26473 sgd_solver.cpp:106] Iteration 120800, lr = 6.87195e-06
I0502 11:29:54.541980 26473 solver.cpp:242] Iteration 120900 (105.831 iter/s, 0.944902s/100 iter), loss = 0.186649
I0502 11:29:54.542017 26473 solver.cpp:261]     Train net output #0: loss = 0.186649 (* 1 = 0.186649 loss)
I0502 11:29:54.542026 26473 sgd_solver.cpp:106] Iteration 120900, lr = 6.87195e-06
I0502 11:29:54.546800 26473 solver.cpp:242] Iteration 120900 (105.826 iter/s, 0.944946s/100 iter), loss = 0.0676238
I0502 11:29:54.546823 26473 solver.cpp:261]     Train net output #0: loss = 0.0676238 (* 1 = 0.0676238 loss)
I0502 11:29:54.546833 26473 sgd_solver.cpp:106] Iteration 120900, lr = 6.87195e-06
I0502 11:29:55.482460 26473 solver.cpp:362] Iteration 121000, Testing net (#0)
I0502 11:29:55.482482 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:55.606892 26473 solver.cpp:429]     Test net output #0: loss = 0.214943 (* 1 = 0.214943 loss)
I0502 11:29:55.609777 26473 solver.cpp:242] Iteration 121000 (93.6557 iter/s, 1.06774s/100 iter), loss = 0.0431718
I0502 11:29:55.609797 26473 solver.cpp:261]     Train net output #0: loss = 0.0431718 (* 1 = 0.0431718 loss)
I0502 11:29:55.609805 26473 sgd_solver.cpp:106] Iteration 121000, lr = 6.87195e-06
I0502 11:29:55.611467 26473 solver.cpp:362] Iteration 121000, Testing net (#0)
I0502 11:29:55.611481 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:29:55.742130 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:29:55.742152 26473 solver.cpp:429]     Test net output #1: loss = 0.0869492 (* 1 = 0.0869492 loss)
I0502 11:29:55.745086 26473 solver.cpp:242] Iteration 121000 (83.4557 iter/s, 1.19824s/100 iter), loss = 0.0821422
I0502 11:29:55.745106 26473 solver.cpp:261]     Train net output #0: loss = 0.0821422 (* 1 = 0.0821422 loss)
I0502 11:29:55.745115 26473 sgd_solver.cpp:106] Iteration 121000, lr = 6.87195e-06
I0502 11:29:56.685145 26473 solver.cpp:242] Iteration 121100 (92.9954 iter/s, 1.07532s/100 iter), loss = 0.139343
I0502 11:29:56.685180 26473 solver.cpp:261]     Train net output #0: loss = 0.139343 (* 1 = 0.139343 loss)
I0502 11:29:56.685189 26473 sgd_solver.cpp:106] Iteration 121100, lr = 6.87195e-06
I0502 11:29:56.690006 26473 solver.cpp:242] Iteration 121100 (105.834 iter/s, 0.944873s/100 iter), loss = 0.0939376
I0502 11:29:56.690028 26473 solver.cpp:261]     Train net output #0: loss = 0.0939376 (* 1 = 0.0939376 loss)
I0502 11:29:56.690037 26473 sgd_solver.cpp:106] Iteration 121100, lr = 6.87195e-06
I0502 11:29:57.628993 26473 solver.cpp:242] Iteration 121200 (105.956 iter/s, 0.943784s/100 iter), loss = 0.120026
I0502 11:29:57.629029 26473 solver.cpp:261]     Train net output #0: loss = 0.120026 (* 1 = 0.120026 loss)
I0502 11:29:57.629037 26473 sgd_solver.cpp:106] Iteration 121200, lr = 6.87195e-06
I0502 11:29:57.633796 26473 solver.cpp:242] Iteration 121200 (105.96 iter/s, 0.94375s/100 iter), loss = 0.147473
I0502 11:29:57.633819 26473 solver.cpp:261]     Train net output #0: loss = 0.147473 (* 1 = 0.147473 loss)
I0502 11:29:57.633827 26473 sgd_solver.cpp:106] Iteration 121200, lr = 6.87195e-06
I0502 11:29:58.572880 26473 solver.cpp:242] Iteration 121300 (105.953 iter/s, 0.943817s/100 iter), loss = 0.139188
I0502 11:29:58.572914 26473 solver.cpp:261]     Train net output #0: loss = 0.139188 (* 1 = 0.139188 loss)
I0502 11:29:58.572923 26473 sgd_solver.cpp:106] Iteration 121300, lr = 6.87195e-06
I0502 11:29:58.577700 26473 solver.cpp:242] Iteration 121300 (105.948 iter/s, 0.943864s/100 iter), loss = 0.147619
I0502 11:29:58.577723 26473 solver.cpp:261]     Train net output #0: loss = 0.147619 (* 1 = 0.147619 loss)
I0502 11:29:58.577731 26473 sgd_solver.cpp:106] Iteration 121300, lr = 6.87195e-06
I0502 11:29:59.517134 26473 solver.cpp:242] Iteration 121400 (105.911 iter/s, 0.944191s/100 iter), loss = 0.207387
I0502 11:29:59.517175 26473 solver.cpp:261]     Train net output #0: loss = 0.207387 (* 1 = 0.207387 loss)
I0502 11:29:59.517184 26473 sgd_solver.cpp:106] Iteration 121400, lr = 6.87195e-06
I0502 11:29:59.521962 26473 solver.cpp:242] Iteration 121400 (105.907 iter/s, 0.944221s/100 iter), loss = 0.0775919
I0502 11:29:59.521984 26473 solver.cpp:261]     Train net output #0: loss = 0.0775919 (* 1 = 0.0775919 loss)
I0502 11:29:59.521993 26473 sgd_solver.cpp:106] Iteration 121400, lr = 6.87195e-06
I0502 11:30:00.469610 26473 solver.cpp:362] Iteration 121500, Testing net (#0)
I0502 11:30:00.469637 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:00.594321 26473 solver.cpp:429]     Test net output #0: loss = 0.248479 (* 1 = 0.248479 loss)
I0502 11:30:00.597204 26473 solver.cpp:242] Iteration 121500 (92.5917 iter/s, 1.08001s/100 iter), loss = 0.188087
I0502 11:30:00.597224 26473 solver.cpp:261]     Train net output #0: loss = 0.188087 (* 1 = 0.188087 loss)
I0502 11:30:00.597234 26473 sgd_solver.cpp:106] Iteration 121500, lr = 6.87195e-06
I0502 11:30:00.598924 26473 solver.cpp:362] Iteration 121500, Testing net (#0)
I0502 11:30:00.598939 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:00.729878 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:30:00.729899 26473 solver.cpp:429]     Test net output #1: loss = 0.0909193 (* 1 = 0.0909193 loss)
I0502 11:30:00.732820 26473 solver.cpp:242] Iteration 121500 (82.5891 iter/s, 1.21081s/100 iter), loss = 0.0852211
I0502 11:30:00.732839 26473 solver.cpp:261]     Train net output #0: loss = 0.0852211 (* 1 = 0.0852211 loss)
I0502 11:30:00.732848 26473 sgd_solver.cpp:106] Iteration 121500, lr = 6.87195e-06
I0502 11:30:01.676038 26473 solver.cpp:242] Iteration 121600 (92.6969 iter/s, 1.07879s/100 iter), loss = 0.313673
I0502 11:30:01.676079 26473 solver.cpp:261]     Train net output #0: loss = 0.313673 (* 1 = 0.313673 loss)
I0502 11:30:01.676087 26473 sgd_solver.cpp:106] Iteration 121600, lr = 6.87195e-06
I0502 11:30:01.680930 26473 solver.cpp:242] Iteration 121600 (105.478 iter/s, 0.948063s/100 iter), loss = 0.0726023
I0502 11:30:01.680953 26473 solver.cpp:261]     Train net output #0: loss = 0.0726023 (* 1 = 0.0726023 loss)
I0502 11:30:01.680963 26473 sgd_solver.cpp:106] Iteration 121600, lr = 6.87195e-06
I0502 11:30:02.620404 26473 solver.cpp:242] Iteration 121700 (105.899 iter/s, 0.944294s/100 iter), loss = 0.741723
I0502 11:30:02.620450 26473 solver.cpp:261]     Train net output #0: loss = 0.741723 (* 1 = 0.741723 loss)
I0502 11:30:02.620458 26473 sgd_solver.cpp:106] Iteration 121700, lr = 6.87195e-06
I0502 11:30:02.625236 26473 solver.cpp:242] Iteration 121700 (105.902 iter/s, 0.944266s/100 iter), loss = 0.200278
I0502 11:30:02.625259 26473 solver.cpp:261]     Train net output #0: loss = 0.200278 (* 1 = 0.200278 loss)
I0502 11:30:02.625268 26473 sgd_solver.cpp:106] Iteration 121700, lr = 6.87195e-06
I0502 11:30:03.564484 26473 solver.cpp:242] Iteration 121800 (105.932 iter/s, 0.944006s/100 iter), loss = 0.131951
I0502 11:30:03.564527 26473 solver.cpp:261]     Train net output #0: loss = 0.131951 (* 1 = 0.131951 loss)
I0502 11:30:03.564537 26473 sgd_solver.cpp:106] Iteration 121800, lr = 6.87195e-06
I0502 11:30:03.569308 26473 solver.cpp:242] Iteration 121800 (105.929 iter/s, 0.94403s/100 iter), loss = 0.037093
I0502 11:30:03.569330 26473 solver.cpp:261]     Train net output #0: loss = 0.037093 (* 1 = 0.037093 loss)
I0502 11:30:03.569339 26473 sgd_solver.cpp:106] Iteration 121800, lr = 6.87195e-06
I0502 11:30:04.508502 26473 solver.cpp:242] Iteration 121900 (105.938 iter/s, 0.943946s/100 iter), loss = 0.102471
I0502 11:30:04.508569 26473 solver.cpp:261]     Train net output #0: loss = 0.102471 (* 1 = 0.102471 loss)
I0502 11:30:04.508580 26473 sgd_solver.cpp:106] Iteration 121900, lr = 6.87195e-06
I0502 11:30:04.513365 26473 solver.cpp:242] Iteration 121900 (105.93 iter/s, 0.944016s/100 iter), loss = 0.115415
I0502 11:30:04.513387 26473 solver.cpp:261]     Train net output #0: loss = 0.115415 (* 1 = 0.115415 loss)
I0502 11:30:04.513396 26473 sgd_solver.cpp:106] Iteration 121900, lr = 6.87195e-06
I0502 11:30:05.449975 26473 solver.cpp:362] Iteration 122000, Testing net (#0)
I0502 11:30:05.450001 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:05.574266 26473 solver.cpp:429]     Test net output #0: loss = 0.22907 (* 1 = 0.22907 loss)
I0502 11:30:05.577126 26473 solver.cpp:242] Iteration 122000 (93.5842 iter/s, 1.06856s/100 iter), loss = 0.285169
I0502 11:30:05.577147 26473 solver.cpp:261]     Train net output #0: loss = 0.285169 (* 1 = 0.285169 loss)
I0502 11:30:05.577155 26473 sgd_solver.cpp:106] Iteration 122000, lr = 6.87195e-06
I0502 11:30:05.578773 26473 solver.cpp:362] Iteration 122000, Testing net (#0)
I0502 11:30:05.578786 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:05.709620 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9485
I0502 11:30:05.709643 26473 solver.cpp:429]     Test net output #1: loss = 0.0987311 (* 1 = 0.0987311 loss)
I0502 11:30:05.712584 26473 solver.cpp:242] Iteration 122000 (83.3907 iter/s, 1.19917s/100 iter), loss = 0.0547066
I0502 11:30:05.712604 26473 solver.cpp:261]     Train net output #0: loss = 0.0547066 (* 1 = 0.0547066 loss)
I0502 11:30:05.712613 26473 sgd_solver.cpp:106] Iteration 122000, lr = 6.87195e-06
I0502 11:30:06.651557 26473 solver.cpp:242] Iteration 122100 (93.0766 iter/s, 1.07438s/100 iter), loss = 0.240052
I0502 11:30:06.651598 26473 solver.cpp:261]     Train net output #0: loss = 0.240052 (* 1 = 0.240052 loss)
I0502 11:30:06.651607 26473 sgd_solver.cpp:106] Iteration 122100, lr = 6.87195e-06
I0502 11:30:06.656445 26473 solver.cpp:242] Iteration 122100 (105.953 iter/s, 0.943814s/100 iter), loss = 0.217256
I0502 11:30:06.656467 26473 solver.cpp:261]     Train net output #0: loss = 0.217256 (* 1 = 0.217256 loss)
I0502 11:30:06.656476 26473 sgd_solver.cpp:106] Iteration 122100, lr = 6.87195e-06
I0502 11:30:07.595638 26473 solver.cpp:242] Iteration 122200 (105.931 iter/s, 0.944007s/100 iter), loss = 0.339198
I0502 11:30:07.595679 26473 solver.cpp:261]     Train net output #0: loss = 0.339198 (* 1 = 0.339198 loss)
I0502 11:30:07.595687 26473 sgd_solver.cpp:106] Iteration 122200, lr = 6.87195e-06
I0502 11:30:07.600446 26473 solver.cpp:242] Iteration 122200 (105.937 iter/s, 0.943961s/100 iter), loss = 0.0101509
I0502 11:30:07.600469 26473 solver.cpp:261]     Train net output #0: loss = 0.0101509 (* 1 = 0.0101509 loss)
I0502 11:30:07.600478 26473 sgd_solver.cpp:106] Iteration 122200, lr = 6.87195e-06
I0502 11:30:08.539078 26473 solver.cpp:242] Iteration 122300 (106.003 iter/s, 0.943369s/100 iter), loss = 0.264899
I0502 11:30:08.539114 26473 solver.cpp:261]     Train net output #0: loss = 0.264899 (* 1 = 0.264899 loss)
I0502 11:30:08.539124 26473 sgd_solver.cpp:106] Iteration 122300, lr = 6.87195e-06
I0502 11:30:08.543889 26473 solver.cpp:242] Iteration 122300 (105.999 iter/s, 0.943402s/100 iter), loss = 0.0510274
I0502 11:30:08.543912 26473 solver.cpp:261]     Train net output #0: loss = 0.0510274 (* 1 = 0.0510274 loss)
I0502 11:30:08.543920 26473 sgd_solver.cpp:106] Iteration 122300, lr = 6.87195e-06
I0502 11:30:09.483573 26473 solver.cpp:242] Iteration 122400 (105.884 iter/s, 0.944432s/100 iter), loss = 0.176129
I0502 11:30:09.483603 26473 solver.cpp:261]     Train net output #0: loss = 0.176129 (* 1 = 0.176129 loss)
I0502 11:30:09.483613 26473 sgd_solver.cpp:106] Iteration 122400, lr = 6.87195e-06
I0502 11:30:09.488363 26473 solver.cpp:242] Iteration 122400 (105.883 iter/s, 0.944434s/100 iter), loss = 0.126259
I0502 11:30:09.488385 26473 solver.cpp:261]     Train net output #0: loss = 0.126259 (* 1 = 0.126259 loss)
I0502 11:30:09.488402 26473 sgd_solver.cpp:106] Iteration 122400, lr = 6.87195e-06
I0502 11:30:10.424325 26473 solver.cpp:362] Iteration 122500, Testing net (#0)
I0502 11:30:10.424352 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:10.548717 26473 solver.cpp:429]     Test net output #0: loss = 0.233638 (* 1 = 0.233638 loss)
I0502 11:30:10.551579 26473 solver.cpp:242] Iteration 122500 (93.6368 iter/s, 1.06796s/100 iter), loss = 0.636213
I0502 11:30:10.551599 26473 solver.cpp:261]     Train net output #0: loss = 0.636213 (* 1 = 0.636213 loss)
I0502 11:30:10.551606 26473 sgd_solver.cpp:106] Iteration 122500, lr = 6.87195e-06
I0502 11:30:10.553233 26473 solver.cpp:362] Iteration 122500, Testing net (#0)
I0502 11:30:10.553247 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:10.683962 26473 solver.cpp:429]     Test net output #0: accuracy = 0.959
I0502 11:30:10.683984 26473 solver.cpp:429]     Test net output #1: loss = 0.089841 (* 1 = 0.089841 loss)
I0502 11:30:10.686918 26473 solver.cpp:242] Iteration 122500 (83.4368 iter/s, 1.19851s/100 iter), loss = 0.133384
I0502 11:30:10.686939 26473 solver.cpp:261]     Train net output #0: loss = 0.133384 (* 1 = 0.133384 loss)
I0502 11:30:10.686947 26473 sgd_solver.cpp:106] Iteration 122500, lr = 6.87195e-06
I0502 11:30:11.626195 26473 solver.cpp:242] Iteration 122600 (93.0605 iter/s, 1.07457s/100 iter), loss = 0.0552345
I0502 11:30:11.626230 26473 solver.cpp:261]     Train net output #0: loss = 0.0552345 (* 1 = 0.0552345 loss)
I0502 11:30:11.626238 26473 sgd_solver.cpp:106] Iteration 122600, lr = 6.87195e-06
I0502 11:30:11.631079 26473 solver.cpp:242] Iteration 122600 (105.919 iter/s, 0.944114s/100 iter), loss = 0.0935446
I0502 11:30:11.631103 26473 solver.cpp:261]     Train net output #0: loss = 0.0935446 (* 1 = 0.0935446 loss)
I0502 11:30:11.631111 26473 sgd_solver.cpp:106] Iteration 122600, lr = 6.87195e-06
I0502 11:30:12.570935 26473 solver.cpp:242] Iteration 122700 (105.856 iter/s, 0.944683s/100 iter), loss = 0.0927639
I0502 11:30:12.570967 26473 solver.cpp:261]     Train net output #0: loss = 0.0927639 (* 1 = 0.0927639 loss)
I0502 11:30:12.570976 26473 sgd_solver.cpp:106] Iteration 122700, lr = 6.87195e-06
I0502 11:30:12.575821 26473 solver.cpp:242] Iteration 122700 (105.854 iter/s, 0.944693s/100 iter), loss = 0.0768986
I0502 11:30:12.575845 26473 solver.cpp:261]     Train net output #0: loss = 0.0768986 (* 1 = 0.0768986 loss)
I0502 11:30:12.575853 26473 sgd_solver.cpp:106] Iteration 122700, lr = 6.87195e-06
I0502 11:30:13.514497 26473 solver.cpp:242] Iteration 122800 (105.989 iter/s, 0.943498s/100 iter), loss = 0.107112
I0502 11:30:13.514524 26473 solver.cpp:261]     Train net output #0: loss = 0.107112 (* 1 = 0.107112 loss)
I0502 11:30:13.514533 26473 sgd_solver.cpp:106] Iteration 122800, lr = 6.87195e-06
I0502 11:30:13.519366 26473 solver.cpp:242] Iteration 122800 (105.988 iter/s, 0.943501s/100 iter), loss = 0.0890108
I0502 11:30:13.519397 26473 solver.cpp:261]     Train net output #0: loss = 0.0890108 (* 1 = 0.0890108 loss)
I0502 11:30:13.519405 26473 sgd_solver.cpp:106] Iteration 122800, lr = 6.87195e-06
I0502 11:30:14.459633 26473 solver.cpp:242] Iteration 122900 (105.811 iter/s, 0.945078s/100 iter), loss = 0.099511
I0502 11:30:14.459679 26473 solver.cpp:261]     Train net output #0: loss = 0.099511 (* 1 = 0.099511 loss)
I0502 11:30:14.459687 26473 sgd_solver.cpp:106] Iteration 122900, lr = 6.87195e-06
I0502 11:30:14.464447 26473 solver.cpp:242] Iteration 122900 (105.816 iter/s, 0.945033s/100 iter), loss = 0.0510444
I0502 11:30:14.464469 26473 solver.cpp:261]     Train net output #0: loss = 0.0510444 (* 1 = 0.0510444 loss)
I0502 11:30:14.464478 26473 sgd_solver.cpp:106] Iteration 122900, lr = 6.87195e-06
I0502 11:30:15.400645 26473 solver.cpp:362] Iteration 123000, Testing net (#0)
I0502 11:30:15.400673 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:15.525085 26473 solver.cpp:429]     Test net output #0: loss = 0.220474 (* 1 = 0.220474 loss)
I0502 11:30:15.527993 26473 solver.cpp:242] Iteration 123000 (93.607 iter/s, 1.0683s/100 iter), loss = 0.102174
I0502 11:30:15.528024 26473 solver.cpp:261]     Train net output #0: loss = 0.102174 (* 1 = 0.102174 loss)
I0502 11:30:15.528033 26473 sgd_solver.cpp:106] Iteration 123000, lr = 6.87195e-06
I0502 11:30:15.529661 26473 solver.cpp:362] Iteration 123000, Testing net (#0)
I0502 11:30:15.529675 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:15.660269 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:30:15.660290 26473 solver.cpp:429]     Test net output #1: loss = 0.0829677 (* 1 = 0.0829677 loss)
I0502 11:30:15.663218 26473 solver.cpp:242] Iteration 123000 (83.4217 iter/s, 1.19873s/100 iter), loss = 0.129406
I0502 11:30:15.663239 26473 solver.cpp:261]     Train net output #0: loss = 0.129406 (* 1 = 0.129406 loss)
I0502 11:30:15.663247 26473 sgd_solver.cpp:106] Iteration 123000, lr = 6.87195e-06
I0502 11:30:16.602843 26473 solver.cpp:242] Iteration 123100 (93.0413 iter/s, 1.07479s/100 iter), loss = 0.29301
I0502 11:30:16.602885 26473 solver.cpp:261]     Train net output #0: loss = 0.29301 (* 1 = 0.29301 loss)
I0502 11:30:16.602895 26473 sgd_solver.cpp:106] Iteration 123100, lr = 6.87195e-06
I0502 11:30:16.607698 26473 solver.cpp:242] Iteration 123100 (105.883 iter/s, 0.94444s/100 iter), loss = 0.070599
I0502 11:30:16.607722 26473 solver.cpp:261]     Train net output #0: loss = 0.070599 (* 1 = 0.070599 loss)
I0502 11:30:16.607729 26473 sgd_solver.cpp:106] Iteration 123100, lr = 6.87195e-06
I0502 11:30:17.546056 26473 solver.cpp:242] Iteration 123200 (106.028 iter/s, 0.943146s/100 iter), loss = 0.512988
I0502 11:30:17.546098 26473 solver.cpp:261]     Train net output #0: loss = 0.512988 (* 1 = 0.512988 loss)
I0502 11:30:17.546108 26473 sgd_solver.cpp:106] Iteration 123200, lr = 6.87195e-06
I0502 11:30:17.550935 26473 solver.cpp:242] Iteration 123200 (106.023 iter/s, 0.943188s/100 iter), loss = 0.0916652
I0502 11:30:17.550959 26473 solver.cpp:261]     Train net output #0: loss = 0.0916652 (* 1 = 0.0916652 loss)
I0502 11:30:17.550967 26473 sgd_solver.cpp:106] Iteration 123200, lr = 6.87195e-06
I0502 11:30:18.489370 26473 solver.cpp:242] Iteration 123300 (106.018 iter/s, 0.94324s/100 iter), loss = 0.428464
I0502 11:30:18.489413 26473 solver.cpp:261]     Train net output #0: loss = 0.428464 (* 1 = 0.428464 loss)
I0502 11:30:18.489421 26473 sgd_solver.cpp:106] Iteration 123300, lr = 6.87195e-06
I0502 11:30:18.494179 26473 solver.cpp:242] Iteration 123300 (106.022 iter/s, 0.943202s/100 iter), loss = 0.0920694
I0502 11:30:18.494204 26473 solver.cpp:261]     Train net output #0: loss = 0.0920694 (* 1 = 0.0920694 loss)
I0502 11:30:18.494211 26473 sgd_solver.cpp:106] Iteration 123300, lr = 6.87195e-06
I0502 11:30:19.434047 26473 solver.cpp:242] Iteration 123400 (105.864 iter/s, 0.944605s/100 iter), loss = 0.278876
I0502 11:30:19.434092 26473 solver.cpp:261]     Train net output #0: loss = 0.278876 (* 1 = 0.278876 loss)
I0502 11:30:19.434101 26473 sgd_solver.cpp:106] Iteration 123400, lr = 6.87195e-06
I0502 11:30:19.438850 26473 solver.cpp:242] Iteration 123400 (105.862 iter/s, 0.944629s/100 iter), loss = 0.0938824
I0502 11:30:19.438874 26473 solver.cpp:261]     Train net output #0: loss = 0.0938824 (* 1 = 0.0938824 loss)
I0502 11:30:19.438882 26473 sgd_solver.cpp:106] Iteration 123400, lr = 6.87195e-06
I0502 11:30:20.393404 26473 solver.cpp:362] Iteration 123500, Testing net (#0)
I0502 11:30:20.393431 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:20.517747 26473 solver.cpp:429]     Test net output #0: loss = 0.242076 (* 1 = 0.242076 loss)
I0502 11:30:20.520617 26473 solver.cpp:242] Iteration 123500 (92.0382 iter/s, 1.08651s/100 iter), loss = 0.0322566
I0502 11:30:20.520637 26473 solver.cpp:261]     Train net output #0: loss = 0.0322566 (* 1 = 0.0322566 loss)
I0502 11:30:20.520644 26473 sgd_solver.cpp:106] Iteration 123500, lr = 6.87195e-06
I0502 11:30:20.522264 26473 solver.cpp:362] Iteration 123500, Testing net (#0)
I0502 11:30:20.522276 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:20.652977 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:30:20.653020 26473 solver.cpp:429]     Test net output #1: loss = 0.0787315 (* 1 = 0.0787315 loss)
I0502 11:30:20.655942 26473 solver.cpp:242] Iteration 123500 (82.1661 iter/s, 1.21705s/100 iter), loss = 0.0630976
I0502 11:30:20.655963 26473 solver.cpp:261]     Train net output #0: loss = 0.0630976 (* 1 = 0.0630976 loss)
I0502 11:30:20.655972 26473 sgd_solver.cpp:106] Iteration 123500, lr = 6.87195e-06
I0502 11:30:21.596379 26473 solver.cpp:242] Iteration 123600 (92.9616 iter/s, 1.07571s/100 iter), loss = 0.548806
I0502 11:30:21.596426 26473 solver.cpp:261]     Train net output #0: loss = 0.548806 (* 1 = 0.548806 loss)
I0502 11:30:21.596434 26473 sgd_solver.cpp:106] Iteration 123600, lr = 6.87195e-06
I0502 11:30:21.601222 26473 solver.cpp:242] Iteration 123600 (105.793 iter/s, 0.94524s/100 iter), loss = 0.0607794
I0502 11:30:21.601245 26473 solver.cpp:261]     Train net output #0: loss = 0.0607794 (* 1 = 0.0607794 loss)
I0502 11:30:21.601254 26473 sgd_solver.cpp:106] Iteration 123600, lr = 6.87195e-06
I0502 11:30:22.540513 26473 solver.cpp:242] Iteration 123700 (105.925 iter/s, 0.944063s/100 iter), loss = 0.334966
I0502 11:30:22.540558 26473 solver.cpp:261]     Train net output #0: loss = 0.334966 (* 1 = 0.334966 loss)
I0502 11:30:22.540568 26473 sgd_solver.cpp:106] Iteration 123700, lr = 6.87195e-06
I0502 11:30:22.545497 26473 solver.cpp:242] Iteration 123700 (105.907 iter/s, 0.944226s/100 iter), loss = 0.0420984
I0502 11:30:22.545521 26473 solver.cpp:261]     Train net output #0: loss = 0.0420984 (* 1 = 0.0420984 loss)
I0502 11:30:22.545531 26473 sgd_solver.cpp:106] Iteration 123700, lr = 6.87195e-06
I0502 11:30:23.485713 26473 solver.cpp:242] Iteration 123800 (105.806 iter/s, 0.945128s/100 iter), loss = 0.750664
I0502 11:30:23.485754 26473 solver.cpp:261]     Train net output #0: loss = 0.750664 (* 1 = 0.750664 loss)
I0502 11:30:23.485762 26473 sgd_solver.cpp:106] Iteration 123800, lr = 6.87195e-06
I0502 11:30:23.490530 26473 solver.cpp:242] Iteration 123800 (105.821 iter/s, 0.944992s/100 iter), loss = 0.0913221
I0502 11:30:23.490555 26473 solver.cpp:261]     Train net output #0: loss = 0.0913221 (* 1 = 0.0913221 loss)
I0502 11:30:23.490562 26473 sgd_solver.cpp:106] Iteration 123800, lr = 6.87195e-06
I0502 11:30:24.429029 26473 solver.cpp:242] Iteration 123900 (106.017 iter/s, 0.943246s/100 iter), loss = 0.0429802
I0502 11:30:24.429065 26473 solver.cpp:261]     Train net output #0: loss = 0.0429802 (* 1 = 0.0429802 loss)
I0502 11:30:24.429075 26473 sgd_solver.cpp:106] Iteration 123900, lr = 6.87195e-06
I0502 11:30:24.433830 26473 solver.cpp:242] Iteration 123900 (106.016 iter/s, 0.943258s/100 iter), loss = 0.063814
I0502 11:30:24.433851 26473 solver.cpp:261]     Train net output #0: loss = 0.063814 (* 1 = 0.063814 loss)
I0502 11:30:24.433861 26473 sgd_solver.cpp:106] Iteration 123900, lr = 6.87195e-06
I0502 11:30:25.370098 26473 solver.cpp:362] Iteration 124000, Testing net (#0)
I0502 11:30:25.370118 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:25.494545 26473 solver.cpp:429]     Test net output #0: loss = 0.256502 (* 1 = 0.256502 loss)
I0502 11:30:25.497413 26473 solver.cpp:242] Iteration 124000 (93.604 iter/s, 1.06833s/100 iter), loss = 0.0617467
I0502 11:30:25.497433 26473 solver.cpp:261]     Train net output #0: loss = 0.0617467 (* 1 = 0.0617467 loss)
I0502 11:30:25.497442 26473 sgd_solver.cpp:106] Iteration 124000, lr = 6.87195e-06
I0502 11:30:25.499061 26473 solver.cpp:362] Iteration 124000, Testing net (#0)
I0502 11:30:25.499074 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:25.629678 26473 solver.cpp:429]     Test net output #0: accuracy = 0.955
I0502 11:30:25.629699 26473 solver.cpp:429]     Test net output #1: loss = 0.0887653 (* 1 = 0.0887653 loss)
I0502 11:30:25.632614 26473 solver.cpp:242] Iteration 124000 (83.4208 iter/s, 1.19874s/100 iter), loss = 0.0581141
I0502 11:30:25.632634 26473 solver.cpp:261]     Train net output #0: loss = 0.0581141 (* 1 = 0.0581141 loss)
I0502 11:30:25.632643 26473 sgd_solver.cpp:106] Iteration 124000, lr = 6.87195e-06
I0502 11:30:26.571579 26473 solver.cpp:242] Iteration 124100 (93.0996 iter/s, 1.07412s/100 iter), loss = 0.408485
I0502 11:30:26.571609 26473 solver.cpp:261]     Train net output #0: loss = 0.408485 (* 1 = 0.408485 loss)
I0502 11:30:26.571619 26473 sgd_solver.cpp:106] Iteration 124100, lr = 6.87195e-06
I0502 11:30:26.576418 26473 solver.cpp:242] Iteration 124100 (105.959 iter/s, 0.943766s/100 iter), loss = 0.1396
I0502 11:30:26.576442 26473 solver.cpp:261]     Train net output #0: loss = 0.1396 (* 1 = 0.1396 loss)
I0502 11:30:26.576449 26473 sgd_solver.cpp:106] Iteration 124100, lr = 6.87195e-06
I0502 11:30:27.515866 26473 solver.cpp:242] Iteration 124200 (105.906 iter/s, 0.944229s/100 iter), loss = 0.11928
I0502 11:30:27.515913 26473 solver.cpp:261]     Train net output #0: loss = 0.11928 (* 1 = 0.11928 loss)
I0502 11:30:27.515921 26473 sgd_solver.cpp:106] Iteration 124200, lr = 6.87195e-06
I0502 11:30:27.520772 26473 solver.cpp:242] Iteration 124200 (105.898 iter/s, 0.944304s/100 iter), loss = 0.0291801
I0502 11:30:27.520798 26473 solver.cpp:261]     Train net output #0: loss = 0.0291801 (* 1 = 0.0291801 loss)
I0502 11:30:27.520807 26473 sgd_solver.cpp:106] Iteration 124200, lr = 6.87195e-06
I0502 11:30:28.460199 26473 solver.cpp:242] Iteration 124300 (105.904 iter/s, 0.944255s/100 iter), loss = 0.0336115
I0502 11:30:28.460244 26473 solver.cpp:261]     Train net output #0: loss = 0.0336115 (* 1 = 0.0336115 loss)
I0502 11:30:28.460253 26473 sgd_solver.cpp:106] Iteration 124300, lr = 6.87195e-06
I0502 11:30:28.465019 26473 solver.cpp:242] Iteration 124300 (105.909 iter/s, 0.944204s/100 iter), loss = 0.225774
I0502 11:30:28.465042 26473 solver.cpp:261]     Train net output #0: loss = 0.225774 (* 1 = 0.225774 loss)
I0502 11:30:28.465050 26473 sgd_solver.cpp:106] Iteration 124300, lr = 6.87195e-06
I0502 11:30:29.404445 26473 solver.cpp:242] Iteration 124400 (105.913 iter/s, 0.944173s/100 iter), loss = 0.114493
I0502 11:30:29.404489 26473 solver.cpp:261]     Train net output #0: loss = 0.114493 (* 1 = 0.114493 loss)
I0502 11:30:29.404498 26473 sgd_solver.cpp:106] Iteration 124400, lr = 6.87195e-06
I0502 11:30:29.409258 26473 solver.cpp:242] Iteration 124400 (105.91 iter/s, 0.944198s/100 iter), loss = 0.104411
I0502 11:30:29.409281 26473 solver.cpp:261]     Train net output #0: loss = 0.104411 (* 1 = 0.104411 loss)
I0502 11:30:29.409291 26473 sgd_solver.cpp:106] Iteration 124400, lr = 6.87195e-06
I0502 11:30:30.345510 26473 solver.cpp:362] Iteration 124500, Testing net (#0)
I0502 11:30:30.345538 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:30.470010 26473 solver.cpp:429]     Test net output #0: loss = 0.235301 (* 1 = 0.235301 loss)
I0502 11:30:30.472901 26473 solver.cpp:242] Iteration 124500 (93.5984 iter/s, 1.06839s/100 iter), loss = 0.409258
I0502 11:30:30.472923 26473 solver.cpp:261]     Train net output #0: loss = 0.409258 (* 1 = 0.409258 loss)
I0502 11:30:30.472930 26473 sgd_solver.cpp:106] Iteration 124500, lr = 6.87195e-06
I0502 11:30:30.474620 26473 solver.cpp:362] Iteration 124500, Testing net (#0)
I0502 11:30:30.474634 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:30.605329 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:30:30.605352 26473 solver.cpp:429]     Test net output #1: loss = 0.0891888 (* 1 = 0.0891888 loss)
I0502 11:30:30.608273 26473 solver.cpp:242] Iteration 124500 (83.4049 iter/s, 1.19897s/100 iter), loss = 0.097421
I0502 11:30:30.608292 26473 solver.cpp:261]     Train net output #0: loss = 0.097421 (* 1 = 0.097421 loss)
I0502 11:30:30.608301 26473 sgd_solver.cpp:106] Iteration 124500, lr = 6.87195e-06
I0502 11:30:31.547617 26473 solver.cpp:242] Iteration 124600 (93.0522 iter/s, 1.07467s/100 iter), loss = 0.205836
I0502 11:30:31.547674 26473 solver.cpp:261]     Train net output #0: loss = 0.205836 (* 1 = 0.205836 loss)
I0502 11:30:31.547684 26473 sgd_solver.cpp:106] Iteration 124600, lr = 6.87195e-06
I0502 11:30:31.552501 26473 solver.cpp:242] Iteration 124600 (105.911 iter/s, 0.944191s/100 iter), loss = 0.0189428
I0502 11:30:31.552533 26473 solver.cpp:261]     Train net output #0: loss = 0.0189428 (* 1 = 0.0189428 loss)
I0502 11:30:31.552543 26473 sgd_solver.cpp:106] Iteration 124600, lr = 6.87195e-06
I0502 11:30:32.492216 26473 solver.cpp:242] Iteration 124700 (105.874 iter/s, 0.944516s/100 iter), loss = 0.312477
I0502 11:30:32.492255 26473 solver.cpp:261]     Train net output #0: loss = 0.312477 (* 1 = 0.312477 loss)
I0502 11:30:32.492264 26473 sgd_solver.cpp:106] Iteration 124700, lr = 6.87195e-06
I0502 11:30:32.497167 26473 solver.cpp:242] Iteration 124700 (105.864 iter/s, 0.944607s/100 iter), loss = 0.112091
I0502 11:30:32.497191 26473 solver.cpp:261]     Train net output #0: loss = 0.112091 (* 1 = 0.112091 loss)
I0502 11:30:32.497200 26473 sgd_solver.cpp:106] Iteration 124700, lr = 6.87195e-06
I0502 11:30:33.436295 26473 solver.cpp:242] Iteration 124800 (105.931 iter/s, 0.944009s/100 iter), loss = 0.0772139
I0502 11:30:33.436338 26473 solver.cpp:261]     Train net output #0: loss = 0.0772139 (* 1 = 0.0772139 loss)
I0502 11:30:33.436347 26473 sgd_solver.cpp:106] Iteration 124800, lr = 6.87195e-06
I0502 11:30:33.441112 26473 solver.cpp:242] Iteration 124800 (105.943 iter/s, 0.943904s/100 iter), loss = 0.0439406
I0502 11:30:33.441135 26473 solver.cpp:261]     Train net output #0: loss = 0.0439406 (* 1 = 0.0439406 loss)
I0502 11:30:33.441143 26473 sgd_solver.cpp:106] Iteration 124800, lr = 6.87195e-06
I0502 11:30:34.380342 26473 solver.cpp:242] Iteration 124900 (105.935 iter/s, 0.943973s/100 iter), loss = 0.31227
I0502 11:30:34.380383 26473 solver.cpp:261]     Train net output #0: loss = 0.31227 (* 1 = 0.31227 loss)
I0502 11:30:34.380393 26473 sgd_solver.cpp:106] Iteration 124900, lr = 6.87195e-06
I0502 11:30:34.385159 26473 solver.cpp:242] Iteration 124900 (105.932 iter/s, 0.944005s/100 iter), loss = 0.115346
I0502 11:30:34.385182 26473 solver.cpp:261]     Train net output #0: loss = 0.115346 (* 1 = 0.115346 loss)
I0502 11:30:34.385191 26473 sgd_solver.cpp:106] Iteration 124900, lr = 6.87195e-06
I0502 11:30:35.320991 26473 solver.cpp:362] Iteration 125000, Testing net (#0)
I0502 11:30:35.321017 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:35.445430 26473 solver.cpp:429]     Test net output #0: loss = 0.262854 (* 1 = 0.262854 loss)
I0502 11:30:35.448284 26473 solver.cpp:242] Iteration 125000 (93.6432 iter/s, 1.06788s/100 iter), loss = 0.0683956
I0502 11:30:35.448303 26473 solver.cpp:261]     Train net output #0: loss = 0.0683956 (* 1 = 0.0683956 loss)
I0502 11:30:35.448312 26473 sgd_solver.cpp:106] Iteration 125000, lr = 6.87195e-06
I0502 11:30:35.449931 26473 solver.cpp:362] Iteration 125000, Testing net (#0)
I0502 11:30:35.449945 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:35.580518 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:30:35.580539 26473 solver.cpp:429]     Test net output #1: loss = 0.0921653 (* 1 = 0.0921653 loss)
I0502 11:30:35.583473 26473 solver.cpp:242] Iteration 125000 (83.4537 iter/s, 1.19827s/100 iter), loss = 0.176016
I0502 11:30:35.583493 26473 solver.cpp:261]     Train net output #0: loss = 0.176016 (* 1 = 0.176016 loss)
I0502 11:30:35.583501 26473 sgd_solver.cpp:106] Iteration 125000, lr = 6.87195e-06
I0502 11:30:36.522637 26473 solver.cpp:242] Iteration 125100 (93.0836 iter/s, 1.0743s/100 iter), loss = 0.233805
I0502 11:30:36.522677 26473 solver.cpp:261]     Train net output #0: loss = 0.233805 (* 1 = 0.233805 loss)
I0502 11:30:36.522686 26473 sgd_solver.cpp:106] Iteration 125100, lr = 6.87195e-06
I0502 11:30:36.527432 26473 solver.cpp:242] Iteration 125100 (105.941 iter/s, 0.94392s/100 iter), loss = 0.0964501
I0502 11:30:36.527456 26473 solver.cpp:261]     Train net output #0: loss = 0.0964501 (* 1 = 0.0964501 loss)
I0502 11:30:36.527463 26473 sgd_solver.cpp:106] Iteration 125100, lr = 6.87195e-06
I0502 11:30:37.466325 26473 solver.cpp:242] Iteration 125200 (105.974 iter/s, 0.943624s/100 iter), loss = 0.0930211
I0502 11:30:37.466357 26473 solver.cpp:261]     Train net output #0: loss = 0.0930211 (* 1 = 0.0930211 loss)
I0502 11:30:37.466367 26473 sgd_solver.cpp:106] Iteration 125200, lr = 6.87195e-06
I0502 11:30:37.471220 26473 solver.cpp:242] Iteration 125200 (105.962 iter/s, 0.943737s/100 iter), loss = 0.0427216
I0502 11:30:37.471243 26473 solver.cpp:261]     Train net output #0: loss = 0.0427216 (* 1 = 0.0427216 loss)
I0502 11:30:37.471252 26473 sgd_solver.cpp:106] Iteration 125200, lr = 6.87195e-06
I0502 11:30:38.410755 26473 solver.cpp:242] Iteration 125300 (105.89 iter/s, 0.944376s/100 iter), loss = 0.0901269
I0502 11:30:38.410786 26473 solver.cpp:261]     Train net output #0: loss = 0.0901269 (* 1 = 0.0901269 loss)
I0502 11:30:38.410795 26473 sgd_solver.cpp:106] Iteration 125300, lr = 6.87195e-06
I0502 11:30:38.415616 26473 solver.cpp:242] Iteration 125300 (105.893 iter/s, 0.944348s/100 iter), loss = 0.0703839
I0502 11:30:38.415640 26473 solver.cpp:261]     Train net output #0: loss = 0.0703839 (* 1 = 0.0703839 loss)
I0502 11:30:38.415648 26473 sgd_solver.cpp:106] Iteration 125300, lr = 6.87195e-06
I0502 11:30:39.355240 26473 solver.cpp:242] Iteration 125400 (105.885 iter/s, 0.944424s/100 iter), loss = 0.141263
I0502 11:30:39.355285 26473 solver.cpp:261]     Train net output #0: loss = 0.141263 (* 1 = 0.141263 loss)
I0502 11:30:39.355294 26473 sgd_solver.cpp:106] Iteration 125400, lr = 6.87195e-06
I0502 11:30:39.360085 26473 solver.cpp:242] Iteration 125400 (105.884 iter/s, 0.944428s/100 iter), loss = 0.0917196
I0502 11:30:39.360108 26473 solver.cpp:261]     Train net output #0: loss = 0.0917196 (* 1 = 0.0917196 loss)
I0502 11:30:39.360117 26473 sgd_solver.cpp:106] Iteration 125400, lr = 6.87195e-06
I0502 11:30:40.296018 26473 solver.cpp:362] Iteration 125500, Testing net (#0)
I0502 11:30:40.296047 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:40.420390 26473 solver.cpp:429]     Test net output #0: loss = 0.198138 (* 1 = 0.198138 loss)
I0502 11:30:40.423254 26473 solver.cpp:242] Iteration 125500 (93.6372 iter/s, 1.06795s/100 iter), loss = 0.128665
I0502 11:30:40.423274 26473 solver.cpp:261]     Train net output #0: loss = 0.128665 (* 1 = 0.128665 loss)
I0502 11:30:40.423282 26473 sgd_solver.cpp:106] Iteration 125500, lr = 6.87195e-06
I0502 11:30:40.424911 26473 solver.cpp:362] Iteration 125500, Testing net (#0)
I0502 11:30:40.424924 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:40.555408 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:30:40.555430 26473 solver.cpp:429]     Test net output #1: loss = 0.0793029 (* 1 = 0.0793029 loss)
I0502 11:30:40.558357 26473 solver.cpp:242] Iteration 125500 (83.4566 iter/s, 1.19823s/100 iter), loss = 0.0474389
I0502 11:30:40.558377 26473 solver.cpp:261]     Train net output #0: loss = 0.0474389 (* 1 = 0.0474389 loss)
I0502 11:30:40.558385 26473 sgd_solver.cpp:106] Iteration 125500, lr = 6.87195e-06
I0502 11:30:41.497771 26473 solver.cpp:242] Iteration 125600 (93.0692 iter/s, 1.07447s/100 iter), loss = 0.106889
I0502 11:30:41.497800 26473 solver.cpp:261]     Train net output #0: loss = 0.106889 (* 1 = 0.106889 loss)
I0502 11:30:41.497809 26473 sgd_solver.cpp:106] Iteration 125600, lr = 6.87195e-06
I0502 11:30:41.502586 26473 solver.cpp:242] Iteration 125600 (105.911 iter/s, 0.944191s/100 iter), loss = 0.0012142
I0502 11:30:41.502609 26473 solver.cpp:261]     Train net output #0: loss = 0.0012142 (* 1 = 0.0012142 loss)
I0502 11:30:41.502617 26473 sgd_solver.cpp:106] Iteration 125600, lr = 6.87195e-06
I0502 11:30:42.441874 26473 solver.cpp:242] Iteration 125700 (105.927 iter/s, 0.944047s/100 iter), loss = 0.0898076
I0502 11:30:42.441931 26473 solver.cpp:261]     Train net output #0: loss = 0.0898076 (* 1 = 0.0898076 loss)
I0502 11:30:42.441941 26473 sgd_solver.cpp:106] Iteration 125700, lr = 6.87195e-06
I0502 11:30:42.446844 26473 solver.cpp:242] Iteration 125700 (105.909 iter/s, 0.944209s/100 iter), loss = 0.0831282
I0502 11:30:42.446878 26473 solver.cpp:261]     Train net output #0: loss = 0.0831282 (* 1 = 0.0831282 loss)
I0502 11:30:42.446887 26473 sgd_solver.cpp:106] Iteration 125700, lr = 6.87195e-06
I0502 11:30:43.386751 26473 solver.cpp:242] Iteration 125800 (105.843 iter/s, 0.944797s/100 iter), loss = 0.0469796
I0502 11:30:43.386801 26473 solver.cpp:261]     Train net output #0: loss = 0.0469796 (* 1 = 0.0469796 loss)
I0502 11:30:43.386811 26473 sgd_solver.cpp:106] Iteration 125800, lr = 6.87195e-06
I0502 11:30:43.391651 26473 solver.cpp:242] Iteration 125800 (105.848 iter/s, 0.944749s/100 iter), loss = 0.100215
I0502 11:30:43.391675 26473 solver.cpp:261]     Train net output #0: loss = 0.100215 (* 1 = 0.100215 loss)
I0502 11:30:43.391685 26473 sgd_solver.cpp:106] Iteration 125800, lr = 6.87195e-06
I0502 11:30:44.330637 26473 solver.cpp:242] Iteration 125900 (105.954 iter/s, 0.943807s/100 iter), loss = 0.193801
I0502 11:30:44.330679 26473 solver.cpp:261]     Train net output #0: loss = 0.193801 (* 1 = 0.193801 loss)
I0502 11:30:44.330688 26473 sgd_solver.cpp:106] Iteration 125900, lr = 6.87195e-06
I0502 11:30:44.335448 26473 solver.cpp:242] Iteration 125900 (105.96 iter/s, 0.943754s/100 iter), loss = 0.169725
I0502 11:30:44.335470 26473 solver.cpp:261]     Train net output #0: loss = 0.169725 (* 1 = 0.169725 loss)
I0502 11:30:44.335479 26473 sgd_solver.cpp:106] Iteration 125900, lr = 6.87195e-06
I0502 11:30:45.272603 26473 solver.cpp:362] Iteration 126000, Testing net (#0)
I0502 11:30:45.272631 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:45.396975 26473 solver.cpp:429]     Test net output #0: loss = 0.315092 (* 1 = 0.315092 loss)
I0502 11:30:45.399868 26473 solver.cpp:242] Iteration 126000 (93.5305 iter/s, 1.06917s/100 iter), loss = 0.0869693
I0502 11:30:45.399888 26473 solver.cpp:261]     Train net output #0: loss = 0.0869693 (* 1 = 0.0869693 loss)
I0502 11:30:45.399896 26473 sgd_solver.cpp:106] Iteration 126000, lr = 6.87195e-06
I0502 11:30:45.401521 26473 solver.cpp:362] Iteration 126000, Testing net (#0)
I0502 11:30:45.401535 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:45.531939 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:30:45.531960 26473 solver.cpp:429]     Test net output #1: loss = 0.0909095 (* 1 = 0.0909095 loss)
I0502 11:30:45.534881 26473 solver.cpp:242] Iteration 126000 (83.3757 iter/s, 1.19939s/100 iter), loss = 0.121152
I0502 11:30:45.534901 26473 solver.cpp:261]     Train net output #0: loss = 0.121152 (* 1 = 0.121152 loss)
I0502 11:30:45.534910 26473 sgd_solver.cpp:106] Iteration 126000, lr = 6.87195e-06
I0502 11:30:46.473825 26473 solver.cpp:242] Iteration 126100 (93.1179 iter/s, 1.07391s/100 iter), loss = 0.128094
I0502 11:30:46.473868 26473 solver.cpp:261]     Train net output #0: loss = 0.128094 (* 1 = 0.128094 loss)
I0502 11:30:46.473877 26473 sgd_solver.cpp:106] Iteration 126100, lr = 6.87195e-06
I0502 11:30:46.478636 26473 solver.cpp:242] Iteration 126100 (105.964 iter/s, 0.943715s/100 iter), loss = 0.0847673
I0502 11:30:46.478660 26473 solver.cpp:261]     Train net output #0: loss = 0.0847673 (* 1 = 0.0847673 loss)
I0502 11:30:46.478668 26473 sgd_solver.cpp:106] Iteration 126100, lr = 6.87195e-06
I0502 11:30:47.417891 26473 solver.cpp:242] Iteration 126200 (105.933 iter/s, 0.943994s/100 iter), loss = 0.222595
I0502 11:30:47.417932 26473 solver.cpp:261]     Train net output #0: loss = 0.222595 (* 1 = 0.222595 loss)
I0502 11:30:47.417942 26473 sgd_solver.cpp:106] Iteration 126200, lr = 6.87195e-06
I0502 11:30:47.422698 26473 solver.cpp:242] Iteration 126200 (105.93 iter/s, 0.944021s/100 iter), loss = 0.173287
I0502 11:30:47.422721 26473 solver.cpp:261]     Train net output #0: loss = 0.173287 (* 1 = 0.173287 loss)
I0502 11:30:47.422729 26473 sgd_solver.cpp:106] Iteration 126200, lr = 6.87195e-06
I0502 11:30:48.361922 26473 solver.cpp:242] Iteration 126300 (105.936 iter/s, 0.943965s/100 iter), loss = 0.116675
I0502 11:30:48.361959 26473 solver.cpp:261]     Train net output #0: loss = 0.116675 (* 1 = 0.116675 loss)
I0502 11:30:48.361968 26473 sgd_solver.cpp:106] Iteration 126300, lr = 6.87195e-06
I0502 11:30:48.366789 26473 solver.cpp:242] Iteration 126300 (105.927 iter/s, 0.944043s/100 iter), loss = 0.0642254
I0502 11:30:48.366812 26473 solver.cpp:261]     Train net output #0: loss = 0.0642254 (* 1 = 0.0642254 loss)
I0502 11:30:48.366830 26473 sgd_solver.cpp:106] Iteration 126300, lr = 6.87195e-06
I0502 11:30:49.305596 26473 solver.cpp:242] Iteration 126400 (105.976 iter/s, 0.943607s/100 iter), loss = 0.305236
I0502 11:30:49.305634 26473 solver.cpp:261]     Train net output #0: loss = 0.305236 (* 1 = 0.305236 loss)
I0502 11:30:49.305644 26473 sgd_solver.cpp:106] Iteration 126400, lr = 6.87195e-06
I0502 11:30:49.310395 26473 solver.cpp:242] Iteration 126400 (105.981 iter/s, 0.943564s/100 iter), loss = 0.101767
I0502 11:30:49.310417 26473 solver.cpp:261]     Train net output #0: loss = 0.101767 (* 1 = 0.101767 loss)
I0502 11:30:49.310426 26473 sgd_solver.cpp:106] Iteration 126400, lr = 6.87195e-06
I0502 11:30:50.245867 26473 solver.cpp:362] Iteration 126500, Testing net (#0)
I0502 11:30:50.245889 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:50.370381 26473 solver.cpp:429]     Test net output #0: loss = 0.232352 (* 1 = 0.232352 loss)
I0502 11:30:50.373261 26473 solver.cpp:242] Iteration 126500 (93.6673 iter/s, 1.06761s/100 iter), loss = 0.112083
I0502 11:30:50.373281 26473 solver.cpp:261]     Train net output #0: loss = 0.112083 (* 1 = 0.112083 loss)
I0502 11:30:50.373291 26473 sgd_solver.cpp:106] Iteration 126500, lr = 6.87195e-06
I0502 11:30:50.374936 26473 solver.cpp:362] Iteration 126500, Testing net (#0)
I0502 11:30:50.374949 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:50.505549 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:30:50.505581 26473 solver.cpp:429]     Test net output #1: loss = 0.0812991 (* 1 = 0.0812991 loss)
I0502 11:30:50.508496 26473 solver.cpp:242] Iteration 126500 (83.4685 iter/s, 1.19806s/100 iter), loss = 0.0123865
I0502 11:30:50.508514 26473 solver.cpp:261]     Train net output #0: loss = 0.0123865 (* 1 = 0.0123865 loss)
I0502 11:30:50.508523 26473 sgd_solver.cpp:106] Iteration 126500, lr = 6.87195e-06
I0502 11:30:51.448556 26473 solver.cpp:242] Iteration 126600 (93.0025 iter/s, 1.07524s/100 iter), loss = 0.174934
I0502 11:30:51.448598 26473 solver.cpp:261]     Train net output #0: loss = 0.174934 (* 1 = 0.174934 loss)
I0502 11:30:51.448606 26473 sgd_solver.cpp:106] Iteration 126600, lr = 6.87195e-06
I0502 11:30:51.453373 26473 solver.cpp:242] Iteration 126600 (105.838 iter/s, 0.944841s/100 iter), loss = 0.0911868
I0502 11:30:51.453397 26473 solver.cpp:261]     Train net output #0: loss = 0.0911868 (* 1 = 0.0911868 loss)
I0502 11:30:51.453405 26473 sgd_solver.cpp:106] Iteration 126600, lr = 6.87195e-06
I0502 11:30:52.392606 26473 solver.cpp:242] Iteration 126700 (105.934 iter/s, 0.943984s/100 iter), loss = 0.262211
I0502 11:30:52.392642 26473 solver.cpp:261]     Train net output #0: loss = 0.262211 (* 1 = 0.262211 loss)
I0502 11:30:52.392650 26473 sgd_solver.cpp:106] Iteration 126700, lr = 6.87195e-06
I0502 11:30:52.397420 26473 solver.cpp:242] Iteration 126700 (105.932 iter/s, 0.944006s/100 iter), loss = 0.0385755
I0502 11:30:52.397444 26473 solver.cpp:261]     Train net output #0: loss = 0.0385755 (* 1 = 0.0385755 loss)
I0502 11:30:52.397451 26473 sgd_solver.cpp:106] Iteration 126700, lr = 6.87195e-06
I0502 11:30:53.338008 26473 solver.cpp:242] Iteration 126800 (105.782 iter/s, 0.945342s/100 iter), loss = 0.0873283
I0502 11:30:53.338044 26473 solver.cpp:261]     Train net output #0: loss = 0.0873283 (* 1 = 0.0873283 loss)
I0502 11:30:53.338053 26473 sgd_solver.cpp:106] Iteration 126800, lr = 6.87195e-06
I0502 11:30:53.342871 26473 solver.cpp:242] Iteration 126800 (105.775 iter/s, 0.945401s/100 iter), loss = 0.111457
I0502 11:30:53.342895 26473 solver.cpp:261]     Train net output #0: loss = 0.111457 (* 1 = 0.111457 loss)
I0502 11:30:53.342902 26473 sgd_solver.cpp:106] Iteration 126800, lr = 6.87195e-06
I0502 11:30:54.283151 26473 solver.cpp:242] Iteration 126900 (105.811 iter/s, 0.945077s/100 iter), loss = 0.0586155
I0502 11:30:54.283181 26473 solver.cpp:261]     Train net output #0: loss = 0.0586155 (* 1 = 0.0586155 loss)
I0502 11:30:54.283190 26473 sgd_solver.cpp:106] Iteration 126900, lr = 6.87195e-06
I0502 11:30:54.287968 26473 solver.cpp:242] Iteration 126900 (105.814 iter/s, 0.945057s/100 iter), loss = 0.055166
I0502 11:30:54.287992 26473 solver.cpp:261]     Train net output #0: loss = 0.055166 (* 1 = 0.055166 loss)
I0502 11:30:54.287999 26473 sgd_solver.cpp:106] Iteration 126900, lr = 6.87195e-06
I0502 11:30:55.224409 26473 solver.cpp:362] Iteration 127000, Testing net (#0)
I0502 11:30:55.224436 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:55.348758 26473 solver.cpp:429]     Test net output #0: loss = 0.250377 (* 1 = 0.250377 loss)
I0502 11:30:55.351613 26473 solver.cpp:242] Iteration 127000 (93.5968 iter/s, 1.06841s/100 iter), loss = 0.236312
I0502 11:30:55.351634 26473 solver.cpp:261]     Train net output #0: loss = 0.236312 (* 1 = 0.236312 loss)
I0502 11:30:55.351641 26473 sgd_solver.cpp:106] Iteration 127000, lr = 6.87195e-06
I0502 11:30:55.353262 26473 solver.cpp:362] Iteration 127000, Testing net (#0)
I0502 11:30:55.353276 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:30:55.483889 26473 solver.cpp:429]     Test net output #0: accuracy = 0.967
I0502 11:30:55.483911 26473 solver.cpp:429]     Test net output #1: loss = 0.0791808 (* 1 = 0.0791808 loss)
I0502 11:30:55.486816 26473 solver.cpp:242] Iteration 127000 (83.4164 iter/s, 1.19881s/100 iter), loss = 0.136514
I0502 11:30:55.486836 26473 solver.cpp:261]     Train net output #0: loss = 0.136514 (* 1 = 0.136514 loss)
I0502 11:30:55.486845 26473 sgd_solver.cpp:106] Iteration 127000, lr = 6.87195e-06
I0502 11:30:56.426481 26473 solver.cpp:242] Iteration 127100 (93.039 iter/s, 1.07482s/100 iter), loss = 0.144789
I0502 11:30:56.426514 26473 solver.cpp:261]     Train net output #0: loss = 0.144789 (* 1 = 0.144789 loss)
I0502 11:30:56.426522 26473 sgd_solver.cpp:106] Iteration 127100, lr = 6.87195e-06
I0502 11:30:56.431280 26473 solver.cpp:242] Iteration 127100 (105.884 iter/s, 0.944426s/100 iter), loss = 0.0285911
I0502 11:30:56.431303 26473 solver.cpp:261]     Train net output #0: loss = 0.0285911 (* 1 = 0.0285911 loss)
I0502 11:30:56.431311 26473 sgd_solver.cpp:106] Iteration 127100, lr = 6.87195e-06
I0502 11:30:57.371248 26473 solver.cpp:242] Iteration 127200 (105.853 iter/s, 0.94471s/100 iter), loss = 0.0815896
I0502 11:30:57.371284 26473 solver.cpp:261]     Train net output #0: loss = 0.0815896 (* 1 = 0.0815896 loss)
I0502 11:30:57.371294 26473 sgd_solver.cpp:106] Iteration 127200, lr = 6.87195e-06
I0502 11:30:57.376060 26473 solver.cpp:242] Iteration 127200 (105.849 iter/s, 0.94474s/100 iter), loss = 0.146085
I0502 11:30:57.376082 26473 solver.cpp:261]     Train net output #0: loss = 0.146085 (* 1 = 0.146085 loss)
I0502 11:30:57.376091 26473 sgd_solver.cpp:106] Iteration 127200, lr = 6.87195e-06
I0502 11:30:58.315950 26473 solver.cpp:242] Iteration 127300 (105.86 iter/s, 0.944642s/100 iter), loss = 0.277661
I0502 11:30:58.316006 26473 solver.cpp:261]     Train net output #0: loss = 0.277661 (* 1 = 0.277661 loss)
I0502 11:30:58.316015 26473 sgd_solver.cpp:106] Iteration 127300, lr = 6.87195e-06
I0502 11:30:58.320940 26473 solver.cpp:242] Iteration 127300 (105.839 iter/s, 0.944829s/100 iter), loss = 0.00248411
I0502 11:30:58.320963 26473 solver.cpp:261]     Train net output #0: loss = 0.00248411 (* 1 = 0.00248411 loss)
I0502 11:30:58.320972 26473 sgd_solver.cpp:106] Iteration 127300, lr = 6.87195e-06
I0502 11:30:59.261046 26473 solver.cpp:242] Iteration 127400 (105.819 iter/s, 0.945008s/100 iter), loss = 0.23432
I0502 11:30:59.261087 26473 solver.cpp:261]     Train net output #0: loss = 0.23432 (* 1 = 0.23432 loss)
I0502 11:30:59.261096 26473 sgd_solver.cpp:106] Iteration 127400, lr = 6.87195e-06
I0502 11:30:59.265856 26473 solver.cpp:242] Iteration 127400 (105.834 iter/s, 0.944875s/100 iter), loss = 0.0632511
I0502 11:30:59.265878 26473 solver.cpp:261]     Train net output #0: loss = 0.0632511 (* 1 = 0.0632511 loss)
I0502 11:30:59.265887 26473 sgd_solver.cpp:106] Iteration 127400, lr = 6.87195e-06
I0502 11:31:00.202286 26473 solver.cpp:362] Iteration 127500, Testing net (#0)
I0502 11:31:00.202327 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:00.331746 26473 solver.cpp:429]     Test net output #0: loss = 0.261202 (* 1 = 0.261202 loss)
I0502 11:31:00.334640 26473 solver.cpp:242] Iteration 127500 (93.1502 iter/s, 1.07353s/100 iter), loss = 0.190806
I0502 11:31:00.334661 26473 solver.cpp:261]     Train net output #0: loss = 0.190806 (* 1 = 0.190806 loss)
I0502 11:31:00.334671 26473 sgd_solver.cpp:106] Iteration 127500, lr = 6.87195e-06
I0502 11:31:00.336452 26473 solver.cpp:362] Iteration 127500, Testing net (#0)
I0502 11:31:00.336467 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:00.467521 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9645
I0502 11:31:00.467542 26473 solver.cpp:429]     Test net output #1: loss = 0.0793122 (* 1 = 0.0793122 loss)
I0502 11:31:00.470486 26473 solver.cpp:242] Iteration 127500 (83.016 iter/s, 1.20459s/100 iter), loss = 0.0774871
I0502 11:31:00.470506 26473 solver.cpp:261]     Train net output #0: loss = 0.0774871 (* 1 = 0.0774871 loss)
I0502 11:31:00.470515 26473 sgd_solver.cpp:106] Iteration 127500, lr = 6.87195e-06
I0502 11:31:01.410063 26473 solver.cpp:242] Iteration 127600 (92.9913 iter/s, 1.07537s/100 iter), loss = 0.650238
I0502 11:31:01.410105 26473 solver.cpp:261]     Train net output #0: loss = 0.650238 (* 1 = 0.650238 loss)
I0502 11:31:01.410115 26473 sgd_solver.cpp:106] Iteration 127600, lr = 6.87195e-06
I0502 11:31:01.414857 26473 solver.cpp:242] Iteration 127600 (105.895 iter/s, 0.944334s/100 iter), loss = 0.0290795
I0502 11:31:01.414880 26473 solver.cpp:261]     Train net output #0: loss = 0.0290795 (* 1 = 0.0290795 loss)
I0502 11:31:01.414890 26473 sgd_solver.cpp:106] Iteration 127600, lr = 6.87195e-06
I0502 11:31:02.354185 26473 solver.cpp:242] Iteration 127700 (105.926 iter/s, 0.944054s/100 iter), loss = 0.125921
I0502 11:31:02.354228 26473 solver.cpp:261]     Train net output #0: loss = 0.125921 (* 1 = 0.125921 loss)
I0502 11:31:02.354235 26473 sgd_solver.cpp:106] Iteration 127700, lr = 6.87195e-06
I0502 11:31:02.359015 26473 solver.cpp:242] Iteration 127700 (105.919 iter/s, 0.944116s/100 iter), loss = 0.0354528
I0502 11:31:02.359038 26473 solver.cpp:261]     Train net output #0: loss = 0.0354528 (* 1 = 0.0354528 loss)
I0502 11:31:02.359047 26473 sgd_solver.cpp:106] Iteration 127700, lr = 6.87195e-06
I0502 11:31:03.298435 26473 solver.cpp:242] Iteration 127800 (105.912 iter/s, 0.944182s/100 iter), loss = 0.316731
I0502 11:31:03.298475 26473 solver.cpp:261]     Train net output #0: loss = 0.316731 (* 1 = 0.316731 loss)
I0502 11:31:03.298483 26473 sgd_solver.cpp:106] Iteration 127800, lr = 6.87195e-06
I0502 11:31:03.303308 26473 solver.cpp:242] Iteration 127800 (105.905 iter/s, 0.944242s/100 iter), loss = 0.0731261
I0502 11:31:03.303330 26473 solver.cpp:261]     Train net output #0: loss = 0.0731261 (* 1 = 0.0731261 loss)
I0502 11:31:03.303339 26473 sgd_solver.cpp:106] Iteration 127800, lr = 6.87195e-06
I0502 11:31:04.242697 26473 solver.cpp:242] Iteration 127900 (105.911 iter/s, 0.944191s/100 iter), loss = 0.175289
I0502 11:31:04.242733 26473 solver.cpp:261]     Train net output #0: loss = 0.175289 (* 1 = 0.175289 loss)
I0502 11:31:04.242743 26473 sgd_solver.cpp:106] Iteration 127900, lr = 6.87195e-06
I0502 11:31:04.247511 26473 solver.cpp:242] Iteration 127900 (105.914 iter/s, 0.944163s/100 iter), loss = 0.0439123
I0502 11:31:04.247534 26473 solver.cpp:261]     Train net output #0: loss = 0.0439123 (* 1 = 0.0439123 loss)
I0502 11:31:04.247542 26473 sgd_solver.cpp:106] Iteration 127900, lr = 6.87195e-06
I0502 11:31:05.184250 26473 solver.cpp:362] Iteration 128000, Testing net (#0)
I0502 11:31:05.184276 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:05.308513 26473 solver.cpp:429]     Test net output #0: loss = 0.248777 (* 1 = 0.248777 loss)
I0502 11:31:05.311405 26473 solver.cpp:242] Iteration 128000 (93.5757 iter/s, 1.06865s/100 iter), loss = 0.231331
I0502 11:31:05.311426 26473 solver.cpp:261]     Train net output #0: loss = 0.231331 (* 1 = 0.231331 loss)
I0502 11:31:05.311434 26473 sgd_solver.cpp:106] Iteration 128000, lr = 6.87195e-06
I0502 11:31:05.313078 26473 solver.cpp:362] Iteration 128000, Testing net (#0)
I0502 11:31:05.313092 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:05.443769 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:31:05.443791 26473 solver.cpp:429]     Test net output #1: loss = 0.0824782 (* 1 = 0.0824782 loss)
I0502 11:31:05.446722 26473 solver.cpp:242] Iteration 128000 (83.3913 iter/s, 1.19917s/100 iter), loss = 0.00199332
I0502 11:31:05.446743 26473 solver.cpp:261]     Train net output #0: loss = 0.00199332 (* 1 = 0.00199332 loss)
I0502 11:31:05.446750 26473 sgd_solver.cpp:106] Iteration 128000, lr = 6.87195e-06
I0502 11:31:06.386991 26473 solver.cpp:242] Iteration 128100 (92.9771 iter/s, 1.07553s/100 iter), loss = 0.124666
I0502 11:31:06.387032 26473 solver.cpp:261]     Train net output #0: loss = 0.124666 (* 1 = 0.124666 loss)
I0502 11:31:06.387040 26473 sgd_solver.cpp:106] Iteration 128100, lr = 6.87195e-06
I0502 11:31:06.391835 26473 solver.cpp:242] Iteration 128100 (105.812 iter/s, 0.945074s/100 iter), loss = 0.024799
I0502 11:31:06.391860 26473 solver.cpp:261]     Train net output #0: loss = 0.024799 (* 1 = 0.024799 loss)
I0502 11:31:06.391868 26473 sgd_solver.cpp:106] Iteration 128100, lr = 6.87195e-06
I0502 11:31:07.330934 26473 solver.cpp:242] Iteration 128200 (105.946 iter/s, 0.943876s/100 iter), loss = 0.110177
I0502 11:31:07.330972 26473 solver.cpp:261]     Train net output #0: loss = 0.110177 (* 1 = 0.110177 loss)
I0502 11:31:07.330981 26473 sgd_solver.cpp:106] Iteration 128200, lr = 6.87195e-06
I0502 11:31:07.335741 26473 solver.cpp:242] Iteration 128200 (105.947 iter/s, 0.943864s/100 iter), loss = 0.175971
I0502 11:31:07.335763 26473 solver.cpp:261]     Train net output #0: loss = 0.175971 (* 1 = 0.175971 loss)
I0502 11:31:07.335772 26473 sgd_solver.cpp:106] Iteration 128200, lr = 6.87195e-06
I0502 11:31:08.274195 26473 solver.cpp:242] Iteration 128300 (106.022 iter/s, 0.943199s/100 iter), loss = 0.116641
I0502 11:31:08.274227 26473 solver.cpp:261]     Train net output #0: loss = 0.116641 (* 1 = 0.116641 loss)
I0502 11:31:08.274236 26473 sgd_solver.cpp:106] Iteration 128300, lr = 6.87195e-06
I0502 11:31:08.279036 26473 solver.cpp:242] Iteration 128300 (106.017 iter/s, 0.943244s/100 iter), loss = 0.00599748
I0502 11:31:08.279057 26473 solver.cpp:261]     Train net output #0: loss = 0.00599748 (* 1 = 0.00599748 loss)
I0502 11:31:08.279067 26473 sgd_solver.cpp:106] Iteration 128300, lr = 6.87195e-06
I0502 11:31:09.218852 26473 solver.cpp:242] Iteration 128400 (105.865 iter/s, 0.944601s/100 iter), loss = 0.141066
I0502 11:31:09.218910 26473 solver.cpp:261]     Train net output #0: loss = 0.141066 (* 1 = 0.141066 loss)
I0502 11:31:09.218924 26473 sgd_solver.cpp:106] Iteration 128400, lr = 6.87195e-06
I0502 11:31:09.223789 26473 solver.cpp:242] Iteration 128400 (105.853 iter/s, 0.944708s/100 iter), loss = 0.0287456
I0502 11:31:09.223814 26473 solver.cpp:261]     Train net output #0: loss = 0.0287456 (* 1 = 0.0287456 loss)
I0502 11:31:09.223824 26473 sgd_solver.cpp:106] Iteration 128400, lr = 6.87195e-06
I0502 11:31:10.160091 26473 solver.cpp:362] Iteration 128500, Testing net (#0)
I0502 11:31:10.160117 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:10.284425 26473 solver.cpp:429]     Test net output #0: loss = 0.267696 (* 1 = 0.267696 loss)
I0502 11:31:10.287297 26473 solver.cpp:242] Iteration 128500 (93.6006 iter/s, 1.06837s/100 iter), loss = 0.286295
I0502 11:31:10.287317 26473 solver.cpp:261]     Train net output #0: loss = 0.286295 (* 1 = 0.286295 loss)
I0502 11:31:10.287325 26473 sgd_solver.cpp:106] Iteration 128500, lr = 6.87195e-06
I0502 11:31:10.288961 26473 solver.cpp:362] Iteration 128500, Testing net (#0)
I0502 11:31:10.288975 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:10.419761 26473 solver.cpp:429]     Test net output #0: accuracy = 0.973
I0502 11:31:10.419782 26473 solver.cpp:429]     Test net output #1: loss = 0.0688214 (* 1 = 0.0688214 loss)
I0502 11:31:10.422703 26473 solver.cpp:242] Iteration 128500 (83.4121 iter/s, 1.19887s/100 iter), loss = 0.0535092
I0502 11:31:10.422735 26473 solver.cpp:261]     Train net output #0: loss = 0.0535092 (* 1 = 0.0535092 loss)
I0502 11:31:10.422744 26473 sgd_solver.cpp:106] Iteration 128500, lr = 6.87195e-06
I0502 11:31:11.361960 26473 solver.cpp:242] Iteration 128600 (93.0569 iter/s, 1.07461s/100 iter), loss = 0.0748076
I0502 11:31:11.362002 26473 solver.cpp:261]     Train net output #0: loss = 0.0748076 (* 1 = 0.0748076 loss)
I0502 11:31:11.362011 26473 sgd_solver.cpp:106] Iteration 128600, lr = 6.87195e-06
I0502 11:31:11.366796 26473 solver.cpp:242] Iteration 128600 (105.927 iter/s, 0.944043s/100 iter), loss = 0.0203623
I0502 11:31:11.366821 26473 solver.cpp:261]     Train net output #0: loss = 0.0203623 (* 1 = 0.0203623 loss)
I0502 11:31:11.366828 26473 sgd_solver.cpp:106] Iteration 128600, lr = 6.87195e-06
I0502 11:31:12.306684 26473 solver.cpp:242] Iteration 128700 (105.859 iter/s, 0.944651s/100 iter), loss = 0.078129
I0502 11:31:12.306727 26473 solver.cpp:261]     Train net output #0: loss = 0.078129 (* 1 = 0.078129 loss)
I0502 11:31:12.306736 26473 sgd_solver.cpp:106] Iteration 128700, lr = 6.87195e-06
I0502 11:31:12.311511 26473 solver.cpp:242] Iteration 128700 (105.857 iter/s, 0.944674s/100 iter), loss = 0.0839554
I0502 11:31:12.311534 26473 solver.cpp:261]     Train net output #0: loss = 0.0839554 (* 1 = 0.0839554 loss)
I0502 11:31:12.311543 26473 sgd_solver.cpp:106] Iteration 128700, lr = 6.87195e-06
I0502 11:31:13.250804 26473 solver.cpp:242] Iteration 128800 (105.926 iter/s, 0.944052s/100 iter), loss = 0.245595
I0502 11:31:13.250847 26473 solver.cpp:261]     Train net output #0: loss = 0.245595 (* 1 = 0.245595 loss)
I0502 11:31:13.250856 26473 sgd_solver.cpp:106] Iteration 128800, lr = 6.87195e-06
I0502 11:31:13.255609 26473 solver.cpp:242] Iteration 128800 (105.926 iter/s, 0.944055s/100 iter), loss = 0.0881369
I0502 11:31:13.255630 26473 solver.cpp:261]     Train net output #0: loss = 0.0881369 (* 1 = 0.0881369 loss)
I0502 11:31:13.255640 26473 sgd_solver.cpp:106] Iteration 128800, lr = 6.87195e-06
I0502 11:31:14.194504 26473 solver.cpp:242] Iteration 128900 (105.973 iter/s, 0.943632s/100 iter), loss = 0.0983501
I0502 11:31:14.194541 26473 solver.cpp:261]     Train net output #0: loss = 0.0983501 (* 1 = 0.0983501 loss)
I0502 11:31:14.194550 26473 sgd_solver.cpp:106] Iteration 128900, lr = 6.87195e-06
I0502 11:31:14.199352 26473 solver.cpp:242] Iteration 128900 (105.966 iter/s, 0.943695s/100 iter), loss = 0.107603
I0502 11:31:14.199375 26473 solver.cpp:261]     Train net output #0: loss = 0.107603 (* 1 = 0.107603 loss)
I0502 11:31:14.199384 26473 sgd_solver.cpp:106] Iteration 128900, lr = 6.87195e-06
I0502 11:31:15.135874 26473 solver.cpp:362] Iteration 129000, Testing net (#0)
I0502 11:31:15.135900 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:15.260381 26473 solver.cpp:429]     Test net output #0: loss = 0.210374 (* 1 = 0.210374 loss)
I0502 11:31:15.263272 26473 solver.cpp:242] Iteration 129000 (93.5707 iter/s, 1.06871s/100 iter), loss = 0.116687
I0502 11:31:15.263291 26473 solver.cpp:261]     Train net output #0: loss = 0.116687 (* 1 = 0.116687 loss)
I0502 11:31:15.263299 26473 sgd_solver.cpp:106] Iteration 129000, lr = 6.87195e-06
I0502 11:31:15.264971 26473 solver.cpp:362] Iteration 129000, Testing net (#0)
I0502 11:31:15.264983 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:15.395761 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:31:15.395782 26473 solver.cpp:429]     Test net output #1: loss = 0.0936862 (* 1 = 0.0936862 loss)
I0502 11:31:15.398710 26473 solver.cpp:242] Iteration 129000 (83.3811 iter/s, 1.19931s/100 iter), loss = 0.0372598
I0502 11:31:15.398730 26473 solver.cpp:261]     Train net output #0: loss = 0.0372598 (* 1 = 0.0372598 loss)
I0502 11:31:15.398738 26473 sgd_solver.cpp:106] Iteration 129000, lr = 6.87195e-06
I0502 11:31:16.338471 26473 solver.cpp:242] Iteration 129100 (93.0105 iter/s, 1.07515s/100 iter), loss = 0.492308
I0502 11:31:16.338512 26473 solver.cpp:261]     Train net output #0: loss = 0.492308 (* 1 = 0.492308 loss)
I0502 11:31:16.338532 26473 sgd_solver.cpp:106] Iteration 129100, lr = 6.87195e-06
I0502 11:31:16.343289 26473 solver.cpp:242] Iteration 129100 (105.871 iter/s, 0.944542s/100 iter), loss = 0.119482
I0502 11:31:16.343312 26473 solver.cpp:261]     Train net output #0: loss = 0.119482 (* 1 = 0.119482 loss)
I0502 11:31:16.343322 26473 sgd_solver.cpp:106] Iteration 129100, lr = 6.87195e-06
I0502 11:31:17.281889 26473 solver.cpp:242] Iteration 129200 (106.005 iter/s, 0.94335s/100 iter), loss = 0.386567
I0502 11:31:17.281929 26473 solver.cpp:261]     Train net output #0: loss = 0.386567 (* 1 = 0.386567 loss)
I0502 11:31:17.281936 26473 sgd_solver.cpp:106] Iteration 129200, lr = 6.87195e-06
I0502 11:31:17.286692 26473 solver.cpp:242] Iteration 129200 (106.004 iter/s, 0.943361s/100 iter), loss = 0.0540706
I0502 11:31:17.286715 26473 solver.cpp:261]     Train net output #0: loss = 0.0540706 (* 1 = 0.0540706 loss)
I0502 11:31:17.286723 26473 sgd_solver.cpp:106] Iteration 129200, lr = 6.87195e-06
I0502 11:31:18.226495 26473 solver.cpp:242] Iteration 129300 (105.871 iter/s, 0.944542s/100 iter), loss = 0.251237
I0502 11:31:18.226534 26473 solver.cpp:261]     Train net output #0: loss = 0.251237 (* 1 = 0.251237 loss)
I0502 11:31:18.226543 26473 sgd_solver.cpp:106] Iteration 129300, lr = 6.87195e-06
I0502 11:31:18.231302 26473 solver.cpp:242] Iteration 129300 (105.868 iter/s, 0.944568s/100 iter), loss = 0.0953493
I0502 11:31:18.231325 26473 solver.cpp:261]     Train net output #0: loss = 0.0953493 (* 1 = 0.0953493 loss)
I0502 11:31:18.231333 26473 sgd_solver.cpp:106] Iteration 129300, lr = 6.87195e-06
I0502 11:31:19.170016 26473 solver.cpp:242] Iteration 129400 (105.993 iter/s, 0.943457s/100 iter), loss = 0.571323
I0502 11:31:19.170047 26473 solver.cpp:261]     Train net output #0: loss = 0.571323 (* 1 = 0.571323 loss)
I0502 11:31:19.170055 26473 sgd_solver.cpp:106] Iteration 129400, lr = 6.87195e-06
I0502 11:31:19.174887 26473 solver.cpp:242] Iteration 129400 (105.984 iter/s, 0.943536s/100 iter), loss = 0.0613241
I0502 11:31:19.174909 26473 solver.cpp:261]     Train net output #0: loss = 0.0613241 (* 1 = 0.0613241 loss)
I0502 11:31:19.174918 26473 sgd_solver.cpp:106] Iteration 129400, lr = 6.87195e-06
I0502 11:31:20.111286 26473 solver.cpp:362] Iteration 129500, Testing net (#0)
I0502 11:31:20.111328 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:20.235749 26473 solver.cpp:429]     Test net output #0: loss = 0.182526 (* 1 = 0.182526 loss)
I0502 11:31:20.238637 26473 solver.cpp:242] Iteration 129500 (93.5829 iter/s, 1.06857s/100 iter), loss = 0.0540449
I0502 11:31:20.238657 26473 solver.cpp:261]     Train net output #0: loss = 0.0540449 (* 1 = 0.0540449 loss)
I0502 11:31:20.238665 26473 sgd_solver.cpp:106] Iteration 129500, lr = 6.87195e-06
I0502 11:31:20.240284 26473 solver.cpp:362] Iteration 129500, Testing net (#0)
I0502 11:31:20.240298 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:20.371033 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:31:20.371054 26473 solver.cpp:429]     Test net output #1: loss = 0.0815181 (* 1 = 0.0815181 loss)
I0502 11:31:20.373975 26473 solver.cpp:242] Iteration 129500 (83.3997 iter/s, 1.19904s/100 iter), loss = 0.121759
I0502 11:31:20.373996 26473 solver.cpp:261]     Train net output #0: loss = 0.121759 (* 1 = 0.121759 loss)
I0502 11:31:20.374003 26473 sgd_solver.cpp:106] Iteration 129500, lr = 6.87195e-06
I0502 11:31:21.313063 26473 solver.cpp:242] Iteration 129600 (93.0777 iter/s, 1.07437s/100 iter), loss = 0.168352
I0502 11:31:21.313108 26473 solver.cpp:261]     Train net output #0: loss = 0.168352 (* 1 = 0.168352 loss)
I0502 11:31:21.313118 26473 sgd_solver.cpp:106] Iteration 129600, lr = 6.87195e-06
I0502 11:31:21.317900 26473 solver.cpp:242] Iteration 129600 (105.945 iter/s, 0.943886s/100 iter), loss = 0.233484
I0502 11:31:21.317924 26473 solver.cpp:261]     Train net output #0: loss = 0.233484 (* 1 = 0.233484 loss)
I0502 11:31:21.317931 26473 sgd_solver.cpp:106] Iteration 129600, lr = 6.87195e-06
I0502 11:31:22.258234 26473 solver.cpp:242] Iteration 129700 (105.809 iter/s, 0.945101s/100 iter), loss = 0.104842
I0502 11:31:22.258271 26473 solver.cpp:261]     Train net output #0: loss = 0.104842 (* 1 = 0.104842 loss)
I0502 11:31:22.258280 26473 sgd_solver.cpp:106] Iteration 129700, lr = 6.87195e-06
I0502 11:31:22.263092 26473 solver.cpp:242] Iteration 129700 (105.803 iter/s, 0.945151s/100 iter), loss = 0.161157
I0502 11:31:22.263115 26473 solver.cpp:261]     Train net output #0: loss = 0.161157 (* 1 = 0.161157 loss)
I0502 11:31:22.263124 26473 sgd_solver.cpp:106] Iteration 129700, lr = 6.87195e-06
I0502 11:31:23.202067 26473 solver.cpp:242] Iteration 129800 (105.958 iter/s, 0.94377s/100 iter), loss = 0.18211
I0502 11:31:23.202111 26473 solver.cpp:261]     Train net output #0: loss = 0.18211 (* 1 = 0.18211 loss)
I0502 11:31:23.202119 26473 sgd_solver.cpp:106] Iteration 129800, lr = 6.87195e-06
I0502 11:31:23.206907 26473 solver.cpp:242] Iteration 129800 (105.958 iter/s, 0.943772s/100 iter), loss = 0.0176144
I0502 11:31:23.206929 26473 solver.cpp:261]     Train net output #0: loss = 0.0176144 (* 1 = 0.0176144 loss)
I0502 11:31:23.206938 26473 sgd_solver.cpp:106] Iteration 129800, lr = 6.87195e-06
I0502 11:31:24.146303 26473 solver.cpp:242] Iteration 129900 (105.913 iter/s, 0.944168s/100 iter), loss = 0.0567933
I0502 11:31:24.146348 26473 solver.cpp:261]     Train net output #0: loss = 0.0567933 (* 1 = 0.0567933 loss)
I0502 11:31:24.146358 26473 sgd_solver.cpp:106] Iteration 129900, lr = 6.87195e-06
I0502 11:31:24.151183 26473 solver.cpp:242] Iteration 129900 (105.907 iter/s, 0.944227s/100 iter), loss = 0.0920387
I0502 11:31:24.151206 26473 solver.cpp:261]     Train net output #0: loss = 0.0920387 (* 1 = 0.0920387 loss)
I0502 11:31:24.151216 26473 sgd_solver.cpp:106] Iteration 129900, lr = 6.87195e-06
I0502 11:31:25.087357 26473 solver.cpp:362] Iteration 130000, Testing net (#0)
I0502 11:31:25.087383 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:25.211724 26473 solver.cpp:429]     Test net output #0: loss = 0.280577 (* 1 = 0.280577 loss)
I0502 11:31:25.214610 26473 solver.cpp:242] Iteration 130000 (93.6115 iter/s, 1.06825s/100 iter), loss = 0.259504
I0502 11:31:25.214632 26473 solver.cpp:261]     Train net output #0: loss = 0.259504 (* 1 = 0.259504 loss)
I0502 11:31:25.214639 26473 sgd_solver.cpp:106] Iteration 130000, lr = 5.49756e-06
I0502 11:31:25.216255 26473 solver.cpp:362] Iteration 130000, Testing net (#0)
I0502 11:31:25.216269 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:25.346990 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:31:25.347013 26473 solver.cpp:429]     Test net output #1: loss = 0.0977933 (* 1 = 0.0977933 loss)
I0502 11:31:25.349946 26473 solver.cpp:242] Iteration 130000 (83.4224 iter/s, 1.19872s/100 iter), loss = 0.159615
I0502 11:31:25.349967 26473 solver.cpp:261]     Train net output #0: loss = 0.159615 (* 1 = 0.159615 loss)
I0502 11:31:25.349974 26473 sgd_solver.cpp:106] Iteration 130000, lr = 5.49756e-06
I0502 11:31:26.289590 26473 solver.cpp:242] Iteration 130100 (93.0297 iter/s, 1.07493s/100 iter), loss = 0.3089
I0502 11:31:26.289631 26473 solver.cpp:261]     Train net output #0: loss = 0.3089 (* 1 = 0.3089 loss)
I0502 11:31:26.289639 26473 sgd_solver.cpp:106] Iteration 130100, lr = 5.49756e-06
I0502 11:31:26.294414 26473 solver.cpp:242] Iteration 130100 (105.884 iter/s, 0.944429s/100 iter), loss = 0.165426
I0502 11:31:26.294436 26473 solver.cpp:261]     Train net output #0: loss = 0.165426 (* 1 = 0.165426 loss)
I0502 11:31:26.294445 26473 sgd_solver.cpp:106] Iteration 130100, lr = 5.49756e-06
I0502 11:31:27.233237 26473 solver.cpp:242] Iteration 130200 (105.98 iter/s, 0.943578s/100 iter), loss = 0.10865
I0502 11:31:27.233276 26473 solver.cpp:261]     Train net output #0: loss = 0.10865 (* 1 = 0.10865 loss)
I0502 11:31:27.233285 26473 sgd_solver.cpp:106] Iteration 130200, lr = 5.49756e-06
I0502 11:31:27.238028 26473 solver.cpp:242] Iteration 130200 (105.98 iter/s, 0.943573s/100 iter), loss = 0.0658789
I0502 11:31:27.238049 26473 solver.cpp:261]     Train net output #0: loss = 0.0658789 (* 1 = 0.0658789 loss)
I0502 11:31:27.238065 26473 sgd_solver.cpp:106] Iteration 130200, lr = 5.49756e-06
I0502 11:31:28.197196 26473 solver.cpp:242] Iteration 130300 (103.746 iter/s, 0.963892s/100 iter), loss = 0.445226
I0502 11:31:28.197243 26473 solver.cpp:261]     Train net output #0: loss = 0.445226 (* 1 = 0.445226 loss)
I0502 11:31:28.197252 26473 sgd_solver.cpp:106] Iteration 130300, lr = 5.49756e-06
I0502 11:31:28.201999 26473 solver.cpp:242] Iteration 130300 (103.742 iter/s, 0.963931s/100 iter), loss = 0.0568169
I0502 11:31:28.202024 26473 solver.cpp:261]     Train net output #0: loss = 0.0568169 (* 1 = 0.0568169 loss)
I0502 11:31:28.202033 26473 sgd_solver.cpp:106] Iteration 130300, lr = 5.49756e-06
I0502 11:31:29.140439 26473 solver.cpp:242] Iteration 130400 (106.025 iter/s, 0.943173s/100 iter), loss = 0.0712402
I0502 11:31:29.140476 26473 solver.cpp:261]     Train net output #0: loss = 0.0712402 (* 1 = 0.0712402 loss)
I0502 11:31:29.140486 26473 sgd_solver.cpp:106] Iteration 130400, lr = 5.49756e-06
I0502 11:31:29.145308 26473 solver.cpp:242] Iteration 130400 (106.016 iter/s, 0.943258s/100 iter), loss = 0.100128
I0502 11:31:29.145331 26473 solver.cpp:261]     Train net output #0: loss = 0.100128 (* 1 = 0.100128 loss)
I0502 11:31:29.145340 26473 sgd_solver.cpp:106] Iteration 130400, lr = 5.49756e-06
I0502 11:31:30.081504 26473 solver.cpp:362] Iteration 130500, Testing net (#0)
I0502 11:31:30.081526 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:30.205765 26473 solver.cpp:429]     Test net output #0: loss = 0.267543 (* 1 = 0.267543 loss)
I0502 11:31:30.208626 26473 solver.cpp:242] Iteration 130500 (93.6214 iter/s, 1.06813s/100 iter), loss = 0.165196
I0502 11:31:30.208645 26473 solver.cpp:261]     Train net output #0: loss = 0.165196 (* 1 = 0.165196 loss)
I0502 11:31:30.208654 26473 sgd_solver.cpp:106] Iteration 130500, lr = 5.49756e-06
I0502 11:31:30.210276 26473 solver.cpp:362] Iteration 130500, Testing net (#0)
I0502 11:31:30.210289 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:30.340881 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:31:30.340903 26473 solver.cpp:429]     Test net output #1: loss = 0.0837278 (* 1 = 0.0837278 loss)
I0502 11:31:30.343823 26473 solver.cpp:242] Iteration 130500 (83.4397 iter/s, 1.19847s/100 iter), loss = 0.0334444
I0502 11:31:30.343842 26473 solver.cpp:261]     Train net output #0: loss = 0.0334444 (* 1 = 0.0334444 loss)
I0502 11:31:30.343852 26473 sgd_solver.cpp:106] Iteration 130500, lr = 5.49756e-06
I0502 11:31:31.283141 26473 solver.cpp:242] Iteration 130600 (93.0697 iter/s, 1.07446s/100 iter), loss = 0.149429
I0502 11:31:31.283181 26473 solver.cpp:261]     Train net output #0: loss = 0.149429 (* 1 = 0.149429 loss)
I0502 11:31:31.283190 26473 sgd_solver.cpp:106] Iteration 130600, lr = 5.49756e-06
I0502 11:31:31.287999 26473 solver.cpp:242] Iteration 130600 (105.917 iter/s, 0.944138s/100 iter), loss = 0.0983271
I0502 11:31:31.288023 26473 solver.cpp:261]     Train net output #0: loss = 0.0983271 (* 1 = 0.0983271 loss)
I0502 11:31:31.288031 26473 sgd_solver.cpp:106] Iteration 130600, lr = 5.49756e-06
I0502 11:31:32.227246 26473 solver.cpp:242] Iteration 130700 (105.928 iter/s, 0.944038s/100 iter), loss = 0.100365
I0502 11:31:32.227279 26473 solver.cpp:261]     Train net output #0: loss = 0.100365 (* 1 = 0.100365 loss)
I0502 11:31:32.227288 26473 sgd_solver.cpp:106] Iteration 130700, lr = 5.49756e-06
I0502 11:31:32.232053 26473 solver.cpp:242] Iteration 130700 (105.931 iter/s, 0.944011s/100 iter), loss = 0.0623893
I0502 11:31:32.232075 26473 solver.cpp:261]     Train net output #0: loss = 0.0623893 (* 1 = 0.0623893 loss)
I0502 11:31:32.232084 26473 sgd_solver.cpp:106] Iteration 130700, lr = 5.49756e-06
I0502 11:31:33.172103 26473 solver.cpp:242] Iteration 130800 (105.843 iter/s, 0.944797s/100 iter), loss = 0.144702
I0502 11:31:33.172135 26473 solver.cpp:261]     Train net output #0: loss = 0.144702 (* 1 = 0.144702 loss)
I0502 11:31:33.172144 26473 sgd_solver.cpp:106] Iteration 130800, lr = 5.49756e-06
I0502 11:31:33.176931 26473 solver.cpp:242] Iteration 130800 (105.838 iter/s, 0.944839s/100 iter), loss = 0.044908
I0502 11:31:33.176955 26473 solver.cpp:261]     Train net output #0: loss = 0.044908 (* 1 = 0.044908 loss)
I0502 11:31:33.176964 26473 sgd_solver.cpp:106] Iteration 130800, lr = 5.49756e-06
I0502 11:31:34.116860 26473 solver.cpp:242] Iteration 130900 (105.854 iter/s, 0.9447s/100 iter), loss = 0.137023
I0502 11:31:34.116902 26473 solver.cpp:261]     Train net output #0: loss = 0.137023 (* 1 = 0.137023 loss)
I0502 11:31:34.116911 26473 sgd_solver.cpp:106] Iteration 130900, lr = 5.49756e-06
I0502 11:31:34.121733 26473 solver.cpp:242] Iteration 130900 (105.848 iter/s, 0.944752s/100 iter), loss = 0.0687134
I0502 11:31:34.121757 26473 solver.cpp:261]     Train net output #0: loss = 0.0687134 (* 1 = 0.0687134 loss)
I0502 11:31:34.121764 26473 sgd_solver.cpp:106] Iteration 130900, lr = 5.49756e-06
I0502 11:31:35.058969 26473 solver.cpp:362] Iteration 131000, Testing net (#0)
I0502 11:31:35.058990 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:35.183440 26473 solver.cpp:429]     Test net output #0: loss = 0.264957 (* 1 = 0.264957 loss)
I0502 11:31:35.186317 26473 solver.cpp:242] Iteration 131000 (93.5107 iter/s, 1.0694s/100 iter), loss = 0.187672
I0502 11:31:35.186338 26473 solver.cpp:261]     Train net output #0: loss = 0.187672 (* 1 = 0.187672 loss)
I0502 11:31:35.186347 26473 sgd_solver.cpp:106] Iteration 131000, lr = 5.49756e-06
I0502 11:31:35.188089 26473 solver.cpp:362] Iteration 131000, Testing net (#0)
I0502 11:31:35.188102 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:35.318775 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:31:35.318794 26473 solver.cpp:429]     Test net output #1: loss = 0.0830264 (* 1 = 0.0830264 loss)
I0502 11:31:35.321697 26473 solver.cpp:242] Iteration 131000 (83.3388 iter/s, 1.19992s/100 iter), loss = 0.0534059
I0502 11:31:35.321717 26473 solver.cpp:261]     Train net output #0: loss = 0.0534059 (* 1 = 0.0534059 loss)
I0502 11:31:35.321725 26473 sgd_solver.cpp:106] Iteration 131000, lr = 5.49756e-06
I0502 11:31:36.261114 26473 solver.cpp:242] Iteration 131100 (93.0455 iter/s, 1.07474s/100 iter), loss = 0.0289039
I0502 11:31:36.261169 26473 solver.cpp:261]     Train net output #0: loss = 0.0289039 (* 1 = 0.0289039 loss)
I0502 11:31:36.261179 26473 sgd_solver.cpp:106] Iteration 131100, lr = 5.49756e-06
I0502 11:31:36.265983 26473 solver.cpp:242] Iteration 131100 (105.906 iter/s, 0.944238s/100 iter), loss = 0.0407696
I0502 11:31:36.266006 26473 solver.cpp:261]     Train net output #0: loss = 0.0407696 (* 1 = 0.0407696 loss)
I0502 11:31:36.266016 26473 sgd_solver.cpp:106] Iteration 131100, lr = 5.49756e-06
I0502 11:31:37.205644 26473 solver.cpp:242] Iteration 131200 (105.882 iter/s, 0.944447s/100 iter), loss = 0.0290935
I0502 11:31:37.205688 26473 solver.cpp:261]     Train net output #0: loss = 0.0290935 (* 1 = 0.0290935 loss)
I0502 11:31:37.205698 26473 sgd_solver.cpp:106] Iteration 131200, lr = 5.49756e-06
I0502 11:31:37.210458 26473 solver.cpp:242] Iteration 131200 (105.884 iter/s, 0.944432s/100 iter), loss = 0.0534243
I0502 11:31:37.210480 26473 solver.cpp:261]     Train net output #0: loss = 0.0534243 (* 1 = 0.0534243 loss)
I0502 11:31:37.210489 26473 sgd_solver.cpp:106] Iteration 131200, lr = 5.49756e-06
I0502 11:31:38.150738 26473 solver.cpp:242] Iteration 131300 (105.818 iter/s, 0.945023s/100 iter), loss = 0.317887
I0502 11:31:38.150784 26473 solver.cpp:261]     Train net output #0: loss = 0.317887 (* 1 = 0.317887 loss)
I0502 11:31:38.150792 26473 sgd_solver.cpp:106] Iteration 131300, lr = 5.49756e-06
I0502 11:31:38.155572 26473 solver.cpp:242] Iteration 131300 (105.812 iter/s, 0.945075s/100 iter), loss = 0.150356
I0502 11:31:38.155596 26473 solver.cpp:261]     Train net output #0: loss = 0.150356 (* 1 = 0.150356 loss)
I0502 11:31:38.155604 26473 sgd_solver.cpp:106] Iteration 131300, lr = 5.49756e-06
I0502 11:31:39.094162 26473 solver.cpp:242] Iteration 131400 (106.005 iter/s, 0.943353s/100 iter), loss = 0.128048
I0502 11:31:39.094215 26473 solver.cpp:261]     Train net output #0: loss = 0.128048 (* 1 = 0.128048 loss)
I0502 11:31:39.094224 26473 sgd_solver.cpp:106] Iteration 131400, lr = 5.49756e-06
I0502 11:31:39.099000 26473 solver.cpp:242] Iteration 131400 (106.001 iter/s, 0.943387s/100 iter), loss = 0.0992766
I0502 11:31:39.099025 26473 solver.cpp:261]     Train net output #0: loss = 0.0992766 (* 1 = 0.0992766 loss)
I0502 11:31:39.099032 26473 sgd_solver.cpp:106] Iteration 131400, lr = 5.49756e-06
I0502 11:31:40.036144 26473 solver.cpp:362] Iteration 131500, Testing net (#0)
I0502 11:31:40.036171 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:40.160408 26473 solver.cpp:429]     Test net output #0: loss = 0.220704 (* 1 = 0.220704 loss)
I0502 11:31:40.163275 26473 solver.cpp:242] Iteration 131500 (93.5416 iter/s, 1.06904s/100 iter), loss = 0.263333
I0502 11:31:40.163295 26473 solver.cpp:261]     Train net output #0: loss = 0.263333 (* 1 = 0.263333 loss)
I0502 11:31:40.163303 26473 sgd_solver.cpp:106] Iteration 131500, lr = 5.49756e-06
I0502 11:31:40.165004 26473 solver.cpp:362] Iteration 131500, Testing net (#0)
I0502 11:31:40.165017 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:40.295609 26473 solver.cpp:429]     Test net output #0: accuracy = 0.957
I0502 11:31:40.295629 26473 solver.cpp:429]     Test net output #1: loss = 0.0795669 (* 1 = 0.0795669 loss)
I0502 11:31:40.298557 26473 solver.cpp:242] Iteration 131500 (83.3673 iter/s, 1.19951s/100 iter), loss = 0.120696
I0502 11:31:40.298576 26473 solver.cpp:261]     Train net output #0: loss = 0.120696 (* 1 = 0.120696 loss)
I0502 11:31:40.298585 26473 sgd_solver.cpp:106] Iteration 131500, lr = 5.49756e-06
I0502 11:31:41.237979 26473 solver.cpp:242] Iteration 131600 (93.0535 iter/s, 1.07465s/100 iter), loss = 0.32434
I0502 11:31:41.238023 26473 solver.cpp:261]     Train net output #0: loss = 0.32434 (* 1 = 0.32434 loss)
I0502 11:31:41.238032 26473 sgd_solver.cpp:106] Iteration 131600, lr = 5.49756e-06
I0502 11:31:41.242794 26473 solver.cpp:242] Iteration 131600 (105.91 iter/s, 0.944199s/100 iter), loss = 0.0538473
I0502 11:31:41.242820 26473 solver.cpp:261]     Train net output #0: loss = 0.0538473 (* 1 = 0.0538473 loss)
I0502 11:31:41.242828 26473 sgd_solver.cpp:106] Iteration 131600, lr = 5.49756e-06
I0502 11:31:42.182929 26473 solver.cpp:242] Iteration 131700 (105.834 iter/s, 0.944878s/100 iter), loss = 0.395753
I0502 11:31:42.182971 26473 solver.cpp:261]     Train net output #0: loss = 0.395753 (* 1 = 0.395753 loss)
I0502 11:31:42.182981 26473 sgd_solver.cpp:106] Iteration 131700, lr = 5.49756e-06
I0502 11:31:42.187741 26473 solver.cpp:242] Iteration 131700 (105.831 iter/s, 0.944902s/100 iter), loss = 0.00906237
I0502 11:31:42.187763 26473 solver.cpp:261]     Train net output #0: loss = 0.00906237 (* 1 = 0.00906237 loss)
I0502 11:31:42.187772 26473 sgd_solver.cpp:106] Iteration 131700, lr = 5.49756e-06
I0502 11:31:43.126993 26473 solver.cpp:242] Iteration 131800 (105.933 iter/s, 0.943994s/100 iter), loss = 0.476036
I0502 11:31:43.127034 26473 solver.cpp:261]     Train net output #0: loss = 0.476036 (* 1 = 0.476036 loss)
I0502 11:31:43.127043 26473 sgd_solver.cpp:106] Iteration 131800, lr = 5.49756e-06
I0502 11:31:43.131835 26473 solver.cpp:242] Iteration 131800 (105.926 iter/s, 0.944054s/100 iter), loss = 0.0564507
I0502 11:31:43.131860 26473 solver.cpp:261]     Train net output #0: loss = 0.0564507 (* 1 = 0.0564507 loss)
I0502 11:31:43.131868 26473 sgd_solver.cpp:106] Iteration 131800, lr = 5.49756e-06
I0502 11:31:44.071038 26473 solver.cpp:242] Iteration 131900 (105.935 iter/s, 0.943978s/100 iter), loss = 0.0597563
I0502 11:31:44.071075 26473 solver.cpp:261]     Train net output #0: loss = 0.0597563 (* 1 = 0.0597563 loss)
I0502 11:31:44.071084 26473 sgd_solver.cpp:106] Iteration 131900, lr = 5.49756e-06
I0502 11:31:44.075836 26473 solver.cpp:242] Iteration 131900 (105.937 iter/s, 0.943959s/100 iter), loss = 0.0602932
I0502 11:31:44.075860 26473 solver.cpp:261]     Train net output #0: loss = 0.0602932 (* 1 = 0.0602932 loss)
I0502 11:31:44.075868 26473 sgd_solver.cpp:106] Iteration 131900, lr = 5.49756e-06
I0502 11:31:45.011847 26473 solver.cpp:362] Iteration 132000, Testing net (#0)
I0502 11:31:45.011874 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:45.136240 26473 solver.cpp:429]     Test net output #0: loss = 0.231048 (* 1 = 0.231048 loss)
I0502 11:31:45.139122 26473 solver.cpp:242] Iteration 132000 (93.6304 iter/s, 1.06803s/100 iter), loss = 0.48976
I0502 11:31:45.139142 26473 solver.cpp:261]     Train net output #0: loss = 0.48976 (* 1 = 0.48976 loss)
I0502 11:31:45.139150 26473 sgd_solver.cpp:106] Iteration 132000, lr = 5.49756e-06
I0502 11:31:45.140872 26473 solver.cpp:362] Iteration 132000, Testing net (#0)
I0502 11:31:45.140887 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:45.271642 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:31:45.271664 26473 solver.cpp:429]     Test net output #1: loss = 0.0903151 (* 1 = 0.0903151 loss)
I0502 11:31:45.274595 26473 solver.cpp:242] Iteration 132000 (83.4227 iter/s, 1.19871s/100 iter), loss = 0.0515392
I0502 11:31:45.274616 26473 solver.cpp:261]     Train net output #0: loss = 0.0515392 (* 1 = 0.0515392 loss)
I0502 11:31:45.274623 26473 sgd_solver.cpp:106] Iteration 132000, lr = 5.49756e-06
I0502 11:31:46.213104 26473 solver.cpp:242] Iteration 132100 (93.116 iter/s, 1.07393s/100 iter), loss = 0.229578
I0502 11:31:46.213138 26473 solver.cpp:261]     Train net output #0: loss = 0.229578 (* 1 = 0.229578 loss)
I0502 11:31:46.213147 26473 sgd_solver.cpp:106] Iteration 132100, lr = 5.49756e-06
I0502 11:31:46.217886 26473 solver.cpp:242] Iteration 132100 (106.016 iter/s, 0.943253s/100 iter), loss = 0.0643594
I0502 11:31:46.217910 26473 solver.cpp:261]     Train net output #0: loss = 0.0643594 (* 1 = 0.0643594 loss)
I0502 11:31:46.217917 26473 sgd_solver.cpp:106] Iteration 132100, lr = 5.49756e-06
I0502 11:31:47.157254 26473 solver.cpp:242] Iteration 132200 (105.922 iter/s, 0.944089s/100 iter), loss = 0.299521
I0502 11:31:47.157287 26473 solver.cpp:261]     Train net output #0: loss = 0.299521 (* 1 = 0.299521 loss)
I0502 11:31:47.157296 26473 sgd_solver.cpp:106] Iteration 132200, lr = 5.49756e-06
I0502 11:31:47.162078 26473 solver.cpp:242] Iteration 132200 (105.915 iter/s, 0.944151s/100 iter), loss = 0.0632517
I0502 11:31:47.162101 26473 solver.cpp:261]     Train net output #0: loss = 0.0632517 (* 1 = 0.0632517 loss)
I0502 11:31:47.162111 26473 sgd_solver.cpp:106] Iteration 132200, lr = 5.49756e-06
I0502 11:31:48.100795 26473 solver.cpp:242] Iteration 132300 (105.991 iter/s, 0.943478s/100 iter), loss = 0.135533
I0502 11:31:48.100836 26473 solver.cpp:261]     Train net output #0: loss = 0.135533 (* 1 = 0.135533 loss)
I0502 11:31:48.100845 26473 sgd_solver.cpp:106] Iteration 132300, lr = 5.49756e-06
I0502 11:31:48.105578 26473 solver.cpp:242] Iteration 132300 (105.993 iter/s, 0.943458s/100 iter), loss = 0.0112479
I0502 11:31:48.105602 26473 solver.cpp:261]     Train net output #0: loss = 0.0112479 (* 1 = 0.0112479 loss)
I0502 11:31:48.105609 26473 sgd_solver.cpp:106] Iteration 132300, lr = 5.49756e-06
I0502 11:31:49.045600 26473 solver.cpp:242] Iteration 132400 (105.85 iter/s, 0.944736s/100 iter), loss = 0.182351
I0502 11:31:49.045642 26473 solver.cpp:261]     Train net output #0: loss = 0.182351 (* 1 = 0.182351 loss)
I0502 11:31:49.045651 26473 sgd_solver.cpp:106] Iteration 132400, lr = 5.49756e-06
I0502 11:31:49.050410 26473 solver.cpp:242] Iteration 132400 (105.843 iter/s, 0.944792s/100 iter), loss = 0.0997337
I0502 11:31:49.050434 26473 solver.cpp:261]     Train net output #0: loss = 0.0997337 (* 1 = 0.0997337 loss)
I0502 11:31:49.050442 26473 sgd_solver.cpp:106] Iteration 132400, lr = 5.49756e-06
I0502 11:31:49.985568 26473 solver.cpp:362] Iteration 132500, Testing net (#0)
I0502 11:31:49.985596 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:50.109884 26473 solver.cpp:429]     Test net output #0: loss = 0.25428 (* 1 = 0.25428 loss)
I0502 11:31:50.112752 26473 solver.cpp:242] Iteration 132500 (93.7127 iter/s, 1.06709s/100 iter), loss = 0.125258
I0502 11:31:50.112781 26473 solver.cpp:261]     Train net output #0: loss = 0.125258 (* 1 = 0.125258 loss)
I0502 11:31:50.112789 26473 sgd_solver.cpp:106] Iteration 132500, lr = 5.49756e-06
I0502 11:31:50.114485 26473 solver.cpp:362] Iteration 132500, Testing net (#0)
I0502 11:31:50.114500 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:50.245182 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9685
I0502 11:31:50.245203 26473 solver.cpp:429]     Test net output #1: loss = 0.0792902 (* 1 = 0.0792902 loss)
I0502 11:31:50.248136 26473 solver.cpp:242] Iteration 132500 (83.4946 iter/s, 1.19768s/100 iter), loss = 0.0429913
I0502 11:31:50.248157 26473 solver.cpp:261]     Train net output #0: loss = 0.0429913 (* 1 = 0.0429913 loss)
I0502 11:31:50.248164 26473 sgd_solver.cpp:106] Iteration 132500, lr = 5.49756e-06
I0502 11:31:51.187857 26473 solver.cpp:242] Iteration 132600 (93.0197 iter/s, 1.07504s/100 iter), loss = 0.0792829
I0502 11:31:51.187901 26473 solver.cpp:261]     Train net output #0: loss = 0.0792829 (* 1 = 0.0792829 loss)
I0502 11:31:51.187909 26473 sgd_solver.cpp:106] Iteration 132600, lr = 5.49756e-06
I0502 11:31:51.192687 26473 solver.cpp:242] Iteration 132600 (105.875 iter/s, 0.944512s/100 iter), loss = 0.0516689
I0502 11:31:51.192710 26473 solver.cpp:261]     Train net output #0: loss = 0.0516689 (* 1 = 0.0516689 loss)
I0502 11:31:51.192718 26473 sgd_solver.cpp:106] Iteration 132600, lr = 5.49756e-06
I0502 11:31:52.132282 26473 solver.cpp:242] Iteration 132700 (105.893 iter/s, 0.944352s/100 iter), loss = 0.375549
I0502 11:31:52.132338 26473 solver.cpp:261]     Train net output #0: loss = 0.375549 (* 1 = 0.375549 loss)
I0502 11:31:52.132347 26473 sgd_solver.cpp:106] Iteration 132700, lr = 5.49756e-06
I0502 11:31:52.137158 26473 solver.cpp:242] Iteration 132700 (105.884 iter/s, 0.94443s/100 iter), loss = 0.0550088
I0502 11:31:52.137182 26473 solver.cpp:261]     Train net output #0: loss = 0.0550088 (* 1 = 0.0550088 loss)
I0502 11:31:52.137192 26473 sgd_solver.cpp:106] Iteration 132700, lr = 5.49756e-06
I0502 11:31:53.076864 26473 solver.cpp:242] Iteration 132800 (105.876 iter/s, 0.944499s/100 iter), loss = 0.108123
I0502 11:31:53.076916 26473 solver.cpp:261]     Train net output #0: loss = 0.108123 (* 1 = 0.108123 loss)
I0502 11:31:53.076925 26473 sgd_solver.cpp:106] Iteration 132800, lr = 5.49756e-06
I0502 11:31:53.081696 26473 solver.cpp:242] Iteration 132800 (105.877 iter/s, 0.944497s/100 iter), loss = 0.145185
I0502 11:31:53.081719 26473 solver.cpp:261]     Train net output #0: loss = 0.145185 (* 1 = 0.145185 loss)
I0502 11:31:53.081727 26473 sgd_solver.cpp:106] Iteration 132800, lr = 5.49756e-06
I0502 11:31:54.021664 26473 solver.cpp:242] Iteration 132900 (105.851 iter/s, 0.944723s/100 iter), loss = 0.0855116
I0502 11:31:54.021705 26473 solver.cpp:261]     Train net output #0: loss = 0.0855116 (* 1 = 0.0855116 loss)
I0502 11:31:54.021715 26473 sgd_solver.cpp:106] Iteration 132900, lr = 5.49756e-06
I0502 11:31:54.026482 26473 solver.cpp:242] Iteration 132900 (105.849 iter/s, 0.944745s/100 iter), loss = 0.029198
I0502 11:31:54.026505 26473 solver.cpp:261]     Train net output #0: loss = 0.029198 (* 1 = 0.029198 loss)
I0502 11:31:54.026515 26473 sgd_solver.cpp:106] Iteration 132900, lr = 5.49756e-06
I0502 11:31:54.963364 26473 solver.cpp:362] Iteration 133000, Testing net (#0)
I0502 11:31:54.963390 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:55.087666 26473 solver.cpp:429]     Test net output #0: loss = 0.209396 (* 1 = 0.209396 loss)
I0502 11:31:55.090557 26473 solver.cpp:242] Iteration 133000 (93.5599 iter/s, 1.06883s/100 iter), loss = 0.457103
I0502 11:31:55.090579 26473 solver.cpp:261]     Train net output #0: loss = 0.457103 (* 1 = 0.457103 loss)
I0502 11:31:55.090587 26473 sgd_solver.cpp:106] Iteration 133000, lr = 5.49756e-06
I0502 11:31:55.092283 26473 solver.cpp:362] Iteration 133000, Testing net (#0)
I0502 11:31:55.092298 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:31:55.222823 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:31:55.222854 26473 solver.cpp:429]     Test net output #1: loss = 0.0846112 (* 1 = 0.0846112 loss)
I0502 11:31:55.225785 26473 solver.cpp:242] Iteration 133000 (83.3849 iter/s, 1.19926s/100 iter), loss = 0.000959521
I0502 11:31:55.225805 26473 solver.cpp:261]     Train net output #0: loss = 0.000959521 (* 1 = 0.000959521 loss)
I0502 11:31:55.225813 26473 sgd_solver.cpp:106] Iteration 133000, lr = 5.49756e-06
I0502 11:31:56.164700 26473 solver.cpp:242] Iteration 133100 (93.1024 iter/s, 1.07409s/100 iter), loss = 0.07567
I0502 11:31:56.164739 26473 solver.cpp:261]     Train net output #0: loss = 0.07567 (* 1 = 0.07567 loss)
I0502 11:31:56.164748 26473 sgd_solver.cpp:106] Iteration 133100, lr = 5.49756e-06
I0502 11:31:56.169510 26473 solver.cpp:242] Iteration 133100 (105.967 iter/s, 0.943688s/100 iter), loss = 0.00344274
I0502 11:31:56.169533 26473 solver.cpp:261]     Train net output #0: loss = 0.00344274 (* 1 = 0.00344274 loss)
I0502 11:31:56.169541 26473 sgd_solver.cpp:106] Iteration 133100, lr = 5.49756e-06
I0502 11:31:57.108968 26473 solver.cpp:242] Iteration 133200 (105.91 iter/s, 0.9442s/100 iter), loss = 0.261962
I0502 11:31:57.109001 26473 solver.cpp:261]     Train net output #0: loss = 0.261962 (* 1 = 0.261962 loss)
I0502 11:31:57.109010 26473 sgd_solver.cpp:106] Iteration 133200, lr = 5.49756e-06
I0502 11:31:57.113775 26473 solver.cpp:242] Iteration 133200 (105.907 iter/s, 0.944224s/100 iter), loss = 0.0100921
I0502 11:31:57.113798 26473 solver.cpp:261]     Train net output #0: loss = 0.0100921 (* 1 = 0.0100921 loss)
I0502 11:31:57.113806 26473 sgd_solver.cpp:106] Iteration 133200, lr = 5.49756e-06
I0502 11:31:58.052467 26473 solver.cpp:242] Iteration 133300 (105.995 iter/s, 0.943441s/100 iter), loss = 0.563891
I0502 11:31:58.052498 26473 solver.cpp:261]     Train net output #0: loss = 0.563891 (* 1 = 0.563891 loss)
I0502 11:31:58.052507 26473 sgd_solver.cpp:106] Iteration 133300, lr = 5.49756e-06
I0502 11:31:58.057255 26473 solver.cpp:242] Iteration 133300 (105.995 iter/s, 0.943439s/100 iter), loss = 0.160867
I0502 11:31:58.057278 26473 solver.cpp:261]     Train net output #0: loss = 0.160867 (* 1 = 0.160867 loss)
I0502 11:31:58.057286 26473 sgd_solver.cpp:106] Iteration 133300, lr = 5.49756e-06
I0502 11:31:58.996964 26473 solver.cpp:242] Iteration 133400 (105.883 iter/s, 0.944437s/100 iter), loss = 0.216322
I0502 11:31:58.997007 26473 solver.cpp:261]     Train net output #0: loss = 0.216322 (* 1 = 0.216322 loss)
I0502 11:31:58.997016 26473 sgd_solver.cpp:106] Iteration 133400, lr = 5.49756e-06
I0502 11:31:59.001770 26473 solver.cpp:242] Iteration 133400 (105.879 iter/s, 0.944474s/100 iter), loss = 0.220439
I0502 11:31:59.001793 26473 solver.cpp:261]     Train net output #0: loss = 0.220439 (* 1 = 0.220439 loss)
I0502 11:31:59.001801 26473 sgd_solver.cpp:106] Iteration 133400, lr = 5.49756e-06
I0502 11:31:59.937417 26473 solver.cpp:362] Iteration 133500, Testing net (#0)
I0502 11:31:59.937444 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:00.061749 26473 solver.cpp:429]     Test net output #0: loss = 0.20016 (* 1 = 0.20016 loss)
I0502 11:32:00.064630 26473 solver.cpp:242] Iteration 133500 (93.6677 iter/s, 1.0676s/100 iter), loss = 0.820081
I0502 11:32:00.064649 26473 solver.cpp:261]     Train net output #0: loss = 0.820081 (* 1 = 0.820081 loss)
I0502 11:32:00.064657 26473 sgd_solver.cpp:106] Iteration 133500, lr = 5.49756e-06
I0502 11:32:00.066350 26473 solver.cpp:362] Iteration 133500, Testing net (#0)
I0502 11:32:00.066364 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:00.197047 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9615
I0502 11:32:00.197069 26473 solver.cpp:429]     Test net output #1: loss = 0.0783036 (* 1 = 0.0783036 loss)
I0502 11:32:00.200016 26473 solver.cpp:242] Iteration 133500 (83.4586 iter/s, 1.1982s/100 iter), loss = 0.192069
I0502 11:32:00.200045 26473 solver.cpp:261]     Train net output #0: loss = 0.192069 (* 1 = 0.192069 loss)
I0502 11:32:00.200057 26473 sgd_solver.cpp:106] Iteration 133500, lr = 5.49756e-06
I0502 11:32:01.157416 26473 solver.cpp:242] Iteration 133600 (91.5132 iter/s, 1.09274s/100 iter), loss = 0.0811301
I0502 11:32:01.157465 26473 solver.cpp:261]     Train net output #0: loss = 0.0811301 (* 1 = 0.0811301 loss)
I0502 11:32:01.157476 26473 sgd_solver.cpp:106] Iteration 133600, lr = 5.49756e-06
I0502 11:32:01.162356 26473 solver.cpp:242] Iteration 133600 (103.919 iter/s, 0.962288s/100 iter), loss = 0.124999
I0502 11:32:01.162379 26473 solver.cpp:261]     Train net output #0: loss = 0.124999 (* 1 = 0.124999 loss)
I0502 11:32:01.162389 26473 sgd_solver.cpp:106] Iteration 133600, lr = 5.49756e-06
I0502 11:32:02.108741 26473 solver.cpp:242] Iteration 133700 (105.125 iter/s, 0.951245s/100 iter), loss = 0.143769
I0502 11:32:02.108785 26473 solver.cpp:261]     Train net output #0: loss = 0.143769 (* 1 = 0.143769 loss)
I0502 11:32:02.108795 26473 sgd_solver.cpp:106] Iteration 133700, lr = 5.49756e-06
I0502 11:32:02.113683 26473 solver.cpp:242] Iteration 133700 (105.121 iter/s, 0.951286s/100 iter), loss = 0.0396986
I0502 11:32:02.113708 26473 solver.cpp:261]     Train net output #0: loss = 0.0396986 (* 1 = 0.0396986 loss)
I0502 11:32:02.113716 26473 sgd_solver.cpp:106] Iteration 133700, lr = 5.49756e-06
I0502 11:32:03.061336 26473 solver.cpp:242] Iteration 133800 (104.984 iter/s, 0.952522s/100 iter), loss = 0.119703
I0502 11:32:03.061381 26473 solver.cpp:261]     Train net output #0: loss = 0.119703 (* 1 = 0.119703 loss)
I0502 11:32:03.061394 26473 sgd_solver.cpp:106] Iteration 133800, lr = 5.49756e-06
I0502 11:32:03.066227 26473 solver.cpp:242] Iteration 133800 (104.987 iter/s, 0.952501s/100 iter), loss = 0.041812
I0502 11:32:03.066251 26473 solver.cpp:261]     Train net output #0: loss = 0.041812 (* 1 = 0.041812 loss)
I0502 11:32:03.066259 26473 sgd_solver.cpp:106] Iteration 133800, lr = 5.49756e-06
I0502 11:32:04.014065 26473 solver.cpp:242] Iteration 133900 (104.969 iter/s, 0.952658s/100 iter), loss = 0.15124
I0502 11:32:04.014107 26473 solver.cpp:261]     Train net output #0: loss = 0.15124 (* 1 = 0.15124 loss)
I0502 11:32:04.014117 26473 sgd_solver.cpp:106] Iteration 133900, lr = 5.49756e-06
I0502 11:32:04.018911 26473 solver.cpp:242] Iteration 133900 (104.971 iter/s, 0.952642s/100 iter), loss = 0.0689364
I0502 11:32:04.018935 26473 solver.cpp:261]     Train net output #0: loss = 0.0689364 (* 1 = 0.0689364 loss)
I0502 11:32:04.018944 26473 sgd_solver.cpp:106] Iteration 133900, lr = 5.49756e-06
I0502 11:32:04.956125 26473 solver.cpp:362] Iteration 134000, Testing net (#0)
I0502 11:32:04.956151 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:05.080422 26473 solver.cpp:429]     Test net output #0: loss = 0.250639 (* 1 = 0.250639 loss)
I0502 11:32:05.083295 26473 solver.cpp:242] Iteration 134000 (93.5305 iter/s, 1.06917s/100 iter), loss = 0.364915
I0502 11:32:05.083315 26473 solver.cpp:261]     Train net output #0: loss = 0.364915 (* 1 = 0.364915 loss)
I0502 11:32:05.083323 26473 sgd_solver.cpp:106] Iteration 134000, lr = 5.49756e-06
I0502 11:32:05.085018 26473 solver.cpp:362] Iteration 134000, Testing net (#0)
I0502 11:32:05.085033 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:05.215643 26473 solver.cpp:429]     Test net output #0: accuracy = 0.958
I0502 11:32:05.215665 26473 solver.cpp:429]     Test net output #1: loss = 0.0891664 (* 1 = 0.0891664 loss)
I0502 11:32:05.218590 26473 solver.cpp:242] Iteration 134000 (83.3588 iter/s, 1.19963s/100 iter), loss = 0.0861992
I0502 11:32:05.218608 26473 solver.cpp:261]     Train net output #0: loss = 0.0861992 (* 1 = 0.0861992 loss)
I0502 11:32:05.218617 26473 sgd_solver.cpp:106] Iteration 134000, lr = 5.49756e-06
I0502 11:32:06.157970 26473 solver.cpp:242] Iteration 134100 (93.0554 iter/s, 1.07463s/100 iter), loss = 0.22251
I0502 11:32:06.158011 26473 solver.cpp:261]     Train net output #0: loss = 0.22251 (* 1 = 0.22251 loss)
I0502 11:32:06.158020 26473 sgd_solver.cpp:106] Iteration 134100, lr = 5.49756e-06
I0502 11:32:06.162842 26473 solver.cpp:242] Iteration 134100 (105.909 iter/s, 0.944209s/100 iter), loss = 0.169603
I0502 11:32:06.162866 26473 solver.cpp:261]     Train net output #0: loss = 0.169603 (* 1 = 0.169603 loss)
I0502 11:32:06.162884 26473 sgd_solver.cpp:106] Iteration 134100, lr = 5.49756e-06
I0502 11:32:07.101418 26473 solver.cpp:242] Iteration 134200 (106.002 iter/s, 0.943376s/100 iter), loss = 0.0479649
I0502 11:32:07.101459 26473 solver.cpp:261]     Train net output #0: loss = 0.0479649 (* 1 = 0.0479649 loss)
I0502 11:32:07.101467 26473 sgd_solver.cpp:106] Iteration 134200, lr = 5.49756e-06
I0502 11:32:07.106262 26473 solver.cpp:242] Iteration 134200 (106.002 iter/s, 0.943377s/100 iter), loss = 0.161917
I0502 11:32:07.106286 26473 solver.cpp:261]     Train net output #0: loss = 0.161917 (* 1 = 0.161917 loss)
I0502 11:32:07.106294 26473 sgd_solver.cpp:106] Iteration 134200, lr = 5.49756e-06
I0502 11:32:08.044765 26473 solver.cpp:242] Iteration 134300 (106.013 iter/s, 0.943277s/100 iter), loss = 0.297189
I0502 11:32:08.044801 26473 solver.cpp:261]     Train net output #0: loss = 0.297189 (* 1 = 0.297189 loss)
I0502 11:32:08.044811 26473 sgd_solver.cpp:106] Iteration 134300, lr = 5.49756e-06
I0502 11:32:08.049540 26473 solver.cpp:242] Iteration 134300 (106.018 iter/s, 0.943236s/100 iter), loss = 0.129325
I0502 11:32:08.049561 26473 solver.cpp:261]     Train net output #0: loss = 0.129325 (* 1 = 0.129325 loss)
I0502 11:32:08.049569 26473 sgd_solver.cpp:106] Iteration 134300, lr = 5.49756e-06
I0502 11:32:08.989082 26473 solver.cpp:242] Iteration 134400 (105.904 iter/s, 0.944254s/100 iter), loss = 0.164306
I0502 11:32:08.989117 26473 solver.cpp:261]     Train net output #0: loss = 0.164306 (* 1 = 0.164306 loss)
I0502 11:32:08.989126 26473 sgd_solver.cpp:106] Iteration 134400, lr = 5.49756e-06
I0502 11:32:08.993878 26473 solver.cpp:242] Iteration 134400 (105.899 iter/s, 0.944298s/100 iter), loss = 0.0614269
I0502 11:32:08.993901 26473 solver.cpp:261]     Train net output #0: loss = 0.0614269 (* 1 = 0.0614269 loss)
I0502 11:32:08.993909 26473 sgd_solver.cpp:106] Iteration 134400, lr = 5.49756e-06
I0502 11:32:09.930357 26473 solver.cpp:362] Iteration 134500, Testing net (#0)
I0502 11:32:09.930378 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:10.054725 26473 solver.cpp:429]     Test net output #0: loss = 0.225151 (* 1 = 0.225151 loss)
I0502 11:32:10.057602 26473 solver.cpp:242] Iteration 134500 (93.5921 iter/s, 1.06847s/100 iter), loss = 0.1916
I0502 11:32:10.057622 26473 solver.cpp:261]     Train net output #0: loss = 0.1916 (* 1 = 0.1916 loss)
I0502 11:32:10.057631 26473 sgd_solver.cpp:106] Iteration 134500, lr = 5.49756e-06
I0502 11:32:10.059250 26473 solver.cpp:362] Iteration 134500, Testing net (#0)
I0502 11:32:10.059263 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:10.190160 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9665
I0502 11:32:10.190181 26473 solver.cpp:429]     Test net output #1: loss = 0.0760759 (* 1 = 0.0760759 loss)
I0502 11:32:10.193095 26473 solver.cpp:242] Iteration 134500 (83.3907 iter/s, 1.19917s/100 iter), loss = 0.129029
I0502 11:32:10.193115 26473 solver.cpp:261]     Train net output #0: loss = 0.129029 (* 1 = 0.129029 loss)
I0502 11:32:10.193125 26473 sgd_solver.cpp:106] Iteration 134500, lr = 5.49756e-06
I0502 11:32:11.133450 26473 solver.cpp:242] Iteration 134600 (92.9543 iter/s, 1.0758s/100 iter), loss = 0.269093
I0502 11:32:11.133491 26473 solver.cpp:261]     Train net output #0: loss = 0.269093 (* 1 = 0.269093 loss)
I0502 11:32:11.133499 26473 sgd_solver.cpp:106] Iteration 134600, lr = 5.49756e-06
I0502 11:32:11.138329 26473 solver.cpp:242] Iteration 134600 (105.799 iter/s, 0.945188s/100 iter), loss = 0.0435544
I0502 11:32:11.138353 26473 solver.cpp:261]     Train net output #0: loss = 0.0435544 (* 1 = 0.0435544 loss)
I0502 11:32:11.138362 26473 sgd_solver.cpp:106] Iteration 134600, lr = 5.49756e-06
I0502 11:32:12.078300 26473 solver.cpp:242] Iteration 134700 (105.845 iter/s, 0.944781s/100 iter), loss = 0.178689
I0502 11:32:12.078335 26473 solver.cpp:261]     Train net output #0: loss = 0.178689 (* 1 = 0.178689 loss)
I0502 11:32:12.078343 26473 sgd_solver.cpp:106] Iteration 134700, lr = 5.49756e-06
I0502 11:32:12.083102 26473 solver.cpp:242] Iteration 134700 (105.85 iter/s, 0.944732s/100 iter), loss = 0.113396
I0502 11:32:12.083125 26473 solver.cpp:261]     Train net output #0: loss = 0.113396 (* 1 = 0.113396 loss)
I0502 11:32:12.083134 26473 sgd_solver.cpp:106] Iteration 134700, lr = 5.49756e-06
I0502 11:32:13.022349 26473 solver.cpp:242] Iteration 134800 (105.934 iter/s, 0.943985s/100 iter), loss = 0.122056
I0502 11:32:13.022392 26473 solver.cpp:261]     Train net output #0: loss = 0.122056 (* 1 = 0.122056 loss)
I0502 11:32:13.022402 26473 sgd_solver.cpp:106] Iteration 134800, lr = 5.49756e-06
I0502 11:32:13.027194 26473 solver.cpp:242] Iteration 134800 (105.927 iter/s, 0.94405s/100 iter), loss = 0.0329886
I0502 11:32:13.027215 26473 solver.cpp:261]     Train net output #0: loss = 0.0329886 (* 1 = 0.0329886 loss)
I0502 11:32:13.027225 26473 sgd_solver.cpp:106] Iteration 134800, lr = 5.49756e-06
I0502 11:32:13.966475 26473 solver.cpp:242] Iteration 134900 (105.926 iter/s, 0.944053s/100 iter), loss = 0.380253
I0502 11:32:13.966532 26473 solver.cpp:261]     Train net output #0: loss = 0.380253 (* 1 = 0.380253 loss)
I0502 11:32:13.966542 26473 sgd_solver.cpp:106] Iteration 134900, lr = 5.49756e-06
I0502 11:32:13.971349 26473 solver.cpp:242] Iteration 134900 (105.919 iter/s, 0.944116s/100 iter), loss = 0.112599
I0502 11:32:13.971374 26473 solver.cpp:261]     Train net output #0: loss = 0.112599 (* 1 = 0.112599 loss)
I0502 11:32:13.971381 26473 sgd_solver.cpp:106] Iteration 134900, lr = 5.49756e-06
I0502 11:32:14.908264 26473 solver.cpp:362] Iteration 135000, Testing net (#0)
I0502 11:32:14.908289 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:15.032480 26473 solver.cpp:429]     Test net output #0: loss = 0.221461 (* 1 = 0.221461 loss)
I0502 11:32:15.035363 26473 solver.cpp:242] Iteration 135000 (93.5617 iter/s, 1.06881s/100 iter), loss = 0.185559
I0502 11:32:15.035383 26473 solver.cpp:261]     Train net output #0: loss = 0.185559 (* 1 = 0.185559 loss)
I0502 11:32:15.035392 26473 sgd_solver.cpp:106] Iteration 135000, lr = 5.49756e-06
I0502 11:32:15.037014 26473 solver.cpp:362] Iteration 135000, Testing net (#0)
I0502 11:32:15.037027 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:15.167732 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9655
I0502 11:32:15.167754 26473 solver.cpp:429]     Test net output #1: loss = 0.0830486 (* 1 = 0.0830486 loss)
I0502 11:32:15.170691 26473 solver.cpp:242] Iteration 135000 (83.3822 iter/s, 1.1993s/100 iter), loss = 0.0509475
I0502 11:32:15.170711 26473 solver.cpp:261]     Train net output #0: loss = 0.0509475 (* 1 = 0.0509475 loss)
I0502 11:32:15.170719 26473 sgd_solver.cpp:106] Iteration 135000, lr = 5.49756e-06
I0502 11:32:16.110083 26473 solver.cpp:242] Iteration 135100 (93.0516 iter/s, 1.07467s/100 iter), loss = 0.138282
I0502 11:32:16.110128 26473 solver.cpp:261]     Train net output #0: loss = 0.138282 (* 1 = 0.138282 loss)
I0502 11:32:16.110136 26473 sgd_solver.cpp:106] Iteration 135100, lr = 5.49756e-06
I0502 11:32:16.114980 26473 solver.cpp:242] Iteration 135100 (105.905 iter/s, 0.944243s/100 iter), loss = 0.00726262
I0502 11:32:16.115003 26473 solver.cpp:261]     Train net output #0: loss = 0.00726262 (* 1 = 0.00726262 loss)
I0502 11:32:16.115012 26473 sgd_solver.cpp:106] Iteration 135100, lr = 5.49756e-06
I0502 11:32:17.054116 26473 solver.cpp:242] Iteration 135200 (105.937 iter/s, 0.943958s/100 iter), loss = 0.0323499
I0502 11:32:17.054157 26473 solver.cpp:261]     Train net output #0: loss = 0.0323499 (* 1 = 0.0323499 loss)
I0502 11:32:17.054167 26473 sgd_solver.cpp:106] Iteration 135200, lr = 5.49756e-06
I0502 11:32:17.058933 26473 solver.cpp:242] Iteration 135200 (105.942 iter/s, 0.943911s/100 iter), loss = 0.0725009
I0502 11:32:17.058955 26473 solver.cpp:261]     Train net output #0: loss = 0.0725009 (* 1 = 0.0725009 loss)
I0502 11:32:17.058964 26473 sgd_solver.cpp:106] Iteration 135200, lr = 5.49756e-06
I0502 11:32:17.998432 26473 solver.cpp:242] Iteration 135300 (105.905 iter/s, 0.944245s/100 iter), loss = 0.0595987
I0502 11:32:17.998483 26473 solver.cpp:261]     Train net output #0: loss = 0.0595987 (* 1 = 0.0595987 loss)
I0502 11:32:17.998493 26473 sgd_solver.cpp:106] Iteration 135300, lr = 5.49756e-06
I0502 11:32:18.003265 26473 solver.cpp:242] Iteration 135300 (105.899 iter/s, 0.944292s/100 iter), loss = 0.00372755
I0502 11:32:18.003288 26473 solver.cpp:261]     Train net output #0: loss = 0.00372755 (* 1 = 0.00372755 loss)
I0502 11:32:18.003298 26473 sgd_solver.cpp:106] Iteration 135300, lr = 5.49756e-06
I0502 11:32:18.941129 26473 solver.cpp:242] Iteration 135400 (106.087 iter/s, 0.942618s/100 iter), loss = 0.157074
I0502 11:32:18.941165 26473 solver.cpp:261]     Train net output #0: loss = 0.157074 (* 1 = 0.157074 loss)
I0502 11:32:18.941174 26473 sgd_solver.cpp:106] Iteration 135400, lr = 5.49756e-06
I0502 11:32:18.945930 26473 solver.cpp:242] Iteration 135400 (106.087 iter/s, 0.942624s/100 iter), loss = 0.0759778
I0502 11:32:18.945952 26473 solver.cpp:261]     Train net output #0: loss = 0.0759778 (* 1 = 0.0759778 loss)
I0502 11:32:18.945961 26473 sgd_solver.cpp:106] Iteration 135400, lr = 5.49756e-06
I0502 11:32:19.882766 26473 solver.cpp:362] Iteration 135500, Testing net (#0)
I0502 11:32:19.882789 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:20.007138 26473 solver.cpp:429]     Test net output #0: loss = 0.239329 (* 1 = 0.239329 loss)
I0502 11:32:20.010030 26473 solver.cpp:242] Iteration 135500 (93.5588 iter/s, 1.06885s/100 iter), loss = 0.0610266
I0502 11:32:20.010049 26473 solver.cpp:261]     Train net output #0: loss = 0.0610266 (* 1 = 0.0610266 loss)
I0502 11:32:20.010058 26473 sgd_solver.cpp:106] Iteration 135500, lr = 5.49756e-06
I0502 11:32:20.011674 26473 solver.cpp:362] Iteration 135500, Testing net (#0)
I0502 11:32:20.011688 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:20.142298 26473 solver.cpp:429]     Test net output #0: accuracy = 0.959
I0502 11:32:20.142319 26473 solver.cpp:429]     Test net output #1: loss = 0.0902815 (* 1 = 0.0902815 loss)
I0502 11:32:20.145237 26473 solver.cpp:242] Iteration 135500 (83.3845 iter/s, 1.19926s/100 iter), loss = 0.0608135
I0502 11:32:20.145257 26473 solver.cpp:261]     Train net output #0: loss = 0.0608135 (* 1 = 0.0608135 loss)
I0502 11:32:20.145265 26473 sgd_solver.cpp:106] Iteration 135500, lr = 5.49756e-06
I0502 11:32:21.085000 26473 solver.cpp:242] Iteration 135600 (93.03 iter/s, 1.07492s/100 iter), loss = 0.196993
I0502 11:32:21.085041 26473 solver.cpp:261]     Train net output #0: loss = 0.196993 (* 1 = 0.196993 loss)
I0502 11:32:21.085050 26473 sgd_solver.cpp:106] Iteration 135600, lr = 5.49756e-06
I0502 11:32:21.089870 26473 solver.cpp:242] Iteration 135600 (105.867 iter/s, 0.944586s/100 iter), loss = 0.0763491
I0502 11:32:21.089895 26473 solver.cpp:261]     Train net output #0: loss = 0.0763491 (* 1 = 0.0763491 loss)
I0502 11:32:21.089902 26473 sgd_solver.cpp:106] Iteration 135600, lr = 5.49756e-06
I0502 11:32:22.029011 26473 solver.cpp:242] Iteration 135700 (105.939 iter/s, 0.943941s/100 iter), loss = 0.185176
I0502 11:32:22.029047 26473 solver.cpp:261]     Train net output #0: loss = 0.185176 (* 1 = 0.185176 loss)
I0502 11:32:22.029057 26473 sgd_solver.cpp:106] Iteration 135700, lr = 5.49756e-06
I0502 11:32:22.033802 26473 solver.cpp:242] Iteration 135700 (105.944 iter/s, 0.94389s/100 iter), loss = 0.0155746
I0502 11:32:22.033825 26473 solver.cpp:261]     Train net output #0: loss = 0.0155746 (* 1 = 0.0155746 loss)
I0502 11:32:22.033834 26473 sgd_solver.cpp:106] Iteration 135700, lr = 5.49756e-06
I0502 11:32:22.973646 26473 solver.cpp:242] Iteration 135800 (105.869 iter/s, 0.944567s/100 iter), loss = 0.201297
I0502 11:32:22.973685 26473 solver.cpp:261]     Train net output #0: loss = 0.201297 (* 1 = 0.201297 loss)
I0502 11:32:22.973693 26473 sgd_solver.cpp:106] Iteration 135800, lr = 5.49756e-06
I0502 11:32:22.978463 26473 solver.cpp:242] Iteration 135800 (105.863 iter/s, 0.94462s/100 iter), loss = 0.0355697
I0502 11:32:22.978487 26473 solver.cpp:261]     Train net output #0: loss = 0.0355697 (* 1 = 0.0355697 loss)
I0502 11:32:22.978502 26473 sgd_solver.cpp:106] Iteration 135800, lr = 5.49756e-06
I0502 11:32:23.918450 26473 solver.cpp:242] Iteration 135900 (105.849 iter/s, 0.944739s/100 iter), loss = 0.0820579
I0502 11:32:23.918485 26473 solver.cpp:261]     Train net output #0: loss = 0.0820579 (* 1 = 0.0820579 loss)
I0502 11:32:23.918494 26473 sgd_solver.cpp:106] Iteration 135900, lr = 5.49756e-06
I0502 11:32:23.923235 26473 solver.cpp:242] Iteration 135900 (105.85 iter/s, 0.944731s/100 iter), loss = 0.156742
I0502 11:32:23.923257 26473 solver.cpp:261]     Train net output #0: loss = 0.156742 (* 1 = 0.156742 loss)
I0502 11:32:23.923266 26473 sgd_solver.cpp:106] Iteration 135900, lr = 5.49756e-06
I0502 11:32:24.859477 26473 solver.cpp:362] Iteration 136000, Testing net (#0)
I0502 11:32:24.859508 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:24.983844 26473 solver.cpp:429]     Test net output #0: loss = 0.207262 (* 1 = 0.207262 loss)
I0502 11:32:24.986719 26473 solver.cpp:242] Iteration 136000 (93.6142 iter/s, 1.06821s/100 iter), loss = 0.323463
I0502 11:32:24.986739 26473 solver.cpp:261]     Train net output #0: loss = 0.323463 (* 1 = 0.323463 loss)
I0502 11:32:24.986748 26473 sgd_solver.cpp:106] Iteration 136000, lr = 5.49756e-06
I0502 11:32:24.988356 26473 solver.cpp:362] Iteration 136000, Testing net (#0)
I0502 11:32:24.988369 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:25.118999 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:32:25.119019 26473 solver.cpp:429]     Test net output #1: loss = 0.079 (* 1 = 0.079 loss)
I0502 11:32:25.121942 26473 solver.cpp:242] Iteration 136000 (83.4262 iter/s, 1.19866s/100 iter), loss = 0.00793935
I0502 11:32:25.121963 26473 solver.cpp:261]     Train net output #0: loss = 0.00793935 (* 1 = 0.00793935 loss)
I0502 11:32:25.121971 26473 sgd_solver.cpp:106] Iteration 136000, lr = 5.49756e-06
I0502 11:32:26.061179 26473 solver.cpp:242] Iteration 136100 (93.0743 iter/s, 1.07441s/100 iter), loss = 0.133521
I0502 11:32:26.061221 26473 solver.cpp:261]     Train net output #0: loss = 0.133521 (* 1 = 0.133521 loss)
I0502 11:32:26.061230 26473 sgd_solver.cpp:106] Iteration 136100, lr = 5.49756e-06
I0502 11:32:26.066071 26473 solver.cpp:242] Iteration 136100 (105.923 iter/s, 0.944081s/100 iter), loss = 0.00862193
I0502 11:32:26.066095 26473 solver.cpp:261]     Train net output #0: loss = 0.00862193 (* 1 = 0.00862193 loss)
I0502 11:32:26.066103 26473 sgd_solver.cpp:106] Iteration 136100, lr = 5.49756e-06
I0502 11:32:27.005501 26473 solver.cpp:242] Iteration 136200 (105.904 iter/s, 0.944248s/100 iter), loss = 0.0400357
I0502 11:32:27.005543 26473 solver.cpp:261]     Train net output #0: loss = 0.0400357 (* 1 = 0.0400357 loss)
I0502 11:32:27.005553 26473 sgd_solver.cpp:106] Iteration 136200, lr = 5.49756e-06
I0502 11:32:27.010325 26473 solver.cpp:242] Iteration 136200 (105.908 iter/s, 0.944212s/100 iter), loss = 0.102889
I0502 11:32:27.010349 26473 solver.cpp:261]     Train net output #0: loss = 0.102889 (* 1 = 0.102889 loss)
I0502 11:32:27.010356 26473 sgd_solver.cpp:106] Iteration 136200, lr = 5.49756e-06
I0502 11:32:27.948875 26473 solver.cpp:242] Iteration 136300 (106.011 iter/s, 0.943301s/100 iter), loss = 0.423402
I0502 11:32:27.948917 26473 solver.cpp:261]     Train net output #0: loss = 0.423402 (* 1 = 0.423402 loss)
I0502 11:32:27.948925 26473 sgd_solver.cpp:106] Iteration 136300, lr = 5.49756e-06
I0502 11:32:27.953673 26473 solver.cpp:242] Iteration 136300 (106.01 iter/s, 0.943308s/100 iter), loss = 0.00772034
I0502 11:32:27.953696 26473 solver.cpp:261]     Train net output #0: loss = 0.00772034 (* 1 = 0.00772034 loss)
I0502 11:32:27.953706 26473 sgd_solver.cpp:106] Iteration 136300, lr = 5.49756e-06
I0502 11:32:28.894338 26473 solver.cpp:242] Iteration 136400 (105.776 iter/s, 0.945393s/100 iter), loss = 0.352229
I0502 11:32:28.894381 26473 solver.cpp:261]     Train net output #0: loss = 0.352229 (* 1 = 0.352229 loss)
I0502 11:32:28.894389 26473 sgd_solver.cpp:106] Iteration 136400, lr = 5.49756e-06
I0502 11:32:28.899174 26473 solver.cpp:242] Iteration 136400 (105.769 iter/s, 0.94546s/100 iter), loss = 0.0122625
I0502 11:32:28.899205 26473 solver.cpp:261]     Train net output #0: loss = 0.0122625 (* 1 = 0.0122625 loss)
I0502 11:32:28.899214 26473 sgd_solver.cpp:106] Iteration 136400, lr = 5.49756e-06
I0502 11:32:29.834285 26473 solver.cpp:362] Iteration 136500, Testing net (#0)
I0502 11:32:29.834312 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:29.958530 26473 solver.cpp:429]     Test net output #0: loss = 0.245297 (* 1 = 0.245297 loss)
I0502 11:32:29.961429 26473 solver.cpp:242] Iteration 136500 (93.718 iter/s, 1.06703s/100 iter), loss = 0.0991212
I0502 11:32:29.961450 26473 solver.cpp:261]     Train net output #0: loss = 0.0991212 (* 1 = 0.0991212 loss)
I0502 11:32:29.961459 26473 sgd_solver.cpp:106] Iteration 136500, lr = 5.49756e-06
I0502 11:32:29.963084 26473 solver.cpp:362] Iteration 136500, Testing net (#0)
I0502 11:32:29.963099 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:30.093737 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:32:30.093760 26473 solver.cpp:429]     Test net output #1: loss = 0.0849724 (* 1 = 0.0849724 loss)
I0502 11:32:30.096680 26473 solver.cpp:242] Iteration 136500 (83.5105 iter/s, 1.19745s/100 iter), loss = 0.0745683
I0502 11:32:30.096700 26473 solver.cpp:261]     Train net output #0: loss = 0.0745683 (* 1 = 0.0745683 loss)
I0502 11:32:30.096709 26473 sgd_solver.cpp:106] Iteration 136500, lr = 5.49756e-06
I0502 11:32:31.035606 26473 solver.cpp:242] Iteration 136600 (93.0989 iter/s, 1.07413s/100 iter), loss = 0.0880848
I0502 11:32:31.035648 26473 solver.cpp:261]     Train net output #0: loss = 0.0880848 (* 1 = 0.0880848 loss)
I0502 11:32:31.035657 26473 sgd_solver.cpp:106] Iteration 136600, lr = 5.49756e-06
I0502 11:32:31.040483 26473 solver.cpp:242] Iteration 136600 (105.96 iter/s, 0.943756s/100 iter), loss = 0.239932
I0502 11:32:31.040508 26473 solver.cpp:261]     Train net output #0: loss = 0.239932 (* 1 = 0.239932 loss)
I0502 11:32:31.040515 26473 sgd_solver.cpp:106] Iteration 136600, lr = 5.49756e-06
I0502 11:32:31.979362 26473 solver.cpp:242] Iteration 136700 (105.967 iter/s, 0.94369s/100 iter), loss = 0.200445
I0502 11:32:31.979403 26473 solver.cpp:261]     Train net output #0: loss = 0.200445 (* 1 = 0.200445 loss)
I0502 11:32:31.979413 26473 sgd_solver.cpp:106] Iteration 136700, lr = 5.49756e-06
I0502 11:32:31.984298 26473 solver.cpp:242] Iteration 136700 (105.958 iter/s, 0.943767s/100 iter), loss = 0.0018739
I0502 11:32:31.984323 26473 solver.cpp:261]     Train net output #0: loss = 0.0018739 (* 1 = 0.0018739 loss)
I0502 11:32:31.984333 26473 sgd_solver.cpp:106] Iteration 136700, lr = 5.49756e-06
I0502 11:32:32.923344 26473 solver.cpp:242] Iteration 136800 (105.942 iter/s, 0.943912s/100 iter), loss = 0.0626979
I0502 11:32:32.923384 26473 solver.cpp:261]     Train net output #0: loss = 0.0626979 (* 1 = 0.0626979 loss)
I0502 11:32:32.923393 26473 sgd_solver.cpp:106] Iteration 136800, lr = 5.49756e-06
I0502 11:32:32.928169 26473 solver.cpp:242] Iteration 136800 (105.952 iter/s, 0.943828s/100 iter), loss = 0.0837845
I0502 11:32:32.928192 26473 solver.cpp:261]     Train net output #0: loss = 0.0837845 (* 1 = 0.0837845 loss)
I0502 11:32:32.928200 26473 sgd_solver.cpp:106] Iteration 136800, lr = 5.49756e-06
I0502 11:32:33.867187 26473 solver.cpp:242] Iteration 136900 (105.958 iter/s, 0.943769s/100 iter), loss = 0.343933
I0502 11:32:33.867225 26473 solver.cpp:261]     Train net output #0: loss = 0.343933 (* 1 = 0.343933 loss)
I0502 11:32:33.867234 26473 sgd_solver.cpp:106] Iteration 136900, lr = 5.49756e-06
I0502 11:32:33.872087 26473 solver.cpp:242] Iteration 136900 (105.946 iter/s, 0.943875s/100 iter), loss = 0.100792
I0502 11:32:33.872110 26473 solver.cpp:261]     Train net output #0: loss = 0.100792 (* 1 = 0.100792 loss)
I0502 11:32:33.872119 26473 sgd_solver.cpp:106] Iteration 136900, lr = 5.49756e-06
I0502 11:32:34.807729 26473 solver.cpp:362] Iteration 137000, Testing net (#0)
I0502 11:32:34.807750 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:34.932034 26473 solver.cpp:429]     Test net output #0: loss = 0.244777 (* 1 = 0.244777 loss)
I0502 11:32:34.934909 26473 solver.cpp:242] Iteration 137000 (93.6623 iter/s, 1.06767s/100 iter), loss = 0.0939961
I0502 11:32:34.934929 26473 solver.cpp:261]     Train net output #0: loss = 0.0939961 (* 1 = 0.0939961 loss)
I0502 11:32:34.934938 26473 sgd_solver.cpp:106] Iteration 137000, lr = 5.49756e-06
I0502 11:32:34.936554 26473 solver.cpp:362] Iteration 137000, Testing net (#0)
I0502 11:32:34.936566 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:35.067243 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9705
I0502 11:32:35.067276 26473 solver.cpp:429]     Test net output #1: loss = 0.0786273 (* 1 = 0.0786273 loss)
I0502 11:32:35.070232 26473 solver.cpp:242] Iteration 137000 (83.4654 iter/s, 1.1981s/100 iter), loss = 0.222698
I0502 11:32:35.070255 26473 solver.cpp:261]     Train net output #0: loss = 0.222698 (* 1 = 0.222698 loss)
I0502 11:32:35.070262 26473 sgd_solver.cpp:106] Iteration 137000, lr = 5.49756e-06
I0502 11:32:36.008817 26473 solver.cpp:242] Iteration 137100 (93.122 iter/s, 1.07386s/100 iter), loss = 0.261201
I0502 11:32:36.008848 26473 solver.cpp:261]     Train net output #0: loss = 0.261201 (* 1 = 0.261201 loss)
I0502 11:32:36.008857 26473 sgd_solver.cpp:106] Iteration 137100, lr = 5.49756e-06
I0502 11:32:36.013617 26473 solver.cpp:242] Iteration 137100 (106.006 iter/s, 0.943345s/100 iter), loss = 0.0912801
I0502 11:32:36.013639 26473 solver.cpp:261]     Train net output #0: loss = 0.0912801 (* 1 = 0.0912801 loss)
I0502 11:32:36.013648 26473 sgd_solver.cpp:106] Iteration 137100, lr = 5.49756e-06
I0502 11:32:36.972635 26473 solver.cpp:242] Iteration 137200 (103.76 iter/s, 0.963761s/100 iter), loss = 0.194022
I0502 11:32:36.972681 26473 solver.cpp:261]     Train net output #0: loss = 0.194022 (* 1 = 0.194022 loss)
I0502 11:32:36.972689 26473 sgd_solver.cpp:106] Iteration 137200, lr = 5.49756e-06
I0502 11:32:36.977520 26473 solver.cpp:242] Iteration 137200 (103.75 iter/s, 0.963853s/100 iter), loss = 0.0121569
I0502 11:32:36.977547 26473 solver.cpp:261]     Train net output #0: loss = 0.0121569 (* 1 = 0.0121569 loss)
I0502 11:32:36.977555 26473 sgd_solver.cpp:106] Iteration 137200, lr = 5.49756e-06
I0502 11:32:37.917170 26473 solver.cpp:242] Iteration 137300 (105.881 iter/s, 0.944459s/100 iter), loss = 0.376334
I0502 11:32:37.917212 26473 solver.cpp:261]     Train net output #0: loss = 0.376334 (* 1 = 0.376334 loss)
I0502 11:32:37.917222 26473 sgd_solver.cpp:106] Iteration 137300, lr = 5.49756e-06
I0502 11:32:37.921985 26473 solver.cpp:242] Iteration 137300 (105.885 iter/s, 0.94442s/100 iter), loss = 0.141384
I0502 11:32:37.922008 26473 solver.cpp:261]     Train net output #0: loss = 0.141384 (* 1 = 0.141384 loss)
I0502 11:32:37.922016 26473 sgd_solver.cpp:106] Iteration 137300, lr = 5.49756e-06
I0502 11:32:38.861624 26473 solver.cpp:242] Iteration 137400 (105.889 iter/s, 0.944382s/100 iter), loss = 0.0785954
I0502 11:32:38.861666 26473 solver.cpp:261]     Train net output #0: loss = 0.0785954 (* 1 = 0.0785954 loss)
I0502 11:32:38.861675 26473 sgd_solver.cpp:106] Iteration 137400, lr = 5.49756e-06
I0502 11:32:38.866437 26473 solver.cpp:242] Iteration 137400 (105.886 iter/s, 0.944411s/100 iter), loss = 0.0406329
I0502 11:32:38.866461 26473 solver.cpp:261]     Train net output #0: loss = 0.0406329 (* 1 = 0.0406329 loss)
I0502 11:32:38.866469 26473 sgd_solver.cpp:106] Iteration 137400, lr = 5.49756e-06
I0502 11:32:39.802208 26473 solver.cpp:362] Iteration 137500, Testing net (#0)
I0502 11:32:39.802237 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:39.926369 26473 solver.cpp:429]     Test net output #0: loss = 0.242307 (* 1 = 0.242307 loss)
I0502 11:32:39.929255 26473 solver.cpp:242] Iteration 137500 (93.6707 iter/s, 1.06757s/100 iter), loss = 0.138799
I0502 11:32:39.929275 26473 solver.cpp:261]     Train net output #0: loss = 0.138799 (* 1 = 0.138799 loss)
I0502 11:32:39.929283 26473 sgd_solver.cpp:106] Iteration 137500, lr = 5.49756e-06
I0502 11:32:39.930901 26473 solver.cpp:362] Iteration 137500, Testing net (#0)
I0502 11:32:39.930920 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:40.061475 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9615
I0502 11:32:40.061498 26473 solver.cpp:429]     Test net output #1: loss = 0.0821971 (* 1 = 0.0821971 loss)
I0502 11:32:40.064425 26473 solver.cpp:242] Iteration 137500 (83.4764 iter/s, 1.19794s/100 iter), loss = 0.0962761
I0502 11:32:40.064445 26473 solver.cpp:261]     Train net output #0: loss = 0.0962761 (* 1 = 0.0962761 loss)
I0502 11:32:40.064453 26473 sgd_solver.cpp:106] Iteration 137500, lr = 5.49756e-06
I0502 11:32:41.003865 26473 solver.cpp:242] Iteration 137600 (93.0613 iter/s, 1.07456s/100 iter), loss = 0.135873
I0502 11:32:41.003907 26473 solver.cpp:261]     Train net output #0: loss = 0.135873 (* 1 = 0.135873 loss)
I0502 11:32:41.003916 26473 sgd_solver.cpp:106] Iteration 137600, lr = 5.49756e-06
I0502 11:32:41.008734 26473 solver.cpp:242] Iteration 137600 (105.902 iter/s, 0.944271s/100 iter), loss = 0.105089
I0502 11:32:41.008757 26473 solver.cpp:261]     Train net output #0: loss = 0.105089 (* 1 = 0.105089 loss)
I0502 11:32:41.008766 26473 sgd_solver.cpp:106] Iteration 137600, lr = 5.49756e-06
I0502 11:32:41.947849 26473 solver.cpp:242] Iteration 137700 (105.942 iter/s, 0.943916s/100 iter), loss = 0.101852
I0502 11:32:41.947888 26473 solver.cpp:261]     Train net output #0: loss = 0.101852 (* 1 = 0.101852 loss)
I0502 11:32:41.947897 26473 sgd_solver.cpp:106] Iteration 137700, lr = 5.49756e-06
I0502 11:32:41.952826 26473 solver.cpp:242] Iteration 137700 (105.928 iter/s, 0.94404s/100 iter), loss = 0.169937
I0502 11:32:41.952850 26473 solver.cpp:261]     Train net output #0: loss = 0.169937 (* 1 = 0.169937 loss)
I0502 11:32:41.952859 26473 sgd_solver.cpp:106] Iteration 137700, lr = 5.49756e-06
I0502 11:32:42.892980 26473 solver.cpp:242] Iteration 137800 (105.813 iter/s, 0.945062s/100 iter), loss = 0.11151
I0502 11:32:42.893019 26473 solver.cpp:261]     Train net output #0: loss = 0.11151 (* 1 = 0.11151 loss)
I0502 11:32:42.893028 26473 sgd_solver.cpp:106] Iteration 137800, lr = 5.49756e-06
I0502 11:32:42.897805 26473 solver.cpp:242] Iteration 137800 (105.827 iter/s, 0.944937s/100 iter), loss = 0.122616
I0502 11:32:42.897828 26473 solver.cpp:261]     Train net output #0: loss = 0.122616 (* 1 = 0.122616 loss)
I0502 11:32:42.897837 26473 sgd_solver.cpp:106] Iteration 137800, lr = 5.49756e-06
I0502 11:32:43.837019 26473 solver.cpp:242] Iteration 137900 (105.936 iter/s, 0.943969s/100 iter), loss = 0.230908
I0502 11:32:43.837059 26473 solver.cpp:261]     Train net output #0: loss = 0.230908 (* 1 = 0.230908 loss)
I0502 11:32:43.837069 26473 sgd_solver.cpp:106] Iteration 137900, lr = 5.49756e-06
I0502 11:32:43.841833 26473 solver.cpp:242] Iteration 137900 (105.934 iter/s, 0.943987s/100 iter), loss = 0.077138
I0502 11:32:43.841856 26473 solver.cpp:261]     Train net output #0: loss = 0.077138 (* 1 = 0.077138 loss)
I0502 11:32:43.841866 26473 sgd_solver.cpp:106] Iteration 137900, lr = 5.49756e-06
I0502 11:32:44.777861 26473 solver.cpp:362] Iteration 138000, Testing net (#0)
I0502 11:32:44.777884 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:44.902226 26473 solver.cpp:429]     Test net output #0: loss = 0.228495 (* 1 = 0.228495 loss)
I0502 11:32:44.905110 26473 solver.cpp:242] Iteration 138000 (93.6301 iter/s, 1.06803s/100 iter), loss = 0.652696
I0502 11:32:44.905130 26473 solver.cpp:261]     Train net output #0: loss = 0.652696 (* 1 = 0.652696 loss)
I0502 11:32:44.905138 26473 sgd_solver.cpp:106] Iteration 138000, lr = 5.49756e-06
I0502 11:32:44.906759 26473 solver.cpp:362] Iteration 138000, Testing net (#0)
I0502 11:32:44.906774 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:45.037400 26473 solver.cpp:429]     Test net output #0: accuracy = 0.969
I0502 11:32:45.037420 26473 solver.cpp:429]     Test net output #1: loss = 0.0751291 (* 1 = 0.0751291 loss)
I0502 11:32:45.040338 26473 solver.cpp:242] Iteration 138000 (83.4404 iter/s, 1.19846s/100 iter), loss = 0.0595099
I0502 11:32:45.040357 26473 solver.cpp:261]     Train net output #0: loss = 0.0595099 (* 1 = 0.0595099 loss)
I0502 11:32:45.040374 26473 sgd_solver.cpp:106] Iteration 138000, lr = 5.49756e-06
I0502 11:32:45.979087 26473 solver.cpp:242] Iteration 138100 (93.116 iter/s, 1.07393s/100 iter), loss = 0.0324706
I0502 11:32:45.979122 26473 solver.cpp:261]     Train net output #0: loss = 0.0324706 (* 1 = 0.0324706 loss)
I0502 11:32:45.979131 26473 sgd_solver.cpp:106] Iteration 138100, lr = 5.49756e-06
I0502 11:32:45.983889 26473 solver.cpp:242] Iteration 138100 (105.987 iter/s, 0.943514s/100 iter), loss = 0.204328
I0502 11:32:45.983913 26473 solver.cpp:261]     Train net output #0: loss = 0.204328 (* 1 = 0.204328 loss)
I0502 11:32:45.983922 26473 sgd_solver.cpp:106] Iteration 138100, lr = 5.49756e-06
I0502 11:32:46.923995 26473 solver.cpp:242] Iteration 138200 (105.837 iter/s, 0.944849s/100 iter), loss = 0.159521
I0502 11:32:46.924026 26473 solver.cpp:261]     Train net output #0: loss = 0.159521 (* 1 = 0.159521 loss)
I0502 11:32:46.924036 26473 sgd_solver.cpp:106] Iteration 138200, lr = 5.49756e-06
I0502 11:32:46.928880 26473 solver.cpp:242] Iteration 138200 (105.827 iter/s, 0.94494s/100 iter), loss = 0.0352785
I0502 11:32:46.928903 26473 solver.cpp:261]     Train net output #0: loss = 0.0352785 (* 1 = 0.0352785 loss)
I0502 11:32:46.928911 26473 sgd_solver.cpp:106] Iteration 138200, lr = 5.49756e-06
I0502 11:32:47.867445 26473 solver.cpp:242] Iteration 138300 (106.001 iter/s, 0.943389s/100 iter), loss = 0.240927
I0502 11:32:47.867487 26473 solver.cpp:261]     Train net output #0: loss = 0.240927 (* 1 = 0.240927 loss)
I0502 11:32:47.867496 26473 sgd_solver.cpp:106] Iteration 138300, lr = 5.49756e-06
I0502 11:32:47.872241 26473 solver.cpp:242] Iteration 138300 (106.009 iter/s, 0.94332s/100 iter), loss = 0.0842298
I0502 11:32:47.872263 26473 solver.cpp:261]     Train net output #0: loss = 0.0842298 (* 1 = 0.0842298 loss)
I0502 11:32:47.872272 26473 sgd_solver.cpp:106] Iteration 138300, lr = 5.49756e-06
I0502 11:32:48.811305 26473 solver.cpp:242] Iteration 138400 (105.956 iter/s, 0.943786s/100 iter), loss = 0.200226
I0502 11:32:48.811349 26473 solver.cpp:261]     Train net output #0: loss = 0.200226 (* 1 = 0.200226 loss)
I0502 11:32:48.811358 26473 sgd_solver.cpp:106] Iteration 138400, lr = 5.49756e-06
I0502 11:32:48.816155 26473 solver.cpp:242] Iteration 138400 (105.946 iter/s, 0.943874s/100 iter), loss = 0.109489
I0502 11:32:48.816179 26473 solver.cpp:261]     Train net output #0: loss = 0.109489 (* 1 = 0.109489 loss)
I0502 11:32:48.816187 26473 sgd_solver.cpp:106] Iteration 138400, lr = 5.49756e-06
I0502 11:32:49.752009 26473 solver.cpp:362] Iteration 138500, Testing net (#0)
I0502 11:32:49.752038 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:49.876338 26473 solver.cpp:429]     Test net output #0: loss = 0.263771 (* 1 = 0.263771 loss)
I0502 11:32:49.879206 26473 solver.cpp:242] Iteration 138500 (93.647 iter/s, 1.06784s/100 iter), loss = 0.500621
I0502 11:32:49.879227 26473 solver.cpp:261]     Train net output #0: loss = 0.500621 (* 1 = 0.500621 loss)
I0502 11:32:49.879235 26473 sgd_solver.cpp:106] Iteration 138500, lr = 5.49756e-06
I0502 11:32:49.880872 26473 solver.cpp:362] Iteration 138500, Testing net (#0)
I0502 11:32:49.880887 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:50.011283 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:32:50.011306 26473 solver.cpp:429]     Test net output #1: loss = 0.0874371 (* 1 = 0.0874371 loss)
I0502 11:32:50.014236 26473 solver.cpp:242] Iteration 138500 (83.4698 iter/s, 1.19804s/100 iter), loss = 0.0513573
I0502 11:32:50.014257 26473 solver.cpp:261]     Train net output #0: loss = 0.0513573 (* 1 = 0.0513573 loss)
I0502 11:32:50.014266 26473 sgd_solver.cpp:106] Iteration 138500, lr = 5.49756e-06
I0502 11:32:50.954392 26473 solver.cpp:242] Iteration 138600 (93.0116 iter/s, 1.07513s/100 iter), loss = 0.0999241
I0502 11:32:50.954452 26473 solver.cpp:261]     Train net output #0: loss = 0.0999241 (* 1 = 0.0999241 loss)
I0502 11:32:50.954463 26473 sgd_solver.cpp:106] Iteration 138600, lr = 5.49756e-06
I0502 11:32:50.959291 26473 solver.cpp:242] Iteration 138600 (105.818 iter/s, 0.945016s/100 iter), loss = 0.0239824
I0502 11:32:50.959314 26473 solver.cpp:261]     Train net output #0: loss = 0.0239824 (* 1 = 0.0239824 loss)
I0502 11:32:50.959322 26473 sgd_solver.cpp:106] Iteration 138600, lr = 5.49756e-06
I0502 11:32:51.898010 26473 solver.cpp:242] Iteration 138700 (105.985 iter/s, 0.943534s/100 iter), loss = 0.135954
I0502 11:32:51.898048 26473 solver.cpp:261]     Train net output #0: loss = 0.135954 (* 1 = 0.135954 loss)
I0502 11:32:51.898058 26473 sgd_solver.cpp:106] Iteration 138700, lr = 5.49756e-06
I0502 11:32:51.902885 26473 solver.cpp:242] Iteration 138700 (105.983 iter/s, 0.943544s/100 iter), loss = 0.0641934
I0502 11:32:51.902909 26473 solver.cpp:261]     Train net output #0: loss = 0.0641934 (* 1 = 0.0641934 loss)
I0502 11:32:51.902918 26473 sgd_solver.cpp:106] Iteration 138700, lr = 5.49756e-06
I0502 11:32:52.843111 26473 solver.cpp:242] Iteration 138800 (105.817 iter/s, 0.945032s/100 iter), loss = 0.204442
I0502 11:32:52.843152 26473 solver.cpp:261]     Train net output #0: loss = 0.204442 (* 1 = 0.204442 loss)
I0502 11:32:52.843160 26473 sgd_solver.cpp:106] Iteration 138800, lr = 5.49756e-06
I0502 11:32:52.847952 26473 solver.cpp:242] Iteration 138800 (105.817 iter/s, 0.945025s/100 iter), loss = 0.0336079
I0502 11:32:52.847975 26473 solver.cpp:261]     Train net output #0: loss = 0.0336079 (* 1 = 0.0336079 loss)
I0502 11:32:52.847985 26473 sgd_solver.cpp:106] Iteration 138800, lr = 5.49756e-06
I0502 11:32:53.787160 26473 solver.cpp:242] Iteration 138900 (105.935 iter/s, 0.94398s/100 iter), loss = 0.212494
I0502 11:32:53.787199 26473 solver.cpp:261]     Train net output #0: loss = 0.212494 (* 1 = 0.212494 loss)
I0502 11:32:53.787207 26473 sgd_solver.cpp:106] Iteration 138900, lr = 5.49756e-06
I0502 11:32:53.791965 26473 solver.cpp:242] Iteration 138900 (105.935 iter/s, 0.943971s/100 iter), loss = 0.0878439
I0502 11:32:53.791987 26473 solver.cpp:261]     Train net output #0: loss = 0.0878439 (* 1 = 0.0878439 loss)
I0502 11:32:53.791996 26473 sgd_solver.cpp:106] Iteration 138900, lr = 5.49756e-06
I0502 11:32:54.728736 26473 solver.cpp:362] Iteration 139000, Testing net (#0)
I0502 11:32:54.728761 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:54.853075 26473 solver.cpp:429]     Test net output #0: loss = 0.280314 (* 1 = 0.280314 loss)
I0502 11:32:54.855965 26473 solver.cpp:242] Iteration 139000 (93.5674 iter/s, 1.06875s/100 iter), loss = 0.0579521
I0502 11:32:54.855985 26473 solver.cpp:261]     Train net output #0: loss = 0.0579521 (* 1 = 0.0579521 loss)
I0502 11:32:54.855993 26473 sgd_solver.cpp:106] Iteration 139000, lr = 5.49756e-06
I0502 11:32:54.857619 26473 solver.cpp:362] Iteration 139000, Testing net (#0)
I0502 11:32:54.857631 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:54.988126 26473 solver.cpp:429]     Test net output #0: accuracy = 0.967
I0502 11:32:54.988147 26473 solver.cpp:429]     Test net output #1: loss = 0.0761806 (* 1 = 0.0761806 loss)
I0502 11:32:54.991077 26473 solver.cpp:242] Iteration 139000 (83.398 iter/s, 1.19907s/100 iter), loss = 0.00110786
I0502 11:32:54.991098 26473 solver.cpp:261]     Train net output #0: loss = 0.00110786 (* 1 = 0.00110786 loss)
I0502 11:32:54.991106 26473 sgd_solver.cpp:106] Iteration 139000, lr = 5.49756e-06
I0502 11:32:55.932021 26473 solver.cpp:242] Iteration 139100 (92.9363 iter/s, 1.07601s/100 iter), loss = 0.662895
I0502 11:32:55.932060 26473 solver.cpp:261]     Train net output #0: loss = 0.662895 (* 1 = 0.662895 loss)
I0502 11:32:55.932070 26473 sgd_solver.cpp:106] Iteration 139100, lr = 5.49756e-06
I0502 11:32:55.936836 26473 solver.cpp:242] Iteration 139100 (105.74 iter/s, 0.945719s/100 iter), loss = 0.0377802
I0502 11:32:55.936861 26473 solver.cpp:261]     Train net output #0: loss = 0.0377802 (* 1 = 0.0377802 loss)
I0502 11:32:55.936868 26473 sgd_solver.cpp:106] Iteration 139100, lr = 5.49756e-06
I0502 11:32:56.875784 26473 solver.cpp:242] Iteration 139200 (105.966 iter/s, 0.943701s/100 iter), loss = 0.0967143
I0502 11:32:56.875823 26473 solver.cpp:261]     Train net output #0: loss = 0.0967143 (* 1 = 0.0967143 loss)
I0502 11:32:56.875833 26473 sgd_solver.cpp:106] Iteration 139200, lr = 5.49756e-06
I0502 11:32:56.880697 26473 solver.cpp:242] Iteration 139200 (105.954 iter/s, 0.943809s/100 iter), loss = 0.0494628
I0502 11:32:56.880720 26473 solver.cpp:261]     Train net output #0: loss = 0.0494628 (* 1 = 0.0494628 loss)
I0502 11:32:56.880729 26473 sgd_solver.cpp:106] Iteration 139200, lr = 5.49756e-06
I0502 11:32:57.819913 26473 solver.cpp:242] Iteration 139300 (105.925 iter/s, 0.944067s/100 iter), loss = 0.110216
I0502 11:32:57.819958 26473 solver.cpp:261]     Train net output #0: loss = 0.110216 (* 1 = 0.110216 loss)
I0502 11:32:57.819967 26473 sgd_solver.cpp:106] Iteration 139300, lr = 5.49756e-06
I0502 11:32:57.824784 26473 solver.cpp:242] Iteration 139300 (105.928 iter/s, 0.94404s/100 iter), loss = 0.00618513
I0502 11:32:57.824808 26473 solver.cpp:261]     Train net output #0: loss = 0.00618513 (* 1 = 0.00618513 loss)
I0502 11:32:57.824816 26473 sgd_solver.cpp:106] Iteration 139300, lr = 5.49756e-06
I0502 11:32:58.764689 26473 solver.cpp:242] Iteration 139400 (105.854 iter/s, 0.944701s/100 iter), loss = 0.0722754
I0502 11:32:58.764731 26473 solver.cpp:261]     Train net output #0: loss = 0.0722754 (* 1 = 0.0722754 loss)
I0502 11:32:58.764740 26473 sgd_solver.cpp:106] Iteration 139400, lr = 5.49756e-06
I0502 11:32:58.769512 26473 solver.cpp:242] Iteration 139400 (105.855 iter/s, 0.944686s/100 iter), loss = 0.115552
I0502 11:32:58.769534 26473 solver.cpp:261]     Train net output #0: loss = 0.115552 (* 1 = 0.115552 loss)
I0502 11:32:58.769543 26473 sgd_solver.cpp:106] Iteration 139400, lr = 5.49756e-06
I0502 11:32:59.704617 26473 solver.cpp:362] Iteration 139500, Testing net (#0)
I0502 11:32:59.704645 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:59.828963 26473 solver.cpp:429]     Test net output #0: loss = 0.23885 (* 1 = 0.23885 loss)
I0502 11:32:59.831838 26473 solver.cpp:242] Iteration 139500 (93.7129 iter/s, 1.06709s/100 iter), loss = 0.184173
I0502 11:32:59.831858 26473 solver.cpp:261]     Train net output #0: loss = 0.184173 (* 1 = 0.184173 loss)
I0502 11:32:59.831866 26473 sgd_solver.cpp:106] Iteration 139500, lr = 5.49756e-06
I0502 11:32:59.833492 26473 solver.cpp:362] Iteration 139500, Testing net (#0)
I0502 11:32:59.833506 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:32:59.964100 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9665
I0502 11:32:59.964118 26473 solver.cpp:429]     Test net output #1: loss = 0.0851583 (* 1 = 0.0851583 loss)
I0502 11:32:59.967037 26473 solver.cpp:242] Iteration 139500 (83.5086 iter/s, 1.19748s/100 iter), loss = 0.120162
I0502 11:32:59.967057 26473 solver.cpp:261]     Train net output #0: loss = 0.120162 (* 1 = 0.120162 loss)
I0502 11:32:59.967067 26473 sgd_solver.cpp:106] Iteration 139500, lr = 5.49756e-06
I0502 11:33:00.924192 26473 solver.cpp:242] Iteration 139600 (91.5496 iter/s, 1.0923s/100 iter), loss = 0.0484993
I0502 11:33:00.924237 26473 solver.cpp:261]     Train net output #0: loss = 0.0484993 (* 1 = 0.0484993 loss)
I0502 11:33:00.924247 26473 sgd_solver.cpp:106] Iteration 139600, lr = 5.49756e-06
I0502 11:33:00.929141 26473 solver.cpp:242] Iteration 139600 (103.943 iter/s, 0.962064s/100 iter), loss = 0.150806
I0502 11:33:00.929164 26473 solver.cpp:261]     Train net output #0: loss = 0.150806 (* 1 = 0.150806 loss)
I0502 11:33:00.929173 26473 sgd_solver.cpp:106] Iteration 139600, lr = 5.49756e-06
I0502 11:33:01.875160 26473 solver.cpp:242] Iteration 139700 (105.164 iter/s, 0.950898s/100 iter), loss = 0.0924368
I0502 11:33:01.875207 26473 solver.cpp:261]     Train net output #0: loss = 0.0924368 (* 1 = 0.0924368 loss)
I0502 11:33:01.875219 26473 sgd_solver.cpp:106] Iteration 139700, lr = 5.49756e-06
I0502 11:33:01.880040 26473 solver.cpp:242] Iteration 139700 (105.168 iter/s, 0.950858s/100 iter), loss = 0.0101729
I0502 11:33:01.880064 26473 solver.cpp:261]     Train net output #0: loss = 0.0101729 (* 1 = 0.0101729 loss)
I0502 11:33:01.880080 26473 sgd_solver.cpp:106] Iteration 139700, lr = 5.49756e-06
I0502 11:33:02.828488 26473 solver.cpp:242] Iteration 139800 (104.904 iter/s, 0.953257s/100 iter), loss = 0.194649
I0502 11:33:02.828532 26473 solver.cpp:261]     Train net output #0: loss = 0.194649 (* 1 = 0.194649 loss)
I0502 11:33:02.828541 26473 sgd_solver.cpp:106] Iteration 139800, lr = 5.49756e-06
I0502 11:33:02.833420 26473 solver.cpp:242] Iteration 139800 (104.896 iter/s, 0.953329s/100 iter), loss = 0.0751484
I0502 11:33:02.833444 26473 solver.cpp:261]     Train net output #0: loss = 0.0751484 (* 1 = 0.0751484 loss)
I0502 11:33:02.833452 26473 sgd_solver.cpp:106] Iteration 139800, lr = 5.49756e-06
I0502 11:33:03.781589 26473 solver.cpp:242] Iteration 139900 (104.929 iter/s, 0.953028s/100 iter), loss = 0.101886
I0502 11:33:03.781630 26473 solver.cpp:261]     Train net output #0: loss = 0.101886 (* 1 = 0.101886 loss)
I0502 11:33:03.781639 26473 sgd_solver.cpp:106] Iteration 139900, lr = 5.49756e-06
I0502 11:33:03.786444 26473 solver.cpp:242] Iteration 139900 (104.934 iter/s, 0.952982s/100 iter), loss = 0.180302
I0502 11:33:03.786468 26473 solver.cpp:261]     Train net output #0: loss = 0.180302 (* 1 = 0.180302 loss)
I0502 11:33:03.786476 26473 sgd_solver.cpp:106] Iteration 139900, lr = 5.49756e-06
I0502 11:33:04.726593 26473 solver.cpp:362] Iteration 140000, Testing net (#0)
I0502 11:33:04.726619 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:04.851001 26473 solver.cpp:429]     Test net output #0: loss = 0.198958 (* 1 = 0.198958 loss)
I0502 11:33:04.853883 26473 solver.cpp:242] Iteration 140000 (93.2632 iter/s, 1.07223s/100 iter), loss = 0.481088
I0502 11:33:04.853904 26473 solver.cpp:261]     Train net output #0: loss = 0.481088 (* 1 = 0.481088 loss)
I0502 11:33:04.853912 26473 sgd_solver.cpp:106] Iteration 140000, lr = 4.39805e-06
I0502 11:33:04.855589 26473 solver.cpp:362] Iteration 140000, Testing net (#0)
I0502 11:33:04.855602 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:04.986299 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:33:04.986320 26473 solver.cpp:429]     Test net output #1: loss = 0.0764586 (* 1 = 0.0764586 loss)
I0502 11:33:04.989239 26473 solver.cpp:242] Iteration 140000 (83.1427 iter/s, 1.20275s/100 iter), loss = 0.0175901
I0502 11:33:04.989259 26473 solver.cpp:261]     Train net output #0: loss = 0.0175901 (* 1 = 0.0175901 loss)
I0502 11:33:04.989267 26473 sgd_solver.cpp:106] Iteration 140000, lr = 4.39805e-06
I0502 11:33:05.928020 26473 solver.cpp:242] Iteration 140100 (93.1023 iter/s, 1.07409s/100 iter), loss = 0.332088
I0502 11:33:05.928061 26473 solver.cpp:261]     Train net output #0: loss = 0.332088 (* 1 = 0.332088 loss)
I0502 11:33:05.928071 26473 sgd_solver.cpp:106] Iteration 140100, lr = 4.39805e-06
I0502 11:33:05.932854 26473 solver.cpp:242] Iteration 140100 (105.98 iter/s, 0.943577s/100 iter), loss = 0.120992
I0502 11:33:05.932878 26473 solver.cpp:261]     Train net output #0: loss = 0.120992 (* 1 = 0.120992 loss)
I0502 11:33:05.932886 26473 sgd_solver.cpp:106] Iteration 140100, lr = 4.39805e-06
I0502 11:33:06.872673 26473 solver.cpp:242] Iteration 140200 (105.867 iter/s, 0.944586s/100 iter), loss = 0.0535456
I0502 11:33:06.872717 26473 solver.cpp:261]     Train net output #0: loss = 0.0535456 (* 1 = 0.0535456 loss)
I0502 11:33:06.872727 26473 sgd_solver.cpp:106] Iteration 140200, lr = 4.39805e-06
I0502 11:33:06.877514 26473 solver.cpp:242] Iteration 140200 (105.863 iter/s, 0.944618s/100 iter), loss = 0.0311305
I0502 11:33:06.877539 26473 solver.cpp:261]     Train net output #0: loss = 0.0311305 (* 1 = 0.0311305 loss)
I0502 11:33:06.877548 26473 sgd_solver.cpp:106] Iteration 140200, lr = 4.39805e-06
I0502 11:33:07.817772 26473 solver.cpp:242] Iteration 140300 (105.817 iter/s, 0.945032s/100 iter), loss = 0.0858548
I0502 11:33:07.817811 26473 solver.cpp:261]     Train net output #0: loss = 0.0858548 (* 1 = 0.0858548 loss)
I0502 11:33:07.817819 26473 sgd_solver.cpp:106] Iteration 140300, lr = 4.39805e-06
I0502 11:33:07.822656 26473 solver.cpp:242] Iteration 140300 (105.81 iter/s, 0.945091s/100 iter), loss = 0.131475
I0502 11:33:07.822679 26473 solver.cpp:261]     Train net output #0: loss = 0.131475 (* 1 = 0.131475 loss)
I0502 11:33:07.822687 26473 sgd_solver.cpp:106] Iteration 140300, lr = 4.39805e-06
I0502 11:33:08.762181 26473 solver.cpp:242] Iteration 140400 (105.894 iter/s, 0.944341s/100 iter), loss = 0.155086
I0502 11:33:08.762215 26473 solver.cpp:261]     Train net output #0: loss = 0.155086 (* 1 = 0.155086 loss)
I0502 11:33:08.762224 26473 sgd_solver.cpp:106] Iteration 140400, lr = 4.39805e-06
I0502 11:33:08.766976 26473 solver.cpp:242] Iteration 140400 (105.901 iter/s, 0.944279s/100 iter), loss = 0.0233882
I0502 11:33:08.766999 26473 solver.cpp:261]     Train net output #0: loss = 0.0233882 (* 1 = 0.0233882 loss)
I0502 11:33:08.767007 26473 sgd_solver.cpp:106] Iteration 140400, lr = 4.39805e-06
I0502 11:33:09.703025 26473 solver.cpp:362] Iteration 140500, Testing net (#0)
I0502 11:33:09.703048 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:09.827327 26473 solver.cpp:429]     Test net output #0: loss = 0.279187 (* 1 = 0.279187 loss)
I0502 11:33:09.830191 26473 solver.cpp:242] Iteration 140500 (93.6367 iter/s, 1.06796s/100 iter), loss = 0.202345
I0502 11:33:09.830212 26473 solver.cpp:261]     Train net output #0: loss = 0.202345 (* 1 = 0.202345 loss)
I0502 11:33:09.830220 26473 sgd_solver.cpp:106] Iteration 140500, lr = 4.39805e-06
I0502 11:33:09.831832 26473 solver.cpp:362] Iteration 140500, Testing net (#0)
I0502 11:33:09.831845 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:09.962427 26473 solver.cpp:429]     Test net output #0: accuracy = 0.959
I0502 11:33:09.962447 26473 solver.cpp:429]     Test net output #1: loss = 0.100519 (* 1 = 0.100519 loss)
I0502 11:33:09.965392 26473 solver.cpp:242] Iteration 140500 (83.4465 iter/s, 1.19837s/100 iter), loss = 0.18959
I0502 11:33:09.965412 26473 solver.cpp:261]     Train net output #0: loss = 0.18959 (* 1 = 0.18959 loss)
I0502 11:33:09.965421 26473 sgd_solver.cpp:106] Iteration 140500, lr = 4.39805e-06
I0502 11:33:10.904124 26473 solver.cpp:242] Iteration 140600 (93.1201 iter/s, 1.07388s/100 iter), loss = 0.148476
I0502 11:33:10.904162 26473 solver.cpp:261]     Train net output #0: loss = 0.148476 (* 1 = 0.148476 loss)
I0502 11:33:10.904171 26473 sgd_solver.cpp:106] Iteration 140600, lr = 4.39805e-06
I0502 11:33:10.908941 26473 solver.cpp:242] Iteration 140600 (105.987 iter/s, 0.94351s/100 iter), loss = 0.021845
I0502 11:33:10.908963 26473 solver.cpp:261]     Train net output #0: loss = 0.021845 (* 1 = 0.021845 loss)
I0502 11:33:10.908972 26473 sgd_solver.cpp:106] Iteration 140600, lr = 4.39805e-06
I0502 11:33:11.848840 26473 solver.cpp:242] Iteration 140700 (105.859 iter/s, 0.944653s/100 iter), loss = 0.176131
I0502 11:33:11.848878 26473 solver.cpp:261]     Train net output #0: loss = 0.176131 (* 1 = 0.176131 loss)
I0502 11:33:11.848886 26473 sgd_solver.cpp:106] Iteration 140700, lr = 4.39805e-06
I0502 11:33:11.853642 26473 solver.cpp:242] Iteration 140700 (105.858 iter/s, 0.944661s/100 iter), loss = 0.103833
I0502 11:33:11.853665 26473 solver.cpp:261]     Train net output #0: loss = 0.103833 (* 1 = 0.103833 loss)
I0502 11:33:11.853674 26473 sgd_solver.cpp:106] Iteration 140700, lr = 4.39805e-06
I0502 11:33:12.793090 26473 solver.cpp:242] Iteration 140800 (105.911 iter/s, 0.944189s/100 iter), loss = 0.122866
I0502 11:33:12.793123 26473 solver.cpp:261]     Train net output #0: loss = 0.122866 (* 1 = 0.122866 loss)
I0502 11:33:12.793133 26473 sgd_solver.cpp:106] Iteration 140800, lr = 4.39805e-06
I0502 11:33:12.797942 26473 solver.cpp:242] Iteration 140800 (105.904 iter/s, 0.944251s/100 iter), loss = 0.032933
I0502 11:33:12.797965 26473 solver.cpp:261]     Train net output #0: loss = 0.032933 (* 1 = 0.032933 loss)
I0502 11:33:12.797972 26473 sgd_solver.cpp:106] Iteration 140800, lr = 4.39805e-06
I0502 11:33:13.737279 26473 solver.cpp:242] Iteration 140900 (105.918 iter/s, 0.944124s/100 iter), loss = 0.110938
I0502 11:33:13.737323 26473 solver.cpp:261]     Train net output #0: loss = 0.110938 (* 1 = 0.110938 loss)
I0502 11:33:13.737339 26473 sgd_solver.cpp:106] Iteration 140900, lr = 4.39805e-06
I0502 11:33:13.742118 26473 solver.cpp:242] Iteration 140900 (105.917 iter/s, 0.944136s/100 iter), loss = 0.0345
I0502 11:33:13.742141 26473 solver.cpp:261]     Train net output #0: loss = 0.0345 (* 1 = 0.0345 loss)
I0502 11:33:13.742151 26473 sgd_solver.cpp:106] Iteration 140900, lr = 4.39805e-06
I0502 11:33:14.677575 26473 solver.cpp:362] Iteration 141000, Testing net (#0)
I0502 11:33:14.677604 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:14.801966 26473 solver.cpp:429]     Test net output #0: loss = 0.273516 (* 1 = 0.273516 loss)
I0502 11:33:14.804841 26473 solver.cpp:242] Iteration 141000 (93.6768 iter/s, 1.0675s/100 iter), loss = 0.0654856
I0502 11:33:14.804862 26473 solver.cpp:261]     Train net output #0: loss = 0.0654856 (* 1 = 0.0654856 loss)
I0502 11:33:14.804870 26473 sgd_solver.cpp:106] Iteration 141000, lr = 4.39805e-06
I0502 11:33:14.806498 26473 solver.cpp:362] Iteration 141000, Testing net (#0)
I0502 11:33:14.806509 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:14.937163 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:33:14.937185 26473 solver.cpp:429]     Test net output #1: loss = 0.0839725 (* 1 = 0.0839725 loss)
I0502 11:33:14.940098 26473 solver.cpp:242] Iteration 141000 (83.477 iter/s, 1.19793s/100 iter), loss = 0.0143764
I0502 11:33:14.940116 26473 solver.cpp:261]     Train net output #0: loss = 0.0143764 (* 1 = 0.0143764 loss)
I0502 11:33:14.940124 26473 sgd_solver.cpp:106] Iteration 141000, lr = 4.39805e-06
I0502 11:33:15.880385 26473 solver.cpp:242] Iteration 141100 (92.9806 iter/s, 1.07549s/100 iter), loss = 0.0967479
I0502 11:33:15.880432 26473 solver.cpp:261]     Train net output #0: loss = 0.0967479 (* 1 = 0.0967479 loss)
I0502 11:33:15.880440 26473 sgd_solver.cpp:106] Iteration 141100, lr = 4.39805e-06
I0502 11:33:15.885190 26473 solver.cpp:242] Iteration 141100 (105.814 iter/s, 0.945057s/100 iter), loss = 0.072286
I0502 11:33:15.885213 26473 solver.cpp:261]     Train net output #0: loss = 0.072286 (* 1 = 0.072286 loss)
I0502 11:33:15.885221 26473 sgd_solver.cpp:106] Iteration 141100, lr = 4.39805e-06
I0502 11:33:16.824201 26473 solver.cpp:242] Iteration 141200 (105.961 iter/s, 0.943743s/100 iter), loss = 0.135085
I0502 11:33:16.824245 26473 solver.cpp:261]     Train net output #0: loss = 0.135085 (* 1 = 0.135085 loss)
I0502 11:33:16.824254 26473 sgd_solver.cpp:106] Iteration 141200, lr = 4.39805e-06
I0502 11:33:16.829023 26473 solver.cpp:242] Iteration 141200 (105.956 iter/s, 0.943792s/100 iter), loss = 0.0728785
I0502 11:33:16.829047 26473 solver.cpp:261]     Train net output #0: loss = 0.0728785 (* 1 = 0.0728785 loss)
I0502 11:33:16.829056 26473 sgd_solver.cpp:106] Iteration 141200, lr = 4.39805e-06
I0502 11:33:17.768887 26473 solver.cpp:242] Iteration 141300 (105.863 iter/s, 0.944618s/100 iter), loss = 0.149917
I0502 11:33:17.768941 26473 solver.cpp:261]     Train net output #0: loss = 0.149917 (* 1 = 0.149917 loss)
I0502 11:33:17.768951 26473 sgd_solver.cpp:106] Iteration 141300, lr = 4.39805e-06
I0502 11:33:17.773810 26473 solver.cpp:242] Iteration 141300 (105.85 iter/s, 0.944736s/100 iter), loss = 0.0749519
I0502 11:33:17.773834 26473 solver.cpp:261]     Train net output #0: loss = 0.0749519 (* 1 = 0.0749519 loss)
I0502 11:33:17.773844 26473 sgd_solver.cpp:106] Iteration 141300, lr = 4.39805e-06
I0502 11:33:18.713146 26473 solver.cpp:242] Iteration 141400 (105.913 iter/s, 0.944174s/100 iter), loss = 0.229718
I0502 11:33:18.713186 26473 solver.cpp:261]     Train net output #0: loss = 0.229718 (* 1 = 0.229718 loss)
I0502 11:33:18.713196 26473 sgd_solver.cpp:106] Iteration 141400, lr = 4.39805e-06
I0502 11:33:18.717949 26473 solver.cpp:242] Iteration 141400 (105.921 iter/s, 0.944097s/100 iter), loss = 0.101377
I0502 11:33:18.717972 26473 solver.cpp:261]     Train net output #0: loss = 0.101377 (* 1 = 0.101377 loss)
I0502 11:33:18.717981 26473 sgd_solver.cpp:106] Iteration 141400, lr = 4.39805e-06
I0502 11:33:19.654624 26473 solver.cpp:362] Iteration 141500, Testing net (#0)
I0502 11:33:19.654651 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:19.778895 26473 solver.cpp:429]     Test net output #0: loss = 0.220634 (* 1 = 0.220634 loss)
I0502 11:33:19.781760 26473 solver.cpp:242] Iteration 141500 (93.5843 iter/s, 1.06856s/100 iter), loss = 0.139224
I0502 11:33:19.781780 26473 solver.cpp:261]     Train net output #0: loss = 0.139224 (* 1 = 0.139224 loss)
I0502 11:33:19.781790 26473 sgd_solver.cpp:106] Iteration 141500, lr = 4.39805e-06
I0502 11:33:19.783409 26473 solver.cpp:362] Iteration 141500, Testing net (#0)
I0502 11:33:19.783421 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:19.914162 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9645
I0502 11:33:19.914183 26473 solver.cpp:429]     Test net output #1: loss = 0.0741721 (* 1 = 0.0741721 loss)
I0502 11:33:19.917106 26473 solver.cpp:242] Iteration 141500 (83.395 iter/s, 1.19911s/100 iter), loss = 0.00586683
I0502 11:33:19.917126 26473 solver.cpp:261]     Train net output #0: loss = 0.00586683 (* 1 = 0.00586683 loss)
I0502 11:33:19.917135 26473 sgd_solver.cpp:106] Iteration 141500, lr = 4.39805e-06
I0502 11:33:20.856459 26473 solver.cpp:242] Iteration 141600 (93.0537 iter/s, 1.07465s/100 iter), loss = 0.388439
I0502 11:33:20.856497 26473 solver.cpp:261]     Train net output #0: loss = 0.388439 (* 1 = 0.388439 loss)
I0502 11:33:20.856505 26473 sgd_solver.cpp:106] Iteration 141600, lr = 4.39805e-06
I0502 11:33:20.861275 26473 solver.cpp:242] Iteration 141600 (105.917 iter/s, 0.944132s/100 iter), loss = 0.0535929
I0502 11:33:20.861299 26473 solver.cpp:261]     Train net output #0: loss = 0.0535929 (* 1 = 0.0535929 loss)
I0502 11:33:20.861306 26473 sgd_solver.cpp:106] Iteration 141600, lr = 4.39805e-06
I0502 11:33:21.800709 26473 solver.cpp:242] Iteration 141700 (105.911 iter/s, 0.944185s/100 iter), loss = 0.18403
I0502 11:33:21.800750 26473 solver.cpp:261]     Train net output #0: loss = 0.18403 (* 1 = 0.18403 loss)
I0502 11:33:21.800758 26473 sgd_solver.cpp:106] Iteration 141700, lr = 4.39805e-06
I0502 11:33:21.805615 26473 solver.cpp:242] Iteration 141700 (105.899 iter/s, 0.944298s/100 iter), loss = 0.117844
I0502 11:33:21.805639 26473 solver.cpp:261]     Train net output #0: loss = 0.117844 (* 1 = 0.117844 loss)
I0502 11:33:21.805647 26473 sgd_solver.cpp:106] Iteration 141700, lr = 4.39805e-06
I0502 11:33:22.745050 26473 solver.cpp:242] Iteration 141800 (105.901 iter/s, 0.944277s/100 iter), loss = 0.161776
I0502 11:33:22.745085 26473 solver.cpp:261]     Train net output #0: loss = 0.161776 (* 1 = 0.161776 loss)
I0502 11:33:22.745095 26473 sgd_solver.cpp:106] Iteration 141800, lr = 4.39805e-06
I0502 11:33:22.749917 26473 solver.cpp:242] Iteration 141800 (105.904 iter/s, 0.944252s/100 iter), loss = 0.00269101
I0502 11:33:22.749939 26473 solver.cpp:261]     Train net output #0: loss = 0.00269101 (* 1 = 0.00269101 loss)
I0502 11:33:22.749948 26473 sgd_solver.cpp:106] Iteration 141800, lr = 4.39805e-06
I0502 11:33:23.689051 26473 solver.cpp:242] Iteration 141900 (105.939 iter/s, 0.943943s/100 iter), loss = 0.132478
I0502 11:33:23.689085 26473 solver.cpp:261]     Train net output #0: loss = 0.132478 (* 1 = 0.132478 loss)
I0502 11:33:23.689093 26473 sgd_solver.cpp:106] Iteration 141900, lr = 4.39805e-06
I0502 11:33:23.693924 26473 solver.cpp:242] Iteration 141900 (105.937 iter/s, 0.943961s/100 iter), loss = 0.183187
I0502 11:33:23.693946 26473 solver.cpp:261]     Train net output #0: loss = 0.183187 (* 1 = 0.183187 loss)
I0502 11:33:23.693955 26473 sgd_solver.cpp:106] Iteration 141900, lr = 4.39805e-06
I0502 11:33:24.630190 26473 solver.cpp:362] Iteration 142000, Testing net (#0)
I0502 11:33:24.630218 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:24.754405 26473 solver.cpp:429]     Test net output #0: loss = 0.244804 (* 1 = 0.244804 loss)
I0502 11:33:24.757279 26473 solver.cpp:242] Iteration 142000 (93.6175 iter/s, 1.06818s/100 iter), loss = 0.10142
I0502 11:33:24.757300 26473 solver.cpp:261]     Train net output #0: loss = 0.10142 (* 1 = 0.10142 loss)
I0502 11:33:24.757318 26473 sgd_solver.cpp:106] Iteration 142000, lr = 4.39805e-06
I0502 11:33:24.758941 26473 solver.cpp:362] Iteration 142000, Testing net (#0)
I0502 11:33:24.758955 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:24.889372 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:33:24.889394 26473 solver.cpp:429]     Test net output #1: loss = 0.0835179 (* 1 = 0.0835179 loss)
I0502 11:33:24.892308 26473 solver.cpp:242] Iteration 142000 (83.4488 iter/s, 1.19834s/100 iter), loss = 0.0963827
I0502 11:33:24.892328 26473 solver.cpp:261]     Train net output #0: loss = 0.0963827 (* 1 = 0.0963827 loss)
I0502 11:33:24.892336 26473 sgd_solver.cpp:106] Iteration 142000, lr = 4.39805e-06
I0502 11:33:25.831343 26473 solver.cpp:242] Iteration 142100 (93.1089 iter/s, 1.07401s/100 iter), loss = 0.159528
I0502 11:33:25.831384 26473 solver.cpp:261]     Train net output #0: loss = 0.159528 (* 1 = 0.159528 loss)
I0502 11:33:25.831393 26473 sgd_solver.cpp:106] Iteration 142100, lr = 4.39805e-06
I0502 11:33:25.836182 26473 solver.cpp:242] Iteration 142100 (105.951 iter/s, 0.943835s/100 iter), loss = 0.107535
I0502 11:33:25.836206 26473 solver.cpp:261]     Train net output #0: loss = 0.107535 (* 1 = 0.107535 loss)
I0502 11:33:25.836215 26473 sgd_solver.cpp:106] Iteration 142100, lr = 4.39805e-06
I0502 11:33:26.775096 26473 solver.cpp:242] Iteration 142200 (105.968 iter/s, 0.943686s/100 iter), loss = 0.0749462
I0502 11:33:26.775140 26473 solver.cpp:261]     Train net output #0: loss = 0.0749462 (* 1 = 0.0749462 loss)
I0502 11:33:26.775148 26473 sgd_solver.cpp:106] Iteration 142200, lr = 4.39805e-06
I0502 11:33:26.779903 26473 solver.cpp:242] Iteration 142200 (105.968 iter/s, 0.943679s/100 iter), loss = 0.0750491
I0502 11:33:26.779927 26473 solver.cpp:261]     Train net output #0: loss = 0.0750491 (* 1 = 0.0750491 loss)
I0502 11:33:26.779934 26473 sgd_solver.cpp:106] Iteration 142200, lr = 4.39805e-06
I0502 11:33:27.719709 26473 solver.cpp:242] Iteration 142300 (105.871 iter/s, 0.944544s/100 iter), loss = 0.13196
I0502 11:33:27.719749 26473 solver.cpp:261]     Train net output #0: loss = 0.13196 (* 1 = 0.13196 loss)
I0502 11:33:27.719758 26473 sgd_solver.cpp:106] Iteration 142300, lr = 4.39805e-06
I0502 11:33:27.724658 26473 solver.cpp:242] Iteration 142300 (105.853 iter/s, 0.944704s/100 iter), loss = 0.016014
I0502 11:33:27.724681 26473 solver.cpp:261]     Train net output #0: loss = 0.016014 (* 1 = 0.016014 loss)
I0502 11:33:27.724689 26473 sgd_solver.cpp:106] Iteration 142300, lr = 4.39805e-06
I0502 11:33:28.663455 26473 solver.cpp:242] Iteration 142400 (105.968 iter/s, 0.943683s/100 iter), loss = 0.108502
I0502 11:33:28.663496 26473 solver.cpp:261]     Train net output #0: loss = 0.108502 (* 1 = 0.108502 loss)
I0502 11:33:28.663503 26473 sgd_solver.cpp:106] Iteration 142400, lr = 4.39805e-06
I0502 11:33:28.668351 26473 solver.cpp:242] Iteration 142400 (105.972 iter/s, 0.943647s/100 iter), loss = 0.105658
I0502 11:33:28.668388 26473 solver.cpp:261]     Train net output #0: loss = 0.105658 (* 1 = 0.105658 loss)
I0502 11:33:28.668397 26473 sgd_solver.cpp:106] Iteration 142400, lr = 4.39805e-06
I0502 11:33:29.603544 26473 solver.cpp:362] Iteration 142500, Testing net (#0)
I0502 11:33:29.603566 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:29.727826 26473 solver.cpp:429]     Test net output #0: loss = 0.212563 (* 1 = 0.212563 loss)
I0502 11:33:29.730693 26473 solver.cpp:242] Iteration 142500 (93.7048 iter/s, 1.06718s/100 iter), loss = 0.256883
I0502 11:33:29.730713 26473 solver.cpp:261]     Train net output #0: loss = 0.256883 (* 1 = 0.256883 loss)
I0502 11:33:29.730722 26473 sgd_solver.cpp:106] Iteration 142500, lr = 4.39805e-06
I0502 11:33:29.732343 26473 solver.cpp:362] Iteration 142500, Testing net (#0)
I0502 11:33:29.732355 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:29.863059 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:33:29.863080 26473 solver.cpp:429]     Test net output #1: loss = 0.0857956 (* 1 = 0.0857956 loss)
I0502 11:33:29.866026 26473 solver.cpp:242] Iteration 142500 (83.4991 iter/s, 1.19762s/100 iter), loss = 0.0921527
I0502 11:33:29.866046 26473 solver.cpp:261]     Train net output #0: loss = 0.0921527 (* 1 = 0.0921527 loss)
I0502 11:33:29.866055 26473 sgd_solver.cpp:106] Iteration 142500, lr = 4.39805e-06
I0502 11:33:30.806270 26473 solver.cpp:242] Iteration 142600 (92.9779 iter/s, 1.07552s/100 iter), loss = 0.548775
I0502 11:33:30.806310 26473 solver.cpp:261]     Train net output #0: loss = 0.548775 (* 1 = 0.548775 loss)
I0502 11:33:30.806319 26473 sgd_solver.cpp:106] Iteration 142600, lr = 4.39805e-06
I0502 11:33:30.811074 26473 solver.cpp:242] Iteration 142600 (105.819 iter/s, 0.945009s/100 iter), loss = 0.109479
I0502 11:33:30.811096 26473 solver.cpp:261]     Train net output #0: loss = 0.109479 (* 1 = 0.109479 loss)
I0502 11:33:30.811105 26473 sgd_solver.cpp:106] Iteration 142600, lr = 4.39805e-06
I0502 11:33:31.750937 26473 solver.cpp:242] Iteration 142700 (105.865 iter/s, 0.944599s/100 iter), loss = 0.0893895
I0502 11:33:31.750978 26473 solver.cpp:261]     Train net output #0: loss = 0.0893895 (* 1 = 0.0893895 loss)
I0502 11:33:31.750988 26473 sgd_solver.cpp:106] Iteration 142700, lr = 4.39805e-06
I0502 11:33:31.755723 26473 solver.cpp:242] Iteration 142700 (105.864 iter/s, 0.94461s/100 iter), loss = 0.0179829
I0502 11:33:31.755746 26473 solver.cpp:261]     Train net output #0: loss = 0.0179829 (* 1 = 0.0179829 loss)
I0502 11:33:31.755755 26473 sgd_solver.cpp:106] Iteration 142700, lr = 4.39805e-06
I0502 11:33:32.695111 26473 solver.cpp:242] Iteration 142800 (105.92 iter/s, 0.944111s/100 iter), loss = 0.100367
I0502 11:33:32.695144 26473 solver.cpp:261]     Train net output #0: loss = 0.100367 (* 1 = 0.100367 loss)
I0502 11:33:32.695154 26473 sgd_solver.cpp:106] Iteration 142800, lr = 4.39805e-06
I0502 11:33:32.699939 26473 solver.cpp:242] Iteration 142800 (105.913 iter/s, 0.944175s/100 iter), loss = 0.0712888
I0502 11:33:32.699962 26473 solver.cpp:261]     Train net output #0: loss = 0.0712888 (* 1 = 0.0712888 loss)
I0502 11:33:32.699971 26473 sgd_solver.cpp:106] Iteration 142800, lr = 4.39805e-06
I0502 11:33:33.639405 26473 solver.cpp:242] Iteration 142900 (105.906 iter/s, 0.944238s/100 iter), loss = 0.147116
I0502 11:33:33.639437 26473 solver.cpp:261]     Train net output #0: loss = 0.147116 (* 1 = 0.147116 loss)
I0502 11:33:33.639446 26473 sgd_solver.cpp:106] Iteration 142900, lr = 4.39805e-06
I0502 11:33:33.644274 26473 solver.cpp:242] Iteration 142900 (105.9 iter/s, 0.944287s/100 iter), loss = 0.0394228
I0502 11:33:33.644299 26473 solver.cpp:261]     Train net output #0: loss = 0.0394228 (* 1 = 0.0394228 loss)
I0502 11:33:33.644306 26473 sgd_solver.cpp:106] Iteration 142900, lr = 4.39805e-06
I0502 11:33:34.581164 26473 solver.cpp:362] Iteration 143000, Testing net (#0)
I0502 11:33:34.581195 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:34.705329 26473 solver.cpp:429]     Test net output #0: loss = 0.292637 (* 1 = 0.292637 loss)
I0502 11:33:34.708204 26473 solver.cpp:242] Iteration 143000 (93.5675 iter/s, 1.06875s/100 iter), loss = 0.183744
I0502 11:33:34.708223 26473 solver.cpp:261]     Train net output #0: loss = 0.183744 (* 1 = 0.183744 loss)
I0502 11:33:34.708231 26473 sgd_solver.cpp:106] Iteration 143000, lr = 4.39805e-06
I0502 11:33:34.709870 26473 solver.cpp:362] Iteration 143000, Testing net (#0)
I0502 11:33:34.709885 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:34.840520 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9525
I0502 11:33:34.840539 26473 solver.cpp:429]     Test net output #1: loss = 0.0966815 (* 1 = 0.0966815 loss)
I0502 11:33:34.843475 26473 solver.cpp:242] Iteration 143000 (83.3919 iter/s, 1.19916s/100 iter), loss = 0.132971
I0502 11:33:34.843495 26473 solver.cpp:261]     Train net output #0: loss = 0.132971 (* 1 = 0.132971 loss)
I0502 11:33:34.843504 26473 sgd_solver.cpp:106] Iteration 143000, lr = 4.39805e-06
I0502 11:33:35.782121 26473 solver.cpp:242] Iteration 143100 (93.1215 iter/s, 1.07387s/100 iter), loss = 0.324553
I0502 11:33:35.782173 26473 solver.cpp:261]     Train net output #0: loss = 0.324553 (* 1 = 0.324553 loss)
I0502 11:33:35.782182 26473 sgd_solver.cpp:106] Iteration 143100, lr = 4.39805e-06
I0502 11:33:35.786937 26473 solver.cpp:242] Iteration 143100 (105.997 iter/s, 0.943423s/100 iter), loss = 0.143424
I0502 11:33:35.786960 26473 solver.cpp:261]     Train net output #0: loss = 0.143424 (* 1 = 0.143424 loss)
I0502 11:33:35.786968 26473 sgd_solver.cpp:106] Iteration 143100, lr = 4.39805e-06
I0502 11:33:36.725826 26473 solver.cpp:242] Iteration 143200 (105.974 iter/s, 0.943624s/100 iter), loss = 0.0617701
I0502 11:33:36.725868 26473 solver.cpp:261]     Train net output #0: loss = 0.0617701 (* 1 = 0.0617701 loss)
I0502 11:33:36.725878 26473 sgd_solver.cpp:106] Iteration 143200, lr = 4.39805e-06
I0502 11:33:36.730621 26473 solver.cpp:242] Iteration 143200 (105.972 iter/s, 0.943644s/100 iter), loss = 0.0343454
I0502 11:33:36.730645 26473 solver.cpp:261]     Train net output #0: loss = 0.0343454 (* 1 = 0.0343454 loss)
I0502 11:33:36.730654 26473 sgd_solver.cpp:106] Iteration 143200, lr = 4.39805e-06
I0502 11:33:37.669854 26473 solver.cpp:242] Iteration 143300 (105.937 iter/s, 0.94396s/100 iter), loss = 0.431424
I0502 11:33:37.669894 26473 solver.cpp:261]     Train net output #0: loss = 0.431424 (* 1 = 0.431424 loss)
I0502 11:33:37.669903 26473 sgd_solver.cpp:106] Iteration 143300, lr = 4.39805e-06
I0502 11:33:37.674661 26473 solver.cpp:242] Iteration 143300 (105.932 iter/s, 0.943999s/100 iter), loss = 0.115609
I0502 11:33:37.674685 26473 solver.cpp:261]     Train net output #0: loss = 0.115609 (* 1 = 0.115609 loss)
I0502 11:33:37.674693 26473 sgd_solver.cpp:106] Iteration 143300, lr = 4.39805e-06
I0502 11:33:38.614145 26473 solver.cpp:242] Iteration 143400 (105.907 iter/s, 0.944225s/100 iter), loss = 0.216782
I0502 11:33:38.614187 26473 solver.cpp:261]     Train net output #0: loss = 0.216782 (* 1 = 0.216782 loss)
I0502 11:33:38.614195 26473 sgd_solver.cpp:106] Iteration 143400, lr = 4.39805e-06
I0502 11:33:38.619010 26473 solver.cpp:242] Iteration 143400 (105.898 iter/s, 0.944301s/100 iter), loss = 0.0218642
I0502 11:33:38.619035 26473 solver.cpp:261]     Train net output #0: loss = 0.0218642 (* 1 = 0.0218642 loss)
I0502 11:33:38.619043 26473 sgd_solver.cpp:106] Iteration 143400, lr = 4.39805e-06
I0502 11:33:39.555162 26473 solver.cpp:362] Iteration 143500, Testing net (#0)
I0502 11:33:39.555191 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:39.679611 26473 solver.cpp:429]     Test net output #0: loss = 0.185914 (* 1 = 0.185914 loss)
I0502 11:33:39.682509 26473 solver.cpp:242] Iteration 143500 (93.6062 iter/s, 1.06831s/100 iter), loss = 0.0265844
I0502 11:33:39.682531 26473 solver.cpp:261]     Train net output #0: loss = 0.0265844 (* 1 = 0.0265844 loss)
I0502 11:33:39.682539 26473 sgd_solver.cpp:106] Iteration 143500, lr = 4.39805e-06
I0502 11:33:39.684172 26473 solver.cpp:362] Iteration 143500, Testing net (#0)
I0502 11:33:39.684185 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:39.814941 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9555
I0502 11:33:39.814962 26473 solver.cpp:429]     Test net output #1: loss = 0.0912456 (* 1 = 0.0912456 loss)
I0502 11:33:39.817886 26473 solver.cpp:242] Iteration 143500 (83.4146 iter/s, 1.19883s/100 iter), loss = 0.0171057
I0502 11:33:39.817906 26473 solver.cpp:261]     Train net output #0: loss = 0.0171057 (* 1 = 0.0171057 loss)
I0502 11:33:39.817914 26473 sgd_solver.cpp:106] Iteration 143500, lr = 4.39805e-06
I0502 11:33:40.757601 26473 solver.cpp:242] Iteration 143600 (93.02 iter/s, 1.07504s/100 iter), loss = 0.132084
I0502 11:33:40.757642 26473 solver.cpp:261]     Train net output #0: loss = 0.132084 (* 1 = 0.132084 loss)
I0502 11:33:40.757650 26473 sgd_solver.cpp:106] Iteration 143600, lr = 4.39805e-06
I0502 11:33:40.762413 26473 solver.cpp:242] Iteration 143600 (105.877 iter/s, 0.944489s/100 iter), loss = 0.0550737
I0502 11:33:40.762436 26473 solver.cpp:261]     Train net output #0: loss = 0.0550737 (* 1 = 0.0550737 loss)
I0502 11:33:40.762454 26473 sgd_solver.cpp:106] Iteration 143600, lr = 4.39805e-06
I0502 11:33:41.701067 26473 solver.cpp:242] Iteration 143700 (106 iter/s, 0.9434s/100 iter), loss = 0.217477
I0502 11:33:41.701104 26473 solver.cpp:261]     Train net output #0: loss = 0.217477 (* 1 = 0.217477 loss)
I0502 11:33:41.701113 26473 sgd_solver.cpp:106] Iteration 143700, lr = 4.39805e-06
I0502 11:33:41.705874 26473 solver.cpp:242] Iteration 143700 (105.997 iter/s, 0.94342s/100 iter), loss = 0.0146359
I0502 11:33:41.705898 26473 solver.cpp:261]     Train net output #0: loss = 0.0146359 (* 1 = 0.0146359 loss)
I0502 11:33:41.705906 26473 sgd_solver.cpp:106] Iteration 143700, lr = 4.39805e-06
I0502 11:33:42.645537 26473 solver.cpp:242] Iteration 143800 (105.887 iter/s, 0.944407s/100 iter), loss = 0.0448222
I0502 11:33:42.645576 26473 solver.cpp:261]     Train net output #0: loss = 0.0448222 (* 1 = 0.0448222 loss)
I0502 11:33:42.645584 26473 sgd_solver.cpp:106] Iteration 143800, lr = 4.39805e-06
I0502 11:33:42.650334 26473 solver.cpp:242] Iteration 143800 (105.885 iter/s, 0.944419s/100 iter), loss = 0.0444953
I0502 11:33:42.650357 26473 solver.cpp:261]     Train net output #0: loss = 0.0444953 (* 1 = 0.0444953 loss)
I0502 11:33:42.650365 26473 sgd_solver.cpp:106] Iteration 143800, lr = 4.39805e-06
I0502 11:33:43.589156 26473 solver.cpp:242] Iteration 143900 (105.982 iter/s, 0.943557s/100 iter), loss = 0.209018
I0502 11:33:43.589191 26473 solver.cpp:261]     Train net output #0: loss = 0.209018 (* 1 = 0.209018 loss)
I0502 11:33:43.589200 26473 sgd_solver.cpp:106] Iteration 143900, lr = 4.39805e-06
I0502 11:33:43.594007 26473 solver.cpp:242] Iteration 143900 (105.975 iter/s, 0.943623s/100 iter), loss = 0.0423821
I0502 11:33:43.594029 26473 solver.cpp:261]     Train net output #0: loss = 0.0423821 (* 1 = 0.0423821 loss)
I0502 11:33:43.594038 26473 sgd_solver.cpp:106] Iteration 143900, lr = 4.39805e-06
I0502 11:33:44.549644 26473 solver.cpp:362] Iteration 144000, Testing net (#0)
I0502 11:33:44.549667 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:44.673995 26473 solver.cpp:429]     Test net output #0: loss = 0.215585 (* 1 = 0.215585 loss)
I0502 11:33:44.676874 26473 solver.cpp:242] Iteration 144000 (91.9401 iter/s, 1.08766s/100 iter), loss = 0.191681
I0502 11:33:44.676894 26473 solver.cpp:261]     Train net output #0: loss = 0.191681 (* 1 = 0.191681 loss)
I0502 11:33:44.676903 26473 sgd_solver.cpp:106] Iteration 144000, lr = 4.39805e-06
I0502 11:33:44.678535 26473 solver.cpp:362] Iteration 144000, Testing net (#0)
I0502 11:33:44.678549 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:44.809037 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9575
I0502 11:33:44.809072 26473 solver.cpp:429]     Test net output #1: loss = 0.0767746 (* 1 = 0.0767746 loss)
I0502 11:33:44.812018 26473 solver.cpp:242] Iteration 144000 (82.104 iter/s, 1.21797s/100 iter), loss = 0.0579889
I0502 11:33:44.812039 26473 solver.cpp:261]     Train net output #0: loss = 0.0579889 (* 1 = 0.0579889 loss)
I0502 11:33:44.812048 26473 sgd_solver.cpp:106] Iteration 144000, lr = 4.39805e-06
I0502 11:33:45.751157 26473 solver.cpp:242] Iteration 144100 (93.0899 iter/s, 1.07423s/100 iter), loss = 0.171754
I0502 11:33:45.751190 26473 solver.cpp:261]     Train net output #0: loss = 0.171754 (* 1 = 0.171754 loss)
I0502 11:33:45.751199 26473 sgd_solver.cpp:106] Iteration 144100, lr = 4.39805e-06
I0502 11:33:45.755947 26473 solver.cpp:242] Iteration 144100 (105.945 iter/s, 0.943889s/100 iter), loss = 0.0197905
I0502 11:33:45.755970 26473 solver.cpp:261]     Train net output #0: loss = 0.0197905 (* 1 = 0.0197905 loss)
I0502 11:33:45.755980 26473 sgd_solver.cpp:106] Iteration 144100, lr = 4.39805e-06
I0502 11:33:46.695402 26473 solver.cpp:242] Iteration 144200 (105.912 iter/s, 0.944184s/100 iter), loss = 0.197879
I0502 11:33:46.695433 26473 solver.cpp:261]     Train net output #0: loss = 0.197879 (* 1 = 0.197879 loss)
I0502 11:33:46.695442 26473 sgd_solver.cpp:106] Iteration 144200, lr = 4.39805e-06
I0502 11:33:46.700219 26473 solver.cpp:242] Iteration 144200 (105.906 iter/s, 0.944231s/100 iter), loss = 0.0460152
I0502 11:33:46.700250 26473 solver.cpp:261]     Train net output #0: loss = 0.0460152 (* 1 = 0.0460152 loss)
I0502 11:33:46.700260 26473 sgd_solver.cpp:106] Iteration 144200, lr = 4.39805e-06
I0502 11:33:47.638900 26473 solver.cpp:242] Iteration 144300 (105.995 iter/s, 0.94344s/100 iter), loss = 0.0971707
I0502 11:33:47.638945 26473 solver.cpp:261]     Train net output #0: loss = 0.0971707 (* 1 = 0.0971707 loss)
I0502 11:33:47.638954 26473 sgd_solver.cpp:106] Iteration 144300, lr = 4.39805e-06
I0502 11:33:47.643733 26473 solver.cpp:242] Iteration 144300 (105.992 iter/s, 0.943464s/100 iter), loss = 0.0724098
I0502 11:33:47.643755 26473 solver.cpp:261]     Train net output #0: loss = 0.0724098 (* 1 = 0.0724098 loss)
I0502 11:33:47.643764 26473 sgd_solver.cpp:106] Iteration 144300, lr = 4.39805e-06
I0502 11:33:48.582001 26473 solver.cpp:242] Iteration 144400 (106.041 iter/s, 0.94303s/100 iter), loss = 0.058606
I0502 11:33:48.582044 26473 solver.cpp:261]     Train net output #0: loss = 0.058606 (* 1 = 0.058606 loss)
I0502 11:33:48.582053 26473 sgd_solver.cpp:106] Iteration 144400, lr = 4.39805e-06
I0502 11:33:48.586890 26473 solver.cpp:242] Iteration 144400 (106.032 iter/s, 0.943108s/100 iter), loss = 0.18215
I0502 11:33:48.586915 26473 solver.cpp:261]     Train net output #0: loss = 0.18215 (* 1 = 0.18215 loss)
I0502 11:33:48.586923 26473 sgd_solver.cpp:106] Iteration 144400, lr = 4.39805e-06
I0502 11:33:49.523077 26473 solver.cpp:362] Iteration 144500, Testing net (#0)
I0502 11:33:49.523103 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:49.647447 26473 solver.cpp:429]     Test net output #0: loss = 0.212246 (* 1 = 0.212246 loss)
I0502 11:33:49.650313 26473 solver.cpp:242] Iteration 144500 (93.611 iter/s, 1.06825s/100 iter), loss = 0.10767
I0502 11:33:49.650333 26473 solver.cpp:261]     Train net output #0: loss = 0.10767 (* 1 = 0.10767 loss)
I0502 11:33:49.650342 26473 sgd_solver.cpp:106] Iteration 144500, lr = 4.39805e-06
I0502 11:33:49.651963 26473 solver.cpp:362] Iteration 144500, Testing net (#0)
I0502 11:33:49.651978 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:49.782733 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9565
I0502 11:33:49.782755 26473 solver.cpp:429]     Test net output #1: loss = 0.0909655 (* 1 = 0.0909655 loss)
I0502 11:33:49.785686 26473 solver.cpp:242] Iteration 144500 (83.4202 iter/s, 1.19875s/100 iter), loss = 0.1056
I0502 11:33:49.785706 26473 solver.cpp:261]     Train net output #0: loss = 0.1056 (* 1 = 0.1056 loss)
I0502 11:33:49.785713 26473 sgd_solver.cpp:106] Iteration 144500, lr = 4.39805e-06
I0502 11:33:50.726011 26473 solver.cpp:242] Iteration 144600 (92.9676 iter/s, 1.07564s/100 iter), loss = 0.281504
I0502 11:33:50.726055 26473 solver.cpp:261]     Train net output #0: loss = 0.281504 (* 1 = 0.281504 loss)
I0502 11:33:50.726064 26473 sgd_solver.cpp:106] Iteration 144600, lr = 4.39805e-06
I0502 11:33:50.730828 26473 solver.cpp:242] Iteration 144600 (105.808 iter/s, 0.945104s/100 iter), loss = 0.0498205
I0502 11:33:50.730850 26473 solver.cpp:261]     Train net output #0: loss = 0.0498205 (* 1 = 0.0498205 loss)
I0502 11:33:50.730859 26473 sgd_solver.cpp:106] Iteration 144600, lr = 4.39805e-06
I0502 11:33:51.670240 26473 solver.cpp:242] Iteration 144700 (105.915 iter/s, 0.944158s/100 iter), loss = 0.139008
I0502 11:33:51.670282 26473 solver.cpp:261]     Train net output #0: loss = 0.139008 (* 1 = 0.139008 loss)
I0502 11:33:51.670291 26473 sgd_solver.cpp:106] Iteration 144700, lr = 4.39805e-06
I0502 11:33:51.675055 26473 solver.cpp:242] Iteration 144700 (105.912 iter/s, 0.944184s/100 iter), loss = 0.0900131
I0502 11:33:51.675077 26473 solver.cpp:261]     Train net output #0: loss = 0.0900131 (* 1 = 0.0900131 loss)
I0502 11:33:51.675086 26473 sgd_solver.cpp:106] Iteration 144700, lr = 4.39805e-06
I0502 11:33:52.613965 26473 solver.cpp:242] Iteration 144800 (105.971 iter/s, 0.943655s/100 iter), loss = 0.149886
I0502 11:33:52.614004 26473 solver.cpp:261]     Train net output #0: loss = 0.149886 (* 1 = 0.149886 loss)
I0502 11:33:52.614024 26473 sgd_solver.cpp:106] Iteration 144800, lr = 4.39805e-06
I0502 11:33:52.618787 26473 solver.cpp:242] Iteration 144800 (105.967 iter/s, 0.943692s/100 iter), loss = 0.169935
I0502 11:33:52.618808 26473 solver.cpp:261]     Train net output #0: loss = 0.169935 (* 1 = 0.169935 loss)
I0502 11:33:52.618818 26473 sgd_solver.cpp:106] Iteration 144800, lr = 4.39805e-06
I0502 11:33:53.559181 26473 solver.cpp:242] Iteration 144900 (105.803 iter/s, 0.945153s/100 iter), loss = 0.242096
I0502 11:33:53.559221 26473 solver.cpp:261]     Train net output #0: loss = 0.242096 (* 1 = 0.242096 loss)
I0502 11:33:53.559231 26473 sgd_solver.cpp:106] Iteration 144900, lr = 4.39805e-06
I0502 11:33:53.564075 26473 solver.cpp:242] Iteration 144900 (105.793 iter/s, 0.94524s/100 iter), loss = 0.0902649
I0502 11:33:53.564100 26473 solver.cpp:261]     Train net output #0: loss = 0.0902649 (* 1 = 0.0902649 loss)
I0502 11:33:53.564107 26473 sgd_solver.cpp:106] Iteration 144900, lr = 4.39805e-06
I0502 11:33:54.499996 26473 solver.cpp:362] Iteration 145000, Testing net (#0)
I0502 11:33:54.500020 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:54.624546 26473 solver.cpp:429]     Test net output #0: loss = 0.253334 (* 1 = 0.253334 loss)
I0502 11:33:54.627425 26473 solver.cpp:242] Iteration 145000 (93.6167 iter/s, 1.06819s/100 iter), loss = 0.261773
I0502 11:33:54.627445 26473 solver.cpp:261]     Train net output #0: loss = 0.261773 (* 1 = 0.261773 loss)
I0502 11:33:54.627454 26473 sgd_solver.cpp:106] Iteration 145000, lr = 4.39805e-06
I0502 11:33:54.629241 26473 solver.cpp:362] Iteration 145000, Testing net (#0)
I0502 11:33:54.629257 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:54.760291 26473 solver.cpp:429]     Test net output #0: accuracy = 0.971
I0502 11:33:54.760314 26473 solver.cpp:429]     Test net output #1: loss = 0.0738734 (* 1 = 0.0738734 loss)
I0502 11:33:54.763249 26473 solver.cpp:242] Iteration 145000 (83.3938 iter/s, 1.19913s/100 iter), loss = 0.0517217
I0502 11:33:54.763269 26473 solver.cpp:261]     Train net output #0: loss = 0.0517217 (* 1 = 0.0517217 loss)
I0502 11:33:54.763278 26473 sgd_solver.cpp:106] Iteration 145000, lr = 4.39805e-06
I0502 11:33:55.701582 26473 solver.cpp:242] Iteration 145100 (93.1009 iter/s, 1.0741s/100 iter), loss = 0.0860076
I0502 11:33:55.701622 26473 solver.cpp:261]     Train net output #0: loss = 0.0860076 (* 1 = 0.0860076 loss)
I0502 11:33:55.701632 26473 sgd_solver.cpp:106] Iteration 145100, lr = 4.39805e-06
I0502 11:33:55.706452 26473 solver.cpp:242] Iteration 145100 (106.026 iter/s, 0.943164s/100 iter), loss = 0.13523
I0502 11:33:55.706475 26473 solver.cpp:261]     Train net output #0: loss = 0.13523 (* 1 = 0.13523 loss)
I0502 11:33:55.706485 26473 sgd_solver.cpp:106] Iteration 145100, lr = 4.39805e-06
I0502 11:33:56.645016 26473 solver.cpp:242] Iteration 145200 (106.003 iter/s, 0.943367s/100 iter), loss = 0.0816754
I0502 11:33:56.645052 26473 solver.cpp:261]     Train net output #0: loss = 0.0816754 (* 1 = 0.0816754 loss)
I0502 11:33:56.645061 26473 sgd_solver.cpp:106] Iteration 145200, lr = 4.39805e-06
I0502 11:33:56.649849 26473 solver.cpp:242] Iteration 145200 (106.005 iter/s, 0.943356s/100 iter), loss = 0.0245623
I0502 11:33:56.649871 26473 solver.cpp:261]     Train net output #0: loss = 0.0245623 (* 1 = 0.0245623 loss)
I0502 11:33:56.649880 26473 sgd_solver.cpp:106] Iteration 145200, lr = 4.39805e-06
I0502 11:33:57.589071 26473 solver.cpp:242] Iteration 145300 (105.933 iter/s, 0.943991s/100 iter), loss = 0.240493
I0502 11:33:57.589118 26473 solver.cpp:261]     Train net output #0: loss = 0.240493 (* 1 = 0.240493 loss)
I0502 11:33:57.589128 26473 sgd_solver.cpp:106] Iteration 145300, lr = 4.39805e-06
I0502 11:33:57.593881 26473 solver.cpp:242] Iteration 145300 (105.933 iter/s, 0.943991s/100 iter), loss = 0.0842242
I0502 11:33:57.593905 26473 solver.cpp:261]     Train net output #0: loss = 0.0842242 (* 1 = 0.0842242 loss)
I0502 11:33:57.593914 26473 sgd_solver.cpp:106] Iteration 145300, lr = 4.39805e-06
I0502 11:33:58.533699 26473 solver.cpp:242] Iteration 145400 (105.87 iter/s, 0.944554s/100 iter), loss = 0.332859
I0502 11:33:58.533742 26473 solver.cpp:261]     Train net output #0: loss = 0.332859 (* 1 = 0.332859 loss)
I0502 11:33:58.533751 26473 sgd_solver.cpp:106] Iteration 145400, lr = 4.39805e-06
I0502 11:33:58.538550 26473 solver.cpp:242] Iteration 145400 (105.862 iter/s, 0.944628s/100 iter), loss = 0.0106806
I0502 11:33:58.538575 26473 solver.cpp:261]     Train net output #0: loss = 0.0106806 (* 1 = 0.0106806 loss)
I0502 11:33:58.538583 26473 sgd_solver.cpp:106] Iteration 145400, lr = 4.39805e-06
I0502 11:33:59.475246 26473 solver.cpp:362] Iteration 145500, Testing net (#0)
I0502 11:33:59.475276 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:59.599642 26473 solver.cpp:429]     Test net output #0: loss = 0.231852 (* 1 = 0.231852 loss)
I0502 11:33:59.602520 26473 solver.cpp:242] Iteration 145500 (93.5664 iter/s, 1.06876s/100 iter), loss = 0.21893
I0502 11:33:59.602540 26473 solver.cpp:261]     Train net output #0: loss = 0.21893 (* 1 = 0.21893 loss)
I0502 11:33:59.602550 26473 sgd_solver.cpp:106] Iteration 145500, lr = 4.39805e-06
I0502 11:33:59.604240 26473 solver.cpp:362] Iteration 145500, Testing net (#0)
I0502 11:33:59.604254 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:33:59.734856 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:33:59.734877 26473 solver.cpp:429]     Test net output #1: loss = 0.092022 (* 1 = 0.092022 loss)
I0502 11:33:59.737789 26473 solver.cpp:242] Iteration 145500 (83.3894 iter/s, 1.19919s/100 iter), loss = 0.0795046
I0502 11:33:59.737808 26473 solver.cpp:261]     Train net output #0: loss = 0.0795046 (* 1 = 0.0795046 loss)
I0502 11:33:59.737818 26473 sgd_solver.cpp:106] Iteration 145500, lr = 4.39805e-06
I0502 11:34:00.689709 26473 solver.cpp:242] Iteration 145600 (91.985 iter/s, 1.08713s/100 iter), loss = 0.464047
I0502 11:34:00.689752 26473 solver.cpp:261]     Train net output #0: loss = 0.464047 (* 1 = 0.464047 loss)
I0502 11:34:00.689761 26473 sgd_solver.cpp:106] Iteration 145600, lr = 4.39805e-06
I0502 11:34:00.694564 26473 solver.cpp:242] Iteration 145600 (104.522 iter/s, 0.956737s/100 iter), loss = 0.127501
I0502 11:34:00.694588 26473 solver.cpp:261]     Train net output #0: loss = 0.127501 (* 1 = 0.127501 loss)
I0502 11:34:00.694597 26473 sgd_solver.cpp:106] Iteration 145600, lr = 4.39805e-06
I0502 11:34:01.633777 26473 solver.cpp:242] Iteration 145700 (105.933 iter/s, 0.943996s/100 iter), loss = 0.0842236
I0502 11:34:01.633821 26473 solver.cpp:261]     Train net output #0: loss = 0.0842236 (* 1 = 0.0842236 loss)
I0502 11:34:01.633829 26473 sgd_solver.cpp:106] Iteration 145700, lr = 4.39805e-06
I0502 11:34:01.638586 26473 solver.cpp:242] Iteration 145700 (105.935 iter/s, 0.94398s/100 iter), loss = 0.162556
I0502 11:34:01.638609 26473 solver.cpp:261]     Train net output #0: loss = 0.162556 (* 1 = 0.162556 loss)
I0502 11:34:01.638617 26473 sgd_solver.cpp:106] Iteration 145700, lr = 4.39805e-06
I0502 11:34:02.577419 26473 solver.cpp:242] Iteration 145800 (105.98 iter/s, 0.943572s/100 iter), loss = 0.0528178
I0502 11:34:02.577460 26473 solver.cpp:261]     Train net output #0: loss = 0.0528178 (* 1 = 0.0528178 loss)
I0502 11:34:02.577468 26473 sgd_solver.cpp:106] Iteration 145800, lr = 4.39805e-06
I0502 11:34:02.582208 26473 solver.cpp:242] Iteration 145800 (105.979 iter/s, 0.943581s/100 iter), loss = 0.113406
I0502 11:34:02.582231 26473 solver.cpp:261]     Train net output #0: loss = 0.113406 (* 1 = 0.113406 loss)
I0502 11:34:02.582239 26473 sgd_solver.cpp:106] Iteration 145800, lr = 4.39805e-06
I0502 11:34:03.521714 26473 solver.cpp:242] Iteration 145900 (105.906 iter/s, 0.944229s/100 iter), loss = 0.275392
I0502 11:34:03.521754 26473 solver.cpp:261]     Train net output #0: loss = 0.275392 (* 1 = 0.275392 loss)
I0502 11:34:03.521762 26473 sgd_solver.cpp:106] Iteration 145900, lr = 4.39805e-06
I0502 11:34:03.526523 26473 solver.cpp:242] Iteration 145900 (105.902 iter/s, 0.944273s/100 iter), loss = 0.0436851
I0502 11:34:03.526553 26473 solver.cpp:261]     Train net output #0: loss = 0.0436851 (* 1 = 0.0436851 loss)
I0502 11:34:03.526562 26473 sgd_solver.cpp:106] Iteration 145900, lr = 4.39805e-06
I0502 11:34:04.462420 26473 solver.cpp:362] Iteration 146000, Testing net (#0)
I0502 11:34:04.462445 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:04.586833 26473 solver.cpp:429]     Test net output #0: loss = 0.223829 (* 1 = 0.223829 loss)
I0502 11:34:04.589701 26473 solver.cpp:242] Iteration 146000 (93.6391 iter/s, 1.06793s/100 iter), loss = 0.0869267
I0502 11:34:04.589721 26473 solver.cpp:261]     Train net output #0: loss = 0.0869267 (* 1 = 0.0869267 loss)
I0502 11:34:04.589730 26473 sgd_solver.cpp:106] Iteration 146000, lr = 4.39805e-06
I0502 11:34:04.591428 26473 solver.cpp:362] Iteration 146000, Testing net (#0)
I0502 11:34:04.591441 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:04.722121 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9645
I0502 11:34:04.722149 26473 solver.cpp:429]     Test net output #1: loss = 0.0876688 (* 1 = 0.0876688 loss)
I0502 11:34:04.725065 26473 solver.cpp:242] Iteration 146000 (83.4382 iter/s, 1.19849s/100 iter), loss = 0.087315
I0502 11:34:04.725085 26473 solver.cpp:261]     Train net output #0: loss = 0.087315 (* 1 = 0.087315 loss)
I0502 11:34:04.725095 26473 sgd_solver.cpp:106] Iteration 146000, lr = 4.39805e-06
I0502 11:34:05.664986 26473 solver.cpp:242] Iteration 146100 (93.0033 iter/s, 1.07523s/100 iter), loss = 0.317908
I0502 11:34:05.665040 26473 solver.cpp:261]     Train net output #0: loss = 0.317908 (* 1 = 0.317908 loss)
I0502 11:34:05.665050 26473 sgd_solver.cpp:106] Iteration 146100, lr = 4.39805e-06
I0502 11:34:05.669870 26473 solver.cpp:242] Iteration 146100 (105.846 iter/s, 0.944767s/100 iter), loss = 0.130264
I0502 11:34:05.669904 26473 solver.cpp:261]     Train net output #0: loss = 0.130264 (* 1 = 0.130264 loss)
I0502 11:34:05.669912 26473 sgd_solver.cpp:106] Iteration 146100, lr = 4.39805e-06
I0502 11:34:06.608654 26473 solver.cpp:242] Iteration 146200 (105.979 iter/s, 0.943584s/100 iter), loss = 0.520539
I0502 11:34:06.608695 26473 solver.cpp:261]     Train net output #0: loss = 0.520539 (* 1 = 0.520539 loss)
I0502 11:34:06.608703 26473 sgd_solver.cpp:106] Iteration 146200, lr = 4.39805e-06
I0502 11:34:06.613456 26473 solver.cpp:242] Iteration 146200 (105.985 iter/s, 0.943533s/100 iter), loss = 0.0375818
I0502 11:34:06.613478 26473 solver.cpp:261]     Train net output #0: loss = 0.0375818 (* 1 = 0.0375818 loss)
I0502 11:34:06.613487 26473 sgd_solver.cpp:106] Iteration 146200, lr = 4.39805e-06
I0502 11:34:07.552618 26473 solver.cpp:242] Iteration 146300 (105.944 iter/s, 0.943896s/100 iter), loss = 0.137272
I0502 11:34:07.552656 26473 solver.cpp:261]     Train net output #0: loss = 0.137272 (* 1 = 0.137272 loss)
I0502 11:34:07.552665 26473 sgd_solver.cpp:106] Iteration 146300, lr = 4.39805e-06
I0502 11:34:07.557411 26473 solver.cpp:242] Iteration 146300 (105.942 iter/s, 0.943915s/100 iter), loss = 0.104106
I0502 11:34:07.557435 26473 solver.cpp:261]     Train net output #0: loss = 0.104106 (* 1 = 0.104106 loss)
I0502 11:34:07.557443 26473 sgd_solver.cpp:106] Iteration 146300, lr = 4.39805e-06
I0502 11:34:08.496354 26473 solver.cpp:242] Iteration 146400 (105.969 iter/s, 0.94367s/100 iter), loss = 0.0541104
I0502 11:34:08.496400 26473 solver.cpp:261]     Train net output #0: loss = 0.0541104 (* 1 = 0.0541104 loss)
I0502 11:34:08.496409 26473 sgd_solver.cpp:106] Iteration 146400, lr = 4.39805e-06
I0502 11:34:08.501168 26473 solver.cpp:242] Iteration 146400 (105.964 iter/s, 0.943715s/100 iter), loss = 0.072071
I0502 11:34:08.501190 26473 solver.cpp:261]     Train net output #0: loss = 0.072071 (* 1 = 0.072071 loss)
I0502 11:34:08.501199 26473 sgd_solver.cpp:106] Iteration 146400, lr = 4.39805e-06
I0502 11:34:09.437382 26473 solver.cpp:362] Iteration 146500, Testing net (#0)
I0502 11:34:09.437408 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:09.561728 26473 solver.cpp:429]     Test net output #0: loss = 0.213999 (* 1 = 0.213999 loss)
I0502 11:34:09.564601 26473 solver.cpp:242] Iteration 146500 (93.6169 iter/s, 1.06818s/100 iter), loss = 0.10428
I0502 11:34:09.564621 26473 solver.cpp:261]     Train net output #0: loss = 0.10428 (* 1 = 0.10428 loss)
I0502 11:34:09.564630 26473 sgd_solver.cpp:106] Iteration 146500, lr = 4.39805e-06
I0502 11:34:09.566332 26473 solver.cpp:362] Iteration 146500, Testing net (#0)
I0502 11:34:09.566345 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:09.696944 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:34:09.696967 26473 solver.cpp:429]     Test net output #1: loss = 0.0866792 (* 1 = 0.0866792 loss)
I0502 11:34:09.699884 26473 solver.cpp:242] Iteration 146500 (83.4256 iter/s, 1.19867s/100 iter), loss = 0.0978848
I0502 11:34:09.699904 26473 solver.cpp:261]     Train net output #0: loss = 0.0978848 (* 1 = 0.0978848 loss)
I0502 11:34:09.699913 26473 sgd_solver.cpp:106] Iteration 146500, lr = 4.39805e-06
I0502 11:34:10.640177 26473 solver.cpp:242] Iteration 146600 (92.9781 iter/s, 1.07552s/100 iter), loss = 0.429625
I0502 11:34:10.640210 26473 solver.cpp:261]     Train net output #0: loss = 0.429625 (* 1 = 0.429625 loss)
I0502 11:34:10.640219 26473 sgd_solver.cpp:106] Iteration 146600, lr = 4.39805e-06
I0502 11:34:10.644994 26473 solver.cpp:242] Iteration 146600 (105.812 iter/s, 0.945071s/100 iter), loss = 0.11954
I0502 11:34:10.645017 26473 solver.cpp:261]     Train net output #0: loss = 0.11954 (* 1 = 0.11954 loss)
I0502 11:34:10.645025 26473 sgd_solver.cpp:106] Iteration 146600, lr = 4.39805e-06
I0502 11:34:11.583742 26473 solver.cpp:242] Iteration 146700 (105.988 iter/s, 0.943501s/100 iter), loss = 0.207365
I0502 11:34:11.583786 26473 solver.cpp:261]     Train net output #0: loss = 0.207365 (* 1 = 0.207365 loss)
I0502 11:34:11.583794 26473 sgd_solver.cpp:106] Iteration 146700, lr = 4.39805e-06
I0502 11:34:11.588558 26473 solver.cpp:242] Iteration 146700 (105.986 iter/s, 0.943522s/100 iter), loss = 0.235735
I0502 11:34:11.588582 26473 solver.cpp:261]     Train net output #0: loss = 0.235735 (* 1 = 0.235735 loss)
I0502 11:34:11.588590 26473 sgd_solver.cpp:106] Iteration 146700, lr = 4.39805e-06
I0502 11:34:12.528578 26473 solver.cpp:242] Iteration 146800 (105.846 iter/s, 0.944765s/100 iter), loss = 0.115528
I0502 11:34:12.528623 26473 solver.cpp:261]     Train net output #0: loss = 0.115528 (* 1 = 0.115528 loss)
I0502 11:34:12.528633 26473 sgd_solver.cpp:106] Iteration 146800, lr = 4.39805e-06
I0502 11:34:12.533416 26473 solver.cpp:242] Iteration 146800 (105.841 iter/s, 0.944817s/100 iter), loss = 0.11128
I0502 11:34:12.533439 26473 solver.cpp:261]     Train net output #0: loss = 0.11128 (* 1 = 0.11128 loss)
I0502 11:34:12.533447 26473 sgd_solver.cpp:106] Iteration 146800, lr = 4.39805e-06
I0502 11:34:13.472615 26473 solver.cpp:242] Iteration 146900 (105.936 iter/s, 0.943962s/100 iter), loss = 0.189103
I0502 11:34:13.472661 26473 solver.cpp:261]     Train net output #0: loss = 0.189103 (* 1 = 0.189103 loss)
I0502 11:34:13.472669 26473 sgd_solver.cpp:106] Iteration 146900, lr = 4.39805e-06
I0502 11:34:13.477458 26473 solver.cpp:242] Iteration 146900 (105.932 iter/s, 0.944s/100 iter), loss = 0.0300542
I0502 11:34:13.477481 26473 solver.cpp:261]     Train net output #0: loss = 0.0300542 (* 1 = 0.0300542 loss)
I0502 11:34:13.477490 26473 sgd_solver.cpp:106] Iteration 146900, lr = 4.39805e-06
I0502 11:34:14.412952 26473 solver.cpp:362] Iteration 147000, Testing net (#0)
I0502 11:34:14.412981 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:14.537256 26473 solver.cpp:429]     Test net output #0: loss = 0.228768 (* 1 = 0.228768 loss)
I0502 11:34:14.540122 26473 solver.cpp:242] Iteration 147000 (93.6818 iter/s, 1.06744s/100 iter), loss = 0.0908389
I0502 11:34:14.540143 26473 solver.cpp:261]     Train net output #0: loss = 0.0908389 (* 1 = 0.0908389 loss)
I0502 11:34:14.540150 26473 sgd_solver.cpp:106] Iteration 147000, lr = 4.39805e-06
I0502 11:34:14.541844 26473 solver.cpp:362] Iteration 147000, Testing net (#0)
I0502 11:34:14.541858 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:14.672309 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:34:14.672330 26473 solver.cpp:429]     Test net output #1: loss = 0.0800276 (* 1 = 0.0800276 loss)
I0502 11:34:14.675256 26473 solver.cpp:242] Iteration 147000 (83.4896 iter/s, 1.19775s/100 iter), loss = 0.0645141
I0502 11:34:14.675276 26473 solver.cpp:261]     Train net output #0: loss = 0.0645141 (* 1 = 0.0645141 loss)
I0502 11:34:14.675283 26473 sgd_solver.cpp:106] Iteration 147000, lr = 4.39805e-06
I0502 11:34:15.614281 26473 solver.cpp:242] Iteration 147100 (93.1007 iter/s, 1.07411s/100 iter), loss = 0.138829
I0502 11:34:15.614322 26473 solver.cpp:261]     Train net output #0: loss = 0.138829 (* 1 = 0.138829 loss)
I0502 11:34:15.614331 26473 sgd_solver.cpp:106] Iteration 147100, lr = 4.39805e-06
I0502 11:34:15.619091 26473 solver.cpp:242] Iteration 147100 (105.955 iter/s, 0.943796s/100 iter), loss = 0.0171306
I0502 11:34:15.619113 26473 solver.cpp:261]     Train net output #0: loss = 0.0171306 (* 1 = 0.0171306 loss)
I0502 11:34:15.619122 26473 sgd_solver.cpp:106] Iteration 147100, lr = 4.39805e-06
I0502 11:34:16.559722 26473 solver.cpp:242] Iteration 147200 (105.779 iter/s, 0.945371s/100 iter), loss = 0.146333
I0502 11:34:16.559764 26473 solver.cpp:261]     Train net output #0: loss = 0.146333 (* 1 = 0.146333 loss)
I0502 11:34:16.559773 26473 sgd_solver.cpp:106] Iteration 147200, lr = 4.39805e-06
I0502 11:34:16.564538 26473 solver.cpp:242] Iteration 147200 (105.774 iter/s, 0.945408s/100 iter), loss = 0.0412807
I0502 11:34:16.564566 26473 solver.cpp:261]     Train net output #0: loss = 0.0412807 (* 1 = 0.0412807 loss)
I0502 11:34:16.564575 26473 sgd_solver.cpp:106] Iteration 147200, lr = 4.39805e-06
I0502 11:34:17.502959 26473 solver.cpp:242] Iteration 147300 (106.026 iter/s, 0.943166s/100 iter), loss = 0.256107
I0502 11:34:17.503001 26473 solver.cpp:261]     Train net output #0: loss = 0.256107 (* 1 = 0.256107 loss)
I0502 11:34:17.503010 26473 sgd_solver.cpp:106] Iteration 147300, lr = 4.39805e-06
I0502 11:34:17.507782 26473 solver.cpp:242] Iteration 147300 (106.022 iter/s, 0.943198s/100 iter), loss = 0.0509259
I0502 11:34:17.507805 26473 solver.cpp:261]     Train net output #0: loss = 0.0509259 (* 1 = 0.0509259 loss)
I0502 11:34:17.507814 26473 sgd_solver.cpp:106] Iteration 147300, lr = 4.39805e-06
I0502 11:34:18.447366 26473 solver.cpp:242] Iteration 147400 (105.894 iter/s, 0.944338s/100 iter), loss = 0.192628
I0502 11:34:18.447407 26473 solver.cpp:261]     Train net output #0: loss = 0.192628 (* 1 = 0.192628 loss)
I0502 11:34:18.447415 26473 sgd_solver.cpp:106] Iteration 147400, lr = 4.39805e-06
I0502 11:34:18.452288 26473 solver.cpp:242] Iteration 147400 (105.88 iter/s, 0.944465s/100 iter), loss = 0.0386448
I0502 11:34:18.452311 26473 solver.cpp:261]     Train net output #0: loss = 0.0386448 (* 1 = 0.0386448 loss)
I0502 11:34:18.452320 26473 sgd_solver.cpp:106] Iteration 147400, lr = 4.39805e-06
I0502 11:34:19.387696 26473 solver.cpp:362] Iteration 147500, Testing net (#0)
I0502 11:34:19.387719 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:19.512065 26473 solver.cpp:429]     Test net output #0: loss = 0.250296 (* 1 = 0.250296 loss)
I0502 11:34:19.514935 26473 solver.cpp:242] Iteration 147500 (93.6759 iter/s, 1.06751s/100 iter), loss = 0.0501012
I0502 11:34:19.514955 26473 solver.cpp:261]     Train net output #0: loss = 0.0501012 (* 1 = 0.0501012 loss)
I0502 11:34:19.514963 26473 sgd_solver.cpp:106] Iteration 147500, lr = 4.39805e-06
I0502 11:34:19.516676 26473 solver.cpp:362] Iteration 147500, Testing net (#0)
I0502 11:34:19.516696 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:19.647141 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9705
I0502 11:34:19.647161 26473 solver.cpp:429]     Test net output #1: loss = 0.0790534 (* 1 = 0.0790534 loss)
I0502 11:34:19.650084 26473 solver.cpp:242] Iteration 147500 (83.4898 iter/s, 1.19775s/100 iter), loss = 0.0595673
I0502 11:34:19.650104 26473 solver.cpp:261]     Train net output #0: loss = 0.0595673 (* 1 = 0.0595673 loss)
I0502 11:34:19.650120 26473 sgd_solver.cpp:106] Iteration 147500, lr = 4.39805e-06
I0502 11:34:20.589696 26473 solver.cpp:242] Iteration 147600 (93.0479 iter/s, 1.07472s/100 iter), loss = 0.0392309
I0502 11:34:20.589735 26473 solver.cpp:261]     Train net output #0: loss = 0.0392309 (* 1 = 0.0392309 loss)
I0502 11:34:20.589743 26473 sgd_solver.cpp:106] Iteration 147600, lr = 4.39805e-06
I0502 11:34:20.594591 26473 solver.cpp:242] Iteration 147600 (105.88 iter/s, 0.944464s/100 iter), loss = 0.0542868
I0502 11:34:20.594615 26473 solver.cpp:261]     Train net output #0: loss = 0.0542868 (* 1 = 0.0542868 loss)
I0502 11:34:20.594624 26473 sgd_solver.cpp:106] Iteration 147600, lr = 4.39805e-06
I0502 11:34:21.533577 26473 solver.cpp:242] Iteration 147700 (105.953 iter/s, 0.943814s/100 iter), loss = 0.153962
I0502 11:34:21.533613 26473 solver.cpp:261]     Train net output #0: loss = 0.153962 (* 1 = 0.153962 loss)
I0502 11:34:21.533622 26473 sgd_solver.cpp:106] Iteration 147700, lr = 4.39805e-06
I0502 11:34:21.538389 26473 solver.cpp:242] Iteration 147700 (105.96 iter/s, 0.943756s/100 iter), loss = 0.0122718
I0502 11:34:21.538411 26473 solver.cpp:261]     Train net output #0: loss = 0.0122718 (* 1 = 0.0122718 loss)
I0502 11:34:21.538419 26473 sgd_solver.cpp:106] Iteration 147700, lr = 4.39805e-06
I0502 11:34:22.478008 26473 solver.cpp:242] Iteration 147800 (105.891 iter/s, 0.944364s/100 iter), loss = 0.123846
I0502 11:34:22.478047 26473 solver.cpp:261]     Train net output #0: loss = 0.123846 (* 1 = 0.123846 loss)
I0502 11:34:22.478057 26473 sgd_solver.cpp:106] Iteration 147800, lr = 4.39805e-06
I0502 11:34:22.482928 26473 solver.cpp:242] Iteration 147800 (105.876 iter/s, 0.944498s/100 iter), loss = 0.0101324
I0502 11:34:22.482951 26473 solver.cpp:261]     Train net output #0: loss = 0.0101324 (* 1 = 0.0101324 loss)
I0502 11:34:22.482960 26473 sgd_solver.cpp:106] Iteration 147800, lr = 4.39805e-06
I0502 11:34:23.421813 26473 solver.cpp:242] Iteration 147900 (105.961 iter/s, 0.94374s/100 iter), loss = 0.0780958
I0502 11:34:23.421841 26473 solver.cpp:261]     Train net output #0: loss = 0.0780958 (* 1 = 0.0780958 loss)
I0502 11:34:23.421850 26473 sgd_solver.cpp:106] Iteration 147900, lr = 4.39805e-06
I0502 11:34:23.426627 26473 solver.cpp:242] Iteration 147900 (105.971 iter/s, 0.943658s/100 iter), loss = 0.131138
I0502 11:34:23.426651 26473 solver.cpp:261]     Train net output #0: loss = 0.131138 (* 1 = 0.131138 loss)
I0502 11:34:23.426659 26473 sgd_solver.cpp:106] Iteration 147900, lr = 4.39805e-06
I0502 11:34:24.362609 26473 solver.cpp:362] Iteration 148000, Testing net (#0)
I0502 11:34:24.362637 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:24.486951 26473 solver.cpp:429]     Test net output #0: loss = 0.273084 (* 1 = 0.273084 loss)
I0502 11:34:24.489831 26473 solver.cpp:242] Iteration 148000 (93.6355 iter/s, 1.06797s/100 iter), loss = 0.119941
I0502 11:34:24.489851 26473 solver.cpp:261]     Train net output #0: loss = 0.119941 (* 1 = 0.119941 loss)
I0502 11:34:24.489861 26473 sgd_solver.cpp:106] Iteration 148000, lr = 4.39805e-06
I0502 11:34:24.491472 26473 solver.cpp:362] Iteration 148000, Testing net (#0)
I0502 11:34:24.491485 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:24.622314 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9575
I0502 11:34:24.622336 26473 solver.cpp:429]     Test net output #1: loss = 0.0837679 (* 1 = 0.0837679 loss)
I0502 11:34:24.625260 26473 solver.cpp:242] Iteration 148000 (83.4314 iter/s, 1.19859s/100 iter), loss = 0.00928737
I0502 11:34:24.625282 26473 solver.cpp:261]     Train net output #0: loss = 0.00928737 (* 1 = 0.00928737 loss)
I0502 11:34:24.625290 26473 sgd_solver.cpp:106] Iteration 148000, lr = 4.39805e-06
I0502 11:34:25.564337 26473 solver.cpp:242] Iteration 148100 (93.0702 iter/s, 1.07446s/100 iter), loss = 0.227623
I0502 11:34:25.564383 26473 solver.cpp:261]     Train net output #0: loss = 0.227623 (* 1 = 0.227623 loss)
I0502 11:34:25.564393 26473 sgd_solver.cpp:106] Iteration 148100, lr = 4.39805e-06
I0502 11:34:25.569208 26473 solver.cpp:242] Iteration 148100 (105.943 iter/s, 0.943902s/100 iter), loss = 0.0466947
I0502 11:34:25.569242 26473 solver.cpp:261]     Train net output #0: loss = 0.0466947 (* 1 = 0.0466947 loss)
I0502 11:34:25.569252 26473 sgd_solver.cpp:106] Iteration 148100, lr = 4.39805e-06
I0502 11:34:26.507685 26473 solver.cpp:242] Iteration 148200 (106.014 iter/s, 0.943271s/100 iter), loss = 0.189572
I0502 11:34:26.507727 26473 solver.cpp:261]     Train net output #0: loss = 0.189572 (* 1 = 0.189572 loss)
I0502 11:34:26.507736 26473 sgd_solver.cpp:106] Iteration 148200, lr = 4.39805e-06
I0502 11:34:26.512513 26473 solver.cpp:242] Iteration 148200 (106.016 iter/s, 0.943253s/100 iter), loss = 0.0484654
I0502 11:34:26.512537 26473 solver.cpp:261]     Train net output #0: loss = 0.0484654 (* 1 = 0.0484654 loss)
I0502 11:34:26.512545 26473 sgd_solver.cpp:106] Iteration 148200, lr = 4.39805e-06
I0502 11:34:27.451680 26473 solver.cpp:242] Iteration 148300 (105.941 iter/s, 0.943923s/100 iter), loss = 0.130803
I0502 11:34:27.451725 26473 solver.cpp:261]     Train net output #0: loss = 0.130803 (* 1 = 0.130803 loss)
I0502 11:34:27.451733 26473 sgd_solver.cpp:106] Iteration 148300, lr = 4.39805e-06
I0502 11:34:27.456497 26473 solver.cpp:242] Iteration 148300 (105.939 iter/s, 0.943942s/100 iter), loss = 0.116439
I0502 11:34:27.456521 26473 solver.cpp:261]     Train net output #0: loss = 0.116439 (* 1 = 0.116439 loss)
I0502 11:34:27.456528 26473 sgd_solver.cpp:106] Iteration 148300, lr = 4.39805e-06
I0502 11:34:28.395439 26473 solver.cpp:242] Iteration 148400 (105.967 iter/s, 0.943688s/100 iter), loss = 0.11629
I0502 11:34:28.395481 26473 solver.cpp:261]     Train net output #0: loss = 0.11629 (* 1 = 0.11629 loss)
I0502 11:34:28.395489 26473 sgd_solver.cpp:106] Iteration 148400, lr = 4.39805e-06
I0502 11:34:28.400280 26473 solver.cpp:242] Iteration 148400 (105.961 iter/s, 0.943742s/100 iter), loss = 0.147505
I0502 11:34:28.400303 26473 solver.cpp:261]     Train net output #0: loss = 0.147505 (* 1 = 0.147505 loss)
I0502 11:34:28.400312 26473 sgd_solver.cpp:106] Iteration 148400, lr = 4.39805e-06
I0502 11:34:29.335680 26473 solver.cpp:362] Iteration 148500, Testing net (#0)
I0502 11:34:29.335705 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:29.460144 26473 solver.cpp:429]     Test net output #0: loss = 0.212147 (* 1 = 0.212147 loss)
I0502 11:34:29.463022 26473 solver.cpp:242] Iteration 148500 (93.6747 iter/s, 1.06752s/100 iter), loss = 0.0765926
I0502 11:34:29.463042 26473 solver.cpp:261]     Train net output #0: loss = 0.0765926 (* 1 = 0.0765926 loss)
I0502 11:34:29.463050 26473 sgd_solver.cpp:106] Iteration 148500, lr = 4.39805e-06
I0502 11:34:29.464680 26473 solver.cpp:362] Iteration 148500, Testing net (#0)
I0502 11:34:29.464694 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:29.595513 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:34:29.595541 26473 solver.cpp:429]     Test net output #1: loss = 0.0741149 (* 1 = 0.0741149 loss)
I0502 11:34:29.598500 26473 solver.cpp:242] Iteration 148500 (83.4602 iter/s, 1.19818s/100 iter), loss = 0.0736262
I0502 11:34:29.598520 26473 solver.cpp:261]     Train net output #0: loss = 0.0736262 (* 1 = 0.0736262 loss)
I0502 11:34:29.598529 26473 sgd_solver.cpp:106] Iteration 148500, lr = 4.39805e-06
I0502 11:34:30.537930 26473 solver.cpp:242] Iteration 148600 (93.0353 iter/s, 1.07486s/100 iter), loss = 0.124363
I0502 11:34:30.537969 26473 solver.cpp:261]     Train net output #0: loss = 0.124363 (* 1 = 0.124363 loss)
I0502 11:34:30.537978 26473 sgd_solver.cpp:106] Iteration 148600, lr = 4.39805e-06
I0502 11:34:30.542811 26473 solver.cpp:242] Iteration 148600 (105.903 iter/s, 0.944264s/100 iter), loss = 0.0442682
I0502 11:34:30.542834 26473 solver.cpp:261]     Train net output #0: loss = 0.0442682 (* 1 = 0.0442682 loss)
I0502 11:34:30.542843 26473 sgd_solver.cpp:106] Iteration 148600, lr = 4.39805e-06
I0502 11:34:31.482724 26473 solver.cpp:242] Iteration 148700 (105.851 iter/s, 0.944724s/100 iter), loss = 0.294755
I0502 11:34:31.482764 26473 solver.cpp:261]     Train net output #0: loss = 0.294755 (* 1 = 0.294755 loss)
I0502 11:34:31.482781 26473 sgd_solver.cpp:106] Iteration 148700, lr = 4.39805e-06
I0502 11:34:31.487560 26473 solver.cpp:242] Iteration 148700 (105.853 iter/s, 0.944707s/100 iter), loss = 0.00149252
I0502 11:34:31.487582 26473 solver.cpp:261]     Train net output #0: loss = 0.00149252 (* 1 = 0.00149252 loss)
I0502 11:34:31.487591 26473 sgd_solver.cpp:106] Iteration 148700, lr = 4.39805e-06
I0502 11:34:32.426215 26473 solver.cpp:242] Iteration 148800 (105.997 iter/s, 0.943422s/100 iter), loss = 0.126862
I0502 11:34:32.426252 26473 solver.cpp:261]     Train net output #0: loss = 0.126862 (* 1 = 0.126862 loss)
I0502 11:34:32.426261 26473 sgd_solver.cpp:106] Iteration 148800, lr = 4.39805e-06
I0502 11:34:32.431015 26473 solver.cpp:242] Iteration 148800 (105.998 iter/s, 0.943415s/100 iter), loss = 0.00491573
I0502 11:34:32.431038 26473 solver.cpp:261]     Train net output #0: loss = 0.00491573 (* 1 = 0.00491573 loss)
I0502 11:34:32.431047 26473 sgd_solver.cpp:106] Iteration 148800, lr = 4.39805e-06
I0502 11:34:33.370277 26473 solver.cpp:242] Iteration 148900 (105.933 iter/s, 0.943997s/100 iter), loss = 0.573353
I0502 11:34:33.370314 26473 solver.cpp:261]     Train net output #0: loss = 0.573353 (* 1 = 0.573353 loss)
I0502 11:34:33.370322 26473 sgd_solver.cpp:106] Iteration 148900, lr = 4.39805e-06
I0502 11:34:33.375066 26473 solver.cpp:242] Iteration 148900 (105.931 iter/s, 0.94401s/100 iter), loss = 0.156218
I0502 11:34:33.375089 26473 solver.cpp:261]     Train net output #0: loss = 0.156218 (* 1 = 0.156218 loss)
I0502 11:34:33.375097 26473 sgd_solver.cpp:106] Iteration 148900, lr = 4.39805e-06
I0502 11:34:34.311141 26473 solver.cpp:362] Iteration 149000, Testing net (#0)
I0502 11:34:34.311161 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:34.435490 26473 solver.cpp:429]     Test net output #0: loss = 0.254288 (* 1 = 0.254288 loss)
I0502 11:34:34.438347 26473 solver.cpp:242] Iteration 149000 (93.6316 iter/s, 1.06802s/100 iter), loss = 0.102886
I0502 11:34:34.438367 26473 solver.cpp:261]     Train net output #0: loss = 0.102886 (* 1 = 0.102886 loss)
I0502 11:34:34.438375 26473 sgd_solver.cpp:106] Iteration 149000, lr = 4.39805e-06
I0502 11:34:34.440003 26473 solver.cpp:362] Iteration 149000, Testing net (#0)
I0502 11:34:34.440016 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:34.570453 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:34:34.570473 26473 solver.cpp:429]     Test net output #1: loss = 0.0765622 (* 1 = 0.0765622 loss)
I0502 11:34:34.573393 26473 solver.cpp:242] Iteration 149000 (83.4527 iter/s, 1.19828s/100 iter), loss = 0.0415124
I0502 11:34:34.573415 26473 solver.cpp:261]     Train net output #0: loss = 0.0415124 (* 1 = 0.0415124 loss)
I0502 11:34:34.573422 26473 sgd_solver.cpp:106] Iteration 149000, lr = 4.39805e-06
I0502 11:34:35.512302 26473 solver.cpp:242] Iteration 149100 (93.1177 iter/s, 1.07391s/100 iter), loss = 0.147016
I0502 11:34:35.512343 26473 solver.cpp:261]     Train net output #0: loss = 0.147016 (* 1 = 0.147016 loss)
I0502 11:34:35.512352 26473 sgd_solver.cpp:106] Iteration 149100, lr = 4.39805e-06
I0502 11:34:35.517200 26473 solver.cpp:242] Iteration 149100 (105.959 iter/s, 0.94376s/100 iter), loss = 0.0475939
I0502 11:34:35.517223 26473 solver.cpp:261]     Train net output #0: loss = 0.0475939 (* 1 = 0.0475939 loss)
I0502 11:34:35.517232 26473 sgd_solver.cpp:106] Iteration 149100, lr = 4.39805e-06
I0502 11:34:36.457077 26473 solver.cpp:242] Iteration 149200 (105.852 iter/s, 0.944713s/100 iter), loss = 0.217737
I0502 11:34:36.457123 26473 solver.cpp:261]     Train net output #0: loss = 0.217737 (* 1 = 0.217737 loss)
I0502 11:34:36.457131 26473 sgd_solver.cpp:106] Iteration 149200, lr = 4.39805e-06
I0502 11:34:36.461902 26473 solver.cpp:242] Iteration 149200 (105.858 iter/s, 0.944661s/100 iter), loss = 0.0428495
I0502 11:34:36.461925 26473 solver.cpp:261]     Train net output #0: loss = 0.0428495 (* 1 = 0.0428495 loss)
I0502 11:34:36.461935 26473 sgd_solver.cpp:106] Iteration 149200, lr = 4.39805e-06
I0502 11:34:37.401015 26473 solver.cpp:242] Iteration 149300 (105.948 iter/s, 0.943863s/100 iter), loss = 0.163413
I0502 11:34:37.401057 26473 solver.cpp:261]     Train net output #0: loss = 0.163413 (* 1 = 0.163413 loss)
I0502 11:34:37.401065 26473 sgd_solver.cpp:106] Iteration 149300, lr = 4.39805e-06
I0502 11:34:37.405807 26473 solver.cpp:242] Iteration 149300 (105.947 iter/s, 0.943864s/100 iter), loss = 0.137206
I0502 11:34:37.405830 26473 solver.cpp:261]     Train net output #0: loss = 0.137206 (* 1 = 0.137206 loss)
I0502 11:34:37.405838 26473 sgd_solver.cpp:106] Iteration 149300, lr = 4.39805e-06
I0502 11:34:38.346112 26473 solver.cpp:242] Iteration 149400 (105.817 iter/s, 0.945027s/100 iter), loss = 0.0691804
I0502 11:34:38.346170 26473 solver.cpp:261]     Train net output #0: loss = 0.0691804 (* 1 = 0.0691804 loss)
I0502 11:34:38.346184 26473 sgd_solver.cpp:106] Iteration 149400, lr = 4.39805e-06
I0502 11:34:38.350999 26473 solver.cpp:242] Iteration 149400 (105.803 iter/s, 0.945151s/100 iter), loss = 0.106026
I0502 11:34:38.351023 26473 solver.cpp:261]     Train net output #0: loss = 0.106026 (* 1 = 0.106026 loss)
I0502 11:34:38.351032 26473 sgd_solver.cpp:106] Iteration 149400, lr = 4.39805e-06
I0502 11:34:39.286798 26473 solver.cpp:362] Iteration 149500, Testing net (#0)
I0502 11:34:39.286824 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:39.411152 26473 solver.cpp:429]     Test net output #0: loss = 0.250337 (* 1 = 0.250337 loss)
I0502 11:34:39.414033 26473 solver.cpp:242] Iteration 149500 (93.6465 iter/s, 1.06785s/100 iter), loss = 0.0838085
I0502 11:34:39.414053 26473 solver.cpp:261]     Train net output #0: loss = 0.0838085 (* 1 = 0.0838085 loss)
I0502 11:34:39.414062 26473 sgd_solver.cpp:106] Iteration 149500, lr = 4.39805e-06
I0502 11:34:39.415688 26473 solver.cpp:362] Iteration 149500, Testing net (#0)
I0502 11:34:39.415701 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:39.546577 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:34:39.546598 26473 solver.cpp:429]     Test net output #1: loss = 0.0731227 (* 1 = 0.0731227 loss)
I0502 11:34:39.549530 26473 solver.cpp:242] Iteration 149500 (83.4386 iter/s, 1.19849s/100 iter), loss = 0.0674434
I0502 11:34:39.549551 26473 solver.cpp:261]     Train net output #0: loss = 0.0674434 (* 1 = 0.0674434 loss)
I0502 11:34:39.549559 26473 sgd_solver.cpp:106] Iteration 149500, lr = 4.39805e-06
I0502 11:34:40.489436 26473 solver.cpp:242] Iteration 149600 (92.9926 iter/s, 1.07535s/100 iter), loss = 0.0989665
I0502 11:34:40.489481 26473 solver.cpp:261]     Train net output #0: loss = 0.0989665 (* 1 = 0.0989665 loss)
I0502 11:34:40.489490 26473 sgd_solver.cpp:106] Iteration 149600, lr = 4.39805e-06
I0502 11:34:40.494410 26473 solver.cpp:242] Iteration 149600 (105.839 iter/s, 0.944833s/100 iter), loss = 0.0625402
I0502 11:34:40.494434 26473 solver.cpp:261]     Train net output #0: loss = 0.0625402 (* 1 = 0.0625402 loss)
I0502 11:34:40.494443 26473 sgd_solver.cpp:106] Iteration 149600, lr = 4.39805e-06
I0502 11:34:41.434453 26473 solver.cpp:242] Iteration 149700 (105.827 iter/s, 0.94494s/100 iter), loss = 0.0883683
I0502 11:34:41.434495 26473 solver.cpp:261]     Train net output #0: loss = 0.0883683 (* 1 = 0.0883683 loss)
I0502 11:34:41.434504 26473 sgd_solver.cpp:106] Iteration 149700, lr = 4.39805e-06
I0502 11:34:41.439260 26473 solver.cpp:242] Iteration 149700 (105.842 iter/s, 0.944809s/100 iter), loss = 0.00993922
I0502 11:34:41.439283 26473 solver.cpp:261]     Train net output #0: loss = 0.00993922 (* 1 = 0.00993922 loss)
I0502 11:34:41.439292 26473 sgd_solver.cpp:106] Iteration 149700, lr = 4.39805e-06
I0502 11:34:42.379135 26473 solver.cpp:242] Iteration 149800 (105.864 iter/s, 0.94461s/100 iter), loss = 0.920974
I0502 11:34:42.379175 26473 solver.cpp:261]     Train net output #0: loss = 0.920974 (* 1 = 0.920974 loss)
I0502 11:34:42.379184 26473 sgd_solver.cpp:106] Iteration 149800, lr = 4.39805e-06
I0502 11:34:42.383981 26473 solver.cpp:242] Iteration 149800 (105.856 iter/s, 0.944679s/100 iter), loss = 0.1518
I0502 11:34:42.384013 26473 solver.cpp:261]     Train net output #0: loss = 0.1518 (* 1 = 0.1518 loss)
I0502 11:34:42.384022 26473 sgd_solver.cpp:106] Iteration 149800, lr = 4.39805e-06
I0502 11:34:43.323318 26473 solver.cpp:242] Iteration 149900 (105.919 iter/s, 0.944116s/100 iter), loss = 0.357758
I0502 11:34:43.323356 26473 solver.cpp:261]     Train net output #0: loss = 0.357758 (* 1 = 0.357758 loss)
I0502 11:34:43.323365 26473 sgd_solver.cpp:106] Iteration 149900, lr = 4.39805e-06
I0502 11:34:43.328150 26473 solver.cpp:242] Iteration 149900 (105.919 iter/s, 0.94412s/100 iter), loss = 0.00509649
I0502 11:34:43.328173 26473 solver.cpp:261]     Train net output #0: loss = 0.00509649 (* 1 = 0.00509649 loss)
I0502 11:34:43.328182 26473 sgd_solver.cpp:106] Iteration 149900, lr = 4.39805e-06
I0502 11:34:44.257858 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_150000.caffemodel
I0502 11:34:44.262100 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_150000.solverstate
I0502 11:34:44.268975 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_150000.caffemodel
I0502 11:34:44.273149 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_150000.solverstate
I0502 11:34:44.276645 26473 solver.cpp:362] Iteration 150000, Testing net (#0)
I0502 11:34:44.276660 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:44.401134 26473 solver.cpp:429]     Test net output #0: loss = 0.260814 (* 1 = 0.260814 loss)
I0502 11:34:44.404021 26473 solver.cpp:242] Iteration 150000 (92.5372 iter/s, 1.08065s/100 iter), loss = 0.0526674
I0502 11:34:44.404042 26473 solver.cpp:261]     Train net output #0: loss = 0.0526674 (* 1 = 0.0526674 loss)
I0502 11:34:44.404050 26473 sgd_solver.cpp:106] Iteration 150000, lr = 3.51844e-06
I0502 11:34:44.405730 26473 solver.cpp:362] Iteration 150000, Testing net (#0)
I0502 11:34:44.405742 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:44.536257 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:34:44.536278 26473 solver.cpp:429]     Test net output #1: loss = 0.0835831 (* 1 = 0.0835831 loss)
I0502 11:34:44.539201 26473 solver.cpp:242] Iteration 150000 (82.5759 iter/s, 1.21101s/100 iter), loss = 0.00338806
I0502 11:34:44.539222 26473 solver.cpp:261]     Train net output #0: loss = 0.00338806 (* 1 = 0.00338806 loss)
I0502 11:34:44.539229 26473 sgd_solver.cpp:106] Iteration 150000, lr = 3.51844e-06
I0502 11:34:45.477262 26473 solver.cpp:242] Iteration 150100 (93.1798 iter/s, 1.07319s/100 iter), loss = 0.175194
I0502 11:34:45.477299 26473 solver.cpp:261]     Train net output #0: loss = 0.175194 (* 1 = 0.175194 loss)
I0502 11:34:45.477308 26473 sgd_solver.cpp:106] Iteration 150100, lr = 3.51844e-06
I0502 11:34:45.482161 26473 solver.cpp:242] Iteration 150100 (106.054 iter/s, 0.942913s/100 iter), loss = 0.0678959
I0502 11:34:45.482185 26473 solver.cpp:261]     Train net output #0: loss = 0.0678959 (* 1 = 0.0678959 loss)
I0502 11:34:45.482193 26473 sgd_solver.cpp:106] Iteration 150100, lr = 3.51844e-06
I0502 11:34:46.421355 26473 solver.cpp:242] Iteration 150200 (105.929 iter/s, 0.944033s/100 iter), loss = 0.0329266
I0502 11:34:46.421389 26473 solver.cpp:261]     Train net output #0: loss = 0.0329266 (* 1 = 0.0329266 loss)
I0502 11:34:46.421409 26473 sgd_solver.cpp:106] Iteration 150200, lr = 3.51844e-06
I0502 11:34:46.426240 26473 solver.cpp:242] Iteration 150200 (105.929 iter/s, 0.944032s/100 iter), loss = 0.0732235
I0502 11:34:46.426264 26473 solver.cpp:261]     Train net output #0: loss = 0.0732235 (* 1 = 0.0732235 loss)
I0502 11:34:46.426271 26473 sgd_solver.cpp:106] Iteration 150200, lr = 3.51844e-06
I0502 11:34:47.365887 26473 solver.cpp:242] Iteration 150300 (105.88 iter/s, 0.944469s/100 iter), loss = 0.0982954
I0502 11:34:47.365921 26473 solver.cpp:261]     Train net output #0: loss = 0.0982954 (* 1 = 0.0982954 loss)
I0502 11:34:47.365929 26473 sgd_solver.cpp:106] Iteration 150300, lr = 3.51844e-06
I0502 11:34:47.370688 26473 solver.cpp:242] Iteration 150300 (105.886 iter/s, 0.944408s/100 iter), loss = 0.130932
I0502 11:34:47.370710 26473 solver.cpp:261]     Train net output #0: loss = 0.130932 (* 1 = 0.130932 loss)
I0502 11:34:47.370719 26473 sgd_solver.cpp:106] Iteration 150300, lr = 3.51844e-06
I0502 11:34:48.309792 26473 solver.cpp:242] Iteration 150400 (105.95 iter/s, 0.94384s/100 iter), loss = 0.265847
I0502 11:34:48.309834 26473 solver.cpp:261]     Train net output #0: loss = 0.265847 (* 1 = 0.265847 loss)
I0502 11:34:48.309844 26473 sgd_solver.cpp:106] Iteration 150400, lr = 3.51844e-06
I0502 11:34:48.314617 26473 solver.cpp:242] Iteration 150400 (105.945 iter/s, 0.943888s/100 iter), loss = 0.0955089
I0502 11:34:48.314640 26473 solver.cpp:261]     Train net output #0: loss = 0.0955089 (* 1 = 0.0955089 loss)
I0502 11:34:48.314649 26473 sgd_solver.cpp:106] Iteration 150400, lr = 3.51844e-06
I0502 11:34:49.250557 26473 solver.cpp:362] Iteration 150500, Testing net (#0)
I0502 11:34:49.250600 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:49.375252 26473 solver.cpp:429]     Test net output #0: loss = 0.185558 (* 1 = 0.185558 loss)
I0502 11:34:49.378124 26473 solver.cpp:242] Iteration 150500 (93.609 iter/s, 1.06827s/100 iter), loss = 0.0344844
I0502 11:34:49.378145 26473 solver.cpp:261]     Train net output #0: loss = 0.0344844 (* 1 = 0.0344844 loss)
I0502 11:34:49.378154 26473 sgd_solver.cpp:106] Iteration 150500, lr = 3.51844e-06
I0502 11:34:49.379778 26473 solver.cpp:362] Iteration 150500, Testing net (#0)
I0502 11:34:49.379792 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:49.510843 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:34:49.510870 26473 solver.cpp:429]     Test net output #1: loss = 0.0848622 (* 1 = 0.0848622 loss)
I0502 11:34:49.513820 26473 solver.cpp:242] Iteration 150500 (83.3918 iter/s, 1.19916s/100 iter), loss = 0.0403106
I0502 11:34:49.513840 26473 solver.cpp:261]     Train net output #0: loss = 0.0403106 (* 1 = 0.0403106 loss)
I0502 11:34:49.513849 26473 sgd_solver.cpp:106] Iteration 150500, lr = 3.51844e-06
I0502 11:34:50.453285 26473 solver.cpp:242] Iteration 150600 (93.0135 iter/s, 1.07511s/100 iter), loss = 0.116056
I0502 11:34:50.453321 26473 solver.cpp:261]     Train net output #0: loss = 0.116056 (* 1 = 0.116056 loss)
I0502 11:34:50.453330 26473 sgd_solver.cpp:106] Iteration 150600, lr = 3.51844e-06
I0502 11:34:50.458139 26473 solver.cpp:242] Iteration 150600 (105.902 iter/s, 0.944273s/100 iter), loss = 0.0852184
I0502 11:34:50.458163 26473 solver.cpp:261]     Train net output #0: loss = 0.0852184 (* 1 = 0.0852184 loss)
I0502 11:34:50.458171 26473 sgd_solver.cpp:106] Iteration 150600, lr = 3.51844e-06
I0502 11:34:51.397995 26473 solver.cpp:242] Iteration 150700 (105.859 iter/s, 0.94465s/100 iter), loss = 0.102418
I0502 11:34:51.398036 26473 solver.cpp:261]     Train net output #0: loss = 0.102418 (* 1 = 0.102418 loss)
I0502 11:34:51.398046 26473 sgd_solver.cpp:106] Iteration 150700, lr = 3.51844e-06
I0502 11:34:51.402865 26473 solver.cpp:242] Iteration 150700 (105.856 iter/s, 0.944679s/100 iter), loss = 0.0441336
I0502 11:34:51.402889 26473 solver.cpp:261]     Train net output #0: loss = 0.0441336 (* 1 = 0.0441336 loss)
I0502 11:34:51.402897 26473 sgd_solver.cpp:106] Iteration 150700, lr = 3.51844e-06
I0502 11:34:52.342459 26473 solver.cpp:242] Iteration 150800 (105.888 iter/s, 0.944394s/100 iter), loss = 0.680783
I0502 11:34:52.342502 26473 solver.cpp:261]     Train net output #0: loss = 0.680783 (* 1 = 0.680783 loss)
I0502 11:34:52.342511 26473 sgd_solver.cpp:106] Iteration 150800, lr = 3.51844e-06
I0502 11:34:52.347278 26473 solver.cpp:242] Iteration 150800 (105.891 iter/s, 0.944371s/100 iter), loss = 0.0402874
I0502 11:34:52.347301 26473 solver.cpp:261]     Train net output #0: loss = 0.0402874 (* 1 = 0.0402874 loss)
I0502 11:34:52.347309 26473 sgd_solver.cpp:106] Iteration 150800, lr = 3.51844e-06
I0502 11:34:53.306529 26473 solver.cpp:242] Iteration 150900 (103.735 iter/s, 0.963997s/100 iter), loss = 0.102845
I0502 11:34:53.306574 26473 solver.cpp:261]     Train net output #0: loss = 0.102845 (* 1 = 0.102845 loss)
I0502 11:34:53.306583 26473 sgd_solver.cpp:106] Iteration 150900, lr = 3.51844e-06
I0502 11:34:53.311342 26473 solver.cpp:242] Iteration 150900 (103.732 iter/s, 0.964023s/100 iter), loss = 0.0540686
I0502 11:34:53.311367 26473 solver.cpp:261]     Train net output #0: loss = 0.0540686 (* 1 = 0.0540686 loss)
I0502 11:34:53.311377 26473 sgd_solver.cpp:106] Iteration 150900, lr = 3.51844e-06
I0502 11:34:54.248984 26473 solver.cpp:362] Iteration 151000, Testing net (#0)
I0502 11:34:54.249013 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:54.373325 26473 solver.cpp:429]     Test net output #0: loss = 0.203843 (* 1 = 0.203843 loss)
I0502 11:34:54.376224 26473 solver.cpp:242] Iteration 151000 (93.4902 iter/s, 1.06963s/100 iter), loss = 0.168914
I0502 11:34:54.376245 26473 solver.cpp:261]     Train net output #0: loss = 0.168914 (* 1 = 0.168914 loss)
I0502 11:34:54.376253 26473 sgd_solver.cpp:106] Iteration 151000, lr = 3.51844e-06
I0502 11:34:54.377924 26473 solver.cpp:362] Iteration 151000, Testing net (#0)
I0502 11:34:54.377938 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:54.508807 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:34:54.508829 26473 solver.cpp:429]     Test net output #1: loss = 0.090371 (* 1 = 0.090371 loss)
I0502 11:34:54.511764 26473 solver.cpp:242] Iteration 151000 (83.3074 iter/s, 1.20037s/100 iter), loss = 0.0808937
I0502 11:34:54.511782 26473 solver.cpp:261]     Train net output #0: loss = 0.0808937 (* 1 = 0.0808937 loss)
I0502 11:34:54.511791 26473 sgd_solver.cpp:106] Iteration 151000, lr = 3.51844e-06
I0502 11:34:55.451402 26473 solver.cpp:242] Iteration 151100 (93.0121 iter/s, 1.07513s/100 iter), loss = 0.184982
I0502 11:34:55.451442 26473 solver.cpp:261]     Train net output #0: loss = 0.184982 (* 1 = 0.184982 loss)
I0502 11:34:55.451452 26473 sgd_solver.cpp:106] Iteration 151100, lr = 3.51844e-06
I0502 11:34:55.456212 26473 solver.cpp:242] Iteration 151100 (105.886 iter/s, 0.944412s/100 iter), loss = 0.0607077
I0502 11:34:55.456236 26473 solver.cpp:261]     Train net output #0: loss = 0.0607077 (* 1 = 0.0607077 loss)
I0502 11:34:55.456245 26473 sgd_solver.cpp:106] Iteration 151100, lr = 3.51844e-06
I0502 11:34:56.395982 26473 solver.cpp:242] Iteration 151200 (105.875 iter/s, 0.944513s/100 iter), loss = 0.173868
I0502 11:34:56.396024 26473 solver.cpp:261]     Train net output #0: loss = 0.173868 (* 1 = 0.173868 loss)
I0502 11:34:56.396034 26473 sgd_solver.cpp:106] Iteration 151200, lr = 3.51844e-06
I0502 11:34:56.400866 26473 solver.cpp:242] Iteration 151200 (105.865 iter/s, 0.944602s/100 iter), loss = 0.0263021
I0502 11:34:56.400888 26473 solver.cpp:261]     Train net output #0: loss = 0.0263021 (* 1 = 0.0263021 loss)
I0502 11:34:56.400897 26473 sgd_solver.cpp:106] Iteration 151200, lr = 3.51844e-06
I0502 11:34:57.339704 26473 solver.cpp:242] Iteration 151300 (105.972 iter/s, 0.943649s/100 iter), loss = 0.498321
I0502 11:34:57.339742 26473 solver.cpp:261]     Train net output #0: loss = 0.498321 (* 1 = 0.498321 loss)
I0502 11:34:57.339751 26473 sgd_solver.cpp:106] Iteration 151300, lr = 3.51844e-06
I0502 11:34:57.344547 26473 solver.cpp:242] Iteration 151300 (105.973 iter/s, 0.94364s/100 iter), loss = 0.0258151
I0502 11:34:57.344581 26473 solver.cpp:261]     Train net output #0: loss = 0.0258151 (* 1 = 0.0258151 loss)
I0502 11:34:57.344591 26473 sgd_solver.cpp:106] Iteration 151300, lr = 3.51844e-06
I0502 11:34:58.283496 26473 solver.cpp:242] Iteration 151400 (105.963 iter/s, 0.943724s/100 iter), loss = 0.0909128
I0502 11:34:58.283537 26473 solver.cpp:261]     Train net output #0: loss = 0.0909128 (* 1 = 0.0909128 loss)
I0502 11:34:58.283546 26473 sgd_solver.cpp:106] Iteration 151400, lr = 3.51844e-06
I0502 11:34:58.288362 26473 solver.cpp:242] Iteration 151400 (105.959 iter/s, 0.943764s/100 iter), loss = 0.0286604
I0502 11:34:58.288385 26473 solver.cpp:261]     Train net output #0: loss = 0.0286604 (* 1 = 0.0286604 loss)
I0502 11:34:58.288394 26473 sgd_solver.cpp:106] Iteration 151400, lr = 3.51844e-06
I0502 11:34:59.224542 26473 solver.cpp:362] Iteration 151500, Testing net (#0)
I0502 11:34:59.224570 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:59.348883 26473 solver.cpp:429]     Test net output #0: loss = 0.259749 (* 1 = 0.259749 loss)
I0502 11:34:59.351765 26473 solver.cpp:242] Iteration 151500 (93.6146 iter/s, 1.06821s/100 iter), loss = 0.0698352
I0502 11:34:59.351784 26473 solver.cpp:261]     Train net output #0: loss = 0.0698352 (* 1 = 0.0698352 loss)
I0502 11:34:59.351793 26473 sgd_solver.cpp:106] Iteration 151500, lr = 3.51844e-06
I0502 11:34:59.353446 26473 solver.cpp:362] Iteration 151500, Testing net (#0)
I0502 11:34:59.353459 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:34:59.484220 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:34:59.484254 26473 solver.cpp:429]     Test net output #1: loss = 0.0850103 (* 1 = 0.0850103 loss)
I0502 11:34:59.487185 26473 solver.cpp:242] Iteration 151500 (83.4183 iter/s, 1.19878s/100 iter), loss = 0.134739
I0502 11:34:59.487207 26473 solver.cpp:261]     Train net output #0: loss = 0.134739 (* 1 = 0.134739 loss)
I0502 11:34:59.487215 26473 sgd_solver.cpp:106] Iteration 151500, lr = 3.51844e-06
I0502 11:35:00.439999 26473 solver.cpp:242] Iteration 151600 (91.8962 iter/s, 1.08818s/100 iter), loss = 0.0251946
I0502 11:35:00.440047 26473 solver.cpp:261]     Train net output #0: loss = 0.0251946 (* 1 = 0.0251946 loss)
I0502 11:35:00.440057 26473 sgd_solver.cpp:106] Iteration 151600, lr = 3.51844e-06
I0502 11:35:00.444851 26473 solver.cpp:242] Iteration 151600 (104.425 iter/s, 0.957625s/100 iter), loss = 0.055758
I0502 11:35:00.444876 26473 solver.cpp:261]     Train net output #0: loss = 0.055758 (* 1 = 0.055758 loss)
I0502 11:35:00.444885 26473 sgd_solver.cpp:106] Iteration 151600, lr = 3.51844e-06
I0502 11:35:01.388670 26473 solver.cpp:242] Iteration 151700 (105.419 iter/s, 0.9486s/100 iter), loss = 0.590161
I0502 11:35:01.388706 26473 solver.cpp:261]     Train net output #0: loss = 0.590161 (* 1 = 0.590161 loss)
I0502 11:35:01.388715 26473 sgd_solver.cpp:106] Iteration 151700, lr = 3.51844e-06
I0502 11:35:01.393559 26473 solver.cpp:242] Iteration 151700 (105.412 iter/s, 0.948657s/100 iter), loss = 0.00539706
I0502 11:35:01.393584 26473 solver.cpp:261]     Train net output #0: loss = 0.00539706 (* 1 = 0.00539706 loss)
I0502 11:35:01.393592 26473 sgd_solver.cpp:106] Iteration 151700, lr = 3.51844e-06
I0502 11:35:02.332093 26473 solver.cpp:242] Iteration 151800 (106.005 iter/s, 0.943356s/100 iter), loss = 0.279936
I0502 11:35:02.332125 26473 solver.cpp:261]     Train net output #0: loss = 0.279936 (* 1 = 0.279936 loss)
I0502 11:35:02.332134 26473 sgd_solver.cpp:106] Iteration 151800, lr = 3.51844e-06
I0502 11:35:02.336882 26473 solver.cpp:242] Iteration 151800 (106.013 iter/s, 0.943281s/100 iter), loss = 0.227217
I0502 11:35:02.336905 26473 solver.cpp:261]     Train net output #0: loss = 0.227217 (* 1 = 0.227217 loss)
I0502 11:35:02.336912 26473 sgd_solver.cpp:106] Iteration 151800, lr = 3.51844e-06
I0502 11:35:03.276300 26473 solver.cpp:242] Iteration 151900 (105.916 iter/s, 0.944147s/100 iter), loss = 0.0475215
I0502 11:35:03.276332 26473 solver.cpp:261]     Train net output #0: loss = 0.0475215 (* 1 = 0.0475215 loss)
I0502 11:35:03.276346 26473 sgd_solver.cpp:106] Iteration 151900, lr = 3.51844e-06
I0502 11:35:03.281092 26473 solver.cpp:242] Iteration 151900 (105.913 iter/s, 0.94417s/100 iter), loss = 0.0293761
I0502 11:35:03.281116 26473 solver.cpp:261]     Train net output #0: loss = 0.0293761 (* 1 = 0.0293761 loss)
I0502 11:35:03.281123 26473 sgd_solver.cpp:106] Iteration 151900, lr = 3.51844e-06
I0502 11:35:04.216229 26473 solver.cpp:362] Iteration 152000, Testing net (#0)
I0502 11:35:04.216248 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:04.340595 26473 solver.cpp:429]     Test net output #0: loss = 0.254531 (* 1 = 0.254531 loss)
I0502 11:35:04.343473 26473 solver.cpp:242] Iteration 152000 (93.7099 iter/s, 1.06712s/100 iter), loss = 0.119471
I0502 11:35:04.343492 26473 solver.cpp:261]     Train net output #0: loss = 0.119471 (* 1 = 0.119471 loss)
I0502 11:35:04.343502 26473 sgd_solver.cpp:106] Iteration 152000, lr = 3.51844e-06
I0502 11:35:04.345120 26473 solver.cpp:362] Iteration 152000, Testing net (#0)
I0502 11:35:04.345132 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:04.475742 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:35:04.475764 26473 solver.cpp:429]     Test net output #1: loss = 0.0793684 (* 1 = 0.0793684 loss)
I0502 11:35:04.478689 26473 solver.cpp:242] Iteration 152000 (83.5036 iter/s, 1.19755s/100 iter), loss = 0.0578628
I0502 11:35:04.478709 26473 solver.cpp:261]     Train net output #0: loss = 0.0578628 (* 1 = 0.0578628 loss)
I0502 11:35:04.478718 26473 sgd_solver.cpp:106] Iteration 152000, lr = 3.51844e-06
I0502 11:35:05.416815 26473 solver.cpp:242] Iteration 152100 (93.1713 iter/s, 1.07329s/100 iter), loss = 0.113885
I0502 11:35:05.416849 26473 solver.cpp:261]     Train net output #0: loss = 0.113885 (* 1 = 0.113885 loss)
I0502 11:35:05.416858 26473 sgd_solver.cpp:106] Iteration 152100, lr = 3.51844e-06
I0502 11:35:05.421625 26473 solver.cpp:242] Iteration 152100 (106.056 iter/s, 0.942898s/100 iter), loss = 0.15821
I0502 11:35:05.421648 26473 solver.cpp:261]     Train net output #0: loss = 0.15821 (* 1 = 0.15821 loss)
I0502 11:35:05.421658 26473 sgd_solver.cpp:106] Iteration 152100, lr = 3.51844e-06
I0502 11:35:06.361347 26473 solver.cpp:242] Iteration 152200 (105.879 iter/s, 0.944474s/100 iter), loss = 0.156345
I0502 11:35:06.361377 26473 solver.cpp:261]     Train net output #0: loss = 0.156345 (* 1 = 0.156345 loss)
I0502 11:35:06.361387 26473 sgd_solver.cpp:106] Iteration 152200, lr = 3.51844e-06
I0502 11:35:06.366221 26473 solver.cpp:242] Iteration 152200 (105.871 iter/s, 0.944547s/100 iter), loss = 0.0489145
I0502 11:35:06.366243 26473 solver.cpp:261]     Train net output #0: loss = 0.0489145 (* 1 = 0.0489145 loss)
I0502 11:35:06.366252 26473 sgd_solver.cpp:106] Iteration 152200, lr = 3.51844e-06
I0502 11:35:07.304647 26473 solver.cpp:242] Iteration 152300 (106.018 iter/s, 0.943239s/100 iter), loss = 0.105953
I0502 11:35:07.304693 26473 solver.cpp:261]     Train net output #0: loss = 0.105953 (* 1 = 0.105953 loss)
I0502 11:35:07.304702 26473 sgd_solver.cpp:106] Iteration 152300, lr = 3.51844e-06
I0502 11:35:07.309463 26473 solver.cpp:242] Iteration 152300 (106.022 iter/s, 0.943201s/100 iter), loss = 0.106592
I0502 11:35:07.309486 26473 solver.cpp:261]     Train net output #0: loss = 0.106592 (* 1 = 0.106592 loss)
I0502 11:35:07.309495 26473 sgd_solver.cpp:106] Iteration 152300, lr = 3.51844e-06
I0502 11:35:08.249614 26473 solver.cpp:242] Iteration 152400 (105.832 iter/s, 0.944892s/100 iter), loss = 0.255075
I0502 11:35:08.249657 26473 solver.cpp:261]     Train net output #0: loss = 0.255075 (* 1 = 0.255075 loss)
I0502 11:35:08.249665 26473 sgd_solver.cpp:106] Iteration 152400, lr = 3.51844e-06
I0502 11:35:08.254436 26473 solver.cpp:242] Iteration 152400 (105.828 iter/s, 0.944932s/100 iter), loss = 0.0252332
I0502 11:35:08.254461 26473 solver.cpp:261]     Train net output #0: loss = 0.0252332 (* 1 = 0.0252332 loss)
I0502 11:35:08.254468 26473 sgd_solver.cpp:106] Iteration 152400, lr = 3.51844e-06
I0502 11:35:09.191473 26473 solver.cpp:362] Iteration 152500, Testing net (#0)
I0502 11:35:09.191509 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:09.315989 26473 solver.cpp:429]     Test net output #0: loss = 0.252785 (* 1 = 0.252785 loss)
I0502 11:35:09.318869 26473 solver.cpp:242] Iteration 152500 (93.5283 iter/s, 1.0692s/100 iter), loss = 0.445507
I0502 11:35:09.318889 26473 solver.cpp:261]     Train net output #0: loss = 0.445507 (* 1 = 0.445507 loss)
I0502 11:35:09.318898 26473 sgd_solver.cpp:106] Iteration 152500, lr = 3.51844e-06
I0502 11:35:09.320519 26473 solver.cpp:362] Iteration 152500, Testing net (#0)
I0502 11:35:09.320531 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:09.451501 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:35:09.451519 26473 solver.cpp:429]     Test net output #1: loss = 0.078294 (* 1 = 0.078294 loss)
I0502 11:35:09.454430 26473 solver.cpp:242] Iteration 152500 (83.3368 iter/s, 1.19995s/100 iter), loss = 0.0439547
I0502 11:35:09.454450 26473 solver.cpp:261]     Train net output #0: loss = 0.0439547 (* 1 = 0.0439547 loss)
I0502 11:35:09.454459 26473 sgd_solver.cpp:106] Iteration 152500, lr = 3.51844e-06
I0502 11:35:10.395666 26473 solver.cpp:242] Iteration 152600 (92.8724 iter/s, 1.07675s/100 iter), loss = 0.0857583
I0502 11:35:10.395709 26473 solver.cpp:261]     Train net output #0: loss = 0.0857583 (* 1 = 0.0857583 loss)
I0502 11:35:10.395719 26473 sgd_solver.cpp:106] Iteration 152600, lr = 3.51844e-06
I0502 11:35:10.400468 26473 solver.cpp:242] Iteration 152600 (105.708 iter/s, 0.945999s/100 iter), loss = 0.0831601
I0502 11:35:10.400491 26473 solver.cpp:261]     Train net output #0: loss = 0.0831601 (* 1 = 0.0831601 loss)
I0502 11:35:10.400501 26473 sgd_solver.cpp:106] Iteration 152600, lr = 3.51844e-06
I0502 11:35:11.340693 26473 solver.cpp:242] Iteration 152700 (105.825 iter/s, 0.944958s/100 iter), loss = 0.0139227
I0502 11:35:11.340739 26473 solver.cpp:261]     Train net output #0: loss = 0.0139227 (* 1 = 0.0139227 loss)
I0502 11:35:11.340747 26473 sgd_solver.cpp:106] Iteration 152700, lr = 3.51844e-06
I0502 11:35:11.345587 26473 solver.cpp:242] Iteration 152700 (105.813 iter/s, 0.945067s/100 iter), loss = 0.0747852
I0502 11:35:11.345609 26473 solver.cpp:261]     Train net output #0: loss = 0.0747852 (* 1 = 0.0747852 loss)
I0502 11:35:11.345618 26473 sgd_solver.cpp:106] Iteration 152700, lr = 3.51844e-06
I0502 11:35:12.284556 26473 solver.cpp:242] Iteration 152800 (105.957 iter/s, 0.943782s/100 iter), loss = 0.0414963
I0502 11:35:12.284597 26473 solver.cpp:261]     Train net output #0: loss = 0.0414963 (* 1 = 0.0414963 loss)
I0502 11:35:12.284606 26473 sgd_solver.cpp:106] Iteration 152800, lr = 3.51844e-06
I0502 11:35:12.289391 26473 solver.cpp:242] Iteration 152800 (105.959 iter/s, 0.943763s/100 iter), loss = 0.0365577
I0502 11:35:12.289413 26473 solver.cpp:261]     Train net output #0: loss = 0.0365577 (* 1 = 0.0365577 loss)
I0502 11:35:12.289422 26473 sgd_solver.cpp:106] Iteration 152800, lr = 3.51844e-06
I0502 11:35:13.229266 26473 solver.cpp:242] Iteration 152900 (105.861 iter/s, 0.944637s/100 iter), loss = 0.2329
I0502 11:35:13.229307 26473 solver.cpp:261]     Train net output #0: loss = 0.2329 (* 1 = 0.2329 loss)
I0502 11:35:13.229316 26473 sgd_solver.cpp:106] Iteration 152900, lr = 3.51844e-06
I0502 11:35:13.234066 26473 solver.cpp:242] Iteration 152900 (105.861 iter/s, 0.944633s/100 iter), loss = 0.248523
I0502 11:35:13.234088 26473 solver.cpp:261]     Train net output #0: loss = 0.248523 (* 1 = 0.248523 loss)
I0502 11:35:13.234097 26473 sgd_solver.cpp:106] Iteration 152900, lr = 3.51844e-06
I0502 11:35:14.170167 26473 solver.cpp:362] Iteration 153000, Testing net (#0)
I0502 11:35:14.170194 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:14.294541 26473 solver.cpp:429]     Test net output #0: loss = 0.21575 (* 1 = 0.21575 loss)
I0502 11:35:14.297412 26473 solver.cpp:242] Iteration 153000 (93.6254 iter/s, 1.06809s/100 iter), loss = 0.111677
I0502 11:35:14.297432 26473 solver.cpp:261]     Train net output #0: loss = 0.111677 (* 1 = 0.111677 loss)
I0502 11:35:14.297451 26473 sgd_solver.cpp:106] Iteration 153000, lr = 3.51844e-06
I0502 11:35:14.299080 26473 solver.cpp:362] Iteration 153000, Testing net (#0)
I0502 11:35:14.299093 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:14.429967 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:35:14.429988 26473 solver.cpp:429]     Test net output #1: loss = 0.0773117 (* 1 = 0.0773117 loss)
I0502 11:35:14.432903 26473 solver.cpp:242] Iteration 153000 (83.4172 iter/s, 1.19879s/100 iter), loss = 0.0447527
I0502 11:35:14.432922 26473 solver.cpp:261]     Train net output #0: loss = 0.0447527 (* 1 = 0.0447527 loss)
I0502 11:35:14.432930 26473 sgd_solver.cpp:106] Iteration 153000, lr = 3.51844e-06
I0502 11:35:15.372251 26473 solver.cpp:242] Iteration 153100 (93.0415 iter/s, 1.07479s/100 iter), loss = 0.173542
I0502 11:35:15.372294 26473 solver.cpp:261]     Train net output #0: loss = 0.173542 (* 1 = 0.173542 loss)
I0502 11:35:15.372303 26473 sgd_solver.cpp:106] Iteration 153100, lr = 3.51844e-06
I0502 11:35:15.377063 26473 solver.cpp:242] Iteration 153100 (105.918 iter/s, 0.944123s/100 iter), loss = 0.179012
I0502 11:35:15.377086 26473 solver.cpp:261]     Train net output #0: loss = 0.179012 (* 1 = 0.179012 loss)
I0502 11:35:15.377094 26473 sgd_solver.cpp:106] Iteration 153100, lr = 3.51844e-06
I0502 11:35:16.315544 26473 solver.cpp:242] Iteration 153200 (106.019 iter/s, 0.943226s/100 iter), loss = 1.14819
I0502 11:35:16.315587 26473 solver.cpp:261]     Train net output #0: loss = 1.14819 (* 1 = 1.14819 loss)
I0502 11:35:16.315594 26473 sgd_solver.cpp:106] Iteration 153200, lr = 3.51844e-06
I0502 11:35:16.320425 26473 solver.cpp:242] Iteration 153200 (106.009 iter/s, 0.943312s/100 iter), loss = 0.152722
I0502 11:35:16.320449 26473 solver.cpp:261]     Train net output #0: loss = 0.152722 (* 1 = 0.152722 loss)
I0502 11:35:16.320457 26473 sgd_solver.cpp:106] Iteration 153200, lr = 3.51844e-06
I0502 11:35:17.258924 26473 solver.cpp:242] Iteration 153300 (106.009 iter/s, 0.943314s/100 iter), loss = 0.15805
I0502 11:35:17.258962 26473 solver.cpp:261]     Train net output #0: loss = 0.15805 (* 1 = 0.15805 loss)
I0502 11:35:17.258971 26473 sgd_solver.cpp:106] Iteration 153300, lr = 3.51844e-06
I0502 11:35:17.263797 26473 solver.cpp:242] Iteration 153300 (106.008 iter/s, 0.943324s/100 iter), loss = 0.0228918
I0502 11:35:17.263820 26473 solver.cpp:261]     Train net output #0: loss = 0.0228918 (* 1 = 0.0228918 loss)
I0502 11:35:17.263829 26473 sgd_solver.cpp:106] Iteration 153300, lr = 3.51844e-06
I0502 11:35:18.203095 26473 solver.cpp:242] Iteration 153400 (105.92 iter/s, 0.944105s/100 iter), loss = 1.03721
I0502 11:35:18.203135 26473 solver.cpp:261]     Train net output #0: loss = 1.03721 (* 1 = 1.03721 loss)
I0502 11:35:18.203145 26473 sgd_solver.cpp:106] Iteration 153400, lr = 3.51844e-06
I0502 11:35:18.207890 26473 solver.cpp:242] Iteration 153400 (105.927 iter/s, 0.94405s/100 iter), loss = 0.274994
I0502 11:35:18.207912 26473 solver.cpp:261]     Train net output #0: loss = 0.274994 (* 1 = 0.274994 loss)
I0502 11:35:18.207921 26473 sgd_solver.cpp:106] Iteration 153400, lr = 3.51844e-06
I0502 11:35:19.144160 26473 solver.cpp:362] Iteration 153500, Testing net (#0)
I0502 11:35:19.144184 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:19.268579 26473 solver.cpp:429]     Test net output #0: loss = 0.219813 (* 1 = 0.219813 loss)
I0502 11:35:19.271445 26473 solver.cpp:242] Iteration 153500 (93.6074 iter/s, 1.06829s/100 iter), loss = 0.0692844
I0502 11:35:19.271464 26473 solver.cpp:261]     Train net output #0: loss = 0.0692844 (* 1 = 0.0692844 loss)
I0502 11:35:19.271473 26473 sgd_solver.cpp:106] Iteration 153500, lr = 3.51844e-06
I0502 11:35:19.273099 26473 solver.cpp:362] Iteration 153500, Testing net (#0)
I0502 11:35:19.273113 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:19.404038 26473 solver.cpp:429]     Test net output #0: accuracy = 0.954
I0502 11:35:19.404060 26473 solver.cpp:429]     Test net output #1: loss = 0.0927306 (* 1 = 0.0927306 loss)
I0502 11:35:19.406994 26473 solver.cpp:242] Iteration 153500 (83.3986 iter/s, 1.19906s/100 iter), loss = 0.0264055
I0502 11:35:19.407016 26473 solver.cpp:261]     Train net output #0: loss = 0.0264055 (* 1 = 0.0264055 loss)
I0502 11:35:19.407023 26473 sgd_solver.cpp:106] Iteration 153500, lr = 3.51844e-06
I0502 11:35:20.345950 26473 solver.cpp:242] Iteration 153600 (93.0705 iter/s, 1.07445s/100 iter), loss = 0.0394328
I0502 11:35:20.345990 26473 solver.cpp:261]     Train net output #0: loss = 0.0394328 (* 1 = 0.0394328 loss)
I0502 11:35:20.345999 26473 sgd_solver.cpp:106] Iteration 153600, lr = 3.51844e-06
I0502 11:35:20.350764 26473 solver.cpp:242] Iteration 153600 (105.963 iter/s, 0.94373s/100 iter), loss = 0.0114523
I0502 11:35:20.350786 26473 solver.cpp:261]     Train net output #0: loss = 0.0114523 (* 1 = 0.0114523 loss)
I0502 11:35:20.350795 26473 sgd_solver.cpp:106] Iteration 153600, lr = 3.51844e-06
I0502 11:35:21.289470 26473 solver.cpp:242] Iteration 153700 (105.993 iter/s, 0.943454s/100 iter), loss = 0.223906
I0502 11:35:21.289510 26473 solver.cpp:261]     Train net output #0: loss = 0.223906 (* 1 = 0.223906 loss)
I0502 11:35:21.289517 26473 sgd_solver.cpp:106] Iteration 153700, lr = 3.51844e-06
I0502 11:35:21.294286 26473 solver.cpp:242] Iteration 153700 (105.99 iter/s, 0.943482s/100 iter), loss = 0.0426425
I0502 11:35:21.294308 26473 solver.cpp:261]     Train net output #0: loss = 0.0426425 (* 1 = 0.0426425 loss)
I0502 11:35:21.294317 26473 sgd_solver.cpp:106] Iteration 153700, lr = 3.51844e-06
I0502 11:35:22.233018 26473 solver.cpp:242] Iteration 153800 (105.99 iter/s, 0.943486s/100 iter), loss = 0.40247
I0502 11:35:22.233050 26473 solver.cpp:261]     Train net output #0: loss = 0.40247 (* 1 = 0.40247 loss)
I0502 11:35:22.233059 26473 sgd_solver.cpp:106] Iteration 153800, lr = 3.51844e-06
I0502 11:35:22.237872 26473 solver.cpp:242] Iteration 153800 (105.984 iter/s, 0.943539s/100 iter), loss = 0.201965
I0502 11:35:22.237896 26473 solver.cpp:261]     Train net output #0: loss = 0.201965 (* 1 = 0.201965 loss)
I0502 11:35:22.237905 26473 sgd_solver.cpp:106] Iteration 153800, lr = 3.51844e-06
I0502 11:35:23.179971 26473 solver.cpp:242] Iteration 153900 (105.609 iter/s, 0.946891s/100 iter), loss = 0.127604
I0502 11:35:23.180002 26473 solver.cpp:261]     Train net output #0: loss = 0.127604 (* 1 = 0.127604 loss)
I0502 11:35:23.180011 26473 sgd_solver.cpp:106] Iteration 153900, lr = 3.51844e-06
I0502 11:35:23.184821 26473 solver.cpp:242] Iteration 153900 (105.607 iter/s, 0.946907s/100 iter), loss = 0.0376196
I0502 11:35:23.184845 26473 solver.cpp:261]     Train net output #0: loss = 0.0376196 (* 1 = 0.0376196 loss)
I0502 11:35:23.184854 26473 sgd_solver.cpp:106] Iteration 153900, lr = 3.51844e-06
I0502 11:35:24.120497 26473 solver.cpp:362] Iteration 154000, Testing net (#0)
I0502 11:35:24.120527 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:24.244849 26473 solver.cpp:429]     Test net output #0: loss = 0.209396 (* 1 = 0.209396 loss)
I0502 11:35:24.247720 26473 solver.cpp:242] Iteration 154000 (93.6593 iter/s, 1.0677s/100 iter), loss = 0.12975
I0502 11:35:24.247740 26473 solver.cpp:261]     Train net output #0: loss = 0.12975 (* 1 = 0.12975 loss)
I0502 11:35:24.247747 26473 sgd_solver.cpp:106] Iteration 154000, lr = 3.51844e-06
I0502 11:35:24.249377 26473 solver.cpp:362] Iteration 154000, Testing net (#0)
I0502 11:35:24.249389 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:24.379994 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:35:24.380015 26473 solver.cpp:429]     Test net output #1: loss = 0.0837879 (* 1 = 0.0837879 loss)
I0502 11:35:24.382943 26473 solver.cpp:242] Iteration 154000 (83.467 iter/s, 1.19808s/100 iter), loss = 0.0715894
I0502 11:35:24.382963 26473 solver.cpp:261]     Train net output #0: loss = 0.0715894 (* 1 = 0.0715894 loss)
I0502 11:35:24.382972 26473 sgd_solver.cpp:106] Iteration 154000, lr = 3.51844e-06
I0502 11:35:25.322007 26473 solver.cpp:242] Iteration 154100 (93.0893 iter/s, 1.07424s/100 iter), loss = 0.0772508
I0502 11:35:25.322057 26473 solver.cpp:261]     Train net output #0: loss = 0.0772508 (* 1 = 0.0772508 loss)
I0502 11:35:25.322067 26473 sgd_solver.cpp:106] Iteration 154100, lr = 3.51844e-06
I0502 11:35:25.326817 26473 solver.cpp:242] Iteration 154100 (105.951 iter/s, 0.943835s/100 iter), loss = 0.158032
I0502 11:35:25.326840 26473 solver.cpp:261]     Train net output #0: loss = 0.158032 (* 1 = 0.158032 loss)
I0502 11:35:25.326849 26473 sgd_solver.cpp:106] Iteration 154100, lr = 3.51844e-06
I0502 11:35:26.266122 26473 solver.cpp:242] Iteration 154200 (105.928 iter/s, 0.944042s/100 iter), loss = 0.335078
I0502 11:35:26.266156 26473 solver.cpp:261]     Train net output #0: loss = 0.335078 (* 1 = 0.335078 loss)
I0502 11:35:26.266165 26473 sgd_solver.cpp:106] Iteration 154200, lr = 3.51844e-06
I0502 11:35:26.270956 26473 solver.cpp:242] Iteration 154200 (105.921 iter/s, 0.944096s/100 iter), loss = 0.149094
I0502 11:35:26.270978 26473 solver.cpp:261]     Train net output #0: loss = 0.149094 (* 1 = 0.149094 loss)
I0502 11:35:26.270987 26473 sgd_solver.cpp:106] Iteration 154200, lr = 3.51844e-06
I0502 11:35:27.210216 26473 solver.cpp:242] Iteration 154300 (105.928 iter/s, 0.944037s/100 iter), loss = 0.0687616
I0502 11:35:27.210252 26473 solver.cpp:261]     Train net output #0: loss = 0.0687616 (* 1 = 0.0687616 loss)
I0502 11:35:27.210260 26473 sgd_solver.cpp:106] Iteration 154300, lr = 3.51844e-06
I0502 11:35:27.215093 26473 solver.cpp:242] Iteration 154300 (105.922 iter/s, 0.944089s/100 iter), loss = 0.133805
I0502 11:35:27.215116 26473 solver.cpp:261]     Train net output #0: loss = 0.133805 (* 1 = 0.133805 loss)
I0502 11:35:27.215126 26473 sgd_solver.cpp:106] Iteration 154300, lr = 3.51844e-06
I0502 11:35:28.153869 26473 solver.cpp:242] Iteration 154400 (105.979 iter/s, 0.943586s/100 iter), loss = 0.219386
I0502 11:35:28.153913 26473 solver.cpp:261]     Train net output #0: loss = 0.219386 (* 1 = 0.219386 loss)
I0502 11:35:28.153921 26473 sgd_solver.cpp:106] Iteration 154400, lr = 3.51844e-06
I0502 11:35:28.158699 26473 solver.cpp:242] Iteration 154400 (105.981 iter/s, 0.943564s/100 iter), loss = 0.0087313
I0502 11:35:28.158721 26473 solver.cpp:261]     Train net output #0: loss = 0.0087313 (* 1 = 0.0087313 loss)
I0502 11:35:28.158730 26473 sgd_solver.cpp:106] Iteration 154400, lr = 3.51844e-06
I0502 11:35:29.094759 26473 solver.cpp:362] Iteration 154500, Testing net (#0)
I0502 11:35:29.094785 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:29.219116 26473 solver.cpp:429]     Test net output #0: loss = 0.233981 (* 1 = 0.233981 loss)
I0502 11:35:29.221992 26473 solver.cpp:242] Iteration 154500 (93.6276 iter/s, 1.06806s/100 iter), loss = 0.124244
I0502 11:35:29.222013 26473 solver.cpp:261]     Train net output #0: loss = 0.124244 (* 1 = 0.124244 loss)
I0502 11:35:29.222023 26473 sgd_solver.cpp:106] Iteration 154500, lr = 3.51844e-06
I0502 11:35:29.223637 26473 solver.cpp:362] Iteration 154500, Testing net (#0)
I0502 11:35:29.223650 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:29.354435 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:35:29.354459 26473 solver.cpp:429]     Test net output #1: loss = 0.0805033 (* 1 = 0.0805033 loss)
I0502 11:35:29.357383 26473 solver.cpp:242] Iteration 154500 (83.4278 iter/s, 1.19864s/100 iter), loss = 0.114116
I0502 11:35:29.357403 26473 solver.cpp:261]     Train net output #0: loss = 0.114116 (* 1 = 0.114116 loss)
I0502 11:35:29.357411 26473 sgd_solver.cpp:106] Iteration 154500, lr = 3.51844e-06
I0502 11:35:30.296890 26473 solver.cpp:242] Iteration 154600 (93.0366 iter/s, 1.07485s/100 iter), loss = 0.0405156
I0502 11:35:30.296932 26473 solver.cpp:261]     Train net output #0: loss = 0.0405156 (* 1 = 0.0405156 loss)
I0502 11:35:30.296941 26473 sgd_solver.cpp:106] Iteration 154600, lr = 3.51844e-06
I0502 11:35:30.301707 26473 solver.cpp:242] Iteration 154600 (105.9 iter/s, 0.944287s/100 iter), loss = 0.321057
I0502 11:35:30.301730 26473 solver.cpp:261]     Train net output #0: loss = 0.321057 (* 1 = 0.321057 loss)
I0502 11:35:30.301739 26473 sgd_solver.cpp:106] Iteration 154600, lr = 3.51844e-06
I0502 11:35:31.240525 26473 solver.cpp:242] Iteration 154700 (105.981 iter/s, 0.943568s/100 iter), loss = 0.0400325
I0502 11:35:31.240587 26473 solver.cpp:261]     Train net output #0: loss = 0.0400325 (* 1 = 0.0400325 loss)
I0502 11:35:31.240604 26473 sgd_solver.cpp:106] Iteration 154700, lr = 3.51844e-06
I0502 11:35:31.245414 26473 solver.cpp:242] Iteration 154700 (105.97 iter/s, 0.943666s/100 iter), loss = 0.0402418
I0502 11:35:31.245437 26473 solver.cpp:261]     Train net output #0: loss = 0.0402418 (* 1 = 0.0402418 loss)
I0502 11:35:31.245446 26473 sgd_solver.cpp:106] Iteration 154700, lr = 3.51844e-06
I0502 11:35:32.184803 26473 solver.cpp:242] Iteration 154800 (105.911 iter/s, 0.944191s/100 iter), loss = 0.385092
I0502 11:35:32.184844 26473 solver.cpp:261]     Train net output #0: loss = 0.385092 (* 1 = 0.385092 loss)
I0502 11:35:32.184854 26473 sgd_solver.cpp:106] Iteration 154800, lr = 3.51844e-06
I0502 11:35:32.189682 26473 solver.cpp:242] Iteration 154800 (105.908 iter/s, 0.944217s/100 iter), loss = 0.121182
I0502 11:35:32.189704 26473 solver.cpp:261]     Train net output #0: loss = 0.121182 (* 1 = 0.121182 loss)
I0502 11:35:32.189713 26473 sgd_solver.cpp:106] Iteration 154800, lr = 3.51844e-06
I0502 11:35:33.128643 26473 solver.cpp:242] Iteration 154900 (105.958 iter/s, 0.943768s/100 iter), loss = 0.404886
I0502 11:35:33.128684 26473 solver.cpp:261]     Train net output #0: loss = 0.404886 (* 1 = 0.404886 loss)
I0502 11:35:33.128691 26473 sgd_solver.cpp:106] Iteration 154900, lr = 3.51844e-06
I0502 11:35:33.133451 26473 solver.cpp:242] Iteration 154900 (105.963 iter/s, 0.943729s/100 iter), loss = 0.0439811
I0502 11:35:33.133474 26473 solver.cpp:261]     Train net output #0: loss = 0.0439811 (* 1 = 0.0439811 loss)
I0502 11:35:33.133483 26473 sgd_solver.cpp:106] Iteration 154900, lr = 3.51844e-06
I0502 11:35:34.070242 26473 solver.cpp:362] Iteration 155000, Testing net (#0)
I0502 11:35:34.070269 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:34.194618 26473 solver.cpp:429]     Test net output #0: loss = 0.206392 (* 1 = 0.206392 loss)
I0502 11:35:34.197506 26473 solver.cpp:242] Iteration 155000 (93.5625 iter/s, 1.0688s/100 iter), loss = 0.148647
I0502 11:35:34.197526 26473 solver.cpp:261]     Train net output #0: loss = 0.148647 (* 1 = 0.148647 loss)
I0502 11:35:34.197535 26473 sgd_solver.cpp:106] Iteration 155000, lr = 3.51844e-06
I0502 11:35:34.199219 26473 solver.cpp:362] Iteration 155000, Testing net (#0)
I0502 11:35:34.199232 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:34.330315 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:35:34.330341 26473 solver.cpp:429]     Test net output #1: loss = 0.0771001 (* 1 = 0.0771001 loss)
I0502 11:35:34.333266 26473 solver.cpp:242] Iteration 155000 (83.3493 iter/s, 1.19977s/100 iter), loss = 0.099583
I0502 11:35:34.333286 26473 solver.cpp:261]     Train net output #0: loss = 0.099583 (* 1 = 0.099583 loss)
I0502 11:35:34.333294 26473 sgd_solver.cpp:106] Iteration 155000, lr = 3.51844e-06
I0502 11:35:35.271941 26473 solver.cpp:242] Iteration 155100 (93.0766 iter/s, 1.07438s/100 iter), loss = 0.152242
I0502 11:35:35.271981 26473 solver.cpp:261]     Train net output #0: loss = 0.152242 (* 1 = 0.152242 loss)
I0502 11:35:35.271991 26473 sgd_solver.cpp:106] Iteration 155100, lr = 3.51844e-06
I0502 11:35:35.276760 26473 solver.cpp:242] Iteration 155100 (105.993 iter/s, 0.943456s/100 iter), loss = 0.0449484
I0502 11:35:35.276783 26473 solver.cpp:261]     Train net output #0: loss = 0.0449484 (* 1 = 0.0449484 loss)
I0502 11:35:35.276792 26473 sgd_solver.cpp:106] Iteration 155100, lr = 3.51844e-06
I0502 11:35:36.215327 26473 solver.cpp:242] Iteration 155200 (106.009 iter/s, 0.943318s/100 iter), loss = 0.125278
I0502 11:35:36.215366 26473 solver.cpp:261]     Train net output #0: loss = 0.125278 (* 1 = 0.125278 loss)
I0502 11:35:36.215375 26473 sgd_solver.cpp:106] Iteration 155200, lr = 3.51844e-06
I0502 11:35:36.220134 26473 solver.cpp:242] Iteration 155200 (106.007 iter/s, 0.943333s/100 iter), loss = 0.111149
I0502 11:35:36.220165 26473 solver.cpp:261]     Train net output #0: loss = 0.111149 (* 1 = 0.111149 loss)
I0502 11:35:36.220175 26473 sgd_solver.cpp:106] Iteration 155200, lr = 3.51844e-06
I0502 11:35:37.159654 26473 solver.cpp:242] Iteration 155300 (105.903 iter/s, 0.944263s/100 iter), loss = 0.125384
I0502 11:35:37.159698 26473 solver.cpp:261]     Train net output #0: loss = 0.125384 (* 1 = 0.125384 loss)
I0502 11:35:37.159708 26473 sgd_solver.cpp:106] Iteration 155300, lr = 3.51844e-06
I0502 11:35:37.164525 26473 solver.cpp:242] Iteration 155300 (105.895 iter/s, 0.944335s/100 iter), loss = 0.0784058
I0502 11:35:37.164549 26473 solver.cpp:261]     Train net output #0: loss = 0.0784058 (* 1 = 0.0784058 loss)
I0502 11:35:37.164564 26473 sgd_solver.cpp:106] Iteration 155300, lr = 3.51844e-06
I0502 11:35:38.104120 26473 solver.cpp:242] Iteration 155400 (105.888 iter/s, 0.944391s/100 iter), loss = 0.105767
I0502 11:35:38.104154 26473 solver.cpp:261]     Train net output #0: loss = 0.105767 (* 1 = 0.105767 loss)
I0502 11:35:38.104163 26473 sgd_solver.cpp:106] Iteration 155400, lr = 3.51844e-06
I0502 11:35:38.108942 26473 solver.cpp:242] Iteration 155400 (105.89 iter/s, 0.944374s/100 iter), loss = 0.0419971
I0502 11:35:38.108964 26473 solver.cpp:261]     Train net output #0: loss = 0.0419971 (* 1 = 0.0419971 loss)
I0502 11:35:38.108973 26473 sgd_solver.cpp:106] Iteration 155400, lr = 3.51844e-06
I0502 11:35:39.046108 26473 solver.cpp:362] Iteration 155500, Testing net (#0)
I0502 11:35:39.046129 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:39.170480 26473 solver.cpp:429]     Test net output #0: loss = 0.242183 (* 1 = 0.242183 loss)
I0502 11:35:39.173378 26473 solver.cpp:242] Iteration 155500 (93.5274 iter/s, 1.06921s/100 iter), loss = 0.31684
I0502 11:35:39.173399 26473 solver.cpp:261]     Train net output #0: loss = 0.31684 (* 1 = 0.31684 loss)
I0502 11:35:39.173408 26473 sgd_solver.cpp:106] Iteration 155500, lr = 3.51844e-06
I0502 11:35:39.175029 26473 solver.cpp:362] Iteration 155500, Testing net (#0)
I0502 11:35:39.175042 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:39.305621 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:35:39.305644 26473 solver.cpp:429]     Test net output #1: loss = 0.0796891 (* 1 = 0.0796891 loss)
I0502 11:35:39.308565 26473 solver.cpp:242] Iteration 155500 (83.3625 iter/s, 1.19958s/100 iter), loss = 0.00899944
I0502 11:35:39.308584 26473 solver.cpp:261]     Train net output #0: loss = 0.00899944 (* 1 = 0.00899944 loss)
I0502 11:35:39.308593 26473 sgd_solver.cpp:106] Iteration 155500, lr = 3.51844e-06
I0502 11:35:40.247910 26473 solver.cpp:242] Iteration 155600 (93.0682 iter/s, 1.07448s/100 iter), loss = 0.297622
I0502 11:35:40.247947 26473 solver.cpp:261]     Train net output #0: loss = 0.297622 (* 1 = 0.297622 loss)
I0502 11:35:40.247956 26473 sgd_solver.cpp:106] Iteration 155600, lr = 3.51844e-06
I0502 11:35:40.252717 26473 solver.cpp:242] Iteration 155600 (105.919 iter/s, 0.944114s/100 iter), loss = 0.0291065
I0502 11:35:40.252740 26473 solver.cpp:261]     Train net output #0: loss = 0.0291065 (* 1 = 0.0291065 loss)
I0502 11:35:40.252748 26473 sgd_solver.cpp:106] Iteration 155600, lr = 3.51844e-06
I0502 11:35:41.192302 26473 solver.cpp:242] Iteration 155700 (105.895 iter/s, 0.944328s/100 iter), loss = 0.0315336
I0502 11:35:41.192340 26473 solver.cpp:261]     Train net output #0: loss = 0.0315336 (* 1 = 0.0315336 loss)
I0502 11:35:41.192349 26473 sgd_solver.cpp:106] Iteration 155700, lr = 3.51844e-06
I0502 11:35:41.197108 26473 solver.cpp:242] Iteration 155700 (105.893 iter/s, 0.94435s/100 iter), loss = 0.0303974
I0502 11:35:41.197131 26473 solver.cpp:261]     Train net output #0: loss = 0.0303974 (* 1 = 0.0303974 loss)
I0502 11:35:41.197139 26473 sgd_solver.cpp:106] Iteration 155700, lr = 3.51844e-06
I0502 11:35:42.135395 26473 solver.cpp:242] Iteration 155800 (106.041 iter/s, 0.943028s/100 iter), loss = 0.0501491
I0502 11:35:42.135432 26473 solver.cpp:261]     Train net output #0: loss = 0.0501491 (* 1 = 0.0501491 loss)
I0502 11:35:42.135449 26473 sgd_solver.cpp:106] Iteration 155800, lr = 3.51844e-06
I0502 11:35:42.140281 26473 solver.cpp:242] Iteration 155800 (106.031 iter/s, 0.943122s/100 iter), loss = 0.0119146
I0502 11:35:42.140305 26473 solver.cpp:261]     Train net output #0: loss = 0.0119146 (* 1 = 0.0119146 loss)
I0502 11:35:42.140313 26473 sgd_solver.cpp:106] Iteration 155800, lr = 3.51844e-06
I0502 11:35:43.079695 26473 solver.cpp:242] Iteration 155900 (105.905 iter/s, 0.94424s/100 iter), loss = 0.291422
I0502 11:35:43.079727 26473 solver.cpp:261]     Train net output #0: loss = 0.291422 (* 1 = 0.291422 loss)
I0502 11:35:43.079736 26473 sgd_solver.cpp:106] Iteration 155900, lr = 3.51844e-06
I0502 11:35:43.084555 26473 solver.cpp:242] Iteration 155900 (105.907 iter/s, 0.944223s/100 iter), loss = 0.01897
I0502 11:35:43.084578 26473 solver.cpp:261]     Train net output #0: loss = 0.01897 (* 1 = 0.01897 loss)
I0502 11:35:43.084586 26473 sgd_solver.cpp:106] Iteration 155900, lr = 3.51844e-06
I0502 11:35:44.020050 26473 solver.cpp:362] Iteration 156000, Testing net (#0)
I0502 11:35:44.020078 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:44.144439 26473 solver.cpp:429]     Test net output #0: loss = 0.252499 (* 1 = 0.252499 loss)
I0502 11:35:44.147311 26473 solver.cpp:242] Iteration 156000 (93.6711 iter/s, 1.06757s/100 iter), loss = 0.342774
I0502 11:35:44.147331 26473 solver.cpp:261]     Train net output #0: loss = 0.342774 (* 1 = 0.342774 loss)
I0502 11:35:44.147339 26473 sgd_solver.cpp:106] Iteration 156000, lr = 3.51844e-06
I0502 11:35:44.148968 26473 solver.cpp:362] Iteration 156000, Testing net (#0)
I0502 11:35:44.148982 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:44.279603 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:35:44.279624 26473 solver.cpp:429]     Test net output #1: loss = 0.083811 (* 1 = 0.083811 loss)
I0502 11:35:44.282570 26473 solver.cpp:242] Iteration 156000 (83.4744 iter/s, 1.19797s/100 iter), loss = 0.086794
I0502 11:35:44.282590 26473 solver.cpp:261]     Train net output #0: loss = 0.086794 (* 1 = 0.086794 loss)
I0502 11:35:44.282598 26473 sgd_solver.cpp:106] Iteration 156000, lr = 3.51844e-06
I0502 11:35:45.221983 26473 solver.cpp:242] Iteration 156100 (93.056 iter/s, 1.07462s/100 iter), loss = 0.321151
I0502 11:35:45.222018 26473 solver.cpp:261]     Train net output #0: loss = 0.321151 (* 1 = 0.321151 loss)
I0502 11:35:45.222028 26473 sgd_solver.cpp:106] Iteration 156100, lr = 3.51844e-06
I0502 11:35:45.226780 26473 solver.cpp:242] Iteration 156100 (105.913 iter/s, 0.944172s/100 iter), loss = 0.10015
I0502 11:35:45.226804 26473 solver.cpp:261]     Train net output #0: loss = 0.10015 (* 1 = 0.10015 loss)
I0502 11:35:45.226812 26473 sgd_solver.cpp:106] Iteration 156100, lr = 3.51844e-06
I0502 11:35:46.166321 26473 solver.cpp:242] Iteration 156200 (105.901 iter/s, 0.944276s/100 iter), loss = 0.3552
I0502 11:35:46.166353 26473 solver.cpp:261]     Train net output #0: loss = 0.3552 (* 1 = 0.3552 loss)
I0502 11:35:46.166363 26473 sgd_solver.cpp:106] Iteration 156200, lr = 3.51844e-06
I0502 11:35:46.171133 26473 solver.cpp:242] Iteration 156200 (105.897 iter/s, 0.944311s/100 iter), loss = 0.0595412
I0502 11:35:46.171156 26473 solver.cpp:261]     Train net output #0: loss = 0.0595412 (* 1 = 0.0595412 loss)
I0502 11:35:46.171165 26473 sgd_solver.cpp:106] Iteration 156200, lr = 3.51844e-06
I0502 11:35:47.110882 26473 solver.cpp:242] Iteration 156300 (105.876 iter/s, 0.944504s/100 iter), loss = 0.154697
I0502 11:35:47.110914 26473 solver.cpp:261]     Train net output #0: loss = 0.154697 (* 1 = 0.154697 loss)
I0502 11:35:47.110922 26473 sgd_solver.cpp:106] Iteration 156300, lr = 3.51844e-06
I0502 11:35:47.115686 26473 solver.cpp:242] Iteration 156300 (105.875 iter/s, 0.944512s/100 iter), loss = 0.0716157
I0502 11:35:47.115710 26473 solver.cpp:261]     Train net output #0: loss = 0.0716157 (* 1 = 0.0716157 loss)
I0502 11:35:47.115718 26473 sgd_solver.cpp:106] Iteration 156300, lr = 3.51844e-06
I0502 11:35:48.054563 26473 solver.cpp:242] Iteration 156400 (105.974 iter/s, 0.943626s/100 iter), loss = 0.185947
I0502 11:35:48.054603 26473 solver.cpp:261]     Train net output #0: loss = 0.185947 (* 1 = 0.185947 loss)
I0502 11:35:48.054613 26473 sgd_solver.cpp:106] Iteration 156400, lr = 3.51844e-06
I0502 11:35:48.059435 26473 solver.cpp:242] Iteration 156400 (105.966 iter/s, 0.943701s/100 iter), loss = 0.100605
I0502 11:35:48.059458 26473 solver.cpp:261]     Train net output #0: loss = 0.100605 (* 1 = 0.100605 loss)
I0502 11:35:48.059466 26473 sgd_solver.cpp:106] Iteration 156400, lr = 3.51844e-06
I0502 11:35:48.994639 26473 solver.cpp:362] Iteration 156500, Testing net (#0)
I0502 11:35:48.994668 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:49.118981 26473 solver.cpp:429]     Test net output #0: loss = 0.213409 (* 1 = 0.213409 loss)
I0502 11:35:49.121855 26473 solver.cpp:242] Iteration 156500 (93.7001 iter/s, 1.06723s/100 iter), loss = 0.264099
I0502 11:35:49.121876 26473 solver.cpp:261]     Train net output #0: loss = 0.264099 (* 1 = 0.264099 loss)
I0502 11:35:49.121884 26473 sgd_solver.cpp:106] Iteration 156500, lr = 3.51844e-06
I0502 11:35:49.123525 26473 solver.cpp:362] Iteration 156500, Testing net (#0)
I0502 11:35:49.123538 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:49.254120 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9655
I0502 11:35:49.254140 26473 solver.cpp:429]     Test net output #1: loss = 0.0855815 (* 1 = 0.0855815 loss)
I0502 11:35:49.257077 26473 solver.cpp:242] Iteration 156500 (83.5004 iter/s, 1.1976s/100 iter), loss = 0.102529
I0502 11:35:49.257097 26473 solver.cpp:261]     Train net output #0: loss = 0.102529 (* 1 = 0.102529 loss)
I0502 11:35:49.257105 26473 sgd_solver.cpp:106] Iteration 156500, lr = 3.51844e-06
I0502 11:35:50.196514 26473 solver.cpp:242] Iteration 156600 (93.0574 iter/s, 1.07461s/100 iter), loss = 0.0850745
I0502 11:35:50.196564 26473 solver.cpp:261]     Train net output #0: loss = 0.0850745 (* 1 = 0.0850745 loss)
I0502 11:35:50.196575 26473 sgd_solver.cpp:106] Iteration 156600, lr = 3.51844e-06
I0502 11:35:50.201326 26473 solver.cpp:242] Iteration 156600 (105.909 iter/s, 0.944211s/100 iter), loss = 0.034622
I0502 11:35:50.201350 26473 solver.cpp:261]     Train net output #0: loss = 0.034622 (* 1 = 0.034622 loss)
I0502 11:35:50.201359 26473 sgd_solver.cpp:106] Iteration 156600, lr = 3.51844e-06
I0502 11:35:51.140404 26473 solver.cpp:242] Iteration 156700 (105.953 iter/s, 0.943815s/100 iter), loss = 0.17538
I0502 11:35:51.140447 26473 solver.cpp:261]     Train net output #0: loss = 0.17538 (* 1 = 0.17538 loss)
I0502 11:35:51.140455 26473 sgd_solver.cpp:106] Iteration 156700, lr = 3.51844e-06
I0502 11:35:51.145220 26473 solver.cpp:242] Iteration 156700 (105.949 iter/s, 0.943852s/100 iter), loss = 0.109057
I0502 11:35:51.145242 26473 solver.cpp:261]     Train net output #0: loss = 0.109057 (* 1 = 0.109057 loss)
I0502 11:35:51.145251 26473 sgd_solver.cpp:106] Iteration 156700, lr = 3.51844e-06
I0502 11:35:52.085855 26473 solver.cpp:242] Iteration 156800 (105.777 iter/s, 0.945382s/100 iter), loss = 0.0793564
I0502 11:35:52.085912 26473 solver.cpp:261]     Train net output #0: loss = 0.0793564 (* 1 = 0.0793564 loss)
I0502 11:35:52.085927 26473 sgd_solver.cpp:106] Iteration 156800, lr = 3.51844e-06
I0502 11:35:52.090751 26473 solver.cpp:242] Iteration 156800 (105.765 iter/s, 0.94549s/100 iter), loss = 0.0638654
I0502 11:35:52.090775 26473 solver.cpp:261]     Train net output #0: loss = 0.0638654 (* 1 = 0.0638654 loss)
I0502 11:35:52.090785 26473 sgd_solver.cpp:106] Iteration 156800, lr = 3.51844e-06
I0502 11:35:53.030766 26473 solver.cpp:242] Iteration 156900 (105.839 iter/s, 0.94483s/100 iter), loss = 0.0794412
I0502 11:35:53.030807 26473 solver.cpp:261]     Train net output #0: loss = 0.0794412 (* 1 = 0.0794412 loss)
I0502 11:35:53.030817 26473 sgd_solver.cpp:106] Iteration 156900, lr = 3.51844e-06
I0502 11:35:53.035643 26473 solver.cpp:242] Iteration 156900 (105.838 iter/s, 0.944842s/100 iter), loss = 0.00539523
I0502 11:35:53.035667 26473 solver.cpp:261]     Train net output #0: loss = 0.00539523 (* 1 = 0.00539523 loss)
I0502 11:35:53.035682 26473 sgd_solver.cpp:106] Iteration 156900, lr = 3.51844e-06
I0502 11:35:53.971848 26473 solver.cpp:362] Iteration 157000, Testing net (#0)
I0502 11:35:53.971876 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:54.096140 26473 solver.cpp:429]     Test net output #0: loss = 0.232673 (* 1 = 0.232673 loss)
I0502 11:35:54.099014 26473 solver.cpp:242] Iteration 157000 (93.6165 iter/s, 1.06819s/100 iter), loss = 0.0946256
I0502 11:35:54.099033 26473 solver.cpp:261]     Train net output #0: loss = 0.0946256 (* 1 = 0.0946256 loss)
I0502 11:35:54.099042 26473 sgd_solver.cpp:106] Iteration 157000, lr = 3.51844e-06
I0502 11:35:54.100682 26473 solver.cpp:362] Iteration 157000, Testing net (#0)
I0502 11:35:54.100695 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:54.231439 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9505
I0502 11:35:54.231461 26473 solver.cpp:429]     Test net output #1: loss = 0.107013 (* 1 = 0.107013 loss)
I0502 11:35:54.234382 26473 solver.cpp:242] Iteration 157000 (83.4241 iter/s, 1.19869s/100 iter), loss = 0.0580368
I0502 11:35:54.234402 26473 solver.cpp:261]     Train net output #0: loss = 0.0580368 (* 1 = 0.0580368 loss)
I0502 11:35:54.234411 26473 sgd_solver.cpp:106] Iteration 157000, lr = 3.51844e-06
I0502 11:35:55.173043 26473 solver.cpp:242] Iteration 157100 (93.1118 iter/s, 1.07398s/100 iter), loss = 0.212918
I0502 11:35:55.173084 26473 solver.cpp:261]     Train net output #0: loss = 0.212918 (* 1 = 0.212918 loss)
I0502 11:35:55.173094 26473 sgd_solver.cpp:106] Iteration 157100, lr = 3.51844e-06
I0502 11:35:55.177824 26473 solver.cpp:242] Iteration 157100 (105.999 iter/s, 0.943404s/100 iter), loss = 0.130757
I0502 11:35:55.177847 26473 solver.cpp:261]     Train net output #0: loss = 0.130757 (* 1 = 0.130757 loss)
I0502 11:35:55.177855 26473 sgd_solver.cpp:106] Iteration 157100, lr = 3.51844e-06
I0502 11:35:56.117374 26473 solver.cpp:242] Iteration 157200 (105.903 iter/s, 0.944258s/100 iter), loss = 0.110063
I0502 11:35:56.117413 26473 solver.cpp:261]     Train net output #0: loss = 0.110063 (* 1 = 0.110063 loss)
I0502 11:35:56.117422 26473 sgd_solver.cpp:106] Iteration 157200, lr = 3.51844e-06
I0502 11:35:56.122272 26473 solver.cpp:242] Iteration 157200 (105.887 iter/s, 0.944407s/100 iter), loss = 0.236304
I0502 11:35:56.122295 26473 solver.cpp:261]     Train net output #0: loss = 0.236304 (* 1 = 0.236304 loss)
I0502 11:35:56.122303 26473 sgd_solver.cpp:106] Iteration 157200, lr = 3.51844e-06
I0502 11:35:57.061978 26473 solver.cpp:242] Iteration 157300 (105.872 iter/s, 0.944541s/100 iter), loss = 0.0977423
I0502 11:35:57.062019 26473 solver.cpp:261]     Train net output #0: loss = 0.0977423 (* 1 = 0.0977423 loss)
I0502 11:35:57.062028 26473 sgd_solver.cpp:106] Iteration 157300, lr = 3.51844e-06
I0502 11:35:57.066773 26473 solver.cpp:242] Iteration 157300 (105.881 iter/s, 0.94446s/100 iter), loss = 0.1101
I0502 11:35:57.066795 26473 solver.cpp:261]     Train net output #0: loss = 0.1101 (* 1 = 0.1101 loss)
I0502 11:35:57.066804 26473 sgd_solver.cpp:106] Iteration 157300, lr = 3.51844e-06
I0502 11:35:58.006072 26473 solver.cpp:242] Iteration 157400 (105.929 iter/s, 0.94403s/100 iter), loss = 0.0635337
I0502 11:35:58.006114 26473 solver.cpp:261]     Train net output #0: loss = 0.0635337 (* 1 = 0.0635337 loss)
I0502 11:35:58.006122 26473 sgd_solver.cpp:106] Iteration 157400, lr = 3.51844e-06
I0502 11:35:58.010947 26473 solver.cpp:242] Iteration 157400 (105.918 iter/s, 0.944126s/100 iter), loss = 0.0401778
I0502 11:35:58.010970 26473 solver.cpp:261]     Train net output #0: loss = 0.0401778 (* 1 = 0.0401778 loss)
I0502 11:35:58.010978 26473 sgd_solver.cpp:106] Iteration 157400, lr = 3.51844e-06
I0502 11:35:58.947571 26473 solver.cpp:362] Iteration 157500, Testing net (#0)
I0502 11:35:58.947594 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:59.071880 26473 solver.cpp:429]     Test net output #0: loss = 0.214393 (* 1 = 0.214393 loss)
I0502 11:35:59.074741 26473 solver.cpp:242] Iteration 157500 (93.5796 iter/s, 1.06861s/100 iter), loss = 0.0855877
I0502 11:35:59.074770 26473 solver.cpp:261]     Train net output #0: loss = 0.0855877 (* 1 = 0.0855877 loss)
I0502 11:35:59.074779 26473 sgd_solver.cpp:106] Iteration 157500, lr = 3.51844e-06
I0502 11:35:59.076393 26473 solver.cpp:362] Iteration 157500, Testing net (#0)
I0502 11:35:59.076406 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:35:59.207103 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:35:59.207123 26473 solver.cpp:429]     Test net output #1: loss = 0.0793739 (* 1 = 0.0793739 loss)
I0502 11:35:59.210044 26473 solver.cpp:242] Iteration 157500 (83.3991 iter/s, 1.19905s/100 iter), loss = 0.106622
I0502 11:35:59.210064 26473 solver.cpp:261]     Train net output #0: loss = 0.106622 (* 1 = 0.106622 loss)
I0502 11:35:59.210073 26473 sgd_solver.cpp:106] Iteration 157500, lr = 3.51844e-06
I0502 11:36:00.149154 26473 solver.cpp:242] Iteration 157600 (93.0794 iter/s, 1.07435s/100 iter), loss = 0.16518
I0502 11:36:00.149193 26473 solver.cpp:261]     Train net output #0: loss = 0.16518 (* 1 = 0.16518 loss)
I0502 11:36:00.149201 26473 sgd_solver.cpp:106] Iteration 157600, lr = 3.51844e-06
I0502 11:36:00.153952 26473 solver.cpp:242] Iteration 157600 (105.947 iter/s, 0.94387s/100 iter), loss = 0.00264397
I0502 11:36:00.153975 26473 solver.cpp:261]     Train net output #0: loss = 0.00264397 (* 1 = 0.00264397 loss)
I0502 11:36:00.153985 26473 sgd_solver.cpp:106] Iteration 157600, lr = 3.51844e-06
I0502 11:36:01.131311 26473 solver.cpp:242] Iteration 157700 (101.824 iter/s, 0.982089s/100 iter), loss = 0.42209
I0502 11:36:01.131352 26473 solver.cpp:261]     Train net output #0: loss = 0.42209 (* 1 = 0.42209 loss)
I0502 11:36:01.131361 26473 sgd_solver.cpp:106] Iteration 157700, lr = 3.51844e-06
I0502 11:36:01.136126 26473 solver.cpp:242] Iteration 157700 (101.819 iter/s, 0.982132s/100 iter), loss = 0.114115
I0502 11:36:01.136150 26473 solver.cpp:261]     Train net output #0: loss = 0.114115 (* 1 = 0.114115 loss)
I0502 11:36:01.136158 26473 sgd_solver.cpp:106] Iteration 157700, lr = 3.51844e-06
I0502 11:36:02.075233 26473 solver.cpp:242] Iteration 157800 (105.949 iter/s, 0.943855s/100 iter), loss = 0.0539156
I0502 11:36:02.075270 26473 solver.cpp:261]     Train net output #0: loss = 0.0539156 (* 1 = 0.0539156 loss)
I0502 11:36:02.075279 26473 sgd_solver.cpp:106] Iteration 157800, lr = 3.51844e-06
I0502 11:36:02.080044 26473 solver.cpp:242] Iteration 157800 (105.946 iter/s, 0.943875s/100 iter), loss = 0.0670677
I0502 11:36:02.080066 26473 solver.cpp:261]     Train net output #0: loss = 0.0670677 (* 1 = 0.0670677 loss)
I0502 11:36:02.080075 26473 sgd_solver.cpp:106] Iteration 157800, lr = 3.51844e-06
I0502 11:36:03.020665 26473 solver.cpp:242] Iteration 157900 (105.779 iter/s, 0.945369s/100 iter), loss = 0.176293
I0502 11:36:03.020709 26473 solver.cpp:261]     Train net output #0: loss = 0.176293 (* 1 = 0.176293 loss)
I0502 11:36:03.020717 26473 sgd_solver.cpp:106] Iteration 157900, lr = 3.51844e-06
I0502 11:36:03.025557 26473 solver.cpp:242] Iteration 157900 (105.768 iter/s, 0.945463s/100 iter), loss = 0.134
I0502 11:36:03.025580 26473 solver.cpp:261]     Train net output #0: loss = 0.134 (* 1 = 0.134 loss)
I0502 11:36:03.025589 26473 sgd_solver.cpp:106] Iteration 157900, lr = 3.51844e-06
I0502 11:36:03.960989 26473 solver.cpp:362] Iteration 158000, Testing net (#0)
I0502 11:36:03.961009 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:04.085321 26473 solver.cpp:429]     Test net output #0: loss = 0.248239 (* 1 = 0.248239 loss)
I0502 11:36:04.088186 26473 solver.cpp:242] Iteration 158000 (93.6803 iter/s, 1.06746s/100 iter), loss = 0.058314
I0502 11:36:04.088205 26473 solver.cpp:261]     Train net output #0: loss = 0.058314 (* 1 = 0.058314 loss)
I0502 11:36:04.088213 26473 sgd_solver.cpp:106] Iteration 158000, lr = 3.51844e-06
I0502 11:36:04.089850 26473 solver.cpp:362] Iteration 158000, Testing net (#0)
I0502 11:36:04.089864 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:04.220270 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9705
I0502 11:36:04.220301 26473 solver.cpp:429]     Test net output #1: loss = 0.0729237 (* 1 = 0.0729237 loss)
I0502 11:36:04.223227 26473 solver.cpp:242] Iteration 158000 (83.4986 iter/s, 1.19763s/100 iter), loss = 0.092387
I0502 11:36:04.223248 26473 solver.cpp:261]     Train net output #0: loss = 0.092387 (* 1 = 0.092387 loss)
I0502 11:36:04.223256 26473 sgd_solver.cpp:106] Iteration 158000, lr = 3.51844e-06
I0502 11:36:05.162991 26473 solver.cpp:242] Iteration 158100 (93.0446 iter/s, 1.07475s/100 iter), loss = 0.226748
I0502 11:36:05.163025 26473 solver.cpp:261]     Train net output #0: loss = 0.226748 (* 1 = 0.226748 loss)
I0502 11:36:05.163034 26473 sgd_solver.cpp:106] Iteration 158100, lr = 3.51844e-06
I0502 11:36:05.167801 26473 solver.cpp:242] Iteration 158100 (105.872 iter/s, 0.944535s/100 iter), loss = 0.106151
I0502 11:36:05.167825 26473 solver.cpp:261]     Train net output #0: loss = 0.106151 (* 1 = 0.106151 loss)
I0502 11:36:05.167834 26473 sgd_solver.cpp:106] Iteration 158100, lr = 3.51844e-06
I0502 11:36:06.106464 26473 solver.cpp:242] Iteration 158200 (105.998 iter/s, 0.943411s/100 iter), loss = 0.39941
I0502 11:36:06.106498 26473 solver.cpp:261]     Train net output #0: loss = 0.39941 (* 1 = 0.39941 loss)
I0502 11:36:06.106506 26473 sgd_solver.cpp:106] Iteration 158200, lr = 3.51844e-06
I0502 11:36:06.111270 26473 solver.cpp:242] Iteration 158200 (105.997 iter/s, 0.943427s/100 iter), loss = 0.139175
I0502 11:36:06.111292 26473 solver.cpp:261]     Train net output #0: loss = 0.139175 (* 1 = 0.139175 loss)
I0502 11:36:06.111301 26473 sgd_solver.cpp:106] Iteration 158200, lr = 3.51844e-06
I0502 11:36:07.050084 26473 solver.cpp:242] Iteration 158300 (105.981 iter/s, 0.943562s/100 iter), loss = 0.0930167
I0502 11:36:07.050117 26473 solver.cpp:261]     Train net output #0: loss = 0.0930167 (* 1 = 0.0930167 loss)
I0502 11:36:07.050137 26473 sgd_solver.cpp:106] Iteration 158300, lr = 3.51844e-06
I0502 11:36:07.054908 26473 solver.cpp:242] Iteration 158300 (105.977 iter/s, 0.943598s/100 iter), loss = 0.134148
I0502 11:36:07.054931 26473 solver.cpp:261]     Train net output #0: loss = 0.134148 (* 1 = 0.134148 loss)
I0502 11:36:07.054939 26473 sgd_solver.cpp:106] Iteration 158300, lr = 3.51844e-06
I0502 11:36:07.994019 26473 solver.cpp:242] Iteration 158400 (105.946 iter/s, 0.943877s/100 iter), loss = 0.138774
I0502 11:36:07.994046 26473 solver.cpp:261]     Train net output #0: loss = 0.138774 (* 1 = 0.138774 loss)
I0502 11:36:07.994055 26473 sgd_solver.cpp:106] Iteration 158400, lr = 3.51844e-06
I0502 11:36:07.998916 26473 solver.cpp:242] Iteration 158400 (105.937 iter/s, 0.943959s/100 iter), loss = 0.0243584
I0502 11:36:07.998939 26473 solver.cpp:261]     Train net output #0: loss = 0.0243584 (* 1 = 0.0243584 loss)
I0502 11:36:07.998949 26473 sgd_solver.cpp:106] Iteration 158400, lr = 3.51844e-06
I0502 11:36:08.934463 26473 solver.cpp:362] Iteration 158500, Testing net (#0)
I0502 11:36:08.934491 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:09.058620 26473 solver.cpp:429]     Test net output #0: loss = 0.236026 (* 1 = 0.236026 loss)
I0502 11:36:09.061497 26473 solver.cpp:242] Iteration 158500 (93.6829 iter/s, 1.06743s/100 iter), loss = 0.0418672
I0502 11:36:09.061518 26473 solver.cpp:261]     Train net output #0: loss = 0.0418672 (* 1 = 0.0418672 loss)
I0502 11:36:09.061527 26473 sgd_solver.cpp:106] Iteration 158500, lr = 3.51844e-06
I0502 11:36:09.063225 26473 solver.cpp:362] Iteration 158500, Testing net (#0)
I0502 11:36:09.063240 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:09.193981 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:36:09.194000 26473 solver.cpp:429]     Test net output #1: loss = 0.0821949 (* 1 = 0.0821949 loss)
I0502 11:36:09.196919 26473 solver.cpp:242] Iteration 158500 (83.4752 iter/s, 1.19796s/100 iter), loss = 0.0788041
I0502 11:36:09.196939 26473 solver.cpp:261]     Train net output #0: loss = 0.0788041 (* 1 = 0.0788041 loss)
I0502 11:36:09.196948 26473 sgd_solver.cpp:106] Iteration 158500, lr = 3.51844e-06
I0502 11:36:10.136819 26473 solver.cpp:242] Iteration 158600 (93 iter/s, 1.07527s/100 iter), loss = 0.172768
I0502 11:36:10.136862 26473 solver.cpp:261]     Train net output #0: loss = 0.172768 (* 1 = 0.172768 loss)
I0502 11:36:10.136870 26473 sgd_solver.cpp:106] Iteration 158600, lr = 3.51844e-06
I0502 11:36:10.141625 26473 solver.cpp:242] Iteration 158600 (105.857 iter/s, 0.944668s/100 iter), loss = 0.0831412
I0502 11:36:10.141649 26473 solver.cpp:261]     Train net output #0: loss = 0.0831412 (* 1 = 0.0831412 loss)
I0502 11:36:10.141657 26473 sgd_solver.cpp:106] Iteration 158600, lr = 3.51844e-06
I0502 11:36:11.080102 26473 solver.cpp:242] Iteration 158700 (106.021 iter/s, 0.943211s/100 iter), loss = 0.329042
I0502 11:36:11.080144 26473 solver.cpp:261]     Train net output #0: loss = 0.329042 (* 1 = 0.329042 loss)
I0502 11:36:11.080153 26473 sgd_solver.cpp:106] Iteration 158700, lr = 3.51844e-06
I0502 11:36:11.084938 26473 solver.cpp:242] Iteration 158700 (106.014 iter/s, 0.943271s/100 iter), loss = 0.043094
I0502 11:36:11.084960 26473 solver.cpp:261]     Train net output #0: loss = 0.043094 (* 1 = 0.043094 loss)
I0502 11:36:11.084969 26473 sgd_solver.cpp:106] Iteration 158700, lr = 3.51844e-06
I0502 11:36:12.026603 26473 solver.cpp:242] Iteration 158800 (105.66 iter/s, 0.946431s/100 iter), loss = 0.233467
I0502 11:36:12.026646 26473 solver.cpp:261]     Train net output #0: loss = 0.233467 (* 1 = 0.233467 loss)
I0502 11:36:12.026655 26473 sgd_solver.cpp:106] Iteration 158800, lr = 3.51844e-06
I0502 11:36:12.031426 26473 solver.cpp:242] Iteration 158800 (105.658 iter/s, 0.946448s/100 iter), loss = 0.0315795
I0502 11:36:12.031450 26473 solver.cpp:261]     Train net output #0: loss = 0.0315795 (* 1 = 0.0315795 loss)
I0502 11:36:12.031458 26473 sgd_solver.cpp:106] Iteration 158800, lr = 3.51844e-06
I0502 11:36:12.970626 26473 solver.cpp:242] Iteration 158900 (105.937 iter/s, 0.943954s/100 iter), loss = 0.82442
I0502 11:36:12.970669 26473 solver.cpp:261]     Train net output #0: loss = 0.82442 (* 1 = 0.82442 loss)
I0502 11:36:12.970677 26473 sgd_solver.cpp:106] Iteration 158900, lr = 3.51844e-06
I0502 11:36:12.975495 26473 solver.cpp:242] Iteration 158900 (105.93 iter/s, 0.944019s/100 iter), loss = 0.126292
I0502 11:36:12.975519 26473 solver.cpp:261]     Train net output #0: loss = 0.126292 (* 1 = 0.126292 loss)
I0502 11:36:12.975528 26473 sgd_solver.cpp:106] Iteration 158900, lr = 3.51844e-06
I0502 11:36:13.912020 26473 solver.cpp:362] Iteration 159000, Testing net (#0)
I0502 11:36:13.912050 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:14.036453 26473 solver.cpp:429]     Test net output #0: loss = 0.241738 (* 1 = 0.241738 loss)
I0502 11:36:14.039335 26473 solver.cpp:242] Iteration 159000 (93.5762 iter/s, 1.06865s/100 iter), loss = 0.0695798
I0502 11:36:14.039356 26473 solver.cpp:261]     Train net output #0: loss = 0.0695798 (* 1 = 0.0695798 loss)
I0502 11:36:14.039366 26473 sgd_solver.cpp:106] Iteration 159000, lr = 3.51844e-06
I0502 11:36:14.041126 26473 solver.cpp:362] Iteration 159000, Testing net (#0)
I0502 11:36:14.041141 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:14.171874 26473 solver.cpp:429]     Test net output #0: accuracy = 0.97
I0502 11:36:14.171895 26473 solver.cpp:429]     Test net output #1: loss = 0.0750005 (* 1 = 0.0750005 loss)
I0502 11:36:14.174811 26473 solver.cpp:242] Iteration 159000 (83.3839 iter/s, 1.19927s/100 iter), loss = 0.139382
I0502 11:36:14.174831 26473 solver.cpp:261]     Train net output #0: loss = 0.139382 (* 1 = 0.139382 loss)
I0502 11:36:14.174839 26473 sgd_solver.cpp:106] Iteration 159000, lr = 3.51844e-06
I0502 11:36:15.114109 26473 solver.cpp:242] Iteration 159100 (93.0476 iter/s, 1.07472s/100 iter), loss = 0.127226
I0502 11:36:15.114151 26473 solver.cpp:261]     Train net output #0: loss = 0.127226 (* 1 = 0.127226 loss)
I0502 11:36:15.114161 26473 sgd_solver.cpp:106] Iteration 159100, lr = 3.51844e-06
I0502 11:36:15.118944 26473 solver.cpp:242] Iteration 159100 (105.922 iter/s, 0.944095s/100 iter), loss = 0.0433624
I0502 11:36:15.118978 26473 solver.cpp:261]     Train net output #0: loss = 0.0433624 (* 1 = 0.0433624 loss)
I0502 11:36:15.118988 26473 sgd_solver.cpp:106] Iteration 159100, lr = 3.51844e-06
I0502 11:36:16.058002 26473 solver.cpp:242] Iteration 159200 (105.952 iter/s, 0.943821s/100 iter), loss = 0.175287
I0502 11:36:16.058043 26473 solver.cpp:261]     Train net output #0: loss = 0.175287 (* 1 = 0.175287 loss)
I0502 11:36:16.058051 26473 sgd_solver.cpp:106] Iteration 159200, lr = 3.51844e-06
I0502 11:36:16.062847 26473 solver.cpp:242] Iteration 159200 (105.949 iter/s, 0.943852s/100 iter), loss = 0.0147541
I0502 11:36:16.062871 26473 solver.cpp:261]     Train net output #0: loss = 0.0147541 (* 1 = 0.0147541 loss)
I0502 11:36:16.062880 26473 sgd_solver.cpp:106] Iteration 159200, lr = 3.51844e-06
I0502 11:36:17.001271 26473 solver.cpp:242] Iteration 159300 (106.022 iter/s, 0.9432s/100 iter), loss = 0.180573
I0502 11:36:17.001312 26473 solver.cpp:261]     Train net output #0: loss = 0.180573 (* 1 = 0.180573 loss)
I0502 11:36:17.001322 26473 sgd_solver.cpp:106] Iteration 159300, lr = 3.51844e-06
I0502 11:36:17.006079 26473 solver.cpp:242] Iteration 159300 (106.023 iter/s, 0.94319s/100 iter), loss = 0.00973295
I0502 11:36:17.006103 26473 solver.cpp:261]     Train net output #0: loss = 0.00973295 (* 1 = 0.00973295 loss)
I0502 11:36:17.006111 26473 sgd_solver.cpp:106] Iteration 159300, lr = 3.51844e-06
I0502 11:36:17.944840 26473 solver.cpp:242] Iteration 159400 (105.988 iter/s, 0.943504s/100 iter), loss = 0.178939
I0502 11:36:17.944878 26473 solver.cpp:261]     Train net output #0: loss = 0.178939 (* 1 = 0.178939 loss)
I0502 11:36:17.944887 26473 sgd_solver.cpp:106] Iteration 159400, lr = 3.51844e-06
I0502 11:36:17.949656 26473 solver.cpp:242] Iteration 159400 (105.984 iter/s, 0.943535s/100 iter), loss = 0.0164332
I0502 11:36:17.949679 26473 solver.cpp:261]     Train net output #0: loss = 0.0164332 (* 1 = 0.0164332 loss)
I0502 11:36:17.949688 26473 sgd_solver.cpp:106] Iteration 159400, lr = 3.51844e-06
I0502 11:36:18.885807 26473 solver.cpp:362] Iteration 159500, Testing net (#0)
I0502 11:36:18.885833 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:19.009979 26473 solver.cpp:429]     Test net output #0: loss = 0.234843 (* 1 = 0.234843 loss)
I0502 11:36:19.012848 26473 solver.cpp:242] Iteration 159500 (93.6372 iter/s, 1.06795s/100 iter), loss = 0.223988
I0502 11:36:19.012868 26473 solver.cpp:261]     Train net output #0: loss = 0.223988 (* 1 = 0.223988 loss)
I0502 11:36:19.012876 26473 sgd_solver.cpp:106] Iteration 159500, lr = 3.51844e-06
I0502 11:36:19.014564 26473 solver.cpp:362] Iteration 159500, Testing net (#0)
I0502 11:36:19.014576 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:19.145318 26473 solver.cpp:429]     Test net output #0: accuracy = 0.967
I0502 11:36:19.145342 26473 solver.cpp:429]     Test net output #1: loss = 0.0747893 (* 1 = 0.0747893 loss)
I0502 11:36:19.148267 26473 solver.cpp:242] Iteration 159500 (83.4329 iter/s, 1.19857s/100 iter), loss = 0.147622
I0502 11:36:19.148286 26473 solver.cpp:261]     Train net output #0: loss = 0.147622 (* 1 = 0.147622 loss)
I0502 11:36:19.148294 26473 sgd_solver.cpp:106] Iteration 159500, lr = 3.51844e-06
I0502 11:36:20.087076 26473 solver.cpp:242] Iteration 159600 (93.0947 iter/s, 1.07417s/100 iter), loss = 0.0723244
I0502 11:36:20.087116 26473 solver.cpp:261]     Train net output #0: loss = 0.0723244 (* 1 = 0.0723244 loss)
I0502 11:36:20.087124 26473 sgd_solver.cpp:106] Iteration 159600, lr = 3.51844e-06
I0502 11:36:20.091884 26473 solver.cpp:242] Iteration 159600 (105.979 iter/s, 0.943579s/100 iter), loss = 0.104357
I0502 11:36:20.091907 26473 solver.cpp:261]     Train net output #0: loss = 0.104357 (* 1 = 0.104357 loss)
I0502 11:36:20.091915 26473 sgd_solver.cpp:106] Iteration 159600, lr = 3.51844e-06
I0502 11:36:21.031232 26473 solver.cpp:242] Iteration 159700 (105.922 iter/s, 0.944087s/100 iter), loss = 0.1722
I0502 11:36:21.031270 26473 solver.cpp:261]     Train net output #0: loss = 0.1722 (* 1 = 0.1722 loss)
I0502 11:36:21.031280 26473 sgd_solver.cpp:106] Iteration 159700, lr = 3.51844e-06
I0502 11:36:21.036068 26473 solver.cpp:242] Iteration 159700 (105.916 iter/s, 0.944143s/100 iter), loss = 0.188704
I0502 11:36:21.036092 26473 solver.cpp:261]     Train net output #0: loss = 0.188704 (* 1 = 0.188704 loss)
I0502 11:36:21.036100 26473 sgd_solver.cpp:106] Iteration 159700, lr = 3.51844e-06
I0502 11:36:21.974707 26473 solver.cpp:242] Iteration 159800 (105.999 iter/s, 0.943408s/100 iter), loss = 0.142535
I0502 11:36:21.974743 26473 solver.cpp:261]     Train net output #0: loss = 0.142535 (* 1 = 0.142535 loss)
I0502 11:36:21.974752 26473 sgd_solver.cpp:106] Iteration 159800, lr = 3.51844e-06
I0502 11:36:21.979509 26473 solver.cpp:242] Iteration 159800 (106 iter/s, 0.9434s/100 iter), loss = 0.0358368
I0502 11:36:21.979532 26473 solver.cpp:261]     Train net output #0: loss = 0.0358368 (* 1 = 0.0358368 loss)
I0502 11:36:21.979540 26473 sgd_solver.cpp:106] Iteration 159800, lr = 3.51844e-06
I0502 11:36:22.918105 26473 solver.cpp:242] Iteration 159900 (106.007 iter/s, 0.943337s/100 iter), loss = 0.202419
I0502 11:36:22.918140 26473 solver.cpp:261]     Train net output #0: loss = 0.202419 (* 1 = 0.202419 loss)
I0502 11:36:22.918149 26473 sgd_solver.cpp:106] Iteration 159900, lr = 3.51844e-06
I0502 11:36:22.922917 26473 solver.cpp:242] Iteration 159900 (106.003 iter/s, 0.943367s/100 iter), loss = 0.00375683
I0502 11:36:22.922940 26473 solver.cpp:261]     Train net output #0: loss = 0.00375683 (* 1 = 0.00375683 loss)
I0502 11:36:22.922950 26473 sgd_solver.cpp:106] Iteration 159900, lr = 3.51844e-06
I0502 11:36:23.859383 26473 solver.cpp:362] Iteration 160000, Testing net (#0)
I0502 11:36:23.859407 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:23.983597 26473 solver.cpp:429]     Test net output #0: loss = 0.248779 (* 1 = 0.248779 loss)
I0502 11:36:23.986479 26473 solver.cpp:242] Iteration 160000 (93.6049 iter/s, 1.06832s/100 iter), loss = 0.0658909
I0502 11:36:23.986500 26473 solver.cpp:261]     Train net output #0: loss = 0.0658909 (* 1 = 0.0658909 loss)
I0502 11:36:23.986510 26473 sgd_solver.cpp:106] Iteration 160000, lr = 2.81475e-06
I0502 11:36:23.988204 26473 solver.cpp:362] Iteration 160000, Testing net (#0)
I0502 11:36:23.988216 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:24.118808 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9615
I0502 11:36:24.118829 26473 solver.cpp:429]     Test net output #1: loss = 0.0776219 (* 1 = 0.0776219 loss)
I0502 11:36:24.121753 26473 solver.cpp:242] Iteration 160000 (83.4174 iter/s, 1.19879s/100 iter), loss = 0.0585837
I0502 11:36:24.121773 26473 solver.cpp:261]     Train net output #0: loss = 0.0585837 (* 1 = 0.0585837 loss)
I0502 11:36:24.121780 26473 sgd_solver.cpp:106] Iteration 160000, lr = 2.81475e-06
I0502 11:36:25.059667 26473 solver.cpp:242] Iteration 160100 (93.185 iter/s, 1.07313s/100 iter), loss = 0.142679
I0502 11:36:25.059700 26473 solver.cpp:261]     Train net output #0: loss = 0.142679 (* 1 = 0.142679 loss)
I0502 11:36:25.059708 26473 sgd_solver.cpp:106] Iteration 160100, lr = 2.81475e-06
I0502 11:36:25.064465 26473 solver.cpp:242] Iteration 160100 (106.081 iter/s, 0.942674s/100 iter), loss = 0.0526473
I0502 11:36:25.064487 26473 solver.cpp:261]     Train net output #0: loss = 0.0526473 (* 1 = 0.0526473 loss)
I0502 11:36:25.064496 26473 sgd_solver.cpp:106] Iteration 160100, lr = 2.81475e-06
I0502 11:36:26.003549 26473 solver.cpp:242] Iteration 160200 (105.952 iter/s, 0.943822s/100 iter), loss = 0.250943
I0502 11:36:26.003582 26473 solver.cpp:261]     Train net output #0: loss = 0.250943 (* 1 = 0.250943 loss)
I0502 11:36:26.003590 26473 sgd_solver.cpp:106] Iteration 160200, lr = 2.81475e-06
I0502 11:36:26.008383 26473 solver.cpp:242] Iteration 160200 (105.946 iter/s, 0.943878s/100 iter), loss = 0.0341819
I0502 11:36:26.008406 26473 solver.cpp:261]     Train net output #0: loss = 0.0341819 (* 1 = 0.0341819 loss)
I0502 11:36:26.008415 26473 sgd_solver.cpp:106] Iteration 160200, lr = 2.81475e-06
I0502 11:36:26.946985 26473 solver.cpp:242] Iteration 160300 (106.002 iter/s, 0.943375s/100 iter), loss = 0.349918
I0502 11:36:26.947024 26473 solver.cpp:261]     Train net output #0: loss = 0.349918 (* 1 = 0.349918 loss)
I0502 11:36:26.947034 26473 sgd_solver.cpp:106] Iteration 160300, lr = 2.81475e-06
I0502 11:36:26.951817 26473 solver.cpp:242] Iteration 160300 (106 iter/s, 0.943393s/100 iter), loss = 0.0251149
I0502 11:36:26.951840 26473 solver.cpp:261]     Train net output #0: loss = 0.0251149 (* 1 = 0.0251149 loss)
I0502 11:36:26.951848 26473 sgd_solver.cpp:106] Iteration 160300, lr = 2.81475e-06
I0502 11:36:27.891223 26473 solver.cpp:242] Iteration 160400 (105.913 iter/s, 0.944173s/100 iter), loss = 0.0855071
I0502 11:36:27.891268 26473 solver.cpp:261]     Train net output #0: loss = 0.0855071 (* 1 = 0.0855071 loss)
I0502 11:36:27.891278 26473 sgd_solver.cpp:106] Iteration 160400, lr = 2.81475e-06
I0502 11:36:27.896050 26473 solver.cpp:242] Iteration 160400 (105.911 iter/s, 0.944193s/100 iter), loss = 0.159589
I0502 11:36:27.896075 26473 solver.cpp:261]     Train net output #0: loss = 0.159589 (* 1 = 0.159589 loss)
I0502 11:36:27.896082 26473 sgd_solver.cpp:106] Iteration 160400, lr = 2.81475e-06
I0502 11:36:28.831801 26473 solver.cpp:362] Iteration 160500, Testing net (#0)
I0502 11:36:28.831845 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:28.956122 26473 solver.cpp:429]     Test net output #0: loss = 0.259628 (* 1 = 0.259628 loss)
I0502 11:36:28.958998 26473 solver.cpp:242] Iteration 160500 (93.6582 iter/s, 1.06771s/100 iter), loss = 0.0678266
I0502 11:36:28.959018 26473 solver.cpp:261]     Train net output #0: loss = 0.0678266 (* 1 = 0.0678266 loss)
I0502 11:36:28.959028 26473 sgd_solver.cpp:106] Iteration 160500, lr = 2.81475e-06
I0502 11:36:28.960736 26473 solver.cpp:362] Iteration 160500, Testing net (#0)
I0502 11:36:28.960750 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:29.091384 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9725
I0502 11:36:29.091406 26473 solver.cpp:429]     Test net output #1: loss = 0.0686401 (* 1 = 0.0686401 loss)
I0502 11:36:29.094310 26473 solver.cpp:242] Iteration 160500 (83.4575 iter/s, 1.19822s/100 iter), loss = 0.066654
I0502 11:36:29.094331 26473 solver.cpp:261]     Train net output #0: loss = 0.066654 (* 1 = 0.066654 loss)
I0502 11:36:29.094338 26473 sgd_solver.cpp:106] Iteration 160500, lr = 2.81475e-06
I0502 11:36:30.033507 26473 solver.cpp:242] Iteration 160600 (93.0703 iter/s, 1.07446s/100 iter), loss = 0.148927
I0502 11:36:30.033536 26473 solver.cpp:261]     Train net output #0: loss = 0.148927 (* 1 = 0.148927 loss)
I0502 11:36:30.033545 26473 sgd_solver.cpp:106] Iteration 160600, lr = 2.81475e-06
I0502 11:36:30.038298 26473 solver.cpp:242] Iteration 160600 (105.938 iter/s, 0.943951s/100 iter), loss = 0.0255907
I0502 11:36:30.038321 26473 solver.cpp:261]     Train net output #0: loss = 0.0255907 (* 1 = 0.0255907 loss)
I0502 11:36:30.038329 26473 sgd_solver.cpp:106] Iteration 160600, lr = 2.81475e-06
I0502 11:36:30.978417 26473 solver.cpp:242] Iteration 160700 (105.837 iter/s, 0.94485s/100 iter), loss = 0.129411
I0502 11:36:30.978462 26473 solver.cpp:261]     Train net output #0: loss = 0.129411 (* 1 = 0.129411 loss)
I0502 11:36:30.978471 26473 sgd_solver.cpp:106] Iteration 160700, lr = 2.81475e-06
I0502 11:36:30.983222 26473 solver.cpp:242] Iteration 160700 (105.833 iter/s, 0.944884s/100 iter), loss = 0.0266004
I0502 11:36:30.983247 26473 solver.cpp:261]     Train net output #0: loss = 0.0266004 (* 1 = 0.0266004 loss)
I0502 11:36:30.983254 26473 sgd_solver.cpp:106] Iteration 160700, lr = 2.81475e-06
I0502 11:36:31.922199 26473 solver.cpp:242] Iteration 160800 (105.965 iter/s, 0.943707s/100 iter), loss = 0.299646
I0502 11:36:31.922250 26473 solver.cpp:261]     Train net output #0: loss = 0.299646 (* 1 = 0.299646 loss)
I0502 11:36:31.922260 26473 sgd_solver.cpp:106] Iteration 160800, lr = 2.81475e-06
I0502 11:36:31.927057 26473 solver.cpp:242] Iteration 160800 (105.956 iter/s, 0.943792s/100 iter), loss = 0.0287062
I0502 11:36:31.927083 26473 solver.cpp:261]     Train net output #0: loss = 0.0287062 (* 1 = 0.0287062 loss)
I0502 11:36:31.927099 26473 sgd_solver.cpp:106] Iteration 160800, lr = 2.81475e-06
I0502 11:36:32.865540 26473 solver.cpp:242] Iteration 160900 (106.014 iter/s, 0.943275s/100 iter), loss = 0.140987
I0502 11:36:32.865582 26473 solver.cpp:261]     Train net output #0: loss = 0.140987 (* 1 = 0.140987 loss)
I0502 11:36:32.865592 26473 sgd_solver.cpp:106] Iteration 160900, lr = 2.81475e-06
I0502 11:36:32.870367 26473 solver.cpp:242] Iteration 160900 (106.015 iter/s, 0.943267s/100 iter), loss = 0.0330002
I0502 11:36:32.870389 26473 solver.cpp:261]     Train net output #0: loss = 0.0330002 (* 1 = 0.0330002 loss)
I0502 11:36:32.870398 26473 sgd_solver.cpp:106] Iteration 160900, lr = 2.81475e-06
I0502 11:36:33.805704 26473 solver.cpp:362] Iteration 161000, Testing net (#0)
I0502 11:36:33.805732 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:33.930078 26473 solver.cpp:429]     Test net output #0: loss = 0.199914 (* 1 = 0.199914 loss)
I0502 11:36:33.932965 26473 solver.cpp:242] Iteration 161000 (93.6887 iter/s, 1.06736s/100 iter), loss = 0.220816
I0502 11:36:33.932987 26473 solver.cpp:261]     Train net output #0: loss = 0.220816 (* 1 = 0.220816 loss)
I0502 11:36:33.932996 26473 sgd_solver.cpp:106] Iteration 161000, lr = 2.81475e-06
I0502 11:36:33.934720 26473 solver.cpp:362] Iteration 161000, Testing net (#0)
I0502 11:36:33.934732 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:34.065341 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:36:34.065363 26473 solver.cpp:429]     Test net output #1: loss = 0.0861392 (* 1 = 0.0861392 loss)
I0502 11:36:34.068289 26473 solver.cpp:242] Iteration 161000 (83.4809 iter/s, 1.19788s/100 iter), loss = 0.134987
I0502 11:36:34.068308 26473 solver.cpp:261]     Train net output #0: loss = 0.134987 (* 1 = 0.134987 loss)
I0502 11:36:34.068316 26473 sgd_solver.cpp:106] Iteration 161000, lr = 2.81475e-06
I0502 11:36:35.008910 26473 solver.cpp:242] Iteration 161100 (92.9466 iter/s, 1.07589s/100 iter), loss = 0.223423
I0502 11:36:35.008956 26473 solver.cpp:261]     Train net output #0: loss = 0.223423 (* 1 = 0.223423 loss)
I0502 11:36:35.008965 26473 sgd_solver.cpp:106] Iteration 161100, lr = 2.81475e-06
I0502 11:36:35.013743 26473 solver.cpp:242] Iteration 161100 (105.773 iter/s, 0.945416s/100 iter), loss = 0.0419521
I0502 11:36:35.013767 26473 solver.cpp:261]     Train net output #0: loss = 0.0419521 (* 1 = 0.0419521 loss)
I0502 11:36:35.013775 26473 sgd_solver.cpp:106] Iteration 161100, lr = 2.81475e-06
I0502 11:36:35.953408 26473 solver.cpp:242] Iteration 161200 (105.885 iter/s, 0.944424s/100 iter), loss = 0.255184
I0502 11:36:35.953459 26473 solver.cpp:261]     Train net output #0: loss = 0.255184 (* 1 = 0.255184 loss)
I0502 11:36:35.953467 26473 sgd_solver.cpp:106] Iteration 161200, lr = 2.81475e-06
I0502 11:36:35.958353 26473 solver.cpp:242] Iteration 161200 (105.869 iter/s, 0.944567s/100 iter), loss = 0.0548991
I0502 11:36:35.958377 26473 solver.cpp:261]     Train net output #0: loss = 0.0548991 (* 1 = 0.0548991 loss)
I0502 11:36:35.958385 26473 sgd_solver.cpp:106] Iteration 161200, lr = 2.81475e-06
I0502 11:36:36.897795 26473 solver.cpp:242] Iteration 161300 (105.898 iter/s, 0.944307s/100 iter), loss = 0.197039
I0502 11:36:36.897837 26473 solver.cpp:261]     Train net output #0: loss = 0.197039 (* 1 = 0.197039 loss)
I0502 11:36:36.897845 26473 sgd_solver.cpp:106] Iteration 161300, lr = 2.81475e-06
I0502 11:36:36.902618 26473 solver.cpp:242] Iteration 161300 (105.907 iter/s, 0.944223s/100 iter), loss = 0.125637
I0502 11:36:36.902642 26473 solver.cpp:261]     Train net output #0: loss = 0.125637 (* 1 = 0.125637 loss)
I0502 11:36:36.902652 26473 sgd_solver.cpp:106] Iteration 161300, lr = 2.81475e-06
I0502 11:36:37.841691 26473 solver.cpp:242] Iteration 161400 (105.952 iter/s, 0.943827s/100 iter), loss = 0.11485
I0502 11:36:37.841728 26473 solver.cpp:261]     Train net output #0: loss = 0.11485 (* 1 = 0.11485 loss)
I0502 11:36:37.841737 26473 sgd_solver.cpp:106] Iteration 161400, lr = 2.81475e-06
I0502 11:36:37.846508 26473 solver.cpp:242] Iteration 161400 (105.949 iter/s, 0.943848s/100 iter), loss = 0.00112195
I0502 11:36:37.846532 26473 solver.cpp:261]     Train net output #0: loss = 0.00112195 (* 1 = 0.00112195 loss)
I0502 11:36:37.846540 26473 sgd_solver.cpp:106] Iteration 161400, lr = 2.81475e-06
I0502 11:36:38.782915 26473 solver.cpp:362] Iteration 161500, Testing net (#0)
I0502 11:36:38.782940 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:38.907155 26473 solver.cpp:429]     Test net output #0: loss = 0.172483 (* 1 = 0.172483 loss)
I0502 11:36:38.910017 26473 solver.cpp:242] Iteration 161500 (93.6093 iter/s, 1.06827s/100 iter), loss = 0.211079
I0502 11:36:38.910037 26473 solver.cpp:261]     Train net output #0: loss = 0.211079 (* 1 = 0.211079 loss)
I0502 11:36:38.910044 26473 sgd_solver.cpp:106] Iteration 161500, lr = 2.81475e-06
I0502 11:36:38.911741 26473 solver.cpp:362] Iteration 161500, Testing net (#0)
I0502 11:36:38.911754 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:39.042304 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:36:39.042338 26473 solver.cpp:429]     Test net output #1: loss = 0.0778261 (* 1 = 0.0778261 loss)
I0502 11:36:39.045270 26473 solver.cpp:242] Iteration 161500 (83.4225 iter/s, 1.19872s/100 iter), loss = 0.0409493
I0502 11:36:39.045292 26473 solver.cpp:261]     Train net output #0: loss = 0.0409493 (* 1 = 0.0409493 loss)
I0502 11:36:39.045300 26473 sgd_solver.cpp:106] Iteration 161500, lr = 2.81475e-06
I0502 11:36:39.985518 26473 solver.cpp:242] Iteration 161600 (92.9838 iter/s, 1.07546s/100 iter), loss = 0.138893
I0502 11:36:39.985560 26473 solver.cpp:261]     Train net output #0: loss = 0.138893 (* 1 = 0.138893 loss)
I0502 11:36:39.985569 26473 sgd_solver.cpp:106] Iteration 161600, lr = 2.81475e-06
I0502 11:36:39.990388 26473 solver.cpp:242] Iteration 161600 (105.812 iter/s, 0.945072s/100 iter), loss = 0.0467526
I0502 11:36:39.990411 26473 solver.cpp:261]     Train net output #0: loss = 0.0467526 (* 1 = 0.0467526 loss)
I0502 11:36:39.990420 26473 sgd_solver.cpp:106] Iteration 161600, lr = 2.81475e-06
I0502 11:36:40.928416 26473 solver.cpp:242] Iteration 161700 (106.064 iter/s, 0.942826s/100 iter), loss = 0.071153
I0502 11:36:40.928453 26473 solver.cpp:261]     Train net output #0: loss = 0.071153 (* 1 = 0.071153 loss)
I0502 11:36:40.928462 26473 sgd_solver.cpp:106] Iteration 161700, lr = 2.81475e-06
I0502 11:36:40.933233 26473 solver.cpp:242] Iteration 161700 (106.066 iter/s, 0.942805s/100 iter), loss = 0.138424
I0502 11:36:40.933257 26473 solver.cpp:261]     Train net output #0: loss = 0.138424 (* 1 = 0.138424 loss)
I0502 11:36:40.933266 26473 sgd_solver.cpp:106] Iteration 161700, lr = 2.81475e-06
I0502 11:36:41.871989 26473 solver.cpp:242] Iteration 161800 (105.987 iter/s, 0.943508s/100 iter), loss = 0.209937
I0502 11:36:41.872025 26473 solver.cpp:261]     Train net output #0: loss = 0.209937 (* 1 = 0.209937 loss)
I0502 11:36:41.872033 26473 sgd_solver.cpp:106] Iteration 161800, lr = 2.81475e-06
I0502 11:36:41.876806 26473 solver.cpp:242] Iteration 161800 (105.985 iter/s, 0.94353s/100 iter), loss = 0.0490461
I0502 11:36:41.876829 26473 solver.cpp:261]     Train net output #0: loss = 0.0490461 (* 1 = 0.0490461 loss)
I0502 11:36:41.876838 26473 sgd_solver.cpp:106] Iteration 161800, lr = 2.81475e-06
I0502 11:36:42.817097 26473 solver.cpp:242] Iteration 161900 (105.815 iter/s, 0.945045s/100 iter), loss = 0.16239
I0502 11:36:42.817131 26473 solver.cpp:261]     Train net output #0: loss = 0.16239 (* 1 = 0.16239 loss)
I0502 11:36:42.817140 26473 sgd_solver.cpp:106] Iteration 161900, lr = 2.81475e-06
I0502 11:36:42.821884 26473 solver.cpp:242] Iteration 161900 (105.816 iter/s, 0.945036s/100 iter), loss = 0.0161549
I0502 11:36:42.821907 26473 solver.cpp:261]     Train net output #0: loss = 0.0161549 (* 1 = 0.0161549 loss)
I0502 11:36:42.821916 26473 sgd_solver.cpp:106] Iteration 161900, lr = 2.81475e-06
I0502 11:36:43.758370 26473 solver.cpp:362] Iteration 162000, Testing net (#0)
I0502 11:36:43.758394 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:43.882511 26473 solver.cpp:429]     Test net output #0: loss = 0.258858 (* 1 = 0.258858 loss)
I0502 11:36:43.885402 26473 solver.cpp:242] Iteration 162000 (93.6109 iter/s, 1.06825s/100 iter), loss = 0.219597
I0502 11:36:43.885422 26473 solver.cpp:261]     Train net output #0: loss = 0.219597 (* 1 = 0.219597 loss)
I0502 11:36:43.885431 26473 sgd_solver.cpp:106] Iteration 162000, lr = 2.81475e-06
I0502 11:36:43.887076 26473 solver.cpp:362] Iteration 162000, Testing net (#0)
I0502 11:36:43.887090 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:44.017657 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9675
I0502 11:36:44.017678 26473 solver.cpp:429]     Test net output #1: loss = 0.0883052 (* 1 = 0.0883052 loss)
I0502 11:36:44.020587 26473 solver.cpp:242] Iteration 162000 (83.4265 iter/s, 1.19866s/100 iter), loss = 0.0293474
I0502 11:36:44.020607 26473 solver.cpp:261]     Train net output #0: loss = 0.0293474 (* 1 = 0.0293474 loss)
I0502 11:36:44.020617 26473 sgd_solver.cpp:106] Iteration 162000, lr = 2.81475e-06
I0502 11:36:44.960434 26473 solver.cpp:242] Iteration 162100 (93.0247 iter/s, 1.07498s/100 iter), loss = 0.0461293
I0502 11:36:44.960476 26473 solver.cpp:261]     Train net output #0: loss = 0.0461293 (* 1 = 0.0461293 loss)
I0502 11:36:44.960485 26473 sgd_solver.cpp:106] Iteration 162100, lr = 2.81475e-06
I0502 11:36:44.965313 26473 solver.cpp:242] Iteration 162100 (105.856 iter/s, 0.944679s/100 iter), loss = 0.0330313
I0502 11:36:44.965337 26473 solver.cpp:261]     Train net output #0: loss = 0.0330313 (* 1 = 0.0330313 loss)
I0502 11:36:44.965345 26473 sgd_solver.cpp:106] Iteration 162100, lr = 2.81475e-06
I0502 11:36:45.904177 26473 solver.cpp:242] Iteration 162200 (105.969 iter/s, 0.943672s/100 iter), loss = 0.106264
I0502 11:36:45.904209 26473 solver.cpp:261]     Train net output #0: loss = 0.106264 (* 1 = 0.106264 loss)
I0502 11:36:45.904218 26473 sgd_solver.cpp:106] Iteration 162200, lr = 2.81475e-06
I0502 11:36:45.908983 26473 solver.cpp:242] Iteration 162200 (105.974 iter/s, 0.943628s/100 iter), loss = 0.0626918
I0502 11:36:45.909008 26473 solver.cpp:261]     Train net output #0: loss = 0.0626918 (* 1 = 0.0626918 loss)
I0502 11:36:45.909015 26473 sgd_solver.cpp:106] Iteration 162200, lr = 2.81475e-06
I0502 11:36:46.848104 26473 solver.cpp:242] Iteration 162300 (105.947 iter/s, 0.943864s/100 iter), loss = 0.0453529
I0502 11:36:46.848145 26473 solver.cpp:261]     Train net output #0: loss = 0.0453529 (* 1 = 0.0453529 loss)
I0502 11:36:46.848153 26473 sgd_solver.cpp:106] Iteration 162300, lr = 2.81475e-06
I0502 11:36:46.852921 26473 solver.cpp:242] Iteration 162300 (105.944 iter/s, 0.943897s/100 iter), loss = 0.015459
I0502 11:36:46.852944 26473 solver.cpp:261]     Train net output #0: loss = 0.015459 (* 1 = 0.015459 loss)
I0502 11:36:46.852953 26473 sgd_solver.cpp:106] Iteration 162300, lr = 2.81475e-06
I0502 11:36:47.792497 26473 solver.cpp:242] Iteration 162400 (105.896 iter/s, 0.944325s/100 iter), loss = 0.0766995
I0502 11:36:47.792541 26473 solver.cpp:261]     Train net output #0: loss = 0.0766995 (* 1 = 0.0766995 loss)
I0502 11:36:47.792549 26473 sgd_solver.cpp:106] Iteration 162400, lr = 2.81475e-06
I0502 11:36:47.797329 26473 solver.cpp:242] Iteration 162400 (105.891 iter/s, 0.944367s/100 iter), loss = 0.125992
I0502 11:36:47.797351 26473 solver.cpp:261]     Train net output #0: loss = 0.125992 (* 1 = 0.125992 loss)
I0502 11:36:47.797360 26473 sgd_solver.cpp:106] Iteration 162400, lr = 2.81475e-06
I0502 11:36:48.733840 26473 solver.cpp:362] Iteration 162500, Testing net (#0)
I0502 11:36:48.733868 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:48.858052 26473 solver.cpp:429]     Test net output #0: loss = 0.269215 (* 1 = 0.269215 loss)
I0502 11:36:48.860896 26473 solver.cpp:242] Iteration 162500 (93.6033 iter/s, 1.06834s/100 iter), loss = 0.120382
I0502 11:36:48.860916 26473 solver.cpp:261]     Train net output #0: loss = 0.120382 (* 1 = 0.120382 loss)
I0502 11:36:48.860925 26473 sgd_solver.cpp:106] Iteration 162500, lr = 2.81475e-06
I0502 11:36:48.862545 26473 solver.cpp:362] Iteration 162500, Testing net (#0)
I0502 11:36:48.862558 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:48.993057 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:36:48.993077 26473 solver.cpp:429]     Test net output #1: loss = 0.0850742 (* 1 = 0.0850742 loss)
I0502 11:36:48.996009 26473 solver.cpp:242] Iteration 162500 (83.4282 iter/s, 1.19864s/100 iter), loss = 0.0265812
I0502 11:36:48.996028 26473 solver.cpp:261]     Train net output #0: loss = 0.0265812 (* 1 = 0.0265812 loss)
I0502 11:36:48.996037 26473 sgd_solver.cpp:106] Iteration 162500, lr = 2.81475e-06
I0502 11:36:49.935210 26473 solver.cpp:242] Iteration 162600 (93.0867 iter/s, 1.07427s/100 iter), loss = 0.137548
I0502 11:36:49.935242 26473 solver.cpp:261]     Train net output #0: loss = 0.137548 (* 1 = 0.137548 loss)
I0502 11:36:49.935251 26473 sgd_solver.cpp:106] Iteration 162600, lr = 2.81475e-06
I0502 11:36:49.940091 26473 solver.cpp:242] Iteration 162600 (105.928 iter/s, 0.944037s/100 iter), loss = 0.0213274
I0502 11:36:49.940115 26473 solver.cpp:261]     Train net output #0: loss = 0.0213274 (* 1 = 0.0213274 loss)
I0502 11:36:49.940124 26473 sgd_solver.cpp:106] Iteration 162600, lr = 2.81475e-06
I0502 11:36:50.880604 26473 solver.cpp:242] Iteration 162700 (105.783 iter/s, 0.945331s/100 iter), loss = 0.0561064
I0502 11:36:50.880640 26473 solver.cpp:261]     Train net output #0: loss = 0.0561064 (* 1 = 0.0561064 loss)
I0502 11:36:50.880648 26473 sgd_solver.cpp:106] Iteration 162700, lr = 2.81475e-06
I0502 11:36:50.885401 26473 solver.cpp:242] Iteration 162700 (105.79 iter/s, 0.945268s/100 iter), loss = 0.0867944
I0502 11:36:50.885422 26473 solver.cpp:261]     Train net output #0: loss = 0.0867944 (* 1 = 0.0867944 loss)
I0502 11:36:50.885432 26473 sgd_solver.cpp:106] Iteration 162700, lr = 2.81475e-06
I0502 11:36:51.823849 26473 solver.cpp:242] Iteration 162800 (106.024 iter/s, 0.943181s/100 iter), loss = 0.0618899
I0502 11:36:51.823892 26473 solver.cpp:261]     Train net output #0: loss = 0.0618899 (* 1 = 0.0618899 loss)
I0502 11:36:51.823900 26473 sgd_solver.cpp:106] Iteration 162800, lr = 2.81475e-06
I0502 11:36:51.828656 26473 solver.cpp:242] Iteration 162800 (106.02 iter/s, 0.943216s/100 iter), loss = 0.0729672
I0502 11:36:51.828680 26473 solver.cpp:261]     Train net output #0: loss = 0.0729672 (* 1 = 0.0729672 loss)
I0502 11:36:51.828688 26473 sgd_solver.cpp:106] Iteration 162800, lr = 2.81475e-06
I0502 11:36:52.768396 26473 solver.cpp:242] Iteration 162900 (105.879 iter/s, 0.944476s/100 iter), loss = 0.232061
I0502 11:36:52.768440 26473 solver.cpp:261]     Train net output #0: loss = 0.232061 (* 1 = 0.232061 loss)
I0502 11:36:52.768450 26473 sgd_solver.cpp:106] Iteration 162900, lr = 2.81475e-06
I0502 11:36:52.773219 26473 solver.cpp:242] Iteration 162900 (105.874 iter/s, 0.944522s/100 iter), loss = 0.0848894
I0502 11:36:52.773241 26473 solver.cpp:261]     Train net output #0: loss = 0.0848894 (* 1 = 0.0848894 loss)
I0502 11:36:52.773250 26473 sgd_solver.cpp:106] Iteration 162900, lr = 2.81475e-06
I0502 11:36:53.709435 26473 solver.cpp:362] Iteration 163000, Testing net (#0)
I0502 11:36:53.709462 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:53.833786 26473 solver.cpp:429]     Test net output #0: loss = 0.258716 (* 1 = 0.258716 loss)
I0502 11:36:53.836657 26473 solver.cpp:242] Iteration 163000 (93.6156 iter/s, 1.0682s/100 iter), loss = 0.238853
I0502 11:36:53.836678 26473 solver.cpp:261]     Train net output #0: loss = 0.238853 (* 1 = 0.238853 loss)
I0502 11:36:53.836685 26473 sgd_solver.cpp:106] Iteration 163000, lr = 2.81475e-06
I0502 11:36:53.838317 26473 solver.cpp:362] Iteration 163000, Testing net (#0)
I0502 11:36:53.838330 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:53.968840 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:36:53.968861 26473 solver.cpp:429]     Test net output #1: loss = 0.0846883 (* 1 = 0.0846883 loss)
I0502 11:36:53.971794 26473 solver.cpp:242] Iteration 163000 (83.4354 iter/s, 1.19853s/100 iter), loss = 0.0382007
I0502 11:36:53.971822 26473 solver.cpp:261]     Train net output #0: loss = 0.0382007 (* 1 = 0.0382007 loss)
I0502 11:36:53.971832 26473 sgd_solver.cpp:106] Iteration 163000, lr = 2.81475e-06
I0502 11:36:54.910617 26473 solver.cpp:242] Iteration 163100 (93.1175 iter/s, 1.07391s/100 iter), loss = 0.303548
I0502 11:36:54.910661 26473 solver.cpp:261]     Train net output #0: loss = 0.303548 (* 1 = 0.303548 loss)
I0502 11:36:54.910670 26473 sgd_solver.cpp:106] Iteration 163100, lr = 2.81475e-06
I0502 11:36:54.915535 26473 solver.cpp:242] Iteration 163100 (105.967 iter/s, 0.943687s/100 iter), loss = 0.00887877
I0502 11:36:54.915558 26473 solver.cpp:261]     Train net output #0: loss = 0.00887877 (* 1 = 0.00887877 loss)
I0502 11:36:54.915567 26473 sgd_solver.cpp:106] Iteration 163100, lr = 2.81475e-06
I0502 11:36:55.855118 26473 solver.cpp:242] Iteration 163200 (105.884 iter/s, 0.944427s/100 iter), loss = 0.308075
I0502 11:36:55.855160 26473 solver.cpp:261]     Train net output #0: loss = 0.308075 (* 1 = 0.308075 loss)
I0502 11:36:55.855170 26473 sgd_solver.cpp:106] Iteration 163200, lr = 2.81475e-06
I0502 11:36:55.859941 26473 solver.cpp:242] Iteration 163200 (105.891 iter/s, 0.944364s/100 iter), loss = 0.138192
I0502 11:36:55.859963 26473 solver.cpp:261]     Train net output #0: loss = 0.138192 (* 1 = 0.138192 loss)
I0502 11:36:55.859972 26473 sgd_solver.cpp:106] Iteration 163200, lr = 2.81475e-06
I0502 11:36:56.798130 26473 solver.cpp:242] Iteration 163300 (106.051 iter/s, 0.94294s/100 iter), loss = 0.193345
I0502 11:36:56.798171 26473 solver.cpp:261]     Train net output #0: loss = 0.193345 (* 1 = 0.193345 loss)
I0502 11:36:56.798180 26473 sgd_solver.cpp:106] Iteration 163300, lr = 2.81475e-06
I0502 11:36:56.802953 26473 solver.cpp:242] Iteration 163300 (106.049 iter/s, 0.942962s/100 iter), loss = 0.00874564
I0502 11:36:56.802978 26473 solver.cpp:261]     Train net output #0: loss = 0.00874564 (* 1 = 0.00874564 loss)
I0502 11:36:56.802985 26473 sgd_solver.cpp:106] Iteration 163300, lr = 2.81475e-06
I0502 11:36:57.742667 26473 solver.cpp:242] Iteration 163400 (105.88 iter/s, 0.944468s/100 iter), loss = 0.127052
I0502 11:36:57.742710 26473 solver.cpp:261]     Train net output #0: loss = 0.127052 (* 1 = 0.127052 loss)
I0502 11:36:57.742719 26473 sgd_solver.cpp:106] Iteration 163400, lr = 2.81475e-06
I0502 11:36:57.747462 26473 solver.cpp:242] Iteration 163400 (105.88 iter/s, 0.944468s/100 iter), loss = 0.0063118
I0502 11:36:57.747485 26473 solver.cpp:261]     Train net output #0: loss = 0.0063118 (* 1 = 0.0063118 loss)
I0502 11:36:57.747494 26473 sgd_solver.cpp:106] Iteration 163400, lr = 2.81475e-06
I0502 11:36:58.682966 26473 solver.cpp:362] Iteration 163500, Testing net (#0)
I0502 11:36:58.682992 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:58.807313 26473 solver.cpp:429]     Test net output #0: loss = 0.228262 (* 1 = 0.228262 loss)
I0502 11:36:58.810194 26473 solver.cpp:242] Iteration 163500 (93.6798 iter/s, 1.06747s/100 iter), loss = 0.175878
I0502 11:36:58.810214 26473 solver.cpp:261]     Train net output #0: loss = 0.175878 (* 1 = 0.175878 loss)
I0502 11:36:58.810222 26473 sgd_solver.cpp:106] Iteration 163500, lr = 2.81475e-06
I0502 11:36:58.811838 26473 solver.cpp:362] Iteration 163500, Testing net (#0)
I0502 11:36:58.811852 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:36:58.942509 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:36:58.942530 26473 solver.cpp:429]     Test net output #1: loss = 0.0772625 (* 1 = 0.0772625 loss)
I0502 11:36:58.945456 26473 solver.cpp:242] Iteration 163500 (83.4759 iter/s, 1.19795s/100 iter), loss = 0.0594423
I0502 11:36:58.945475 26473 solver.cpp:261]     Train net output #0: loss = 0.0594423 (* 1 = 0.0594423 loss)
I0502 11:36:58.945484 26473 sgd_solver.cpp:106] Iteration 163500, lr = 2.81475e-06
I0502 11:36:59.884546 26473 solver.cpp:242] Iteration 163600 (93.0835 iter/s, 1.0743s/100 iter), loss = 0.0545585
I0502 11:36:59.884591 26473 solver.cpp:261]     Train net output #0: loss = 0.0545585 (* 1 = 0.0545585 loss)
I0502 11:36:59.884610 26473 sgd_solver.cpp:106] Iteration 163600, lr = 2.81475e-06
I0502 11:36:59.889430 26473 solver.cpp:242] Iteration 163600 (105.94 iter/s, 0.943927s/100 iter), loss = 0.0812593
I0502 11:36:59.889452 26473 solver.cpp:261]     Train net output #0: loss = 0.0812593 (* 1 = 0.0812593 loss)
I0502 11:36:59.889461 26473 sgd_solver.cpp:106] Iteration 163600, lr = 2.81475e-06
I0502 11:37:00.838774 26473 solver.cpp:242] Iteration 163700 (104.805 iter/s, 0.954152s/100 iter), loss = 0.127872
I0502 11:37:00.838816 26473 solver.cpp:261]     Train net output #0: loss = 0.127872 (* 1 = 0.127872 loss)
I0502 11:37:00.838825 26473 sgd_solver.cpp:106] Iteration 163700, lr = 2.81475e-06
I0502 11:37:00.843595 26473 solver.cpp:242] Iteration 163700 (104.808 iter/s, 0.954123s/100 iter), loss = 0.0862007
I0502 11:37:00.843618 26473 solver.cpp:261]     Train net output #0: loss = 0.0862007 (* 1 = 0.0862007 loss)
I0502 11:37:00.843627 26473 sgd_solver.cpp:106] Iteration 163700, lr = 2.81475e-06
I0502 11:37:01.782389 26473 solver.cpp:242] Iteration 163800 (105.983 iter/s, 0.943543s/100 iter), loss = 0.109508
I0502 11:37:01.782426 26473 solver.cpp:261]     Train net output #0: loss = 0.109508 (* 1 = 0.109508 loss)
I0502 11:37:01.782435 26473 sgd_solver.cpp:106] Iteration 163800, lr = 2.81475e-06
I0502 11:37:01.787196 26473 solver.cpp:242] Iteration 163800 (105.982 iter/s, 0.94356s/100 iter), loss = 0.161227
I0502 11:37:01.787220 26473 solver.cpp:261]     Train net output #0: loss = 0.161227 (* 1 = 0.161227 loss)
I0502 11:37:01.787227 26473 sgd_solver.cpp:106] Iteration 163800, lr = 2.81475e-06
I0502 11:37:02.727346 26473 solver.cpp:242] Iteration 163900 (105.832 iter/s, 0.944892s/100 iter), loss = 0.100983
I0502 11:37:02.727387 26473 solver.cpp:261]     Train net output #0: loss = 0.100983 (* 1 = 0.100983 loss)
I0502 11:37:02.727396 26473 sgd_solver.cpp:106] Iteration 163900, lr = 2.81475e-06
I0502 11:37:02.732203 26473 solver.cpp:242] Iteration 163900 (105.824 iter/s, 0.944965s/100 iter), loss = 0.120133
I0502 11:37:02.732225 26473 solver.cpp:261]     Train net output #0: loss = 0.120133 (* 1 = 0.120133 loss)
I0502 11:37:02.732234 26473 sgd_solver.cpp:106] Iteration 163900, lr = 2.81475e-06
I0502 11:37:03.667418 26473 solver.cpp:362] Iteration 164000, Testing net (#0)
I0502 11:37:03.667439 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:03.791767 26473 solver.cpp:429]     Test net output #0: loss = 0.22157 (* 1 = 0.22157 loss)
I0502 11:37:03.794639 26473 solver.cpp:242] Iteration 164000 (93.7001 iter/s, 1.06723s/100 iter), loss = 0.186325
I0502 11:37:03.794659 26473 solver.cpp:261]     Train net output #0: loss = 0.186325 (* 1 = 0.186325 loss)
I0502 11:37:03.794667 26473 sgd_solver.cpp:106] Iteration 164000, lr = 2.81475e-06
I0502 11:37:03.796281 26473 solver.cpp:362] Iteration 164000, Testing net (#0)
I0502 11:37:03.796294 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:03.927006 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:37:03.927027 26473 solver.cpp:429]     Test net output #1: loss = 0.0852493 (* 1 = 0.0852493 loss)
I0502 11:37:03.929945 26473 solver.cpp:242] Iteration 164000 (83.4934 iter/s, 1.1977s/100 iter), loss = 0.113947
I0502 11:37:03.929966 26473 solver.cpp:261]     Train net output #0: loss = 0.113947 (* 1 = 0.113947 loss)
I0502 11:37:03.929975 26473 sgd_solver.cpp:106] Iteration 164000, lr = 2.81475e-06
I0502 11:37:04.869400 26473 solver.cpp:242] Iteration 164100 (93.0483 iter/s, 1.07471s/100 iter), loss = 0.187322
I0502 11:37:04.869438 26473 solver.cpp:261]     Train net output #0: loss = 0.187322 (* 1 = 0.187322 loss)
I0502 11:37:04.869447 26473 sgd_solver.cpp:106] Iteration 164100, lr = 2.81475e-06
I0502 11:37:04.874286 26473 solver.cpp:242] Iteration 164100 (105.899 iter/s, 0.944294s/100 iter), loss = 0.0684998
I0502 11:37:04.874310 26473 solver.cpp:261]     Train net output #0: loss = 0.0684998 (* 1 = 0.0684998 loss)
I0502 11:37:04.874318 26473 sgd_solver.cpp:106] Iteration 164100, lr = 2.81475e-06
I0502 11:37:05.813171 26473 solver.cpp:242] Iteration 164200 (105.965 iter/s, 0.943711s/100 iter), loss = 0.277052
I0502 11:37:05.813218 26473 solver.cpp:261]     Train net output #0: loss = 0.277052 (* 1 = 0.277052 loss)
I0502 11:37:05.813227 26473 sgd_solver.cpp:106] Iteration 164200, lr = 2.81475e-06
I0502 11:37:05.818047 26473 solver.cpp:242] Iteration 164200 (105.964 iter/s, 0.943713s/100 iter), loss = 0.0537047
I0502 11:37:05.818069 26473 solver.cpp:261]     Train net output #0: loss = 0.0537047 (* 1 = 0.0537047 loss)
I0502 11:37:05.818078 26473 sgd_solver.cpp:106] Iteration 164200, lr = 2.81475e-06
I0502 11:37:06.756501 26473 solver.cpp:242] Iteration 164300 (106.016 iter/s, 0.943255s/100 iter), loss = 0.726235
I0502 11:37:06.756532 26473 solver.cpp:261]     Train net output #0: loss = 0.726235 (* 1 = 0.726235 loss)
I0502 11:37:06.756541 26473 sgd_solver.cpp:106] Iteration 164300, lr = 2.81475e-06
I0502 11:37:06.761306 26473 solver.cpp:242] Iteration 164300 (106.02 iter/s, 0.943218s/100 iter), loss = 0.206752
I0502 11:37:06.761327 26473 solver.cpp:261]     Train net output #0: loss = 0.206752 (* 1 = 0.206752 loss)
I0502 11:37:06.761337 26473 sgd_solver.cpp:106] Iteration 164300, lr = 2.81475e-06
I0502 11:37:07.699959 26473 solver.cpp:242] Iteration 164400 (106 iter/s, 0.943397s/100 iter), loss = 0.131856
I0502 11:37:07.700003 26473 solver.cpp:261]     Train net output #0: loss = 0.131856 (* 1 = 0.131856 loss)
I0502 11:37:07.700012 26473 sgd_solver.cpp:106] Iteration 164400, lr = 2.81475e-06
I0502 11:37:07.704758 26473 solver.cpp:242] Iteration 164400 (105.998 iter/s, 0.943412s/100 iter), loss = 0.0311008
I0502 11:37:07.704782 26473 solver.cpp:261]     Train net output #0: loss = 0.0311008 (* 1 = 0.0311008 loss)
I0502 11:37:07.704790 26473 sgd_solver.cpp:106] Iteration 164400, lr = 2.81475e-06
I0502 11:37:08.640473 26473 solver.cpp:362] Iteration 164500, Testing net (#0)
I0502 11:37:08.640503 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:08.764873 26473 solver.cpp:429]     Test net output #0: loss = 0.245252 (* 1 = 0.245252 loss)
I0502 11:37:08.767747 26473 solver.cpp:242] Iteration 164500 (93.657 iter/s, 1.06773s/100 iter), loss = 0.0862662
I0502 11:37:08.767768 26473 solver.cpp:261]     Train net output #0: loss = 0.0862662 (* 1 = 0.0862662 loss)
I0502 11:37:08.767776 26473 sgd_solver.cpp:106] Iteration 164500, lr = 2.81475e-06
I0502 11:37:08.769394 26473 solver.cpp:362] Iteration 164500, Testing net (#0)
I0502 11:37:08.769408 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:08.900228 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:37:08.900252 26473 solver.cpp:429]     Test net output #1: loss = 0.0814125 (* 1 = 0.0814125 loss)
I0502 11:37:08.903197 26473 solver.cpp:242] Iteration 164500 (83.4451 iter/s, 1.19839s/100 iter), loss = 0.0753026
I0502 11:37:08.903216 26473 solver.cpp:261]     Train net output #0: loss = 0.0753026 (* 1 = 0.0753026 loss)
I0502 11:37:08.903225 26473 sgd_solver.cpp:106] Iteration 164500, lr = 2.81475e-06
I0502 11:37:09.862367 26473 solver.cpp:242] Iteration 164600 (91.3599 iter/s, 1.09457s/100 iter), loss = 0.241737
I0502 11:37:09.862399 26473 solver.cpp:261]     Train net output #0: loss = 0.241737 (* 1 = 0.241737 loss)
I0502 11:37:09.862408 26473 sgd_solver.cpp:106] Iteration 164600, lr = 2.81475e-06
I0502 11:37:09.867166 26473 solver.cpp:242] Iteration 164600 (103.742 iter/s, 0.963929s/100 iter), loss = 0.0525007
I0502 11:37:09.867188 26473 solver.cpp:261]     Train net output #0: loss = 0.0525007 (* 1 = 0.0525007 loss)
I0502 11:37:09.867197 26473 sgd_solver.cpp:106] Iteration 164600, lr = 2.81475e-06
I0502 11:37:10.806066 26473 solver.cpp:242] Iteration 164700 (105.972 iter/s, 0.943643s/100 iter), loss = 0.129359
I0502 11:37:10.806097 26473 solver.cpp:261]     Train net output #0: loss = 0.129359 (* 1 = 0.129359 loss)
I0502 11:37:10.806105 26473 sgd_solver.cpp:106] Iteration 164700, lr = 2.81475e-06
I0502 11:37:10.810917 26473 solver.cpp:242] Iteration 164700 (105.965 iter/s, 0.943704s/100 iter), loss = 0.20126
I0502 11:37:10.810940 26473 solver.cpp:261]     Train net output #0: loss = 0.20126 (* 1 = 0.20126 loss)
I0502 11:37:10.810956 26473 sgd_solver.cpp:106] Iteration 164700, lr = 2.81475e-06
I0502 11:37:11.749505 26473 solver.cpp:242] Iteration 164800 (106.002 iter/s, 0.943375s/100 iter), loss = 0.349705
I0502 11:37:11.749548 26473 solver.cpp:261]     Train net output #0: loss = 0.349705 (* 1 = 0.349705 loss)
I0502 11:37:11.749557 26473 sgd_solver.cpp:106] Iteration 164800, lr = 2.81475e-06
I0502 11:37:11.754330 26473 solver.cpp:242] Iteration 164800 (106.003 iter/s, 0.943372s/100 iter), loss = 0.0100134
I0502 11:37:11.754354 26473 solver.cpp:261]     Train net output #0: loss = 0.0100134 (* 1 = 0.0100134 loss)
I0502 11:37:11.754362 26473 sgd_solver.cpp:106] Iteration 164800, lr = 2.81475e-06
I0502 11:37:12.693153 26473 solver.cpp:242] Iteration 164900 (105.98 iter/s, 0.943576s/100 iter), loss = 0.26824
I0502 11:37:12.693195 26473 solver.cpp:261]     Train net output #0: loss = 0.26824 (* 1 = 0.26824 loss)
I0502 11:37:12.693204 26473 sgd_solver.cpp:106] Iteration 164900, lr = 2.81475e-06
I0502 11:37:12.697955 26473 solver.cpp:242] Iteration 164900 (105.979 iter/s, 0.943583s/100 iter), loss = 0.0545564
I0502 11:37:12.697978 26473 solver.cpp:261]     Train net output #0: loss = 0.0545564 (* 1 = 0.0545564 loss)
I0502 11:37:12.697986 26473 sgd_solver.cpp:106] Iteration 164900, lr = 2.81475e-06
I0502 11:37:13.634824 26473 solver.cpp:362] Iteration 165000, Testing net (#0)
I0502 11:37:13.634852 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:13.759239 26473 solver.cpp:429]     Test net output #0: loss = 0.196249 (* 1 = 0.196249 loss)
I0502 11:37:13.762121 26473 solver.cpp:242] Iteration 165000 (93.5535 iter/s, 1.06891s/100 iter), loss = 0.170846
I0502 11:37:13.762142 26473 solver.cpp:261]     Train net output #0: loss = 0.170846 (* 1 = 0.170846 loss)
I0502 11:37:13.762151 26473 sgd_solver.cpp:106] Iteration 165000, lr = 2.81475e-06
I0502 11:37:13.763777 26473 solver.cpp:362] Iteration 165000, Testing net (#0)
I0502 11:37:13.763792 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:13.894587 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:37:13.894609 26473 solver.cpp:429]     Test net output #1: loss = 0.0806612 (* 1 = 0.0806612 loss)
I0502 11:37:13.897521 26473 solver.cpp:242] Iteration 165000 (83.3665 iter/s, 1.19952s/100 iter), loss = 0.0981941
I0502 11:37:13.897541 26473 solver.cpp:261]     Train net output #0: loss = 0.0981941 (* 1 = 0.0981941 loss)
I0502 11:37:13.897548 26473 sgd_solver.cpp:106] Iteration 165000, lr = 2.81475e-06
I0502 11:37:14.837263 26473 solver.cpp:242] Iteration 165100 (93.0154 iter/s, 1.07509s/100 iter), loss = 0.552382
I0502 11:37:14.837304 26473 solver.cpp:261]     Train net output #0: loss = 0.552382 (* 1 = 0.552382 loss)
I0502 11:37:14.837313 26473 sgd_solver.cpp:106] Iteration 165100, lr = 2.81475e-06
I0502 11:37:14.842068 26473 solver.cpp:242] Iteration 165100 (105.875 iter/s, 0.94451s/100 iter), loss = 0.0990196
I0502 11:37:14.842092 26473 solver.cpp:261]     Train net output #0: loss = 0.0990196 (* 1 = 0.0990196 loss)
I0502 11:37:14.842102 26473 sgd_solver.cpp:106] Iteration 165100, lr = 2.81475e-06
I0502 11:37:15.781394 26473 solver.cpp:242] Iteration 165200 (105.925 iter/s, 0.944066s/100 iter), loss = 0.0606796
I0502 11:37:15.781450 26473 solver.cpp:261]     Train net output #0: loss = 0.0606796 (* 1 = 0.0606796 loss)
I0502 11:37:15.781461 26473 sgd_solver.cpp:106] Iteration 165200, lr = 2.81475e-06
I0502 11:37:15.786339 26473 solver.cpp:242] Iteration 165200 (105.907 iter/s, 0.944221s/100 iter), loss = 0.0849383
I0502 11:37:15.786363 26473 solver.cpp:261]     Train net output #0: loss = 0.0849383 (* 1 = 0.0849383 loss)
I0502 11:37:15.786372 26473 sgd_solver.cpp:106] Iteration 165200, lr = 2.81475e-06
I0502 11:37:16.725052 26473 solver.cpp:242] Iteration 165300 (105.98 iter/s, 0.943571s/100 iter), loss = 0.0915114
I0502 11:37:16.725095 26473 solver.cpp:261]     Train net output #0: loss = 0.0915114 (* 1 = 0.0915114 loss)
I0502 11:37:16.725105 26473 sgd_solver.cpp:106] Iteration 165300, lr = 2.81475e-06
I0502 11:37:16.729874 26473 solver.cpp:242] Iteration 165300 (105.989 iter/s, 0.943493s/100 iter), loss = 0.068002
I0502 11:37:16.729897 26473 solver.cpp:261]     Train net output #0: loss = 0.068002 (* 1 = 0.068002 loss)
I0502 11:37:16.729905 26473 sgd_solver.cpp:106] Iteration 165300, lr = 2.81475e-06
I0502 11:37:17.670248 26473 solver.cpp:242] Iteration 165400 (105.806 iter/s, 0.945123s/100 iter), loss = 0.1147
I0502 11:37:17.670289 26473 solver.cpp:261]     Train net output #0: loss = 0.1147 (* 1 = 0.1147 loss)
I0502 11:37:17.670297 26473 sgd_solver.cpp:106] Iteration 165400, lr = 2.81475e-06
I0502 11:37:17.675048 26473 solver.cpp:242] Iteration 165400 (105.805 iter/s, 0.945134s/100 iter), loss = 0.0894788
I0502 11:37:17.675072 26473 solver.cpp:261]     Train net output #0: loss = 0.0894788 (* 1 = 0.0894788 loss)
I0502 11:37:17.675081 26473 sgd_solver.cpp:106] Iteration 165400, lr = 2.81475e-06
I0502 11:37:18.611300 26473 solver.cpp:362] Iteration 165500, Testing net (#0)
I0502 11:37:18.611325 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:18.735584 26473 solver.cpp:429]     Test net output #0: loss = 0.213758 (* 1 = 0.213758 loss)
I0502 11:37:18.738466 26473 solver.cpp:242] Iteration 165500 (93.6189 iter/s, 1.06816s/100 iter), loss = 0.0875895
I0502 11:37:18.738487 26473 solver.cpp:261]     Train net output #0: loss = 0.0875895 (* 1 = 0.0875895 loss)
I0502 11:37:18.738495 26473 sgd_solver.cpp:106] Iteration 165500, lr = 2.81475e-06
I0502 11:37:18.740114 26473 solver.cpp:362] Iteration 165500, Testing net (#0)
I0502 11:37:18.740128 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:18.870551 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:37:18.870571 26473 solver.cpp:429]     Test net output #1: loss = 0.0742779 (* 1 = 0.0742779 loss)
I0502 11:37:18.873497 26473 solver.cpp:242] Iteration 165500 (83.4443 iter/s, 1.1984s/100 iter), loss = 0.0478258
I0502 11:37:18.873517 26473 solver.cpp:261]     Train net output #0: loss = 0.0478258 (* 1 = 0.0478258 loss)
I0502 11:37:18.873525 26473 sgd_solver.cpp:106] Iteration 165500, lr = 2.81475e-06
I0502 11:37:19.812155 26473 solver.cpp:242] Iteration 165600 (93.1411 iter/s, 1.07364s/100 iter), loss = 0.108943
I0502 11:37:19.812196 26473 solver.cpp:261]     Train net output #0: loss = 0.108943 (* 1 = 0.108943 loss)
I0502 11:37:19.812206 26473 sgd_solver.cpp:106] Iteration 165600, lr = 2.81475e-06
I0502 11:37:19.817000 26473 solver.cpp:242] Iteration 165600 (105.992 iter/s, 0.943465s/100 iter), loss = 0.120802
I0502 11:37:19.817023 26473 solver.cpp:261]     Train net output #0: loss = 0.120802 (* 1 = 0.120802 loss)
I0502 11:37:19.817031 26473 sgd_solver.cpp:106] Iteration 165600, lr = 2.81475e-06
I0502 11:37:20.757570 26473 solver.cpp:242] Iteration 165700 (105.781 iter/s, 0.94535s/100 iter), loss = 0.252169
I0502 11:37:20.757611 26473 solver.cpp:261]     Train net output #0: loss = 0.252169 (* 1 = 0.252169 loss)
I0502 11:37:20.757621 26473 sgd_solver.cpp:106] Iteration 165700, lr = 2.81475e-06
I0502 11:37:20.762475 26473 solver.cpp:242] Iteration 165700 (105.772 iter/s, 0.945425s/100 iter), loss = 0.065207
I0502 11:37:20.762498 26473 solver.cpp:261]     Train net output #0: loss = 0.065207 (* 1 = 0.065207 loss)
I0502 11:37:20.762506 26473 sgd_solver.cpp:106] Iteration 165700, lr = 2.81475e-06
I0502 11:37:21.701483 26473 solver.cpp:242] Iteration 165800 (105.95 iter/s, 0.943838s/100 iter), loss = 0.295614
I0502 11:37:21.701524 26473 solver.cpp:261]     Train net output #0: loss = 0.295614 (* 1 = 0.295614 loss)
I0502 11:37:21.701532 26473 sgd_solver.cpp:106] Iteration 165800, lr = 2.81475e-06
I0502 11:37:21.706346 26473 solver.cpp:242] Iteration 165800 (105.951 iter/s, 0.943829s/100 iter), loss = 0.113569
I0502 11:37:21.706368 26473 solver.cpp:261]     Train net output #0: loss = 0.113569 (* 1 = 0.113569 loss)
I0502 11:37:21.706377 26473 sgd_solver.cpp:106] Iteration 165800, lr = 2.81475e-06
I0502 11:37:22.645395 26473 solver.cpp:242] Iteration 165900 (105.95 iter/s, 0.943843s/100 iter), loss = 0.401237
I0502 11:37:22.645442 26473 solver.cpp:261]     Train net output #0: loss = 0.401237 (* 1 = 0.401237 loss)
I0502 11:37:22.645450 26473 sgd_solver.cpp:106] Iteration 165900, lr = 2.81475e-06
I0502 11:37:22.650243 26473 solver.cpp:242] Iteration 165900 (105.948 iter/s, 0.943857s/100 iter), loss = 0.0952855
I0502 11:37:22.650266 26473 solver.cpp:261]     Train net output #0: loss = 0.0952855 (* 1 = 0.0952855 loss)
I0502 11:37:22.650275 26473 sgd_solver.cpp:106] Iteration 165900, lr = 2.81475e-06
I0502 11:37:23.587389 26473 solver.cpp:362] Iteration 166000, Testing net (#0)
I0502 11:37:23.587410 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:23.711777 26473 solver.cpp:429]     Test net output #0: loss = 0.230144 (* 1 = 0.230144 loss)
I0502 11:37:23.714665 26473 solver.cpp:242] Iteration 166000 (93.5273 iter/s, 1.06921s/100 iter), loss = 0.266179
I0502 11:37:23.714685 26473 solver.cpp:261]     Train net output #0: loss = 0.266179 (* 1 = 0.266179 loss)
I0502 11:37:23.714694 26473 sgd_solver.cpp:106] Iteration 166000, lr = 2.81475e-06
I0502 11:37:23.716305 26473 solver.cpp:362] Iteration 166000, Testing net (#0)
I0502 11:37:23.716318 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:23.847105 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:37:23.847132 26473 solver.cpp:429]     Test net output #1: loss = 0.079605 (* 1 = 0.079605 loss)
I0502 11:37:23.850061 26473 solver.cpp:242] Iteration 166000 (83.3491 iter/s, 1.19977s/100 iter), loss = 0.0894495
I0502 11:37:23.850081 26473 solver.cpp:261]     Train net output #0: loss = 0.0894495 (* 1 = 0.0894495 loss)
I0502 11:37:23.850090 26473 sgd_solver.cpp:106] Iteration 166000, lr = 2.81475e-06
I0502 11:37:24.790105 26473 solver.cpp:242] Iteration 166100 (92.9895 iter/s, 1.07539s/100 iter), loss = 0.0386963
I0502 11:37:24.790141 26473 solver.cpp:261]     Train net output #0: loss = 0.0386963 (* 1 = 0.0386963 loss)
I0502 11:37:24.790150 26473 sgd_solver.cpp:106] Iteration 166100, lr = 2.81475e-06
I0502 11:37:24.794890 26473 solver.cpp:242] Iteration 166100 (105.844 iter/s, 0.944791s/100 iter), loss = 0.0595936
I0502 11:37:24.794914 26473 solver.cpp:261]     Train net output #0: loss = 0.0595936 (* 1 = 0.0595936 loss)
I0502 11:37:24.794921 26473 sgd_solver.cpp:106] Iteration 166100, lr = 2.81475e-06
I0502 11:37:25.734475 26473 solver.cpp:242] Iteration 166200 (105.897 iter/s, 0.94431s/100 iter), loss = 0.494651
I0502 11:37:25.734510 26473 solver.cpp:261]     Train net output #0: loss = 0.494651 (* 1 = 0.494651 loss)
I0502 11:37:25.734519 26473 sgd_solver.cpp:106] Iteration 166200, lr = 2.81475e-06
I0502 11:37:25.739339 26473 solver.cpp:242] Iteration 166200 (105.887 iter/s, 0.9444s/100 iter), loss = 0.0509945
I0502 11:37:25.739362 26473 solver.cpp:261]     Train net output #0: loss = 0.0509945 (* 1 = 0.0509945 loss)
I0502 11:37:25.739370 26473 sgd_solver.cpp:106] Iteration 166200, lr = 2.81475e-06
I0502 11:37:26.679527 26473 solver.cpp:242] Iteration 166300 (105.822 iter/s, 0.944985s/100 iter), loss = 0.362338
I0502 11:37:26.679564 26473 solver.cpp:261]     Train net output #0: loss = 0.362338 (* 1 = 0.362338 loss)
I0502 11:37:26.679572 26473 sgd_solver.cpp:106] Iteration 166300, lr = 2.81475e-06
I0502 11:37:26.684334 26473 solver.cpp:242] Iteration 166300 (105.825 iter/s, 0.944953s/100 iter), loss = 0.0421791
I0502 11:37:26.684356 26473 solver.cpp:261]     Train net output #0: loss = 0.0421791 (* 1 = 0.0421791 loss)
I0502 11:37:26.684365 26473 sgd_solver.cpp:106] Iteration 166300, lr = 2.81475e-06
I0502 11:37:27.623841 26473 solver.cpp:242] Iteration 166400 (105.904 iter/s, 0.944249s/100 iter), loss = 0.683605
I0502 11:37:27.623870 26473 solver.cpp:261]     Train net output #0: loss = 0.683605 (* 1 = 0.683605 loss)
I0502 11:37:27.623879 26473 sgd_solver.cpp:106] Iteration 166400, lr = 2.81475e-06
I0502 11:37:27.628644 26473 solver.cpp:242] Iteration 166400 (105.902 iter/s, 0.94427s/100 iter), loss = 0.0708691
I0502 11:37:27.628667 26473 solver.cpp:261]     Train net output #0: loss = 0.0708691 (* 1 = 0.0708691 loss)
I0502 11:37:27.628675 26473 sgd_solver.cpp:106] Iteration 166400, lr = 2.81475e-06
I0502 11:37:28.564570 26473 solver.cpp:362] Iteration 166500, Testing net (#0)
I0502 11:37:28.564599 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:28.688863 26473 solver.cpp:429]     Test net output #0: loss = 0.209455 (* 1 = 0.209455 loss)
I0502 11:37:28.691735 26473 solver.cpp:242] Iteration 166500 (93.6466 iter/s, 1.06784s/100 iter), loss = 0.0340752
I0502 11:37:28.691754 26473 solver.cpp:261]     Train net output #0: loss = 0.0340752 (* 1 = 0.0340752 loss)
I0502 11:37:28.691762 26473 sgd_solver.cpp:106] Iteration 166500, lr = 2.81475e-06
I0502 11:37:28.693393 26473 solver.cpp:362] Iteration 166500, Testing net (#0)
I0502 11:37:28.693406 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:28.824136 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:37:28.824156 26473 solver.cpp:429]     Test net output #1: loss = 0.0782156 (* 1 = 0.0782156 loss)
I0502 11:37:28.827082 26473 solver.cpp:242] Iteration 166500 (83.445 iter/s, 1.19839s/100 iter), loss = 0.0504492
I0502 11:37:28.827102 26473 solver.cpp:261]     Train net output #0: loss = 0.0504492 (* 1 = 0.0504492 loss)
I0502 11:37:28.827111 26473 sgd_solver.cpp:106] Iteration 166500, lr = 2.81475e-06
I0502 11:37:29.765666 26473 solver.cpp:242] Iteration 166600 (93.12 iter/s, 1.07388s/100 iter), loss = 0.0582673
I0502 11:37:29.765697 26473 solver.cpp:261]     Train net output #0: loss = 0.0582673 (* 1 = 0.0582673 loss)
I0502 11:37:29.765705 26473 sgd_solver.cpp:106] Iteration 166600, lr = 2.81475e-06
I0502 11:37:29.770470 26473 solver.cpp:242] Iteration 166600 (106.005 iter/s, 0.94335s/100 iter), loss = 0.0573746
I0502 11:37:29.770493 26473 solver.cpp:261]     Train net output #0: loss = 0.0573746 (* 1 = 0.0573746 loss)
I0502 11:37:29.770501 26473 sgd_solver.cpp:106] Iteration 166600, lr = 2.81475e-06
I0502 11:37:30.709455 26473 solver.cpp:242] Iteration 166700 (105.962 iter/s, 0.943734s/100 iter), loss = 0.415747
I0502 11:37:30.709484 26473 solver.cpp:261]     Train net output #0: loss = 0.415747 (* 1 = 0.415747 loss)
I0502 11:37:30.709493 26473 sgd_solver.cpp:106] Iteration 166700, lr = 2.81475e-06
I0502 11:37:30.714426 26473 solver.cpp:242] Iteration 166700 (105.943 iter/s, 0.943906s/100 iter), loss = 0.135549
I0502 11:37:30.714448 26473 solver.cpp:261]     Train net output #0: loss = 0.135549 (* 1 = 0.135549 loss)
I0502 11:37:30.714457 26473 sgd_solver.cpp:106] Iteration 166700, lr = 2.81475e-06
I0502 11:37:31.653271 26473 solver.cpp:242] Iteration 166800 (105.959 iter/s, 0.943761s/100 iter), loss = 0.120957
I0502 11:37:31.653328 26473 solver.cpp:261]     Train net output #0: loss = 0.120957 (* 1 = 0.120957 loss)
I0502 11:37:31.653338 26473 sgd_solver.cpp:106] Iteration 166800, lr = 2.81475e-06
I0502 11:37:31.658231 26473 solver.cpp:242] Iteration 166800 (105.959 iter/s, 0.943759s/100 iter), loss = 0.0190031
I0502 11:37:31.658254 26473 solver.cpp:261]     Train net output #0: loss = 0.0190031 (* 1 = 0.0190031 loss)
I0502 11:37:31.658263 26473 sgd_solver.cpp:106] Iteration 166800, lr = 2.81475e-06
I0502 11:37:32.597995 26473 solver.cpp:242] Iteration 166900 (105.861 iter/s, 0.944635s/100 iter), loss = 0.0332709
I0502 11:37:32.598037 26473 solver.cpp:261]     Train net output #0: loss = 0.0332709 (* 1 = 0.0332709 loss)
I0502 11:37:32.598047 26473 sgd_solver.cpp:106] Iteration 166900, lr = 2.81475e-06
I0502 11:37:32.602814 26473 solver.cpp:242] Iteration 166900 (105.871 iter/s, 0.944542s/100 iter), loss = 0.199153
I0502 11:37:32.602836 26473 solver.cpp:261]     Train net output #0: loss = 0.199153 (* 1 = 0.199153 loss)
I0502 11:37:32.602845 26473 sgd_solver.cpp:106] Iteration 166900, lr = 2.81475e-06
I0502 11:37:33.538666 26473 solver.cpp:362] Iteration 167000, Testing net (#0)
I0502 11:37:33.538693 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:33.663070 26473 solver.cpp:429]     Test net output #0: loss = 0.221914 (* 1 = 0.221914 loss)
I0502 11:37:33.665942 26473 solver.cpp:242] Iteration 167000 (93.6428 iter/s, 1.06789s/100 iter), loss = 0.0957441
I0502 11:37:33.665971 26473 solver.cpp:261]     Train net output #0: loss = 0.0957441 (* 1 = 0.0957441 loss)
I0502 11:37:33.665980 26473 sgd_solver.cpp:106] Iteration 167000, lr = 2.81475e-06
I0502 11:37:33.667601 26473 solver.cpp:362] Iteration 167000, Testing net (#0)
I0502 11:37:33.667614 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:33.798436 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:37:33.798458 26473 solver.cpp:429]     Test net output #1: loss = 0.0878159 (* 1 = 0.0878159 loss)
I0502 11:37:33.801375 26473 solver.cpp:242] Iteration 167000 (83.4364 iter/s, 1.19852s/100 iter), loss = 0.0961971
I0502 11:37:33.801395 26473 solver.cpp:261]     Train net output #0: loss = 0.0961971 (* 1 = 0.0961971 loss)
I0502 11:37:33.801403 26473 sgd_solver.cpp:106] Iteration 167000, lr = 2.81475e-06
I0502 11:37:34.741276 26473 solver.cpp:242] Iteration 167100 (92.9996 iter/s, 1.07527s/100 iter), loss = 0.416481
I0502 11:37:34.741320 26473 solver.cpp:261]     Train net output #0: loss = 0.416481 (* 1 = 0.416481 loss)
I0502 11:37:34.741329 26473 sgd_solver.cpp:106] Iteration 167100, lr = 2.81475e-06
I0502 11:37:34.746089 26473 solver.cpp:242] Iteration 167100 (105.856 iter/s, 0.944676s/100 iter), loss = 0.103332
I0502 11:37:34.746112 26473 solver.cpp:261]     Train net output #0: loss = 0.103332 (* 1 = 0.103332 loss)
I0502 11:37:34.746120 26473 sgd_solver.cpp:106] Iteration 167100, lr = 2.81475e-06
I0502 11:37:35.685091 26473 solver.cpp:242] Iteration 167200 (105.961 iter/s, 0.943745s/100 iter), loss = 0.221422
I0502 11:37:35.685133 26473 solver.cpp:261]     Train net output #0: loss = 0.221422 (* 1 = 0.221422 loss)
I0502 11:37:35.685142 26473 sgd_solver.cpp:106] Iteration 167200, lr = 2.81475e-06
I0502 11:37:35.689976 26473 solver.cpp:242] Iteration 167200 (105.95 iter/s, 0.943837s/100 iter), loss = 0.0222113
I0502 11:37:35.689999 26473 solver.cpp:261]     Train net output #0: loss = 0.0222113 (* 1 = 0.0222113 loss)
I0502 11:37:35.690007 26473 sgd_solver.cpp:106] Iteration 167200, lr = 2.81475e-06
I0502 11:37:36.629315 26473 solver.cpp:242] Iteration 167300 (105.915 iter/s, 0.944158s/100 iter), loss = 0.381834
I0502 11:37:36.629360 26473 solver.cpp:261]     Train net output #0: loss = 0.381834 (* 1 = 0.381834 loss)
I0502 11:37:36.629369 26473 sgd_solver.cpp:106] Iteration 167300, lr = 2.81475e-06
I0502 11:37:36.634177 26473 solver.cpp:242] Iteration 167300 (105.915 iter/s, 0.944153s/100 iter), loss = 0.119935
I0502 11:37:36.634201 26473 solver.cpp:261]     Train net output #0: loss = 0.119935 (* 1 = 0.119935 loss)
I0502 11:37:36.634209 26473 sgd_solver.cpp:106] Iteration 167300, lr = 2.81475e-06
I0502 11:37:37.573384 26473 solver.cpp:242] Iteration 167400 (105.933 iter/s, 0.943993s/100 iter), loss = 0.0818124
I0502 11:37:37.573426 26473 solver.cpp:261]     Train net output #0: loss = 0.0818124 (* 1 = 0.0818124 loss)
I0502 11:37:37.573434 26473 sgd_solver.cpp:106] Iteration 167400, lr = 2.81475e-06
I0502 11:37:37.578193 26473 solver.cpp:242] Iteration 167400 (105.935 iter/s, 0.943975s/100 iter), loss = 0.0527989
I0502 11:37:37.578217 26473 solver.cpp:261]     Train net output #0: loss = 0.0527989 (* 1 = 0.0527989 loss)
I0502 11:37:37.578225 26473 sgd_solver.cpp:106] Iteration 167400, lr = 2.81475e-06
I0502 11:37:38.514533 26473 solver.cpp:362] Iteration 167500, Testing net (#0)
I0502 11:37:38.514560 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:38.638820 26473 solver.cpp:429]     Test net output #0: loss = 0.23871 (* 1 = 0.23871 loss)
I0502 11:37:38.641718 26473 solver.cpp:242] Iteration 167500 (93.6088 iter/s, 1.06828s/100 iter), loss = 0.332237
I0502 11:37:38.641738 26473 solver.cpp:261]     Train net output #0: loss = 0.332237 (* 1 = 0.332237 loss)
I0502 11:37:38.641747 26473 sgd_solver.cpp:106] Iteration 167500, lr = 2.81475e-06
I0502 11:37:38.643363 26473 solver.cpp:362] Iteration 167500, Testing net (#0)
I0502 11:37:38.643376 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:38.774075 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:37:38.774104 26473 solver.cpp:429]     Test net output #1: loss = 0.0869449 (* 1 = 0.0869449 loss)
I0502 11:37:38.777041 26473 solver.cpp:242] Iteration 167500 (83.4165 iter/s, 1.1988s/100 iter), loss = 0.120669
I0502 11:37:38.777062 26473 solver.cpp:261]     Train net output #0: loss = 0.120669 (* 1 = 0.120669 loss)
I0502 11:37:38.777070 26473 sgd_solver.cpp:106] Iteration 167500, lr = 2.81475e-06
I0502 11:37:39.716212 26473 solver.cpp:242] Iteration 167600 (93.0715 iter/s, 1.07444s/100 iter), loss = 0.0667808
I0502 11:37:39.716253 26473 solver.cpp:261]     Train net output #0: loss = 0.0667808 (* 1 = 0.0667808 loss)
I0502 11:37:39.716262 26473 sgd_solver.cpp:106] Iteration 167600, lr = 2.81475e-06
I0502 11:37:39.721036 26473 solver.cpp:242] Iteration 167600 (105.937 iter/s, 0.943955s/100 iter), loss = 0.169006
I0502 11:37:39.721060 26473 solver.cpp:261]     Train net output #0: loss = 0.169006 (* 1 = 0.169006 loss)
I0502 11:37:39.721067 26473 sgd_solver.cpp:106] Iteration 167600, lr = 2.81475e-06
I0502 11:37:40.659566 26473 solver.cpp:242] Iteration 167700 (106.012 iter/s, 0.943287s/100 iter), loss = 0.161874
I0502 11:37:40.659606 26473 solver.cpp:261]     Train net output #0: loss = 0.161874 (* 1 = 0.161874 loss)
I0502 11:37:40.659615 26473 sgd_solver.cpp:106] Iteration 167700, lr = 2.81475e-06
I0502 11:37:40.664374 26473 solver.cpp:242] Iteration 167700 (106.011 iter/s, 0.943298s/100 iter), loss = 0.103002
I0502 11:37:40.664397 26473 solver.cpp:261]     Train net output #0: loss = 0.103002 (* 1 = 0.103002 loss)
I0502 11:37:40.664405 26473 sgd_solver.cpp:106] Iteration 167700, lr = 2.81475e-06
I0502 11:37:41.602726 26473 solver.cpp:242] Iteration 167800 (106.034 iter/s, 0.943097s/100 iter), loss = 0.0794639
I0502 11:37:41.602766 26473 solver.cpp:261]     Train net output #0: loss = 0.0794639 (* 1 = 0.0794639 loss)
I0502 11:37:41.602776 26473 sgd_solver.cpp:106] Iteration 167800, lr = 2.81475e-06
I0502 11:37:41.607604 26473 solver.cpp:242] Iteration 167800 (106.024 iter/s, 0.943181s/100 iter), loss = 0.0397788
I0502 11:37:41.607627 26473 solver.cpp:261]     Train net output #0: loss = 0.0397788 (* 1 = 0.0397788 loss)
I0502 11:37:41.607635 26473 sgd_solver.cpp:106] Iteration 167800, lr = 2.81475e-06
I0502 11:37:42.547608 26473 solver.cpp:242] Iteration 167900 (105.841 iter/s, 0.94481s/100 iter), loss = 0.0680136
I0502 11:37:42.547647 26473 solver.cpp:261]     Train net output #0: loss = 0.0680136 (* 1 = 0.0680136 loss)
I0502 11:37:42.547657 26473 sgd_solver.cpp:106] Iteration 167900, lr = 2.81475e-06
I0502 11:37:42.552418 26473 solver.cpp:242] Iteration 167900 (105.846 iter/s, 0.944773s/100 iter), loss = 0.0645406
I0502 11:37:42.552441 26473 solver.cpp:261]     Train net output #0: loss = 0.0645406 (* 1 = 0.0645406 loss)
I0502 11:37:42.552449 26473 sgd_solver.cpp:106] Iteration 167900, lr = 2.81475e-06
I0502 11:37:43.487484 26473 solver.cpp:362] Iteration 168000, Testing net (#0)
I0502 11:37:43.487506 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:43.611713 26473 solver.cpp:429]     Test net output #0: loss = 0.195839 (* 1 = 0.195839 loss)
I0502 11:37:43.614594 26473 solver.cpp:242] Iteration 168000 (93.727 iter/s, 1.06693s/100 iter), loss = 0.131428
I0502 11:37:43.614614 26473 solver.cpp:261]     Train net output #0: loss = 0.131428 (* 1 = 0.131428 loss)
I0502 11:37:43.614624 26473 sgd_solver.cpp:106] Iteration 168000, lr = 2.81475e-06
I0502 11:37:43.616235 26473 solver.cpp:362] Iteration 168000, Testing net (#0)
I0502 11:37:43.616248 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:43.746709 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:37:43.746731 26473 solver.cpp:429]     Test net output #1: loss = 0.0749069 (* 1 = 0.0749069 loss)
I0502 11:37:43.749650 26473 solver.cpp:242] Iteration 168000 (83.5291 iter/s, 1.19719s/100 iter), loss = 0.0970903
I0502 11:37:43.749671 26473 solver.cpp:261]     Train net output #0: loss = 0.0970903 (* 1 = 0.0970903 loss)
I0502 11:37:43.749680 26473 sgd_solver.cpp:106] Iteration 168000, lr = 2.81475e-06
I0502 11:37:44.688804 26473 solver.cpp:242] Iteration 168100 (93.096 iter/s, 1.07416s/100 iter), loss = 0.117862
I0502 11:37:44.688843 26473 solver.cpp:261]     Train net output #0: loss = 0.117862 (* 1 = 0.117862 loss)
I0502 11:37:44.688851 26473 sgd_solver.cpp:106] Iteration 168100, lr = 2.81475e-06
I0502 11:37:44.693612 26473 solver.cpp:242] Iteration 168100 (105.941 iter/s, 0.943923s/100 iter), loss = 0.0451946
I0502 11:37:44.693635 26473 solver.cpp:261]     Train net output #0: loss = 0.0451946 (* 1 = 0.0451946 loss)
I0502 11:37:44.693644 26473 sgd_solver.cpp:106] Iteration 168100, lr = 2.81475e-06
I0502 11:37:45.632789 26473 solver.cpp:242] Iteration 168200 (105.941 iter/s, 0.943923s/100 iter), loss = 0.077769
I0502 11:37:45.632825 26473 solver.cpp:261]     Train net output #0: loss = 0.077769 (* 1 = 0.077769 loss)
I0502 11:37:45.632834 26473 sgd_solver.cpp:106] Iteration 168200, lr = 2.81475e-06
I0502 11:37:45.637612 26473 solver.cpp:242] Iteration 168200 (105.937 iter/s, 0.943959s/100 iter), loss = 0.00102813
I0502 11:37:45.637635 26473 solver.cpp:261]     Train net output #0: loss = 0.00102813 (* 1 = 0.00102813 loss)
I0502 11:37:45.637645 26473 sgd_solver.cpp:106] Iteration 168200, lr = 2.81475e-06
I0502 11:37:46.577672 26473 solver.cpp:242] Iteration 168300 (105.84 iter/s, 0.944822s/100 iter), loss = 0.0777595
I0502 11:37:46.577718 26473 solver.cpp:261]     Train net output #0: loss = 0.0777595 (* 1 = 0.0777595 loss)
I0502 11:37:46.577726 26473 sgd_solver.cpp:106] Iteration 168300, lr = 2.81475e-06
I0502 11:37:46.582578 26473 solver.cpp:242] Iteration 168300 (105.83 iter/s, 0.944915s/100 iter), loss = 0.0723182
I0502 11:37:46.582602 26473 solver.cpp:261]     Train net output #0: loss = 0.0723182 (* 1 = 0.0723182 loss)
I0502 11:37:46.582612 26473 sgd_solver.cpp:106] Iteration 168300, lr = 2.81475e-06
I0502 11:37:47.523311 26473 solver.cpp:242] Iteration 168400 (105.757 iter/s, 0.945565s/100 iter), loss = 0.0372865
I0502 11:37:47.523345 26473 solver.cpp:261]     Train net output #0: loss = 0.0372865 (* 1 = 0.0372865 loss)
I0502 11:37:47.523353 26473 sgd_solver.cpp:106] Iteration 168400, lr = 2.81475e-06
I0502 11:37:47.528117 26473 solver.cpp:242] Iteration 168400 (105.765 iter/s, 0.945496s/100 iter), loss = 0.0597007
I0502 11:37:47.528141 26473 solver.cpp:261]     Train net output #0: loss = 0.0597007 (* 1 = 0.0597007 loss)
I0502 11:37:47.528149 26473 sgd_solver.cpp:106] Iteration 168400, lr = 2.81475e-06
I0502 11:37:48.463912 26473 solver.cpp:362] Iteration 168500, Testing net (#0)
I0502 11:37:48.463932 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:48.588119 26473 solver.cpp:429]     Test net output #0: loss = 0.280362 (* 1 = 0.280362 loss)
I0502 11:37:48.590975 26473 solver.cpp:242] Iteration 168500 (93.667 iter/s, 1.06761s/100 iter), loss = 0.187182
I0502 11:37:48.590994 26473 solver.cpp:261]     Train net output #0: loss = 0.187182 (* 1 = 0.187182 loss)
I0502 11:37:48.591003 26473 sgd_solver.cpp:106] Iteration 168500, lr = 2.81475e-06
I0502 11:37:48.592638 26473 solver.cpp:362] Iteration 168500, Testing net (#0)
I0502 11:37:48.592650 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:48.723312 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:37:48.723332 26473 solver.cpp:429]     Test net output #1: loss = 0.0824855 (* 1 = 0.0824855 loss)
I0502 11:37:48.726260 26473 solver.cpp:242] Iteration 168500 (83.4656 iter/s, 1.1981s/100 iter), loss = 0.137881
I0502 11:37:48.726280 26473 solver.cpp:261]     Train net output #0: loss = 0.137881 (* 1 = 0.137881 loss)
I0502 11:37:48.726289 26473 sgd_solver.cpp:106] Iteration 168500, lr = 2.81475e-06
I0502 11:37:49.664731 26473 solver.cpp:242] Iteration 168600 (93.1353 iter/s, 1.07371s/100 iter), loss = 0.0841654
I0502 11:37:49.664762 26473 solver.cpp:261]     Train net output #0: loss = 0.0841654 (* 1 = 0.0841654 loss)
I0502 11:37:49.664770 26473 sgd_solver.cpp:106] Iteration 168600, lr = 2.81475e-06
I0502 11:37:49.669524 26473 solver.cpp:242] Iteration 168600 (106.019 iter/s, 0.943225s/100 iter), loss = 0.110097
I0502 11:37:49.669548 26473 solver.cpp:261]     Train net output #0: loss = 0.110097 (* 1 = 0.110097 loss)
I0502 11:37:49.669564 26473 sgd_solver.cpp:106] Iteration 168600, lr = 2.81475e-06
I0502 11:37:50.610169 26473 solver.cpp:242] Iteration 168700 (105.777 iter/s, 0.945381s/100 iter), loss = 0.134977
I0502 11:37:50.610213 26473 solver.cpp:261]     Train net output #0: loss = 0.134977 (* 1 = 0.134977 loss)
I0502 11:37:50.610221 26473 sgd_solver.cpp:106] Iteration 168700, lr = 2.81475e-06
I0502 11:37:50.614959 26473 solver.cpp:242] Iteration 168700 (105.776 iter/s, 0.945393s/100 iter), loss = 0.0965855
I0502 11:37:50.614981 26473 solver.cpp:261]     Train net output #0: loss = 0.0965855 (* 1 = 0.0965855 loss)
I0502 11:37:50.614989 26473 sgd_solver.cpp:106] Iteration 168700, lr = 2.81475e-06
I0502 11:37:51.554273 26473 solver.cpp:242] Iteration 168800 (105.929 iter/s, 0.944033s/100 iter), loss = 0.211896
I0502 11:37:51.554314 26473 solver.cpp:261]     Train net output #0: loss = 0.211896 (* 1 = 0.211896 loss)
I0502 11:37:51.554323 26473 sgd_solver.cpp:106] Iteration 168800, lr = 2.81475e-06
I0502 11:37:51.559197 26473 solver.cpp:242] Iteration 168800 (105.911 iter/s, 0.944189s/100 iter), loss = 0.154561
I0502 11:37:51.559221 26473 solver.cpp:261]     Train net output #0: loss = 0.154561 (* 1 = 0.154561 loss)
I0502 11:37:51.559229 26473 sgd_solver.cpp:106] Iteration 168800, lr = 2.81475e-06
I0502 11:37:52.498106 26473 solver.cpp:242] Iteration 168900 (105.959 iter/s, 0.94376s/100 iter), loss = 0.0833255
I0502 11:37:52.498163 26473 solver.cpp:261]     Train net output #0: loss = 0.0833255 (* 1 = 0.0833255 loss)
I0502 11:37:52.498173 26473 sgd_solver.cpp:106] Iteration 168900, lr = 2.81475e-06
I0502 11:37:52.502975 26473 solver.cpp:242] Iteration 168900 (105.962 iter/s, 0.943737s/100 iter), loss = 0.0702059
I0502 11:37:52.503000 26473 solver.cpp:261]     Train net output #0: loss = 0.0702059 (* 1 = 0.0702059 loss)
I0502 11:37:52.503007 26473 sgd_solver.cpp:106] Iteration 168900, lr = 2.81475e-06
I0502 11:37:53.439920 26473 solver.cpp:362] Iteration 169000, Testing net (#0)
I0502 11:37:53.439946 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:53.564573 26473 solver.cpp:429]     Test net output #0: loss = 0.224355 (* 1 = 0.224355 loss)
I0502 11:37:53.567451 26473 solver.cpp:242] Iteration 169000 (93.5217 iter/s, 1.06927s/100 iter), loss = 0.286668
I0502 11:37:53.567471 26473 solver.cpp:261]     Train net output #0: loss = 0.286668 (* 1 = 0.286668 loss)
I0502 11:37:53.567479 26473 sgd_solver.cpp:106] Iteration 169000, lr = 2.81475e-06
I0502 11:37:53.569129 26473 solver.cpp:362] Iteration 169000, Testing net (#0)
I0502 11:37:53.569145 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:53.699901 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9655
I0502 11:37:53.699923 26473 solver.cpp:429]     Test net output #1: loss = 0.0781318 (* 1 = 0.0781318 loss)
I0502 11:37:53.702852 26473 solver.cpp:242] Iteration 169000 (83.3451 iter/s, 1.19983s/100 iter), loss = 0.0855533
I0502 11:37:53.702872 26473 solver.cpp:261]     Train net output #0: loss = 0.0855533 (* 1 = 0.0855533 loss)
I0502 11:37:53.702879 26473 sgd_solver.cpp:106] Iteration 169000, lr = 2.81475e-06
I0502 11:37:54.641522 26473 solver.cpp:242] Iteration 169100 (93.1082 iter/s, 1.07402s/100 iter), loss = 0.091874
I0502 11:37:54.641563 26473 solver.cpp:261]     Train net output #0: loss = 0.091874 (* 1 = 0.091874 loss)
I0502 11:37:54.641572 26473 sgd_solver.cpp:106] Iteration 169100, lr = 2.81475e-06
I0502 11:37:54.646314 26473 solver.cpp:242] Iteration 169100 (105.997 iter/s, 0.943425s/100 iter), loss = 0.00913567
I0502 11:37:54.646337 26473 solver.cpp:261]     Train net output #0: loss = 0.00913567 (* 1 = 0.00913567 loss)
I0502 11:37:54.646347 26473 sgd_solver.cpp:106] Iteration 169100, lr = 2.81475e-06
I0502 11:37:55.585970 26473 solver.cpp:242] Iteration 169200 (105.89 iter/s, 0.944379s/100 iter), loss = 0.144917
I0502 11:37:55.586010 26473 solver.cpp:261]     Train net output #0: loss = 0.144917 (* 1 = 0.144917 loss)
I0502 11:37:55.586019 26473 sgd_solver.cpp:106] Iteration 169200, lr = 2.81475e-06
I0502 11:37:55.590801 26473 solver.cpp:242] Iteration 169200 (105.882 iter/s, 0.944445s/100 iter), loss = 0.0828013
I0502 11:37:55.590826 26473 solver.cpp:261]     Train net output #0: loss = 0.0828013 (* 1 = 0.0828013 loss)
I0502 11:37:55.590834 26473 sgd_solver.cpp:106] Iteration 169200, lr = 2.81475e-06
I0502 11:37:56.529901 26473 solver.cpp:242] Iteration 169300 (105.947 iter/s, 0.943865s/100 iter), loss = 0.255099
I0502 11:37:56.529942 26473 solver.cpp:261]     Train net output #0: loss = 0.255099 (* 1 = 0.255099 loss)
I0502 11:37:56.529950 26473 sgd_solver.cpp:106] Iteration 169300, lr = 2.81475e-06
I0502 11:37:56.534785 26473 solver.cpp:242] Iteration 169300 (105.94 iter/s, 0.943932s/100 iter), loss = 0.0322953
I0502 11:37:56.534808 26473 solver.cpp:261]     Train net output #0: loss = 0.0322953 (* 1 = 0.0322953 loss)
I0502 11:37:56.534817 26473 sgd_solver.cpp:106] Iteration 169300, lr = 2.81475e-06
I0502 11:37:57.474063 26473 solver.cpp:242] Iteration 169400 (105.922 iter/s, 0.944091s/100 iter), loss = 0.0723942
I0502 11:37:57.474104 26473 solver.cpp:261]     Train net output #0: loss = 0.0723942 (* 1 = 0.0723942 loss)
I0502 11:37:57.474113 26473 sgd_solver.cpp:106] Iteration 169400, lr = 2.81475e-06
I0502 11:37:57.478883 26473 solver.cpp:242] Iteration 169400 (105.926 iter/s, 0.944056s/100 iter), loss = 0.106154
I0502 11:37:57.478905 26473 solver.cpp:261]     Train net output #0: loss = 0.106154 (* 1 = 0.106154 loss)
I0502 11:37:57.478914 26473 sgd_solver.cpp:106] Iteration 169400, lr = 2.81475e-06
I0502 11:37:58.415313 26473 solver.cpp:362] Iteration 169500, Testing net (#0)
I0502 11:37:58.415341 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:58.539693 26473 solver.cpp:429]     Test net output #0: loss = 0.24503 (* 1 = 0.24503 loss)
I0502 11:37:58.542562 26473 solver.cpp:242] Iteration 169500 (93.5945 iter/s, 1.06844s/100 iter), loss = 0.0728509
I0502 11:37:58.542582 26473 solver.cpp:261]     Train net output #0: loss = 0.0728509 (* 1 = 0.0728509 loss)
I0502 11:37:58.542589 26473 sgd_solver.cpp:106] Iteration 169500, lr = 2.81475e-06
I0502 11:37:58.544216 26473 solver.cpp:362] Iteration 169500, Testing net (#0)
I0502 11:37:58.544229 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:37:58.674944 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9665
I0502 11:37:58.674967 26473 solver.cpp:429]     Test net output #1: loss = 0.076899 (* 1 = 0.076899 loss)
I0502 11:37:58.677881 26473 solver.cpp:242] Iteration 169500 (83.406 iter/s, 1.19895s/100 iter), loss = 0.0542781
I0502 11:37:58.677901 26473 solver.cpp:261]     Train net output #0: loss = 0.0542781 (* 1 = 0.0542781 loss)
I0502 11:37:58.677909 26473 sgd_solver.cpp:106] Iteration 169500, lr = 2.81475e-06
I0502 11:37:59.617812 26473 solver.cpp:242] Iteration 169600 (93.006 iter/s, 1.0752s/100 iter), loss = 0.234927
I0502 11:37:59.617852 26473 solver.cpp:261]     Train net output #0: loss = 0.234927 (* 1 = 0.234927 loss)
I0502 11:37:59.617861 26473 sgd_solver.cpp:106] Iteration 169600, lr = 2.81475e-06
I0502 11:37:59.622637 26473 solver.cpp:242] Iteration 169600 (105.852 iter/s, 0.944719s/100 iter), loss = 0.127527
I0502 11:37:59.622660 26473 solver.cpp:261]     Train net output #0: loss = 0.127527 (* 1 = 0.127527 loss)
I0502 11:37:59.622668 26473 sgd_solver.cpp:106] Iteration 169600, lr = 2.81475e-06
I0502 11:38:00.573910 26473 solver.cpp:242] Iteration 169700 (104.599 iter/s, 0.956031s/100 iter), loss = 0.162047
I0502 11:38:00.573951 26473 solver.cpp:261]     Train net output #0: loss = 0.162047 (* 1 = 0.162047 loss)
I0502 11:38:00.573959 26473 sgd_solver.cpp:106] Iteration 169700, lr = 2.81475e-06
I0502 11:38:00.578707 26473 solver.cpp:242] Iteration 169700 (104.599 iter/s, 0.956029s/100 iter), loss = 0.0216193
I0502 11:38:00.578730 26473 solver.cpp:261]     Train net output #0: loss = 0.0216193 (* 1 = 0.0216193 loss)
I0502 11:38:00.578739 26473 sgd_solver.cpp:106] Iteration 169700, lr = 2.81475e-06
I0502 11:38:01.518748 26473 solver.cpp:242] Iteration 169800 (105.846 iter/s, 0.944773s/100 iter), loss = 0.0778068
I0502 11:38:01.518795 26473 solver.cpp:261]     Train net output #0: loss = 0.0778068 (* 1 = 0.0778068 loss)
I0502 11:38:01.518805 26473 sgd_solver.cpp:106] Iteration 169800, lr = 2.81475e-06
I0502 11:38:01.523643 26473 solver.cpp:242] Iteration 169800 (105.833 iter/s, 0.944887s/100 iter), loss = 0.114733
I0502 11:38:01.523668 26473 solver.cpp:261]     Train net output #0: loss = 0.114733 (* 1 = 0.114733 loss)
I0502 11:38:01.523675 26473 sgd_solver.cpp:106] Iteration 169800, lr = 2.81475e-06
I0502 11:38:02.463889 26473 solver.cpp:242] Iteration 169900 (105.812 iter/s, 0.945071s/100 iter), loss = 0.255873
I0502 11:38:02.463927 26473 solver.cpp:261]     Train net output #0: loss = 0.255873 (* 1 = 0.255873 loss)
I0502 11:38:02.463935 26473 sgd_solver.cpp:106] Iteration 169900, lr = 2.81475e-06
I0502 11:38:02.468756 26473 solver.cpp:242] Iteration 169900 (105.813 iter/s, 0.945065s/100 iter), loss = 0.00239875
I0502 11:38:02.468780 26473 solver.cpp:261]     Train net output #0: loss = 0.00239875 (* 1 = 0.00239875 loss)
I0502 11:38:02.468788 26473 sgd_solver.cpp:106] Iteration 169900, lr = 2.81475e-06
I0502 11:38:03.404177 26473 solver.cpp:362] Iteration 170000, Testing net (#0)
I0502 11:38:03.404202 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:03.528395 26473 solver.cpp:429]     Test net output #0: loss = 0.23826 (* 1 = 0.23826 loss)
I0502 11:38:03.531292 26473 solver.cpp:242] Iteration 170000 (93.6902 iter/s, 1.06735s/100 iter), loss = 0.224325
I0502 11:38:03.531311 26473 solver.cpp:261]     Train net output #0: loss = 0.224325 (* 1 = 0.224325 loss)
I0502 11:38:03.531321 26473 sgd_solver.cpp:106] Iteration 170000, lr = 2.2518e-06
I0502 11:38:03.532979 26473 solver.cpp:362] Iteration 170000, Testing net (#0)
I0502 11:38:03.532994 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:03.663723 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9705
I0502 11:38:03.663744 26473 solver.cpp:429]     Test net output #1: loss = 0.0696846 (* 1 = 0.0696846 loss)
I0502 11:38:03.666682 26473 solver.cpp:242] Iteration 170000 (83.4808 iter/s, 1.19788s/100 iter), loss = 0.0692791
I0502 11:38:03.666702 26473 solver.cpp:261]     Train net output #0: loss = 0.0692791 (* 1 = 0.0692791 loss)
I0502 11:38:03.666709 26473 sgd_solver.cpp:106] Iteration 170000, lr = 2.2518e-06
I0502 11:38:04.607666 26473 solver.cpp:242] Iteration 170100 (92.909 iter/s, 1.07632s/100 iter), loss = 0.13807
I0502 11:38:04.607703 26473 solver.cpp:261]     Train net output #0: loss = 0.13807 (* 1 = 0.13807 loss)
I0502 11:38:04.607712 26473 sgd_solver.cpp:106] Iteration 170100, lr = 2.2518e-06
I0502 11:38:04.612471 26473 solver.cpp:242] Iteration 170100 (105.736 iter/s, 0.945752s/100 iter), loss = 0.0605884
I0502 11:38:04.612495 26473 solver.cpp:261]     Train net output #0: loss = 0.0605884 (* 1 = 0.0605884 loss)
I0502 11:38:04.612504 26473 sgd_solver.cpp:106] Iteration 170100, lr = 2.2518e-06
I0502 11:38:05.551234 26473 solver.cpp:242] Iteration 170200 (105.988 iter/s, 0.943505s/100 iter), loss = 0.291007
I0502 11:38:05.551268 26473 solver.cpp:261]     Train net output #0: loss = 0.291007 (* 1 = 0.291007 loss)
I0502 11:38:05.551277 26473 sgd_solver.cpp:106] Iteration 170200, lr = 2.2518e-06
I0502 11:38:05.556046 26473 solver.cpp:242] Iteration 170200 (105.985 iter/s, 0.943533s/100 iter), loss = 0.0227
I0502 11:38:05.556069 26473 solver.cpp:261]     Train net output #0: loss = 0.0227 (* 1 = 0.0227 loss)
I0502 11:38:05.556077 26473 sgd_solver.cpp:106] Iteration 170200, lr = 2.2518e-06
I0502 11:38:06.495097 26473 solver.cpp:242] Iteration 170300 (105.955 iter/s, 0.9438s/100 iter), loss = 0.0850031
I0502 11:38:06.495137 26473 solver.cpp:261]     Train net output #0: loss = 0.0850031 (* 1 = 0.0850031 loss)
I0502 11:38:06.495146 26473 sgd_solver.cpp:106] Iteration 170300, lr = 2.2518e-06
I0502 11:38:06.499955 26473 solver.cpp:242] Iteration 170300 (105.947 iter/s, 0.943869s/100 iter), loss = 0.030025
I0502 11:38:06.499979 26473 solver.cpp:261]     Train net output #0: loss = 0.030025 (* 1 = 0.030025 loss)
I0502 11:38:06.499996 26473 sgd_solver.cpp:106] Iteration 170300, lr = 2.2518e-06
I0502 11:38:07.439163 26473 solver.cpp:242] Iteration 170400 (105.932 iter/s, 0.944005s/100 iter), loss = 0.34312
I0502 11:38:07.439196 26473 solver.cpp:261]     Train net output #0: loss = 0.34312 (* 1 = 0.34312 loss)
I0502 11:38:07.439204 26473 sgd_solver.cpp:106] Iteration 170400, lr = 2.2518e-06
I0502 11:38:07.444017 26473 solver.cpp:242] Iteration 170400 (105.931 iter/s, 0.944011s/100 iter), loss = 0.0671315
I0502 11:38:07.444041 26473 solver.cpp:261]     Train net output #0: loss = 0.0671315 (* 1 = 0.0671315 loss)
I0502 11:38:07.444049 26473 sgd_solver.cpp:106] Iteration 170400, lr = 2.2518e-06
I0502 11:38:08.379596 26473 solver.cpp:362] Iteration 170500, Testing net (#0)
I0502 11:38:08.379622 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:08.504323 26473 solver.cpp:429]     Test net output #0: loss = 0.249196 (* 1 = 0.249196 loss)
I0502 11:38:08.507216 26473 solver.cpp:242] Iteration 170500 (93.6329 iter/s, 1.068s/100 iter), loss = 0.125694
I0502 11:38:08.507236 26473 solver.cpp:261]     Train net output #0: loss = 0.125694 (* 1 = 0.125694 loss)
I0502 11:38:08.507246 26473 sgd_solver.cpp:106] Iteration 170500, lr = 2.2518e-06
I0502 11:38:08.508944 26473 solver.cpp:362] Iteration 170500, Testing net (#0)
I0502 11:38:08.508960 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:08.639696 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9545
I0502 11:38:08.639717 26473 solver.cpp:429]     Test net output #1: loss = 0.0912119 (* 1 = 0.0912119 loss)
I0502 11:38:08.642645 26473 solver.cpp:242] Iteration 170500 (83.4318 iter/s, 1.19858s/100 iter), loss = 0.0440011
I0502 11:38:08.642665 26473 solver.cpp:261]     Train net output #0: loss = 0.0440011 (* 1 = 0.0440011 loss)
I0502 11:38:08.642673 26473 sgd_solver.cpp:106] Iteration 170500, lr = 2.2518e-06
I0502 11:38:09.581854 26473 solver.cpp:242] Iteration 170600 (93.0589 iter/s, 1.07459s/100 iter), loss = 0.202331
I0502 11:38:09.581887 26473 solver.cpp:261]     Train net output #0: loss = 0.202331 (* 1 = 0.202331 loss)
I0502 11:38:09.581895 26473 sgd_solver.cpp:106] Iteration 170600, lr = 2.2518e-06
I0502 11:38:09.586642 26473 solver.cpp:242] Iteration 170600 (105.937 iter/s, 0.943958s/100 iter), loss = 0.00193266
I0502 11:38:09.586663 26473 solver.cpp:261]     Train net output #0: loss = 0.00193266 (* 1 = 0.00193266 loss)
I0502 11:38:09.586673 26473 sgd_solver.cpp:106] Iteration 170600, lr = 2.2518e-06
I0502 11:38:10.526543 26473 solver.cpp:242] Iteration 170700 (105.862 iter/s, 0.944629s/100 iter), loss = 0.13284
I0502 11:38:10.526587 26473 solver.cpp:261]     Train net output #0: loss = 0.13284 (* 1 = 0.13284 loss)
I0502 11:38:10.526595 26473 sgd_solver.cpp:106] Iteration 170700, lr = 2.2518e-06
I0502 11:38:10.531354 26473 solver.cpp:242] Iteration 170700 (105.857 iter/s, 0.944672s/100 iter), loss = 0.03763
I0502 11:38:10.531376 26473 solver.cpp:261]     Train net output #0: loss = 0.03763 (* 1 = 0.03763 loss)
I0502 11:38:10.531385 26473 sgd_solver.cpp:106] Iteration 170700, lr = 2.2518e-06
I0502 11:38:11.469657 26473 solver.cpp:242] Iteration 170800 (106.04 iter/s, 0.943045s/100 iter), loss = 0.0916358
I0502 11:38:11.469700 26473 solver.cpp:261]     Train net output #0: loss = 0.0916358 (* 1 = 0.0916358 loss)
I0502 11:38:11.469709 26473 sgd_solver.cpp:106] Iteration 170800, lr = 2.2518e-06
I0502 11:38:11.474452 26473 solver.cpp:242] Iteration 170800 (106.038 iter/s, 0.943058s/100 iter), loss = 0.119756
I0502 11:38:11.474475 26473 solver.cpp:261]     Train net output #0: loss = 0.119756 (* 1 = 0.119756 loss)
I0502 11:38:11.474483 26473 sgd_solver.cpp:106] Iteration 170800, lr = 2.2518e-06
I0502 11:38:12.414525 26473 solver.cpp:242] Iteration 170900 (105.843 iter/s, 0.944798s/100 iter), loss = 0.0867107
I0502 11:38:12.414567 26473 solver.cpp:261]     Train net output #0: loss = 0.0867107 (* 1 = 0.0867107 loss)
I0502 11:38:12.414577 26473 sgd_solver.cpp:106] Iteration 170900, lr = 2.2518e-06
I0502 11:38:12.419423 26473 solver.cpp:242] Iteration 170900 (105.829 iter/s, 0.944922s/100 iter), loss = 0.00446867
I0502 11:38:12.419455 26473 solver.cpp:261]     Train net output #0: loss = 0.00446867 (* 1 = 0.00446867 loss)
I0502 11:38:12.419463 26473 sgd_solver.cpp:106] Iteration 170900, lr = 2.2518e-06
I0502 11:38:13.355079 26473 solver.cpp:362] Iteration 171000, Testing net (#0)
I0502 11:38:13.355123 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:13.479467 26473 solver.cpp:429]     Test net output #0: loss = 0.241427 (* 1 = 0.241427 loss)
I0502 11:38:13.482355 26473 solver.cpp:242] Iteration 171000 (93.6531 iter/s, 1.06777s/100 iter), loss = 0.118492
I0502 11:38:13.482375 26473 solver.cpp:261]     Train net output #0: loss = 0.118492 (* 1 = 0.118492 loss)
I0502 11:38:13.482384 26473 sgd_solver.cpp:106] Iteration 171000, lr = 2.2518e-06
I0502 11:38:13.484004 26473 solver.cpp:362] Iteration 171000, Testing net (#0)
I0502 11:38:13.484016 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:13.614817 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9685
I0502 11:38:13.614843 26473 solver.cpp:429]     Test net output #1: loss = 0.0679265 (* 1 = 0.0679265 loss)
I0502 11:38:13.617765 26473 solver.cpp:242] Iteration 171000 (83.4523 iter/s, 1.19829s/100 iter), loss = 0.0186489
I0502 11:38:13.617785 26473 solver.cpp:261]     Train net output #0: loss = 0.0186489 (* 1 = 0.0186489 loss)
I0502 11:38:13.617794 26473 sgd_solver.cpp:106] Iteration 171000, lr = 2.2518e-06
I0502 11:38:14.556838 26473 solver.cpp:242] Iteration 171100 (93.0724 iter/s, 1.07443s/100 iter), loss = 0.208136
I0502 11:38:14.556872 26473 solver.cpp:261]     Train net output #0: loss = 0.208136 (* 1 = 0.208136 loss)
I0502 11:38:14.556881 26473 sgd_solver.cpp:106] Iteration 171100, lr = 2.2518e-06
I0502 11:38:14.561744 26473 solver.cpp:242] Iteration 171100 (105.939 iter/s, 0.943942s/100 iter), loss = 0.0701359
I0502 11:38:14.561767 26473 solver.cpp:261]     Train net output #0: loss = 0.0701359 (* 1 = 0.0701359 loss)
I0502 11:38:14.561775 26473 sgd_solver.cpp:106] Iteration 171100, lr = 2.2518e-06
I0502 11:38:15.500006 26473 solver.cpp:242] Iteration 171200 (106.033 iter/s, 0.943106s/100 iter), loss = 0.0592627
I0502 11:38:15.500048 26473 solver.cpp:261]     Train net output #0: loss = 0.0592627 (* 1 = 0.0592627 loss)
I0502 11:38:15.500058 26473 sgd_solver.cpp:106] Iteration 171200, lr = 2.2518e-06
I0502 11:38:15.504827 26473 solver.cpp:242] Iteration 171200 (106.04 iter/s, 0.943042s/100 iter), loss = 0.0166478
I0502 11:38:15.504851 26473 solver.cpp:261]     Train net output #0: loss = 0.0166478 (* 1 = 0.0166478 loss)
I0502 11:38:15.504859 26473 sgd_solver.cpp:106] Iteration 171200, lr = 2.2518e-06
I0502 11:38:16.444399 26473 solver.cpp:242] Iteration 171300 (105.896 iter/s, 0.944324s/100 iter), loss = 0.0545596
I0502 11:38:16.444440 26473 solver.cpp:261]     Train net output #0: loss = 0.0545596 (* 1 = 0.0545596 loss)
I0502 11:38:16.444449 26473 sgd_solver.cpp:106] Iteration 171300, lr = 2.2518e-06
I0502 11:38:16.449209 26473 solver.cpp:242] Iteration 171300 (105.894 iter/s, 0.94434s/100 iter), loss = 0.0907951
I0502 11:38:16.449232 26473 solver.cpp:261]     Train net output #0: loss = 0.0907951 (* 1 = 0.0907951 loss)
I0502 11:38:16.449241 26473 sgd_solver.cpp:106] Iteration 171300, lr = 2.2518e-06
I0502 11:38:17.407846 26473 solver.cpp:242] Iteration 171400 (103.801 iter/s, 0.963379s/100 iter), loss = 0.239306
I0502 11:38:17.407892 26473 solver.cpp:261]     Train net output #0: loss = 0.239306 (* 1 = 0.239306 loss)
I0502 11:38:17.407902 26473 sgd_solver.cpp:106] Iteration 171400, lr = 2.2518e-06
I0502 11:38:17.412737 26473 solver.cpp:242] Iteration 171400 (103.791 iter/s, 0.963478s/100 iter), loss = 0.0878514
I0502 11:38:17.412762 26473 solver.cpp:261]     Train net output #0: loss = 0.0878514 (* 1 = 0.0878514 loss)
I0502 11:38:17.412771 26473 sgd_solver.cpp:106] Iteration 171400, lr = 2.2518e-06
I0502 11:38:18.348739 26473 solver.cpp:362] Iteration 171500, Testing net (#0)
I0502 11:38:18.348768 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:18.472952 26473 solver.cpp:429]     Test net output #0: loss = 0.215233 (* 1 = 0.215233 loss)
I0502 11:38:18.475831 26473 solver.cpp:242] Iteration 171500 (93.6398 iter/s, 1.06792s/100 iter), loss = 0.0813829
I0502 11:38:18.475852 26473 solver.cpp:261]     Train net output #0: loss = 0.0813829 (* 1 = 0.0813829 loss)
I0502 11:38:18.475860 26473 sgd_solver.cpp:106] Iteration 171500, lr = 2.2518e-06
I0502 11:38:18.477494 26473 solver.cpp:362] Iteration 171500, Testing net (#0)
I0502 11:38:18.477521 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:18.608191 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9585
I0502 11:38:18.608214 26473 solver.cpp:429]     Test net output #1: loss = 0.0844552 (* 1 = 0.0844552 loss)
I0502 11:38:18.611146 26473 solver.cpp:242] Iteration 171500 (83.4472 iter/s, 1.19836s/100 iter), loss = 0.130134
I0502 11:38:18.611166 26473 solver.cpp:261]     Train net output #0: loss = 0.130134 (* 1 = 0.130134 loss)
I0502 11:38:18.611174 26473 sgd_solver.cpp:106] Iteration 171500, lr = 2.2518e-06
I0502 11:38:19.549986 26473 solver.cpp:242] Iteration 171600 (93.101 iter/s, 1.0741s/100 iter), loss = 0.109983
I0502 11:38:19.550029 26473 solver.cpp:261]     Train net output #0: loss = 0.109983 (* 1 = 0.109983 loss)
I0502 11:38:19.550038 26473 sgd_solver.cpp:106] Iteration 171600, lr = 2.2518e-06
I0502 11:38:19.554816 26473 solver.cpp:242] Iteration 171600 (105.973 iter/s, 0.943632s/100 iter), loss = 0.0343289
I0502 11:38:19.554838 26473 solver.cpp:261]     Train net output #0: loss = 0.0343289 (* 1 = 0.0343289 loss)
I0502 11:38:19.554847 26473 sgd_solver.cpp:106] Iteration 171600, lr = 2.2518e-06
I0502 11:38:20.494042 26473 solver.cpp:242] Iteration 171700 (105.934 iter/s, 0.943985s/100 iter), loss = 0.470358
I0502 11:38:20.494082 26473 solver.cpp:261]     Train net output #0: loss = 0.470358 (* 1 = 0.470358 loss)
I0502 11:38:20.494091 26473 sgd_solver.cpp:106] Iteration 171700, lr = 2.2518e-06
I0502 11:38:20.498859 26473 solver.cpp:242] Iteration 171700 (105.932 iter/s, 0.944002s/100 iter), loss = 0.101629
I0502 11:38:20.498883 26473 solver.cpp:261]     Train net output #0: loss = 0.101629 (* 1 = 0.101629 loss)
I0502 11:38:20.498893 26473 sgd_solver.cpp:106] Iteration 171700, lr = 2.2518e-06
I0502 11:38:21.438555 26473 solver.cpp:242] Iteration 171800 (105.882 iter/s, 0.944447s/100 iter), loss = 0.35441
I0502 11:38:21.438594 26473 solver.cpp:261]     Train net output #0: loss = 0.35441 (* 1 = 0.35441 loss)
I0502 11:38:21.438603 26473 sgd_solver.cpp:106] Iteration 171800, lr = 2.2518e-06
I0502 11:38:21.443356 26473 solver.cpp:242] Iteration 171800 (105.881 iter/s, 0.944455s/100 iter), loss = 0.0403588
I0502 11:38:21.443379 26473 solver.cpp:261]     Train net output #0: loss = 0.0403588 (* 1 = 0.0403588 loss)
I0502 11:38:21.443388 26473 sgd_solver.cpp:106] Iteration 171800, lr = 2.2518e-06
I0502 11:38:22.383478 26473 solver.cpp:242] Iteration 171900 (105.836 iter/s, 0.944859s/100 iter), loss = 0.229003
I0502 11:38:22.383517 26473 solver.cpp:261]     Train net output #0: loss = 0.229003 (* 1 = 0.229003 loss)
I0502 11:38:22.383525 26473 sgd_solver.cpp:106] Iteration 171900, lr = 2.2518e-06
I0502 11:38:22.388355 26473 solver.cpp:242] Iteration 171900 (105.826 iter/s, 0.944948s/100 iter), loss = 0.0963717
I0502 11:38:22.388380 26473 solver.cpp:261]     Train net output #0: loss = 0.0963717 (* 1 = 0.0963717 loss)
I0502 11:38:22.388387 26473 sgd_solver.cpp:106] Iteration 171900, lr = 2.2518e-06
I0502 11:38:23.324349 26473 solver.cpp:362] Iteration 172000, Testing net (#0)
I0502 11:38:23.324374 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:23.448981 26473 solver.cpp:429]     Test net output #0: loss = 0.182772 (* 1 = 0.182772 loss)
I0502 11:38:23.451861 26473 solver.cpp:242] Iteration 172000 (93.6043 iter/s, 1.06833s/100 iter), loss = 0.540328
I0502 11:38:23.451881 26473 solver.cpp:261]     Train net output #0: loss = 0.540328 (* 1 = 0.540328 loss)
I0502 11:38:23.451890 26473 sgd_solver.cpp:106] Iteration 172000, lr = 2.2518e-06
I0502 11:38:23.453585 26473 solver.cpp:362] Iteration 172000, Testing net (#0)
I0502 11:38:23.453604 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:23.584204 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:38:23.584226 26473 solver.cpp:429]     Test net output #1: loss = 0.0795158 (* 1 = 0.0795158 loss)
I0502 11:38:23.587147 26473 solver.cpp:242] Iteration 172000 (83.4204 iter/s, 1.19875s/100 iter), loss = 0.0560265
I0502 11:38:23.587168 26473 solver.cpp:261]     Train net output #0: loss = 0.0560265 (* 1 = 0.0560265 loss)
I0502 11:38:23.587177 26473 sgd_solver.cpp:106] Iteration 172000, lr = 2.2518e-06
I0502 11:38:24.526448 26473 solver.cpp:242] Iteration 172100 (93.0636 iter/s, 1.07453s/100 iter), loss = 0.055613
I0502 11:38:24.526489 26473 solver.cpp:261]     Train net output #0: loss = 0.055613 (* 1 = 0.055613 loss)
I0502 11:38:24.526496 26473 sgd_solver.cpp:106] Iteration 172100, lr = 2.2518e-06
I0502 11:38:24.531273 26473 solver.cpp:242] Iteration 172100 (105.922 iter/s, 0.944087s/100 iter), loss = 0.114655
I0502 11:38:24.531296 26473 solver.cpp:261]     Train net output #0: loss = 0.114655 (* 1 = 0.114655 loss)
I0502 11:38:24.531304 26473 sgd_solver.cpp:106] Iteration 172100, lr = 2.2518e-06
I0502 11:38:25.469952 26473 solver.cpp:242] Iteration 172200 (105.995 iter/s, 0.943437s/100 iter), loss = 0.111274
I0502 11:38:25.469987 26473 solver.cpp:261]     Train net output #0: loss = 0.111274 (* 1 = 0.111274 loss)
I0502 11:38:25.469996 26473 sgd_solver.cpp:106] Iteration 172200, lr = 2.2518e-06
I0502 11:38:25.474756 26473 solver.cpp:242] Iteration 172200 (105.995 iter/s, 0.943443s/100 iter), loss = 0.190446
I0502 11:38:25.474779 26473 solver.cpp:261]     Train net output #0: loss = 0.190446 (* 1 = 0.190446 loss)
I0502 11:38:25.474787 26473 sgd_solver.cpp:106] Iteration 172200, lr = 2.2518e-06
I0502 11:38:26.414733 26473 solver.cpp:242] Iteration 172300 (105.851 iter/s, 0.944721s/100 iter), loss = 0.0986004
I0502 11:38:26.414769 26473 solver.cpp:261]     Train net output #0: loss = 0.0986004 (* 1 = 0.0986004 loss)
I0502 11:38:26.414777 26473 sgd_solver.cpp:106] Iteration 172300, lr = 2.2518e-06
I0502 11:38:26.419520 26473 solver.cpp:242] Iteration 172300 (105.851 iter/s, 0.944724s/100 iter), loss = 0.124034
I0502 11:38:26.419543 26473 solver.cpp:261]     Train net output #0: loss = 0.124034 (* 1 = 0.124034 loss)
I0502 11:38:26.419551 26473 sgd_solver.cpp:106] Iteration 172300, lr = 2.2518e-06
I0502 11:38:27.358712 26473 solver.cpp:242] Iteration 172400 (105.941 iter/s, 0.94392s/100 iter), loss = 0.174595
I0502 11:38:27.358744 26473 solver.cpp:261]     Train net output #0: loss = 0.174595 (* 1 = 0.174595 loss)
I0502 11:38:27.358753 26473 sgd_solver.cpp:106] Iteration 172400, lr = 2.2518e-06
I0502 11:38:27.363579 26473 solver.cpp:242] Iteration 172400 (105.931 iter/s, 0.944009s/100 iter), loss = 0.0161397
I0502 11:38:27.363603 26473 solver.cpp:261]     Train net output #0: loss = 0.0161397 (* 1 = 0.0161397 loss)
I0502 11:38:27.363612 26473 sgd_solver.cpp:106] Iteration 172400, lr = 2.2518e-06
I0502 11:38:28.299813 26473 solver.cpp:362] Iteration 172500, Testing net (#0)
I0502 11:38:28.299834 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:28.424057 26473 solver.cpp:429]     Test net output #0: loss = 0.23334 (* 1 = 0.23334 loss)
I0502 11:38:28.426942 26473 solver.cpp:242] Iteration 172500 (93.6173 iter/s, 1.06818s/100 iter), loss = 0.0476901
I0502 11:38:28.426962 26473 solver.cpp:261]     Train net output #0: loss = 0.0476901 (* 1 = 0.0476901 loss)
I0502 11:38:28.426970 26473 sgd_solver.cpp:106] Iteration 172500, lr = 2.2518e-06
I0502 11:38:28.428673 26473 solver.cpp:362] Iteration 172500, Testing net (#0)
I0502 11:38:28.428686 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:28.559468 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:38:28.559489 26473 solver.cpp:429]     Test net output #1: loss = 0.0923066 (* 1 = 0.0923066 loss)
I0502 11:38:28.562403 26473 solver.cpp:242] Iteration 172500 (83.4182 iter/s, 1.19878s/100 iter), loss = 0.0832419
I0502 11:38:28.562423 26473 solver.cpp:261]     Train net output #0: loss = 0.0832419 (* 1 = 0.0832419 loss)
I0502 11:38:28.562440 26473 sgd_solver.cpp:106] Iteration 172500, lr = 2.2518e-06
I0502 11:38:29.501283 26473 solver.cpp:242] Iteration 172600 (93.0848 iter/s, 1.07429s/100 iter), loss = 0.199084
I0502 11:38:29.501320 26473 solver.cpp:261]     Train net output #0: loss = 0.199084 (* 1 = 0.199084 loss)
I0502 11:38:29.501329 26473 sgd_solver.cpp:106] Iteration 172600, lr = 2.2518e-06
I0502 11:38:29.506095 26473 solver.cpp:242] Iteration 172600 (105.971 iter/s, 0.943653s/100 iter), loss = 0.1797
I0502 11:38:29.506119 26473 solver.cpp:261]     Train net output #0: loss = 0.1797 (* 1 = 0.1797 loss)
I0502 11:38:29.506127 26473 sgd_solver.cpp:106] Iteration 172600, lr = 2.2518e-06
I0502 11:38:30.445704 26473 solver.cpp:242] Iteration 172700 (105.892 iter/s, 0.944356s/100 iter), loss = 0.266519
I0502 11:38:30.445734 26473 solver.cpp:261]     Train net output #0: loss = 0.266519 (* 1 = 0.266519 loss)
I0502 11:38:30.445744 26473 sgd_solver.cpp:106] Iteration 172700, lr = 2.2518e-06
I0502 11:38:30.450495 26473 solver.cpp:242] Iteration 172700 (105.892 iter/s, 0.944358s/100 iter), loss = 0.145059
I0502 11:38:30.450516 26473 solver.cpp:261]     Train net output #0: loss = 0.145059 (* 1 = 0.145059 loss)
I0502 11:38:30.450525 26473 sgd_solver.cpp:106] Iteration 172700, lr = 2.2518e-06
I0502 11:38:31.389274 26473 solver.cpp:242] Iteration 172800 (105.987 iter/s, 0.943512s/100 iter), loss = 0.0656502
I0502 11:38:31.389317 26473 solver.cpp:261]     Train net output #0: loss = 0.0656502 (* 1 = 0.0656502 loss)
I0502 11:38:31.389327 26473 sgd_solver.cpp:106] Iteration 172800, lr = 2.2518e-06
I0502 11:38:31.394079 26473 solver.cpp:242] Iteration 172800 (105.983 iter/s, 0.943544s/100 iter), loss = 0.0601328
I0502 11:38:31.394104 26473 solver.cpp:261]     Train net output #0: loss = 0.0601328 (* 1 = 0.0601328 loss)
I0502 11:38:31.394111 26473 sgd_solver.cpp:106] Iteration 172800, lr = 2.2518e-06
I0502 11:38:32.334635 26473 solver.cpp:242] Iteration 172900 (105.788 iter/s, 0.945291s/100 iter), loss = 0.30709
I0502 11:38:32.334677 26473 solver.cpp:261]     Train net output #0: loss = 0.30709 (* 1 = 0.30709 loss)
I0502 11:38:32.334686 26473 sgd_solver.cpp:106] Iteration 172900, lr = 2.2518e-06
I0502 11:38:32.339454 26473 solver.cpp:242] Iteration 172900 (105.783 iter/s, 0.945333s/100 iter), loss = 0.0288725
I0502 11:38:32.339478 26473 solver.cpp:261]     Train net output #0: loss = 0.0288725 (* 1 = 0.0288725 loss)
I0502 11:38:32.339486 26473 sgd_solver.cpp:106] Iteration 172900, lr = 2.2518e-06
I0502 11:38:33.275516 26473 solver.cpp:362] Iteration 173000, Testing net (#0)
I0502 11:38:33.275543 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:33.399852 26473 solver.cpp:429]     Test net output #0: loss = 0.256166 (* 1 = 0.256166 loss)
I0502 11:38:33.402725 26473 solver.cpp:242] Iteration 173000 (93.6304 iter/s, 1.06803s/100 iter), loss = 0.0652937
I0502 11:38:33.402745 26473 solver.cpp:261]     Train net output #0: loss = 0.0652937 (* 1 = 0.0652937 loss)
I0502 11:38:33.402755 26473 sgd_solver.cpp:106] Iteration 173000, lr = 2.2518e-06
I0502 11:38:33.404443 26473 solver.cpp:362] Iteration 173000, Testing net (#0)
I0502 11:38:33.404456 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:33.535032 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9655
I0502 11:38:33.535056 26473 solver.cpp:429]     Test net output #1: loss = 0.0778076 (* 1 = 0.0778076 loss)
I0502 11:38:33.537984 26473 solver.cpp:242] Iteration 173000 (83.4386 iter/s, 1.19849s/100 iter), loss = 0.0903461
I0502 11:38:33.538004 26473 solver.cpp:261]     Train net output #0: loss = 0.0903461 (* 1 = 0.0903461 loss)
I0502 11:38:33.538012 26473 sgd_solver.cpp:106] Iteration 173000, lr = 2.2518e-06
I0502 11:38:34.478379 26473 solver.cpp:242] Iteration 173100 (92.9715 iter/s, 1.0756s/100 iter), loss = 0.134001
I0502 11:38:34.478423 26473 solver.cpp:261]     Train net output #0: loss = 0.134001 (* 1 = 0.134001 loss)
I0502 11:38:34.478432 26473 sgd_solver.cpp:106] Iteration 173100, lr = 2.2518e-06
I0502 11:38:34.483188 26473 solver.cpp:242] Iteration 173100 (105.802 iter/s, 0.945165s/100 iter), loss = 0.0220414
I0502 11:38:34.483211 26473 solver.cpp:261]     Train net output #0: loss = 0.0220414 (* 1 = 0.0220414 loss)
I0502 11:38:34.483219 26473 sgd_solver.cpp:106] Iteration 173100, lr = 2.2518e-06
I0502 11:38:35.422451 26473 solver.cpp:242] Iteration 173200 (105.933 iter/s, 0.943996s/100 iter), loss = 0.158279
I0502 11:38:35.422492 26473 solver.cpp:261]     Train net output #0: loss = 0.158279 (* 1 = 0.158279 loss)
I0502 11:38:35.422502 26473 sgd_solver.cpp:106] Iteration 173200, lr = 2.2518e-06
I0502 11:38:35.427260 26473 solver.cpp:242] Iteration 173200 (105.929 iter/s, 0.944032s/100 iter), loss = 0.0773458
I0502 11:38:35.427284 26473 solver.cpp:261]     Train net output #0: loss = 0.0773458 (* 1 = 0.0773458 loss)
I0502 11:38:35.427292 26473 sgd_solver.cpp:106] Iteration 173200, lr = 2.2518e-06
I0502 11:38:36.365540 26473 solver.cpp:242] Iteration 173300 (106.042 iter/s, 0.943021s/100 iter), loss = 0.119914
I0502 11:38:36.365582 26473 solver.cpp:261]     Train net output #0: loss = 0.119914 (* 1 = 0.119914 loss)
I0502 11:38:36.365591 26473 sgd_solver.cpp:106] Iteration 173300, lr = 2.2518e-06
I0502 11:38:36.370335 26473 solver.cpp:242] Iteration 173300 (106.041 iter/s, 0.943033s/100 iter), loss = 0.0585546
I0502 11:38:36.370358 26473 solver.cpp:261]     Train net output #0: loss = 0.0585546 (* 1 = 0.0585546 loss)
I0502 11:38:36.370367 26473 sgd_solver.cpp:106] Iteration 173300, lr = 2.2518e-06
I0502 11:38:37.308951 26473 solver.cpp:242] Iteration 173400 (106.006 iter/s, 0.943344s/100 iter), loss = 0.151939
I0502 11:38:37.308990 26473 solver.cpp:261]     Train net output #0: loss = 0.151939 (* 1 = 0.151939 loss)
I0502 11:38:37.309000 26473 sgd_solver.cpp:106] Iteration 173400, lr = 2.2518e-06
I0502 11:38:37.313735 26473 solver.cpp:242] Iteration 173400 (106.004 iter/s, 0.943359s/100 iter), loss = 0.0385626
I0502 11:38:37.313758 26473 solver.cpp:261]     Train net output #0: loss = 0.0385626 (* 1 = 0.0385626 loss)
I0502 11:38:37.313766 26473 sgd_solver.cpp:106] Iteration 173400, lr = 2.2518e-06
I0502 11:38:38.250218 26473 solver.cpp:362] Iteration 173500, Testing net (#0)
I0502 11:38:38.250246 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:38.374581 26473 solver.cpp:429]     Test net output #0: loss = 0.229735 (* 1 = 0.229735 loss)
I0502 11:38:38.377451 26473 solver.cpp:242] Iteration 173500 (93.5943 iter/s, 1.06844s/100 iter), loss = 0.10984
I0502 11:38:38.377473 26473 solver.cpp:261]     Train net output #0: loss = 0.10984 (* 1 = 0.10984 loss)
I0502 11:38:38.377482 26473 sgd_solver.cpp:106] Iteration 173500, lr = 2.2518e-06
I0502 11:38:38.379190 26473 solver.cpp:362] Iteration 173500, Testing net (#0)
I0502 11:38:38.379204 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:38.509694 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:38:38.509716 26473 solver.cpp:429]     Test net output #1: loss = 0.0783467 (* 1 = 0.0783467 loss)
I0502 11:38:38.512672 26473 solver.cpp:242] Iteration 173500 (83.4102 iter/s, 1.19889s/100 iter), loss = 0.0514347
I0502 11:38:38.512692 26473 solver.cpp:261]     Train net output #0: loss = 0.0514347 (* 1 = 0.0514347 loss)
I0502 11:38:38.512701 26473 sgd_solver.cpp:106] Iteration 173500, lr = 2.2518e-06
I0502 11:38:39.451987 26473 solver.cpp:242] Iteration 173600 (93.0683 iter/s, 1.07448s/100 iter), loss = 0.186622
I0502 11:38:39.452030 26473 solver.cpp:261]     Train net output #0: loss = 0.186622 (* 1 = 0.186622 loss)
I0502 11:38:39.452039 26473 sgd_solver.cpp:106] Iteration 173600, lr = 2.2518e-06
I0502 11:38:39.456807 26473 solver.cpp:242] Iteration 173600 (105.921 iter/s, 0.944097s/100 iter), loss = 0.042903
I0502 11:38:39.456831 26473 solver.cpp:261]     Train net output #0: loss = 0.042903 (* 1 = 0.042903 loss)
I0502 11:38:39.456840 26473 sgd_solver.cpp:106] Iteration 173600, lr = 2.2518e-06
I0502 11:38:40.397653 26473 solver.cpp:242] Iteration 173700 (105.754 iter/s, 0.945593s/100 iter), loss = 0.0314664
I0502 11:38:40.397698 26473 solver.cpp:261]     Train net output #0: loss = 0.0314664 (* 1 = 0.0314664 loss)
I0502 11:38:40.397717 26473 sgd_solver.cpp:106] Iteration 173700, lr = 2.2518e-06
I0502 11:38:40.402477 26473 solver.cpp:242] Iteration 173700 (105.75 iter/s, 0.945627s/100 iter), loss = 0.0306641
I0502 11:38:40.402500 26473 solver.cpp:261]     Train net output #0: loss = 0.0306641 (* 1 = 0.0306641 loss)
I0502 11:38:40.402508 26473 sgd_solver.cpp:106] Iteration 173700, lr = 2.2518e-06
I0502 11:38:41.342356 26473 solver.cpp:242] Iteration 173800 (105.861 iter/s, 0.944631s/100 iter), loss = 0.0273015
I0502 11:38:41.342396 26473 solver.cpp:261]     Train net output #0: loss = 0.0273015 (* 1 = 0.0273015 loss)
I0502 11:38:41.342404 26473 sgd_solver.cpp:106] Iteration 173800, lr = 2.2518e-06
I0502 11:38:41.347182 26473 solver.cpp:242] Iteration 173800 (105.858 iter/s, 0.944664s/100 iter), loss = 0.0467001
I0502 11:38:41.347204 26473 solver.cpp:261]     Train net output #0: loss = 0.0467001 (* 1 = 0.0467001 loss)
I0502 11:38:41.347213 26473 sgd_solver.cpp:106] Iteration 173800, lr = 2.2518e-06
I0502 11:38:42.288360 26473 solver.cpp:242] Iteration 173900 (105.715 iter/s, 0.945939s/100 iter), loss = 0.322101
I0502 11:38:42.288400 26473 solver.cpp:261]     Train net output #0: loss = 0.322101 (* 1 = 0.322101 loss)
I0502 11:38:42.288409 26473 sgd_solver.cpp:106] Iteration 173900, lr = 2.2518e-06
I0502 11:38:42.293190 26473 solver.cpp:242] Iteration 173900 (105.712 iter/s, 0.945967s/100 iter), loss = 0.13776
I0502 11:38:42.293212 26473 solver.cpp:261]     Train net output #0: loss = 0.13776 (* 1 = 0.13776 loss)
I0502 11:38:42.293221 26473 sgd_solver.cpp:106] Iteration 173900, lr = 2.2518e-06
I0502 11:38:43.228516 26473 solver.cpp:362] Iteration 174000, Testing net (#0)
I0502 11:38:43.228541 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:43.352847 26473 solver.cpp:429]     Test net output #0: loss = 0.237363 (* 1 = 0.237363 loss)
I0502 11:38:43.355752 26473 solver.cpp:242] Iteration 174000 (93.6914 iter/s, 1.06733s/100 iter), loss = 0.12956
I0502 11:38:43.355772 26473 solver.cpp:261]     Train net output #0: loss = 0.12956 (* 1 = 0.12956 loss)
I0502 11:38:43.355779 26473 sgd_solver.cpp:106] Iteration 174000, lr = 2.2518e-06
I0502 11:38:43.357478 26473 solver.cpp:362] Iteration 174000, Testing net (#0)
I0502 11:38:43.357493 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:43.488209 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:38:43.488230 26473 solver.cpp:429]     Test net output #1: loss = 0.0769756 (* 1 = 0.0769756 loss)
I0502 11:38:43.491158 26473 solver.cpp:242] Iteration 174000 (83.4777 iter/s, 1.19792s/100 iter), loss = 0.0898571
I0502 11:38:43.491178 26473 solver.cpp:261]     Train net output #0: loss = 0.0898571 (* 1 = 0.0898571 loss)
I0502 11:38:43.491186 26473 sgd_solver.cpp:106] Iteration 174000, lr = 2.2518e-06
I0502 11:38:44.429801 26473 solver.cpp:242] Iteration 174100 (93.1103 iter/s, 1.07399s/100 iter), loss = 0.236973
I0502 11:38:44.429841 26473 solver.cpp:261]     Train net output #0: loss = 0.236973 (* 1 = 0.236973 loss)
I0502 11:38:44.429850 26473 sgd_solver.cpp:106] Iteration 174100, lr = 2.2518e-06
I0502 11:38:44.434648 26473 solver.cpp:242] Iteration 174100 (105.994 iter/s, 0.943451s/100 iter), loss = 0.110656
I0502 11:38:44.434671 26473 solver.cpp:261]     Train net output #0: loss = 0.110656 (* 1 = 0.110656 loss)
I0502 11:38:44.434680 26473 sgd_solver.cpp:106] Iteration 174100, lr = 2.2518e-06
I0502 11:38:45.374001 26473 solver.cpp:242] Iteration 174200 (105.918 iter/s, 0.944131s/100 iter), loss = 0.333598
I0502 11:38:45.374042 26473 solver.cpp:261]     Train net output #0: loss = 0.333598 (* 1 = 0.333598 loss)
I0502 11:38:45.374049 26473 sgd_solver.cpp:106] Iteration 174200, lr = 2.2518e-06
I0502 11:38:45.378803 26473 solver.cpp:242] Iteration 174200 (105.92 iter/s, 0.944113s/100 iter), loss = 0.0549114
I0502 11:38:45.378825 26473 solver.cpp:261]     Train net output #0: loss = 0.0549114 (* 1 = 0.0549114 loss)
I0502 11:38:45.378834 26473 sgd_solver.cpp:106] Iteration 174200, lr = 2.2518e-06
I0502 11:38:46.318696 26473 solver.cpp:242] Iteration 174300 (105.862 iter/s, 0.944628s/100 iter), loss = 0.343771
I0502 11:38:46.318729 26473 solver.cpp:261]     Train net output #0: loss = 0.343771 (* 1 = 0.343771 loss)
I0502 11:38:46.318737 26473 sgd_solver.cpp:106] Iteration 174300, lr = 2.2518e-06
I0502 11:38:46.323492 26473 solver.cpp:242] Iteration 174300 (105.86 iter/s, 0.944648s/100 iter), loss = 0.0065083
I0502 11:38:46.323515 26473 solver.cpp:261]     Train net output #0: loss = 0.0065083 (* 1 = 0.0065083 loss)
I0502 11:38:46.323523 26473 sgd_solver.cpp:106] Iteration 174300, lr = 2.2518e-06
I0502 11:38:47.262733 26473 solver.cpp:242] Iteration 174400 (105.934 iter/s, 0.94398s/100 iter), loss = 0.484009
I0502 11:38:47.262766 26473 solver.cpp:261]     Train net output #0: loss = 0.484009 (* 1 = 0.484009 loss)
I0502 11:38:47.262775 26473 sgd_solver.cpp:106] Iteration 174400, lr = 2.2518e-06
I0502 11:38:47.267532 26473 solver.cpp:242] Iteration 174400 (105.932 iter/s, 0.943999s/100 iter), loss = 0.057932
I0502 11:38:47.267555 26473 solver.cpp:261]     Train net output #0: loss = 0.057932 (* 1 = 0.057932 loss)
I0502 11:38:47.267565 26473 sgd_solver.cpp:106] Iteration 174400, lr = 2.2518e-06
I0502 11:38:48.204215 26473 solver.cpp:362] Iteration 174500, Testing net (#0)
I0502 11:38:48.204234 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:48.328452 26473 solver.cpp:429]     Test net output #0: loss = 0.205026 (* 1 = 0.205026 loss)
I0502 11:38:48.331331 26473 solver.cpp:242] Iteration 174500 (93.5852 iter/s, 1.06855s/100 iter), loss = 0.061905
I0502 11:38:48.331351 26473 solver.cpp:261]     Train net output #0: loss = 0.061905 (* 1 = 0.061905 loss)
I0502 11:38:48.331359 26473 sgd_solver.cpp:106] Iteration 174500, lr = 2.2518e-06
I0502 11:38:48.333063 26473 solver.cpp:362] Iteration 174500, Testing net (#0)
I0502 11:38:48.333077 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:48.463620 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9615
I0502 11:38:48.463642 26473 solver.cpp:429]     Test net output #1: loss = 0.087238 (* 1 = 0.087238 loss)
I0502 11:38:48.466569 26473 solver.cpp:242] Iteration 174500 (83.4033 iter/s, 1.19899s/100 iter), loss = 0.0579865
I0502 11:38:48.466589 26473 solver.cpp:261]     Train net output #0: loss = 0.0579865 (* 1 = 0.0579865 loss)
I0502 11:38:48.466598 26473 sgd_solver.cpp:106] Iteration 174500, lr = 2.2518e-06
I0502 11:38:49.405287 26473 solver.cpp:242] Iteration 174600 (93.1183 iter/s, 1.0739s/100 iter), loss = 0.489231
I0502 11:38:49.405323 26473 solver.cpp:261]     Train net output #0: loss = 0.489231 (* 1 = 0.489231 loss)
I0502 11:38:49.405331 26473 sgd_solver.cpp:106] Iteration 174600, lr = 2.2518e-06
I0502 11:38:49.410096 26473 solver.cpp:242] Iteration 174600 (105.99 iter/s, 0.943488s/100 iter), loss = 0.0629715
I0502 11:38:49.410120 26473 solver.cpp:261]     Train net output #0: loss = 0.0629715 (* 1 = 0.0629715 loss)
I0502 11:38:49.410128 26473 sgd_solver.cpp:106] Iteration 174600, lr = 2.2518e-06
I0502 11:38:50.350548 26473 solver.cpp:242] Iteration 174700 (105.798 iter/s, 0.945196s/100 iter), loss = 0.220927
I0502 11:38:50.350584 26473 solver.cpp:261]     Train net output #0: loss = 0.220927 (* 1 = 0.220927 loss)
I0502 11:38:50.350594 26473 sgd_solver.cpp:106] Iteration 174700, lr = 2.2518e-06
I0502 11:38:50.355363 26473 solver.cpp:242] Iteration 174700 (105.795 iter/s, 0.945226s/100 iter), loss = 0.0597991
I0502 11:38:50.355386 26473 solver.cpp:261]     Train net output #0: loss = 0.0597991 (* 1 = 0.0597991 loss)
I0502 11:38:50.355394 26473 sgd_solver.cpp:106] Iteration 174700, lr = 2.2518e-06
I0502 11:38:51.294308 26473 solver.cpp:242] Iteration 174800 (105.966 iter/s, 0.943698s/100 iter), loss = 0.30096
I0502 11:38:51.294337 26473 solver.cpp:261]     Train net output #0: loss = 0.30096 (* 1 = 0.30096 loss)
I0502 11:38:51.294347 26473 sgd_solver.cpp:106] Iteration 174800, lr = 2.2518e-06
I0502 11:38:51.299100 26473 solver.cpp:242] Iteration 174800 (105.966 iter/s, 0.943696s/100 iter), loss = 0.0576364
I0502 11:38:51.299131 26473 solver.cpp:261]     Train net output #0: loss = 0.0576364 (* 1 = 0.0576364 loss)
I0502 11:38:51.299140 26473 sgd_solver.cpp:106] Iteration 174800, lr = 2.2518e-06
I0502 11:38:52.238546 26473 solver.cpp:242] Iteration 174900 (105.912 iter/s, 0.944179s/100 iter), loss = 0.124635
I0502 11:38:52.238590 26473 solver.cpp:261]     Train net output #0: loss = 0.124635 (* 1 = 0.124635 loss)
I0502 11:38:52.238598 26473 sgd_solver.cpp:106] Iteration 174900, lr = 2.2518e-06
I0502 11:38:52.243348 26473 solver.cpp:242] Iteration 174900 (105.91 iter/s, 0.9442s/100 iter), loss = 0.0157842
I0502 11:38:52.243372 26473 solver.cpp:261]     Train net output #0: loss = 0.0157842 (* 1 = 0.0157842 loss)
I0502 11:38:52.243381 26473 sgd_solver.cpp:106] Iteration 174900, lr = 2.2518e-06
I0502 11:38:53.179301 26473 solver.cpp:362] Iteration 175000, Testing net (#0)
I0502 11:38:53.179330 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:53.303679 26473 solver.cpp:429]     Test net output #0: loss = 0.257569 (* 1 = 0.257569 loss)
I0502 11:38:53.306556 26473 solver.cpp:242] Iteration 175000 (93.6374 iter/s, 1.06795s/100 iter), loss = 0.173507
I0502 11:38:53.306576 26473 solver.cpp:261]     Train net output #0: loss = 0.173507 (* 1 = 0.173507 loss)
I0502 11:38:53.306584 26473 sgd_solver.cpp:106] Iteration 175000, lr = 2.2518e-06
I0502 11:38:53.308282 26473 solver.cpp:362] Iteration 175000, Testing net (#0)
I0502 11:38:53.308295 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:53.439028 26473 solver.cpp:429]     Test net output #0: accuracy = 0.966
I0502 11:38:53.439045 26473 solver.cpp:429]     Test net output #1: loss = 0.0737119 (* 1 = 0.0737119 loss)
I0502 11:38:53.441969 26473 solver.cpp:242] Iteration 175000 (83.4323 iter/s, 1.19858s/100 iter), loss = 0.102006
I0502 11:38:53.441989 26473 solver.cpp:261]     Train net output #0: loss = 0.102006 (* 1 = 0.102006 loss)
I0502 11:38:53.441998 26473 sgd_solver.cpp:106] Iteration 175000, lr = 2.2518e-06
I0502 11:38:54.381266 26473 solver.cpp:242] Iteration 175100 (93.0526 iter/s, 1.07466s/100 iter), loss = 0.127854
I0502 11:38:54.381310 26473 solver.cpp:261]     Train net output #0: loss = 0.127854 (* 1 = 0.127854 loss)
I0502 11:38:54.381319 26473 sgd_solver.cpp:106] Iteration 175100, lr = 2.2518e-06
I0502 11:38:54.386128 26473 solver.cpp:242] Iteration 175100 (105.919 iter/s, 0.944116s/100 iter), loss = 0.0246725
I0502 11:38:54.386152 26473 solver.cpp:261]     Train net output #0: loss = 0.0246725 (* 1 = 0.0246725 loss)
I0502 11:38:54.386162 26473 sgd_solver.cpp:106] Iteration 175100, lr = 2.2518e-06
I0502 11:38:55.324851 26473 solver.cpp:242] Iteration 175200 (105.987 iter/s, 0.94351s/100 iter), loss = 0.0787725
I0502 11:38:55.324909 26473 solver.cpp:261]     Train net output #0: loss = 0.0787725 (* 1 = 0.0787725 loss)
I0502 11:38:55.324919 26473 sgd_solver.cpp:106] Iteration 175200, lr = 2.2518e-06
I0502 11:38:55.329737 26473 solver.cpp:242] Iteration 175200 (105.981 iter/s, 0.943566s/100 iter), loss = 0.0380164
I0502 11:38:55.329761 26473 solver.cpp:261]     Train net output #0: loss = 0.0380164 (* 1 = 0.0380164 loss)
I0502 11:38:55.329771 26473 sgd_solver.cpp:106] Iteration 175200, lr = 2.2518e-06
I0502 11:38:56.269253 26473 solver.cpp:242] Iteration 175300 (105.897 iter/s, 0.944314s/100 iter), loss = 0.400266
I0502 11:38:56.269297 26473 solver.cpp:261]     Train net output #0: loss = 0.400266 (* 1 = 0.400266 loss)
I0502 11:38:56.269306 26473 sgd_solver.cpp:106] Iteration 175300, lr = 2.2518e-06
I0502 11:38:56.274072 26473 solver.cpp:242] Iteration 175300 (105.899 iter/s, 0.944293s/100 iter), loss = 0.0474969
I0502 11:38:56.274096 26473 solver.cpp:261]     Train net output #0: loss = 0.0474969 (* 1 = 0.0474969 loss)
I0502 11:38:56.274106 26473 sgd_solver.cpp:106] Iteration 175300, lr = 2.2518e-06
I0502 11:38:57.213439 26473 solver.cpp:242] Iteration 175400 (105.919 iter/s, 0.944114s/100 iter), loss = 0.0973445
I0502 11:38:57.213480 26473 solver.cpp:261]     Train net output #0: loss = 0.0973445 (* 1 = 0.0973445 loss)
I0502 11:38:57.213490 26473 sgd_solver.cpp:106] Iteration 175400, lr = 2.2518e-06
I0502 11:38:57.218269 26473 solver.cpp:242] Iteration 175400 (105.915 iter/s, 0.944155s/100 iter), loss = 0.109394
I0502 11:38:57.218292 26473 solver.cpp:261]     Train net output #0: loss = 0.109394 (* 1 = 0.109394 loss)
I0502 11:38:57.218300 26473 sgd_solver.cpp:106] Iteration 175400, lr = 2.2518e-06
I0502 11:38:58.155676 26473 solver.cpp:362] Iteration 175500, Testing net (#0)
I0502 11:38:58.155707 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:58.280253 26473 solver.cpp:429]     Test net output #0: loss = 0.184693 (* 1 = 0.184693 loss)
I0502 11:38:58.283138 26473 solver.cpp:242] Iteration 175500 (93.4893 iter/s, 1.06964s/100 iter), loss = 0.0960774
I0502 11:38:58.283159 26473 solver.cpp:261]     Train net output #0: loss = 0.0960774 (* 1 = 0.0960774 loss)
I0502 11:38:58.283167 26473 sgd_solver.cpp:106] Iteration 175500, lr = 2.2518e-06
I0502 11:38:58.284910 26473 solver.cpp:362] Iteration 175500, Testing net (#0)
I0502 11:38:58.284924 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:38:58.415582 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:38:58.415603 26473 solver.cpp:429]     Test net output #1: loss = 0.0846279 (* 1 = 0.0846279 loss)
I0502 11:38:58.418536 26473 solver.cpp:242] Iteration 175500 (83.3178 iter/s, 1.20022s/100 iter), loss = 0.0241768
I0502 11:38:58.418556 26473 solver.cpp:261]     Train net output #0: loss = 0.0241768 (* 1 = 0.0241768 loss)
I0502 11:38:58.418565 26473 sgd_solver.cpp:106] Iteration 175500, lr = 2.2518e-06
I0502 11:38:59.358178 26473 solver.cpp:242] Iteration 175600 (93.0238 iter/s, 1.07499s/100 iter), loss = 0.49223
I0502 11:38:59.358219 26473 solver.cpp:261]     Train net output #0: loss = 0.49223 (* 1 = 0.49223 loss)
I0502 11:38:59.358228 26473 sgd_solver.cpp:106] Iteration 175600, lr = 2.2518e-06
I0502 11:38:59.363041 26473 solver.cpp:242] Iteration 175600 (105.881 iter/s, 0.944461s/100 iter), loss = 0.000970051
I0502 11:38:59.363065 26473 solver.cpp:261]     Train net output #0: loss = 0.000970051 (* 1 = 0.000970051 loss)
I0502 11:38:59.363073 26473 sgd_solver.cpp:106] Iteration 175600, lr = 2.2518e-06
I0502 11:39:00.314505 26473 solver.cpp:242] Iteration 175700 (104.575 iter/s, 0.956253s/100 iter), loss = 0.0675962
I0502 11:39:00.314553 26473 solver.cpp:261]     Train net output #0: loss = 0.0675962 (* 1 = 0.0675962 loss)
I0502 11:39:00.314563 26473 sgd_solver.cpp:106] Iteration 175700, lr = 2.2518e-06
I0502 11:39:00.319375 26473 solver.cpp:242] Iteration 175700 (104.571 iter/s, 0.956291s/100 iter), loss = 0.0028146
I0502 11:39:00.319401 26473 solver.cpp:261]     Train net output #0: loss = 0.0028146 (* 1 = 0.0028146 loss)
I0502 11:39:00.319409 26473 sgd_solver.cpp:106] Iteration 175700, lr = 2.2518e-06
I0502 11:39:01.260270 26473 solver.cpp:242] Iteration 175800 (105.743 iter/s, 0.94569s/100 iter), loss = 0.221724
I0502 11:39:01.260313 26473 solver.cpp:261]     Train net output #0: loss = 0.221724 (* 1 = 0.221724 loss)
I0502 11:39:01.260321 26473 sgd_solver.cpp:106] Iteration 175800, lr = 2.2518e-06
I0502 11:39:01.265090 26473 solver.cpp:242] Iteration 175800 (105.745 iter/s, 0.945673s/100 iter), loss = 0.00840573
I0502 11:39:01.265115 26473 solver.cpp:261]     Train net output #0: loss = 0.00840573 (* 1 = 0.00840573 loss)
I0502 11:39:01.265123 26473 sgd_solver.cpp:106] Iteration 175800, lr = 2.2518e-06
I0502 11:39:02.205667 26473 solver.cpp:242] Iteration 175900 (105.783 iter/s, 0.945329s/100 iter), loss = 0.525399
I0502 11:39:02.205706 26473 solver.cpp:261]     Train net output #0: loss = 0.525399 (* 1 = 0.525399 loss)
I0502 11:39:02.205715 26473 sgd_solver.cpp:106] Iteration 175900, lr = 2.2518e-06
I0502 11:39:02.210489 26473 solver.cpp:242] Iteration 175900 (105.78 iter/s, 0.945355s/100 iter), loss = 0.160324
I0502 11:39:02.210511 26473 solver.cpp:261]     Train net output #0: loss = 0.160324 (* 1 = 0.160324 loss)
I0502 11:39:02.210520 26473 sgd_solver.cpp:106] Iteration 175900, lr = 2.2518e-06
I0502 11:39:03.146736 26473 solver.cpp:362] Iteration 176000, Testing net (#0)
I0502 11:39:03.146766 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:03.271163 26473 solver.cpp:429]     Test net output #0: loss = 0.218685 (* 1 = 0.218685 loss)
I0502 11:39:03.274027 26473 solver.cpp:242] Iteration 176000 (93.6064 iter/s, 1.0683s/100 iter), loss = 0.21906
I0502 11:39:03.274047 26473 solver.cpp:261]     Train net output #0: loss = 0.21906 (* 1 = 0.21906 loss)
I0502 11:39:03.274055 26473 sgd_solver.cpp:106] Iteration 176000, lr = 2.2518e-06
I0502 11:39:03.275679 26473 solver.cpp:362] Iteration 176000, Testing net (#0)
I0502 11:39:03.275692 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:03.406136 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9615
I0502 11:39:03.406157 26473 solver.cpp:429]     Test net output #1: loss = 0.0748728 (* 1 = 0.0748728 loss)
I0502 11:39:03.409080 26473 solver.cpp:242] Iteration 176000 (83.4344 iter/s, 1.19855s/100 iter), loss = 0.104346
I0502 11:39:03.409099 26473 solver.cpp:261]     Train net output #0: loss = 0.104346 (* 1 = 0.104346 loss)
I0502 11:39:03.409107 26473 sgd_solver.cpp:106] Iteration 176000, lr = 2.2518e-06
I0502 11:39:04.349678 26473 solver.cpp:242] Iteration 176100 (92.9711 iter/s, 1.0756s/100 iter), loss = 0.715786
I0502 11:39:04.349720 26473 solver.cpp:261]     Train net output #0: loss = 0.715786 (* 1 = 0.715786 loss)
I0502 11:39:04.349728 26473 sgd_solver.cpp:106] Iteration 176100, lr = 2.2518e-06
I0502 11:39:04.354540 26473 solver.cpp:242] Iteration 176100 (105.774 iter/s, 0.945415s/100 iter), loss = 0.177841
I0502 11:39:04.354564 26473 solver.cpp:261]     Train net output #0: loss = 0.177841 (* 1 = 0.177841 loss)
I0502 11:39:04.354573 26473 sgd_solver.cpp:106] Iteration 176100, lr = 2.2518e-06
I0502 11:39:05.293850 26473 solver.cpp:242] Iteration 176200 (105.921 iter/s, 0.944102s/100 iter), loss = 0.0886363
I0502 11:39:05.293889 26473 solver.cpp:261]     Train net output #0: loss = 0.0886363 (* 1 = 0.0886363 loss)
I0502 11:39:05.293898 26473 sgd_solver.cpp:106] Iteration 176200, lr = 2.2518e-06
I0502 11:39:05.298715 26473 solver.cpp:242] Iteration 176200 (105.917 iter/s, 0.944132s/100 iter), loss = 0.132029
I0502 11:39:05.298738 26473 solver.cpp:261]     Train net output #0: loss = 0.132029 (* 1 = 0.132029 loss)
I0502 11:39:05.298746 26473 sgd_solver.cpp:106] Iteration 176200, lr = 2.2518e-06
I0502 11:39:06.237963 26473 solver.cpp:242] Iteration 176300 (105.927 iter/s, 0.944045s/100 iter), loss = 0.154167
I0502 11:39:06.238004 26473 solver.cpp:261]     Train net output #0: loss = 0.154167 (* 1 = 0.154167 loss)
I0502 11:39:06.238013 26473 sgd_solver.cpp:106] Iteration 176300, lr = 2.2518e-06
I0502 11:39:06.242775 26473 solver.cpp:242] Iteration 176300 (105.93 iter/s, 0.944019s/100 iter), loss = 0.0373498
I0502 11:39:06.242799 26473 solver.cpp:261]     Train net output #0: loss = 0.0373498 (* 1 = 0.0373498 loss)
I0502 11:39:06.242807 26473 sgd_solver.cpp:106] Iteration 176300, lr = 2.2518e-06
I0502 11:39:07.181155 26473 solver.cpp:242] Iteration 176400 (106.03 iter/s, 0.943125s/100 iter), loss = 0.147216
I0502 11:39:07.181186 26473 solver.cpp:261]     Train net output #0: loss = 0.147216 (* 1 = 0.147216 loss)
I0502 11:39:07.181195 26473 sgd_solver.cpp:106] Iteration 176400, lr = 2.2518e-06
I0502 11:39:07.185930 26473 solver.cpp:242] Iteration 176400 (106.032 iter/s, 0.943112s/100 iter), loss = 0.0364955
I0502 11:39:07.185951 26473 solver.cpp:261]     Train net output #0: loss = 0.0364955 (* 1 = 0.0364955 loss)
I0502 11:39:07.185961 26473 sgd_solver.cpp:106] Iteration 176400, lr = 2.2518e-06
I0502 11:39:08.121829 26473 solver.cpp:362] Iteration 176500, Testing net (#0)
I0502 11:39:08.121856 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:08.246204 26473 solver.cpp:429]     Test net output #0: loss = 0.212972 (* 1 = 0.212972 loss)
I0502 11:39:08.249071 26473 solver.cpp:242] Iteration 176500 (93.6447 iter/s, 1.06787s/100 iter), loss = 0.127724
I0502 11:39:08.249091 26473 solver.cpp:261]     Train net output #0: loss = 0.127724 (* 1 = 0.127724 loss)
I0502 11:39:08.249099 26473 sgd_solver.cpp:106] Iteration 176500, lr = 2.2518e-06
I0502 11:39:08.250723 26473 solver.cpp:362] Iteration 176500, Testing net (#0)
I0502 11:39:08.250737 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:08.381435 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:39:08.381458 26473 solver.cpp:429]     Test net output #1: loss = 0.0853902 (* 1 = 0.0853902 loss)
I0502 11:39:08.384373 26473 solver.cpp:242] Iteration 176500 (83.4445 iter/s, 1.1984s/100 iter), loss = 0.0739637
I0502 11:39:08.384392 26473 solver.cpp:261]     Train net output #0: loss = 0.0739637 (* 1 = 0.0739637 loss)
I0502 11:39:08.384402 26473 sgd_solver.cpp:106] Iteration 176500, lr = 2.2518e-06
I0502 11:39:09.324236 26473 solver.cpp:242] Iteration 176600 (93.0132 iter/s, 1.07512s/100 iter), loss = 0.327177
I0502 11:39:09.324275 26473 solver.cpp:261]     Train net output #0: loss = 0.327177 (* 1 = 0.327177 loss)
I0502 11:39:09.324285 26473 sgd_solver.cpp:106] Iteration 176600, lr = 2.2518e-06
I0502 11:39:09.329159 26473 solver.cpp:242] Iteration 176600 (105.849 iter/s, 0.944738s/100 iter), loss = 0.0660701
I0502 11:39:09.329182 26473 solver.cpp:261]     Train net output #0: loss = 0.0660701 (* 1 = 0.0660701 loss)
I0502 11:39:09.329191 26473 sgd_solver.cpp:106] Iteration 176600, lr = 2.2518e-06
I0502 11:39:10.268875 26473 solver.cpp:242] Iteration 176700 (105.868 iter/s, 0.94457s/100 iter), loss = 0.193827
I0502 11:39:10.268909 26473 solver.cpp:261]     Train net output #0: loss = 0.193827 (* 1 = 0.193827 loss)
I0502 11:39:10.268918 26473 sgd_solver.cpp:106] Iteration 176700, lr = 2.2518e-06
I0502 11:39:10.273684 26473 solver.cpp:242] Iteration 176700 (105.878 iter/s, 0.944483s/100 iter), loss = 0.147429
I0502 11:39:10.273707 26473 solver.cpp:261]     Train net output #0: loss = 0.147429 (* 1 = 0.147429 loss)
I0502 11:39:10.273715 26473 sgd_solver.cpp:106] Iteration 176700, lr = 2.2518e-06
I0502 11:39:11.213060 26473 solver.cpp:242] Iteration 176800 (105.918 iter/s, 0.944124s/100 iter), loss = 0.0473252
I0502 11:39:11.213093 26473 solver.cpp:261]     Train net output #0: loss = 0.0473252 (* 1 = 0.0473252 loss)
I0502 11:39:11.213101 26473 sgd_solver.cpp:106] Iteration 176800, lr = 2.2518e-06
I0502 11:39:11.217839 26473 solver.cpp:242] Iteration 176800 (105.919 iter/s, 0.944115s/100 iter), loss = 0.154381
I0502 11:39:11.217862 26473 solver.cpp:261]     Train net output #0: loss = 0.154381 (* 1 = 0.154381 loss)
I0502 11:39:11.217871 26473 sgd_solver.cpp:106] Iteration 176800, lr = 2.2518e-06
I0502 11:39:12.157816 26473 solver.cpp:242] Iteration 176900 (105.854 iter/s, 0.944697s/100 iter), loss = 0.324314
I0502 11:39:12.157850 26473 solver.cpp:261]     Train net output #0: loss = 0.324314 (* 1 = 0.324314 loss)
I0502 11:39:12.157860 26473 sgd_solver.cpp:106] Iteration 176900, lr = 2.2518e-06
I0502 11:39:12.162606 26473 solver.cpp:242] Iteration 176900 (105.851 iter/s, 0.944725s/100 iter), loss = 0.147705
I0502 11:39:12.162627 26473 solver.cpp:261]     Train net output #0: loss = 0.147705 (* 1 = 0.147705 loss)
I0502 11:39:12.162636 26473 sgd_solver.cpp:106] Iteration 176900, lr = 2.2518e-06
I0502 11:39:13.097870 26473 solver.cpp:362] Iteration 177000, Testing net (#0)
I0502 11:39:13.097898 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:13.222342 26473 solver.cpp:429]     Test net output #0: loss = 0.238259 (* 1 = 0.238259 loss)
I0502 11:39:13.225219 26473 solver.cpp:242] Iteration 177000 (93.6901 iter/s, 1.06735s/100 iter), loss = 0.167459
I0502 11:39:13.225239 26473 solver.cpp:261]     Train net output #0: loss = 0.167459 (* 1 = 0.167459 loss)
I0502 11:39:13.225246 26473 sgd_solver.cpp:106] Iteration 177000, lr = 2.2518e-06
I0502 11:39:13.226864 26473 solver.cpp:362] Iteration 177000, Testing net (#0)
I0502 11:39:13.226878 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:13.357671 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9685
I0502 11:39:13.357692 26473 solver.cpp:429]     Test net output #1: loss = 0.07011 (* 1 = 0.07011 loss)
I0502 11:39:13.360622 26473 solver.cpp:242] Iteration 177000 (83.4743 iter/s, 1.19797s/100 iter), loss = 0.0560489
I0502 11:39:13.360651 26473 solver.cpp:261]     Train net output #0: loss = 0.0560489 (* 1 = 0.0560489 loss)
I0502 11:39:13.360661 26473 sgd_solver.cpp:106] Iteration 177000, lr = 2.2518e-06
I0502 11:39:14.300120 26473 solver.cpp:242] Iteration 177100 (93.0359 iter/s, 1.07485s/100 iter), loss = 0.230945
I0502 11:39:14.300163 26473 solver.cpp:261]     Train net output #0: loss = 0.230945 (* 1 = 0.230945 loss)
I0502 11:39:14.300173 26473 sgd_solver.cpp:106] Iteration 177100, lr = 2.2518e-06
I0502 11:39:14.304998 26473 solver.cpp:242] Iteration 177100 (105.896 iter/s, 0.94432s/100 iter), loss = 0.103732
I0502 11:39:14.305022 26473 solver.cpp:261]     Train net output #0: loss = 0.103732 (* 1 = 0.103732 loss)
I0502 11:39:14.305029 26473 sgd_solver.cpp:106] Iteration 177100, lr = 2.2518e-06
I0502 11:39:15.243368 26473 solver.cpp:242] Iteration 177200 (106.025 iter/s, 0.943173s/100 iter), loss = 0.261237
I0502 11:39:15.243412 26473 solver.cpp:261]     Train net output #0: loss = 0.261237 (* 1 = 0.261237 loss)
I0502 11:39:15.243420 26473 sgd_solver.cpp:106] Iteration 177200, lr = 2.2518e-06
I0502 11:39:15.248193 26473 solver.cpp:242] Iteration 177200 (106.027 iter/s, 0.943153s/100 iter), loss = 0.0399179
I0502 11:39:15.248215 26473 solver.cpp:261]     Train net output #0: loss = 0.0399179 (* 1 = 0.0399179 loss)
I0502 11:39:15.248224 26473 sgd_solver.cpp:106] Iteration 177200, lr = 2.2518e-06
I0502 11:39:16.186970 26473 solver.cpp:242] Iteration 177300 (105.985 iter/s, 0.943528s/100 iter), loss = 0.149747
I0502 11:39:16.187026 26473 solver.cpp:261]     Train net output #0: loss = 0.149747 (* 1 = 0.149747 loss)
I0502 11:39:16.187036 26473 sgd_solver.cpp:106] Iteration 177300, lr = 2.2518e-06
I0502 11:39:16.191850 26473 solver.cpp:242] Iteration 177300 (105.975 iter/s, 0.943616s/100 iter), loss = 0.0947767
I0502 11:39:16.191874 26473 solver.cpp:261]     Train net output #0: loss = 0.0947767 (* 1 = 0.0947767 loss)
I0502 11:39:16.191882 26473 sgd_solver.cpp:106] Iteration 177300, lr = 2.2518e-06
I0502 11:39:17.130842 26473 solver.cpp:242] Iteration 177400 (105.956 iter/s, 0.943788s/100 iter), loss = 0.135636
I0502 11:39:17.130884 26473 solver.cpp:261]     Train net output #0: loss = 0.135636 (* 1 = 0.135636 loss)
I0502 11:39:17.130893 26473 sgd_solver.cpp:106] Iteration 177400, lr = 2.2518e-06
I0502 11:39:17.135679 26473 solver.cpp:242] Iteration 177400 (105.956 iter/s, 0.943787s/100 iter), loss = 0.0306839
I0502 11:39:17.135701 26473 solver.cpp:261]     Train net output #0: loss = 0.0306839 (* 1 = 0.0306839 loss)
I0502 11:39:17.135710 26473 sgd_solver.cpp:106] Iteration 177400, lr = 2.2518e-06
I0502 11:39:18.072863 26473 solver.cpp:362] Iteration 177500, Testing net (#0)
I0502 11:39:18.072890 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:18.197105 26473 solver.cpp:429]     Test net output #0: loss = 0.230097 (* 1 = 0.230097 loss)
I0502 11:39:18.199986 26473 solver.cpp:242] Iteration 177500 (93.538 iter/s, 1.06908s/100 iter), loss = 0.386158
I0502 11:39:18.200006 26473 solver.cpp:261]     Train net output #0: loss = 0.386158 (* 1 = 0.386158 loss)
I0502 11:39:18.200014 26473 sgd_solver.cpp:106] Iteration 177500, lr = 2.2518e-06
I0502 11:39:18.201675 26473 solver.cpp:362] Iteration 177500, Testing net (#0)
I0502 11:39:18.201689 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:18.332128 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:39:18.332149 26473 solver.cpp:429]     Test net output #1: loss = 0.0903056 (* 1 = 0.0903056 loss)
I0502 11:39:18.335062 26473 solver.cpp:242] Iteration 177500 (83.3792 iter/s, 1.19934s/100 iter), loss = 0.0932875
I0502 11:39:18.335083 26473 solver.cpp:261]     Train net output #0: loss = 0.0932875 (* 1 = 0.0932875 loss)
I0502 11:39:18.335091 26473 sgd_solver.cpp:106] Iteration 177500, lr = 2.2518e-06
I0502 11:39:19.273586 26473 solver.cpp:242] Iteration 177600 (93.1487 iter/s, 1.07355s/100 iter), loss = 0.157549
I0502 11:39:19.273627 26473 solver.cpp:261]     Train net output #0: loss = 0.157549 (* 1 = 0.157549 loss)
I0502 11:39:19.273644 26473 sgd_solver.cpp:106] Iteration 177600, lr = 2.2518e-06
I0502 11:39:19.278455 26473 solver.cpp:242] Iteration 177600 (106.006 iter/s, 0.943344s/100 iter), loss = 0.0372334
I0502 11:39:19.278478 26473 solver.cpp:261]     Train net output #0: loss = 0.0372334 (* 1 = 0.0372334 loss)
I0502 11:39:19.278487 26473 sgd_solver.cpp:106] Iteration 177600, lr = 2.2518e-06
I0502 11:39:20.217185 26473 solver.cpp:242] Iteration 177700 (105.985 iter/s, 0.943527s/100 iter), loss = 0.144483
I0502 11:39:20.217228 26473 solver.cpp:261]     Train net output #0: loss = 0.144483 (* 1 = 0.144483 loss)
I0502 11:39:20.217237 26473 sgd_solver.cpp:106] Iteration 177700, lr = 2.2518e-06
I0502 11:39:20.221992 26473 solver.cpp:242] Iteration 177700 (105.989 iter/s, 0.943495s/100 iter), loss = 0.00508096
I0502 11:39:20.222015 26473 solver.cpp:261]     Train net output #0: loss = 0.00508096 (* 1 = 0.00508096 loss)
I0502 11:39:20.222023 26473 sgd_solver.cpp:106] Iteration 177700, lr = 2.2518e-06
I0502 11:39:21.160239 26473 solver.cpp:242] Iteration 177800 (106.047 iter/s, 0.942981s/100 iter), loss = 0.0294014
I0502 11:39:21.160280 26473 solver.cpp:261]     Train net output #0: loss = 0.0294014 (* 1 = 0.0294014 loss)
I0502 11:39:21.160290 26473 sgd_solver.cpp:106] Iteration 177800, lr = 2.2518e-06
I0502 11:39:21.165042 26473 solver.cpp:242] Iteration 177800 (106.043 iter/s, 0.94301s/100 iter), loss = 0.0704218
I0502 11:39:21.165066 26473 solver.cpp:261]     Train net output #0: loss = 0.0704218 (* 1 = 0.0704218 loss)
I0502 11:39:21.165074 26473 sgd_solver.cpp:106] Iteration 177800, lr = 2.2518e-06
I0502 11:39:22.104367 26473 solver.cpp:242] Iteration 177900 (105.925 iter/s, 0.94406s/100 iter), loss = 0.0459343
I0502 11:39:22.104409 26473 solver.cpp:261]     Train net output #0: loss = 0.0459343 (* 1 = 0.0459343 loss)
I0502 11:39:22.104418 26473 sgd_solver.cpp:106] Iteration 177900, lr = 2.2518e-06
I0502 11:39:22.109207 26473 solver.cpp:242] Iteration 177900 (105.918 iter/s, 0.944123s/100 iter), loss = 0.00336236
I0502 11:39:22.109231 26473 solver.cpp:261]     Train net output #0: loss = 0.00336236 (* 1 = 0.00336236 loss)
I0502 11:39:22.109241 26473 sgd_solver.cpp:106] Iteration 177900, lr = 2.2518e-06
I0502 11:39:23.045588 26473 solver.cpp:362] Iteration 178000, Testing net (#0)
I0502 11:39:23.045613 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:23.170070 26473 solver.cpp:429]     Test net output #0: loss = 0.22636 (* 1 = 0.22636 loss)
I0502 11:39:23.172948 26473 solver.cpp:242] Iteration 178000 (93.5873 iter/s, 1.06852s/100 iter), loss = 0.154497
I0502 11:39:23.172969 26473 solver.cpp:261]     Train net output #0: loss = 0.154497 (* 1 = 0.154497 loss)
I0502 11:39:23.172978 26473 sgd_solver.cpp:106] Iteration 178000, lr = 2.2518e-06
I0502 11:39:23.174592 26473 solver.cpp:362] Iteration 178000, Testing net (#0)
I0502 11:39:23.174603 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:23.305436 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:39:23.305457 26473 solver.cpp:429]     Test net output #1: loss = 0.0829639 (* 1 = 0.0829639 loss)
I0502 11:39:23.308382 26473 solver.cpp:242] Iteration 178000 (83.3938 iter/s, 1.19913s/100 iter), loss = 0.0783828
I0502 11:39:23.308401 26473 solver.cpp:261]     Train net output #0: loss = 0.0783828 (* 1 = 0.0783828 loss)
I0502 11:39:23.308409 26473 sgd_solver.cpp:106] Iteration 178000, lr = 2.2518e-06
I0502 11:39:24.247347 26473 solver.cpp:242] Iteration 178100 (93.0797 iter/s, 1.07435s/100 iter), loss = 0.0604887
I0502 11:39:24.247386 26473 solver.cpp:261]     Train net output #0: loss = 0.0604887 (* 1 = 0.0604887 loss)
I0502 11:39:24.247395 26473 sgd_solver.cpp:106] Iteration 178100, lr = 2.2518e-06
I0502 11:39:24.252256 26473 solver.cpp:242] Iteration 178100 (105.952 iter/s, 0.943827s/100 iter), loss = 0.0518248
I0502 11:39:24.252279 26473 solver.cpp:261]     Train net output #0: loss = 0.0518248 (* 1 = 0.0518248 loss)
I0502 11:39:24.252288 26473 sgd_solver.cpp:106] Iteration 178100, lr = 2.2518e-06
I0502 11:39:25.191959 26473 solver.cpp:242] Iteration 178200 (105.87 iter/s, 0.944551s/100 iter), loss = 0.185526
I0502 11:39:25.192005 26473 solver.cpp:261]     Train net output #0: loss = 0.185526 (* 1 = 0.185526 loss)
I0502 11:39:25.192015 26473 sgd_solver.cpp:106] Iteration 178200, lr = 2.2518e-06
I0502 11:39:25.196842 26473 solver.cpp:242] Iteration 178200 (105.872 iter/s, 0.944539s/100 iter), loss = 0.0691505
I0502 11:39:25.196866 26473 solver.cpp:261]     Train net output #0: loss = 0.0691505 (* 1 = 0.0691505 loss)
I0502 11:39:25.196874 26473 sgd_solver.cpp:106] Iteration 178200, lr = 2.2518e-06
I0502 11:39:26.155616 26473 solver.cpp:242] Iteration 178300 (103.78 iter/s, 0.963581s/100 iter), loss = 0.174996
I0502 11:39:26.155653 26473 solver.cpp:261]     Train net output #0: loss = 0.174996 (* 1 = 0.174996 loss)
I0502 11:39:26.155663 26473 sgd_solver.cpp:106] Iteration 178300, lr = 2.2518e-06
I0502 11:39:26.160420 26473 solver.cpp:242] Iteration 178300 (103.784 iter/s, 0.963537s/100 iter), loss = 0.00658593
I0502 11:39:26.160444 26473 solver.cpp:261]     Train net output #0: loss = 0.00658593 (* 1 = 0.00658593 loss)
I0502 11:39:26.160451 26473 sgd_solver.cpp:106] Iteration 178300, lr = 2.2518e-06
I0502 11:39:27.100100 26473 solver.cpp:242] Iteration 178400 (105.885 iter/s, 0.944418s/100 iter), loss = 0.184607
I0502 11:39:27.100137 26473 solver.cpp:261]     Train net output #0: loss = 0.184607 (* 1 = 0.184607 loss)
I0502 11:39:27.100147 26473 sgd_solver.cpp:106] Iteration 178400, lr = 2.2518e-06
I0502 11:39:27.104933 26473 solver.cpp:242] Iteration 178400 (105.879 iter/s, 0.944472s/100 iter), loss = 0.029682
I0502 11:39:27.104957 26473 solver.cpp:261]     Train net output #0: loss = 0.029682 (* 1 = 0.029682 loss)
I0502 11:39:27.104965 26473 sgd_solver.cpp:106] Iteration 178400, lr = 2.2518e-06
I0502 11:39:28.040498 26473 solver.cpp:362] Iteration 178500, Testing net (#0)
I0502 11:39:28.040518 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:28.164963 26473 solver.cpp:429]     Test net output #0: loss = 0.193168 (* 1 = 0.193168 loss)
I0502 11:39:28.167845 26473 solver.cpp:242] Iteration 178500 (93.6602 iter/s, 1.06769s/100 iter), loss = 0.0595194
I0502 11:39:28.167865 26473 solver.cpp:261]     Train net output #0: loss = 0.0595194 (* 1 = 0.0595194 loss)
I0502 11:39:28.167873 26473 sgd_solver.cpp:106] Iteration 178500, lr = 2.2518e-06
I0502 11:39:28.169610 26473 solver.cpp:362] Iteration 178500, Testing net (#0)
I0502 11:39:28.169623 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:28.300772 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9595
I0502 11:39:28.300796 26473 solver.cpp:429]     Test net output #1: loss = 0.0847241 (* 1 = 0.0847241 loss)
I0502 11:39:28.303717 26473 solver.cpp:242] Iteration 178500 (83.421 iter/s, 1.19874s/100 iter), loss = 0.147705
I0502 11:39:28.303736 26473 solver.cpp:261]     Train net output #0: loss = 0.147705 (* 1 = 0.147705 loss)
I0502 11:39:28.303745 26473 sgd_solver.cpp:106] Iteration 178500, lr = 2.2518e-06
I0502 11:39:29.243309 26473 solver.cpp:242] Iteration 178600 (92.9873 iter/s, 1.07542s/100 iter), loss = 0.296765
I0502 11:39:29.243345 26473 solver.cpp:261]     Train net output #0: loss = 0.296765 (* 1 = 0.296765 loss)
I0502 11:39:29.243355 26473 sgd_solver.cpp:106] Iteration 178600, lr = 2.2518e-06
I0502 11:39:29.248124 26473 solver.cpp:242] Iteration 178600 (105.891 iter/s, 0.94437s/100 iter), loss = 0.00595645
I0502 11:39:29.248148 26473 solver.cpp:261]     Train net output #0: loss = 0.00595645 (* 1 = 0.00595645 loss)
I0502 11:39:29.248157 26473 sgd_solver.cpp:106] Iteration 178600, lr = 2.2518e-06
I0502 11:39:30.188455 26473 solver.cpp:242] Iteration 178700 (105.81 iter/s, 0.945086s/100 iter), loss = 0.132862
I0502 11:39:30.188488 26473 solver.cpp:261]     Train net output #0: loss = 0.132862 (* 1 = 0.132862 loss)
I0502 11:39:30.188496 26473 sgd_solver.cpp:106] Iteration 178700, lr = 2.2518e-06
I0502 11:39:30.193348 26473 solver.cpp:242] Iteration 178700 (105.801 iter/s, 0.945174s/100 iter), loss = 0.00869937
I0502 11:39:30.193372 26473 solver.cpp:261]     Train net output #0: loss = 0.00869937 (* 1 = 0.00869937 loss)
I0502 11:39:30.193389 26473 sgd_solver.cpp:106] Iteration 178700, lr = 2.2518e-06
I0502 11:39:31.132860 26473 solver.cpp:242] Iteration 178800 (105.894 iter/s, 0.944343s/100 iter), loss = 0.0288756
I0502 11:39:31.132903 26473 solver.cpp:261]     Train net output #0: loss = 0.0288756 (* 1 = 0.0288756 loss)
I0502 11:39:31.132912 26473 sgd_solver.cpp:106] Iteration 178800, lr = 2.2518e-06
I0502 11:39:31.137696 26473 solver.cpp:242] Iteration 178800 (105.898 iter/s, 0.944306s/100 iter), loss = 0.118397
I0502 11:39:31.137718 26473 solver.cpp:261]     Train net output #0: loss = 0.118397 (* 1 = 0.118397 loss)
I0502 11:39:31.137727 26473 sgd_solver.cpp:106] Iteration 178800, lr = 2.2518e-06
I0502 11:39:32.078204 26473 solver.cpp:242] Iteration 178900 (105.79 iter/s, 0.945273s/100 iter), loss = 0.389272
I0502 11:39:32.078235 26473 solver.cpp:261]     Train net output #0: loss = 0.389272 (* 1 = 0.389272 loss)
I0502 11:39:32.078244 26473 sgd_solver.cpp:106] Iteration 178900, lr = 2.2518e-06
I0502 11:39:32.082996 26473 solver.cpp:242] Iteration 178900 (105.791 iter/s, 0.94526s/100 iter), loss = 0.00735586
I0502 11:39:32.083020 26473 solver.cpp:261]     Train net output #0: loss = 0.00735586 (* 1 = 0.00735586 loss)
I0502 11:39:32.083029 26473 sgd_solver.cpp:106] Iteration 178900, lr = 2.2518e-06
I0502 11:39:33.019904 26473 solver.cpp:362] Iteration 179000, Testing net (#0)
I0502 11:39:33.019932 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:33.144222 26473 solver.cpp:429]     Test net output #0: loss = 0.251268 (* 1 = 0.251268 loss)
I0502 11:39:33.147109 26473 solver.cpp:242] Iteration 179000 (93.558 iter/s, 1.06886s/100 iter), loss = 0.339546
I0502 11:39:33.147130 26473 solver.cpp:261]     Train net output #0: loss = 0.339546 (* 1 = 0.339546 loss)
I0502 11:39:33.147138 26473 sgd_solver.cpp:106] Iteration 179000, lr = 2.2518e-06
I0502 11:39:33.148787 26473 solver.cpp:362] Iteration 179000, Testing net (#0)
I0502 11:39:33.148803 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:33.279186 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:39:33.279204 26473 solver.cpp:429]     Test net output #1: loss = 0.0819291 (* 1 = 0.0819291 loss)
I0502 11:39:33.282166 26473 solver.cpp:242] Iteration 179000 (83.3941 iter/s, 1.19913s/100 iter), loss = 0.0102704
I0502 11:39:33.282186 26473 solver.cpp:261]     Train net output #0: loss = 0.0102704 (* 1 = 0.0102704 loss)
I0502 11:39:33.282194 26473 sgd_solver.cpp:106] Iteration 179000, lr = 2.2518e-06
I0502 11:39:34.222614 26473 solver.cpp:242] Iteration 179100 (92.984 iter/s, 1.07545s/100 iter), loss = 0.0912011
I0502 11:39:34.222656 26473 solver.cpp:261]     Train net output #0: loss = 0.0912011 (* 1 = 0.0912011 loss)
I0502 11:39:34.222666 26473 sgd_solver.cpp:106] Iteration 179100, lr = 2.2518e-06
I0502 11:39:34.227430 26473 solver.cpp:242] Iteration 179100 (105.795 iter/s, 0.945226s/100 iter), loss = 0.0629685
I0502 11:39:34.227454 26473 solver.cpp:261]     Train net output #0: loss = 0.0629685 (* 1 = 0.0629685 loss)
I0502 11:39:34.227463 26473 sgd_solver.cpp:106] Iteration 179100, lr = 2.2518e-06
I0502 11:39:35.167492 26473 solver.cpp:242] Iteration 179200 (105.841 iter/s, 0.944811s/100 iter), loss = 0.0726451
I0502 11:39:35.167536 26473 solver.cpp:261]     Train net output #0: loss = 0.0726451 (* 1 = 0.0726451 loss)
I0502 11:39:35.167546 26473 sgd_solver.cpp:106] Iteration 179200, lr = 2.2518e-06
I0502 11:39:35.172408 26473 solver.cpp:242] Iteration 179200 (105.828 iter/s, 0.944929s/100 iter), loss = 0.227394
I0502 11:39:35.172432 26473 solver.cpp:261]     Train net output #0: loss = 0.227394 (* 1 = 0.227394 loss)
I0502 11:39:35.172441 26473 sgd_solver.cpp:106] Iteration 179200, lr = 2.2518e-06
I0502 11:39:36.111112 26473 solver.cpp:242] Iteration 179300 (105.983 iter/s, 0.943546s/100 iter), loss = 0.173552
I0502 11:39:36.111155 26473 solver.cpp:261]     Train net output #0: loss = 0.173552 (* 1 = 0.173552 loss)
I0502 11:39:36.111165 26473 sgd_solver.cpp:106] Iteration 179300, lr = 2.2518e-06
I0502 11:39:36.115936 26473 solver.cpp:242] Iteration 179300 (105.99 iter/s, 0.943487s/100 iter), loss = 0.00137724
I0502 11:39:36.115959 26473 solver.cpp:261]     Train net output #0: loss = 0.00137724 (* 1 = 0.00137724 loss)
I0502 11:39:36.115967 26473 sgd_solver.cpp:106] Iteration 179300, lr = 2.2518e-06
I0502 11:39:37.055852 26473 solver.cpp:242] Iteration 179400 (105.857 iter/s, 0.944667s/100 iter), loss = 0.0614341
I0502 11:39:37.055910 26473 solver.cpp:261]     Train net output #0: loss = 0.0614341 (* 1 = 0.0614341 loss)
I0502 11:39:37.055923 26473 sgd_solver.cpp:106] Iteration 179400, lr = 2.2518e-06
I0502 11:39:37.060730 26473 solver.cpp:242] Iteration 179400 (105.848 iter/s, 0.944753s/100 iter), loss = 0.0691838
I0502 11:39:37.060753 26473 solver.cpp:261]     Train net output #0: loss = 0.0691838 (* 1 = 0.0691838 loss)
I0502 11:39:37.060761 26473 sgd_solver.cpp:106] Iteration 179400, lr = 2.2518e-06
I0502 11:39:37.997206 26473 solver.cpp:362] Iteration 179500, Testing net (#0)
I0502 11:39:37.997234 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:38.121523 26473 solver.cpp:429]     Test net output #0: loss = 0.216296 (* 1 = 0.216296 loss)
I0502 11:39:38.124405 26473 solver.cpp:242] Iteration 179500 (93.5911 iter/s, 1.06848s/100 iter), loss = 0.322352
I0502 11:39:38.124424 26473 solver.cpp:261]     Train net output #0: loss = 0.322352 (* 1 = 0.322352 loss)
I0502 11:39:38.124433 26473 sgd_solver.cpp:106] Iteration 179500, lr = 2.2518e-06
I0502 11:39:38.126087 26473 solver.cpp:362] Iteration 179500, Testing net (#0)
I0502 11:39:38.126101 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:38.256678 26473 solver.cpp:429]     Test net output #0: accuracy = 0.976
I0502 11:39:38.256700 26473 solver.cpp:429]     Test net output #1: loss = 0.06957 (* 1 = 0.06957 loss)
I0502 11:39:38.259634 26473 solver.cpp:242] Iteration 179500 (83.4126 iter/s, 1.19886s/100 iter), loss = 0.0902033
I0502 11:39:38.259654 26473 solver.cpp:261]     Train net output #0: loss = 0.0902033 (* 1 = 0.0902033 loss)
I0502 11:39:38.259662 26473 sgd_solver.cpp:106] Iteration 179500, lr = 2.2518e-06
I0502 11:39:39.200423 26473 solver.cpp:242] Iteration 179600 (92.9396 iter/s, 1.07597s/100 iter), loss = 0.0968139
I0502 11:39:39.200467 26473 solver.cpp:261]     Train net output #0: loss = 0.0968139 (* 1 = 0.0968139 loss)
I0502 11:39:39.200476 26473 sgd_solver.cpp:106] Iteration 179600, lr = 2.2518e-06
I0502 11:39:39.205273 26473 solver.cpp:242] Iteration 179600 (105.753 iter/s, 0.945601s/100 iter), loss = 0.232286
I0502 11:39:39.205296 26473 solver.cpp:261]     Train net output #0: loss = 0.232286 (* 1 = 0.232286 loss)
I0502 11:39:39.205304 26473 sgd_solver.cpp:106] Iteration 179600, lr = 2.2518e-06
I0502 11:39:40.143719 26473 solver.cpp:242] Iteration 179700 (106.019 iter/s, 0.943229s/100 iter), loss = 0.262812
I0502 11:39:40.143759 26473 solver.cpp:261]     Train net output #0: loss = 0.262812 (* 1 = 0.262812 loss)
I0502 11:39:40.143769 26473 sgd_solver.cpp:106] Iteration 179700, lr = 2.2518e-06
I0502 11:39:40.148607 26473 solver.cpp:242] Iteration 179700 (106.012 iter/s, 0.943285s/100 iter), loss = 0.0985926
I0502 11:39:40.148632 26473 solver.cpp:261]     Train net output #0: loss = 0.0985926 (* 1 = 0.0985926 loss)
I0502 11:39:40.148639 26473 sgd_solver.cpp:106] Iteration 179700, lr = 2.2518e-06
I0502 11:39:41.087991 26473 solver.cpp:242] Iteration 179800 (105.91 iter/s, 0.9442s/100 iter), loss = 0.19392
I0502 11:39:41.088033 26473 solver.cpp:261]     Train net output #0: loss = 0.19392 (* 1 = 0.19392 loss)
I0502 11:39:41.088042 26473 sgd_solver.cpp:106] Iteration 179800, lr = 2.2518e-06
I0502 11:39:41.092823 26473 solver.cpp:242] Iteration 179800 (105.913 iter/s, 0.944174s/100 iter), loss = 0.00936053
I0502 11:39:41.092846 26473 solver.cpp:261]     Train net output #0: loss = 0.00936053 (* 1 = 0.00936053 loss)
I0502 11:39:41.092855 26473 sgd_solver.cpp:106] Iteration 179800, lr = 2.2518e-06
I0502 11:39:42.033396 26473 solver.cpp:242] Iteration 179900 (105.783 iter/s, 0.945332s/100 iter), loss = 0.397307
I0502 11:39:42.033444 26473 solver.cpp:261]     Train net output #0: loss = 0.397307 (* 1 = 0.397307 loss)
I0502 11:39:42.033454 26473 sgd_solver.cpp:106] Iteration 179900, lr = 2.2518e-06
I0502 11:39:42.038312 26473 solver.cpp:242] Iteration 179900 (105.77 iter/s, 0.945448s/100 iter), loss = 0.132734
I0502 11:39:42.038336 26473 solver.cpp:261]     Train net output #0: loss = 0.132734 (* 1 = 0.132734 loss)
I0502 11:39:42.038344 26473 sgd_solver.cpp:106] Iteration 179900, lr = 2.2518e-06
I0502 11:39:42.975353 26473 solver.cpp:362] Iteration 180000, Testing net (#0)
I0502 11:39:42.975378 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:43.099730 26473 solver.cpp:429]     Test net output #0: loss = 0.255666 (* 1 = 0.255666 loss)
I0502 11:39:43.102601 26473 solver.cpp:242] Iteration 180000 (93.5333 iter/s, 1.06914s/100 iter), loss = 0.0914722
I0502 11:39:43.102620 26473 solver.cpp:261]     Train net output #0: loss = 0.0914722 (* 1 = 0.0914722 loss)
I0502 11:39:43.102629 26473 sgd_solver.cpp:106] Iteration 180000, lr = 1.80144e-06
I0502 11:39:43.104288 26473 solver.cpp:362] Iteration 180000, Testing net (#0)
I0502 11:39:43.104301 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:43.235101 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:39:43.235121 26473 solver.cpp:429]     Test net output #1: loss = 0.0779319 (* 1 = 0.0779319 loss)
I0502 11:39:43.238046 26473 solver.cpp:242] Iteration 180000 (83.3548 iter/s, 1.19969s/100 iter), loss = 0.0400494
I0502 11:39:43.238067 26473 solver.cpp:261]     Train net output #0: loss = 0.0400494 (* 1 = 0.0400494 loss)
I0502 11:39:43.238075 26473 sgd_solver.cpp:106] Iteration 180000, lr = 1.80144e-06
I0502 11:39:44.177440 26473 solver.cpp:242] Iteration 180100 (93.0413 iter/s, 1.07479s/100 iter), loss = 0.125366
I0502 11:39:44.177479 26473 solver.cpp:261]     Train net output #0: loss = 0.125366 (* 1 = 0.125366 loss)
I0502 11:39:44.177489 26473 sgd_solver.cpp:106] Iteration 180100, lr = 1.80144e-06
I0502 11:39:44.182255 26473 solver.cpp:242] Iteration 180100 (105.913 iter/s, 0.944169s/100 iter), loss = 0.0678964
I0502 11:39:44.182278 26473 solver.cpp:261]     Train net output #0: loss = 0.0678964 (* 1 = 0.0678964 loss)
I0502 11:39:44.182286 26473 sgd_solver.cpp:106] Iteration 180100, lr = 1.80144e-06
I0502 11:39:45.122143 26473 solver.cpp:242] Iteration 180200 (105.861 iter/s, 0.944638s/100 iter), loss = 0.13705
I0502 11:39:45.122181 26473 solver.cpp:261]     Train net output #0: loss = 0.13705 (* 1 = 0.13705 loss)
I0502 11:39:45.122190 26473 sgd_solver.cpp:106] Iteration 180200, lr = 1.80144e-06
I0502 11:39:45.127017 26473 solver.cpp:242] Iteration 180200 (105.852 iter/s, 0.944712s/100 iter), loss = 0.122752
I0502 11:39:45.127039 26473 solver.cpp:261]     Train net output #0: loss = 0.122752 (* 1 = 0.122752 loss)
I0502 11:39:45.127048 26473 sgd_solver.cpp:106] Iteration 180200, lr = 1.80144e-06
I0502 11:39:46.065505 26473 solver.cpp:242] Iteration 180300 (106.012 iter/s, 0.943291s/100 iter), loss = 0.0921107
I0502 11:39:46.065541 26473 solver.cpp:261]     Train net output #0: loss = 0.0921107 (* 1 = 0.0921107 loss)
I0502 11:39:46.065551 26473 sgd_solver.cpp:106] Iteration 180300, lr = 1.80144e-06
I0502 11:39:46.070314 26473 solver.cpp:242] Iteration 180300 (106.016 iter/s, 0.943258s/100 iter), loss = 0.167177
I0502 11:39:46.070338 26473 solver.cpp:261]     Train net output #0: loss = 0.167177 (* 1 = 0.167177 loss)
I0502 11:39:46.070345 26473 sgd_solver.cpp:106] Iteration 180300, lr = 1.80144e-06
I0502 11:39:47.009374 26473 solver.cpp:242] Iteration 180400 (105.954 iter/s, 0.943803s/100 iter), loss = 0.102217
I0502 11:39:47.009415 26473 solver.cpp:261]     Train net output #0: loss = 0.102217 (* 1 = 0.102217 loss)
I0502 11:39:47.009424 26473 sgd_solver.cpp:106] Iteration 180400, lr = 1.80144e-06
I0502 11:39:47.014180 26473 solver.cpp:242] Iteration 180400 (105.952 iter/s, 0.943825s/100 iter), loss = 0.124227
I0502 11:39:47.014204 26473 solver.cpp:261]     Train net output #0: loss = 0.124227 (* 1 = 0.124227 loss)
I0502 11:39:47.014212 26473 sgd_solver.cpp:106] Iteration 180400, lr = 1.80144e-06
I0502 11:39:47.949350 26473 solver.cpp:362] Iteration 180500, Testing net (#0)
I0502 11:39:47.949374 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:48.073642 26473 solver.cpp:429]     Test net output #0: loss = 0.196461 (* 1 = 0.196461 loss)
I0502 11:39:48.076504 26473 solver.cpp:242] Iteration 180500 (93.7144 iter/s, 1.06707s/100 iter), loss = 0.199612
I0502 11:39:48.076524 26473 solver.cpp:261]     Train net output #0: loss = 0.199612 (* 1 = 0.199612 loss)
I0502 11:39:48.076531 26473 sgd_solver.cpp:106] Iteration 180500, lr = 1.80144e-06
I0502 11:39:48.078156 26473 solver.cpp:362] Iteration 180500, Testing net (#0)
I0502 11:39:48.078171 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:48.208829 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9685
I0502 11:39:48.208850 26473 solver.cpp:429]     Test net output #1: loss = 0.0708635 (* 1 = 0.0708635 loss)
I0502 11:39:48.211752 26473 solver.cpp:242] Iteration 180500 (83.5053 iter/s, 1.19753s/100 iter), loss = 0.0805335
I0502 11:39:48.211772 26473 solver.cpp:261]     Train net output #0: loss = 0.0805335 (* 1 = 0.0805335 loss)
I0502 11:39:48.211781 26473 sgd_solver.cpp:106] Iteration 180500, lr = 1.80144e-06
I0502 11:39:49.151203 26473 solver.cpp:242] Iteration 180600 (93.0535 iter/s, 1.07465s/100 iter), loss = 0.677562
I0502 11:39:49.151239 26473 solver.cpp:261]     Train net output #0: loss = 0.677562 (* 1 = 0.677562 loss)
I0502 11:39:49.151248 26473 sgd_solver.cpp:106] Iteration 180600, lr = 1.80144e-06
I0502 11:39:49.156016 26473 solver.cpp:242] Iteration 180600 (105.907 iter/s, 0.944226s/100 iter), loss = 0.0743693
I0502 11:39:49.156039 26473 solver.cpp:261]     Train net output #0: loss = 0.0743693 (* 1 = 0.0743693 loss)
I0502 11:39:49.156049 26473 sgd_solver.cpp:106] Iteration 180600, lr = 1.80144e-06
I0502 11:39:50.094647 26473 solver.cpp:242] Iteration 180700 (106.001 iter/s, 0.943384s/100 iter), loss = 0.0350982
I0502 11:39:50.094679 26473 solver.cpp:261]     Train net output #0: loss = 0.0350982 (* 1 = 0.0350982 loss)
I0502 11:39:50.094688 26473 sgd_solver.cpp:106] Iteration 180700, lr = 1.80144e-06
I0502 11:39:50.099510 26473 solver.cpp:242] Iteration 180700 (105.995 iter/s, 0.943445s/100 iter), loss = 0.181868
I0502 11:39:50.099534 26473 solver.cpp:261]     Train net output #0: loss = 0.181868 (* 1 = 0.181868 loss)
I0502 11:39:50.099541 26473 sgd_solver.cpp:106] Iteration 180700, lr = 1.80144e-06
I0502 11:39:51.038785 26473 solver.cpp:242] Iteration 180800 (105.923 iter/s, 0.944084s/100 iter), loss = 0.184469
I0502 11:39:51.038817 26473 solver.cpp:261]     Train net output #0: loss = 0.184469 (* 1 = 0.184469 loss)
I0502 11:39:51.038825 26473 sgd_solver.cpp:106] Iteration 180800, lr = 1.80144e-06
I0502 11:39:51.043668 26473 solver.cpp:242] Iteration 180800 (105.92 iter/s, 0.94411s/100 iter), loss = 0.0424242
I0502 11:39:51.043690 26473 solver.cpp:261]     Train net output #0: loss = 0.0424242 (* 1 = 0.0424242 loss)
I0502 11:39:51.043699 26473 sgd_solver.cpp:106] Iteration 180800, lr = 1.80144e-06
I0502 11:39:51.982069 26473 solver.cpp:242] Iteration 180900 (106.019 iter/s, 0.943223s/100 iter), loss = 0.185998
I0502 11:39:51.982098 26473 solver.cpp:261]     Train net output #0: loss = 0.185998 (* 1 = 0.185998 loss)
I0502 11:39:51.982107 26473 sgd_solver.cpp:106] Iteration 180900, lr = 1.80144e-06
I0502 11:39:51.986860 26473 solver.cpp:242] Iteration 180900 (106.027 iter/s, 0.943153s/100 iter), loss = 0.0783467
I0502 11:39:51.986883 26473 solver.cpp:261]     Train net output #0: loss = 0.0783467 (* 1 = 0.0783467 loss)
I0502 11:39:51.986891 26473 sgd_solver.cpp:106] Iteration 180900, lr = 1.80144e-06
I0502 11:39:52.925230 26473 solver.cpp:362] Iteration 181000, Testing net (#0)
I0502 11:39:52.925269 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:53.049628 26473 solver.cpp:429]     Test net output #0: loss = 0.272344 (* 1 = 0.272344 loss)
I0502 11:39:53.052502 26473 solver.cpp:242] Iteration 181000 (93.4243 iter/s, 1.07039s/100 iter), loss = 0.159314
I0502 11:39:53.052530 26473 solver.cpp:261]     Train net output #0: loss = 0.159314 (* 1 = 0.159314 loss)
I0502 11:39:53.052537 26473 sgd_solver.cpp:106] Iteration 181000, lr = 1.80144e-06
I0502 11:39:53.054177 26473 solver.cpp:362] Iteration 181000, Testing net (#0)
I0502 11:39:53.054190 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:53.184959 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:39:53.184980 26473 solver.cpp:429]     Test net output #1: loss = 0.0816581 (* 1 = 0.0816581 loss)
I0502 11:39:53.187913 26473 solver.cpp:242] Iteration 181000 (83.2633 iter/s, 1.20101s/100 iter), loss = 0.0911116
I0502 11:39:53.187933 26473 solver.cpp:261]     Train net output #0: loss = 0.0911116 (* 1 = 0.0911116 loss)
I0502 11:39:53.187942 26473 sgd_solver.cpp:106] Iteration 181000, lr = 1.80144e-06
I0502 11:39:54.126687 26473 solver.cpp:242] Iteration 181100 (93.0986 iter/s, 1.07413s/100 iter), loss = 0.465061
I0502 11:39:54.126715 26473 solver.cpp:261]     Train net output #0: loss = 0.465061 (* 1 = 0.465061 loss)
I0502 11:39:54.126724 26473 sgd_solver.cpp:106] Iteration 181100, lr = 1.80144e-06
I0502 11:39:54.131494 26473 solver.cpp:242] Iteration 181100 (105.984 iter/s, 0.943542s/100 iter), loss = 0.0496497
I0502 11:39:54.131515 26473 solver.cpp:261]     Train net output #0: loss = 0.0496497 (* 1 = 0.0496497 loss)
I0502 11:39:54.131523 26473 sgd_solver.cpp:106] Iteration 181100, lr = 1.80144e-06
I0502 11:39:55.070564 26473 solver.cpp:242] Iteration 181200 (105.952 iter/s, 0.943821s/100 iter), loss = 0.110452
I0502 11:39:55.070606 26473 solver.cpp:261]     Train net output #0: loss = 0.110452 (* 1 = 0.110452 loss)
I0502 11:39:55.070616 26473 sgd_solver.cpp:106] Iteration 181200, lr = 1.80144e-06
I0502 11:39:55.075392 26473 solver.cpp:242] Iteration 181200 (105.948 iter/s, 0.943858s/100 iter), loss = 0.0270519
I0502 11:39:55.075415 26473 solver.cpp:261]     Train net output #0: loss = 0.0270519 (* 1 = 0.0270519 loss)
I0502 11:39:55.075423 26473 sgd_solver.cpp:106] Iteration 181200, lr = 1.80144e-06
I0502 11:39:56.015955 26473 solver.cpp:242] Iteration 181300 (105.784 iter/s, 0.945323s/100 iter), loss = 0.106094
I0502 11:39:56.016000 26473 solver.cpp:261]     Train net output #0: loss = 0.106094 (* 1 = 0.106094 loss)
I0502 11:39:56.016010 26473 sgd_solver.cpp:106] Iteration 181300, lr = 1.80144e-06
I0502 11:39:56.020820 26473 solver.cpp:242] Iteration 181300 (105.778 iter/s, 0.945379s/100 iter), loss = 0.0561531
I0502 11:39:56.020843 26473 solver.cpp:261]     Train net output #0: loss = 0.0561531 (* 1 = 0.0561531 loss)
I0502 11:39:56.020851 26473 sgd_solver.cpp:106] Iteration 181300, lr = 1.80144e-06
I0502 11:39:56.960007 26473 solver.cpp:242] Iteration 181400 (105.935 iter/s, 0.943976s/100 iter), loss = 0.153292
I0502 11:39:56.960049 26473 solver.cpp:261]     Train net output #0: loss = 0.153292 (* 1 = 0.153292 loss)
I0502 11:39:56.960058 26473 sgd_solver.cpp:106] Iteration 181400, lr = 1.80144e-06
I0502 11:39:56.964820 26473 solver.cpp:242] Iteration 181400 (105.937 iter/s, 0.943959s/100 iter), loss = 0.0174678
I0502 11:39:56.964843 26473 solver.cpp:261]     Train net output #0: loss = 0.0174678 (* 1 = 0.0174678 loss)
I0502 11:39:56.964853 26473 sgd_solver.cpp:106] Iteration 181400, lr = 1.80144e-06
I0502 11:39:57.901355 26473 solver.cpp:362] Iteration 181500, Testing net (#0)
I0502 11:39:57.901382 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:58.025682 26473 solver.cpp:429]     Test net output #0: loss = 0.215827 (* 1 = 0.215827 loss)
I0502 11:39:58.028584 26473 solver.cpp:242] Iteration 181500 (93.5878 iter/s, 1.06852s/100 iter), loss = 0.2025
I0502 11:39:58.028605 26473 solver.cpp:261]     Train net output #0: loss = 0.2025 (* 1 = 0.2025 loss)
I0502 11:39:58.028614 26473 sgd_solver.cpp:106] Iteration 181500, lr = 1.80144e-06
I0502 11:39:58.030234 26473 solver.cpp:362] Iteration 181500, Testing net (#0)
I0502 11:39:58.030247 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:39:58.160926 26473 solver.cpp:429]     Test net output #0: accuracy = 0.97
I0502 11:39:58.160957 26473 solver.cpp:429]     Test net output #1: loss = 0.0664087 (* 1 = 0.0664087 loss)
I0502 11:39:58.163875 26473 solver.cpp:242] Iteration 181500 (83.402 iter/s, 1.19901s/100 iter), loss = 0.0953121
I0502 11:39:58.163895 26473 solver.cpp:261]     Train net output #0: loss = 0.0953121 (* 1 = 0.0953121 loss)
I0502 11:39:58.163903 26473 sgd_solver.cpp:106] Iteration 181500, lr = 1.80144e-06
I0502 11:39:59.103543 26473 solver.cpp:242] Iteration 181600 (93.0312 iter/s, 1.07491s/100 iter), loss = 0.0686227
I0502 11:39:59.103585 26473 solver.cpp:261]     Train net output #0: loss = 0.0686227 (* 1 = 0.0686227 loss)
I0502 11:39:59.103593 26473 sgd_solver.cpp:106] Iteration 181600, lr = 1.80144e-06
I0502 11:39:59.108386 26473 solver.cpp:242] Iteration 181600 (105.879 iter/s, 0.944473s/100 iter), loss = 0.00124037
I0502 11:39:59.108410 26473 solver.cpp:261]     Train net output #0: loss = 0.00124037 (* 1 = 0.00124037 loss)
I0502 11:39:59.108418 26473 sgd_solver.cpp:106] Iteration 181600, lr = 1.80144e-06
I0502 11:40:00.048458 26473 solver.cpp:242] Iteration 181700 (105.837 iter/s, 0.944848s/100 iter), loss = 0.25759
I0502 11:40:00.048501 26473 solver.cpp:261]     Train net output #0: loss = 0.25759 (* 1 = 0.25759 loss)
I0502 11:40:00.048511 26473 sgd_solver.cpp:106] Iteration 181700, lr = 1.80144e-06
I0502 11:40:00.053268 26473 solver.cpp:242] Iteration 181700 (105.838 iter/s, 0.944841s/100 iter), loss = 0.0346383
I0502 11:40:00.053292 26473 solver.cpp:261]     Train net output #0: loss = 0.0346383 (* 1 = 0.0346383 loss)
I0502 11:40:00.053300 26473 sgd_solver.cpp:106] Iteration 181700, lr = 1.80144e-06
I0502 11:40:01.010732 26473 solver.cpp:242] Iteration 181800 (103.928 iter/s, 0.962207s/100 iter), loss = 0.072457
I0502 11:40:01.010773 26473 solver.cpp:261]     Train net output #0: loss = 0.072457 (* 1 = 0.072457 loss)
I0502 11:40:01.010782 26473 sgd_solver.cpp:106] Iteration 181800, lr = 1.80144e-06
I0502 11:40:01.015650 26473 solver.cpp:242] Iteration 181800 (103.914 iter/s, 0.962331s/100 iter), loss = 0.0470275
I0502 11:40:01.015673 26473 solver.cpp:261]     Train net output #0: loss = 0.0470275 (* 1 = 0.0470275 loss)
I0502 11:40:01.015682 26473 sgd_solver.cpp:106] Iteration 181800, lr = 1.80144e-06
I0502 11:40:01.965957 26473 solver.cpp:242] Iteration 181900 (104.695 iter/s, 0.955152s/100 iter), loss = 0.101228
I0502 11:40:01.965997 26473 solver.cpp:261]     Train net output #0: loss = 0.101228 (* 1 = 0.101228 loss)
I0502 11:40:01.966006 26473 sgd_solver.cpp:106] Iteration 181900, lr = 1.80144e-06
I0502 11:40:01.970762 26473 solver.cpp:242] Iteration 181900 (104.704 iter/s, 0.955071s/100 iter), loss = 0.0063514
I0502 11:40:01.970785 26473 solver.cpp:261]     Train net output #0: loss = 0.0063514 (* 1 = 0.0063514 loss)
I0502 11:40:01.970794 26473 sgd_solver.cpp:106] Iteration 181900, lr = 1.80144e-06
I0502 11:40:02.906075 26473 solver.cpp:362] Iteration 182000, Testing net (#0)
I0502 11:40:02.906101 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:03.030524 26473 solver.cpp:429]     Test net output #0: loss = 0.240155 (* 1 = 0.240155 loss)
I0502 11:40:03.033419 26473 solver.cpp:242] Iteration 182000 (93.6853 iter/s, 1.0674s/100 iter), loss = 0.0492992
I0502 11:40:03.033440 26473 solver.cpp:261]     Train net output #0: loss = 0.0492992 (* 1 = 0.0492992 loss)
I0502 11:40:03.033449 26473 sgd_solver.cpp:106] Iteration 182000, lr = 1.80144e-06
I0502 11:40:03.035094 26473 solver.cpp:362] Iteration 182000, Testing net (#0)
I0502 11:40:03.035107 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:03.165805 26473 solver.cpp:429]     Test net output #0: accuracy = 0.969
I0502 11:40:03.165825 26473 solver.cpp:429]     Test net output #1: loss = 0.0787436 (* 1 = 0.0787436 loss)
I0502 11:40:03.168757 26473 solver.cpp:242] Iteration 182000 (83.4759 iter/s, 1.19795s/100 iter), loss = 0.0903404
I0502 11:40:03.168776 26473 solver.cpp:261]     Train net output #0: loss = 0.0903404 (* 1 = 0.0903404 loss)
I0502 11:40:03.168786 26473 sgd_solver.cpp:106] Iteration 182000, lr = 1.80144e-06
I0502 11:40:04.108448 26473 solver.cpp:242] Iteration 182100 (93.0254 iter/s, 1.07498s/100 iter), loss = 0.155473
I0502 11:40:04.108501 26473 solver.cpp:261]     Train net output #0: loss = 0.155473 (* 1 = 0.155473 loss)
I0502 11:40:04.108511 26473 sgd_solver.cpp:106] Iteration 182100, lr = 1.80144e-06
I0502 11:40:04.113282 26473 solver.cpp:242] Iteration 182100 (105.877 iter/s, 0.944488s/100 iter), loss = 0.116445
I0502 11:40:04.113306 26473 solver.cpp:261]     Train net output #0: loss = 0.116445 (* 1 = 0.116445 loss)
I0502 11:40:04.113314 26473 sgd_solver.cpp:106] Iteration 182100, lr = 1.80144e-06
I0502 11:40:05.051511 26473 solver.cpp:242] Iteration 182200 (106.046 iter/s, 0.942984s/100 iter), loss = 0.0359319
I0502 11:40:05.051548 26473 solver.cpp:261]     Train net output #0: loss = 0.0359319 (* 1 = 0.0359319 loss)
I0502 11:40:05.051558 26473 sgd_solver.cpp:106] Iteration 182200, lr = 1.80144e-06
I0502 11:40:05.056329 26473 solver.cpp:242] Iteration 182200 (106.044 iter/s, 0.943005s/100 iter), loss = 0.132918
I0502 11:40:05.056352 26473 solver.cpp:261]     Train net output #0: loss = 0.132918 (* 1 = 0.132918 loss)
I0502 11:40:05.056360 26473 sgd_solver.cpp:106] Iteration 182200, lr = 1.80144e-06
I0502 11:40:05.995514 26473 solver.cpp:242] Iteration 182300 (105.939 iter/s, 0.943939s/100 iter), loss = 0.0793694
I0502 11:40:05.995553 26473 solver.cpp:261]     Train net output #0: loss = 0.0793694 (* 1 = 0.0793694 loss)
I0502 11:40:05.995563 26473 sgd_solver.cpp:106] Iteration 182300, lr = 1.80144e-06
I0502 11:40:06.000457 26473 solver.cpp:242] Iteration 182300 (105.923 iter/s, 0.944078s/100 iter), loss = 0.0147419
I0502 11:40:06.000480 26473 solver.cpp:261]     Train net output #0: loss = 0.0147419 (* 1 = 0.0147419 loss)
I0502 11:40:06.000489 26473 sgd_solver.cpp:106] Iteration 182300, lr = 1.80144e-06
I0502 11:40:06.939813 26473 solver.cpp:242] Iteration 182400 (105.906 iter/s, 0.94423s/100 iter), loss = 0.173402
I0502 11:40:06.939851 26473 solver.cpp:261]     Train net output #0: loss = 0.173402 (* 1 = 0.173402 loss)
I0502 11:40:06.939859 26473 sgd_solver.cpp:106] Iteration 182400, lr = 1.80144e-06
I0502 11:40:06.944658 26473 solver.cpp:242] Iteration 182400 (105.914 iter/s, 0.944159s/100 iter), loss = 0.0704029
I0502 11:40:06.944680 26473 solver.cpp:261]     Train net output #0: loss = 0.0704029 (* 1 = 0.0704029 loss)
I0502 11:40:06.944689 26473 sgd_solver.cpp:106] Iteration 182400, lr = 1.80144e-06
I0502 11:40:07.880674 26473 solver.cpp:362] Iteration 182500, Testing net (#0)
I0502 11:40:07.880698 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:08.004997 26473 solver.cpp:429]     Test net output #0: loss = 0.179556 (* 1 = 0.179556 loss)
I0502 11:40:08.007869 26473 solver.cpp:242] Iteration 182500 (93.6329 iter/s, 1.068s/100 iter), loss = 0.0920588
I0502 11:40:08.007889 26473 solver.cpp:261]     Train net output #0: loss = 0.0920588 (* 1 = 0.0920588 loss)
I0502 11:40:08.007897 26473 sgd_solver.cpp:106] Iteration 182500, lr = 1.80144e-06
I0502 11:40:08.009516 26473 solver.cpp:362] Iteration 182500, Testing net (#0)
I0502 11:40:08.009528 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:08.140530 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:40:08.140575 26473 solver.cpp:429]     Test net output #1: loss = 0.0763465 (* 1 = 0.0763465 loss)
I0502 11:40:08.143512 26473 solver.cpp:242] Iteration 182500 (83.416 iter/s, 1.19881s/100 iter), loss = 0.152382
I0502 11:40:08.143532 26473 solver.cpp:261]     Train net output #0: loss = 0.152382 (* 1 = 0.152382 loss)
I0502 11:40:08.143540 26473 sgd_solver.cpp:106] Iteration 182500, lr = 1.80144e-06
I0502 11:40:09.084046 26473 solver.cpp:242] Iteration 182600 (92.9258 iter/s, 1.07613s/100 iter), loss = 0.377432
I0502 11:40:09.084084 26473 solver.cpp:261]     Train net output #0: loss = 0.377432 (* 1 = 0.377432 loss)
I0502 11:40:09.084094 26473 sgd_solver.cpp:106] Iteration 182600, lr = 1.80144e-06
I0502 11:40:09.088888 26473 solver.cpp:242] Iteration 182600 (105.782 iter/s, 0.945338s/100 iter), loss = 0.0138756
I0502 11:40:09.088912 26473 solver.cpp:261]     Train net output #0: loss = 0.0138756 (* 1 = 0.0138756 loss)
I0502 11:40:09.088929 26473 sgd_solver.cpp:106] Iteration 182600, lr = 1.80144e-06
I0502 11:40:10.028761 26473 solver.cpp:242] Iteration 182700 (105.859 iter/s, 0.944652s/100 iter), loss = 0.348238
I0502 11:40:10.028795 26473 solver.cpp:261]     Train net output #0: loss = 0.348238 (* 1 = 0.348238 loss)
I0502 11:40:10.028803 26473 sgd_solver.cpp:106] Iteration 182700, lr = 1.80144e-06
I0502 11:40:10.033558 26473 solver.cpp:242] Iteration 182700 (105.862 iter/s, 0.944628s/100 iter), loss = 0.103516
I0502 11:40:10.033582 26473 solver.cpp:261]     Train net output #0: loss = 0.103516 (* 1 = 0.103516 loss)
I0502 11:40:10.033591 26473 sgd_solver.cpp:106] Iteration 182700, lr = 1.80144e-06
I0502 11:40:10.973145 26473 solver.cpp:242] Iteration 182800 (105.896 iter/s, 0.944327s/100 iter), loss = 0.0593936
I0502 11:40:10.973176 26473 solver.cpp:261]     Train net output #0: loss = 0.0593936 (* 1 = 0.0593936 loss)
I0502 11:40:10.973186 26473 sgd_solver.cpp:106] Iteration 182800, lr = 1.80144e-06
I0502 11:40:10.978024 26473 solver.cpp:242] Iteration 182800 (105.886 iter/s, 0.944416s/100 iter), loss = 0.0266244
I0502 11:40:10.978046 26473 solver.cpp:261]     Train net output #0: loss = 0.0266244 (* 1 = 0.0266244 loss)
I0502 11:40:10.978055 26473 sgd_solver.cpp:106] Iteration 182800, lr = 1.80144e-06
I0502 11:40:11.916586 26473 solver.cpp:242] Iteration 182900 (106.002 iter/s, 0.943378s/100 iter), loss = 0.0869042
I0502 11:40:11.916628 26473 solver.cpp:261]     Train net output #0: loss = 0.0869042 (* 1 = 0.0869042 loss)
I0502 11:40:11.916637 26473 sgd_solver.cpp:106] Iteration 182900, lr = 1.80144e-06
I0502 11:40:11.921383 26473 solver.cpp:242] Iteration 182900 (106.009 iter/s, 0.94332s/100 iter), loss = 0.128483
I0502 11:40:11.921406 26473 solver.cpp:261]     Train net output #0: loss = 0.128483 (* 1 = 0.128483 loss)
I0502 11:40:11.921416 26473 sgd_solver.cpp:106] Iteration 182900, lr = 1.80144e-06
I0502 11:40:12.858935 26473 solver.cpp:362] Iteration 183000, Testing net (#0)
I0502 11:40:12.858963 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:12.983304 26473 solver.cpp:429]     Test net output #0: loss = 0.233555 (* 1 = 0.233555 loss)
I0502 11:40:12.986191 26473 solver.cpp:242] Iteration 183000 (93.4977 iter/s, 1.06955s/100 iter), loss = 0.147322
I0502 11:40:12.986212 26473 solver.cpp:261]     Train net output #0: loss = 0.147322 (* 1 = 0.147322 loss)
I0502 11:40:12.986219 26473 sgd_solver.cpp:106] Iteration 183000, lr = 1.80144e-06
I0502 11:40:12.987841 26473 solver.cpp:362] Iteration 183000, Testing net (#0)
I0502 11:40:12.987854 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:13.118660 26473 solver.cpp:429]     Test net output #0: accuracy = 0.961
I0502 11:40:13.118681 26473 solver.cpp:429]     Test net output #1: loss = 0.092913 (* 1 = 0.092913 loss)
I0502 11:40:13.121609 26473 solver.cpp:242] Iteration 183000 (83.3207 iter/s, 1.20018s/100 iter), loss = 0.0179196
I0502 11:40:13.121629 26473 solver.cpp:261]     Train net output #0: loss = 0.0179196 (* 1 = 0.0179196 loss)
I0502 11:40:13.121639 26473 sgd_solver.cpp:106] Iteration 183000, lr = 1.80144e-06
I0502 11:40:14.061017 26473 solver.cpp:242] Iteration 183100 (93.0426 iter/s, 1.07478s/100 iter), loss = 0.185097
I0502 11:40:14.061051 26473 solver.cpp:261]     Train net output #0: loss = 0.185097 (* 1 = 0.185097 loss)
I0502 11:40:14.061060 26473 sgd_solver.cpp:106] Iteration 183100, lr = 1.80144e-06
I0502 11:40:14.065814 26473 solver.cpp:242] Iteration 183100 (105.914 iter/s, 0.944166s/100 iter), loss = 0.165428
I0502 11:40:14.065836 26473 solver.cpp:261]     Train net output #0: loss = 0.165428 (* 1 = 0.165428 loss)
I0502 11:40:14.065845 26473 sgd_solver.cpp:106] Iteration 183100, lr = 1.80144e-06
I0502 11:40:15.005162 26473 solver.cpp:242] Iteration 183200 (105.923 iter/s, 0.944086s/100 iter), loss = 0.145139
I0502 11:40:15.005198 26473 solver.cpp:261]     Train net output #0: loss = 0.145139 (* 1 = 0.145139 loss)
I0502 11:40:15.005206 26473 sgd_solver.cpp:106] Iteration 183200, lr = 1.80144e-06
I0502 11:40:15.009943 26473 solver.cpp:242] Iteration 183200 (105.922 iter/s, 0.944089s/100 iter), loss = 0.0181781
I0502 11:40:15.009965 26473 solver.cpp:261]     Train net output #0: loss = 0.0181781 (* 1 = 0.0181781 loss)
I0502 11:40:15.009974 26473 sgd_solver.cpp:106] Iteration 183200, lr = 1.80144e-06
I0502 11:40:15.949966 26473 solver.cpp:242] Iteration 183300 (105.849 iter/s, 0.944743s/100 iter), loss = 0.129248
I0502 11:40:15.950011 26473 solver.cpp:261]     Train net output #0: loss = 0.129248 (* 1 = 0.129248 loss)
I0502 11:40:15.950019 26473 sgd_solver.cpp:106] Iteration 183300, lr = 1.80144e-06
I0502 11:40:15.954845 26473 solver.cpp:242] Iteration 183300 (105.837 iter/s, 0.944853s/100 iter), loss = 0.0864799
I0502 11:40:15.954869 26473 solver.cpp:261]     Train net output #0: loss = 0.0864799 (* 1 = 0.0864799 loss)
I0502 11:40:15.954879 26473 sgd_solver.cpp:106] Iteration 183300, lr = 1.80144e-06
I0502 11:40:16.894199 26473 solver.cpp:242] Iteration 183400 (105.914 iter/s, 0.944164s/100 iter), loss = 0.116324
I0502 11:40:16.894242 26473 solver.cpp:261]     Train net output #0: loss = 0.116324 (* 1 = 0.116324 loss)
I0502 11:40:16.894250 26473 sgd_solver.cpp:106] Iteration 183400, lr = 1.80144e-06
I0502 11:40:16.899054 26473 solver.cpp:242] Iteration 183400 (105.914 iter/s, 0.94416s/100 iter), loss = 0.0181489
I0502 11:40:16.899076 26473 solver.cpp:261]     Train net output #0: loss = 0.0181489 (* 1 = 0.0181489 loss)
I0502 11:40:16.899085 26473 sgd_solver.cpp:106] Iteration 183400, lr = 1.80144e-06
I0502 11:40:17.835700 26473 solver.cpp:362] Iteration 183500, Testing net (#0)
I0502 11:40:17.835724 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:17.960005 26473 solver.cpp:429]     Test net output #0: loss = 0.262699 (* 1 = 0.262699 loss)
I0502 11:40:17.962885 26473 solver.cpp:242] Iteration 183500 (93.5781 iter/s, 1.06863s/100 iter), loss = 0.122418
I0502 11:40:17.962906 26473 solver.cpp:261]     Train net output #0: loss = 0.122418 (* 1 = 0.122418 loss)
I0502 11:40:17.962914 26473 sgd_solver.cpp:106] Iteration 183500, lr = 1.80144e-06
I0502 11:40:17.964542 26473 solver.cpp:362] Iteration 183500, Testing net (#0)
I0502 11:40:17.964560 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:18.095242 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9645
I0502 11:40:18.095263 26473 solver.cpp:429]     Test net output #1: loss = 0.0781509 (* 1 = 0.0781509 loss)
I0502 11:40:18.098193 26473 solver.cpp:242] Iteration 183500 (83.3962 iter/s, 1.1991s/100 iter), loss = 0.0388901
I0502 11:40:18.098214 26473 solver.cpp:261]     Train net output #0: loss = 0.0388901 (* 1 = 0.0388901 loss)
I0502 11:40:18.098222 26473 sgd_solver.cpp:106] Iteration 183500, lr = 1.80144e-06
I0502 11:40:19.037088 26473 solver.cpp:242] Iteration 183600 (93.0969 iter/s, 1.07415s/100 iter), loss = 0.0764172
I0502 11:40:19.037132 26473 solver.cpp:261]     Train net output #0: loss = 0.0764172 (* 1 = 0.0764172 loss)
I0502 11:40:19.037142 26473 sgd_solver.cpp:106] Iteration 183600, lr = 1.80144e-06
I0502 11:40:19.041957 26473 solver.cpp:242] Iteration 183600 (105.963 iter/s, 0.943725s/100 iter), loss = 0.0113664
I0502 11:40:19.041982 26473 solver.cpp:261]     Train net output #0: loss = 0.0113664 (* 1 = 0.0113664 loss)
I0502 11:40:19.041991 26473 sgd_solver.cpp:106] Iteration 183600, lr = 1.80144e-06
I0502 11:40:19.980753 26473 solver.cpp:242] Iteration 183700 (105.978 iter/s, 0.943592s/100 iter), loss = 0.0797262
I0502 11:40:19.980794 26473 solver.cpp:261]     Train net output #0: loss = 0.0797262 (* 1 = 0.0797262 loss)
I0502 11:40:19.980803 26473 sgd_solver.cpp:106] Iteration 183700, lr = 1.80144e-06
I0502 11:40:19.985577 26473 solver.cpp:242] Iteration 183700 (105.98 iter/s, 0.943578s/100 iter), loss = 0.0572855
I0502 11:40:19.985600 26473 solver.cpp:261]     Train net output #0: loss = 0.0572855 (* 1 = 0.0572855 loss)
I0502 11:40:19.985610 26473 sgd_solver.cpp:106] Iteration 183700, lr = 1.80144e-06
I0502 11:40:20.924187 26473 solver.cpp:242] Iteration 183800 (106.003 iter/s, 0.943368s/100 iter), loss = 0.125826
I0502 11:40:20.924237 26473 solver.cpp:261]     Train net output #0: loss = 0.125826 (* 1 = 0.125826 loss)
I0502 11:40:20.924245 26473 sgd_solver.cpp:106] Iteration 183800, lr = 1.80144e-06
I0502 11:40:20.929080 26473 solver.cpp:242] Iteration 183800 (105.994 iter/s, 0.943453s/100 iter), loss = 0.0721593
I0502 11:40:20.929105 26473 solver.cpp:261]     Train net output #0: loss = 0.0721593 (* 1 = 0.0721593 loss)
I0502 11:40:20.929113 26473 sgd_solver.cpp:106] Iteration 183800, lr = 1.80144e-06
I0502 11:40:21.869004 26473 solver.cpp:242] Iteration 183900 (105.849 iter/s, 0.944744s/100 iter), loss = 0.124998
I0502 11:40:21.869043 26473 solver.cpp:261]     Train net output #0: loss = 0.124998 (* 1 = 0.124998 loss)
I0502 11:40:21.869052 26473 sgd_solver.cpp:106] Iteration 183900, lr = 1.80144e-06
I0502 11:40:21.873862 26473 solver.cpp:242] Iteration 183900 (105.85 iter/s, 0.944734s/100 iter), loss = 0.055095
I0502 11:40:21.873885 26473 solver.cpp:261]     Train net output #0: loss = 0.055095 (* 1 = 0.055095 loss)
I0502 11:40:21.873894 26473 sgd_solver.cpp:106] Iteration 183900, lr = 1.80144e-06
I0502 11:40:22.810510 26473 solver.cpp:362] Iteration 184000, Testing net (#0)
I0502 11:40:22.810537 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:22.934756 26473 solver.cpp:429]     Test net output #0: loss = 0.221444 (* 1 = 0.221444 loss)
I0502 11:40:22.937623 26473 solver.cpp:242] Iteration 184000 (93.5838 iter/s, 1.06856s/100 iter), loss = 0.207298
I0502 11:40:22.937643 26473 solver.cpp:261]     Train net output #0: loss = 0.207298 (* 1 = 0.207298 loss)
I0502 11:40:22.937650 26473 sgd_solver.cpp:106] Iteration 184000, lr = 1.80144e-06
I0502 11:40:22.939265 26473 solver.cpp:362] Iteration 184000, Testing net (#0)
I0502 11:40:22.939278 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:23.070143 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:40:23.070165 26473 solver.cpp:429]     Test net output #1: loss = 0.0738306 (* 1 = 0.0738306 loss)
I0502 11:40:23.073087 26473 solver.cpp:242] Iteration 184000 (83.3903 iter/s, 1.19918s/100 iter), loss = 0.0931174
I0502 11:40:23.073107 26473 solver.cpp:261]     Train net output #0: loss = 0.0931174 (* 1 = 0.0931174 loss)
I0502 11:40:23.073117 26473 sgd_solver.cpp:106] Iteration 184000, lr = 1.80144e-06
I0502 11:40:24.012717 26473 solver.cpp:242] Iteration 184100 (93.0196 iter/s, 1.07504s/100 iter), loss = 0.124567
I0502 11:40:24.012758 26473 solver.cpp:261]     Train net output #0: loss = 0.124567 (* 1 = 0.124567 loss)
I0502 11:40:24.012768 26473 sgd_solver.cpp:106] Iteration 184100, lr = 1.80144e-06
I0502 11:40:24.017535 26473 solver.cpp:242] Iteration 184100 (105.886 iter/s, 0.944411s/100 iter), loss = 0.00532516
I0502 11:40:24.017559 26473 solver.cpp:261]     Train net output #0: loss = 0.00532516 (* 1 = 0.00532516 loss)
I0502 11:40:24.017567 26473 sgd_solver.cpp:106] Iteration 184100, lr = 1.80144e-06
I0502 11:40:24.956786 26473 solver.cpp:242] Iteration 184200 (105.932 iter/s, 0.943999s/100 iter), loss = 0.309084
I0502 11:40:24.956831 26473 solver.cpp:261]     Train net output #0: loss = 0.309084 (* 1 = 0.309084 loss)
I0502 11:40:24.956840 26473 sgd_solver.cpp:106] Iteration 184200, lr = 1.80144e-06
I0502 11:40:24.961619 26473 solver.cpp:242] Iteration 184200 (105.927 iter/s, 0.944043s/100 iter), loss = 0.0408382
I0502 11:40:24.961642 26473 solver.cpp:261]     Train net output #0: loss = 0.0408382 (* 1 = 0.0408382 loss)
I0502 11:40:24.961650 26473 sgd_solver.cpp:106] Iteration 184200, lr = 1.80144e-06
I0502 11:40:25.901289 26473 solver.cpp:242] Iteration 184300 (105.884 iter/s, 0.944432s/100 iter), loss = 0.187477
I0502 11:40:25.901329 26473 solver.cpp:261]     Train net output #0: loss = 0.187477 (* 1 = 0.187477 loss)
I0502 11:40:25.901337 26473 sgd_solver.cpp:106] Iteration 184300, lr = 1.80144e-06
I0502 11:40:25.906080 26473 solver.cpp:242] Iteration 184300 (105.885 iter/s, 0.944419s/100 iter), loss = 0.122133
I0502 11:40:25.906101 26473 solver.cpp:261]     Train net output #0: loss = 0.122133 (* 1 = 0.122133 loss)
I0502 11:40:25.906118 26473 sgd_solver.cpp:106] Iteration 184300, lr = 1.80144e-06
I0502 11:40:26.845564 26473 solver.cpp:242] Iteration 184400 (105.908 iter/s, 0.944212s/100 iter), loss = 0.154972
I0502 11:40:26.845599 26473 solver.cpp:261]     Train net output #0: loss = 0.154972 (* 1 = 0.154972 loss)
I0502 11:40:26.845608 26473 sgd_solver.cpp:106] Iteration 184400, lr = 1.80144e-06
I0502 11:40:26.850508 26473 solver.cpp:242] Iteration 184400 (105.889 iter/s, 0.944381s/100 iter), loss = 0.00224941
I0502 11:40:26.850533 26473 solver.cpp:261]     Train net output #0: loss = 0.00224941 (* 1 = 0.00224941 loss)
I0502 11:40:26.850540 26473 sgd_solver.cpp:106] Iteration 184400, lr = 1.80144e-06
I0502 11:40:27.786412 26473 solver.cpp:362] Iteration 184500, Testing net (#0)
I0502 11:40:27.786434 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:27.910647 26473 solver.cpp:429]     Test net output #0: loss = 0.236846 (* 1 = 0.236846 loss)
I0502 11:40:27.913523 26473 solver.cpp:242] Iteration 184500 (93.6413 iter/s, 1.06791s/100 iter), loss = 0.124275
I0502 11:40:27.913543 26473 solver.cpp:261]     Train net output #0: loss = 0.124275 (* 1 = 0.124275 loss)
I0502 11:40:27.913552 26473 sgd_solver.cpp:106] Iteration 184500, lr = 1.80144e-06
I0502 11:40:27.915170 26473 solver.cpp:362] Iteration 184500, Testing net (#0)
I0502 11:40:27.915184 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:28.045789 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:40:28.045809 26473 solver.cpp:429]     Test net output #1: loss = 0.0784119 (* 1 = 0.0784119 loss)
I0502 11:40:28.048722 26473 solver.cpp:242] Iteration 184500 (83.4606 iter/s, 1.19817s/100 iter), loss = 0.185594
I0502 11:40:28.048743 26473 solver.cpp:261]     Train net output #0: loss = 0.185594 (* 1 = 0.185594 loss)
I0502 11:40:28.048750 26473 sgd_solver.cpp:106] Iteration 184500, lr = 1.80144e-06
I0502 11:40:28.988451 26473 solver.cpp:242] Iteration 184600 (93.034 iter/s, 1.07488s/100 iter), loss = 0.0953649
I0502 11:40:28.988489 26473 solver.cpp:261]     Train net output #0: loss = 0.0953649 (* 1 = 0.0953649 loss)
I0502 11:40:28.988498 26473 sgd_solver.cpp:106] Iteration 184600, lr = 1.80144e-06
I0502 11:40:28.993239 26473 solver.cpp:242] Iteration 184600 (105.878 iter/s, 0.944479s/100 iter), loss = 0.0995776
I0502 11:40:28.993263 26473 solver.cpp:261]     Train net output #0: loss = 0.0995776 (* 1 = 0.0995776 loss)
I0502 11:40:28.993271 26473 sgd_solver.cpp:106] Iteration 184600, lr = 1.80144e-06
I0502 11:40:29.932098 26473 solver.cpp:242] Iteration 184700 (105.979 iter/s, 0.94358s/100 iter), loss = 0.132205
I0502 11:40:29.932135 26473 solver.cpp:261]     Train net output #0: loss = 0.132205 (* 1 = 0.132205 loss)
I0502 11:40:29.932144 26473 sgd_solver.cpp:106] Iteration 184700, lr = 1.80144e-06
I0502 11:40:29.936942 26473 solver.cpp:242] Iteration 184700 (105.97 iter/s, 0.943662s/100 iter), loss = 0.0972302
I0502 11:40:29.936965 26473 solver.cpp:261]     Train net output #0: loss = 0.0972302 (* 1 = 0.0972302 loss)
I0502 11:40:29.936974 26473 sgd_solver.cpp:106] Iteration 184700, lr = 1.80144e-06
I0502 11:40:30.877212 26473 solver.cpp:242] Iteration 184800 (105.814 iter/s, 0.945052s/100 iter), loss = 0.0712541
I0502 11:40:30.877243 26473 solver.cpp:261]     Train net output #0: loss = 0.0712541 (* 1 = 0.0712541 loss)
I0502 11:40:30.877251 26473 sgd_solver.cpp:106] Iteration 184800, lr = 1.80144e-06
I0502 11:40:30.881990 26473 solver.cpp:242] Iteration 184800 (105.819 iter/s, 0.945008s/100 iter), loss = 0.0735736
I0502 11:40:30.882014 26473 solver.cpp:261]     Train net output #0: loss = 0.0735736 (* 1 = 0.0735736 loss)
I0502 11:40:30.882022 26473 sgd_solver.cpp:106] Iteration 184800, lr = 1.80144e-06
I0502 11:40:31.821199 26473 solver.cpp:242] Iteration 184900 (105.94 iter/s, 0.943931s/100 iter), loss = 0.120268
I0502 11:40:31.821244 26473 solver.cpp:261]     Train net output #0: loss = 0.120268 (* 1 = 0.120268 loss)
I0502 11:40:31.821254 26473 sgd_solver.cpp:106] Iteration 184900, lr = 1.80144e-06
I0502 11:40:31.826071 26473 solver.cpp:242] Iteration 184900 (105.929 iter/s, 0.944032s/100 iter), loss = 0.0161672
I0502 11:40:31.826103 26473 solver.cpp:261]     Train net output #0: loss = 0.0161672 (* 1 = 0.0161672 loss)
I0502 11:40:31.826113 26473 sgd_solver.cpp:106] Iteration 184900, lr = 1.80144e-06
I0502 11:40:32.763180 26473 solver.cpp:362] Iteration 185000, Testing net (#0)
I0502 11:40:32.763207 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:32.887609 26473 solver.cpp:429]     Test net output #0: loss = 0.219795 (* 1 = 0.219795 loss)
I0502 11:40:32.890481 26473 solver.cpp:242] Iteration 185000 (93.5262 iter/s, 1.06922s/100 iter), loss = 0.102111
I0502 11:40:32.890501 26473 solver.cpp:261]     Train net output #0: loss = 0.102111 (* 1 = 0.102111 loss)
I0502 11:40:32.890511 26473 sgd_solver.cpp:106] Iteration 185000, lr = 1.80144e-06
I0502 11:40:32.892135 26473 solver.cpp:362] Iteration 185000, Testing net (#0)
I0502 11:40:32.892149 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:33.022760 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9645
I0502 11:40:33.022783 26473 solver.cpp:429]     Test net output #1: loss = 0.0778222 (* 1 = 0.0778222 loss)
I0502 11:40:33.025714 26473 solver.cpp:242] Iteration 185000 (83.3618 iter/s, 1.19959s/100 iter), loss = 0.107671
I0502 11:40:33.025734 26473 solver.cpp:261]     Train net output #0: loss = 0.107671 (* 1 = 0.107671 loss)
I0502 11:40:33.025743 26473 sgd_solver.cpp:106] Iteration 185000, lr = 1.80144e-06
I0502 11:40:33.984036 26473 solver.cpp:242] Iteration 185100 (91.4492 iter/s, 1.0935s/100 iter), loss = 0.254233
I0502 11:40:33.984071 26473 solver.cpp:261]     Train net output #0: loss = 0.254233 (* 1 = 0.254233 loss)
I0502 11:40:33.984078 26473 sgd_solver.cpp:106] Iteration 185100, lr = 1.80144e-06
I0502 11:40:33.988854 26473 solver.cpp:242] Iteration 185100 (103.831 iter/s, 0.963101s/100 iter), loss = 0.0802935
I0502 11:40:33.988878 26473 solver.cpp:261]     Train net output #0: loss = 0.0802935 (* 1 = 0.0802935 loss)
I0502 11:40:33.988885 26473 sgd_solver.cpp:106] Iteration 185100, lr = 1.80144e-06
I0502 11:40:34.927845 26473 solver.cpp:242] Iteration 185200 (105.961 iter/s, 0.943746s/100 iter), loss = 0.62808
I0502 11:40:34.927880 26473 solver.cpp:261]     Train net output #0: loss = 0.62808 (* 1 = 0.62808 loss)
I0502 11:40:34.927888 26473 sgd_solver.cpp:106] Iteration 185200, lr = 1.80144e-06
I0502 11:40:34.932704 26473 solver.cpp:242] Iteration 185200 (105.954 iter/s, 0.943809s/100 iter), loss = 0.0861596
I0502 11:40:34.932727 26473 solver.cpp:261]     Train net output #0: loss = 0.0861596 (* 1 = 0.0861596 loss)
I0502 11:40:34.932736 26473 sgd_solver.cpp:106] Iteration 185200, lr = 1.80144e-06
I0502 11:40:35.871695 26473 solver.cpp:242] Iteration 185300 (105.956 iter/s, 0.943791s/100 iter), loss = 0.0702967
I0502 11:40:35.871729 26473 solver.cpp:261]     Train net output #0: loss = 0.0702967 (* 1 = 0.0702967 loss)
I0502 11:40:35.871738 26473 sgd_solver.cpp:106] Iteration 185300, lr = 1.80144e-06
I0502 11:40:35.876526 26473 solver.cpp:242] Iteration 185300 (105.957 iter/s, 0.943781s/100 iter), loss = 0.0123518
I0502 11:40:35.876549 26473 solver.cpp:261]     Train net output #0: loss = 0.0123518 (* 1 = 0.0123518 loss)
I0502 11:40:35.876564 26473 sgd_solver.cpp:106] Iteration 185300, lr = 1.80144e-06
I0502 11:40:36.816354 26473 solver.cpp:242] Iteration 185400 (105.865 iter/s, 0.944599s/100 iter), loss = 0.0898403
I0502 11:40:36.816396 26473 solver.cpp:261]     Train net output #0: loss = 0.0898403 (* 1 = 0.0898403 loss)
I0502 11:40:36.816404 26473 sgd_solver.cpp:106] Iteration 185400, lr = 1.80144e-06
I0502 11:40:36.821218 26473 solver.cpp:242] Iteration 185400 (105.86 iter/s, 0.944643s/100 iter), loss = 0.0606959
I0502 11:40:36.821241 26473 solver.cpp:261]     Train net output #0: loss = 0.0606959 (* 1 = 0.0606959 loss)
I0502 11:40:36.821249 26473 sgd_solver.cpp:106] Iteration 185400, lr = 1.80144e-06
I0502 11:40:37.758271 26473 solver.cpp:362] Iteration 185500, Testing net (#0)
I0502 11:40:37.758301 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:37.882601 26473 solver.cpp:429]     Test net output #0: loss = 0.230335 (* 1 = 0.230335 loss)
I0502 11:40:37.885473 26473 solver.cpp:242] Iteration 185500 (93.5403 iter/s, 1.06906s/100 iter), loss = 0.128798
I0502 11:40:37.885493 26473 solver.cpp:261]     Train net output #0: loss = 0.128798 (* 1 = 0.128798 loss)
I0502 11:40:37.885501 26473 sgd_solver.cpp:106] Iteration 185500, lr = 1.80144e-06
I0502 11:40:37.887130 26473 solver.cpp:362] Iteration 185500, Testing net (#0)
I0502 11:40:37.887143 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:38.017873 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:40:38.017892 26473 solver.cpp:429]     Test net output #1: loss = 0.085729 (* 1 = 0.085729 loss)
I0502 11:40:38.020819 26473 solver.cpp:242] Iteration 185500 (83.3641 iter/s, 1.19956s/100 iter), loss = 0.0302061
I0502 11:40:38.020840 26473 solver.cpp:261]     Train net output #0: loss = 0.0302061 (* 1 = 0.0302061 loss)
I0502 11:40:38.020848 26473 sgd_solver.cpp:106] Iteration 185500, lr = 1.80144e-06
I0502 11:40:38.959702 26473 solver.cpp:242] Iteration 185600 (93.0946 iter/s, 1.07418s/100 iter), loss = 0.173179
I0502 11:40:38.959744 26473 solver.cpp:261]     Train net output #0: loss = 0.173179 (* 1 = 0.173179 loss)
I0502 11:40:38.959753 26473 sgd_solver.cpp:106] Iteration 185600, lr = 1.80144e-06
I0502 11:40:38.964526 26473 solver.cpp:242] Iteration 185600 (105.969 iter/s, 0.943668s/100 iter), loss = 0.117042
I0502 11:40:38.964553 26473 solver.cpp:261]     Train net output #0: loss = 0.117042 (* 1 = 0.117042 loss)
I0502 11:40:38.964563 26473 sgd_solver.cpp:106] Iteration 185600, lr = 1.80144e-06
I0502 11:40:39.903693 26473 solver.cpp:242] Iteration 185700 (105.941 iter/s, 0.943921s/100 iter), loss = 0.308893
I0502 11:40:39.903750 26473 solver.cpp:261]     Train net output #0: loss = 0.308893 (* 1 = 0.308893 loss)
I0502 11:40:39.903759 26473 sgd_solver.cpp:106] Iteration 185700, lr = 1.80144e-06
I0502 11:40:39.908557 26473 solver.cpp:242] Iteration 185700 (105.934 iter/s, 0.943986s/100 iter), loss = 0.138855
I0502 11:40:39.908581 26473 solver.cpp:261]     Train net output #0: loss = 0.138855 (* 1 = 0.138855 loss)
I0502 11:40:39.908591 26473 sgd_solver.cpp:106] Iteration 185700, lr = 1.80144e-06
I0502 11:40:40.848692 26473 solver.cpp:242] Iteration 185800 (105.83 iter/s, 0.944915s/100 iter), loss = 0.0625722
I0502 11:40:40.848734 26473 solver.cpp:261]     Train net output #0: loss = 0.0625722 (* 1 = 0.0625722 loss)
I0502 11:40:40.848743 26473 sgd_solver.cpp:106] Iteration 185800, lr = 1.80144e-06
I0502 11:40:40.853500 26473 solver.cpp:242] Iteration 185800 (105.831 iter/s, 0.944901s/100 iter), loss = 0.0277652
I0502 11:40:40.853523 26473 solver.cpp:261]     Train net output #0: loss = 0.0277652 (* 1 = 0.0277652 loss)
I0502 11:40:40.853533 26473 sgd_solver.cpp:106] Iteration 185800, lr = 1.80144e-06
I0502 11:40:41.792948 26473 solver.cpp:242] Iteration 185900 (105.911 iter/s, 0.944185s/100 iter), loss = 0.392008
I0502 11:40:41.792985 26473 solver.cpp:261]     Train net output #0: loss = 0.392008 (* 1 = 0.392008 loss)
I0502 11:40:41.792995 26473 sgd_solver.cpp:106] Iteration 185900, lr = 1.80144e-06
I0502 11:40:41.797853 26473 solver.cpp:242] Iteration 185900 (105.898 iter/s, 0.944303s/100 iter), loss = 0.107191
I0502 11:40:41.797876 26473 solver.cpp:261]     Train net output #0: loss = 0.107191 (* 1 = 0.107191 loss)
I0502 11:40:41.797885 26473 sgd_solver.cpp:106] Iteration 185900, lr = 1.80144e-06
I0502 11:40:42.734298 26473 solver.cpp:362] Iteration 186000, Testing net (#0)
I0502 11:40:42.734324 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:42.858644 26473 solver.cpp:429]     Test net output #0: loss = 0.188915 (* 1 = 0.188915 loss)
I0502 11:40:42.861521 26473 solver.cpp:242] Iteration 186000 (93.5876 iter/s, 1.06852s/100 iter), loss = 0.285296
I0502 11:40:42.861541 26473 solver.cpp:261]     Train net output #0: loss = 0.285296 (* 1 = 0.285296 loss)
I0502 11:40:42.861549 26473 sgd_solver.cpp:106] Iteration 186000, lr = 1.80144e-06
I0502 11:40:42.863171 26473 solver.cpp:362] Iteration 186000, Testing net (#0)
I0502 11:40:42.863193 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:42.993789 26473 solver.cpp:429]     Test net output #0: accuracy = 0.967
I0502 11:40:42.993811 26473 solver.cpp:429]     Test net output #1: loss = 0.0767051 (* 1 = 0.0767051 loss)
I0502 11:40:42.996745 26473 solver.cpp:242] Iteration 186000 (83.4134 iter/s, 1.19885s/100 iter), loss = 0.0336232
I0502 11:40:42.996767 26473 solver.cpp:261]     Train net output #0: loss = 0.0336232 (* 1 = 0.0336232 loss)
I0502 11:40:42.996774 26473 sgd_solver.cpp:106] Iteration 186000, lr = 1.80144e-06
I0502 11:40:43.935669 26473 solver.cpp:242] Iteration 186100 (93.1014 iter/s, 1.0741s/100 iter), loss = 0.0241362
I0502 11:40:43.935708 26473 solver.cpp:261]     Train net output #0: loss = 0.0241362 (* 1 = 0.0241362 loss)
I0502 11:40:43.935717 26473 sgd_solver.cpp:106] Iteration 186100, lr = 1.80144e-06
I0502 11:40:43.940487 26473 solver.cpp:242] Iteration 186100 (105.965 iter/s, 0.943704s/100 iter), loss = 0.00820645
I0502 11:40:43.940510 26473 solver.cpp:261]     Train net output #0: loss = 0.00820645 (* 1 = 0.00820645 loss)
I0502 11:40:43.940520 26473 sgd_solver.cpp:106] Iteration 186100, lr = 1.80144e-06
I0502 11:40:44.880208 26473 solver.cpp:242] Iteration 186200 (105.879 iter/s, 0.944471s/100 iter), loss = 0.126868
I0502 11:40:44.880252 26473 solver.cpp:261]     Train net output #0: loss = 0.126868 (* 1 = 0.126868 loss)
I0502 11:40:44.880261 26473 sgd_solver.cpp:106] Iteration 186200, lr = 1.80144e-06
I0502 11:40:44.885025 26473 solver.cpp:242] Iteration 186200 (105.877 iter/s, 0.944497s/100 iter), loss = 0.0508874
I0502 11:40:44.885047 26473 solver.cpp:261]     Train net output #0: loss = 0.0508874 (* 1 = 0.0508874 loss)
I0502 11:40:44.885056 26473 sgd_solver.cpp:106] Iteration 186200, lr = 1.80144e-06
I0502 11:40:45.823627 26473 solver.cpp:242] Iteration 186300 (106.005 iter/s, 0.943349s/100 iter), loss = 0.168255
I0502 11:40:45.823668 26473 solver.cpp:261]     Train net output #0: loss = 0.168255 (* 1 = 0.168255 loss)
I0502 11:40:45.823676 26473 sgd_solver.cpp:106] Iteration 186300, lr = 1.80144e-06
I0502 11:40:45.828444 26473 solver.cpp:242] Iteration 186300 (106.002 iter/s, 0.943378s/100 iter), loss = 0.0146589
I0502 11:40:45.828469 26473 solver.cpp:261]     Train net output #0: loss = 0.0146589 (* 1 = 0.0146589 loss)
I0502 11:40:45.828476 26473 sgd_solver.cpp:106] Iteration 186300, lr = 1.80144e-06
I0502 11:40:46.767297 26473 solver.cpp:242] Iteration 186400 (105.977 iter/s, 0.943604s/100 iter), loss = 0.0423299
I0502 11:40:46.767336 26473 solver.cpp:261]     Train net output #0: loss = 0.0423299 (* 1 = 0.0423299 loss)
I0502 11:40:46.767345 26473 sgd_solver.cpp:106] Iteration 186400, lr = 1.80144e-06
I0502 11:40:46.772171 26473 solver.cpp:242] Iteration 186400 (105.968 iter/s, 0.943677s/100 iter), loss = 0.0437039
I0502 11:40:46.772194 26473 solver.cpp:261]     Train net output #0: loss = 0.0437039 (* 1 = 0.0437039 loss)
I0502 11:40:46.772203 26473 sgd_solver.cpp:106] Iteration 186400, lr = 1.80144e-06
I0502 11:40:47.709928 26473 solver.cpp:362] Iteration 186500, Testing net (#0)
I0502 11:40:47.709950 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:47.834250 26473 solver.cpp:429]     Test net output #0: loss = 0.256194 (* 1 = 0.256194 loss)
I0502 11:40:47.837121 26473 solver.cpp:242] Iteration 186500 (93.4783 iter/s, 1.06977s/100 iter), loss = 0.177242
I0502 11:40:47.837141 26473 solver.cpp:261]     Train net output #0: loss = 0.177242 (* 1 = 0.177242 loss)
I0502 11:40:47.837151 26473 sgd_solver.cpp:106] Iteration 186500, lr = 1.80144e-06
I0502 11:40:47.838836 26473 solver.cpp:362] Iteration 186500, Testing net (#0)
I0502 11:40:47.838850 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:47.969420 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:40:47.969441 26473 solver.cpp:429]     Test net output #1: loss = 0.0802194 (* 1 = 0.0802194 loss)
I0502 11:40:47.972373 26473 solver.cpp:242] Iteration 186500 (83.3224 iter/s, 1.20016s/100 iter), loss = 0.0330719
I0502 11:40:47.972401 26473 solver.cpp:261]     Train net output #0: loss = 0.0330719 (* 1 = 0.0330719 loss)
I0502 11:40:47.972410 26473 sgd_solver.cpp:106] Iteration 186500, lr = 1.80144e-06
I0502 11:40:48.912119 26473 solver.cpp:242] Iteration 186600 (93.0279 iter/s, 1.07495s/100 iter), loss = 0.19958
I0502 11:40:48.912155 26473 solver.cpp:261]     Train net output #0: loss = 0.19958 (* 1 = 0.19958 loss)
I0502 11:40:48.912164 26473 sgd_solver.cpp:106] Iteration 186600, lr = 1.80144e-06
I0502 11:40:48.916939 26473 solver.cpp:242] Iteration 186600 (105.874 iter/s, 0.944519s/100 iter), loss = 0.0623128
I0502 11:40:48.916962 26473 solver.cpp:261]     Train net output #0: loss = 0.0623128 (* 1 = 0.0623128 loss)
I0502 11:40:48.916970 26473 sgd_solver.cpp:106] Iteration 186600, lr = 1.80144e-06
I0502 11:40:49.856555 26473 solver.cpp:242] Iteration 186700 (105.891 iter/s, 0.944368s/100 iter), loss = 0.173762
I0502 11:40:49.856593 26473 solver.cpp:261]     Train net output #0: loss = 0.173762 (* 1 = 0.173762 loss)
I0502 11:40:49.856602 26473 sgd_solver.cpp:106] Iteration 186700, lr = 1.80144e-06
I0502 11:40:49.861369 26473 solver.cpp:242] Iteration 186700 (105.889 iter/s, 0.944389s/100 iter), loss = 0.0143916
I0502 11:40:49.861392 26473 solver.cpp:261]     Train net output #0: loss = 0.0143916 (* 1 = 0.0143916 loss)
I0502 11:40:49.861402 26473 sgd_solver.cpp:106] Iteration 186700, lr = 1.80144e-06
I0502 11:40:50.800726 26473 solver.cpp:242] Iteration 186800 (105.92 iter/s, 0.944107s/100 iter), loss = 0.206051
I0502 11:40:50.800765 26473 solver.cpp:261]     Train net output #0: loss = 0.206051 (* 1 = 0.206051 loss)
I0502 11:40:50.800773 26473 sgd_solver.cpp:106] Iteration 186800, lr = 1.80144e-06
I0502 11:40:50.805517 26473 solver.cpp:242] Iteration 186800 (105.92 iter/s, 0.944106s/100 iter), loss = 0.0581091
I0502 11:40:50.805541 26473 solver.cpp:261]     Train net output #0: loss = 0.0581091 (* 1 = 0.0581091 loss)
I0502 11:40:50.805548 26473 sgd_solver.cpp:106] Iteration 186800, lr = 1.80144e-06
I0502 11:40:51.744393 26473 solver.cpp:242] Iteration 186900 (105.977 iter/s, 0.943604s/100 iter), loss = 0.0804301
I0502 11:40:51.744423 26473 solver.cpp:261]     Train net output #0: loss = 0.0804301 (* 1 = 0.0804301 loss)
I0502 11:40:51.744432 26473 sgd_solver.cpp:106] Iteration 186900, lr = 1.80144e-06
I0502 11:40:51.749178 26473 solver.cpp:242] Iteration 186900 (105.975 iter/s, 0.943621s/100 iter), loss = 0.07163
I0502 11:40:51.749202 26473 solver.cpp:261]     Train net output #0: loss = 0.07163 (* 1 = 0.07163 loss)
I0502 11:40:51.749210 26473 sgd_solver.cpp:106] Iteration 186900, lr = 1.80144e-06
I0502 11:40:52.686324 26473 solver.cpp:362] Iteration 187000, Testing net (#0)
I0502 11:40:52.686352 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:52.810603 26473 solver.cpp:429]     Test net output #0: loss = 0.20196 (* 1 = 0.20196 loss)
I0502 11:40:52.813472 26473 solver.cpp:242] Iteration 187000 (93.5428 iter/s, 1.06903s/100 iter), loss = 0.0513375
I0502 11:40:52.813493 26473 solver.cpp:261]     Train net output #0: loss = 0.0513375 (* 1 = 0.0513375 loss)
I0502 11:40:52.813501 26473 sgd_solver.cpp:106] Iteration 187000, lr = 1.80144e-06
I0502 11:40:52.815192 26473 solver.cpp:362] Iteration 187000, Testing net (#0)
I0502 11:40:52.815204 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:52.945628 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:40:52.945650 26473 solver.cpp:429]     Test net output #1: loss = 0.0746239 (* 1 = 0.0746239 loss)
I0502 11:40:52.948570 26473 solver.cpp:242] Iteration 187000 (83.3787 iter/s, 1.19935s/100 iter), loss = 0.168046
I0502 11:40:52.948590 26473 solver.cpp:261]     Train net output #0: loss = 0.168046 (* 1 = 0.168046 loss)
I0502 11:40:52.948599 26473 sgd_solver.cpp:106] Iteration 187000, lr = 1.80144e-06
I0502 11:40:53.887903 26473 solver.cpp:242] Iteration 187100 (93.0772 iter/s, 1.07438s/100 iter), loss = 0.0932988
I0502 11:40:53.887936 26473 solver.cpp:261]     Train net output #0: loss = 0.0932988 (* 1 = 0.0932988 loss)
I0502 11:40:53.887953 26473 sgd_solver.cpp:106] Iteration 187100, lr = 1.80144e-06
I0502 11:40:53.892714 26473 solver.cpp:242] Iteration 187100 (105.92 iter/s, 0.944106s/100 iter), loss = 0.087621
I0502 11:40:53.892737 26473 solver.cpp:261]     Train net output #0: loss = 0.087621 (* 1 = 0.087621 loss)
I0502 11:40:53.892746 26473 sgd_solver.cpp:106] Iteration 187100, lr = 1.80144e-06
I0502 11:40:54.833161 26473 solver.cpp:242] Iteration 187200 (105.798 iter/s, 0.945198s/100 iter), loss = 0.176193
I0502 11:40:54.833194 26473 solver.cpp:261]     Train net output #0: loss = 0.176193 (* 1 = 0.176193 loss)
I0502 11:40:54.833202 26473 sgd_solver.cpp:106] Iteration 187200, lr = 1.80144e-06
I0502 11:40:54.837962 26473 solver.cpp:242] Iteration 187200 (105.797 iter/s, 0.945206s/100 iter), loss = 0.046825
I0502 11:40:54.837985 26473 solver.cpp:261]     Train net output #0: loss = 0.046825 (* 1 = 0.046825 loss)
I0502 11:40:54.837993 26473 sgd_solver.cpp:106] Iteration 187200, lr = 1.80144e-06
I0502 11:40:55.777667 26473 solver.cpp:242] Iteration 187300 (105.882 iter/s, 0.944448s/100 iter), loss = 0.126694
I0502 11:40:55.777698 26473 solver.cpp:261]     Train net output #0: loss = 0.126694 (* 1 = 0.126694 loss)
I0502 11:40:55.777707 26473 sgd_solver.cpp:106] Iteration 187300, lr = 1.80144e-06
I0502 11:40:55.782542 26473 solver.cpp:242] Iteration 187300 (105.872 iter/s, 0.94454s/100 iter), loss = 0.0807544
I0502 11:40:55.782565 26473 solver.cpp:261]     Train net output #0: loss = 0.0807544 (* 1 = 0.0807544 loss)
I0502 11:40:55.782574 26473 sgd_solver.cpp:106] Iteration 187300, lr = 1.80144e-06
I0502 11:40:56.723821 26473 solver.cpp:242] Iteration 187400 (105.698 iter/s, 0.946094s/100 iter), loss = 0.163189
I0502 11:40:56.723865 26473 solver.cpp:261]     Train net output #0: loss = 0.163189 (* 1 = 0.163189 loss)
I0502 11:40:56.723875 26473 sgd_solver.cpp:106] Iteration 187400, lr = 1.80144e-06
I0502 11:40:56.728632 26473 solver.cpp:242] Iteration 187400 (105.703 iter/s, 0.946049s/100 iter), loss = 0.161264
I0502 11:40:56.728657 26473 solver.cpp:261]     Train net output #0: loss = 0.161264 (* 1 = 0.161264 loss)
I0502 11:40:56.728664 26473 sgd_solver.cpp:106] Iteration 187400, lr = 1.80144e-06
I0502 11:40:57.664654 26473 solver.cpp:362] Iteration 187500, Testing net (#0)
I0502 11:40:57.664681 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:57.789387 26473 solver.cpp:429]     Test net output #0: loss = 0.258097 (* 1 = 0.258097 loss)
I0502 11:40:57.792290 26473 solver.cpp:242] Iteration 187500 (93.5973 iter/s, 1.06841s/100 iter), loss = 0.217195
I0502 11:40:57.792310 26473 solver.cpp:261]     Train net output #0: loss = 0.217195 (* 1 = 0.217195 loss)
I0502 11:40:57.792318 26473 sgd_solver.cpp:106] Iteration 187500, lr = 1.80144e-06
I0502 11:40:57.794147 26473 solver.cpp:362] Iteration 187500, Testing net (#0)
I0502 11:40:57.794162 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:40:57.924994 26473 solver.cpp:429]     Test net output #0: accuracy = 0.96
I0502 11:40:57.925015 26473 solver.cpp:429]     Test net output #1: loss = 0.0808487 (* 1 = 0.0808487 loss)
I0502 11:40:57.927937 26473 solver.cpp:242] Iteration 187500 (83.3848 iter/s, 1.19926s/100 iter), loss = 0.0901581
I0502 11:40:57.927956 26473 solver.cpp:261]     Train net output #0: loss = 0.0901581 (* 1 = 0.0901581 loss)
I0502 11:40:57.927965 26473 sgd_solver.cpp:106] Iteration 187500, lr = 1.80144e-06
I0502 11:40:58.866926 26473 solver.cpp:242] Iteration 187600 (93.0595 iter/s, 1.07458s/100 iter), loss = 0.242648
I0502 11:40:58.866969 26473 solver.cpp:261]     Train net output #0: loss = 0.242648 (* 1 = 0.242648 loss)
I0502 11:40:58.866978 26473 sgd_solver.cpp:106] Iteration 187600, lr = 1.80144e-06
I0502 11:40:58.871748 26473 solver.cpp:242] Iteration 187600 (105.958 iter/s, 0.943774s/100 iter), loss = 0.0614882
I0502 11:40:58.871773 26473 solver.cpp:261]     Train net output #0: loss = 0.0614882 (* 1 = 0.0614882 loss)
I0502 11:40:58.871780 26473 sgd_solver.cpp:106] Iteration 187600, lr = 1.80144e-06
I0502 11:40:59.811843 26473 solver.cpp:242] Iteration 187700 (105.838 iter/s, 0.944843s/100 iter), loss = 0.0846782
I0502 11:40:59.811892 26473 solver.cpp:261]     Train net output #0: loss = 0.0846782 (* 1 = 0.0846782 loss)
I0502 11:40:59.811900 26473 sgd_solver.cpp:106] Iteration 187700, lr = 1.80144e-06
I0502 11:40:59.816707 26473 solver.cpp:242] Iteration 187700 (105.829 iter/s, 0.944916s/100 iter), loss = 0.124868
I0502 11:40:59.816731 26473 solver.cpp:261]     Train net output #0: loss = 0.124868 (* 1 = 0.124868 loss)
I0502 11:40:59.816740 26473 sgd_solver.cpp:106] Iteration 187700, lr = 1.80144e-06
I0502 11:41:00.769460 26473 solver.cpp:242] Iteration 187800 (104.434 iter/s, 0.957541s/100 iter), loss = 0.0772081
I0502 11:41:00.769520 26473 solver.cpp:261]     Train net output #0: loss = 0.0772081 (* 1 = 0.0772081 loss)
I0502 11:41:00.769533 26473 sgd_solver.cpp:106] Iteration 187800, lr = 1.80144e-06
I0502 11:41:00.774340 26473 solver.cpp:242] Iteration 187800 (104.429 iter/s, 0.957591s/100 iter), loss = 0.0226553
I0502 11:41:00.774365 26473 solver.cpp:261]     Train net output #0: loss = 0.0226553 (* 1 = 0.0226553 loss)
I0502 11:41:00.774374 26473 sgd_solver.cpp:106] Iteration 187800, lr = 1.80144e-06
I0502 11:41:01.713076 26473 solver.cpp:242] Iteration 187900 (105.985 iter/s, 0.943531s/100 iter), loss = 0.217908
I0502 11:41:01.713119 26473 solver.cpp:261]     Train net output #0: loss = 0.217908 (* 1 = 0.217908 loss)
I0502 11:41:01.713127 26473 sgd_solver.cpp:106] Iteration 187900, lr = 1.80144e-06
I0502 11:41:01.717872 26473 solver.cpp:242] Iteration 187900 (105.989 iter/s, 0.94349s/100 iter), loss = 0.0820162
I0502 11:41:01.717896 26473 solver.cpp:261]     Train net output #0: loss = 0.0820162 (* 1 = 0.0820162 loss)
I0502 11:41:01.717905 26473 sgd_solver.cpp:106] Iteration 187900, lr = 1.80144e-06
I0502 11:41:02.654435 26473 solver.cpp:362] Iteration 188000, Testing net (#0)
I0502 11:41:02.654462 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:02.778815 26473 solver.cpp:429]     Test net output #0: loss = 0.226708 (* 1 = 0.226708 loss)
I0502 11:41:02.781688 26473 solver.cpp:242] Iteration 188000 (93.5847 iter/s, 1.06855s/100 iter), loss = 0.308003
I0502 11:41:02.781708 26473 solver.cpp:261]     Train net output #0: loss = 0.308003 (* 1 = 0.308003 loss)
I0502 11:41:02.781718 26473 sgd_solver.cpp:106] Iteration 188000, lr = 1.80144e-06
I0502 11:41:02.783416 26473 solver.cpp:362] Iteration 188000, Testing net (#0)
I0502 11:41:02.783428 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:02.914067 26473 solver.cpp:429]     Test net output #0: accuracy = 0.963
I0502 11:41:02.914088 26473 solver.cpp:429]     Test net output #1: loss = 0.0800676 (* 1 = 0.0800676 loss)
I0502 11:41:02.917006 26473 solver.cpp:242] Iteration 188000 (83.3967 iter/s, 1.19909s/100 iter), loss = 0.0100899
I0502 11:41:02.917026 26473 solver.cpp:261]     Train net output #0: loss = 0.0100899 (* 1 = 0.0100899 loss)
I0502 11:41:02.917034 26473 sgd_solver.cpp:106] Iteration 188000, lr = 1.80144e-06
I0502 11:41:03.856135 26473 solver.cpp:242] Iteration 188100 (93.0758 iter/s, 1.07439s/100 iter), loss = 0.225157
I0502 11:41:03.856178 26473 solver.cpp:261]     Train net output #0: loss = 0.225157 (* 1 = 0.225157 loss)
I0502 11:41:03.856186 26473 sgd_solver.cpp:106] Iteration 188100, lr = 1.80144e-06
I0502 11:41:03.860954 26473 solver.cpp:242] Iteration 188100 (105.942 iter/s, 0.943909s/100 iter), loss = 0.0709923
I0502 11:41:03.860976 26473 solver.cpp:261]     Train net output #0: loss = 0.0709923 (* 1 = 0.0709923 loss)
I0502 11:41:03.860985 26473 sgd_solver.cpp:106] Iteration 188100, lr = 1.80144e-06
I0502 11:41:04.800604 26473 solver.cpp:242] Iteration 188200 (105.888 iter/s, 0.944396s/100 iter), loss = 0.435361
I0502 11:41:04.800647 26473 solver.cpp:261]     Train net output #0: loss = 0.435361 (* 1 = 0.435361 loss)
I0502 11:41:04.800657 26473 sgd_solver.cpp:106] Iteration 188200, lr = 1.80144e-06
I0502 11:41:04.805413 26473 solver.cpp:242] Iteration 188200 (105.885 iter/s, 0.944419s/100 iter), loss = 0.135219
I0502 11:41:04.805435 26473 solver.cpp:261]     Train net output #0: loss = 0.135219 (* 1 = 0.135219 loss)
I0502 11:41:04.805452 26473 sgd_solver.cpp:106] Iteration 188200, lr = 1.80144e-06
I0502 11:41:05.744535 26473 solver.cpp:242] Iteration 188300 (105.948 iter/s, 0.94386s/100 iter), loss = 0.0660773
I0502 11:41:05.744580 26473 solver.cpp:261]     Train net output #0: loss = 0.0660773 (* 1 = 0.0660773 loss)
I0502 11:41:05.744590 26473 sgd_solver.cpp:106] Iteration 188300, lr = 1.80144e-06
I0502 11:41:05.749439 26473 solver.cpp:242] Iteration 188300 (105.934 iter/s, 0.943985s/100 iter), loss = 0.125084
I0502 11:41:05.749461 26473 solver.cpp:261]     Train net output #0: loss = 0.125084 (* 1 = 0.125084 loss)
I0502 11:41:05.749470 26473 sgd_solver.cpp:106] Iteration 188300, lr = 1.80144e-06
I0502 11:41:06.688884 26473 solver.cpp:242] Iteration 188400 (105.901 iter/s, 0.944278s/100 iter), loss = 0.0469467
I0502 11:41:06.688923 26473 solver.cpp:261]     Train net output #0: loss = 0.0469467 (* 1 = 0.0469467 loss)
I0502 11:41:06.688932 26473 sgd_solver.cpp:106] Iteration 188400, lr = 1.80144e-06
I0502 11:41:06.693677 26473 solver.cpp:242] Iteration 188400 (105.91 iter/s, 0.944198s/100 iter), loss = 0.113612
I0502 11:41:06.693701 26473 solver.cpp:261]     Train net output #0: loss = 0.113612 (* 1 = 0.113612 loss)
I0502 11:41:06.693709 26473 sgd_solver.cpp:106] Iteration 188400, lr = 1.80144e-06
I0502 11:41:07.630192 26473 solver.cpp:362] Iteration 188500, Testing net (#0)
I0502 11:41:07.630214 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:07.754413 26473 solver.cpp:429]     Test net output #0: loss = 0.204173 (* 1 = 0.204173 loss)
I0502 11:41:07.757274 26473 solver.cpp:242] Iteration 188500 (93.6038 iter/s, 1.06833s/100 iter), loss = 0.284746
I0502 11:41:07.757295 26473 solver.cpp:261]     Train net output #0: loss = 0.284746 (* 1 = 0.284746 loss)
I0502 11:41:07.757303 26473 sgd_solver.cpp:106] Iteration 188500, lr = 1.80144e-06
I0502 11:41:07.758999 26473 solver.cpp:362] Iteration 188500, Testing net (#0)
I0502 11:41:07.759012 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:07.889703 26473 solver.cpp:429]     Test net output #0: accuracy = 0.953
I0502 11:41:07.889722 26473 solver.cpp:429]     Test net output #1: loss = 0.0946873 (* 1 = 0.0946873 loss)
I0502 11:41:07.892637 26473 solver.cpp:242] Iteration 188500 (83.4088 iter/s, 1.19891s/100 iter), loss = 0.0351813
I0502 11:41:07.892657 26473 solver.cpp:261]     Train net output #0: loss = 0.0351813 (* 1 = 0.0351813 loss)
I0502 11:41:07.892664 26473 sgd_solver.cpp:106] Iteration 188500, lr = 1.80144e-06
I0502 11:41:08.832221 26473 solver.cpp:242] Iteration 188600 (93.0326 iter/s, 1.07489s/100 iter), loss = 0.0871059
I0502 11:41:08.832262 26473 solver.cpp:261]     Train net output #0: loss = 0.0871059 (* 1 = 0.0871059 loss)
I0502 11:41:08.832270 26473 sgd_solver.cpp:106] Iteration 188600, lr = 1.80144e-06
I0502 11:41:08.837033 26473 solver.cpp:242] Iteration 188600 (105.892 iter/s, 0.944357s/100 iter), loss = 0.0789839
I0502 11:41:08.837055 26473 solver.cpp:261]     Train net output #0: loss = 0.0789839 (* 1 = 0.0789839 loss)
I0502 11:41:08.837064 26473 sgd_solver.cpp:106] Iteration 188600, lr = 1.80144e-06
I0502 11:41:09.775215 26473 solver.cpp:242] Iteration 188700 (106.053 iter/s, 0.942926s/100 iter), loss = 0.319478
I0502 11:41:09.775251 26473 solver.cpp:261]     Train net output #0: loss = 0.319478 (* 1 = 0.319478 loss)
I0502 11:41:09.775260 26473 sgd_solver.cpp:106] Iteration 188700, lr = 1.80144e-06
I0502 11:41:09.780036 26473 solver.cpp:242] Iteration 188700 (106.049 iter/s, 0.942963s/100 iter), loss = 0.118127
I0502 11:41:09.780059 26473 solver.cpp:261]     Train net output #0: loss = 0.118127 (* 1 = 0.118127 loss)
I0502 11:41:09.780067 26473 sgd_solver.cpp:106] Iteration 188700, lr = 1.80144e-06
I0502 11:41:10.719240 26473 solver.cpp:242] Iteration 188800 (105.937 iter/s, 0.943959s/100 iter), loss = 0.491621
I0502 11:41:10.719280 26473 solver.cpp:261]     Train net output #0: loss = 0.491621 (* 1 = 0.491621 loss)
I0502 11:41:10.719288 26473 sgd_solver.cpp:106] Iteration 188800, lr = 1.80144e-06
I0502 11:41:10.724126 26473 solver.cpp:242] Iteration 188800 (105.927 iter/s, 0.944049s/100 iter), loss = 0.0322624
I0502 11:41:10.724149 26473 solver.cpp:261]     Train net output #0: loss = 0.0322624 (* 1 = 0.0322624 loss)
I0502 11:41:10.724159 26473 sgd_solver.cpp:106] Iteration 188800, lr = 1.80144e-06
I0502 11:41:11.662972 26473 solver.cpp:242] Iteration 188900 (105.97 iter/s, 0.943666s/100 iter), loss = 0.128628
I0502 11:41:11.663007 26473 solver.cpp:261]     Train net output #0: loss = 0.128628 (* 1 = 0.128628 loss)
I0502 11:41:11.663017 26473 sgd_solver.cpp:106] Iteration 188900, lr = 1.80144e-06
I0502 11:41:11.667789 26473 solver.cpp:242] Iteration 188900 (105.975 iter/s, 0.943622s/100 iter), loss = 0.0953442
I0502 11:41:11.667812 26473 solver.cpp:261]     Train net output #0: loss = 0.0953442 (* 1 = 0.0953442 loss)
I0502 11:41:11.667820 26473 sgd_solver.cpp:106] Iteration 188900, lr = 1.80144e-06
I0502 11:41:12.604404 26473 solver.cpp:362] Iteration 189000, Testing net (#0)
I0502 11:41:12.604423 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:12.728950 26473 solver.cpp:429]     Test net output #0: loss = 0.225598 (* 1 = 0.225598 loss)
I0502 11:41:12.731822 26473 solver.cpp:242] Iteration 189000 (93.5632 iter/s, 1.0688s/100 iter), loss = 0.0459786
I0502 11:41:12.731840 26473 solver.cpp:261]     Train net output #0: loss = 0.0459786 (* 1 = 0.0459786 loss)
I0502 11:41:12.731849 26473 sgd_solver.cpp:106] Iteration 189000, lr = 1.80144e-06
I0502 11:41:12.733572 26473 solver.cpp:362] Iteration 189000, Testing net (#0)
I0502 11:41:12.733585 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:12.864207 26473 solver.cpp:429]     Test net output #0: accuracy = 0.955
I0502 11:41:12.864226 26473 solver.cpp:429]     Test net output #1: loss = 0.0913927 (* 1 = 0.0913927 loss)
I0502 11:41:12.867141 26473 solver.cpp:242] Iteration 189000 (83.3814 iter/s, 1.19931s/100 iter), loss = 0.0689715
I0502 11:41:12.867161 26473 solver.cpp:261]     Train net output #0: loss = 0.0689715 (* 1 = 0.0689715 loss)
I0502 11:41:12.867171 26473 sgd_solver.cpp:106] Iteration 189000, lr = 1.80144e-06
I0502 11:41:13.807283 26473 solver.cpp:242] Iteration 189100 (92.9872 iter/s, 1.07542s/100 iter), loss = 0.105718
I0502 11:41:13.807318 26473 solver.cpp:261]     Train net output #0: loss = 0.105718 (* 1 = 0.105718 loss)
I0502 11:41:13.807327 26473 sgd_solver.cpp:106] Iteration 189100, lr = 1.80144e-06
I0502 11:41:13.812160 26473 solver.cpp:242] Iteration 189100 (105.823 iter/s, 0.944973s/100 iter), loss = 0.104661
I0502 11:41:13.812183 26473 solver.cpp:261]     Train net output #0: loss = 0.104661 (* 1 = 0.104661 loss)
I0502 11:41:13.812191 26473 sgd_solver.cpp:106] Iteration 189100, lr = 1.80144e-06
I0502 11:41:14.750752 26473 solver.cpp:242] Iteration 189200 (105.999 iter/s, 0.943405s/100 iter), loss = 0.403171
I0502 11:41:14.750783 26473 solver.cpp:261]     Train net output #0: loss = 0.403171 (* 1 = 0.403171 loss)
I0502 11:41:14.750792 26473 sgd_solver.cpp:106] Iteration 189200, lr = 1.80144e-06
I0502 11:41:14.755553 26473 solver.cpp:242] Iteration 189200 (106.005 iter/s, 0.943352s/100 iter), loss = 0.116334
I0502 11:41:14.755575 26473 solver.cpp:261]     Train net output #0: loss = 0.116334 (* 1 = 0.116334 loss)
I0502 11:41:14.755584 26473 sgd_solver.cpp:106] Iteration 189200, lr = 1.80144e-06
I0502 11:41:15.695081 26473 solver.cpp:242] Iteration 189300 (105.902 iter/s, 0.944267s/100 iter), loss = 0.194834
I0502 11:41:15.695124 26473 solver.cpp:261]     Train net output #0: loss = 0.194834 (* 1 = 0.194834 loss)
I0502 11:41:15.695134 26473 sgd_solver.cpp:106] Iteration 189300, lr = 1.80144e-06
I0502 11:41:15.699900 26473 solver.cpp:242] Iteration 189300 (105.898 iter/s, 0.944308s/100 iter), loss = 0.168476
I0502 11:41:15.699923 26473 solver.cpp:261]     Train net output #0: loss = 0.168476 (* 1 = 0.168476 loss)
I0502 11:41:15.699932 26473 sgd_solver.cpp:106] Iteration 189300, lr = 1.80144e-06
I0502 11:41:16.640084 26473 solver.cpp:242] Iteration 189400 (105.827 iter/s, 0.944935s/100 iter), loss = 0.111293
I0502 11:41:16.640142 26473 solver.cpp:261]     Train net output #0: loss = 0.111293 (* 1 = 0.111293 loss)
I0502 11:41:16.640166 26473 sgd_solver.cpp:106] Iteration 189400, lr = 1.80144e-06
I0502 11:41:16.644966 26473 solver.cpp:242] Iteration 189400 (105.817 iter/s, 0.945024s/100 iter), loss = 0.107412
I0502 11:41:16.644990 26473 solver.cpp:261]     Train net output #0: loss = 0.107412 (* 1 = 0.107412 loss)
I0502 11:41:16.644999 26473 sgd_solver.cpp:106] Iteration 189400, lr = 1.80144e-06
I0502 11:41:17.581372 26473 solver.cpp:362] Iteration 189500, Testing net (#0)
I0502 11:41:17.581400 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:17.705651 26473 solver.cpp:429]     Test net output #0: loss = 0.206616 (* 1 = 0.206616 loss)
I0502 11:41:17.708513 26473 solver.cpp:242] Iteration 189500 (93.602 iter/s, 1.06835s/100 iter), loss = 0.167768
I0502 11:41:17.708534 26473 solver.cpp:261]     Train net output #0: loss = 0.167768 (* 1 = 0.167768 loss)
I0502 11:41:17.708541 26473 sgd_solver.cpp:106] Iteration 189500, lr = 1.80144e-06
I0502 11:41:17.710176 26473 solver.cpp:362] Iteration 189500, Testing net (#0)
I0502 11:41:17.710189 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:17.840725 26473 solver.cpp:429]     Test net output #0: accuracy = 0.968
I0502 11:41:17.840744 26473 solver.cpp:429]     Test net output #1: loss = 0.0752688 (* 1 = 0.0752688 loss)
I0502 11:41:17.843649 26473 solver.cpp:242] Iteration 189500 (83.4279 iter/s, 1.19864s/100 iter), loss = 0.0231843
I0502 11:41:17.843668 26473 solver.cpp:261]     Train net output #0: loss = 0.0231843 (* 1 = 0.0231843 loss)
I0502 11:41:17.843677 26473 sgd_solver.cpp:106] Iteration 189500, lr = 1.80144e-06
I0502 11:41:18.783466 26473 solver.cpp:242] Iteration 189600 (93.0314 iter/s, 1.07491s/100 iter), loss = 0.0880562
I0502 11:41:18.783505 26473 solver.cpp:261]     Train net output #0: loss = 0.0880562 (* 1 = 0.0880562 loss)
I0502 11:41:18.783514 26473 sgd_solver.cpp:106] Iteration 189600, lr = 1.80144e-06
I0502 11:41:18.788367 26473 solver.cpp:242] Iteration 189600 (105.857 iter/s, 0.944672s/100 iter), loss = 0.0605166
I0502 11:41:18.788389 26473 solver.cpp:261]     Train net output #0: loss = 0.0605166 (* 1 = 0.0605166 loss)
I0502 11:41:18.788398 26473 sgd_solver.cpp:106] Iteration 189600, lr = 1.80144e-06
I0502 11:41:19.728351 26473 solver.cpp:242] Iteration 189700 (105.841 iter/s, 0.944815s/100 iter), loss = 0.126346
I0502 11:41:19.728394 26473 solver.cpp:261]     Train net output #0: loss = 0.126346 (* 1 = 0.126346 loss)
I0502 11:41:19.728402 26473 sgd_solver.cpp:106] Iteration 189700, lr = 1.80144e-06
I0502 11:41:19.733184 26473 solver.cpp:242] Iteration 189700 (105.845 iter/s, 0.944777s/100 iter), loss = 0.0155171
I0502 11:41:19.733207 26473 solver.cpp:261]     Train net output #0: loss = 0.0155171 (* 1 = 0.0155171 loss)
I0502 11:41:19.733216 26473 sgd_solver.cpp:106] Iteration 189700, lr = 1.80144e-06
I0502 11:41:20.672750 26473 solver.cpp:242] Iteration 189800 (105.895 iter/s, 0.944328s/100 iter), loss = 0.12543
I0502 11:41:20.672791 26473 solver.cpp:261]     Train net output #0: loss = 0.12543 (* 1 = 0.12543 loss)
I0502 11:41:20.672798 26473 sgd_solver.cpp:106] Iteration 189800, lr = 1.80144e-06
I0502 11:41:20.677546 26473 solver.cpp:242] Iteration 189800 (105.896 iter/s, 0.94432s/100 iter), loss = 0.0318976
I0502 11:41:20.677568 26473 solver.cpp:261]     Train net output #0: loss = 0.0318976 (* 1 = 0.0318976 loss)
I0502 11:41:20.677577 26473 sgd_solver.cpp:106] Iteration 189800, lr = 1.80144e-06
I0502 11:41:21.617331 26473 solver.cpp:242] Iteration 189900 (105.875 iter/s, 0.944511s/100 iter), loss = 0.212688
I0502 11:41:21.617377 26473 solver.cpp:261]     Train net output #0: loss = 0.212688 (* 1 = 0.212688 loss)
I0502 11:41:21.617385 26473 sgd_solver.cpp:106] Iteration 189900, lr = 1.80144e-06
I0502 11:41:21.622159 26473 solver.cpp:242] Iteration 189900 (105.868 iter/s, 0.944573s/100 iter), loss = 0.0482227
I0502 11:41:21.622185 26473 solver.cpp:261]     Train net output #0: loss = 0.0482227 (* 1 = 0.0482227 loss)
I0502 11:41:21.622195 26473 sgd_solver.cpp:106] Iteration 189900, lr = 1.80144e-06
I0502 11:41:22.558540 26473 solver.cpp:362] Iteration 190000, Testing net (#0)
I0502 11:41:22.558568 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:22.682993 26473 solver.cpp:429]     Test net output #0: loss = 0.233258 (* 1 = 0.233258 loss)
I0502 11:41:22.685881 26473 solver.cpp:242] Iteration 190000 (93.5903 iter/s, 1.06849s/100 iter), loss = 0.166332
I0502 11:41:22.685901 26473 solver.cpp:261]     Train net output #0: loss = 0.166332 (* 1 = 0.166332 loss)
I0502 11:41:22.685909 26473 sgd_solver.cpp:106] Iteration 190000, lr = 1.44115e-06
I0502 11:41:22.687548 26473 solver.cpp:362] Iteration 190000, Testing net (#0)
I0502 11:41:22.687561 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:22.818248 26473 solver.cpp:429]     Test net output #0: accuracy = 0.971
I0502 11:41:22.818270 26473 solver.cpp:429]     Test net output #1: loss = 0.0689671 (* 1 = 0.0689671 loss)
I0502 11:41:22.821194 26473 solver.cpp:242] Iteration 190000 (83.4036 iter/s, 1.19899s/100 iter), loss = 0.0324016
I0502 11:41:22.821214 26473 solver.cpp:261]     Train net output #0: loss = 0.0324016 (* 1 = 0.0324016 loss)
I0502 11:41:22.821223 26473 sgd_solver.cpp:106] Iteration 190000, lr = 1.44115e-06
I0502 11:41:23.760514 26473 solver.cpp:242] Iteration 190100 (93.0591 iter/s, 1.07459s/100 iter), loss = 0.0427282
I0502 11:41:23.760560 26473 solver.cpp:261]     Train net output #0: loss = 0.0427282 (* 1 = 0.0427282 loss)
I0502 11:41:23.760570 26473 sgd_solver.cpp:106] Iteration 190100, lr = 1.44115e-06
I0502 11:41:23.765401 26473 solver.cpp:242] Iteration 190100 (105.914 iter/s, 0.944162s/100 iter), loss = 0.0729845
I0502 11:41:23.765424 26473 solver.cpp:261]     Train net output #0: loss = 0.0729845 (* 1 = 0.0729845 loss)
I0502 11:41:23.765434 26473 sgd_solver.cpp:106] Iteration 190100, lr = 1.44115e-06
I0502 11:41:24.704690 26473 solver.cpp:242] Iteration 190200 (105.921 iter/s, 0.9441s/100 iter), loss = 0.0436314
I0502 11:41:24.704731 26473 solver.cpp:261]     Train net output #0: loss = 0.0436314 (* 1 = 0.0436314 loss)
I0502 11:41:24.704741 26473 sgd_solver.cpp:106] Iteration 190200, lr = 1.44115e-06
I0502 11:41:24.709497 26473 solver.cpp:242] Iteration 190200 (105.926 iter/s, 0.944055s/100 iter), loss = 0.0500529
I0502 11:41:24.709520 26473 solver.cpp:261]     Train net output #0: loss = 0.0500529 (* 1 = 0.0500529 loss)
I0502 11:41:24.709529 26473 sgd_solver.cpp:106] Iteration 190200, lr = 1.44115e-06
I0502 11:41:25.649271 26473 solver.cpp:242] Iteration 190300 (105.875 iter/s, 0.944512s/100 iter), loss = 0.108975
I0502 11:41:25.649309 26473 solver.cpp:261]     Train net output #0: loss = 0.108975 (* 1 = 0.108975 loss)
I0502 11:41:25.649318 26473 sgd_solver.cpp:106] Iteration 190300, lr = 1.44115e-06
I0502 11:41:25.654072 26473 solver.cpp:242] Iteration 190300 (105.872 iter/s, 0.944532s/100 iter), loss = 0.00748963
I0502 11:41:25.654095 26473 solver.cpp:261]     Train net output #0: loss = 0.00748963 (* 1 = 0.00748963 loss)
I0502 11:41:25.654103 26473 sgd_solver.cpp:106] Iteration 190300, lr = 1.44115e-06
I0502 11:41:26.594656 26473 solver.cpp:242] Iteration 190400 (105.784 iter/s, 0.945319s/100 iter), loss = 0.121773
I0502 11:41:26.594700 26473 solver.cpp:261]     Train net output #0: loss = 0.121773 (* 1 = 0.121773 loss)
I0502 11:41:26.594709 26473 sgd_solver.cpp:106] Iteration 190400, lr = 1.44115e-06
I0502 11:41:26.599488 26473 solver.cpp:242] Iteration 190400 (105.778 iter/s, 0.945375s/100 iter), loss = 0.0101801
I0502 11:41:26.599511 26473 solver.cpp:261]     Train net output #0: loss = 0.0101801 (* 1 = 0.0101801 loss)
I0502 11:41:26.599519 26473 sgd_solver.cpp:106] Iteration 190400, lr = 1.44115e-06
I0502 11:41:27.535962 26473 solver.cpp:362] Iteration 190500, Testing net (#0)
I0502 11:41:27.535989 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:27.660228 26473 solver.cpp:429]     Test net output #0: loss = 0.236187 (* 1 = 0.236187 loss)
I0502 11:41:27.663090 26473 solver.cpp:242] Iteration 190500 (93.6003 iter/s, 1.06837s/100 iter), loss = 0.0776933
I0502 11:41:27.663120 26473 solver.cpp:261]     Train net output #0: loss = 0.0776933 (* 1 = 0.0776933 loss)
I0502 11:41:27.663128 26473 sgd_solver.cpp:106] Iteration 190500, lr = 1.44115e-06
I0502 11:41:27.664762 26473 solver.cpp:362] Iteration 190500, Testing net (#0)
I0502 11:41:27.664775 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:27.795313 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9655
I0502 11:41:27.795334 26473 solver.cpp:429]     Test net output #1: loss = 0.079455 (* 1 = 0.079455 loss)
I0502 11:41:27.798277 26473 solver.cpp:242] Iteration 190500 (83.4205 iter/s, 1.19875s/100 iter), loss = 0.135352
I0502 11:41:27.798297 26473 solver.cpp:261]     Train net output #0: loss = 0.135352 (* 1 = 0.135352 loss)
I0502 11:41:27.798305 26473 sgd_solver.cpp:106] Iteration 190500, lr = 1.44115e-06
I0502 11:41:28.737298 26473 solver.cpp:242] Iteration 190600 (93.0969 iter/s, 1.07415s/100 iter), loss = 0.132204
I0502 11:41:28.737337 26473 solver.cpp:261]     Train net output #0: loss = 0.132204 (* 1 = 0.132204 loss)
I0502 11:41:28.737345 26473 sgd_solver.cpp:106] Iteration 190600, lr = 1.44115e-06
I0502 11:41:28.742202 26473 solver.cpp:242] Iteration 190600 (105.946 iter/s, 0.943877s/100 iter), loss = 0.010993
I0502 11:41:28.742224 26473 solver.cpp:261]     Train net output #0: loss = 0.010993 (* 1 = 0.010993 loss)
I0502 11:41:28.742233 26473 sgd_solver.cpp:106] Iteration 190600, lr = 1.44115e-06
I0502 11:41:29.681428 26473 solver.cpp:242] Iteration 190700 (105.925 iter/s, 0.944061s/100 iter), loss = 0.168798
I0502 11:41:29.681466 26473 solver.cpp:261]     Train net output #0: loss = 0.168798 (* 1 = 0.168798 loss)
I0502 11:41:29.681474 26473 sgd_solver.cpp:106] Iteration 190700, lr = 1.44115e-06
I0502 11:41:29.686244 26473 solver.cpp:242] Iteration 190700 (105.932 iter/s, 0.944s/100 iter), loss = 0.0348698
I0502 11:41:29.686265 26473 solver.cpp:261]     Train net output #0: loss = 0.0348698 (* 1 = 0.0348698 loss)
I0502 11:41:29.686273 26473 sgd_solver.cpp:106] Iteration 190700, lr = 1.44115e-06
I0502 11:41:30.625097 26473 solver.cpp:242] Iteration 190800 (105.977 iter/s, 0.943603s/100 iter), loss = 0.158172
I0502 11:41:30.625133 26473 solver.cpp:261]     Train net output #0: loss = 0.158172 (* 1 = 0.158172 loss)
I0502 11:41:30.625143 26473 sgd_solver.cpp:106] Iteration 190800, lr = 1.44115e-06
I0502 11:41:30.629894 26473 solver.cpp:242] Iteration 190800 (105.976 iter/s, 0.943611s/100 iter), loss = 0.0366605
I0502 11:41:30.629916 26473 solver.cpp:261]     Train net output #0: loss = 0.0366605 (* 1 = 0.0366605 loss)
I0502 11:41:30.629925 26473 sgd_solver.cpp:106] Iteration 190800, lr = 1.44115e-06
I0502 11:41:31.569934 26473 solver.cpp:242] Iteration 190900 (105.845 iter/s, 0.944775s/100 iter), loss = 0.118091
I0502 11:41:31.569969 26473 solver.cpp:261]     Train net output #0: loss = 0.118091 (* 1 = 0.118091 loss)
I0502 11:41:31.569978 26473 sgd_solver.cpp:106] Iteration 190900, lr = 1.44115e-06
I0502 11:41:31.574735 26473 solver.cpp:242] Iteration 190900 (105.842 iter/s, 0.944801s/100 iter), loss = 0.105208
I0502 11:41:31.574759 26473 solver.cpp:261]     Train net output #0: loss = 0.105208 (* 1 = 0.105208 loss)
I0502 11:41:31.574766 26473 sgd_solver.cpp:106] Iteration 190900, lr = 1.44115e-06
I0502 11:41:32.511173 26473 solver.cpp:362] Iteration 191000, Testing net (#0)
I0502 11:41:32.511196 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:32.635318 26473 solver.cpp:429]     Test net output #0: loss = 0.22486 (* 1 = 0.22486 loss)
I0502 11:41:32.638186 26473 solver.cpp:242] Iteration 191000 (93.6155 iter/s, 1.0682s/100 iter), loss = 0.114317
I0502 11:41:32.638207 26473 solver.cpp:261]     Train net output #0: loss = 0.114317 (* 1 = 0.114317 loss)
I0502 11:41:32.638216 26473 sgd_solver.cpp:106] Iteration 191000, lr = 1.44115e-06
I0502 11:41:32.639837 26473 solver.cpp:362] Iteration 191000, Testing net (#0)
I0502 11:41:32.639850 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:32.770540 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9675
I0502 11:41:32.770570 26473 solver.cpp:429]     Test net output #1: loss = 0.0707566 (* 1 = 0.0707566 loss)
I0502 11:41:32.773496 26473 solver.cpp:242] Iteration 191000 (83.4225 iter/s, 1.19872s/100 iter), loss = 0.115134
I0502 11:41:32.773516 26473 solver.cpp:261]     Train net output #0: loss = 0.115134 (* 1 = 0.115134 loss)
I0502 11:41:32.773524 26473 sgd_solver.cpp:106] Iteration 191000, lr = 1.44115e-06
I0502 11:41:33.713410 26473 solver.cpp:242] Iteration 191100 (93.0081 iter/s, 1.07518s/100 iter), loss = 0.0457046
I0502 11:41:33.713443 26473 solver.cpp:261]     Train net output #0: loss = 0.0457046 (* 1 = 0.0457046 loss)
I0502 11:41:33.713452 26473 sgd_solver.cpp:106] Iteration 191100, lr = 1.44115e-06
I0502 11:41:33.718271 26473 solver.cpp:242] Iteration 191100 (105.851 iter/s, 0.944727s/100 iter), loss = 0.0810062
I0502 11:41:33.718294 26473 solver.cpp:261]     Train net output #0: loss = 0.0810062 (* 1 = 0.0810062 loss)
I0502 11:41:33.718303 26473 sgd_solver.cpp:106] Iteration 191100, lr = 1.44115e-06
I0502 11:41:34.657723 26473 solver.cpp:242] Iteration 191200 (105.904 iter/s, 0.944249s/100 iter), loss = 0.121037
I0502 11:41:34.657752 26473 solver.cpp:261]     Train net output #0: loss = 0.121037 (* 1 = 0.121037 loss)
I0502 11:41:34.657760 26473 sgd_solver.cpp:106] Iteration 191200, lr = 1.44115e-06
I0502 11:41:34.662531 26473 solver.cpp:242] Iteration 191200 (105.908 iter/s, 0.944219s/100 iter), loss = 0.0306577
I0502 11:41:34.662554 26473 solver.cpp:261]     Train net output #0: loss = 0.0306577 (* 1 = 0.0306577 loss)
I0502 11:41:34.662562 26473 sgd_solver.cpp:106] Iteration 191200, lr = 1.44115e-06
I0502 11:41:35.602461 26473 solver.cpp:242] Iteration 191300 (105.856 iter/s, 0.94468s/100 iter), loss = 0.294783
I0502 11:41:35.602506 26473 solver.cpp:261]     Train net output #0: loss = 0.294783 (* 1 = 0.294783 loss)
I0502 11:41:35.602515 26473 sgd_solver.cpp:106] Iteration 191300, lr = 1.44115e-06
I0502 11:41:35.607390 26473 solver.cpp:242] Iteration 191300 (105.84 iter/s, 0.944818s/100 iter), loss = 0.00139367
I0502 11:41:35.607414 26473 solver.cpp:261]     Train net output #0: loss = 0.00139367 (* 1 = 0.00139367 loss)
I0502 11:41:35.607424 26473 sgd_solver.cpp:106] Iteration 191300, lr = 1.44115e-06
I0502 11:41:36.546339 26473 solver.cpp:242] Iteration 191400 (105.954 iter/s, 0.943805s/100 iter), loss = 0.1203
I0502 11:41:36.546380 26473 solver.cpp:261]     Train net output #0: loss = 0.1203 (* 1 = 0.1203 loss)
I0502 11:41:36.546389 26473 sgd_solver.cpp:106] Iteration 191400, lr = 1.44115e-06
I0502 11:41:36.551158 26473 solver.cpp:242] Iteration 191400 (105.963 iter/s, 0.943726s/100 iter), loss = 0.00446627
I0502 11:41:36.551182 26473 solver.cpp:261]     Train net output #0: loss = 0.00446627 (* 1 = 0.00446627 loss)
I0502 11:41:36.551190 26473 sgd_solver.cpp:106] Iteration 191400, lr = 1.44115e-06
I0502 11:41:37.487402 26473 solver.cpp:362] Iteration 191500, Testing net (#0)
I0502 11:41:37.487444 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:37.611870 26473 solver.cpp:429]     Test net output #0: loss = 0.235244 (* 1 = 0.235244 loss)
I0502 11:41:37.614744 26473 solver.cpp:242] Iteration 191500 (93.6027 iter/s, 1.06835s/100 iter), loss = 0.504487
I0502 11:41:37.614764 26473 solver.cpp:261]     Train net output #0: loss = 0.504487 (* 1 = 0.504487 loss)
I0502 11:41:37.614773 26473 sgd_solver.cpp:106] Iteration 191500, lr = 1.44115e-06
I0502 11:41:37.616394 26473 solver.cpp:362] Iteration 191500, Testing net (#0)
I0502 11:41:37.616406 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:37.747112 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9685
I0502 11:41:37.747138 26473 solver.cpp:429]     Test net output #1: loss = 0.0718618 (* 1 = 0.0718618 loss)
I0502 11:41:37.750063 26473 solver.cpp:242] Iteration 191500 (83.4126 iter/s, 1.19886s/100 iter), loss = 0.143981
I0502 11:41:37.750083 26473 solver.cpp:261]     Train net output #0: loss = 0.143981 (* 1 = 0.143981 loss)
I0502 11:41:37.750092 26473 sgd_solver.cpp:106] Iteration 191500, lr = 1.44115e-06
I0502 11:41:38.690400 26473 solver.cpp:242] Iteration 191600 (92.9706 iter/s, 1.07561s/100 iter), loss = 0.0672555
I0502 11:41:38.690446 26473 solver.cpp:261]     Train net output #0: loss = 0.0672555 (* 1 = 0.0672555 loss)
I0502 11:41:38.690456 26473 sgd_solver.cpp:106] Iteration 191600, lr = 1.44115e-06
I0502 11:41:38.695297 26473 solver.cpp:242] Iteration 191600 (105.799 iter/s, 0.945187s/100 iter), loss = 0.0442191
I0502 11:41:38.695319 26473 solver.cpp:261]     Train net output #0: loss = 0.0442191 (* 1 = 0.0442191 loss)
I0502 11:41:38.695327 26473 sgd_solver.cpp:106] Iteration 191600, lr = 1.44115e-06
I0502 11:41:39.634886 26473 solver.cpp:242] Iteration 191700 (105.885 iter/s, 0.944418s/100 iter), loss = 0.135607
I0502 11:41:39.634929 26473 solver.cpp:261]     Train net output #0: loss = 0.135607 (* 1 = 0.135607 loss)
I0502 11:41:39.634938 26473 sgd_solver.cpp:106] Iteration 191700, lr = 1.44115e-06
I0502 11:41:39.639755 26473 solver.cpp:242] Iteration 191700 (105.886 iter/s, 0.944413s/100 iter), loss = 0.0452092
I0502 11:41:39.639778 26473 solver.cpp:261]     Train net output #0: loss = 0.0452092 (* 1 = 0.0452092 loss)
I0502 11:41:39.639787 26473 sgd_solver.cpp:106] Iteration 191700, lr = 1.44115e-06
I0502 11:41:40.580427 26473 solver.cpp:242] Iteration 191800 (105.768 iter/s, 0.945467s/100 iter), loss = 0.223425
I0502 11:41:40.580469 26473 solver.cpp:261]     Train net output #0: loss = 0.223425 (* 1 = 0.223425 loss)
I0502 11:41:40.580478 26473 sgd_solver.cpp:106] Iteration 191800, lr = 1.44115e-06
I0502 11:41:40.585259 26473 solver.cpp:242] Iteration 191800 (105.768 iter/s, 0.945462s/100 iter), loss = 0.0359049
I0502 11:41:40.585283 26473 solver.cpp:261]     Train net output #0: loss = 0.0359049 (* 1 = 0.0359049 loss)
I0502 11:41:40.585290 26473 sgd_solver.cpp:106] Iteration 191800, lr = 1.44115e-06
I0502 11:41:41.523856 26473 solver.cpp:242] Iteration 191900 (106.004 iter/s, 0.94336s/100 iter), loss = 0.155753
I0502 11:41:41.523898 26473 solver.cpp:261]     Train net output #0: loss = 0.155753 (* 1 = 0.155753 loss)
I0502 11:41:41.523907 26473 sgd_solver.cpp:106] Iteration 191900, lr = 1.44115e-06
I0502 11:41:41.528673 26473 solver.cpp:242] Iteration 191900 (106.003 iter/s, 0.943373s/100 iter), loss = 0.125642
I0502 11:41:41.528695 26473 solver.cpp:261]     Train net output #0: loss = 0.125642 (* 1 = 0.125642 loss)
I0502 11:41:41.528704 26473 sgd_solver.cpp:106] Iteration 191900, lr = 1.44115e-06
I0502 11:41:42.485178 26473 solver.cpp:362] Iteration 192000, Testing net (#0)
I0502 11:41:42.485209 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:42.609441 26473 solver.cpp:429]     Test net output #0: loss = 0.233565 (* 1 = 0.233565 loss)
I0502 11:41:42.612351 26473 solver.cpp:242] Iteration 192000 (91.8751 iter/s, 1.08843s/100 iter), loss = 0.0712014
I0502 11:41:42.612372 26473 solver.cpp:261]     Train net output #0: loss = 0.0712014 (* 1 = 0.0712014 loss)
I0502 11:41:42.612381 26473 sgd_solver.cpp:106] Iteration 192000, lr = 1.44115e-06
I0502 11:41:42.614022 26473 solver.cpp:362] Iteration 192000, Testing net (#0)
I0502 11:41:42.614037 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:42.744683 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:41:42.744705 26473 solver.cpp:429]     Test net output #1: loss = 0.0722507 (* 1 = 0.0722507 loss)
I0502 11:41:42.747619 26473 solver.cpp:242] Iteration 192000 (82.0411 iter/s, 1.2189s/100 iter), loss = 0.0652367
I0502 11:41:42.747639 26473 solver.cpp:261]     Train net output #0: loss = 0.0652367 (* 1 = 0.0652367 loss)
I0502 11:41:42.747648 26473 sgd_solver.cpp:106] Iteration 192000, lr = 1.44115e-06
I0502 11:41:43.686478 26473 solver.cpp:242] Iteration 192100 (93.1032 iter/s, 1.07408s/100 iter), loss = 0.0813363
I0502 11:41:43.686522 26473 solver.cpp:261]     Train net output #0: loss = 0.0813363 (* 1 = 0.0813363 loss)
I0502 11:41:43.686530 26473 sgd_solver.cpp:106] Iteration 192100, lr = 1.44115e-06
I0502 11:41:43.691357 26473 solver.cpp:242] Iteration 192100 (105.967 iter/s, 0.943691s/100 iter), loss = 0.0658962
I0502 11:41:43.691381 26473 solver.cpp:261]     Train net output #0: loss = 0.0658962 (* 1 = 0.0658962 loss)
I0502 11:41:43.691400 26473 sgd_solver.cpp:106] Iteration 192100, lr = 1.44115e-06
I0502 11:41:44.630523 26473 solver.cpp:242] Iteration 192200 (105.935 iter/s, 0.94398s/100 iter), loss = 0.0677271
I0502 11:41:44.630566 26473 solver.cpp:261]     Train net output #0: loss = 0.0677271 (* 1 = 0.0677271 loss)
I0502 11:41:44.630575 26473 sgd_solver.cpp:106] Iteration 192200, lr = 1.44115e-06
I0502 11:41:44.635378 26473 solver.cpp:242] Iteration 192200 (105.935 iter/s, 0.943972s/100 iter), loss = 0.0453212
I0502 11:41:44.635402 26473 solver.cpp:261]     Train net output #0: loss = 0.0453212 (* 1 = 0.0453212 loss)
I0502 11:41:44.635411 26473 sgd_solver.cpp:106] Iteration 192200, lr = 1.44115e-06
I0502 11:41:45.573732 26473 solver.cpp:242] Iteration 192300 (106.029 iter/s, 0.943137s/100 iter), loss = 0.0763488
I0502 11:41:45.573770 26473 solver.cpp:261]     Train net output #0: loss = 0.0763488 (* 1 = 0.0763488 loss)
I0502 11:41:45.573779 26473 sgd_solver.cpp:106] Iteration 192300, lr = 1.44115e-06
I0502 11:41:45.578526 26473 solver.cpp:242] Iteration 192300 (106.033 iter/s, 0.943106s/100 iter), loss = 0.00960927
I0502 11:41:45.578548 26473 solver.cpp:261]     Train net output #0: loss = 0.00960927 (* 1 = 0.00960927 loss)
I0502 11:41:45.578557 26473 sgd_solver.cpp:106] Iteration 192300, lr = 1.44115e-06
I0502 11:41:46.518721 26473 solver.cpp:242] Iteration 192400 (105.829 iter/s, 0.944922s/100 iter), loss = 0.809327
I0502 11:41:46.518761 26473 solver.cpp:261]     Train net output #0: loss = 0.809327 (* 1 = 0.809327 loss)
I0502 11:41:46.518771 26473 sgd_solver.cpp:106] Iteration 192400, lr = 1.44115e-06
I0502 11:41:46.523543 26473 solver.cpp:242] Iteration 192400 (105.823 iter/s, 0.944977s/100 iter), loss = 0.139907
I0502 11:41:46.523566 26473 solver.cpp:261]     Train net output #0: loss = 0.139907 (* 1 = 0.139907 loss)
I0502 11:41:46.523574 26473 sgd_solver.cpp:106] Iteration 192400, lr = 1.44115e-06
I0502 11:41:47.460703 26473 solver.cpp:362] Iteration 192500, Testing net (#0)
I0502 11:41:47.460729 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:47.584991 26473 solver.cpp:429]     Test net output #0: loss = 0.256485 (* 1 = 0.256485 loss)
I0502 11:41:47.587849 26473 solver.cpp:242] Iteration 192500 (93.5393 iter/s, 1.06907s/100 iter), loss = 0.361861
I0502 11:41:47.587868 26473 solver.cpp:261]     Train net output #0: loss = 0.361861 (* 1 = 0.361861 loss)
I0502 11:41:47.587877 26473 sgd_solver.cpp:106] Iteration 192500, lr = 1.44115e-06
I0502 11:41:47.589504 26473 solver.cpp:362] Iteration 192500, Testing net (#0)
I0502 11:41:47.589517 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:47.720073 26473 solver.cpp:429]     Test net output #0: accuracy = 0.971
I0502 11:41:47.720108 26473 solver.cpp:429]     Test net output #1: loss = 0.0735632 (* 1 = 0.0735632 loss)
I0502 11:41:47.723047 26473 solver.cpp:242] Iteration 192500 (83.3708 iter/s, 1.19946s/100 iter), loss = 0.0054616
I0502 11:41:47.723069 26473 solver.cpp:261]     Train net output #0: loss = 0.0054616 (* 1 = 0.0054616 loss)
I0502 11:41:47.723078 26473 sgd_solver.cpp:106] Iteration 192500, lr = 1.44115e-06
I0502 11:41:48.661871 26473 solver.cpp:242] Iteration 192600 (93.112 iter/s, 1.07398s/100 iter), loss = 0.0452138
I0502 11:41:48.661911 26473 solver.cpp:261]     Train net output #0: loss = 0.0452138 (* 1 = 0.0452138 loss)
I0502 11:41:48.661921 26473 sgd_solver.cpp:106] Iteration 192600, lr = 1.44115e-06
I0502 11:41:48.666676 26473 solver.cpp:242] Iteration 192600 (105.979 iter/s, 0.943587s/100 iter), loss = 0.00250334
I0502 11:41:48.666698 26473 solver.cpp:261]     Train net output #0: loss = 0.00250334 (* 1 = 0.00250334 loss)
I0502 11:41:48.666707 26473 sgd_solver.cpp:106] Iteration 192600, lr = 1.44115e-06
I0502 11:41:49.606006 26473 solver.cpp:242] Iteration 192700 (105.924 iter/s, 0.944072s/100 iter), loss = 0.143422
I0502 11:41:49.606046 26473 solver.cpp:261]     Train net output #0: loss = 0.143422 (* 1 = 0.143422 loss)
I0502 11:41:49.606055 26473 sgd_solver.cpp:106] Iteration 192700, lr = 1.44115e-06
I0502 11:41:49.610903 26473 solver.cpp:242] Iteration 192700 (105.912 iter/s, 0.944178s/100 iter), loss = 0.0610453
I0502 11:41:49.610926 26473 solver.cpp:261]     Train net output #0: loss = 0.0610453 (* 1 = 0.0610453 loss)
I0502 11:41:49.610935 26473 sgd_solver.cpp:106] Iteration 192700, lr = 1.44115e-06
I0502 11:41:50.549938 26473 solver.cpp:242] Iteration 192800 (105.948 iter/s, 0.943863s/100 iter), loss = 0.0367268
I0502 11:41:50.549973 26473 solver.cpp:261]     Train net output #0: loss = 0.0367268 (* 1 = 0.0367268 loss)
I0502 11:41:50.549983 26473 sgd_solver.cpp:106] Iteration 192800, lr = 1.44115e-06
I0502 11:41:50.554747 26473 solver.cpp:242] Iteration 192800 (105.954 iter/s, 0.943803s/100 iter), loss = 0.0502074
I0502 11:41:50.554771 26473 solver.cpp:261]     Train net output #0: loss = 0.0502074 (* 1 = 0.0502074 loss)
I0502 11:41:50.554780 26473 sgd_solver.cpp:106] Iteration 192800, lr = 1.44115e-06
I0502 11:41:51.494374 26473 solver.cpp:242] Iteration 192900 (105.89 iter/s, 0.944373s/100 iter), loss = 0.0960654
I0502 11:41:51.494410 26473 solver.cpp:261]     Train net output #0: loss = 0.0960654 (* 1 = 0.0960654 loss)
I0502 11:41:51.494418 26473 sgd_solver.cpp:106] Iteration 192900, lr = 1.44115e-06
I0502 11:41:51.499184 26473 solver.cpp:242] Iteration 192900 (105.888 iter/s, 0.944394s/100 iter), loss = 0.129684
I0502 11:41:51.499207 26473 solver.cpp:261]     Train net output #0: loss = 0.129684 (* 1 = 0.129684 loss)
I0502 11:41:51.499215 26473 sgd_solver.cpp:106] Iteration 192900, lr = 1.44115e-06
I0502 11:41:52.435252 26473 solver.cpp:362] Iteration 193000, Testing net (#0)
I0502 11:41:52.435274 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:52.559669 26473 solver.cpp:429]     Test net output #0: loss = 0.183124 (* 1 = 0.183124 loss)
I0502 11:41:52.562542 26473 solver.cpp:242] Iteration 193000 (93.6229 iter/s, 1.06811s/100 iter), loss = 0.267065
I0502 11:41:52.562562 26473 solver.cpp:261]     Train net output #0: loss = 0.267065 (* 1 = 0.267065 loss)
I0502 11:41:52.562572 26473 sgd_solver.cpp:106] Iteration 193000, lr = 1.44115e-06
I0502 11:41:52.564182 26473 solver.cpp:362] Iteration 193000, Testing net (#0)
I0502 11:41:52.564194 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:52.694715 26473 solver.cpp:429]     Test net output #0: accuracy = 0.964
I0502 11:41:52.694737 26473 solver.cpp:429]     Test net output #1: loss = 0.0805446 (* 1 = 0.0805446 loss)
I0502 11:41:52.697649 26473 solver.cpp:242] Iteration 193000 (83.4431 iter/s, 1.19842s/100 iter), loss = 0.0731409
I0502 11:41:52.697669 26473 solver.cpp:261]     Train net output #0: loss = 0.0731409 (* 1 = 0.0731409 loss)
I0502 11:41:52.697677 26473 sgd_solver.cpp:106] Iteration 193000, lr = 1.44115e-06
I0502 11:41:53.637554 26473 solver.cpp:242] Iteration 193100 (93.0264 iter/s, 1.07496s/100 iter), loss = 0.0309236
I0502 11:41:53.637594 26473 solver.cpp:261]     Train net output #0: loss = 0.0309236 (* 1 = 0.0309236 loss)
I0502 11:41:53.637603 26473 sgd_solver.cpp:106] Iteration 193100, lr = 1.44115e-06
I0502 11:41:53.642350 26473 solver.cpp:242] Iteration 193100 (105.858 iter/s, 0.944664s/100 iter), loss = 0.0371687
I0502 11:41:53.642374 26473 solver.cpp:261]     Train net output #0: loss = 0.0371687 (* 1 = 0.0371687 loss)
I0502 11:41:53.642382 26473 sgd_solver.cpp:106] Iteration 193100, lr = 1.44115e-06
I0502 11:41:54.581074 26473 solver.cpp:242] Iteration 193200 (105.993 iter/s, 0.943458s/100 iter), loss = 0.0987023
I0502 11:41:54.581104 26473 solver.cpp:261]     Train net output #0: loss = 0.0987023 (* 1 = 0.0987023 loss)
I0502 11:41:54.581112 26473 sgd_solver.cpp:106] Iteration 193200, lr = 1.44115e-06
I0502 11:41:54.585963 26473 solver.cpp:242] Iteration 193200 (105.981 iter/s, 0.943562s/100 iter), loss = 0.092753
I0502 11:41:54.585985 26473 solver.cpp:261]     Train net output #0: loss = 0.092753 (* 1 = 0.092753 loss)
I0502 11:41:54.585994 26473 sgd_solver.cpp:106] Iteration 193200, lr = 1.44115e-06
I0502 11:41:55.525470 26473 solver.cpp:242] Iteration 193300 (105.895 iter/s, 0.944335s/100 iter), loss = 0.100858
I0502 11:41:55.525523 26473 solver.cpp:261]     Train net output #0: loss = 0.100858 (* 1 = 0.100858 loss)
I0502 11:41:55.525532 26473 sgd_solver.cpp:106] Iteration 193300, lr = 1.44115e-06
I0502 11:41:55.530297 26473 solver.cpp:242] Iteration 193300 (105.899 iter/s, 0.944293s/100 iter), loss = 0.047016
I0502 11:41:55.530319 26473 solver.cpp:261]     Train net output #0: loss = 0.047016 (* 1 = 0.047016 loss)
I0502 11:41:55.530328 26473 sgd_solver.cpp:106] Iteration 193300, lr = 1.44115e-06
I0502 11:41:56.469244 26473 solver.cpp:242] Iteration 193400 (105.967 iter/s, 0.943693s/100 iter), loss = 0.69241
I0502 11:41:56.469286 26473 solver.cpp:261]     Train net output #0: loss = 0.69241 (* 1 = 0.69241 loss)
I0502 11:41:56.469295 26473 sgd_solver.cpp:106] Iteration 193400, lr = 1.44115e-06
I0502 11:41:56.474050 26473 solver.cpp:242] Iteration 193400 (105.965 iter/s, 0.943712s/100 iter), loss = 0.041294
I0502 11:41:56.474071 26473 solver.cpp:261]     Train net output #0: loss = 0.041294 (* 1 = 0.041294 loss)
I0502 11:41:56.474081 26473 sgd_solver.cpp:106] Iteration 193400, lr = 1.44115e-06
I0502 11:41:57.410989 26473 solver.cpp:362] Iteration 193500, Testing net (#0)
I0502 11:41:57.411017 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:57.535449 26473 solver.cpp:429]     Test net output #0: loss = 0.16629 (* 1 = 0.16629 loss)
I0502 11:41:57.538331 26473 solver.cpp:242] Iteration 193500 (93.5431 iter/s, 1.06903s/100 iter), loss = 0.108651
I0502 11:41:57.538352 26473 solver.cpp:261]     Train net output #0: loss = 0.108651 (* 1 = 0.108651 loss)
I0502 11:41:57.538359 26473 sgd_solver.cpp:106] Iteration 193500, lr = 1.44115e-06
I0502 11:41:57.539974 26473 solver.cpp:362] Iteration 193500, Testing net (#0)
I0502 11:41:57.539986 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:41:57.670536 26473 solver.cpp:429]     Test net output #0: accuracy = 0.969
I0502 11:41:57.670557 26473 solver.cpp:429]     Test net output #1: loss = 0.073114 (* 1 = 0.073114 loss)
I0502 11:41:57.673470 26473 solver.cpp:242] Iteration 193500 (83.3766 iter/s, 1.19938s/100 iter), loss = 0.0713757
I0502 11:41:57.673491 26473 solver.cpp:261]     Train net output #0: loss = 0.0713757 (* 1 = 0.0713757 loss)
I0502 11:41:57.673498 26473 sgd_solver.cpp:106] Iteration 193500, lr = 1.44115e-06
I0502 11:41:58.611917 26473 solver.cpp:242] Iteration 193600 (93.1499 iter/s, 1.07354s/100 iter), loss = 0.156615
I0502 11:41:58.611948 26473 solver.cpp:261]     Train net output #0: loss = 0.156615 (* 1 = 0.156615 loss)
I0502 11:41:58.611956 26473 sgd_solver.cpp:106] Iteration 193600, lr = 1.44115e-06
I0502 11:41:58.616755 26473 solver.cpp:242] Iteration 193600 (106.017 iter/s, 0.943246s/100 iter), loss = 0.082908
I0502 11:41:58.616778 26473 solver.cpp:261]     Train net output #0: loss = 0.082908 (* 1 = 0.082908 loss)
I0502 11:41:58.616787 26473 sgd_solver.cpp:106] Iteration 193600, lr = 1.44115e-06
I0502 11:41:59.555310 26473 solver.cpp:242] Iteration 193700 (106.006 iter/s, 0.94334s/100 iter), loss = 0.18037
I0502 11:41:59.555343 26473 solver.cpp:261]     Train net output #0: loss = 0.18037 (* 1 = 0.18037 loss)
I0502 11:41:59.555352 26473 sgd_solver.cpp:106] Iteration 193700, lr = 1.44115e-06
I0502 11:41:59.560204 26473 solver.cpp:242] Iteration 193700 (106 iter/s, 0.943399s/100 iter), loss = 0.054466
I0502 11:41:59.560225 26473 solver.cpp:261]     Train net output #0: loss = 0.054466 (* 1 = 0.054466 loss)
I0502 11:41:59.560235 26473 sgd_solver.cpp:106] Iteration 193700, lr = 1.44115e-06
I0502 11:42:00.511788 26473 solver.cpp:242] Iteration 193800 (104.557 iter/s, 0.956413s/100 iter), loss = 0.181177
I0502 11:42:00.511835 26473 solver.cpp:261]     Train net output #0: loss = 0.181177 (* 1 = 0.181177 loss)
I0502 11:42:00.511844 26473 sgd_solver.cpp:106] Iteration 193800, lr = 1.44115e-06
I0502 11:42:00.516609 26473 solver.cpp:242] Iteration 193800 (104.563 iter/s, 0.956365s/100 iter), loss = 0.0298143
I0502 11:42:00.516633 26473 solver.cpp:261]     Train net output #0: loss = 0.0298143 (* 1 = 0.0298143 loss)
I0502 11:42:00.516650 26473 sgd_solver.cpp:106] Iteration 193800, lr = 1.44115e-06
I0502 11:42:01.455426 26473 solver.cpp:242] Iteration 193900 (105.981 iter/s, 0.943562s/100 iter), loss = 0.505695
I0502 11:42:01.455468 26473 solver.cpp:261]     Train net output #0: loss = 0.505695 (* 1 = 0.505695 loss)
I0502 11:42:01.455477 26473 sgd_solver.cpp:106] Iteration 193900, lr = 1.44115e-06
I0502 11:42:01.460240 26473 solver.cpp:242] Iteration 193900 (105.978 iter/s, 0.943589s/100 iter), loss = 0.0240188
I0502 11:42:01.460263 26473 solver.cpp:261]     Train net output #0: loss = 0.0240188 (* 1 = 0.0240188 loss)
I0502 11:42:01.460273 26473 sgd_solver.cpp:106] Iteration 193900, lr = 1.44115e-06
I0502 11:42:02.396145 26473 solver.cpp:362] Iteration 194000, Testing net (#0)
I0502 11:42:02.396169 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:02.520750 26473 solver.cpp:429]     Test net output #0: loss = 0.249251 (* 1 = 0.249251 loss)
I0502 11:42:02.523628 26473 solver.cpp:242] Iteration 194000 (93.6205 iter/s, 1.06814s/100 iter), loss = 0.0800908
I0502 11:42:02.523648 26473 solver.cpp:261]     Train net output #0: loss = 0.0800908 (* 1 = 0.0800908 loss)
I0502 11:42:02.523658 26473 sgd_solver.cpp:106] Iteration 194000, lr = 1.44115e-06
I0502 11:42:02.525351 26473 solver.cpp:362] Iteration 194000, Testing net (#0)
I0502 11:42:02.525365 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:02.656183 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9655
I0502 11:42:02.656203 26473 solver.cpp:429]     Test net output #1: loss = 0.0882291 (* 1 = 0.0882291 loss)
I0502 11:42:02.659122 26473 solver.cpp:242] Iteration 194000 (83.4142 iter/s, 1.19884s/100 iter), loss = 0.0277062
I0502 11:42:02.659142 26473 solver.cpp:261]     Train net output #0: loss = 0.0277062 (* 1 = 0.0277062 loss)
I0502 11:42:02.659150 26473 sgd_solver.cpp:106] Iteration 194000, lr = 1.44115e-06
I0502 11:42:03.598248 26473 solver.cpp:242] Iteration 194100 (93.0606 iter/s, 1.07457s/100 iter), loss = 0.0660203
I0502 11:42:03.598302 26473 solver.cpp:261]     Train net output #0: loss = 0.0660203 (* 1 = 0.0660203 loss)
I0502 11:42:03.598322 26473 sgd_solver.cpp:106] Iteration 194100, lr = 1.44115e-06
I0502 11:42:03.603112 26473 solver.cpp:242] Iteration 194100 (105.937 iter/s, 0.943953s/100 iter), loss = 0.122981
I0502 11:42:03.603137 26473 solver.cpp:261]     Train net output #0: loss = 0.122981 (* 1 = 0.122981 loss)
I0502 11:42:03.603145 26473 sgd_solver.cpp:106] Iteration 194100, lr = 1.44115e-06
I0502 11:42:04.542481 26473 solver.cpp:242] Iteration 194200 (105.915 iter/s, 0.944153s/100 iter), loss = 0.01953
I0502 11:42:04.542523 26473 solver.cpp:261]     Train net output #0: loss = 0.01953 (* 1 = 0.01953 loss)
I0502 11:42:04.542532 26473 sgd_solver.cpp:106] Iteration 194200, lr = 1.44115e-06
I0502 11:42:04.547387 26473 solver.cpp:242] Iteration 194200 (105.907 iter/s, 0.944224s/100 iter), loss = 0.051934
I0502 11:42:04.547410 26473 solver.cpp:261]     Train net output #0: loss = 0.051934 (* 1 = 0.051934 loss)
I0502 11:42:04.547418 26473 sgd_solver.cpp:106] Iteration 194200, lr = 1.44115e-06
I0502 11:42:05.486591 26473 solver.cpp:242] Iteration 194300 (105.928 iter/s, 0.944038s/100 iter), loss = 0.522856
I0502 11:42:05.486634 26473 solver.cpp:261]     Train net output #0: loss = 0.522856 (* 1 = 0.522856 loss)
I0502 11:42:05.486642 26473 sgd_solver.cpp:106] Iteration 194300, lr = 1.44115e-06
I0502 11:42:05.491410 26473 solver.cpp:242] Iteration 194300 (105.934 iter/s, 0.943982s/100 iter), loss = 0.0049679
I0502 11:42:05.491432 26473 solver.cpp:261]     Train net output #0: loss = 0.0049679 (* 1 = 0.0049679 loss)
I0502 11:42:05.491441 26473 sgd_solver.cpp:106] Iteration 194300, lr = 1.44115e-06
I0502 11:42:06.430357 26473 solver.cpp:242] Iteration 194400 (105.966 iter/s, 0.943696s/100 iter), loss = 0.281471
I0502 11:42:06.430395 26473 solver.cpp:261]     Train net output #0: loss = 0.281471 (* 1 = 0.281471 loss)
I0502 11:42:06.430404 26473 sgd_solver.cpp:106] Iteration 194400, lr = 1.44115e-06
I0502 11:42:06.435183 26473 solver.cpp:242] Iteration 194400 (105.962 iter/s, 0.943732s/100 iter), loss = 0.232389
I0502 11:42:06.435214 26473 solver.cpp:261]     Train net output #0: loss = 0.232389 (* 1 = 0.232389 loss)
I0502 11:42:06.435223 26473 sgd_solver.cpp:106] Iteration 194400, lr = 1.44115e-06
I0502 11:42:07.371682 26473 solver.cpp:362] Iteration 194500, Testing net (#0)
I0502 11:42:07.371708 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:07.495977 26473 solver.cpp:429]     Test net output #0: loss = 0.268808 (* 1 = 0.268808 loss)
I0502 11:42:07.498842 26473 solver.cpp:242] Iteration 194500 (93.5955 iter/s, 1.06843s/100 iter), loss = 0.0516671
I0502 11:42:07.498862 26473 solver.cpp:261]     Train net output #0: loss = 0.0516671 (* 1 = 0.0516671 loss)
I0502 11:42:07.498869 26473 sgd_solver.cpp:106] Iteration 194500, lr = 1.44115e-06
I0502 11:42:07.500489 26473 solver.cpp:362] Iteration 194500, Testing net (#0)
I0502 11:42:07.500502 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:07.631132 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9605
I0502 11:42:07.631153 26473 solver.cpp:429]     Test net output #1: loss = 0.080644 (* 1 = 0.080644 loss)
I0502 11:42:07.634071 26473 solver.cpp:242] Iteration 194500 (83.4142 iter/s, 1.19884s/100 iter), loss = 0.0294836
I0502 11:42:07.634093 26473 solver.cpp:261]     Train net output #0: loss = 0.0294836 (* 1 = 0.0294836 loss)
I0502 11:42:07.634100 26473 sgd_solver.cpp:106] Iteration 194500, lr = 1.44115e-06
I0502 11:42:08.572718 26473 solver.cpp:242] Iteration 194600 (93.1249 iter/s, 1.07383s/100 iter), loss = 0.127067
I0502 11:42:08.572758 26473 solver.cpp:261]     Train net output #0: loss = 0.127067 (* 1 = 0.127067 loss)
I0502 11:42:08.572767 26473 sgd_solver.cpp:106] Iteration 194600, lr = 1.44115e-06
I0502 11:42:08.577524 26473 solver.cpp:242] Iteration 194600 (105.998 iter/s, 0.943414s/100 iter), loss = 0.0565815
I0502 11:42:08.577548 26473 solver.cpp:261]     Train net output #0: loss = 0.0565815 (* 1 = 0.0565815 loss)
I0502 11:42:08.577556 26473 sgd_solver.cpp:106] Iteration 194600, lr = 1.44115e-06
I0502 11:42:09.516947 26473 solver.cpp:242] Iteration 194700 (105.914 iter/s, 0.944163s/100 iter), loss = 0.0922537
I0502 11:42:09.516993 26473 solver.cpp:261]     Train net output #0: loss = 0.0922537 (* 1 = 0.0922537 loss)
I0502 11:42:09.517001 26473 sgd_solver.cpp:106] Iteration 194700, lr = 1.44115e-06
I0502 11:42:09.521807 26473 solver.cpp:242] Iteration 194700 (105.906 iter/s, 0.944233s/100 iter), loss = 0.153764
I0502 11:42:09.521831 26473 solver.cpp:261]     Train net output #0: loss = 0.153764 (* 1 = 0.153764 loss)
I0502 11:42:09.521838 26473 sgd_solver.cpp:106] Iteration 194700, lr = 1.44115e-06
I0502 11:42:10.460058 26473 solver.cpp:242] Iteration 194800 (106.04 iter/s, 0.943043s/100 iter), loss = 0.181297
I0502 11:42:10.460093 26473 solver.cpp:261]     Train net output #0: loss = 0.181297 (* 1 = 0.181297 loss)
I0502 11:42:10.460103 26473 sgd_solver.cpp:106] Iteration 194800, lr = 1.44115e-06
I0502 11:42:10.464921 26473 solver.cpp:242] Iteration 194800 (106.037 iter/s, 0.943067s/100 iter), loss = 0.0396717
I0502 11:42:10.464944 26473 solver.cpp:261]     Train net output #0: loss = 0.0396717 (* 1 = 0.0396717 loss)
I0502 11:42:10.464953 26473 sgd_solver.cpp:106] Iteration 194800, lr = 1.44115e-06
I0502 11:42:11.404049 26473 solver.cpp:242] Iteration 194900 (105.94 iter/s, 0.943926s/100 iter), loss = 0.100099
I0502 11:42:11.404084 26473 solver.cpp:261]     Train net output #0: loss = 0.100099 (* 1 = 0.100099 loss)
I0502 11:42:11.404093 26473 sgd_solver.cpp:106] Iteration 194900, lr = 1.44115e-06
I0502 11:42:11.408864 26473 solver.cpp:242] Iteration 194900 (105.943 iter/s, 0.943902s/100 iter), loss = 0.110349
I0502 11:42:11.408887 26473 solver.cpp:261]     Train net output #0: loss = 0.110349 (* 1 = 0.110349 loss)
I0502 11:42:11.408895 26473 sgd_solver.cpp:106] Iteration 194900, lr = 1.44115e-06
I0502 11:42:12.345762 26473 solver.cpp:362] Iteration 195000, Testing net (#0)
I0502 11:42:12.345783 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:12.470126 26473 solver.cpp:429]     Test net output #0: loss = 0.270362 (* 1 = 0.270362 loss)
I0502 11:42:12.473012 26473 solver.cpp:242] Iteration 195000 (93.5533 iter/s, 1.06891s/100 iter), loss = 0.385678
I0502 11:42:12.473032 26473 solver.cpp:261]     Train net output #0: loss = 0.385678 (* 1 = 0.385678 loss)
I0502 11:42:12.473040 26473 sgd_solver.cpp:106] Iteration 195000, lr = 1.44115e-06
I0502 11:42:12.474660 26473 solver.cpp:362] Iteration 195000, Testing net (#0)
I0502 11:42:12.474673 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:12.604995 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:42:12.605016 26473 solver.cpp:429]     Test net output #1: loss = 0.0806449 (* 1 = 0.0806449 loss)
I0502 11:42:12.607945 26473 solver.cpp:242] Iteration 195000 (83.4002 iter/s, 1.19904s/100 iter), loss = 0.0342214
I0502 11:42:12.607965 26473 solver.cpp:261]     Train net output #0: loss = 0.0342214 (* 1 = 0.0342214 loss)
I0502 11:42:12.607973 26473 sgd_solver.cpp:106] Iteration 195000, lr = 1.44115e-06
I0502 11:42:13.546982 26473 solver.cpp:242] Iteration 195100 (93.1169 iter/s, 1.07392s/100 iter), loss = 0.410976
I0502 11:42:13.547019 26473 solver.cpp:261]     Train net output #0: loss = 0.410976 (* 1 = 0.410976 loss)
I0502 11:42:13.547029 26473 sgd_solver.cpp:106] Iteration 195100, lr = 1.44115e-06
I0502 11:42:13.551792 26473 solver.cpp:242] Iteration 195100 (105.954 iter/s, 0.94381s/100 iter), loss = 0.0452972
I0502 11:42:13.551815 26473 solver.cpp:261]     Train net output #0: loss = 0.0452972 (* 1 = 0.0452972 loss)
I0502 11:42:13.551823 26473 sgd_solver.cpp:106] Iteration 195100, lr = 1.44115e-06
I0502 11:42:14.491550 26473 solver.cpp:242] Iteration 195200 (105.876 iter/s, 0.944504s/100 iter), loss = 0.118418
I0502 11:42:14.491592 26473 solver.cpp:261]     Train net output #0: loss = 0.118418 (* 1 = 0.118418 loss)
I0502 11:42:14.491601 26473 sgd_solver.cpp:106] Iteration 195200, lr = 1.44115e-06
I0502 11:42:14.496412 26473 solver.cpp:242] Iteration 195200 (105.867 iter/s, 0.944578s/100 iter), loss = 0.0509129
I0502 11:42:14.496435 26473 solver.cpp:261]     Train net output #0: loss = 0.0509129 (* 1 = 0.0509129 loss)
I0502 11:42:14.496444 26473 sgd_solver.cpp:106] Iteration 195200, lr = 1.44115e-06
I0502 11:42:15.435873 26473 solver.cpp:242] Iteration 195300 (105.903 iter/s, 0.944259s/100 iter), loss = 0.0147176
I0502 11:42:15.435904 26473 solver.cpp:261]     Train net output #0: loss = 0.0147176 (* 1 = 0.0147176 loss)
I0502 11:42:15.435912 26473 sgd_solver.cpp:106] Iteration 195300, lr = 1.44115e-06
I0502 11:42:15.440742 26473 solver.cpp:242] Iteration 195300 (105.901 iter/s, 0.944282s/100 iter), loss = 0.0553832
I0502 11:42:15.440765 26473 solver.cpp:261]     Train net output #0: loss = 0.0553832 (* 1 = 0.0553832 loss)
I0502 11:42:15.440773 26473 sgd_solver.cpp:106] Iteration 195300, lr = 1.44115e-06
I0502 11:42:16.380223 26473 solver.cpp:242] Iteration 195400 (105.9 iter/s, 0.944288s/100 iter), loss = 0.0364134
I0502 11:42:16.380265 26473 solver.cpp:261]     Train net output #0: loss = 0.0364134 (* 1 = 0.0364134 loss)
I0502 11:42:16.380275 26473 sgd_solver.cpp:106] Iteration 195400, lr = 1.44115e-06
I0502 11:42:16.385022 26473 solver.cpp:242] Iteration 195400 (105.905 iter/s, 0.94424s/100 iter), loss = 0.0278286
I0502 11:42:16.385046 26473 solver.cpp:261]     Train net output #0: loss = 0.0278286 (* 1 = 0.0278286 loss)
I0502 11:42:16.385053 26473 sgd_solver.cpp:106] Iteration 195400, lr = 1.44115e-06
I0502 11:42:17.323236 26473 solver.cpp:362] Iteration 195500, Testing net (#0)
I0502 11:42:17.323266 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:17.447753 26473 solver.cpp:429]     Test net output #0: loss = 0.204622 (* 1 = 0.204622 loss)
I0502 11:42:17.450633 26473 solver.cpp:242] Iteration 195500 (93.4276 iter/s, 1.07035s/100 iter), loss = 0.221757
I0502 11:42:17.450652 26473 solver.cpp:261]     Train net output #0: loss = 0.221757 (* 1 = 0.221757 loss)
I0502 11:42:17.450660 26473 sgd_solver.cpp:106] Iteration 195500, lr = 1.44115e-06
I0502 11:42:17.452283 26473 solver.cpp:362] Iteration 195500, Testing net (#0)
I0502 11:42:17.452303 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:17.583039 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:42:17.583058 26473 solver.cpp:429]     Test net output #1: loss = 0.0777008 (* 1 = 0.0777008 loss)
I0502 11:42:17.585970 26473 solver.cpp:242] Iteration 195500 (83.2706 iter/s, 1.2009s/100 iter), loss = 0.2335
I0502 11:42:17.585990 26473 solver.cpp:261]     Train net output #0: loss = 0.2335 (* 1 = 0.2335 loss)
I0502 11:42:17.585999 26473 sgd_solver.cpp:106] Iteration 195500, lr = 1.44115e-06
I0502 11:42:18.524828 26473 solver.cpp:242] Iteration 195600 (93.0969 iter/s, 1.07415s/100 iter), loss = 0.125083
I0502 11:42:18.524859 26473 solver.cpp:261]     Train net output #0: loss = 0.125083 (* 1 = 0.125083 loss)
I0502 11:42:18.524868 26473 sgd_solver.cpp:106] Iteration 195600, lr = 1.44115e-06
I0502 11:42:18.529623 26473 solver.cpp:242] Iteration 195600 (105.976 iter/s, 0.943614s/100 iter), loss = 0.0362944
I0502 11:42:18.529645 26473 solver.cpp:261]     Train net output #0: loss = 0.0362944 (* 1 = 0.0362944 loss)
I0502 11:42:18.529654 26473 sgd_solver.cpp:106] Iteration 195600, lr = 1.44115e-06
I0502 11:42:19.468919 26473 solver.cpp:242] Iteration 195700 (105.929 iter/s, 0.944033s/100 iter), loss = 0.154962
I0502 11:42:19.468961 26473 solver.cpp:261]     Train net output #0: loss = 0.154962 (* 1 = 0.154962 loss)
I0502 11:42:19.468971 26473 sgd_solver.cpp:106] Iteration 195700, lr = 1.44115e-06
I0502 11:42:19.473724 26473 solver.cpp:242] Iteration 195700 (105.925 iter/s, 0.94406s/100 iter), loss = 0.183205
I0502 11:42:19.473747 26473 solver.cpp:261]     Train net output #0: loss = 0.183205 (* 1 = 0.183205 loss)
I0502 11:42:19.473757 26473 sgd_solver.cpp:106] Iteration 195700, lr = 1.44115e-06
I0502 11:42:20.413354 26473 solver.cpp:242] Iteration 195800 (105.891 iter/s, 0.944368s/100 iter), loss = 1.19228
I0502 11:42:20.413394 26473 solver.cpp:261]     Train net output #0: loss = 1.19228 (* 1 = 1.19228 loss)
I0502 11:42:20.413403 26473 sgd_solver.cpp:106] Iteration 195800, lr = 1.44115e-06
I0502 11:42:20.418252 26473 solver.cpp:242] Iteration 195800 (105.879 iter/s, 0.944478s/100 iter), loss = 0.155142
I0502 11:42:20.418275 26473 solver.cpp:261]     Train net output #0: loss = 0.155142 (* 1 = 0.155142 loss)
I0502 11:42:20.418283 26473 sgd_solver.cpp:106] Iteration 195800, lr = 1.44115e-06
I0502 11:42:21.356815 26473 solver.cpp:242] Iteration 195900 (106.001 iter/s, 0.94339s/100 iter), loss = 0.158227
I0502 11:42:21.356856 26473 solver.cpp:261]     Train net output #0: loss = 0.158227 (* 1 = 0.158227 loss)
I0502 11:42:21.356865 26473 sgd_solver.cpp:106] Iteration 195900, lr = 1.44115e-06
I0502 11:42:21.361630 26473 solver.cpp:242] Iteration 195900 (106.007 iter/s, 0.943338s/100 iter), loss = 0.0254014
I0502 11:42:21.361654 26473 solver.cpp:261]     Train net output #0: loss = 0.0254014 (* 1 = 0.0254014 loss)
I0502 11:42:21.361662 26473 sgd_solver.cpp:106] Iteration 195900, lr = 1.44115e-06
I0502 11:42:22.297863 26473 solver.cpp:362] Iteration 196000, Testing net (#0)
I0502 11:42:22.297890 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:22.422248 26473 solver.cpp:429]     Test net output #0: loss = 0.237692 (* 1 = 0.237692 loss)
I0502 11:42:22.425113 26473 solver.cpp:242] Iteration 196000 (93.612 iter/s, 1.06824s/100 iter), loss = 0.967864
I0502 11:42:22.425133 26473 solver.cpp:261]     Train net output #0: loss = 0.967864 (* 1 = 0.967864 loss)
I0502 11:42:22.425142 26473 sgd_solver.cpp:106] Iteration 196000, lr = 1.44115e-06
I0502 11:42:22.426790 26473 solver.cpp:362] Iteration 196000, Testing net (#0)
I0502 11:42:22.426805 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:22.557425 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:42:22.557446 26473 solver.cpp:429]     Test net output #1: loss = 0.0812608 (* 1 = 0.0812608 loss)
I0502 11:42:22.560361 26473 solver.cpp:242] Iteration 196000 (83.4247 iter/s, 1.19869s/100 iter), loss = 0.25213
I0502 11:42:22.560380 26473 solver.cpp:261]     Train net output #0: loss = 0.25213 (* 1 = 0.25213 loss)
I0502 11:42:22.560396 26473 sgd_solver.cpp:106] Iteration 196000, lr = 1.44115e-06
I0502 11:42:23.500617 26473 solver.cpp:242] Iteration 196100 (92.9841 iter/s, 1.07545s/100 iter), loss = 0.0669028
I0502 11:42:23.500663 26473 solver.cpp:261]     Train net output #0: loss = 0.0669028 (* 1 = 0.0669028 loss)
I0502 11:42:23.500671 26473 sgd_solver.cpp:106] Iteration 196100, lr = 1.44115e-06
I0502 11:42:23.505432 26473 solver.cpp:242] Iteration 196100 (105.816 iter/s, 0.945033s/100 iter), loss = 0.0246404
I0502 11:42:23.505455 26473 solver.cpp:261]     Train net output #0: loss = 0.0246404 (* 1 = 0.0246404 loss)
I0502 11:42:23.505463 26473 sgd_solver.cpp:106] Iteration 196100, lr = 1.44115e-06
I0502 11:42:24.444311 26473 solver.cpp:242] Iteration 196200 (105.974 iter/s, 0.943624s/100 iter), loss = 0.0361317
I0502 11:42:24.444355 26473 solver.cpp:261]     Train net output #0: loss = 0.0361317 (* 1 = 0.0361317 loss)
I0502 11:42:24.444365 26473 sgd_solver.cpp:106] Iteration 196200, lr = 1.44115e-06
I0502 11:42:24.449131 26473 solver.cpp:242] Iteration 196200 (105.971 iter/s, 0.943658s/100 iter), loss = 0.00902017
I0502 11:42:24.449153 26473 solver.cpp:261]     Train net output #0: loss = 0.00902017 (* 1 = 0.00902017 loss)
I0502 11:42:24.449162 26473 sgd_solver.cpp:106] Iteration 196200, lr = 1.44115e-06
I0502 11:42:25.388190 26473 solver.cpp:242] Iteration 196300 (105.954 iter/s, 0.94381s/100 iter), loss = 0.198154
I0502 11:42:25.388233 26473 solver.cpp:261]     Train net output #0: loss = 0.198154 (* 1 = 0.198154 loss)
I0502 11:42:25.388242 26473 sgd_solver.cpp:106] Iteration 196300, lr = 1.44115e-06
I0502 11:42:25.393101 26473 solver.cpp:242] Iteration 196300 (105.941 iter/s, 0.943921s/100 iter), loss = 0.0530193
I0502 11:42:25.393124 26473 solver.cpp:261]     Train net output #0: loss = 0.0530193 (* 1 = 0.0530193 loss)
I0502 11:42:25.393133 26473 sgd_solver.cpp:106] Iteration 196300, lr = 1.44115e-06
I0502 11:42:26.332765 26473 solver.cpp:242] Iteration 196400 (105.876 iter/s, 0.944503s/100 iter), loss = 0.373872
I0502 11:42:26.332803 26473 solver.cpp:261]     Train net output #0: loss = 0.373872 (* 1 = 0.373872 loss)
I0502 11:42:26.332813 26473 sgd_solver.cpp:106] Iteration 196400, lr = 1.44115e-06
I0502 11:42:26.337584 26473 solver.cpp:242] Iteration 196400 (105.883 iter/s, 0.94444s/100 iter), loss = 0.211994
I0502 11:42:26.337605 26473 solver.cpp:261]     Train net output #0: loss = 0.211994 (* 1 = 0.211994 loss)
I0502 11:42:26.337615 26473 sgd_solver.cpp:106] Iteration 196400, lr = 1.44115e-06
I0502 11:42:27.273604 26473 solver.cpp:362] Iteration 196500, Testing net (#0)
I0502 11:42:27.273629 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:27.397814 26473 solver.cpp:429]     Test net output #0: loss = 0.204565 (* 1 = 0.204565 loss)
I0502 11:42:27.400679 26473 solver.cpp:242] Iteration 196500 (93.6454 iter/s, 1.06786s/100 iter), loss = 0.118315
I0502 11:42:27.400701 26473 solver.cpp:261]     Train net output #0: loss = 0.118315 (* 1 = 0.118315 loss)
I0502 11:42:27.400709 26473 sgd_solver.cpp:106] Iteration 196500, lr = 1.44115e-06
I0502 11:42:27.402385 26473 solver.cpp:362] Iteration 196500, Testing net (#0)
I0502 11:42:27.402400 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:27.533490 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9675
I0502 11:42:27.533519 26473 solver.cpp:429]     Test net output #1: loss = 0.0782785 (* 1 = 0.0782785 loss)
I0502 11:42:27.536469 26473 solver.cpp:242] Iteration 196500 (83.4138 iter/s, 1.19884s/100 iter), loss = 0.0374336
I0502 11:42:27.536489 26473 solver.cpp:261]     Train net output #0: loss = 0.0374336 (* 1 = 0.0374336 loss)
I0502 11:42:27.536499 26473 sgd_solver.cpp:106] Iteration 196500, lr = 1.44115e-06
I0502 11:42:28.475195 26473 solver.cpp:242] Iteration 196600 (93.0697 iter/s, 1.07446s/100 iter), loss = 0.118085
I0502 11:42:28.475236 26473 solver.cpp:261]     Train net output #0: loss = 0.118085 (* 1 = 0.118085 loss)
I0502 11:42:28.475245 26473 sgd_solver.cpp:106] Iteration 196600, lr = 1.44115e-06
I0502 11:42:28.480042 26473 solver.cpp:242] Iteration 196600 (105.985 iter/s, 0.943534s/100 iter), loss = 0.0654283
I0502 11:42:28.480065 26473 solver.cpp:261]     Train net output #0: loss = 0.0654283 (* 1 = 0.0654283 loss)
I0502 11:42:28.480073 26473 sgd_solver.cpp:106] Iteration 196600, lr = 1.44115e-06
I0502 11:42:29.419159 26473 solver.cpp:242] Iteration 196700 (105.944 iter/s, 0.943896s/100 iter), loss = 0.0701899
I0502 11:42:29.419201 26473 solver.cpp:261]     Train net output #0: loss = 0.0701899 (* 1 = 0.0701899 loss)
I0502 11:42:29.419209 26473 sgd_solver.cpp:106] Iteration 196700, lr = 1.44115e-06
I0502 11:42:29.423964 26473 solver.cpp:242] Iteration 196700 (105.946 iter/s, 0.94388s/100 iter), loss = 0.151453
I0502 11:42:29.423985 26473 solver.cpp:261]     Train net output #0: loss = 0.151453 (* 1 = 0.151453 loss)
I0502 11:42:29.423995 26473 sgd_solver.cpp:106] Iteration 196700, lr = 1.44115e-06
I0502 11:42:30.362565 26473 solver.cpp:242] Iteration 196800 (106.006 iter/s, 0.943339s/100 iter), loss = 0.341752
I0502 11:42:30.362603 26473 solver.cpp:261]     Train net output #0: loss = 0.341752 (* 1 = 0.341752 loss)
I0502 11:42:30.362612 26473 sgd_solver.cpp:106] Iteration 196800, lr = 1.44115e-06
I0502 11:42:30.367442 26473 solver.cpp:242] Iteration 196800 (105.996 iter/s, 0.94343s/100 iter), loss = 0.149597
I0502 11:42:30.367465 26473 solver.cpp:261]     Train net output #0: loss = 0.149597 (* 1 = 0.149597 loss)
I0502 11:42:30.367475 26473 sgd_solver.cpp:106] Iteration 196800, lr = 1.44115e-06
I0502 11:42:31.305999 26473 solver.cpp:242] Iteration 196900 (106.004 iter/s, 0.943363s/100 iter), loss = 0.0639003
I0502 11:42:31.306036 26473 solver.cpp:261]     Train net output #0: loss = 0.0639003 (* 1 = 0.0639003 loss)
I0502 11:42:31.306046 26473 sgd_solver.cpp:106] Iteration 196900, lr = 1.44115e-06
I0502 11:42:31.310803 26473 solver.cpp:242] Iteration 196900 (106.009 iter/s, 0.94332s/100 iter), loss = 0.141905
I0502 11:42:31.310825 26473 solver.cpp:261]     Train net output #0: loss = 0.141905 (* 1 = 0.141905 loss)
I0502 11:42:31.310833 26473 sgd_solver.cpp:106] Iteration 196900, lr = 1.44115e-06
I0502 11:42:32.247313 26473 solver.cpp:362] Iteration 197000, Testing net (#0)
I0502 11:42:32.247334 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:32.371788 26473 solver.cpp:429]     Test net output #0: loss = 0.213309 (* 1 = 0.213309 loss)
I0502 11:42:32.374671 26473 solver.cpp:242] Iteration 197000 (93.5789 iter/s, 1.06862s/100 iter), loss = 0.172412
I0502 11:42:32.374691 26473 solver.cpp:261]     Train net output #0: loss = 0.172412 (* 1 = 0.172412 loss)
I0502 11:42:32.374701 26473 sgd_solver.cpp:106] Iteration 197000, lr = 1.44115e-06
I0502 11:42:32.376325 26473 solver.cpp:362] Iteration 197000, Testing net (#0)
I0502 11:42:32.376338 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:32.506772 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9635
I0502 11:42:32.506791 26473 solver.cpp:429]     Test net output #1: loss = 0.0796314 (* 1 = 0.0796314 loss)
I0502 11:42:32.509714 26473 solver.cpp:242] Iteration 197000 (83.412 iter/s, 1.19887s/100 iter), loss = 0.00788146
I0502 11:42:32.509734 26473 solver.cpp:261]     Train net output #0: loss = 0.00788146 (* 1 = 0.00788146 loss)
I0502 11:42:32.509742 26473 sgd_solver.cpp:106] Iteration 197000, lr = 1.44115e-06
I0502 11:42:33.450526 26473 solver.cpp:242] Iteration 197100 (92.9539 iter/s, 1.0758s/100 iter), loss = 0.107474
I0502 11:42:33.450565 26473 solver.cpp:261]     Train net output #0: loss = 0.107474 (* 1 = 0.107474 loss)
I0502 11:42:33.450574 26473 sgd_solver.cpp:106] Iteration 197100, lr = 1.44115e-06
I0502 11:42:33.455350 26473 solver.cpp:242] Iteration 197100 (105.753 iter/s, 0.945598s/100 iter), loss = 0.110407
I0502 11:42:33.455374 26473 solver.cpp:261]     Train net output #0: loss = 0.110407 (* 1 = 0.110407 loss)
I0502 11:42:33.455382 26473 sgd_solver.cpp:106] Iteration 197100, lr = 1.44115e-06
I0502 11:42:34.395689 26473 solver.cpp:242] Iteration 197200 (105.809 iter/s, 0.9451s/100 iter), loss = 0.0369251
I0502 11:42:34.395736 26473 solver.cpp:261]     Train net output #0: loss = 0.0369251 (* 1 = 0.0369251 loss)
I0502 11:42:34.395746 26473 sgd_solver.cpp:106] Iteration 197200, lr = 1.44115e-06
I0502 11:42:34.400491 26473 solver.cpp:242] Iteration 197200 (105.809 iter/s, 0.945099s/100 iter), loss = 0.313305
I0502 11:42:34.400513 26473 solver.cpp:261]     Train net output #0: loss = 0.313305 (* 1 = 0.313305 loss)
I0502 11:42:34.400521 26473 sgd_solver.cpp:106] Iteration 197200, lr = 1.44115e-06
I0502 11:42:35.338580 26473 solver.cpp:242] Iteration 197300 (106.065 iter/s, 0.942819s/100 iter), loss = 0.0319057
I0502 11:42:35.338615 26473 solver.cpp:261]     Train net output #0: loss = 0.0319057 (* 1 = 0.0319057 loss)
I0502 11:42:35.338624 26473 sgd_solver.cpp:106] Iteration 197300, lr = 1.44115e-06
I0502 11:42:35.343452 26473 solver.cpp:242] Iteration 197300 (106.054 iter/s, 0.942913s/100 iter), loss = 0.0317768
I0502 11:42:35.343477 26473 solver.cpp:261]     Train net output #0: loss = 0.0317768 (* 1 = 0.0317768 loss)
I0502 11:42:35.343485 26473 sgd_solver.cpp:106] Iteration 197300, lr = 1.44115e-06
I0502 11:42:36.282222 26473 solver.cpp:242] Iteration 197400 (105.979 iter/s, 0.943584s/100 iter), loss = 0.376394
I0502 11:42:36.282258 26473 solver.cpp:261]     Train net output #0: loss = 0.376394 (* 1 = 0.376394 loss)
I0502 11:42:36.282268 26473 sgd_solver.cpp:106] Iteration 197400, lr = 1.44115e-06
I0502 11:42:36.287077 26473 solver.cpp:242] Iteration 197400 (105.98 iter/s, 0.943578s/100 iter), loss = 0.118527
I0502 11:42:36.287101 26473 solver.cpp:261]     Train net output #0: loss = 0.118527 (* 1 = 0.118527 loss)
I0502 11:42:36.287108 26473 sgd_solver.cpp:106] Iteration 197400, lr = 1.44115e-06
I0502 11:42:37.222039 26473 solver.cpp:362] Iteration 197500, Testing net (#0)
I0502 11:42:37.222069 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:37.346343 26473 solver.cpp:429]     Test net output #0: loss = 0.204295 (* 1 = 0.204295 loss)
I0502 11:42:37.349210 26473 solver.cpp:242] Iteration 197500 (93.7266 iter/s, 1.06693s/100 iter), loss = 0.440793
I0502 11:42:37.349230 26473 solver.cpp:261]     Train net output #0: loss = 0.440793 (* 1 = 0.440793 loss)
I0502 11:42:37.349237 26473 sgd_solver.cpp:106] Iteration 197500, lr = 1.44115e-06
I0502 11:42:37.350864 26473 solver.cpp:362] Iteration 197500, Testing net (#0)
I0502 11:42:37.350878 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:37.481680 26473 solver.cpp:429]     Test net output #0: accuracy = 0.962
I0502 11:42:37.481698 26473 solver.cpp:429]     Test net output #1: loss = 0.0694953 (* 1 = 0.0694953 loss)
I0502 11:42:37.484629 26473 solver.cpp:242] Iteration 197500 (83.5067 iter/s, 1.19751s/100 iter), loss = 0.03649
I0502 11:42:37.484650 26473 solver.cpp:261]     Train net output #0: loss = 0.03649 (* 1 = 0.03649 loss)
I0502 11:42:37.484658 26473 sgd_solver.cpp:106] Iteration 197500, lr = 1.44115e-06
I0502 11:42:38.423017 26473 solver.cpp:242] Iteration 197600 (93.1309 iter/s, 1.07376s/100 iter), loss = 0.107973
I0502 11:42:38.423059 26473 solver.cpp:261]     Train net output #0: loss = 0.107973 (* 1 = 0.107973 loss)
I0502 11:42:38.423069 26473 sgd_solver.cpp:106] Iteration 197600, lr = 1.44115e-06
I0502 11:42:38.427834 26473 solver.cpp:242] Iteration 197600 (106.026 iter/s, 0.943165s/100 iter), loss = 0.0836746
I0502 11:42:38.427856 26473 solver.cpp:261]     Train net output #0: loss = 0.0836746 (* 1 = 0.0836746 loss)
I0502 11:42:38.427865 26473 sgd_solver.cpp:106] Iteration 197600, lr = 1.44115e-06
I0502 11:42:39.367172 26473 solver.cpp:242] Iteration 197700 (105.923 iter/s, 0.944085s/100 iter), loss = 0.16102
I0502 11:42:39.367216 26473 solver.cpp:261]     Train net output #0: loss = 0.16102 (* 1 = 0.16102 loss)
I0502 11:42:39.367225 26473 sgd_solver.cpp:106] Iteration 197700, lr = 1.44115e-06
I0502 11:42:39.372028 26473 solver.cpp:242] Iteration 197700 (105.915 iter/s, 0.944154s/100 iter), loss = 0.03937
I0502 11:42:39.372052 26473 solver.cpp:261]     Train net output #0: loss = 0.03937 (* 1 = 0.03937 loss)
I0502 11:42:39.372069 26473 sgd_solver.cpp:106] Iteration 197700, lr = 1.44115e-06
I0502 11:42:40.310539 26473 solver.cpp:242] Iteration 197800 (106.011 iter/s, 0.943295s/100 iter), loss = 0.125898
I0502 11:42:40.310595 26473 solver.cpp:261]     Train net output #0: loss = 0.125898 (* 1 = 0.125898 loss)
I0502 11:42:40.310603 26473 sgd_solver.cpp:106] Iteration 197800, lr = 1.44115e-06
I0502 11:42:40.315409 26473 solver.cpp:242] Iteration 197800 (106.006 iter/s, 0.94334s/100 iter), loss = 0.0844232
I0502 11:42:40.315433 26473 solver.cpp:261]     Train net output #0: loss = 0.0844232 (* 1 = 0.0844232 loss)
I0502 11:42:40.315441 26473 sgd_solver.cpp:106] Iteration 197800, lr = 1.44115e-06
I0502 11:42:41.254037 26473 solver.cpp:242] Iteration 197900 (105.997 iter/s, 0.94342s/100 iter), loss = 0.147221
I0502 11:42:41.254081 26473 solver.cpp:261]     Train net output #0: loss = 0.147221 (* 1 = 0.147221 loss)
I0502 11:42:41.254089 26473 sgd_solver.cpp:106] Iteration 197900, lr = 1.44115e-06
I0502 11:42:41.258937 26473 solver.cpp:242] Iteration 197900 (105.991 iter/s, 0.943479s/100 iter), loss = 0.0722118
I0502 11:42:41.258961 26473 solver.cpp:261]     Train net output #0: loss = 0.0722118 (* 1 = 0.0722118 loss)
I0502 11:42:41.258970 26473 sgd_solver.cpp:106] Iteration 197900, lr = 1.44115e-06
I0502 11:42:42.194640 26473 solver.cpp:362] Iteration 198000, Testing net (#0)
I0502 11:42:42.194666 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:42.318886 26473 solver.cpp:429]     Test net output #0: loss = 0.231655 (* 1 = 0.231655 loss)
I0502 11:42:42.321754 26473 solver.cpp:242] Iteration 198000 (93.663 iter/s, 1.06766s/100 iter), loss = 0.099491
I0502 11:42:42.321774 26473 solver.cpp:261]     Train net output #0: loss = 0.099491 (* 1 = 0.099491 loss)
I0502 11:42:42.321784 26473 sgd_solver.cpp:106] Iteration 198000, lr = 1.44115e-06
I0502 11:42:42.323397 26473 solver.cpp:362] Iteration 198000, Testing net (#0)
I0502 11:42:42.323410 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:42.454162 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:42:42.454190 26473 solver.cpp:429]     Test net output #1: loss = 0.0826672 (* 1 = 0.0826672 loss)
I0502 11:42:42.457128 26473 solver.cpp:242] Iteration 198000 (83.4623 iter/s, 1.19815s/100 iter), loss = 0.046381
I0502 11:42:42.457147 26473 solver.cpp:261]     Train net output #0: loss = 0.046381 (* 1 = 0.046381 loss)
I0502 11:42:42.457156 26473 sgd_solver.cpp:106] Iteration 198000, lr = 1.44115e-06
I0502 11:42:43.396208 26473 solver.cpp:242] Iteration 198100 (93.0751 iter/s, 1.0744s/100 iter), loss = 0.338314
I0502 11:42:43.396252 26473 solver.cpp:261]     Train net output #0: loss = 0.338314 (* 1 = 0.338314 loss)
I0502 11:42:43.396261 26473 sgd_solver.cpp:106] Iteration 198100, lr = 1.44115e-06
I0502 11:42:43.401021 26473 solver.cpp:242] Iteration 198100 (105.948 iter/s, 0.943856s/100 iter), loss = 0.00671824
I0502 11:42:43.401044 26473 solver.cpp:261]     Train net output #0: loss = 0.00671824 (* 1 = 0.00671824 loss)
I0502 11:42:43.401053 26473 sgd_solver.cpp:106] Iteration 198100, lr = 1.44115e-06
I0502 11:42:44.339851 26473 solver.cpp:242] Iteration 198200 (105.98 iter/s, 0.94357s/100 iter), loss = 0.27739
I0502 11:42:44.339891 26473 solver.cpp:261]     Train net output #0: loss = 0.27739 (* 1 = 0.27739 loss)
I0502 11:42:44.339900 26473 sgd_solver.cpp:106] Iteration 198200, lr = 1.44115e-06
I0502 11:42:44.344705 26473 solver.cpp:242] Iteration 198200 (105.972 iter/s, 0.943643s/100 iter), loss = 0.0176288
I0502 11:42:44.344732 26473 solver.cpp:261]     Train net output #0: loss = 0.0176288 (* 1 = 0.0176288 loss)
I0502 11:42:44.344739 26473 sgd_solver.cpp:106] Iteration 198200, lr = 1.44115e-06
I0502 11:42:45.283165 26473 solver.cpp:242] Iteration 198300 (106.017 iter/s, 0.943248s/100 iter), loss = 0.024825
I0502 11:42:45.283206 26473 solver.cpp:261]     Train net output #0: loss = 0.024825 (* 1 = 0.024825 loss)
I0502 11:42:45.283215 26473 sgd_solver.cpp:106] Iteration 198300, lr = 1.44115e-06
I0502 11:42:45.287976 26473 solver.cpp:242] Iteration 198300 (106.019 iter/s, 0.943228s/100 iter), loss = 0.0279894
I0502 11:42:45.288007 26473 solver.cpp:261]     Train net output #0: loss = 0.0279894 (* 1 = 0.0279894 loss)
I0502 11:42:45.288017 26473 sgd_solver.cpp:106] Iteration 198300, lr = 1.44115e-06
I0502 11:42:46.227193 26473 solver.cpp:242] Iteration 198400 (105.936 iter/s, 0.943964s/100 iter), loss = 0.0445645
I0502 11:42:46.227234 26473 solver.cpp:261]     Train net output #0: loss = 0.0445645 (* 1 = 0.0445645 loss)
I0502 11:42:46.227243 26473 sgd_solver.cpp:106] Iteration 198400, lr = 1.44115e-06
I0502 11:42:46.232084 26473 solver.cpp:242] Iteration 198400 (105.927 iter/s, 0.94405s/100 iter), loss = 0.0102805
I0502 11:42:46.232107 26473 solver.cpp:261]     Train net output #0: loss = 0.0102805 (* 1 = 0.0102805 loss)
I0502 11:42:46.232115 26473 sgd_solver.cpp:106] Iteration 198400, lr = 1.44115e-06
I0502 11:42:47.168535 26473 solver.cpp:362] Iteration 198500, Testing net (#0)
I0502 11:42:47.168575 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:47.292909 26473 solver.cpp:429]     Test net output #0: loss = 0.23724 (* 1 = 0.23724 loss)
I0502 11:42:47.295770 26473 solver.cpp:242] Iteration 198500 (93.5875 iter/s, 1.06852s/100 iter), loss = 0.291467
I0502 11:42:47.295790 26473 solver.cpp:261]     Train net output #0: loss = 0.291467 (* 1 = 0.291467 loss)
I0502 11:42:47.295799 26473 sgd_solver.cpp:106] Iteration 198500, lr = 1.44115e-06
I0502 11:42:47.297431 26473 solver.cpp:362] Iteration 198500, Testing net (#0)
I0502 11:42:47.297444 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:47.428133 26473 solver.cpp:429]     Test net output #0: accuracy = 0.965
I0502 11:42:47.428153 26473 solver.cpp:429]     Test net output #1: loss = 0.0742896 (* 1 = 0.0742896 loss)
I0502 11:42:47.431084 26473 solver.cpp:242] Iteration 198500 (83.4058 iter/s, 1.19896s/100 iter), loss = 0.0156296
I0502 11:42:47.431105 26473 solver.cpp:261]     Train net output #0: loss = 0.0156296 (* 1 = 0.0156296 loss)
I0502 11:42:47.431113 26473 sgd_solver.cpp:106] Iteration 198500, lr = 1.44115e-06
I0502 11:42:48.369551 26473 solver.cpp:242] Iteration 198600 (93.1333 iter/s, 1.07373s/100 iter), loss = 0.255868
I0502 11:42:48.369590 26473 solver.cpp:261]     Train net output #0: loss = 0.255868 (* 1 = 0.255868 loss)
I0502 11:42:48.369598 26473 sgd_solver.cpp:106] Iteration 198600, lr = 1.44115e-06
I0502 11:42:48.374339 26473 solver.cpp:242] Iteration 198600 (106.02 iter/s, 0.943216s/100 iter), loss = 0.0994229
I0502 11:42:48.374362 26473 solver.cpp:261]     Train net output #0: loss = 0.0994229 (* 1 = 0.0994229 loss)
I0502 11:42:48.374370 26473 sgd_solver.cpp:106] Iteration 198600, lr = 1.44115e-06
I0502 11:42:49.313442 26473 solver.cpp:242] Iteration 198700 (105.952 iter/s, 0.943824s/100 iter), loss = 0.293514
I0502 11:42:49.313482 26473 solver.cpp:261]     Train net output #0: loss = 0.293514 (* 1 = 0.293514 loss)
I0502 11:42:49.313491 26473 sgd_solver.cpp:106] Iteration 198700, lr = 1.44115e-06
I0502 11:42:49.318231 26473 solver.cpp:242] Iteration 198700 (105.949 iter/s, 0.943852s/100 iter), loss = 0.100611
I0502 11:42:49.318254 26473 solver.cpp:261]     Train net output #0: loss = 0.100611 (* 1 = 0.100611 loss)
I0502 11:42:49.318264 26473 sgd_solver.cpp:106] Iteration 198700, lr = 1.44115e-06
I0502 11:42:50.276232 26473 solver.cpp:242] Iteration 198800 (103.872 iter/s, 0.962723s/100 iter), loss = 0.368958
I0502 11:42:50.276278 26473 solver.cpp:261]     Train net output #0: loss = 0.368958 (* 1 = 0.368958 loss)
I0502 11:42:50.276286 26473 sgd_solver.cpp:106] Iteration 198800, lr = 1.44115e-06
I0502 11:42:50.281066 26473 solver.cpp:242] Iteration 198800 (103.864 iter/s, 0.962793s/100 iter), loss = 0.0593956
I0502 11:42:50.281091 26473 solver.cpp:261]     Train net output #0: loss = 0.0593956 (* 1 = 0.0593956 loss)
I0502 11:42:50.281100 26473 sgd_solver.cpp:106] Iteration 198800, lr = 1.44115e-06
I0502 11:42:51.220912 26473 solver.cpp:242] Iteration 198900 (105.864 iter/s, 0.94461s/100 iter), loss = 0.143554
I0502 11:42:51.220954 26473 solver.cpp:261]     Train net output #0: loss = 0.143554 (* 1 = 0.143554 loss)
I0502 11:42:51.220971 26473 sgd_solver.cpp:106] Iteration 198900, lr = 1.44115e-06
I0502 11:42:51.225801 26473 solver.cpp:242] Iteration 198900 (105.855 iter/s, 0.944684s/100 iter), loss = 0.0743439
I0502 11:42:51.225826 26473 solver.cpp:261]     Train net output #0: loss = 0.0743439 (* 1 = 0.0743439 loss)
I0502 11:42:51.225834 26473 sgd_solver.cpp:106] Iteration 198900, lr = 1.44115e-06
I0502 11:42:52.161182 26473 solver.cpp:362] Iteration 199000, Testing net (#0)
I0502 11:42:52.161203 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:52.285600 26473 solver.cpp:429]     Test net output #0: loss = 0.215835 (* 1 = 0.215835 loss)
I0502 11:42:52.288465 26473 solver.cpp:242] Iteration 199000 (93.6775 iter/s, 1.06749s/100 iter), loss = 0.178971
I0502 11:42:52.288485 26473 solver.cpp:261]     Train net output #0: loss = 0.178971 (* 1 = 0.178971 loss)
I0502 11:42:52.288492 26473 sgd_solver.cpp:106] Iteration 199000, lr = 1.44115e-06
I0502 11:42:52.290118 26473 solver.cpp:362] Iteration 199000, Testing net (#0)
I0502 11:42:52.290130 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:52.420878 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9555
I0502 11:42:52.420899 26473 solver.cpp:429]     Test net output #1: loss = 0.0930125 (* 1 = 0.0930125 loss)
I0502 11:42:52.423826 26473 solver.cpp:242] Iteration 199000 (83.4738 iter/s, 1.19798s/100 iter), loss = 0.090911
I0502 11:42:52.423846 26473 solver.cpp:261]     Train net output #0: loss = 0.090911 (* 1 = 0.090911 loss)
I0502 11:42:52.423854 26473 sgd_solver.cpp:106] Iteration 199000, lr = 1.44115e-06
I0502 11:42:53.363410 26473 solver.cpp:242] Iteration 199100 (93.0324 iter/s, 1.07489s/100 iter), loss = 0.247647
I0502 11:42:53.363448 26473 solver.cpp:261]     Train net output #0: loss = 0.247647 (* 1 = 0.247647 loss)
I0502 11:42:53.363457 26473 sgd_solver.cpp:106] Iteration 199100, lr = 1.44115e-06
I0502 11:42:53.368245 26473 solver.cpp:242] Iteration 199100 (105.889 iter/s, 0.944381s/100 iter), loss = 0.103649
I0502 11:42:53.368268 26473 solver.cpp:261]     Train net output #0: loss = 0.103649 (* 1 = 0.103649 loss)
I0502 11:42:53.368278 26473 sgd_solver.cpp:106] Iteration 199100, lr = 1.44115e-06
I0502 11:42:54.306546 26473 solver.cpp:242] Iteration 199200 (106.037 iter/s, 0.943071s/100 iter), loss = 0.0799915
I0502 11:42:54.306581 26473 solver.cpp:261]     Train net output #0: loss = 0.0799915 (* 1 = 0.0799915 loss)
I0502 11:42:54.306589 26473 sgd_solver.cpp:106] Iteration 199200, lr = 1.44115e-06
I0502 11:42:54.311350 26473 solver.cpp:242] Iteration 199200 (106.037 iter/s, 0.943064s/100 iter), loss = 0.0356546
I0502 11:42:54.311373 26473 solver.cpp:261]     Train net output #0: loss = 0.0356546 (* 1 = 0.0356546 loss)
I0502 11:42:54.311381 26473 sgd_solver.cpp:106] Iteration 199200, lr = 1.44115e-06
I0502 11:42:55.251714 26473 solver.cpp:242] Iteration 199300 (105.808 iter/s, 0.945107s/100 iter), loss = 0.165601
I0502 11:42:55.251752 26473 solver.cpp:261]     Train net output #0: loss = 0.165601 (* 1 = 0.165601 loss)
I0502 11:42:55.251761 26473 sgd_solver.cpp:106] Iteration 199300, lr = 1.44115e-06
I0502 11:42:55.256510 26473 solver.cpp:242] Iteration 199300 (105.807 iter/s, 0.945118s/100 iter), loss = 0.0948626
I0502 11:42:55.256533 26473 solver.cpp:261]     Train net output #0: loss = 0.0948626 (* 1 = 0.0948626 loss)
I0502 11:42:55.256541 26473 sgd_solver.cpp:106] Iteration 199300, lr = 1.44115e-06
I0502 11:42:56.195399 26473 solver.cpp:242] Iteration 199400 (105.974 iter/s, 0.943624s/100 iter), loss = 0.0750242
I0502 11:42:56.195432 26473 solver.cpp:261]     Train net output #0: loss = 0.0750242 (* 1 = 0.0750242 loss)
I0502 11:42:56.195441 26473 sgd_solver.cpp:106] Iteration 199400, lr = 1.44115e-06
I0502 11:42:56.200265 26473 solver.cpp:242] Iteration 199400 (105.965 iter/s, 0.943706s/100 iter), loss = 0.0666657
I0502 11:42:56.200289 26473 solver.cpp:261]     Train net output #0: loss = 0.0666657 (* 1 = 0.0666657 loss)
I0502 11:42:56.200297 26473 sgd_solver.cpp:106] Iteration 199400, lr = 1.44115e-06
I0502 11:42:57.135807 26473 solver.cpp:362] Iteration 199500, Testing net (#0)
I0502 11:42:57.135826 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:57.260188 26473 solver.cpp:429]     Test net output #0: loss = 0.222204 (* 1 = 0.222204 loss)
I0502 11:42:57.263056 26473 solver.cpp:242] Iteration 199500 (93.6677 iter/s, 1.0676s/100 iter), loss = 0.0733481
I0502 11:42:57.263075 26473 solver.cpp:261]     Train net output #0: loss = 0.0733481 (* 1 = 0.0733481 loss)
I0502 11:42:57.263083 26473 sgd_solver.cpp:106] Iteration 199500, lr = 1.44115e-06
I0502 11:42:57.264722 26473 solver.cpp:362] Iteration 199500, Testing net (#0)
I0502 11:42:57.264735 26473 net.cpp:723] Ignoring source layer parameters
I0502 11:42:57.395330 26473 solver.cpp:429]     Test net output #0: accuracy = 0.9625
I0502 11:42:57.395354 26473 solver.cpp:429]     Test net output #1: loss = 0.0845889 (* 1 = 0.0845889 loss)
I0502 11:42:57.398288 26473 solver.cpp:242] Iteration 199500 (83.474 iter/s, 1.19798s/100 iter), loss = 0.00474668
I0502 11:42:57.398308 26473 solver.cpp:261]     Train net output #0: loss = 0.00474668 (* 1 = 0.00474668 loss)
I0502 11:42:57.398316 26473 sgd_solver.cpp:106] Iteration 199500, lr = 1.44115e-06
I0502 11:42:58.337636 26473 solver.cpp:242] Iteration 199600 (93.0642 iter/s, 1.07453s/100 iter), loss = 0.114018
I0502 11:42:58.337682 26473 solver.cpp:261]     Train net output #0: loss = 0.114018 (* 1 = 0.114018 loss)
I0502 11:42:58.337690 26473 sgd_solver.cpp:106] Iteration 199600, lr = 1.44115e-06
I0502 11:42:58.342484 26473 solver.cpp:242] Iteration 199600 (105.915 iter/s, 0.944158s/100 iter), loss = 0.0620984
I0502 11:42:58.342509 26473 solver.cpp:261]     Train net output #0: loss = 0.0620984 (* 1 = 0.0620984 loss)
I0502 11:42:58.342517 26473 sgd_solver.cpp:106] Iteration 199600, lr = 1.44115e-06
I0502 11:42:59.281131 26473 solver.cpp:242] Iteration 199700 (105.997 iter/s, 0.94342s/100 iter), loss = 0.181699
I0502 11:42:59.281173 26473 solver.cpp:261]     Train net output #0: loss = 0.181699 (* 1 = 0.181699 loss)
I0502 11:42:59.281183 26473 sgd_solver.cpp:106] Iteration 199700, lr = 1.44115e-06
I0502 11:42:59.285961 26473 solver.cpp:242] Iteration 199700 (105.996 iter/s, 0.943436s/100 iter), loss = 0.132171
I0502 11:42:59.285985 26473 solver.cpp:261]     Train net output #0: loss = 0.132171 (* 1 = 0.132171 loss)
I0502 11:42:59.285993 26473 sgd_solver.cpp:106] Iteration 199700, lr = 1.44115e-06
I0502 11:43:00.236860 26473 solver.cpp:242] Iteration 199800 (104.64 iter/s, 0.955656s/100 iter), loss = 0.09942
I0502 11:43:00.236908 26473 solver.cpp:261]     Train net output #0: loss = 0.09942 (* 1 = 0.09942 loss)
I0502 11:43:00.236918 26473 sgd_solver.cpp:106] Iteration 199800, lr = 1.44115e-06
I0502 11:43:00.241720 26473 solver.cpp:242] Iteration 199800 (104.634 iter/s, 0.955717s/100 iter), loss = 0.232713
I0502 11:43:00.241744 26473 solver.cpp:261]     Train net output #0: loss = 0.232713 (* 1 = 0.232713 loss)
I0502 11:43:00.241753 26473 sgd_solver.cpp:106] Iteration 199800, lr = 1.44115e-06
I0502 11:43:01.190697 26473 solver.cpp:242] Iteration 199900 (104.848 iter/s, 0.953764s/100 iter), loss = 0.0935
I0502 11:43:01.190744 26473 solver.cpp:261]     Train net output #0: loss = 0.0935 (* 1 = 0.0935 loss)
I0502 11:43:01.190753 26473 sgd_solver.cpp:106] Iteration 199900, lr = 1.44115e-06
I0502 11:43:01.195641 26473 solver.cpp:242] Iteration 199900 (104.836 iter/s, 0.953868s/100 iter), loss = 0.12163
I0502 11:43:01.195667 26473 solver.cpp:261]     Train net output #0: loss = 0.12163 (* 1 = 0.12163 loss)
I0502 11:43:01.195686 26473 sgd_solver.cpp:106] Iteration 199900, lr = 1.44115e-06
I0502 11:43:02.125442 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_200000.caffemodel
I0502 11:43:02.129724 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_200000.solverstate
I0502 11:43:02.136608 26473 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_200000.caffemodel
I0502 11:43:02.140789 26473 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/20_dis_400_dim/huber_10_conv_k5_p2_64_64_max_k5_p2_64_64_64_ave_fc_64_64_share_5_layers_20_400_joint_1002_gpu1/_iter_200000.solverstate
