joint
huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0506 04:29:00.205992 12834 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 200000
lr_policy: "step"
gamma: 0.8
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 50000
snapshot_prefix: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/"
solver_mode: CPU
net: "./protocol/dis_50_100_dimension.protocol_parameter"
I0506 04:29:00.206094 12834 solver.cpp:91] Creating training net from net file: ./protocol/dis_50_100_dimension.protocol_parameter
I0506 04:29:00.206419 12834 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer intercept
I0506 04:29:00.206437 12834 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss
I0506 04:29:00.206518 12834 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "parameters"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_train-parameters-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HuberLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I0506 04:29:00.206578 12834 layer_factory.hpp:77] Creating layer parameters
I0506 04:29:00.206595 12834 net.cpp:94] Creating Layer parameters
I0506 04:29:00.206600 12834 net.cpp:409] parameters -> data
I0506 04:29:00.206609 12834 net.cpp:409] parameters -> label
I0506 04:29:00.206616 12834 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_train-parameters-path.txt
I0506 04:29:00.206632 12834 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0506 04:29:00.207271 12834 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0506 04:29:00.381638 12834 net.cpp:144] Setting up parameters
I0506 04:29:00.381671 12834 net.cpp:151] Top shape: 20 1 10 10 (2000)
I0506 04:29:00.381676 12834 net.cpp:151] Top shape: 20 (20)
I0506 04:29:00.381680 12834 net.cpp:159] Memory required for data: 8080
I0506 04:29:00.381686 12834 layer_factory.hpp:77] Creating layer conv1
I0506 04:29:00.381703 12834 net.cpp:94] Creating Layer conv1
I0506 04:29:00.381707 12834 net.cpp:435] conv1 <- data
I0506 04:29:00.381714 12834 net.cpp:409] conv1 -> conv1
I0506 04:29:00.385872 12834 net.cpp:144] Setting up conv1
I0506 04:29:00.385888 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.385893 12834 net.cpp:159] Memory required for data: 520080
I0506 04:29:00.385903 12834 layer_factory.hpp:77] Creating layer relu1
I0506 04:29:00.385911 12834 net.cpp:94] Creating Layer relu1
I0506 04:29:00.385915 12834 net.cpp:435] relu1 <- conv1
I0506 04:29:00.385920 12834 net.cpp:396] relu1 -> conv1 (in-place)
I0506 04:29:00.385927 12834 net.cpp:144] Setting up relu1
I0506 04:29:00.385932 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.385936 12834 net.cpp:159] Memory required for data: 1032080
I0506 04:29:00.385938 12834 layer_factory.hpp:77] Creating layer conv2
I0506 04:29:00.385946 12834 net.cpp:94] Creating Layer conv2
I0506 04:29:00.385949 12834 net.cpp:435] conv2 <- conv1
I0506 04:29:00.385954 12834 net.cpp:409] conv2 -> conv2
I0506 04:29:00.391911 12834 net.cpp:144] Setting up conv2
I0506 04:29:00.391926 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.391928 12834 net.cpp:159] Memory required for data: 1544080
I0506 04:29:00.391937 12834 layer_factory.hpp:77] Creating layer relu2
I0506 04:29:00.391944 12834 net.cpp:94] Creating Layer relu2
I0506 04:29:00.391948 12834 net.cpp:435] relu2 <- conv2
I0506 04:29:00.391952 12834 net.cpp:396] relu2 -> conv2 (in-place)
I0506 04:29:00.391959 12834 net.cpp:144] Setting up relu2
I0506 04:29:00.391964 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.391968 12834 net.cpp:159] Memory required for data: 2056080
I0506 04:29:00.391969 12834 layer_factory.hpp:77] Creating layer pool2
I0506 04:29:00.391976 12834 net.cpp:94] Creating Layer pool2
I0506 04:29:00.391979 12834 net.cpp:435] pool2 <- conv2
I0506 04:29:00.391983 12834 net.cpp:409] pool2 -> pool2
I0506 04:29:00.392043 12834 net.cpp:144] Setting up pool2
I0506 04:29:00.392051 12834 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0506 04:29:00.392055 12834 net.cpp:159] Memory required for data: 2184080
I0506 04:29:00.392058 12834 layer_factory.hpp:77] Creating layer conv3
I0506 04:29:00.392066 12834 net.cpp:94] Creating Layer conv3
I0506 04:29:00.392076 12834 net.cpp:435] conv3 <- pool2
I0506 04:29:00.392081 12834 net.cpp:409] conv3 -> conv3
I0506 04:29:00.400187 12834 net.cpp:144] Setting up conv3
I0506 04:29:00.400199 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.400203 12834 net.cpp:159] Memory required for data: 2440080
I0506 04:29:00.400213 12834 layer_factory.hpp:77] Creating layer relu3
I0506 04:29:00.400218 12834 net.cpp:94] Creating Layer relu3
I0506 04:29:00.400221 12834 net.cpp:435] relu3 <- conv3
I0506 04:29:00.400226 12834 net.cpp:396] relu3 -> conv3 (in-place)
I0506 04:29:00.400233 12834 net.cpp:144] Setting up relu3
I0506 04:29:00.400238 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.400240 12834 net.cpp:159] Memory required for data: 2696080
I0506 04:29:00.400243 12834 layer_factory.hpp:77] Creating layer conv4
I0506 04:29:00.400251 12834 net.cpp:94] Creating Layer conv4
I0506 04:29:00.400255 12834 net.cpp:435] conv4 <- conv3
I0506 04:29:00.400260 12834 net.cpp:409] conv4 -> conv4
I0506 04:29:00.415105 12834 net.cpp:144] Setting up conv4
I0506 04:29:00.415120 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.415124 12834 net.cpp:159] Memory required for data: 2952080
I0506 04:29:00.415130 12834 layer_factory.hpp:77] Creating layer relu4
I0506 04:29:00.415136 12834 net.cpp:94] Creating Layer relu4
I0506 04:29:00.415140 12834 net.cpp:435] relu4 <- conv4
I0506 04:29:00.415145 12834 net.cpp:396] relu4 -> conv4 (in-place)
I0506 04:29:00.415153 12834 net.cpp:144] Setting up relu4
I0506 04:29:00.415156 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.415159 12834 net.cpp:159] Memory required for data: 3208080
I0506 04:29:00.415163 12834 layer_factory.hpp:77] Creating layer conv5
I0506 04:29:00.415170 12834 net.cpp:94] Creating Layer conv5
I0506 04:29:00.415174 12834 net.cpp:435] conv5 <- conv4
I0506 04:29:00.415179 12834 net.cpp:409] conv5 -> conv5
I0506 04:29:00.429426 12834 net.cpp:144] Setting up conv5
I0506 04:29:00.429441 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.429445 12834 net.cpp:159] Memory required for data: 3464080
I0506 04:29:00.429455 12834 layer_factory.hpp:77] Creating layer relu5
I0506 04:29:00.429461 12834 net.cpp:94] Creating Layer relu5
I0506 04:29:00.429463 12834 net.cpp:435] relu5 <- conv5
I0506 04:29:00.429468 12834 net.cpp:396] relu5 -> conv5 (in-place)
I0506 04:29:00.429476 12834 net.cpp:144] Setting up relu5
I0506 04:29:00.429481 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.429483 12834 net.cpp:159] Memory required for data: 3720080
I0506 04:29:00.429486 12834 layer_factory.hpp:77] Creating layer pool5
I0506 04:29:00.429491 12834 net.cpp:94] Creating Layer pool5
I0506 04:29:00.429494 12834 net.cpp:435] pool5 <- conv5
I0506 04:29:00.429498 12834 net.cpp:409] pool5 -> pool5
I0506 04:29:00.429539 12834 net.cpp:144] Setting up pool5
I0506 04:29:00.429548 12834 net.cpp:151] Top shape: 20 128 2 2 (10240)
I0506 04:29:00.429550 12834 net.cpp:159] Memory required for data: 3761040
I0506 04:29:00.429553 12834 layer_factory.hpp:77] Creating layer ip1
I0506 04:29:00.429563 12834 net.cpp:94] Creating Layer ip1
I0506 04:29:00.429566 12834 net.cpp:435] ip1 <- pool5
I0506 04:29:00.429572 12834 net.cpp:409] ip1 -> ip1
I0506 04:29:00.443809 12834 net.cpp:144] Setting up ip1
I0506 04:29:00.443822 12834 net.cpp:151] Top shape: 20 1024 (20480)
I0506 04:29:00.443826 12834 net.cpp:159] Memory required for data: 3842960
I0506 04:29:00.443832 12834 layer_factory.hpp:77] Creating layer ip2
I0506 04:29:00.443840 12834 net.cpp:94] Creating Layer ip2
I0506 04:29:00.443845 12834 net.cpp:435] ip2 <- ip1
I0506 04:29:00.443850 12834 net.cpp:409] ip2 -> ip2
I0506 04:29:00.457237 12834 net.cpp:144] Setting up ip2
I0506 04:29:00.457249 12834 net.cpp:151] Top shape: 20 512 (10240)
I0506 04:29:00.457253 12834 net.cpp:159] Memory required for data: 3883920
I0506 04:29:00.457259 12834 layer_factory.hpp:77] Creating layer ip3
I0506 04:29:00.457267 12834 net.cpp:94] Creating Layer ip3
I0506 04:29:00.457269 12834 net.cpp:435] ip3 <- ip2
I0506 04:29:00.457281 12834 net.cpp:409] ip3 -> ip3
I0506 04:29:00.457403 12834 net.cpp:144] Setting up ip3
I0506 04:29:00.457412 12834 net.cpp:151] Top shape: 20 1 (20)
I0506 04:29:00.457414 12834 net.cpp:159] Memory required for data: 3884000
I0506 04:29:00.457420 12834 layer_factory.hpp:77] Creating layer loss
I0506 04:29:00.457432 12834 net.cpp:94] Creating Layer loss
I0506 04:29:00.457437 12834 net.cpp:435] loss <- ip3
I0506 04:29:00.457440 12834 net.cpp:435] loss <- label
I0506 04:29:00.457444 12834 net.cpp:409] loss -> loss
I0506 04:29:00.457499 12834 net.cpp:144] Setting up loss
I0506 04:29:00.457505 12834 net.cpp:151] Top shape: (1)
I0506 04:29:00.457509 12834 net.cpp:154]     with loss weight 1
I0506 04:29:00.457517 12834 net.cpp:159] Memory required for data: 3884004
I0506 04:29:00.457521 12834 net.cpp:220] loss needs backward computation.
I0506 04:29:00.457525 12834 net.cpp:220] ip3 needs backward computation.
I0506 04:29:00.457527 12834 net.cpp:220] ip2 needs backward computation.
I0506 04:29:00.457531 12834 net.cpp:220] ip1 needs backward computation.
I0506 04:29:00.457535 12834 net.cpp:220] pool5 needs backward computation.
I0506 04:29:00.457537 12834 net.cpp:220] relu5 needs backward computation.
I0506 04:29:00.457540 12834 net.cpp:220] conv5 needs backward computation.
I0506 04:29:00.457543 12834 net.cpp:220] relu4 needs backward computation.
I0506 04:29:00.457546 12834 net.cpp:220] conv4 needs backward computation.
I0506 04:29:00.457550 12834 net.cpp:220] relu3 needs backward computation.
I0506 04:29:00.457552 12834 net.cpp:220] conv3 needs backward computation.
I0506 04:29:00.457556 12834 net.cpp:220] pool2 needs backward computation.
I0506 04:29:00.457559 12834 net.cpp:220] relu2 needs backward computation.
I0506 04:29:00.457562 12834 net.cpp:220] conv2 needs backward computation.
I0506 04:29:00.457566 12834 net.cpp:220] relu1 needs backward computation.
I0506 04:29:00.457568 12834 net.cpp:220] conv1 needs backward computation.
I0506 04:29:00.457571 12834 net.cpp:222] parameters does not need backward computation.
I0506 04:29:00.457574 12834 net.cpp:264] This network produces output loss
I0506 04:29:00.457586 12834 net.cpp:284] Network initialization done.
I0506 04:29:00.457919 12834 solver.cpp:181] Creating test net (#0) specified by net file: ./protocol/dis_50_100_dimension.protocol_parameter
I0506 04:29:00.457947 12834 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer parameters
I0506 04:29:00.457960 12834 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0506 04:29:00.458045 12834 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "intercept"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_test-parameters-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HuberLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
  include {
    phase: TEST
  }
}
I0506 04:29:00.458096 12834 layer_factory.hpp:77] Creating layer intercept
I0506 04:29:00.458104 12834 net.cpp:94] Creating Layer intercept
I0506 04:29:00.458107 12834 net.cpp:409] intercept -> data
I0506 04:29:00.458114 12834 net.cpp:409] intercept -> label
I0506 04:29:00.458120 12834 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_test-parameters-path.txt
I0506 04:29:00.458140 12834 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0506 04:29:00.498970 12834 net.cpp:144] Setting up intercept
I0506 04:29:00.499001 12834 net.cpp:151] Top shape: 20 1 10 10 (2000)
I0506 04:29:00.499006 12834 net.cpp:151] Top shape: 20 (20)
I0506 04:29:00.499009 12834 net.cpp:159] Memory required for data: 8080
I0506 04:29:00.499017 12834 layer_factory.hpp:77] Creating layer conv1
I0506 04:29:00.499032 12834 net.cpp:94] Creating Layer conv1
I0506 04:29:00.499037 12834 net.cpp:435] conv1 <- data
I0506 04:29:00.499043 12834 net.cpp:409] conv1 -> conv1
I0506 04:29:00.499855 12834 net.cpp:144] Setting up conv1
I0506 04:29:00.499869 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.499872 12834 net.cpp:159] Memory required for data: 520080
I0506 04:29:00.499882 12834 layer_factory.hpp:77] Creating layer relu1
I0506 04:29:00.499891 12834 net.cpp:94] Creating Layer relu1
I0506 04:29:00.499894 12834 net.cpp:435] relu1 <- conv1
I0506 04:29:00.499898 12834 net.cpp:396] relu1 -> conv1 (in-place)
I0506 04:29:00.499905 12834 net.cpp:144] Setting up relu1
I0506 04:29:00.499910 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.499913 12834 net.cpp:159] Memory required for data: 1032080
I0506 04:29:00.499917 12834 layer_factory.hpp:77] Creating layer conv2
I0506 04:29:00.499932 12834 net.cpp:94] Creating Layer conv2
I0506 04:29:00.499935 12834 net.cpp:435] conv2 <- conv1
I0506 04:29:00.499940 12834 net.cpp:409] conv2 -> conv2
I0506 04:29:00.504001 12834 net.cpp:144] Setting up conv2
I0506 04:29:00.504014 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.504019 12834 net.cpp:159] Memory required for data: 1544080
I0506 04:29:00.504026 12834 layer_factory.hpp:77] Creating layer relu2
I0506 04:29:00.504034 12834 net.cpp:94] Creating Layer relu2
I0506 04:29:00.504036 12834 net.cpp:435] relu2 <- conv2
I0506 04:29:00.504041 12834 net.cpp:396] relu2 -> conv2 (in-place)
I0506 04:29:00.504047 12834 net.cpp:144] Setting up relu2
I0506 04:29:00.504052 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.504055 12834 net.cpp:159] Memory required for data: 2056080
I0506 04:29:00.504057 12834 layer_factory.hpp:77] Creating layer pool2
I0506 04:29:00.504063 12834 net.cpp:94] Creating Layer pool2
I0506 04:29:00.504066 12834 net.cpp:435] pool2 <- conv2
I0506 04:29:00.504072 12834 net.cpp:409] pool2 -> pool2
I0506 04:29:00.504130 12834 net.cpp:144] Setting up pool2
I0506 04:29:00.504138 12834 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0506 04:29:00.504142 12834 net.cpp:159] Memory required for data: 2184080
I0506 04:29:00.504144 12834 layer_factory.hpp:77] Creating layer conv3
I0506 04:29:00.504153 12834 net.cpp:94] Creating Layer conv3
I0506 04:29:00.504156 12834 net.cpp:435] conv3 <- pool2
I0506 04:29:00.504164 12834 net.cpp:409] conv3 -> conv3
I0506 04:29:00.510591 12834 net.cpp:144] Setting up conv3
I0506 04:29:00.510603 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.510607 12834 net.cpp:159] Memory required for data: 2440080
I0506 04:29:00.510615 12834 layer_factory.hpp:77] Creating layer relu3
I0506 04:29:00.510620 12834 net.cpp:94] Creating Layer relu3
I0506 04:29:00.510624 12834 net.cpp:435] relu3 <- conv3
I0506 04:29:00.510630 12834 net.cpp:396] relu3 -> conv3 (in-place)
I0506 04:29:00.510637 12834 net.cpp:144] Setting up relu3
I0506 04:29:00.510641 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.510644 12834 net.cpp:159] Memory required for data: 2696080
I0506 04:29:00.510648 12834 layer_factory.hpp:77] Creating layer conv4
I0506 04:29:00.510656 12834 net.cpp:94] Creating Layer conv4
I0506 04:29:00.510659 12834 net.cpp:435] conv4 <- conv3
I0506 04:29:00.510665 12834 net.cpp:409] conv4 -> conv4
I0506 04:29:00.523020 12834 net.cpp:144] Setting up conv4
I0506 04:29:00.523033 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.523037 12834 net.cpp:159] Memory required for data: 2952080
I0506 04:29:00.523044 12834 layer_factory.hpp:77] Creating layer relu4
I0506 04:29:00.523049 12834 net.cpp:94] Creating Layer relu4
I0506 04:29:00.523053 12834 net.cpp:435] relu4 <- conv4
I0506 04:29:00.523057 12834 net.cpp:396] relu4 -> conv4 (in-place)
I0506 04:29:00.523064 12834 net.cpp:144] Setting up relu4
I0506 04:29:00.523068 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.523072 12834 net.cpp:159] Memory required for data: 3208080
I0506 04:29:00.523074 12834 layer_factory.hpp:77] Creating layer conv5
I0506 04:29:00.523083 12834 net.cpp:94] Creating Layer conv5
I0506 04:29:00.523087 12834 net.cpp:435] conv5 <- conv4
I0506 04:29:00.523092 12834 net.cpp:409] conv5 -> conv5
I0506 04:29:00.535426 12834 net.cpp:144] Setting up conv5
I0506 04:29:00.535439 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.535444 12834 net.cpp:159] Memory required for data: 3464080
I0506 04:29:00.535452 12834 layer_factory.hpp:77] Creating layer relu5
I0506 04:29:00.535459 12834 net.cpp:94] Creating Layer relu5
I0506 04:29:00.535464 12834 net.cpp:435] relu5 <- conv5
I0506 04:29:00.535467 12834 net.cpp:396] relu5 -> conv5 (in-place)
I0506 04:29:00.535473 12834 net.cpp:144] Setting up relu5
I0506 04:29:00.535478 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.535481 12834 net.cpp:159] Memory required for data: 3720080
I0506 04:29:00.535485 12834 layer_factory.hpp:77] Creating layer pool5
I0506 04:29:00.535490 12834 net.cpp:94] Creating Layer pool5
I0506 04:29:00.535500 12834 net.cpp:435] pool5 <- conv5
I0506 04:29:00.535504 12834 net.cpp:409] pool5 -> pool5
I0506 04:29:00.535545 12834 net.cpp:144] Setting up pool5
I0506 04:29:00.535553 12834 net.cpp:151] Top shape: 20 128 2 2 (10240)
I0506 04:29:00.535557 12834 net.cpp:159] Memory required for data: 3761040
I0506 04:29:00.535559 12834 layer_factory.hpp:77] Creating layer ip1
I0506 04:29:00.535565 12834 net.cpp:94] Creating Layer ip1
I0506 04:29:00.535568 12834 net.cpp:435] ip1 <- pool5
I0506 04:29:00.535574 12834 net.cpp:409] ip1 -> ip1
I0506 04:29:00.548662 12834 net.cpp:144] Setting up ip1
I0506 04:29:00.548676 12834 net.cpp:151] Top shape: 20 1024 (20480)
I0506 04:29:00.548679 12834 net.cpp:159] Memory required for data: 3842960
I0506 04:29:00.548686 12834 layer_factory.hpp:77] Creating layer ip2
I0506 04:29:00.548694 12834 net.cpp:94] Creating Layer ip2
I0506 04:29:00.548697 12834 net.cpp:435] ip2 <- ip1
I0506 04:29:00.548703 12834 net.cpp:409] ip2 -> ip2
I0506 04:29:00.561812 12834 net.cpp:144] Setting up ip2
I0506 04:29:00.561826 12834 net.cpp:151] Top shape: 20 512 (10240)
I0506 04:29:00.561830 12834 net.cpp:159] Memory required for data: 3883920
I0506 04:29:00.561836 12834 layer_factory.hpp:77] Creating layer ip3
I0506 04:29:00.561844 12834 net.cpp:94] Creating Layer ip3
I0506 04:29:00.561847 12834 net.cpp:435] ip3 <- ip2
I0506 04:29:00.561853 12834 net.cpp:409] ip3 -> ip3
I0506 04:29:00.561985 12834 net.cpp:144] Setting up ip3
I0506 04:29:00.561992 12834 net.cpp:151] Top shape: 20 1 (20)
I0506 04:29:00.561995 12834 net.cpp:159] Memory required for data: 3884000
I0506 04:29:00.562000 12834 layer_factory.hpp:77] Creating layer loss
I0506 04:29:00.562011 12834 net.cpp:94] Creating Layer loss
I0506 04:29:00.562014 12834 net.cpp:435] loss <- ip3
I0506 04:29:00.562017 12834 net.cpp:435] loss <- label
I0506 04:29:00.562022 12834 net.cpp:409] loss -> loss
I0506 04:29:00.562081 12834 net.cpp:144] Setting up loss
I0506 04:29:00.562088 12834 net.cpp:151] Top shape: (1)
I0506 04:29:00.562091 12834 net.cpp:154]     with loss weight 1
I0506 04:29:00.562100 12834 net.cpp:159] Memory required for data: 3884004
I0506 04:29:00.562104 12834 net.cpp:220] loss needs backward computation.
I0506 04:29:00.562108 12834 net.cpp:220] ip3 needs backward computation.
I0506 04:29:00.562111 12834 net.cpp:220] ip2 needs backward computation.
I0506 04:29:00.562114 12834 net.cpp:220] ip1 needs backward computation.
I0506 04:29:00.562117 12834 net.cpp:220] pool5 needs backward computation.
I0506 04:29:00.562120 12834 net.cpp:220] relu5 needs backward computation.
I0506 04:29:00.562124 12834 net.cpp:220] conv5 needs backward computation.
I0506 04:29:00.562126 12834 net.cpp:220] relu4 needs backward computation.
I0506 04:29:00.562129 12834 net.cpp:220] conv4 needs backward computation.
I0506 04:29:00.562132 12834 net.cpp:220] relu3 needs backward computation.
I0506 04:29:00.562135 12834 net.cpp:220] conv3 needs backward computation.
I0506 04:29:00.562139 12834 net.cpp:220] pool2 needs backward computation.
I0506 04:29:00.562141 12834 net.cpp:220] relu2 needs backward computation.
I0506 04:29:00.562144 12834 net.cpp:220] conv2 needs backward computation.
I0506 04:29:00.562147 12834 net.cpp:220] relu1 needs backward computation.
I0506 04:29:00.562150 12834 net.cpp:220] conv1 needs backward computation.
I0506 04:29:00.562153 12834 net.cpp:222] intercept does not need backward computation.
I0506 04:29:00.562156 12834 net.cpp:264] This network produces output loss
I0506 04:29:00.562167 12834 net.cpp:284] Network initialization done.
I0506 04:29:00.562227 12834 solver.cpp:60] Solver scaffolding done.
I0506 04:29:00.562999 12834 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 200000
lr_policy: "step"
gamma: 0.8
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 50000
snapshot_prefix: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/"
solver_mode: CPU
net: "./protocol/dis_50_100_dimension.protocol_distribution"
I0506 04:29:00.563062 12834 solver.cpp:91] Creating training net from net file: ./protocol/dis_50_100_dimension.protocol_distribution
I0506 04:29:00.563359 12834 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer intercept
I0506 04:29:00.563374 12834 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0506 04:29:00.563459 12834 net.cpp:52] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "parameters"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_train-distributions-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0506 04:29:00.563511 12834 layer_factory.hpp:77] Creating layer parameters
I0506 04:29:00.563519 12834 net.cpp:94] Creating Layer parameters
I0506 04:29:00.563524 12834 net.cpp:409] parameters -> data
I0506 04:29:00.563530 12834 net.cpp:409] parameters -> label
I0506 04:29:00.563536 12834 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_train-distributions-path.txt
I0506 04:29:00.563552 12834 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0506 04:29:00.718542 12834 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0506 04:29:00.721762 12834 net.cpp:144] Setting up parameters
I0506 04:29:00.721787 12834 net.cpp:151] Top shape: 20 1 10 10 (2000)
I0506 04:29:00.721792 12834 net.cpp:151] Top shape: 20 (20)
I0506 04:29:00.721796 12834 net.cpp:159] Memory required for data: 8080
I0506 04:29:00.721801 12834 layer_factory.hpp:77] Creating layer conv1
I0506 04:29:00.721819 12834 net.cpp:94] Creating Layer conv1
I0506 04:29:00.721823 12834 net.cpp:435] conv1 <- data
I0506 04:29:00.721829 12834 net.cpp:409] conv1 -> conv1
I0506 04:29:00.723526 12834 net.cpp:144] Setting up conv1
I0506 04:29:00.723538 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.723542 12834 net.cpp:159] Memory required for data: 520080
I0506 04:29:00.723552 12834 layer_factory.hpp:77] Creating layer relu1
I0506 04:29:00.723561 12834 net.cpp:94] Creating Layer relu1
I0506 04:29:00.723564 12834 net.cpp:435] relu1 <- conv1
I0506 04:29:00.723568 12834 net.cpp:396] relu1 -> conv1 (in-place)
I0506 04:29:00.723575 12834 net.cpp:144] Setting up relu1
I0506 04:29:00.723580 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.723583 12834 net.cpp:159] Memory required for data: 1032080
I0506 04:29:00.723587 12834 layer_factory.hpp:77] Creating layer conv2
I0506 04:29:00.723593 12834 net.cpp:94] Creating Layer conv2
I0506 04:29:00.723597 12834 net.cpp:435] conv2 <- conv1
I0506 04:29:00.723601 12834 net.cpp:409] conv2 -> conv2
I0506 04:29:00.728875 12834 net.cpp:144] Setting up conv2
I0506 04:29:00.728888 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.728893 12834 net.cpp:159] Memory required for data: 1544080
I0506 04:29:00.728900 12834 layer_factory.hpp:77] Creating layer relu2
I0506 04:29:00.728907 12834 net.cpp:94] Creating Layer relu2
I0506 04:29:00.728910 12834 net.cpp:435] relu2 <- conv2
I0506 04:29:00.728915 12834 net.cpp:396] relu2 -> conv2 (in-place)
I0506 04:29:00.728921 12834 net.cpp:144] Setting up relu2
I0506 04:29:00.728926 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.728929 12834 net.cpp:159] Memory required for data: 2056080
I0506 04:29:00.728932 12834 layer_factory.hpp:77] Creating layer pool2
I0506 04:29:00.728938 12834 net.cpp:94] Creating Layer pool2
I0506 04:29:00.728940 12834 net.cpp:435] pool2 <- conv2
I0506 04:29:00.728945 12834 net.cpp:409] pool2 -> pool2
I0506 04:29:00.729001 12834 net.cpp:144] Setting up pool2
I0506 04:29:00.729010 12834 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0506 04:29:00.729013 12834 net.cpp:159] Memory required for data: 2184080
I0506 04:29:00.729017 12834 layer_factory.hpp:77] Creating layer conv3
I0506 04:29:00.729024 12834 net.cpp:94] Creating Layer conv3
I0506 04:29:00.729028 12834 net.cpp:435] conv3 <- pool2
I0506 04:29:00.729033 12834 net.cpp:409] conv3 -> conv3
I0506 04:29:00.737607 12834 net.cpp:144] Setting up conv3
I0506 04:29:00.737620 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.737624 12834 net.cpp:159] Memory required for data: 2440080
I0506 04:29:00.737633 12834 layer_factory.hpp:77] Creating layer relu3
I0506 04:29:00.737638 12834 net.cpp:94] Creating Layer relu3
I0506 04:29:00.737643 12834 net.cpp:435] relu3 <- conv3
I0506 04:29:00.737646 12834 net.cpp:396] relu3 -> conv3 (in-place)
I0506 04:29:00.737659 12834 net.cpp:144] Setting up relu3
I0506 04:29:00.737664 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.737668 12834 net.cpp:159] Memory required for data: 2696080
I0506 04:29:00.737670 12834 layer_factory.hpp:77] Creating layer conv4
I0506 04:29:00.737679 12834 net.cpp:94] Creating Layer conv4
I0506 04:29:00.737682 12834 net.cpp:435] conv4 <- conv3
I0506 04:29:00.737687 12834 net.cpp:409] conv4 -> conv4
I0506 04:29:00.752115 12834 net.cpp:144] Setting up conv4
I0506 04:29:00.752128 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.752132 12834 net.cpp:159] Memory required for data: 2952080
I0506 04:29:00.752138 12834 layer_factory.hpp:77] Creating layer relu4
I0506 04:29:00.752144 12834 net.cpp:94] Creating Layer relu4
I0506 04:29:00.752148 12834 net.cpp:435] relu4 <- conv4
I0506 04:29:00.752152 12834 net.cpp:396] relu4 -> conv4 (in-place)
I0506 04:29:00.752159 12834 net.cpp:144] Setting up relu4
I0506 04:29:00.752164 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.752167 12834 net.cpp:159] Memory required for data: 3208080
I0506 04:29:00.752171 12834 layer_factory.hpp:77] Creating layer conv5
I0506 04:29:00.752177 12834 net.cpp:94] Creating Layer conv5
I0506 04:29:00.752182 12834 net.cpp:435] conv5 <- conv4
I0506 04:29:00.752185 12834 net.cpp:409] conv5 -> conv5
I0506 04:29:00.766744 12834 net.cpp:144] Setting up conv5
I0506 04:29:00.766759 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.766763 12834 net.cpp:159] Memory required for data: 3464080
I0506 04:29:00.766772 12834 layer_factory.hpp:77] Creating layer relu5
I0506 04:29:00.766778 12834 net.cpp:94] Creating Layer relu5
I0506 04:29:00.766782 12834 net.cpp:435] relu5 <- conv5
I0506 04:29:00.766786 12834 net.cpp:396] relu5 -> conv5 (in-place)
I0506 04:29:00.766793 12834 net.cpp:144] Setting up relu5
I0506 04:29:00.766798 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.766801 12834 net.cpp:159] Memory required for data: 3720080
I0506 04:29:00.766804 12834 layer_factory.hpp:77] Creating layer pool5
I0506 04:29:00.766809 12834 net.cpp:94] Creating Layer pool5
I0506 04:29:00.766813 12834 net.cpp:435] pool5 <- conv5
I0506 04:29:00.766816 12834 net.cpp:409] pool5 -> pool5
I0506 04:29:00.766857 12834 net.cpp:144] Setting up pool5
I0506 04:29:00.766865 12834 net.cpp:151] Top shape: 20 128 2 2 (10240)
I0506 04:29:00.766868 12834 net.cpp:159] Memory required for data: 3761040
I0506 04:29:00.766871 12834 layer_factory.hpp:77] Creating layer ip1
I0506 04:29:00.766878 12834 net.cpp:94] Creating Layer ip1
I0506 04:29:00.766881 12834 net.cpp:435] ip1 <- pool5
I0506 04:29:00.766886 12834 net.cpp:409] ip1 -> ip1
I0506 04:29:00.780285 12834 net.cpp:144] Setting up ip1
I0506 04:29:00.780299 12834 net.cpp:151] Top shape: 20 1024 (20480)
I0506 04:29:00.780303 12834 net.cpp:159] Memory required for data: 3842960
I0506 04:29:00.780309 12834 layer_factory.hpp:77] Creating layer ip2
I0506 04:29:00.780316 12834 net.cpp:94] Creating Layer ip2
I0506 04:29:00.780320 12834 net.cpp:435] ip2 <- ip1
I0506 04:29:00.780325 12834 net.cpp:409] ip2 -> ip2
I0506 04:29:00.793738 12834 net.cpp:144] Setting up ip2
I0506 04:29:00.793752 12834 net.cpp:151] Top shape: 20 512 (10240)
I0506 04:29:00.793756 12834 net.cpp:159] Memory required for data: 3883920
I0506 04:29:00.793762 12834 layer_factory.hpp:77] Creating layer ip3
I0506 04:29:00.793769 12834 net.cpp:94] Creating Layer ip3
I0506 04:29:00.793773 12834 net.cpp:435] ip3 <- ip2
I0506 04:29:00.793778 12834 net.cpp:409] ip3 -> ip3
I0506 04:29:00.795320 12834 net.cpp:144] Setting up ip3
I0506 04:29:00.795332 12834 net.cpp:151] Top shape: 20 50 (1000)
I0506 04:29:00.795336 12834 net.cpp:159] Memory required for data: 3887920
I0506 04:29:00.795342 12834 layer_factory.hpp:77] Creating layer loss
I0506 04:29:00.795351 12834 net.cpp:94] Creating Layer loss
I0506 04:29:00.795353 12834 net.cpp:435] loss <- ip3
I0506 04:29:00.795357 12834 net.cpp:435] loss <- label
I0506 04:29:00.795362 12834 net.cpp:409] loss -> loss
I0506 04:29:00.795369 12834 layer_factory.hpp:77] Creating layer loss
I0506 04:29:00.795485 12834 net.cpp:144] Setting up loss
I0506 04:29:00.795491 12834 net.cpp:151] Top shape: (1)
I0506 04:29:00.795495 12834 net.cpp:154]     with loss weight 1
I0506 04:29:00.795505 12834 net.cpp:159] Memory required for data: 3887924
I0506 04:29:00.795507 12834 net.cpp:220] loss needs backward computation.
I0506 04:29:00.795511 12834 net.cpp:220] ip3 needs backward computation.
I0506 04:29:00.795514 12834 net.cpp:220] ip2 needs backward computation.
I0506 04:29:00.795517 12834 net.cpp:220] ip1 needs backward computation.
I0506 04:29:00.795521 12834 net.cpp:220] pool5 needs backward computation.
I0506 04:29:00.795523 12834 net.cpp:220] relu5 needs backward computation.
I0506 04:29:00.795526 12834 net.cpp:220] conv5 needs backward computation.
I0506 04:29:00.795531 12834 net.cpp:220] relu4 needs backward computation.
I0506 04:29:00.795533 12834 net.cpp:220] conv4 needs backward computation.
I0506 04:29:00.795536 12834 net.cpp:220] relu3 needs backward computation.
I0506 04:29:00.795539 12834 net.cpp:220] conv3 needs backward computation.
I0506 04:29:00.795543 12834 net.cpp:220] pool2 needs backward computation.
I0506 04:29:00.795547 12834 net.cpp:220] relu2 needs backward computation.
I0506 04:29:00.795549 12834 net.cpp:220] conv2 needs backward computation.
I0506 04:29:00.795552 12834 net.cpp:220] relu1 needs backward computation.
I0506 04:29:00.795555 12834 net.cpp:220] conv1 needs backward computation.
I0506 04:29:00.795559 12834 net.cpp:222] parameters does not need backward computation.
I0506 04:29:00.795562 12834 net.cpp:264] This network produces output loss
I0506 04:29:00.795572 12834 net.cpp:284] Network initialization done.
I0506 04:29:00.795898 12834 solver.cpp:181] Creating test net (#0) specified by net file: ./protocol/dis_50_100_dimension.protocol_distribution
I0506 04:29:00.795924 12834 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer parameters
I0506 04:29:00.796018 12834 net.cpp:52] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "intercept"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_test-distributions-path.txt"
    batch_size: 20
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool5"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "gaussian"
      std: 0.1
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I0506 04:29:00.796084 12834 layer_factory.hpp:77] Creating layer intercept
I0506 04:29:00.796093 12834 net.cpp:94] Creating Layer intercept
I0506 04:29:00.796097 12834 net.cpp:409] intercept -> data
I0506 04:29:00.796103 12834 net.cpp:409] intercept -> label
I0506 04:29:00.796109 12834 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/input/50_distributions_100_sample_size_test-distributions-path.txt
I0506 04:29:00.796128 12834 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0506 04:29:00.836942 12834 net.cpp:144] Setting up intercept
I0506 04:29:00.836977 12834 net.cpp:151] Top shape: 20 1 10 10 (2000)
I0506 04:29:00.836982 12834 net.cpp:151] Top shape: 20 (20)
I0506 04:29:00.836987 12834 net.cpp:159] Memory required for data: 8080
I0506 04:29:00.836992 12834 layer_factory.hpp:77] Creating layer label_intercept_1_split
I0506 04:29:00.837010 12834 net.cpp:94] Creating Layer label_intercept_1_split
I0506 04:29:00.837014 12834 net.cpp:435] label_intercept_1_split <- label
I0506 04:29:00.837020 12834 net.cpp:409] label_intercept_1_split -> label_intercept_1_split_0
I0506 04:29:00.837029 12834 net.cpp:409] label_intercept_1_split -> label_intercept_1_split_1
I0506 04:29:00.837074 12834 net.cpp:144] Setting up label_intercept_1_split
I0506 04:29:00.837080 12834 net.cpp:151] Top shape: 20 (20)
I0506 04:29:00.837083 12834 net.cpp:151] Top shape: 20 (20)
I0506 04:29:00.837086 12834 net.cpp:159] Memory required for data: 8240
I0506 04:29:00.837090 12834 layer_factory.hpp:77] Creating layer conv1
I0506 04:29:00.837100 12834 net.cpp:94] Creating Layer conv1
I0506 04:29:00.837105 12834 net.cpp:435] conv1 <- data
I0506 04:29:00.837108 12834 net.cpp:409] conv1 -> conv1
I0506 04:29:00.837931 12834 net.cpp:144] Setting up conv1
I0506 04:29:00.837944 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.837949 12834 net.cpp:159] Memory required for data: 520240
I0506 04:29:00.837957 12834 layer_factory.hpp:77] Creating layer relu1
I0506 04:29:00.837965 12834 net.cpp:94] Creating Layer relu1
I0506 04:29:00.837968 12834 net.cpp:435] relu1 <- conv1
I0506 04:29:00.837972 12834 net.cpp:396] relu1 -> conv1 (in-place)
I0506 04:29:00.837980 12834 net.cpp:144] Setting up relu1
I0506 04:29:00.837983 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.837994 12834 net.cpp:159] Memory required for data: 1032240
I0506 04:29:00.837997 12834 layer_factory.hpp:77] Creating layer conv2
I0506 04:29:00.838006 12834 net.cpp:94] Creating Layer conv2
I0506 04:29:00.838009 12834 net.cpp:435] conv2 <- conv1
I0506 04:29:00.838014 12834 net.cpp:409] conv2 -> conv2
I0506 04:29:00.842098 12834 net.cpp:144] Setting up conv2
I0506 04:29:00.842113 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.842116 12834 net.cpp:159] Memory required for data: 1544240
I0506 04:29:00.842123 12834 layer_factory.hpp:77] Creating layer relu2
I0506 04:29:00.842131 12834 net.cpp:94] Creating Layer relu2
I0506 04:29:00.842134 12834 net.cpp:435] relu2 <- conv2
I0506 04:29:00.842139 12834 net.cpp:396] relu2 -> conv2 (in-place)
I0506 04:29:00.842145 12834 net.cpp:144] Setting up relu2
I0506 04:29:00.842150 12834 net.cpp:151] Top shape: 20 64 10 10 (128000)
I0506 04:29:00.842154 12834 net.cpp:159] Memory required for data: 2056240
I0506 04:29:00.842156 12834 layer_factory.hpp:77] Creating layer pool2
I0506 04:29:00.842164 12834 net.cpp:94] Creating Layer pool2
I0506 04:29:00.842166 12834 net.cpp:435] pool2 <- conv2
I0506 04:29:00.842170 12834 net.cpp:409] pool2 -> pool2
I0506 04:29:00.842231 12834 net.cpp:144] Setting up pool2
I0506 04:29:00.842237 12834 net.cpp:151] Top shape: 20 64 5 5 (32000)
I0506 04:29:00.842242 12834 net.cpp:159] Memory required for data: 2184240
I0506 04:29:00.842244 12834 layer_factory.hpp:77] Creating layer conv3
I0506 04:29:00.842252 12834 net.cpp:94] Creating Layer conv3
I0506 04:29:00.842257 12834 net.cpp:435] conv3 <- pool2
I0506 04:29:00.842262 12834 net.cpp:409] conv3 -> conv3
I0506 04:29:00.848330 12834 net.cpp:144] Setting up conv3
I0506 04:29:00.848343 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.848347 12834 net.cpp:159] Memory required for data: 2440240
I0506 04:29:00.848354 12834 layer_factory.hpp:77] Creating layer relu3
I0506 04:29:00.848362 12834 net.cpp:94] Creating Layer relu3
I0506 04:29:00.848366 12834 net.cpp:435] relu3 <- conv3
I0506 04:29:00.848371 12834 net.cpp:396] relu3 -> conv3 (in-place)
I0506 04:29:00.848378 12834 net.cpp:144] Setting up relu3
I0506 04:29:00.848383 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.848387 12834 net.cpp:159] Memory required for data: 2696240
I0506 04:29:00.848389 12834 layer_factory.hpp:77] Creating layer conv4
I0506 04:29:00.848397 12834 net.cpp:94] Creating Layer conv4
I0506 04:29:00.848402 12834 net.cpp:435] conv4 <- conv3
I0506 04:29:00.848407 12834 net.cpp:409] conv4 -> conv4
I0506 04:29:00.860817 12834 net.cpp:144] Setting up conv4
I0506 04:29:00.860831 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.860836 12834 net.cpp:159] Memory required for data: 2952240
I0506 04:29:00.860841 12834 layer_factory.hpp:77] Creating layer relu4
I0506 04:29:00.860847 12834 net.cpp:94] Creating Layer relu4
I0506 04:29:00.860852 12834 net.cpp:435] relu4 <- conv4
I0506 04:29:00.860855 12834 net.cpp:396] relu4 -> conv4 (in-place)
I0506 04:29:00.860862 12834 net.cpp:144] Setting up relu4
I0506 04:29:00.860867 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.860869 12834 net.cpp:159] Memory required for data: 3208240
I0506 04:29:00.860872 12834 layer_factory.hpp:77] Creating layer conv5
I0506 04:29:00.860883 12834 net.cpp:94] Creating Layer conv5
I0506 04:29:00.860887 12834 net.cpp:435] conv5 <- conv4
I0506 04:29:00.860891 12834 net.cpp:409] conv5 -> conv5
I0506 04:29:00.873258 12834 net.cpp:144] Setting up conv5
I0506 04:29:00.873271 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.873275 12834 net.cpp:159] Memory required for data: 3464240
I0506 04:29:00.873286 12834 layer_factory.hpp:77] Creating layer relu5
I0506 04:29:00.873292 12834 net.cpp:94] Creating Layer relu5
I0506 04:29:00.873296 12834 net.cpp:435] relu5 <- conv5
I0506 04:29:00.873301 12834 net.cpp:396] relu5 -> conv5 (in-place)
I0506 04:29:00.873308 12834 net.cpp:144] Setting up relu5
I0506 04:29:00.873312 12834 net.cpp:151] Top shape: 20 128 5 5 (64000)
I0506 04:29:00.873320 12834 net.cpp:159] Memory required for data: 3720240
I0506 04:29:00.873324 12834 layer_factory.hpp:77] Creating layer pool5
I0506 04:29:00.873329 12834 net.cpp:94] Creating Layer pool5
I0506 04:29:00.873332 12834 net.cpp:435] pool5 <- conv5
I0506 04:29:00.873337 12834 net.cpp:409] pool5 -> pool5
I0506 04:29:00.873379 12834 net.cpp:144] Setting up pool5
I0506 04:29:00.873386 12834 net.cpp:151] Top shape: 20 128 2 2 (10240)
I0506 04:29:00.873389 12834 net.cpp:159] Memory required for data: 3761200
I0506 04:29:00.873392 12834 layer_factory.hpp:77] Creating layer ip1
I0506 04:29:00.873399 12834 net.cpp:94] Creating Layer ip1
I0506 04:29:00.873404 12834 net.cpp:435] ip1 <- pool5
I0506 04:29:00.873409 12834 net.cpp:409] ip1 -> ip1
I0506 04:29:00.886569 12834 net.cpp:144] Setting up ip1
I0506 04:29:00.886581 12834 net.cpp:151] Top shape: 20 1024 (20480)
I0506 04:29:00.886585 12834 net.cpp:159] Memory required for data: 3843120
I0506 04:29:00.886591 12834 layer_factory.hpp:77] Creating layer ip2
I0506 04:29:00.886598 12834 net.cpp:94] Creating Layer ip2
I0506 04:29:00.886601 12834 net.cpp:435] ip2 <- ip1
I0506 04:29:00.886617 12834 net.cpp:409] ip2 -> ip2
I0506 04:29:00.899691 12834 net.cpp:144] Setting up ip2
I0506 04:29:00.899704 12834 net.cpp:151] Top shape: 20 512 (10240)
I0506 04:29:00.899708 12834 net.cpp:159] Memory required for data: 3884080
I0506 04:29:00.899714 12834 layer_factory.hpp:77] Creating layer ip3
I0506 04:29:00.899724 12834 net.cpp:94] Creating Layer ip3
I0506 04:29:00.899727 12834 net.cpp:435] ip3 <- ip2
I0506 04:29:00.899732 12834 net.cpp:409] ip3 -> ip3
I0506 04:29:00.900473 12834 net.cpp:144] Setting up ip3
I0506 04:29:00.900482 12834 net.cpp:151] Top shape: 20 50 (1000)
I0506 04:29:00.900485 12834 net.cpp:159] Memory required for data: 3888080
I0506 04:29:00.900490 12834 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0506 04:29:00.900498 12834 net.cpp:94] Creating Layer ip3_ip3_0_split
I0506 04:29:00.900501 12834 net.cpp:435] ip3_ip3_0_split <- ip3
I0506 04:29:00.900506 12834 net.cpp:409] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0506 04:29:00.900511 12834 net.cpp:409] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0506 04:29:00.900574 12834 net.cpp:144] Setting up ip3_ip3_0_split
I0506 04:29:00.900581 12834 net.cpp:151] Top shape: 20 50 (1000)
I0506 04:29:00.900585 12834 net.cpp:151] Top shape: 20 50 (1000)
I0506 04:29:00.900588 12834 net.cpp:159] Memory required for data: 3896080
I0506 04:29:00.900591 12834 layer_factory.hpp:77] Creating layer accuracy
I0506 04:29:00.900598 12834 net.cpp:94] Creating Layer accuracy
I0506 04:29:00.900600 12834 net.cpp:435] accuracy <- ip3_ip3_0_split_0
I0506 04:29:00.900605 12834 net.cpp:435] accuracy <- label_intercept_1_split_0
I0506 04:29:00.900610 12834 net.cpp:409] accuracy -> accuracy
I0506 04:29:00.900619 12834 net.cpp:144] Setting up accuracy
I0506 04:29:00.900624 12834 net.cpp:151] Top shape: (1)
I0506 04:29:00.900627 12834 net.cpp:159] Memory required for data: 3896084
I0506 04:29:00.900630 12834 layer_factory.hpp:77] Creating layer loss
I0506 04:29:00.900635 12834 net.cpp:94] Creating Layer loss
I0506 04:29:00.900638 12834 net.cpp:435] loss <- ip3_ip3_0_split_1
I0506 04:29:00.900642 12834 net.cpp:435] loss <- label_intercept_1_split_1
I0506 04:29:00.900646 12834 net.cpp:409] loss -> loss
I0506 04:29:00.900652 12834 layer_factory.hpp:77] Creating layer loss
I0506 04:29:00.900768 12834 net.cpp:144] Setting up loss
I0506 04:29:00.900775 12834 net.cpp:151] Top shape: (1)
I0506 04:29:00.900779 12834 net.cpp:154]     with loss weight 1
I0506 04:29:00.900789 12834 net.cpp:159] Memory required for data: 3896088
I0506 04:29:00.900791 12834 net.cpp:220] loss needs backward computation.
I0506 04:29:00.900795 12834 net.cpp:222] accuracy does not need backward computation.
I0506 04:29:00.900799 12834 net.cpp:220] ip3_ip3_0_split needs backward computation.
I0506 04:29:00.900802 12834 net.cpp:220] ip3 needs backward computation.
I0506 04:29:00.900805 12834 net.cpp:220] ip2 needs backward computation.
I0506 04:29:00.900809 12834 net.cpp:220] ip1 needs backward computation.
I0506 04:29:00.900816 12834 net.cpp:220] pool5 needs backward computation.
I0506 04:29:00.900820 12834 net.cpp:220] relu5 needs backward computation.
I0506 04:29:00.900823 12834 net.cpp:220] conv5 needs backward computation.
I0506 04:29:00.900826 12834 net.cpp:220] relu4 needs backward computation.
I0506 04:29:00.900830 12834 net.cpp:220] conv4 needs backward computation.
I0506 04:29:00.900832 12834 net.cpp:220] relu3 needs backward computation.
I0506 04:29:00.900835 12834 net.cpp:220] conv3 needs backward computation.
I0506 04:29:00.900838 12834 net.cpp:220] pool2 needs backward computation.
I0506 04:29:00.900841 12834 net.cpp:220] relu2 needs backward computation.
I0506 04:29:00.900845 12834 net.cpp:220] conv2 needs backward computation.
I0506 04:29:00.900847 12834 net.cpp:220] relu1 needs backward computation.
I0506 04:29:00.900851 12834 net.cpp:220] conv1 needs backward computation.
I0506 04:29:00.900854 12834 net.cpp:222] label_intercept_1_split does not need backward computation.
I0506 04:29:00.900858 12834 net.cpp:222] intercept does not need backward computation.
I0506 04:29:00.900861 12834 net.cpp:264] This network produces output accuracy
I0506 04:29:00.900864 12834 net.cpp:264] This network produces output loss
I0506 04:29:00.900888 12834 net.cpp:284] Network initialization done.
I0506 04:29:00.900945 12834 solver.cpp:60] Solver scaffolding done.
I0506 04:29:00.905788 12834 solver.cpp:362] Iteration 0, Testing net (#0)
I0506 04:29:00.905802 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:01.085562 12834 solver.cpp:429]     Test net output #0: loss = 12.7873 (* 1 = 12.7873 loss)
I0506 04:29:01.108001 12834 solver.cpp:242] Iteration 0 (0 iter/s, 0.204229s/100 iter), loss = 10.5297
I0506 04:29:01.108024 12834 solver.cpp:261]     Train net output #0: loss = 10.5297 (* 1 = 10.5297 loss)
I0506 04:29:01.108034 12834 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0506 04:29:01.113576 12834 solver.cpp:362] Iteration 0, Testing net (#0)
I0506 04:29:01.113590 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:01.289649 12834 solver.cpp:429]     Test net output #0: accuracy = 0.0165
I0506 04:29:01.289674 12834 solver.cpp:429]     Test net output #1: loss = 3.91204 (* 1 = 3.91204 loss)
I0506 04:29:01.306632 12834 solver.cpp:242] Iteration 0 (0 iter/s, 0.195079s/100 iter), loss = 3.91212
I0506 04:29:01.306653 12834 solver.cpp:261]     Train net output #0: loss = 3.91212 (* 1 = 3.91212 loss)
I0506 04:29:01.306663 12834 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0506 04:29:02.341243 12834 solver.cpp:242] Iteration 100 (81.0913 iter/s, 1.23318s/100 iter), loss = 4.1673
I0506 04:29:02.341279 12834 solver.cpp:261]     Train net output #0: loss = 4.1673 (* 1 = 4.1673 loss)
I0506 04:29:02.341289 12834 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0506 04:29:02.346060 12834 solver.cpp:242] Iteration 100 (96.2106 iter/s, 1.03939s/100 iter), loss = 3.91709
I0506 04:29:02.346086 12834 solver.cpp:261]     Train net output #0: loss = 3.91709 (* 1 = 3.91709 loss)
I0506 04:29:02.346096 12834 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0506 04:29:03.303961 12834 solver.cpp:242] Iteration 200 (103.88 iter/s, 0.962652s/100 iter), loss = 5.54907
I0506 04:29:03.304008 12834 solver.cpp:261]     Train net output #0: loss = 5.54907 (* 1 = 5.54907 loss)
I0506 04:29:03.304018 12834 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0506 04:29:03.308754 12834 solver.cpp:242] Iteration 200 (103.88 iter/s, 0.962647s/100 iter), loss = 3.90327
I0506 04:29:03.308784 12834 solver.cpp:261]     Train net output #0: loss = 3.90327 (* 1 = 3.90327 loss)
I0506 04:29:03.308794 12834 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0506 04:29:04.244218 12834 solver.cpp:242] Iteration 300 (106.363 iter/s, 0.940174s/100 iter), loss = 5.694
I0506 04:29:04.244251 12834 solver.cpp:261]     Train net output #0: loss = 5.694 (* 1 = 5.694 loss)
I0506 04:29:04.244261 12834 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0506 04:29:04.249016 12834 solver.cpp:242] Iteration 300 (106.359 iter/s, 0.940213s/100 iter), loss = 3.89465
I0506 04:29:04.249053 12834 solver.cpp:261]     Train net output #0: loss = 3.89465 (* 1 = 3.89465 loss)
I0506 04:29:04.249061 12834 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0506 04:29:05.184033 12834 solver.cpp:242] Iteration 400 (106.41 iter/s, 0.939759s/100 iter), loss = 5.71501
I0506 04:29:05.184063 12834 solver.cpp:261]     Train net output #0: loss = 5.71501 (* 1 = 5.71501 loss)
I0506 04:29:05.184072 12834 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0506 04:29:05.188805 12834 solver.cpp:242] Iteration 400 (106.413 iter/s, 0.939735s/100 iter), loss = 3.87902
I0506 04:29:05.188830 12834 solver.cpp:261]     Train net output #0: loss = 3.87902 (* 1 = 3.87902 loss)
I0506 04:29:05.188839 12834 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0506 04:29:06.120666 12834 solver.cpp:362] Iteration 500, Testing net (#0)
I0506 04:29:06.120689 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:06.243602 12834 solver.cpp:429]     Test net output #0: loss = 5.43515 (* 1 = 5.43515 loss)
I0506 04:29:06.246120 12834 solver.cpp:242] Iteration 500 (94.1586 iter/s, 1.06204s/100 iter), loss = 5.37789
I0506 04:29:06.246140 12834 solver.cpp:261]     Train net output #0: loss = 5.37789 (* 1 = 5.37789 loss)
I0506 04:29:06.246148 12834 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0506 04:29:06.247987 12834 solver.cpp:362] Iteration 500, Testing net (#0)
I0506 04:29:06.248001 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:06.377010 12834 solver.cpp:429]     Test net output #0: accuracy = 0.048
I0506 04:29:06.377030 12834 solver.cpp:429]     Test net output #1: loss = 3.73552 (* 1 = 3.73552 loss)
I0506 04:29:06.379583 12834 solver.cpp:242] Iteration 500 (83.9819 iter/s, 1.19073s/100 iter), loss = 3.83352
I0506 04:29:06.379603 12834 solver.cpp:261]     Train net output #0: loss = 3.83352 (* 1 = 3.83352 loss)
I0506 04:29:06.379611 12834 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0506 04:29:07.314368 12834 solver.cpp:242] Iteration 600 (93.6152 iter/s, 1.0682s/100 iter), loss = 6.19611
I0506 04:29:07.314395 12834 solver.cpp:261]     Train net output #0: loss = 6.19611 (* 1 = 6.19611 loss)
I0506 04:29:07.314404 12834 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0506 04:29:07.319169 12834 solver.cpp:242] Iteration 600 (106.434 iter/s, 0.939548s/100 iter), loss = 3.8212
I0506 04:29:07.319193 12834 solver.cpp:261]     Train net output #0: loss = 3.8212 (* 1 = 3.8212 loss)
I0506 04:29:07.319201 12834 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0506 04:29:08.254089 12834 solver.cpp:242] Iteration 700 (106.421 iter/s, 0.939666s/100 iter), loss = 4.66663
I0506 04:29:08.254117 12834 solver.cpp:261]     Train net output #0: loss = 4.66663 (* 1 = 4.66663 loss)
I0506 04:29:08.254125 12834 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0506 04:29:08.258886 12834 solver.cpp:242] Iteration 700 (106.42 iter/s, 0.939675s/100 iter), loss = 3.59871
I0506 04:29:08.258910 12834 solver.cpp:261]     Train net output #0: loss = 3.59871 (* 1 = 3.59871 loss)
I0506 04:29:08.258919 12834 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0506 04:29:09.194026 12834 solver.cpp:242] Iteration 800 (106.396 iter/s, 0.939889s/100 iter), loss = 4.59856
I0506 04:29:09.194059 12834 solver.cpp:261]     Train net output #0: loss = 4.59856 (* 1 = 4.59856 loss)
I0506 04:29:09.194067 12834 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0506 04:29:09.198860 12834 solver.cpp:242] Iteration 800 (106.392 iter/s, 0.939922s/100 iter), loss = 3.63387
I0506 04:29:09.198886 12834 solver.cpp:261]     Train net output #0: loss = 3.63387 (* 1 = 3.63387 loss)
I0506 04:29:09.198894 12834 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0506 04:29:10.134166 12834 solver.cpp:242] Iteration 900 (106.374 iter/s, 0.940083s/100 iter), loss = 4.90092
I0506 04:29:10.134192 12834 solver.cpp:261]     Train net output #0: loss = 4.90092 (* 1 = 4.90092 loss)
I0506 04:29:10.134202 12834 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0506 04:29:10.138929 12834 solver.cpp:242] Iteration 900 (106.38 iter/s, 0.940025s/100 iter), loss = 3.43062
I0506 04:29:10.138960 12834 solver.cpp:261]     Train net output #0: loss = 3.43062 (* 1 = 3.43062 loss)
I0506 04:29:10.138969 12834 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0506 04:29:11.071043 12834 solver.cpp:362] Iteration 1000, Testing net (#0)
I0506 04:29:11.071061 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:11.194077 12834 solver.cpp:429]     Test net output #0: loss = 5.52879 (* 1 = 5.52879 loss)
I0506 04:29:11.196643 12834 solver.cpp:242] Iteration 1000 (94.1237 iter/s, 1.06243s/100 iter), loss = 5.36142
I0506 04:29:11.196666 12834 solver.cpp:261]     Train net output #0: loss = 5.36142 (* 1 = 5.36142 loss)
I0506 04:29:11.196676 12834 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0506 04:29:11.198496 12834 solver.cpp:362] Iteration 1000, Testing net (#0)
I0506 04:29:11.198510 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:11.327428 12834 solver.cpp:429]     Test net output #0: accuracy = 0.105
I0506 04:29:11.327447 12834 solver.cpp:429]     Test net output #1: loss = 3.48605 (* 1 = 3.48605 loss)
I0506 04:29:11.330013 12834 solver.cpp:242] Iteration 1000 (83.9609 iter/s, 1.19103s/100 iter), loss = 3.58588
I0506 04:29:11.330032 12834 solver.cpp:261]     Train net output #0: loss = 3.58588 (* 1 = 3.58588 loss)
I0506 04:29:11.330041 12834 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0506 04:29:12.264794 12834 solver.cpp:242] Iteration 1100 (93.624 iter/s, 1.0681s/100 iter), loss = 6.50141
I0506 04:29:12.264825 12834 solver.cpp:261]     Train net output #0: loss = 6.50141 (* 1 = 6.50141 loss)
I0506 04:29:12.264834 12834 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0506 04:29:12.269588 12834 solver.cpp:242] Iteration 1100 (106.435 iter/s, 0.939536s/100 iter), loss = 3.51575
I0506 04:29:12.269613 12834 solver.cpp:261]     Train net output #0: loss = 3.51575 (* 1 = 3.51575 loss)
I0506 04:29:12.269621 12834 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0506 04:29:13.204854 12834 solver.cpp:242] Iteration 1200 (106.383 iter/s, 0.939998s/100 iter), loss = 3.67269
I0506 04:29:13.204885 12834 solver.cpp:261]     Train net output #0: loss = 3.67269 (* 1 = 3.67269 loss)
I0506 04:29:13.204895 12834 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0506 04:29:13.209661 12834 solver.cpp:242] Iteration 1200 (106.38 iter/s, 0.940029s/100 iter), loss = 3.42592
I0506 04:29:13.209686 12834 solver.cpp:261]     Train net output #0: loss = 3.42592 (* 1 = 3.42592 loss)
I0506 04:29:13.209693 12834 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0506 04:29:14.144651 12834 solver.cpp:242] Iteration 1300 (106.412 iter/s, 0.939739s/100 iter), loss = 5.04658
I0506 04:29:14.144685 12834 solver.cpp:261]     Train net output #0: loss = 5.04658 (* 1 = 5.04658 loss)
I0506 04:29:14.144693 12834 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0506 04:29:14.149433 12834 solver.cpp:242] Iteration 1300 (106.414 iter/s, 0.939729s/100 iter), loss = 3.43432
I0506 04:29:14.149458 12834 solver.cpp:261]     Train net output #0: loss = 3.43432 (* 1 = 3.43432 loss)
I0506 04:29:14.149466 12834 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0506 04:29:15.084476 12834 solver.cpp:242] Iteration 1400 (106.41 iter/s, 0.939765s/100 iter), loss = 3.74588
I0506 04:29:15.084507 12834 solver.cpp:261]     Train net output #0: loss = 3.74588 (* 1 = 3.74588 loss)
I0506 04:29:15.084517 12834 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0506 04:29:15.089257 12834 solver.cpp:242] Iteration 1400 (106.408 iter/s, 0.939781s/100 iter), loss = 3.3692
I0506 04:29:15.089282 12834 solver.cpp:261]     Train net output #0: loss = 3.3692 (* 1 = 3.3692 loss)
I0506 04:29:15.089290 12834 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
I0506 04:29:16.021608 12834 solver.cpp:362] Iteration 1500, Testing net (#0)
I0506 04:29:16.021628 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:16.144511 12834 solver.cpp:429]     Test net output #0: loss = 5.56737 (* 1 = 5.56737 loss)
I0506 04:29:16.147028 12834 solver.cpp:242] Iteration 1500 (94.1176 iter/s, 1.0625s/100 iter), loss = 4.02385
I0506 04:29:16.147049 12834 solver.cpp:261]     Train net output #0: loss = 4.02385 (* 1 = 4.02385 loss)
I0506 04:29:16.147065 12834 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0506 04:29:16.148885 12834 solver.cpp:362] Iteration 1500, Testing net (#0)
I0506 04:29:16.148900 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:16.277758 12834 solver.cpp:429]     Test net output #0: accuracy = 0.079
I0506 04:29:16.277782 12834 solver.cpp:429]     Test net output #1: loss = 3.33529 (* 1 = 3.33529 loss)
I0506 04:29:16.280544 12834 solver.cpp:242] Iteration 1500 (83.9461 iter/s, 1.19124s/100 iter), loss = 3.67922
I0506 04:29:16.280582 12834 solver.cpp:261]     Train net output #0: loss = 3.67922 (* 1 = 3.67922 loss)
I0506 04:29:16.280591 12834 sgd_solver.cpp:106] Iteration 1500, lr = 0.0001
I0506 04:29:17.215855 12834 solver.cpp:242] Iteration 1600 (93.5648 iter/s, 1.06878s/100 iter), loss = 5.6974
I0506 04:29:17.215885 12834 solver.cpp:261]     Train net output #0: loss = 5.6974 (* 1 = 5.6974 loss)
I0506 04:29:17.215894 12834 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0506 04:29:17.220643 12834 solver.cpp:242] Iteration 1600 (106.378 iter/s, 0.940042s/100 iter), loss = 3.37785
I0506 04:29:17.220666 12834 solver.cpp:261]     Train net output #0: loss = 3.37785 (* 1 = 3.37785 loss)
I0506 04:29:17.220675 12834 sgd_solver.cpp:106] Iteration 1600, lr = 0.0001
I0506 04:29:18.155786 12834 solver.cpp:242] Iteration 1700 (106.397 iter/s, 0.939879s/100 iter), loss = 7.40034
I0506 04:29:18.155819 12834 solver.cpp:261]     Train net output #0: loss = 7.40034 (* 1 = 7.40034 loss)
I0506 04:29:18.155828 12834 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0506 04:29:18.160624 12834 solver.cpp:242] Iteration 1700 (106.391 iter/s, 0.939929s/100 iter), loss = 3.27651
I0506 04:29:18.160647 12834 solver.cpp:261]     Train net output #0: loss = 3.27651 (* 1 = 3.27651 loss)
I0506 04:29:18.160656 12834 sgd_solver.cpp:106] Iteration 1700, lr = 0.0001
I0506 04:29:19.095163 12834 solver.cpp:242] Iteration 1800 (106.46 iter/s, 0.939318s/100 iter), loss = 5.50707
I0506 04:29:19.095196 12834 solver.cpp:261]     Train net output #0: loss = 5.50707 (* 1 = 5.50707 loss)
I0506 04:29:19.095204 12834 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0506 04:29:19.099926 12834 solver.cpp:242] Iteration 1800 (106.467 iter/s, 0.93926s/100 iter), loss = 3.38955
I0506 04:29:19.099951 12834 solver.cpp:261]     Train net output #0: loss = 3.38955 (* 1 = 3.38955 loss)
I0506 04:29:19.099961 12834 sgd_solver.cpp:106] Iteration 1800, lr = 0.0001
I0506 04:29:20.035369 12834 solver.cpp:242] Iteration 1900 (106.366 iter/s, 0.940154s/100 iter), loss = 5.00754
I0506 04:29:20.035396 12834 solver.cpp:261]     Train net output #0: loss = 5.00754 (* 1 = 5.00754 loss)
I0506 04:29:20.035405 12834 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0506 04:29:20.040215 12834 solver.cpp:242] Iteration 1900 (106.356 iter/s, 0.940236s/100 iter), loss = 3.23887
I0506 04:29:20.040238 12834 solver.cpp:261]     Train net output #0: loss = 3.23887 (* 1 = 3.23887 loss)
I0506 04:29:20.040247 12834 sgd_solver.cpp:106] Iteration 1900, lr = 0.0001
I0506 04:29:20.972365 12834 solver.cpp:362] Iteration 2000, Testing net (#0)
I0506 04:29:20.972383 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:21.095331 12834 solver.cpp:429]     Test net output #0: loss = 5.59275 (* 1 = 5.59275 loss)
I0506 04:29:21.097851 12834 solver.cpp:242] Iteration 2000 (94.1234 iter/s, 1.06243s/100 iter), loss = 7.63378
I0506 04:29:21.097870 12834 solver.cpp:261]     Train net output #0: loss = 7.63378 (* 1 = 7.63378 loss)
I0506 04:29:21.097879 12834 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0506 04:29:21.099690 12834 solver.cpp:362] Iteration 2000, Testing net (#0)
I0506 04:29:21.099704 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:21.228740 12834 solver.cpp:429]     Test net output #0: accuracy = 0.1145
I0506 04:29:21.228759 12834 solver.cpp:429]     Test net output #1: loss = 3.39578 (* 1 = 3.39578 loss)
I0506 04:29:21.231319 12834 solver.cpp:242] Iteration 2000 (83.9589 iter/s, 1.19106s/100 iter), loss = 3.35792
I0506 04:29:21.231346 12834 solver.cpp:261]     Train net output #0: loss = 3.35792 (* 1 = 3.35792 loss)
I0506 04:29:21.231355 12834 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0506 04:29:22.168006 12834 solver.cpp:242] Iteration 2100 (93.4487 iter/s, 1.07011s/100 iter), loss = 6.67209
I0506 04:29:22.168035 12834 solver.cpp:261]     Train net output #0: loss = 6.67209 (* 1 = 6.67209 loss)
I0506 04:29:22.168043 12834 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0506 04:29:22.172812 12834 solver.cpp:242] Iteration 2100 (106.219 iter/s, 0.941448s/100 iter), loss = 3.20435
I0506 04:29:22.172837 12834 solver.cpp:261]     Train net output #0: loss = 3.20435 (* 1 = 3.20435 loss)
I0506 04:29:22.172845 12834 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0506 04:29:23.107669 12834 solver.cpp:242] Iteration 2200 (106.427 iter/s, 0.93961s/100 iter), loss = 5.24231
I0506 04:29:23.107699 12834 solver.cpp:261]     Train net output #0: loss = 5.24231 (* 1 = 5.24231 loss)
I0506 04:29:23.107708 12834 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0506 04:29:23.112455 12834 solver.cpp:242] Iteration 2200 (106.428 iter/s, 0.939601s/100 iter), loss = 3.29058
I0506 04:29:23.112479 12834 solver.cpp:261]     Train net output #0: loss = 3.29058 (* 1 = 3.29058 loss)
I0506 04:29:23.112488 12834 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0506 04:29:24.048020 12834 solver.cpp:242] Iteration 2300 (106.35 iter/s, 0.94029s/100 iter), loss = 5.37858
I0506 04:29:24.048053 12834 solver.cpp:261]     Train net output #0: loss = 5.37858 (* 1 = 5.37858 loss)
I0506 04:29:24.048063 12834 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0506 04:29:24.052817 12834 solver.cpp:242] Iteration 2300 (106.347 iter/s, 0.940319s/100 iter), loss = 3.42115
I0506 04:29:24.052844 12834 solver.cpp:261]     Train net output #0: loss = 3.42115 (* 1 = 3.42115 loss)
I0506 04:29:24.052852 12834 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0506 04:29:24.988765 12834 solver.cpp:242] Iteration 2400 (106.305 iter/s, 0.940689s/100 iter), loss = 4.60665
I0506 04:29:24.988795 12834 solver.cpp:261]     Train net output #0: loss = 4.60665 (* 1 = 4.60665 loss)
I0506 04:29:24.988803 12834 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0506 04:29:24.993540 12834 solver.cpp:242] Iteration 2400 (106.306 iter/s, 0.940677s/100 iter), loss = 3.06409
I0506 04:29:24.993563 12834 solver.cpp:261]     Train net output #0: loss = 3.06409 (* 1 = 3.06409 loss)
I0506 04:29:24.993571 12834 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0506 04:29:25.926930 12834 solver.cpp:362] Iteration 2500, Testing net (#0)
I0506 04:29:25.926950 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:26.050006 12834 solver.cpp:429]     Test net output #0: loss = 5.19785 (* 1 = 5.19785 loss)
I0506 04:29:26.052530 12834 solver.cpp:242] Iteration 2500 (94.0101 iter/s, 1.06372s/100 iter), loss = 4.99483
I0506 04:29:26.052549 12834 solver.cpp:261]     Train net output #0: loss = 4.99483 (* 1 = 4.99483 loss)
I0506 04:29:26.052562 12834 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0506 04:29:26.054384 12834 solver.cpp:362] Iteration 2500, Testing net (#0)
I0506 04:29:26.054397 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:26.183354 12834 solver.cpp:429]     Test net output #0: accuracy = 0.133
I0506 04:29:26.183372 12834 solver.cpp:429]     Test net output #1: loss = 3.12966 (* 1 = 3.12966 loss)
I0506 04:29:26.185914 12834 solver.cpp:242] Iteration 2500 (83.8695 iter/s, 1.19233s/100 iter), loss = 3.33111
I0506 04:29:26.185933 12834 solver.cpp:261]     Train net output #0: loss = 3.33111 (* 1 = 3.33111 loss)
I0506 04:29:26.185941 12834 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0506 04:29:27.135841 12834 solver.cpp:242] Iteration 2600 (92.3133 iter/s, 1.08327s/100 iter), loss = 4.6041
I0506 04:29:27.135879 12834 solver.cpp:261]     Train net output #0: loss = 4.6041 (* 1 = 4.6041 loss)
I0506 04:29:27.136056 12834 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0506 04:29:27.140990 12834 solver.cpp:242] Iteration 2600 (104.709 iter/s, 0.955028s/100 iter), loss = 3.32393
I0506 04:29:27.141022 12834 solver.cpp:261]     Train net output #0: loss = 3.32393 (* 1 = 3.32393 loss)
I0506 04:29:27.141032 12834 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0506 04:29:28.076468 12834 solver.cpp:242] Iteration 2700 (106.319 iter/s, 0.940566s/100 iter), loss = 5.47314
I0506 04:29:28.076501 12834 solver.cpp:261]     Train net output #0: loss = 5.47314 (* 1 = 5.47314 loss)
I0506 04:29:28.076510 12834 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0506 04:29:28.081239 12834 solver.cpp:242] Iteration 2700 (106.36 iter/s, 0.940199s/100 iter), loss = 2.79062
I0506 04:29:28.081264 12834 solver.cpp:261]     Train net output #0: loss = 2.79062 (* 1 = 2.79062 loss)
I0506 04:29:28.081272 12834 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0506 04:29:29.016535 12834 solver.cpp:242] Iteration 2800 (106.382 iter/s, 0.940013s/100 iter), loss = 5.85417
I0506 04:29:29.016583 12834 solver.cpp:261]     Train net output #0: loss = 5.85417 (* 1 = 5.85417 loss)
I0506 04:29:29.016592 12834 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0506 04:29:29.021378 12834 solver.cpp:242] Iteration 2800 (106.373 iter/s, 0.940087s/100 iter), loss = 2.73628
I0506 04:29:29.021402 12834 solver.cpp:261]     Train net output #0: loss = 2.73628 (* 1 = 2.73628 loss)
I0506 04:29:29.021411 12834 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0506 04:29:29.956022 12834 solver.cpp:242] Iteration 2900 (106.449 iter/s, 0.939417s/100 iter), loss = 5.17432
I0506 04:29:29.956056 12834 solver.cpp:261]     Train net output #0: loss = 5.17432 (* 1 = 5.17432 loss)
I0506 04:29:29.956065 12834 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0506 04:29:29.960774 12834 solver.cpp:242] Iteration 2900 (106.456 iter/s, 0.939353s/100 iter), loss = 2.85043
I0506 04:29:29.960798 12834 solver.cpp:261]     Train net output #0: loss = 2.85043 (* 1 = 2.85043 loss)
I0506 04:29:29.960808 12834 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0506 04:29:30.925675 12834 solver.cpp:362] Iteration 3000, Testing net (#0)
I0506 04:29:30.925698 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:31.059033 12834 solver.cpp:429]     Test net output #0: loss = 5.05802 (* 1 = 5.05802 loss)
I0506 04:29:31.061667 12834 solver.cpp:242] Iteration 3000 (90.4494 iter/s, 1.10559s/100 iter), loss = 4.38862
I0506 04:29:31.061691 12834 solver.cpp:261]     Train net output #0: loss = 4.38862 (* 1 = 4.38862 loss)
I0506 04:29:31.061702 12834 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0506 04:29:31.063891 12834 solver.cpp:362] Iteration 3000, Testing net (#0)
I0506 04:29:31.063907 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:31.205175 12834 solver.cpp:429]     Test net output #0: accuracy = 0.2065
I0506 04:29:31.205196 12834 solver.cpp:429]     Test net output #1: loss = 2.77632 (* 1 = 2.77632 loss)
I0506 04:29:31.207907 12834 solver.cpp:242] Iteration 3000 (80.1869 iter/s, 1.24709s/100 iter), loss = 2.0682
I0506 04:29:31.207931 12834 solver.cpp:261]     Train net output #0: loss = 2.0682 (* 1 = 2.0682 loss)
I0506 04:29:31.207940 12834 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0506 04:29:32.239763 12834 solver.cpp:242] Iteration 3100 (84.8864 iter/s, 1.17804s/100 iter), loss = 4.23121
I0506 04:29:32.239804 12834 solver.cpp:261]     Train net output #0: loss = 4.23121 (* 1 = 4.23121 loss)
I0506 04:29:32.239959 12834 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0506 04:29:32.244786 12834 solver.cpp:242] Iteration 3100 (96.4474 iter/s, 1.03683s/100 iter), loss = 2.84562
I0506 04:29:32.244809 12834 solver.cpp:261]     Train net output #0: loss = 2.84562 (* 1 = 2.84562 loss)
I0506 04:29:32.244818 12834 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0506 04:29:33.180171 12834 solver.cpp:242] Iteration 3200 (106.344 iter/s, 0.94034s/100 iter), loss = 3.0246
I0506 04:29:33.180200 12834 solver.cpp:261]     Train net output #0: loss = 3.0246 (* 1 = 3.0246 loss)
I0506 04:29:33.180209 12834 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0506 04:29:33.184937 12834 solver.cpp:242] Iteration 3200 (106.371 iter/s, 0.940109s/100 iter), loss = 2.83982
I0506 04:29:33.184969 12834 solver.cpp:261]     Train net output #0: loss = 2.83982 (* 1 = 2.83982 loss)
I0506 04:29:33.184978 12834 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0506 04:29:34.120630 12834 solver.cpp:242] Iteration 3300 (106.337 iter/s, 0.940403s/100 iter), loss = 3.0077
I0506 04:29:34.120666 12834 solver.cpp:261]     Train net output #0: loss = 3.0077 (* 1 = 3.0077 loss)
I0506 04:29:34.120674 12834 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0506 04:29:34.125387 12834 solver.cpp:242] Iteration 3300 (106.338 iter/s, 0.9404s/100 iter), loss = 2.7132
I0506 04:29:34.125412 12834 solver.cpp:261]     Train net output #0: loss = 2.7132 (* 1 = 2.7132 loss)
I0506 04:29:34.125422 12834 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0506 04:29:35.060230 12834 solver.cpp:242] Iteration 3400 (106.435 iter/s, 0.939538s/100 iter), loss = 6.82988
I0506 04:29:35.060261 12834 solver.cpp:261]     Train net output #0: loss = 6.82988 (* 1 = 6.82988 loss)
I0506 04:29:35.060271 12834 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0506 04:29:35.065004 12834 solver.cpp:242] Iteration 3400 (106.431 iter/s, 0.939572s/100 iter), loss = 2.4874
I0506 04:29:35.065028 12834 solver.cpp:261]     Train net output #0: loss = 2.4874 (* 1 = 2.4874 loss)
I0506 04:29:35.065037 12834 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0506 04:29:35.997597 12834 solver.cpp:362] Iteration 3500, Testing net (#0)
I0506 04:29:35.997617 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:36.120642 12834 solver.cpp:429]     Test net output #0: loss = 5.02875 (* 1 = 5.02875 loss)
I0506 04:29:36.123157 12834 solver.cpp:242] Iteration 3500 (94.0844 iter/s, 1.06288s/100 iter), loss = 5.85449
I0506 04:29:36.123175 12834 solver.cpp:261]     Train net output #0: loss = 5.85449 (* 1 = 5.85449 loss)
I0506 04:29:36.123184 12834 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0506 04:29:36.125080 12834 solver.cpp:362] Iteration 3500, Testing net (#0)
I0506 04:29:36.125093 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:36.254034 12834 solver.cpp:429]     Test net output #0: accuracy = 0.2525
I0506 04:29:36.254053 12834 solver.cpp:429]     Test net output #1: loss = 2.52406 (* 1 = 2.52406 loss)
I0506 04:29:36.256613 12834 solver.cpp:242] Iteration 3500 (83.9234 iter/s, 1.19156s/100 iter), loss = 2.31871
I0506 04:29:36.256633 12834 solver.cpp:261]     Train net output #0: loss = 2.31871 (* 1 = 2.31871 loss)
I0506 04:29:36.256640 12834 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0506 04:29:37.192124 12834 solver.cpp:242] Iteration 3600 (93.5523 iter/s, 1.06892s/100 iter), loss = 5.75175
I0506 04:29:37.192157 12834 solver.cpp:261]     Train net output #0: loss = 5.75175 (* 1 = 5.75175 loss)
I0506 04:29:37.192167 12834 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0506 04:29:37.196919 12834 solver.cpp:242] Iteration 3600 (106.353 iter/s, 0.940268s/100 iter), loss = 2.41775
I0506 04:29:37.196943 12834 solver.cpp:261]     Train net output #0: loss = 2.41775 (* 1 = 2.41775 loss)
I0506 04:29:37.196951 12834 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0506 04:29:38.132874 12834 solver.cpp:242] Iteration 3700 (106.304 iter/s, 0.940695s/100 iter), loss = 3.56538
I0506 04:29:38.132908 12834 solver.cpp:261]     Train net output #0: loss = 3.56538 (* 1 = 3.56538 loss)
I0506 04:29:38.132917 12834 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0506 04:29:38.137723 12834 solver.cpp:242] Iteration 3700 (106.298 iter/s, 0.940753s/100 iter), loss = 2.39731
I0506 04:29:38.137748 12834 solver.cpp:261]     Train net output #0: loss = 2.39731 (* 1 = 2.39731 loss)
I0506 04:29:38.137756 12834 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0506 04:29:39.073703 12834 solver.cpp:242] Iteration 3800 (106.296 iter/s, 0.940771s/100 iter), loss = 3.05513
I0506 04:29:39.073729 12834 solver.cpp:261]     Train net output #0: loss = 3.05513 (* 1 = 3.05513 loss)
I0506 04:29:39.073738 12834 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0506 04:29:39.078469 12834 solver.cpp:242] Iteration 3800 (106.304 iter/s, 0.940703s/100 iter), loss = 2.47309
I0506 04:29:39.078498 12834 solver.cpp:261]     Train net output #0: loss = 2.47309 (* 1 = 2.47309 loss)
I0506 04:29:39.078508 12834 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0506 04:29:40.015301 12834 solver.cpp:242] Iteration 3900 (106.209 iter/s, 0.941543s/100 iter), loss = 2.06654
I0506 04:29:40.015333 12834 solver.cpp:261]     Train net output #0: loss = 2.06654 (* 1 = 2.06654 loss)
I0506 04:29:40.015342 12834 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0506 04:29:40.020109 12834 solver.cpp:242] Iteration 3900 (106.203 iter/s, 0.941593s/100 iter), loss = 2.43639
I0506 04:29:40.020134 12834 solver.cpp:261]     Train net output #0: loss = 2.43639 (* 1 = 2.43639 loss)
I0506 04:29:40.020143 12834 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0506 04:29:40.952234 12834 solver.cpp:362] Iteration 4000, Testing net (#0)
I0506 04:29:40.952256 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:41.075202 12834 solver.cpp:429]     Test net output #0: loss = 4.60767 (* 1 = 4.60767 loss)
I0506 04:29:41.077728 12834 solver.cpp:242] Iteration 4000 (94.1287 iter/s, 1.06238s/100 iter), loss = 4.40552
I0506 04:29:41.077749 12834 solver.cpp:261]     Train net output #0: loss = 4.40552 (* 1 = 4.40552 loss)
I0506 04:29:41.077757 12834 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0506 04:29:41.079566 12834 solver.cpp:362] Iteration 4000, Testing net (#0)
I0506 04:29:41.079581 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:41.208688 12834 solver.cpp:429]     Test net output #0: accuracy = 0.226
I0506 04:29:41.208706 12834 solver.cpp:429]     Test net output #1: loss = 2.39849 (* 1 = 2.39849 loss)
I0506 04:29:41.211261 12834 solver.cpp:242] Iteration 4000 (83.9556 iter/s, 1.19111s/100 iter), loss = 2.3926
I0506 04:29:41.211282 12834 solver.cpp:261]     Train net output #0: loss = 2.3926 (* 1 = 2.3926 loss)
I0506 04:29:41.211289 12834 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0506 04:29:42.147552 12834 solver.cpp:242] Iteration 4100 (93.4778 iter/s, 1.06977s/100 iter), loss = 1.64651
I0506 04:29:42.147580 12834 solver.cpp:261]     Train net output #0: loss = 1.64651 (* 1 = 1.64651 loss)
I0506 04:29:42.147589 12834 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0506 04:29:42.152349 12834 solver.cpp:242] Iteration 4100 (106.264 iter/s, 0.941049s/100 iter), loss = 1.87058
I0506 04:29:42.152374 12834 solver.cpp:261]     Train net output #0: loss = 1.87058 (* 1 = 1.87058 loss)
I0506 04:29:42.152382 12834 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0506 04:29:43.086941 12834 solver.cpp:242] Iteration 4200 (106.458 iter/s, 0.939338s/100 iter), loss = 3.70948
I0506 04:29:43.086973 12834 solver.cpp:261]     Train net output #0: loss = 3.70948 (* 1 = 3.70948 loss)
I0506 04:29:43.086983 12834 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0506 04:29:43.091720 12834 solver.cpp:242] Iteration 4200 (106.459 iter/s, 0.939328s/100 iter), loss = 2.47741
I0506 04:29:43.091744 12834 solver.cpp:261]     Train net output #0: loss = 2.47741 (* 1 = 2.47741 loss)
I0506 04:29:43.091753 12834 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0506 04:29:44.027204 12834 solver.cpp:242] Iteration 4300 (106.36 iter/s, 0.940201s/100 iter), loss = 3.19879
I0506 04:29:44.027237 12834 solver.cpp:261]     Train net output #0: loss = 3.19879 (* 1 = 3.19879 loss)
I0506 04:29:44.027246 12834 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0506 04:29:44.031992 12834 solver.cpp:242] Iteration 4300 (106.357 iter/s, 0.940229s/100 iter), loss = 2.34167
I0506 04:29:44.032017 12834 solver.cpp:261]     Train net output #0: loss = 2.34167 (* 1 = 2.34167 loss)
I0506 04:29:44.032025 12834 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0506 04:29:44.967389 12834 solver.cpp:242] Iteration 4400 (106.368 iter/s, 0.94013s/100 iter), loss = 4.06907
I0506 04:29:44.967419 12834 solver.cpp:261]     Train net output #0: loss = 4.06907 (* 1 = 4.06907 loss)
I0506 04:29:44.967428 12834 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0506 04:29:44.972239 12834 solver.cpp:242] Iteration 4400 (106.361 iter/s, 0.940195s/100 iter), loss = 1.79231
I0506 04:29:44.972270 12834 solver.cpp:261]     Train net output #0: loss = 1.79231 (* 1 = 1.79231 loss)
I0506 04:29:44.972280 12834 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0506 04:29:45.904696 12834 solver.cpp:362] Iteration 4500, Testing net (#0)
I0506 04:29:45.904716 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:46.027670 12834 solver.cpp:429]     Test net output #0: loss = 4.37779 (* 1 = 4.37779 loss)
I0506 04:29:46.030196 12834 solver.cpp:242] Iteration 4500 (94.0948 iter/s, 1.06276s/100 iter), loss = 3.89521
I0506 04:29:46.030216 12834 solver.cpp:261]     Train net output #0: loss = 3.89521 (* 1 = 3.89521 loss)
I0506 04:29:46.030225 12834 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0506 04:29:46.032042 12834 solver.cpp:362] Iteration 4500, Testing net (#0)
I0506 04:29:46.032054 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:46.160938 12834 solver.cpp:429]     Test net output #0: accuracy = 0.319
I0506 04:29:46.160956 12834 solver.cpp:429]     Test net output #1: loss = 2.22012 (* 1 = 2.22012 loss)
I0506 04:29:46.163509 12834 solver.cpp:242] Iteration 4500 (83.9477 iter/s, 1.19122s/100 iter), loss = 2.06373
I0506 04:29:46.163528 12834 solver.cpp:261]     Train net output #0: loss = 2.06373 (* 1 = 2.06373 loss)
I0506 04:29:46.163537 12834 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0506 04:29:47.152704 12834 solver.cpp:242] Iteration 4600 (89.0899 iter/s, 1.12246s/100 iter), loss = 3.02171
I0506 04:29:47.152740 12834 solver.cpp:261]     Train net output #0: loss = 3.02171 (* 1 = 3.02171 loss)
I0506 04:29:47.152751 12834 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0506 04:29:47.158071 12834 solver.cpp:242] Iteration 4600 (100.552 iter/s, 0.994513s/100 iter), loss = 2.5089
I0506 04:29:47.158099 12834 solver.cpp:261]     Train net output #0: loss = 2.5089 (* 1 = 2.5089 loss)
I0506 04:29:47.158109 12834 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0506 04:29:48.184478 12834 solver.cpp:242] Iteration 4700 (96.9261 iter/s, 1.03171s/100 iter), loss = 6.80359
I0506 04:29:48.184505 12834 solver.cpp:261]     Train net output #0: loss = 6.80359 (* 1 = 6.80359 loss)
I0506 04:29:48.184515 12834 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0506 04:29:48.189251 12834 solver.cpp:242] Iteration 4700 (96.9806 iter/s, 1.03113s/100 iter), loss = 3.25201
I0506 04:29:48.189275 12834 solver.cpp:261]     Train net output #0: loss = 3.25201 (* 1 = 3.25201 loss)
I0506 04:29:48.189283 12834 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0506 04:29:49.124588 12834 solver.cpp:242] Iteration 4800 (106.378 iter/s, 0.940048s/100 iter), loss = 5.95265
I0506 04:29:49.124614 12834 solver.cpp:261]     Train net output #0: loss = 5.95265 (* 1 = 5.95265 loss)
I0506 04:29:49.124622 12834 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0506 04:29:49.129359 12834 solver.cpp:242] Iteration 4800 (106.375 iter/s, 0.940068s/100 iter), loss = 1.9019
I0506 04:29:49.129384 12834 solver.cpp:261]     Train net output #0: loss = 1.9019 (* 1 = 1.9019 loss)
I0506 04:29:49.129392 12834 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0506 04:29:50.065526 12834 solver.cpp:242] Iteration 4900 (106.283 iter/s, 0.940888s/100 iter), loss = 6.37089
I0506 04:29:50.065559 12834 solver.cpp:261]     Train net output #0: loss = 6.37089 (* 1 = 6.37089 loss)
I0506 04:29:50.065567 12834 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0506 04:29:50.070310 12834 solver.cpp:242] Iteration 4900 (106.28 iter/s, 0.940908s/100 iter), loss = 2.28203
I0506 04:29:50.070335 12834 solver.cpp:261]     Train net output #0: loss = 2.28203 (* 1 = 2.28203 loss)
I0506 04:29:50.070343 12834 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0506 04:29:51.015857 12834 solver.cpp:362] Iteration 5000, Testing net (#0)
I0506 04:29:51.015875 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:51.138742 12834 solver.cpp:429]     Test net output #0: loss = 4.15575 (* 1 = 4.15575 loss)
I0506 04:29:51.141257 12834 solver.cpp:242] Iteration 5000 (92.9646 iter/s, 1.07568s/100 iter), loss = 2.72776
I0506 04:29:51.141284 12834 solver.cpp:261]     Train net output #0: loss = 2.72776 (* 1 = 2.72776 loss)
I0506 04:29:51.141294 12834 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0506 04:29:51.143115 12834 solver.cpp:362] Iteration 5000, Testing net (#0)
I0506 04:29:51.143128 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:51.272172 12834 solver.cpp:429]     Test net output #0: accuracy = 0.305
I0506 04:29:51.272191 12834 solver.cpp:429]     Test net output #1: loss = 2.20702 (* 1 = 2.20702 loss)
I0506 04:29:51.274755 12834 solver.cpp:242] Iteration 5000 (83.0289 iter/s, 1.2044s/100 iter), loss = 1.92302
I0506 04:29:51.274775 12834 solver.cpp:261]     Train net output #0: loss = 1.92302 (* 1 = 1.92302 loss)
I0506 04:29:51.274785 12834 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0506 04:29:52.210000 12834 solver.cpp:242] Iteration 5100 (93.5724 iter/s, 1.06869s/100 iter), loss = 3.48688
I0506 04:29:52.210028 12834 solver.cpp:261]     Train net output #0: loss = 3.48688 (* 1 = 3.48688 loss)
I0506 04:29:52.210038 12834 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0506 04:29:52.214793 12834 solver.cpp:242] Iteration 5100 (106.383 iter/s, 0.939999s/100 iter), loss = 2.12772
I0506 04:29:52.214818 12834 solver.cpp:261]     Train net output #0: loss = 2.12772 (* 1 = 2.12772 loss)
I0506 04:29:52.214825 12834 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0506 04:29:53.150315 12834 solver.cpp:242] Iteration 5200 (106.354 iter/s, 0.94026s/100 iter), loss = 4.20513
I0506 04:29:53.150354 12834 solver.cpp:261]     Train net output #0: loss = 4.20513 (* 1 = 4.20513 loss)
I0506 04:29:53.150418 12834 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0506 04:29:53.155216 12834 solver.cpp:242] Iteration 5200 (106.34 iter/s, 0.940381s/100 iter), loss = 2.18841
I0506 04:29:53.155241 12834 solver.cpp:261]     Train net output #0: loss = 2.18841 (* 1 = 2.18841 loss)
I0506 04:29:53.155248 12834 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0506 04:29:54.091526 12834 solver.cpp:242] Iteration 5300 (106.253 iter/s, 0.941148s/100 iter), loss = 4.97942
I0506 04:29:54.091558 12834 solver.cpp:261]     Train net output #0: loss = 4.97942 (* 1 = 4.97942 loss)
I0506 04:29:54.091567 12834 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0506 04:29:54.096390 12834 solver.cpp:242] Iteration 5300 (106.256 iter/s, 0.941121s/100 iter), loss = 2.069
I0506 04:29:54.096415 12834 solver.cpp:261]     Train net output #0: loss = 2.069 (* 1 = 2.069 loss)
I0506 04:29:54.096423 12834 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0506 04:29:55.079427 12834 solver.cpp:242] Iteration 5400 (101.231 iter/s, 0.987842s/100 iter), loss = 2.27629
I0506 04:29:55.079463 12834 solver.cpp:261]     Train net output #0: loss = 2.27629 (* 1 = 2.27629 loss)
I0506 04:29:55.079473 12834 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0506 04:29:55.084698 12834 solver.cpp:242] Iteration 5400 (101.188 iter/s, 0.988264s/100 iter), loss = 1.73625
I0506 04:29:55.084728 12834 solver.cpp:261]     Train net output #0: loss = 1.73625 (* 1 = 1.73625 loss)
I0506 04:29:55.084738 12834 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0506 04:29:56.113631 12834 solver.cpp:362] Iteration 5500, Testing net (#0)
I0506 04:29:56.113654 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:56.247030 12834 solver.cpp:429]     Test net output #0: loss = 4.25945 (* 1 = 4.25945 loss)
I0506 04:29:56.249677 12834 solver.cpp:242] Iteration 5500 (85.4559 iter/s, 1.17019s/100 iter), loss = 3.67616
I0506 04:29:56.249702 12834 solver.cpp:261]     Train net output #0: loss = 3.67616 (* 1 = 3.67616 loss)
I0506 04:29:56.249712 12834 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0506 04:29:56.251982 12834 solver.cpp:362] Iteration 5500, Testing net (#0)
I0506 04:29:56.251997 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:29:56.393168 12834 solver.cpp:429]     Test net output #0: accuracy = 0.3245
I0506 04:29:56.393189 12834 solver.cpp:429]     Test net output #1: loss = 2.0896 (* 1 = 2.0896 loss)
I0506 04:29:56.395887 12834 solver.cpp:242] Iteration 5500 (76.2696 iter/s, 1.31114s/100 iter), loss = 1.87596
I0506 04:29:56.395921 12834 solver.cpp:261]     Train net output #0: loss = 1.87596 (* 1 = 1.87596 loss)
I0506 04:29:56.395932 12834 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0506 04:29:57.339267 12834 solver.cpp:242] Iteration 5600 (91.7819 iter/s, 1.08954s/100 iter), loss = 3.65484
I0506 04:29:57.339293 12834 solver.cpp:261]     Train net output #0: loss = 3.65484 (* 1 = 3.65484 loss)
I0506 04:29:57.339303 12834 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0506 04:29:57.344102 12834 solver.cpp:242] Iteration 5600 (105.467 iter/s, 0.948163s/100 iter), loss = 2.41392
I0506 04:29:57.344126 12834 solver.cpp:261]     Train net output #0: loss = 2.41392 (* 1 = 2.41392 loss)
I0506 04:29:57.344135 12834 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0506 04:29:58.281188 12834 solver.cpp:242] Iteration 5700 (106.172 iter/s, 0.941867s/100 iter), loss = 3.66288
I0506 04:29:58.281215 12834 solver.cpp:261]     Train net output #0: loss = 3.66288 (* 1 = 3.66288 loss)
I0506 04:29:58.281224 12834 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0506 04:29:58.285950 12834 solver.cpp:242] Iteration 5700 (106.179 iter/s, 0.941806s/100 iter), loss = 2.13292
I0506 04:29:58.285974 12834 solver.cpp:261]     Train net output #0: loss = 2.13292 (* 1 = 2.13292 loss)
I0506 04:29:58.285981 12834 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0506 04:29:59.221314 12834 solver.cpp:242] Iteration 5800 (106.374 iter/s, 0.940076s/100 iter), loss = 3.90305
I0506 04:29:59.221341 12834 solver.cpp:261]     Train net output #0: loss = 3.90305 (* 1 = 3.90305 loss)
I0506 04:29:59.221350 12834 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0506 04:29:59.226088 12834 solver.cpp:242] Iteration 5800 (106.372 iter/s, 0.940095s/100 iter), loss = 2.22195
I0506 04:29:59.226110 12834 solver.cpp:261]     Train net output #0: loss = 2.22195 (* 1 = 2.22195 loss)
I0506 04:29:59.226119 12834 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0506 04:30:00.162230 12834 solver.cpp:242] Iteration 5900 (106.286 iter/s, 0.940856s/100 iter), loss = 3.42363
I0506 04:30:00.162262 12834 solver.cpp:261]     Train net output #0: loss = 3.42363 (* 1 = 3.42363 loss)
I0506 04:30:00.162271 12834 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0506 04:30:00.167009 12834 solver.cpp:242] Iteration 5900 (106.283 iter/s, 0.94088s/100 iter), loss = 1.86336
I0506 04:30:00.167034 12834 solver.cpp:261]     Train net output #0: loss = 1.86336 (* 1 = 1.86336 loss)
I0506 04:30:00.167043 12834 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0506 04:30:01.108217 12834 solver.cpp:362] Iteration 6000, Testing net (#0)
I0506 04:30:01.108237 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:01.232055 12834 solver.cpp:429]     Test net output #0: loss = 4.64166 (* 1 = 4.64166 loss)
I0506 04:30:01.234586 12834 solver.cpp:242] Iteration 6000 (93.2573 iter/s, 1.0723s/100 iter), loss = 6.39488
I0506 04:30:01.234606 12834 solver.cpp:261]     Train net output #0: loss = 6.39488 (* 1 = 6.39488 loss)
I0506 04:30:01.234614 12834 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0506 04:30:01.236474 12834 solver.cpp:362] Iteration 6000, Testing net (#0)
I0506 04:30:01.236487 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:01.366550 12834 solver.cpp:429]     Test net output #0: accuracy = 0.3025
I0506 04:30:01.366569 12834 solver.cpp:429]     Test net output #1: loss = 2.03548 (* 1 = 2.03548 loss)
I0506 04:30:01.369158 12834 solver.cpp:242] Iteration 6000 (83.1877 iter/s, 1.2021s/100 iter), loss = 2.10444
I0506 04:30:01.369177 12834 solver.cpp:261]     Train net output #0: loss = 2.10444 (* 1 = 2.10444 loss)
I0506 04:30:01.369186 12834 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0506 04:30:02.315460 12834 solver.cpp:242] Iteration 6100 (92.522 iter/s, 1.08082s/100 iter), loss = 3.03823
I0506 04:30:02.315491 12834 solver.cpp:261]     Train net output #0: loss = 3.03823 (* 1 = 3.03823 loss)
I0506 04:30:02.315501 12834 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0506 04:30:02.320343 12834 solver.cpp:242] Iteration 6100 (105.136 iter/s, 0.951147s/100 iter), loss = 1.91941
I0506 04:30:02.320377 12834 solver.cpp:261]     Train net output #0: loss = 1.91941 (* 1 = 1.91941 loss)
I0506 04:30:02.320386 12834 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0506 04:30:03.279018 12834 solver.cpp:242] Iteration 6200 (103.788 iter/s, 0.963503s/100 iter), loss = 5.08488
I0506 04:30:03.279057 12834 solver.cpp:261]     Train net output #0: loss = 5.08488 (* 1 = 5.08488 loss)
I0506 04:30:03.279121 12834 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0506 04:30:03.283996 12834 solver.cpp:242] Iteration 6200 (103.778 iter/s, 0.963591s/100 iter), loss = 1.99907
I0506 04:30:03.284023 12834 solver.cpp:261]     Train net output #0: loss = 1.99907 (* 1 = 1.99907 loss)
I0506 04:30:03.284031 12834 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0506 04:30:04.221711 12834 solver.cpp:242] Iteration 6300 (106.086 iter/s, 0.942631s/100 iter), loss = 2.02037
I0506 04:30:04.221745 12834 solver.cpp:261]     Train net output #0: loss = 2.02037 (* 1 = 2.02037 loss)
I0506 04:30:04.221755 12834 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0506 04:30:04.226491 12834 solver.cpp:242] Iteration 6300 (106.106 iter/s, 0.94245s/100 iter), loss = 2.22998
I0506 04:30:04.226516 12834 solver.cpp:261]     Train net output #0: loss = 2.22998 (* 1 = 2.22998 loss)
I0506 04:30:04.226524 12834 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0506 04:30:05.162065 12834 solver.cpp:242] Iteration 6400 (106.349 iter/s, 0.940297s/100 iter), loss = 4.20893
I0506 04:30:05.162096 12834 solver.cpp:261]     Train net output #0: loss = 4.20893 (* 1 = 4.20893 loss)
I0506 04:30:05.162103 12834 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0506 04:30:05.166929 12834 solver.cpp:242] Iteration 6400 (106.339 iter/s, 0.940386s/100 iter), loss = 1.99764
I0506 04:30:05.166954 12834 solver.cpp:261]     Train net output #0: loss = 1.99764 (* 1 = 1.99764 loss)
I0506 04:30:05.166962 12834 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0506 04:30:06.098917 12834 solver.cpp:362] Iteration 6500, Testing net (#0)
I0506 04:30:06.098937 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:06.221765 12834 solver.cpp:429]     Test net output #0: loss = 4.08502 (* 1 = 4.08502 loss)
I0506 04:30:06.224280 12834 solver.cpp:242] Iteration 6500 (94.1473 iter/s, 1.06217s/100 iter), loss = 5.28991
I0506 04:30:06.224300 12834 solver.cpp:261]     Train net output #0: loss = 5.28991 (* 1 = 5.28991 loss)
I0506 04:30:06.224309 12834 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0506 04:30:06.226125 12834 solver.cpp:362] Iteration 6500, Testing net (#0)
I0506 04:30:06.226138 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:06.355008 12834 solver.cpp:429]     Test net output #0: accuracy = 0.373
I0506 04:30:06.355026 12834 solver.cpp:429]     Test net output #1: loss = 1.87394 (* 1 = 1.87394 loss)
I0506 04:30:06.357578 12834 solver.cpp:242] Iteration 6500 (83.9909 iter/s, 1.1906s/100 iter), loss = 1.80046
I0506 04:30:06.357599 12834 solver.cpp:261]     Train net output #0: loss = 1.80046 (* 1 = 1.80046 loss)
I0506 04:30:06.357607 12834 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0506 04:30:07.365929 12834 solver.cpp:242] Iteration 6600 (87.5967 iter/s, 1.1416s/100 iter), loss = 5.53116
I0506 04:30:07.365962 12834 solver.cpp:261]     Train net output #0: loss = 5.53116 (* 1 = 5.53116 loss)
I0506 04:30:07.365974 12834 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0506 04:30:07.371203 12834 solver.cpp:242] Iteration 6600 (98.6599 iter/s, 1.01358s/100 iter), loss = 1.71877
I0506 04:30:07.371230 12834 solver.cpp:261]     Train net output #0: loss = 1.71877 (* 1 = 1.71877 loss)
I0506 04:30:07.371242 12834 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0506 04:30:08.394012 12834 solver.cpp:242] Iteration 6700 (97.2738 iter/s, 1.02803s/100 iter), loss = 6.3941
I0506 04:30:08.394040 12834 solver.cpp:261]     Train net output #0: loss = 6.3941 (* 1 = 6.3941 loss)
I0506 04:30:08.394049 12834 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0506 04:30:08.398809 12834 solver.cpp:242] Iteration 6700 (97.318 iter/s, 1.02756s/100 iter), loss = 1.86416
I0506 04:30:08.398846 12834 solver.cpp:261]     Train net output #0: loss = 1.86416 (* 1 = 1.86416 loss)
I0506 04:30:08.398856 12834 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0506 04:30:09.333801 12834 solver.cpp:242] Iteration 6800 (106.413 iter/s, 0.939734s/100 iter), loss = 7.74346
I0506 04:30:09.333830 12834 solver.cpp:261]     Train net output #0: loss = 7.74346 (* 1 = 7.74346 loss)
I0506 04:30:09.333839 12834 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0506 04:30:09.338574 12834 solver.cpp:242] Iteration 6800 (106.416 iter/s, 0.939709s/100 iter), loss = 1.74501
I0506 04:30:09.338598 12834 solver.cpp:261]     Train net output #0: loss = 1.74501 (* 1 = 1.74501 loss)
I0506 04:30:09.338605 12834 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0506 04:30:10.273557 12834 solver.cpp:242] Iteration 6900 (106.416 iter/s, 0.939704s/100 iter), loss = 2.47417
I0506 04:30:10.273586 12834 solver.cpp:261]     Train net output #0: loss = 2.47417 (* 1 = 2.47417 loss)
I0506 04:30:10.273594 12834 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0506 04:30:10.278311 12834 solver.cpp:242] Iteration 6900 (106.418 iter/s, 0.939694s/100 iter), loss = 1.47993
I0506 04:30:10.278334 12834 solver.cpp:261]     Train net output #0: loss = 1.47993 (* 1 = 1.47993 loss)
I0506 04:30:10.278342 12834 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0506 04:30:11.226269 12834 solver.cpp:362] Iteration 7000, Testing net (#0)
I0506 04:30:11.226287 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:11.349280 12834 solver.cpp:429]     Test net output #0: loss = 4.1781 (* 1 = 4.1781 loss)
I0506 04:30:11.351799 12834 solver.cpp:242] Iteration 7000 (92.7478 iter/s, 1.07819s/100 iter), loss = 5.19885
I0506 04:30:11.351819 12834 solver.cpp:261]     Train net output #0: loss = 5.19885 (* 1 = 5.19885 loss)
I0506 04:30:11.351826 12834 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0506 04:30:11.353646 12834 solver.cpp:362] Iteration 7000, Testing net (#0)
I0506 04:30:11.353659 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:11.482967 12834 solver.cpp:429]     Test net output #0: accuracy = 0.4085
I0506 04:30:11.482986 12834 solver.cpp:429]     Test net output #1: loss = 1.7798 (* 1 = 1.7798 loss)
I0506 04:30:11.485536 12834 solver.cpp:242] Iteration 7000 (82.8376 iter/s, 1.20718s/100 iter), loss = 2.03939
I0506 04:30:11.485558 12834 solver.cpp:261]     Train net output #0: loss = 2.03939 (* 1 = 2.03939 loss)
I0506 04:30:11.485565 12834 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0506 04:30:12.507848 12834 solver.cpp:242] Iteration 7100 (86.5051 iter/s, 1.156s/100 iter), loss = 3.10609
I0506 04:30:12.507884 12834 solver.cpp:261]     Train net output #0: loss = 3.10609 (* 1 = 3.10609 loss)
I0506 04:30:12.507894 12834 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0506 04:30:12.513124 12834 solver.cpp:242] Iteration 7100 (97.3192 iter/s, 1.02755s/100 iter), loss = 2.12196
I0506 04:30:12.513152 12834 solver.cpp:261]     Train net output #0: loss = 2.12196 (* 1 = 2.12196 loss)
I0506 04:30:12.513164 12834 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0506 04:30:13.530935 12834 solver.cpp:242] Iteration 7200 (97.7494 iter/s, 1.02302s/100 iter), loss = 4.2975
I0506 04:30:13.530969 12834 solver.cpp:261]     Train net output #0: loss = 4.2975 (* 1 = 4.2975 loss)
I0506 04:30:13.530979 12834 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0506 04:30:13.535735 12834 solver.cpp:242] Iteration 7200 (97.7934 iter/s, 1.02256s/100 iter), loss = 1.74525
I0506 04:30:13.535759 12834 solver.cpp:261]     Train net output #0: loss = 1.74525 (* 1 = 1.74525 loss)
I0506 04:30:13.535768 12834 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0506 04:30:14.471518 12834 solver.cpp:242] Iteration 7300 (106.323 iter/s, 0.940527s/100 iter), loss = 6.39642
I0506 04:30:14.471551 12834 solver.cpp:261]     Train net output #0: loss = 6.39642 (* 1 = 6.39642 loss)
I0506 04:30:14.471560 12834 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0506 04:30:14.476377 12834 solver.cpp:242] Iteration 7300 (106.316 iter/s, 0.940591s/100 iter), loss = 1.81877
I0506 04:30:14.476410 12834 solver.cpp:261]     Train net output #0: loss = 1.81877 (* 1 = 1.81877 loss)
I0506 04:30:14.476420 12834 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0506 04:30:15.412055 12834 solver.cpp:242] Iteration 7400 (106.329 iter/s, 0.940478s/100 iter), loss = 5.07013
I0506 04:30:15.412087 12834 solver.cpp:261]     Train net output #0: loss = 5.07013 (* 1 = 5.07013 loss)
I0506 04:30:15.412096 12834 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0506 04:30:15.416836 12834 solver.cpp:242] Iteration 7400 (106.337 iter/s, 0.940408s/100 iter), loss = 1.55614
I0506 04:30:15.416862 12834 solver.cpp:261]     Train net output #0: loss = 1.55614 (* 1 = 1.55614 loss)
I0506 04:30:15.416870 12834 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0506 04:30:16.348821 12834 solver.cpp:362] Iteration 7500, Testing net (#0)
I0506 04:30:16.348839 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:16.471889 12834 solver.cpp:429]     Test net output #0: loss = 3.96582 (* 1 = 3.96582 loss)
I0506 04:30:16.474406 12834 solver.cpp:242] Iteration 7500 (94.1353 iter/s, 1.0623s/100 iter), loss = 2.71084
I0506 04:30:16.474426 12834 solver.cpp:261]     Train net output #0: loss = 2.71084 (* 1 = 2.71084 loss)
I0506 04:30:16.474434 12834 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0506 04:30:16.476269 12834 solver.cpp:362] Iteration 7500, Testing net (#0)
I0506 04:30:16.476281 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:16.605767 12834 solver.cpp:429]     Test net output #0: accuracy = 0.422
I0506 04:30:16.605785 12834 solver.cpp:429]     Test net output #1: loss = 1.69976 (* 1 = 1.69976 loss)
I0506 04:30:16.608358 12834 solver.cpp:242] Iteration 7500 (83.9296 iter/s, 1.19148s/100 iter), loss = 1.55272
I0506 04:30:16.608378 12834 solver.cpp:261]     Train net output #0: loss = 1.55272 (* 1 = 1.55272 loss)
I0506 04:30:16.608386 12834 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0506 04:30:17.544157 12834 solver.cpp:242] Iteration 7600 (93.4836 iter/s, 1.06971s/100 iter), loss = 2.58637
I0506 04:30:17.544184 12834 solver.cpp:261]     Train net output #0: loss = 2.58637 (* 1 = 2.58637 loss)
I0506 04:30:17.544193 12834 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0506 04:30:17.548918 12834 solver.cpp:242] Iteration 7600 (106.324 iter/s, 0.94052s/100 iter), loss = 2.21501
I0506 04:30:17.548941 12834 solver.cpp:261]     Train net output #0: loss = 2.21501 (* 1 = 2.21501 loss)
I0506 04:30:17.548950 12834 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0506 04:30:18.484309 12834 solver.cpp:242] Iteration 7700 (106.372 iter/s, 0.940097s/100 iter), loss = 4.19943
I0506 04:30:18.484339 12834 solver.cpp:261]     Train net output #0: loss = 4.19943 (* 1 = 4.19943 loss)
I0506 04:30:18.484349 12834 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0506 04:30:18.489080 12834 solver.cpp:242] Iteration 7700 (106.369 iter/s, 0.94012s/100 iter), loss = 1.65155
I0506 04:30:18.489104 12834 solver.cpp:261]     Train net output #0: loss = 1.65155 (* 1 = 1.65155 loss)
I0506 04:30:18.489114 12834 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0506 04:30:19.474536 12834 solver.cpp:242] Iteration 7800 (100.992 iter/s, 0.990173s/100 iter), loss = 5.04289
I0506 04:30:19.474568 12834 solver.cpp:261]     Train net output #0: loss = 5.04289 (* 1 = 5.04289 loss)
I0506 04:30:19.474577 12834 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0506 04:30:19.479308 12834 solver.cpp:242] Iteration 7800 (100.991 iter/s, 0.990183s/100 iter), loss = 1.57678
I0506 04:30:19.479332 12834 solver.cpp:261]     Train net output #0: loss = 1.57678 (* 1 = 1.57678 loss)
I0506 04:30:19.479341 12834 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0506 04:30:20.414892 12834 solver.cpp:242] Iteration 7900 (106.349 iter/s, 0.940298s/100 iter), loss = 6.61063
I0506 04:30:20.414922 12834 solver.cpp:261]     Train net output #0: loss = 6.61063 (* 1 = 6.61063 loss)
I0506 04:30:20.414932 12834 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0506 04:30:20.419674 12834 solver.cpp:242] Iteration 7900 (106.346 iter/s, 0.940323s/100 iter), loss = 1.53746
I0506 04:30:20.419706 12834 solver.cpp:261]     Train net output #0: loss = 1.53746 (* 1 = 1.53746 loss)
I0506 04:30:20.419716 12834 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0506 04:30:21.352056 12834 solver.cpp:362] Iteration 8000, Testing net (#0)
I0506 04:30:21.352075 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:21.475312 12834 solver.cpp:429]     Test net output #0: loss = 3.7368 (* 1 = 3.7368 loss)
I0506 04:30:21.477870 12834 solver.cpp:242] Iteration 8000 (94.0798 iter/s, 1.06293s/100 iter), loss = 5.44105
I0506 04:30:21.477891 12834 solver.cpp:261]     Train net output #0: loss = 5.44105 (* 1 = 5.44105 loss)
I0506 04:30:21.477900 12834 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0506 04:30:21.479754 12834 solver.cpp:362] Iteration 8000, Testing net (#0)
I0506 04:30:21.479766 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:21.608831 12834 solver.cpp:429]     Test net output #0: accuracy = 0.4365
I0506 04:30:21.608850 12834 solver.cpp:429]     Test net output #1: loss = 1.65605 (* 1 = 1.65605 loss)
I0506 04:30:21.611435 12834 solver.cpp:242] Iteration 8000 (83.9131 iter/s, 1.19171s/100 iter), loss = 1.54428
I0506 04:30:21.611455 12834 solver.cpp:261]     Train net output #0: loss = 1.54428 (* 1 = 1.54428 loss)
I0506 04:30:21.611464 12834 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0506 04:30:22.546870 12834 solver.cpp:242] Iteration 8100 (93.5497 iter/s, 1.06895s/100 iter), loss = 4.07994
I0506 04:30:22.546901 12834 solver.cpp:261]     Train net output #0: loss = 4.07994 (* 1 = 4.07994 loss)
I0506 04:30:22.546911 12834 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0506 04:30:22.551661 12834 solver.cpp:242] Iteration 8100 (106.362 iter/s, 0.940188s/100 iter), loss = 1.75679
I0506 04:30:22.551687 12834 solver.cpp:261]     Train net output #0: loss = 1.75679 (* 1 = 1.75679 loss)
I0506 04:30:22.551695 12834 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0506 04:30:23.580696 12834 solver.cpp:242] Iteration 8200 (96.7331 iter/s, 1.03377s/100 iter), loss = 4.94505
I0506 04:30:23.580737 12834 solver.cpp:261]     Train net output #0: loss = 4.94505 (* 1 = 4.94505 loss)
I0506 04:30:23.580749 12834 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0506 04:30:23.586071 12834 solver.cpp:242] Iteration 8200 (96.6786 iter/s, 1.03435s/100 iter), loss = 1.64964
I0506 04:30:23.586099 12834 solver.cpp:261]     Train net output #0: loss = 1.64964 (* 1 = 1.64964 loss)
I0506 04:30:23.586110 12834 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0506 04:30:24.597463 12834 solver.cpp:242] Iteration 8300 (98.3572 iter/s, 1.0167s/100 iter), loss = 2.76333
I0506 04:30:24.597491 12834 solver.cpp:261]     Train net output #0: loss = 2.76333 (* 1 = 2.76333 loss)
I0506 04:30:24.597501 12834 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0506 04:30:24.602246 12834 solver.cpp:242] Iteration 8300 (98.4127 iter/s, 1.01613s/100 iter), loss = 2.11165
I0506 04:30:24.602269 12834 solver.cpp:261]     Train net output #0: loss = 2.11165 (* 1 = 2.11165 loss)
I0506 04:30:24.602277 12834 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0506 04:30:25.537786 12834 solver.cpp:242] Iteration 8400 (106.353 iter/s, 0.940265s/100 iter), loss = 1.22037
I0506 04:30:25.537813 12834 solver.cpp:261]     Train net output #0: loss = 1.22037 (* 1 = 1.22037 loss)
I0506 04:30:25.537822 12834 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0506 04:30:25.542570 12834 solver.cpp:242] Iteration 8400 (106.351 iter/s, 0.940283s/100 iter), loss = 1.34768
I0506 04:30:25.542594 12834 solver.cpp:261]     Train net output #0: loss = 1.34768 (* 1 = 1.34768 loss)
I0506 04:30:25.542603 12834 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0506 04:30:26.475958 12834 solver.cpp:362] Iteration 8500, Testing net (#0)
I0506 04:30:26.475986 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:26.600731 12834 solver.cpp:429]     Test net output #0: loss = 3.79014 (* 1 = 3.79014 loss)
I0506 04:30:26.603374 12834 solver.cpp:242] Iteration 8500 (93.8492 iter/s, 1.06554s/100 iter), loss = 6.09475
I0506 04:30:26.603406 12834 solver.cpp:261]     Train net output #0: loss = 6.09475 (* 1 = 6.09475 loss)
I0506 04:30:26.603417 12834 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0506 04:30:26.605607 12834 solver.cpp:362] Iteration 8500, Testing net (#0)
I0506 04:30:26.605623 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:26.744676 12834 solver.cpp:429]     Test net output #0: accuracy = 0.4345
I0506 04:30:26.744696 12834 solver.cpp:429]     Test net output #1: loss = 1.64662 (* 1 = 1.64662 loss)
I0506 04:30:26.747253 12834 solver.cpp:242] Iteration 8500 (83.0125 iter/s, 1.20464s/100 iter), loss = 1.16995
I0506 04:30:26.747272 12834 solver.cpp:261]     Train net output #0: loss = 1.16995 (* 1 = 1.16995 loss)
I0506 04:30:26.747280 12834 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0506 04:30:27.683079 12834 solver.cpp:242] Iteration 8600 (92.6234 iter/s, 1.07964s/100 iter), loss = 3.19649
I0506 04:30:27.683115 12834 solver.cpp:261]     Train net output #0: loss = 3.19649 (* 1 = 3.19649 loss)
I0506 04:30:27.683125 12834 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0506 04:30:27.687865 12834 solver.cpp:242] Iteration 8600 (106.318 iter/s, 0.940574s/100 iter), loss = 1.83919
I0506 04:30:27.687891 12834 solver.cpp:261]     Train net output #0: loss = 1.83919 (* 1 = 1.83919 loss)
I0506 04:30:27.687899 12834 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0506 04:30:28.623164 12834 solver.cpp:242] Iteration 8700 (106.38 iter/s, 0.940027s/100 iter), loss = 5.7953
I0506 04:30:28.623195 12834 solver.cpp:261]     Train net output #0: loss = 5.7953 (* 1 = 5.7953 loss)
I0506 04:30:28.623204 12834 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0506 04:30:28.627938 12834 solver.cpp:242] Iteration 8700 (106.38 iter/s, 0.940029s/100 iter), loss = 1.81287
I0506 04:30:28.627964 12834 solver.cpp:261]     Train net output #0: loss = 1.81287 (* 1 = 1.81287 loss)
I0506 04:30:28.627971 12834 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0506 04:30:29.582909 12834 solver.cpp:242] Iteration 8800 (104.201 iter/s, 0.959681s/100 iter), loss = 3.059
I0506 04:30:29.582952 12834 solver.cpp:261]     Train net output #0: loss = 3.059 (* 1 = 3.059 loss)
I0506 04:30:29.582960 12834 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0506 04:30:29.587733 12834 solver.cpp:242] Iteration 8800 (104.194 iter/s, 0.959751s/100 iter), loss = 1.68506
I0506 04:30:29.587761 12834 solver.cpp:261]     Train net output #0: loss = 1.68506 (* 1 = 1.68506 loss)
I0506 04:30:29.587769 12834 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0506 04:30:30.523692 12834 solver.cpp:242] Iteration 8900 (106.302 iter/s, 0.940717s/100 iter), loss = 6.06853
I0506 04:30:30.523736 12834 solver.cpp:261]     Train net output #0: loss = 6.06853 (* 1 = 6.06853 loss)
I0506 04:30:30.523744 12834 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0506 04:30:30.528470 12834 solver.cpp:242] Iteration 8900 (106.305 iter/s, 0.940689s/100 iter), loss = 1.77731
I0506 04:30:30.528493 12834 solver.cpp:261]     Train net output #0: loss = 1.77731 (* 1 = 1.77731 loss)
I0506 04:30:30.528502 12834 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0506 04:30:31.461110 12834 solver.cpp:362] Iteration 9000, Testing net (#0)
I0506 04:30:31.461130 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:31.583963 12834 solver.cpp:429]     Test net output #0: loss = 3.86879 (* 1 = 3.86879 loss)
I0506 04:30:31.586501 12834 solver.cpp:242] Iteration 9000 (94.0957 iter/s, 1.06275s/100 iter), loss = 5.47712
I0506 04:30:31.586521 12834 solver.cpp:261]     Train net output #0: loss = 5.47712 (* 1 = 5.47712 loss)
I0506 04:30:31.586529 12834 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0506 04:30:31.588367 12834 solver.cpp:362] Iteration 9000, Testing net (#0)
I0506 04:30:31.588380 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:31.717272 12834 solver.cpp:429]     Test net output #0: accuracy = 0.4635
I0506 04:30:31.717290 12834 solver.cpp:429]     Test net output #1: loss = 1.56417 (* 1 = 1.56417 loss)
I0506 04:30:31.719849 12834 solver.cpp:242] Iteration 9000 (83.9395 iter/s, 1.19133s/100 iter), loss = 1.40531
I0506 04:30:31.719877 12834 solver.cpp:261]     Train net output #0: loss = 1.40531 (* 1 = 1.40531 loss)
I0506 04:30:31.719887 12834 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I0506 04:30:32.655287 12834 solver.cpp:242] Iteration 9100 (93.568 iter/s, 1.06874s/100 iter), loss = 7.4809
I0506 04:30:32.655318 12834 solver.cpp:261]     Train net output #0: loss = 7.4809 (* 1 = 7.4809 loss)
I0506 04:30:32.655328 12834 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0506 04:30:32.660148 12834 solver.cpp:242] Iteration 9100 (106.355 iter/s, 0.940243s/100 iter), loss = 1.24983
I0506 04:30:32.660173 12834 solver.cpp:261]     Train net output #0: loss = 1.24983 (* 1 = 1.24983 loss)
I0506 04:30:32.660182 12834 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I0506 04:30:33.596586 12834 solver.cpp:242] Iteration 9200 (106.242 iter/s, 0.941244s/100 iter), loss = 4.72879
I0506 04:30:33.596612 12834 solver.cpp:261]     Train net output #0: loss = 4.72879 (* 1 = 4.72879 loss)
I0506 04:30:33.596621 12834 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0506 04:30:33.601358 12834 solver.cpp:242] Iteration 9200 (106.251 iter/s, 0.941167s/100 iter), loss = 1.77889
I0506 04:30:33.601382 12834 solver.cpp:261]     Train net output #0: loss = 1.77889 (* 1 = 1.77889 loss)
I0506 04:30:33.601390 12834 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I0506 04:30:34.540477 12834 solver.cpp:242] Iteration 9300 (105.95 iter/s, 0.943837s/100 iter), loss = 4.53261
I0506 04:30:34.540526 12834 solver.cpp:261]     Train net output #0: loss = 4.53261 (* 1 = 4.53261 loss)
I0506 04:30:34.540535 12834 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0506 04:30:34.545327 12834 solver.cpp:242] Iteration 9300 (105.942 iter/s, 0.943917s/100 iter), loss = 1.34881
I0506 04:30:34.545356 12834 solver.cpp:261]     Train net output #0: loss = 1.34881 (* 1 = 1.34881 loss)
I0506 04:30:34.545364 12834 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I0506 04:30:35.635053 12834 solver.cpp:242] Iteration 9400 (91.3668 iter/s, 1.09449s/100 iter), loss = 4.80113
I0506 04:30:35.635103 12834 solver.cpp:261]     Train net output #0: loss = 4.80113 (* 1 = 4.80113 loss)
I0506 04:30:35.635114 12834 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0506 04:30:35.640004 12834 solver.cpp:242] Iteration 9400 (91.3555 iter/s, 1.09463s/100 iter), loss = 1.26522
I0506 04:30:35.640039 12834 solver.cpp:261]     Train net output #0: loss = 1.26522 (* 1 = 1.26522 loss)
I0506 04:30:35.640049 12834 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I0506 04:30:36.663532 12834 solver.cpp:362] Iteration 9500, Testing net (#0)
I0506 04:30:36.663568 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:36.788166 12834 solver.cpp:429]     Test net output #0: loss = 3.66928 (* 1 = 3.66928 loss)
I0506 04:30:36.790789 12834 solver.cpp:242] Iteration 9500 (86.5302 iter/s, 1.15567s/100 iter), loss = 3.20098
I0506 04:30:36.790812 12834 solver.cpp:261]     Train net output #0: loss = 3.20098 (* 1 = 3.20098 loss)
I0506 04:30:36.790822 12834 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0506 04:30:36.792865 12834 solver.cpp:362] Iteration 9500, Testing net (#0)
I0506 04:30:36.792889 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:36.923467 12834 solver.cpp:429]     Test net output #0: accuracy = 0.455
I0506 04:30:36.923485 12834 solver.cpp:429]     Test net output #1: loss = 1.51899 (* 1 = 1.51899 loss)
I0506 04:30:36.926203 12834 solver.cpp:242] Iteration 9500 (77.7519 iter/s, 1.28614s/100 iter), loss = 1.45289
I0506 04:30:36.926224 12834 solver.cpp:261]     Train net output #0: loss = 1.45289 (* 1 = 1.45289 loss)
I0506 04:30:36.926234 12834 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I0506 04:30:37.874743 12834 solver.cpp:242] Iteration 9600 (92.2593 iter/s, 1.0839s/100 iter), loss = 3.52623
I0506 04:30:37.874788 12834 solver.cpp:261]     Train net output #0: loss = 3.52623 (* 1 = 3.52623 loss)
I0506 04:30:37.874797 12834 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0506 04:30:37.879530 12834 solver.cpp:242] Iteration 9600 (104.9 iter/s, 0.953288s/100 iter), loss = 1.56498
I0506 04:30:37.879565 12834 solver.cpp:261]     Train net output #0: loss = 1.56498 (* 1 = 1.56498 loss)
I0506 04:30:37.879575 12834 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I0506 04:30:38.828033 12834 solver.cpp:242] Iteration 9700 (104.908 iter/s, 0.953215s/100 iter), loss = 3.06941
I0506 04:30:38.828073 12834 solver.cpp:261]     Train net output #0: loss = 3.06941 (* 1 = 3.06941 loss)
I0506 04:30:38.828083 12834 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0506 04:30:38.832859 12834 solver.cpp:242] Iteration 9700 (104.901 iter/s, 0.953276s/100 iter), loss = 1.53005
I0506 04:30:38.832885 12834 solver.cpp:261]     Train net output #0: loss = 1.53005 (* 1 = 1.53005 loss)
I0506 04:30:38.832893 12834 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I0506 04:30:39.768728 12834 solver.cpp:242] Iteration 9800 (106.312 iter/s, 0.940629s/100 iter), loss = 5.22025
I0506 04:30:39.768767 12834 solver.cpp:261]     Train net output #0: loss = 5.22025 (* 1 = 5.22025 loss)
I0506 04:30:39.768776 12834 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0506 04:30:39.773530 12834 solver.cpp:242] Iteration 9800 (106.312 iter/s, 0.940627s/100 iter), loss = 1.5747
I0506 04:30:39.773557 12834 solver.cpp:261]     Train net output #0: loss = 1.5747 (* 1 = 1.5747 loss)
I0506 04:30:39.773566 12834 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I0506 04:30:40.708693 12834 solver.cpp:242] Iteration 9900 (106.395 iter/s, 0.939894s/100 iter), loss = 3.93861
I0506 04:30:40.708731 12834 solver.cpp:261]     Train net output #0: loss = 3.93861 (* 1 = 3.93861 loss)
I0506 04:30:40.708740 12834 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0506 04:30:40.713466 12834 solver.cpp:242] Iteration 9900 (106.395 iter/s, 0.939891s/100 iter), loss = 1.84367
I0506 04:30:40.713490 12834 solver.cpp:261]     Train net output #0: loss = 1.84367 (* 1 = 1.84367 loss)
I0506 04:30:40.713500 12834 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I0506 04:30:41.646072 12834 solver.cpp:362] Iteration 10000, Testing net (#0)
I0506 04:30:41.646096 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:41.769210 12834 solver.cpp:429]     Test net output #0: loss = 3.58857 (* 1 = 3.58857 loss)
I0506 04:30:41.771733 12834 solver.cpp:242] Iteration 10000 (94.0751 iter/s, 1.06298s/100 iter), loss = 2.13947
I0506 04:30:41.771755 12834 solver.cpp:261]     Train net output #0: loss = 2.13947 (* 1 = 2.13947 loss)
I0506 04:30:41.771764 12834 sgd_solver.cpp:106] Iteration 10000, lr = 8e-05
I0506 04:30:41.773669 12834 solver.cpp:362] Iteration 10000, Testing net (#0)
I0506 04:30:41.773682 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:41.902660 12834 solver.cpp:429]     Test net output #0: accuracy = 0.4365
I0506 04:30:41.902679 12834 solver.cpp:429]     Test net output #1: loss = 1.56273 (* 1 = 1.56273 loss)
I0506 04:30:41.905233 12834 solver.cpp:242] Iteration 10000 (83.9123 iter/s, 1.19172s/100 iter), loss = 1.38896
I0506 04:30:41.905253 12834 solver.cpp:261]     Train net output #0: loss = 1.38896 (* 1 = 1.38896 loss)
I0506 04:30:41.905261 12834 sgd_solver.cpp:106] Iteration 10000, lr = 8e-05
I0506 04:30:42.867987 12834 solver.cpp:242] Iteration 10100 (91.2242 iter/s, 1.0962s/100 iter), loss = 3.40163
I0506 04:30:42.868029 12834 solver.cpp:261]     Train net output #0: loss = 3.40163 (* 1 = 3.40163 loss)
I0506 04:30:42.868041 12834 sgd_solver.cpp:106] Iteration 10100, lr = 8e-05
I0506 04:30:42.873301 12834 solver.cpp:242] Iteration 10100 (103.303 iter/s, 0.968026s/100 iter), loss = 1.35185
I0506 04:30:42.873330 12834 solver.cpp:261]     Train net output #0: loss = 1.35185 (* 1 = 1.35185 loss)
I0506 04:30:42.873340 12834 sgd_solver.cpp:106] Iteration 10100, lr = 8e-05
I0506 04:30:43.904795 12834 solver.cpp:242] Iteration 10200 (96.456 iter/s, 1.03674s/100 iter), loss = 0.804639
I0506 04:30:43.904835 12834 solver.cpp:261]     Train net output #0: loss = 0.804639 (* 1 = 0.804639 loss)
I0506 04:30:43.904847 12834 sgd_solver.cpp:106] Iteration 10200, lr = 8e-05
I0506 04:30:43.910171 12834 solver.cpp:242] Iteration 10200 (96.4496 iter/s, 1.03681s/100 iter), loss = 1.20037
I0506 04:30:43.910200 12834 solver.cpp:261]     Train net output #0: loss = 1.20037 (* 1 = 1.20037 loss)
I0506 04:30:43.910212 12834 sgd_solver.cpp:106] Iteration 10200, lr = 8e-05
I0506 04:30:44.922111 12834 solver.cpp:242] Iteration 10300 (98.3043 iter/s, 1.01725s/100 iter), loss = 1.13972
I0506 04:30:44.922145 12834 solver.cpp:261]     Train net output #0: loss = 1.13972 (* 1 = 1.13972 loss)
I0506 04:30:44.922155 12834 sgd_solver.cpp:106] Iteration 10300, lr = 8e-05
I0506 04:30:44.926889 12834 solver.cpp:242] Iteration 10300 (98.3602 iter/s, 1.01667s/100 iter), loss = 1.73472
I0506 04:30:44.926914 12834 solver.cpp:261]     Train net output #0: loss = 1.73472 (* 1 = 1.73472 loss)
I0506 04:30:44.926923 12834 sgd_solver.cpp:106] Iteration 10300, lr = 8e-05
I0506 04:30:45.862833 12834 solver.cpp:242] Iteration 10400 (106.309 iter/s, 0.940657s/100 iter), loss = 2.06092
I0506 04:30:45.862869 12834 solver.cpp:261]     Train net output #0: loss = 2.06092 (* 1 = 2.06092 loss)
I0506 04:30:45.862879 12834 sgd_solver.cpp:106] Iteration 10400, lr = 8e-05
I0506 04:30:45.867619 12834 solver.cpp:242] Iteration 10400 (106.305 iter/s, 0.940687s/100 iter), loss = 1.23975
I0506 04:30:45.867645 12834 solver.cpp:261]     Train net output #0: loss = 1.23975 (* 1 = 1.23975 loss)
I0506 04:30:45.867653 12834 sgd_solver.cpp:106] Iteration 10400, lr = 8e-05
I0506 04:30:46.799839 12834 solver.cpp:362] Iteration 10500, Testing net (#0)
I0506 04:30:46.799859 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:46.922945 12834 solver.cpp:429]     Test net output #0: loss = 3.59297 (* 1 = 3.59297 loss)
I0506 04:30:46.925472 12834 solver.cpp:242] Iteration 10500 (94.1102 iter/s, 1.06258s/100 iter), loss = 4.45836
I0506 04:30:46.925492 12834 solver.cpp:261]     Train net output #0: loss = 4.45836 (* 1 = 4.45836 loss)
I0506 04:30:46.925500 12834 sgd_solver.cpp:106] Iteration 10500, lr = 8e-05
I0506 04:30:46.927323 12834 solver.cpp:362] Iteration 10500, Testing net (#0)
I0506 04:30:46.927336 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:47.056888 12834 solver.cpp:429]     Test net output #0: accuracy = 0.4595
I0506 04:30:47.056907 12834 solver.cpp:429]     Test net output #1: loss = 1.48879 (* 1 = 1.48879 loss)
I0506 04:30:47.059475 12834 solver.cpp:242] Iteration 10500 (83.9061 iter/s, 1.19181s/100 iter), loss = 1.6899
I0506 04:30:47.059494 12834 solver.cpp:261]     Train net output #0: loss = 1.6899 (* 1 = 1.6899 loss)
I0506 04:30:47.059504 12834 sgd_solver.cpp:106] Iteration 10500, lr = 8e-05
I0506 04:30:47.994582 12834 solver.cpp:242] Iteration 10600 (93.5401 iter/s, 1.06906s/100 iter), loss = 9.2067
I0506 04:30:47.994611 12834 solver.cpp:261]     Train net output #0: loss = 9.2067 (* 1 = 9.2067 loss)
I0506 04:30:47.994621 12834 sgd_solver.cpp:106] Iteration 10600, lr = 8e-05
I0506 04:30:47.999366 12834 solver.cpp:242] Iteration 10600 (106.4 iter/s, 0.939853s/100 iter), loss = 1.61317
I0506 04:30:47.999389 12834 solver.cpp:261]     Train net output #0: loss = 1.61317 (* 1 = 1.61317 loss)
I0506 04:30:47.999398 12834 sgd_solver.cpp:106] Iteration 10600, lr = 8e-05
I0506 04:30:48.935796 12834 solver.cpp:242] Iteration 10700 (106.252 iter/s, 0.941159s/100 iter), loss = 4.7375
I0506 04:30:48.935837 12834 solver.cpp:261]     Train net output #0: loss = 4.7375 (* 1 = 4.7375 loss)
I0506 04:30:48.935845 12834 sgd_solver.cpp:106] Iteration 10700, lr = 8e-05
I0506 04:30:48.940603 12834 solver.cpp:242] Iteration 10700 (106.248 iter/s, 0.941194s/100 iter), loss = 1.12326
I0506 04:30:48.940629 12834 solver.cpp:261]     Train net output #0: loss = 1.12326 (* 1 = 1.12326 loss)
I0506 04:30:48.940636 12834 sgd_solver.cpp:106] Iteration 10700, lr = 8e-05
I0506 04:30:49.876127 12834 solver.cpp:242] Iteration 10800 (106.354 iter/s, 0.94026s/100 iter), loss = 4.83015
I0506 04:30:49.876166 12834 solver.cpp:261]     Train net output #0: loss = 4.83015 (* 1 = 4.83015 loss)
I0506 04:30:49.876175 12834 sgd_solver.cpp:106] Iteration 10800, lr = 8e-05
I0506 04:30:49.880950 12834 solver.cpp:242] Iteration 10800 (106.349 iter/s, 0.940303s/100 iter), loss = 1.23052
I0506 04:30:49.880975 12834 solver.cpp:261]     Train net output #0: loss = 1.23052 (* 1 = 1.23052 loss)
I0506 04:30:49.880985 12834 sgd_solver.cpp:106] Iteration 10800, lr = 8e-05
I0506 04:30:50.830374 12834 solver.cpp:242] Iteration 10900 (104.802 iter/s, 0.954183s/100 iter), loss = 4.22105
I0506 04:30:50.830420 12834 solver.cpp:261]     Train net output #0: loss = 4.22105 (* 1 = 4.22105 loss)
I0506 04:30:50.830580 12834 sgd_solver.cpp:106] Iteration 10900, lr = 8e-05
I0506 04:30:50.835441 12834 solver.cpp:242] Iteration 10900 (104.774 iter/s, 0.954438s/100 iter), loss = 1.19919
I0506 04:30:50.835467 12834 solver.cpp:261]     Train net output #0: loss = 1.19919 (* 1 = 1.19919 loss)
I0506 04:30:50.835475 12834 sgd_solver.cpp:106] Iteration 10900, lr = 8e-05
I0506 04:30:51.768376 12834 solver.cpp:362] Iteration 11000, Testing net (#0)
I0506 04:30:51.768402 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:51.891331 12834 solver.cpp:429]     Test net output #0: loss = 3.05678 (* 1 = 3.05678 loss)
I0506 04:30:51.893865 12834 solver.cpp:242] Iteration 11000 (94.0355 iter/s, 1.06343s/100 iter), loss = 6.20495
I0506 04:30:51.893892 12834 solver.cpp:261]     Train net output #0: loss = 6.20495 (* 1 = 6.20495 loss)
I0506 04:30:51.893899 12834 sgd_solver.cpp:106] Iteration 11000, lr = 8e-05
I0506 04:30:51.895712 12834 solver.cpp:362] Iteration 11000, Testing net (#0)
I0506 04:30:51.895725 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:52.024699 12834 solver.cpp:429]     Test net output #0: accuracy = 0.512
I0506 04:30:52.024720 12834 solver.cpp:429]     Test net output #1: loss = 1.30747 (* 1 = 1.30747 loss)
I0506 04:30:52.027287 12834 solver.cpp:242] Iteration 11000 (83.9067 iter/s, 1.1918s/100 iter), loss = 1.4754
I0506 04:30:52.027308 12834 solver.cpp:261]     Train net output #0: loss = 1.4754 (* 1 = 1.4754 loss)
I0506 04:30:52.027317 12834 sgd_solver.cpp:106] Iteration 11000, lr = 8e-05
I0506 04:30:53.002130 12834 solver.cpp:242] Iteration 11100 (90.2356 iter/s, 1.10821s/100 iter), loss = 2.07816
I0506 04:30:53.002178 12834 solver.cpp:261]     Train net output #0: loss = 2.07816 (* 1 = 2.07816 loss)
I0506 04:30:53.002189 12834 sgd_solver.cpp:106] Iteration 11100, lr = 8e-05
I0506 04:30:53.007529 12834 solver.cpp:242] Iteration 11100 (102.021 iter/s, 0.980191s/100 iter), loss = 1.47435
I0506 04:30:53.007561 12834 solver.cpp:261]     Train net output #0: loss = 1.47435 (* 1 = 1.47435 loss)
I0506 04:30:53.007572 12834 sgd_solver.cpp:106] Iteration 11100, lr = 8e-05
I0506 04:30:54.007355 12834 solver.cpp:242] Iteration 11200 (99.4876 iter/s, 1.00515s/100 iter), loss = 1.16779
I0506 04:30:54.007395 12834 solver.cpp:261]     Train net output #0: loss = 1.16779 (* 1 = 1.16779 loss)
I0506 04:30:54.007405 12834 sgd_solver.cpp:106] Iteration 11200, lr = 8e-05
I0506 04:30:54.012168 12834 solver.cpp:242] Iteration 11200 (99.5433 iter/s, 1.00459s/100 iter), loss = 1.32159
I0506 04:30:54.012193 12834 solver.cpp:261]     Train net output #0: loss = 1.32159 (* 1 = 1.32159 loss)
I0506 04:30:54.012202 12834 sgd_solver.cpp:106] Iteration 11200, lr = 8e-05
I0506 04:30:54.984896 12834 solver.cpp:242] Iteration 11300 (102.305 iter/s, 0.977468s/100 iter), loss = 3.40295
I0506 04:30:54.984943 12834 solver.cpp:261]     Train net output #0: loss = 3.40295 (* 1 = 3.40295 loss)
I0506 04:30:54.984954 12834 sgd_solver.cpp:106] Iteration 11300, lr = 8e-05
I0506 04:30:54.990198 12834 solver.cpp:242] Iteration 11300 (102.251 iter/s, 0.977984s/100 iter), loss = 1.2688
I0506 04:30:54.990227 12834 solver.cpp:261]     Train net output #0: loss = 1.2688 (* 1 = 1.2688 loss)
I0506 04:30:54.990238 12834 sgd_solver.cpp:106] Iteration 11300, lr = 8e-05
I0506 04:30:56.022289 12834 solver.cpp:242] Iteration 11400 (96.4025 iter/s, 1.03732s/100 iter), loss = 3.155
I0506 04:30:56.022336 12834 solver.cpp:261]     Train net output #0: loss = 3.155 (* 1 = 3.155 loss)
I0506 04:30:56.022416 12834 sgd_solver.cpp:106] Iteration 11400, lr = 8e-05
I0506 04:30:56.027214 12834 solver.cpp:242] Iteration 11400 (96.4351 iter/s, 1.03697s/100 iter), loss = 1.28395
I0506 04:30:56.027237 12834 solver.cpp:261]     Train net output #0: loss = 1.28395 (* 1 = 1.28395 loss)
I0506 04:30:56.027246 12834 sgd_solver.cpp:106] Iteration 11400, lr = 8e-05
I0506 04:30:56.958858 12834 solver.cpp:362] Iteration 11500, Testing net (#0)
I0506 04:30:56.958885 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:57.081879 12834 solver.cpp:429]     Test net output #0: loss = 3.61794 (* 1 = 3.61794 loss)
I0506 04:30:57.084405 12834 solver.cpp:242] Iteration 11500 (94.1573 iter/s, 1.06205s/100 iter), loss = 2.70068
I0506 04:30:57.084425 12834 solver.cpp:261]     Train net output #0: loss = 2.70068 (* 1 = 2.70068 loss)
I0506 04:30:57.084434 12834 sgd_solver.cpp:106] Iteration 11500, lr = 8e-05
I0506 04:30:57.086246 12834 solver.cpp:362] Iteration 11500, Testing net (#0)
I0506 04:30:57.086259 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:30:57.215257 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5395
I0506 04:30:57.215276 12834 solver.cpp:429]     Test net output #1: loss = 1.25415 (* 1 = 1.25415 loss)
I0506 04:30:57.217850 12834 solver.cpp:242] Iteration 11500 (83.9919 iter/s, 1.19059s/100 iter), loss = 1.47513
I0506 04:30:57.217870 12834 solver.cpp:261]     Train net output #0: loss = 1.47513 (* 1 = 1.47513 loss)
I0506 04:30:57.217878 12834 sgd_solver.cpp:106] Iteration 11500, lr = 8e-05
I0506 04:30:58.153561 12834 solver.cpp:242] Iteration 11600 (93.5361 iter/s, 1.06911s/100 iter), loss = 1.831
I0506 04:30:58.153602 12834 solver.cpp:261]     Train net output #0: loss = 1.831 (* 1 = 1.831 loss)
I0506 04:30:58.153611 12834 sgd_solver.cpp:106] Iteration 11600, lr = 8e-05
I0506 04:30:58.158360 12834 solver.cpp:242] Iteration 11600 (106.33 iter/s, 0.94047s/100 iter), loss = 1.23684
I0506 04:30:58.158385 12834 solver.cpp:261]     Train net output #0: loss = 1.23684 (* 1 = 1.23684 loss)
I0506 04:30:58.158393 12834 sgd_solver.cpp:106] Iteration 11600, lr = 8e-05
I0506 04:30:59.146860 12834 solver.cpp:242] Iteration 11700 (100.682 iter/s, 0.993225s/100 iter), loss = 6.3038
I0506 04:30:59.146903 12834 solver.cpp:261]     Train net output #0: loss = 6.3038 (* 1 = 6.3038 loss)
I0506 04:30:59.146914 12834 sgd_solver.cpp:106] Iteration 11700, lr = 8e-05
I0506 04:30:59.152179 12834 solver.cpp:242] Iteration 11700 (100.627 iter/s, 0.993774s/100 iter), loss = 1.29289
I0506 04:30:59.152209 12834 solver.cpp:261]     Train net output #0: loss = 1.29289 (* 1 = 1.29289 loss)
I0506 04:30:59.152220 12834 sgd_solver.cpp:106] Iteration 11700, lr = 8e-05
I0506 04:31:00.184324 12834 solver.cpp:242] Iteration 11800 (96.3953 iter/s, 1.03739s/100 iter), loss = 2.95911
I0506 04:31:00.184370 12834 solver.cpp:261]     Train net output #0: loss = 2.95911 (* 1 = 2.95911 loss)
I0506 04:31:00.184381 12834 sgd_solver.cpp:106] Iteration 11800, lr = 8e-05
I0506 04:31:00.189713 12834 solver.cpp:242] Iteration 11800 (96.3879 iter/s, 1.03747s/100 iter), loss = 0.808289
I0506 04:31:00.189743 12834 solver.cpp:261]     Train net output #0: loss = 0.808289 (* 1 = 0.808289 loss)
I0506 04:31:00.189755 12834 sgd_solver.cpp:106] Iteration 11800, lr = 8e-05
I0506 04:31:01.162888 12834 solver.cpp:242] Iteration 11900 (102.198 iter/s, 0.978489s/100 iter), loss = 4.98194
I0506 04:31:01.162932 12834 solver.cpp:261]     Train net output #0: loss = 4.98194 (* 1 = 4.98194 loss)
I0506 04:31:01.163000 12834 sgd_solver.cpp:106] Iteration 11900, lr = 8e-05
I0506 04:31:01.167840 12834 solver.cpp:242] Iteration 11900 (102.241 iter/s, 0.978078s/100 iter), loss = 1.2468
I0506 04:31:01.167865 12834 solver.cpp:261]     Train net output #0: loss = 1.2468 (* 1 = 1.2468 loss)
I0506 04:31:01.167873 12834 sgd_solver.cpp:106] Iteration 11900, lr = 8e-05
I0506 04:31:02.100965 12834 solver.cpp:362] Iteration 12000, Testing net (#0)
I0506 04:31:02.100987 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:02.223883 12834 solver.cpp:429]     Test net output #0: loss = 3.38162 (* 1 = 3.38162 loss)
I0506 04:31:02.226428 12834 solver.cpp:242] Iteration 12000 (94.0312 iter/s, 1.06348s/100 iter), loss = 1.98202
I0506 04:31:02.226456 12834 solver.cpp:261]     Train net output #0: loss = 1.98202 (* 1 = 1.98202 loss)
I0506 04:31:02.226466 12834 sgd_solver.cpp:106] Iteration 12000, lr = 8e-05
I0506 04:31:02.228358 12834 solver.cpp:362] Iteration 12000, Testing net (#0)
I0506 04:31:02.228371 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:02.357709 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5615
I0506 04:31:02.357728 12834 solver.cpp:429]     Test net output #1: loss = 1.17744 (* 1 = 1.17744 loss)
I0506 04:31:02.360290 12834 solver.cpp:242] Iteration 12000 (83.8643 iter/s, 1.1924s/100 iter), loss = 1.01838
I0506 04:31:02.360308 12834 solver.cpp:261]     Train net output #0: loss = 1.01838 (* 1 = 1.01838 loss)
I0506 04:31:02.360317 12834 sgd_solver.cpp:106] Iteration 12000, lr = 8e-05
I0506 04:31:03.295572 12834 solver.cpp:242] Iteration 12100 (93.5379 iter/s, 1.06909s/100 iter), loss = 7.52766
I0506 04:31:03.295609 12834 solver.cpp:261]     Train net output #0: loss = 7.52766 (* 1 = 7.52766 loss)
I0506 04:31:03.295619 12834 sgd_solver.cpp:106] Iteration 12100, lr = 8e-05
I0506 04:31:03.300395 12834 solver.cpp:242] Iteration 12100 (106.376 iter/s, 0.940066s/100 iter), loss = 1.03642
I0506 04:31:03.300420 12834 solver.cpp:261]     Train net output #0: loss = 1.03642 (* 1 = 1.03642 loss)
I0506 04:31:03.300428 12834 sgd_solver.cpp:106] Iteration 12100, lr = 8e-05
I0506 04:31:04.238474 12834 solver.cpp:242] Iteration 12200 (106.063 iter/s, 0.942836s/100 iter), loss = 2.03633
I0506 04:31:04.238508 12834 solver.cpp:261]     Train net output #0: loss = 2.03633 (* 1 = 2.03633 loss)
I0506 04:31:04.238518 12834 sgd_solver.cpp:106] Iteration 12200, lr = 8e-05
I0506 04:31:04.243284 12834 solver.cpp:242] Iteration 12200 (106.062 iter/s, 0.942846s/100 iter), loss = 1.19336
I0506 04:31:04.243309 12834 solver.cpp:261]     Train net output #0: loss = 1.19336 (* 1 = 1.19336 loss)
I0506 04:31:04.243319 12834 sgd_solver.cpp:106] Iteration 12200, lr = 8e-05
I0506 04:31:05.178066 12834 solver.cpp:242] Iteration 12300 (106.436 iter/s, 0.939529s/100 iter), loss = 5.57028
I0506 04:31:05.178108 12834 solver.cpp:261]     Train net output #0: loss = 5.57028 (* 1 = 5.57028 loss)
I0506 04:31:05.178117 12834 sgd_solver.cpp:106] Iteration 12300, lr = 8e-05
I0506 04:31:05.182857 12834 solver.cpp:242] Iteration 12300 (106.436 iter/s, 0.939529s/100 iter), loss = 1.18074
I0506 04:31:05.182883 12834 solver.cpp:261]     Train net output #0: loss = 1.18074 (* 1 = 1.18074 loss)
I0506 04:31:05.182893 12834 sgd_solver.cpp:106] Iteration 12300, lr = 8e-05
I0506 04:31:06.116899 12834 solver.cpp:242] Iteration 12400 (106.523 iter/s, 0.93876s/100 iter), loss = 2.05782
I0506 04:31:06.116940 12834 solver.cpp:261]     Train net output #0: loss = 2.05782 (* 1 = 2.05782 loss)
I0506 04:31:06.116950 12834 sgd_solver.cpp:106] Iteration 12400, lr = 8e-05
I0506 04:31:06.121661 12834 solver.cpp:242] Iteration 12400 (106.524 iter/s, 0.938759s/100 iter), loss = 0.934786
I0506 04:31:06.121687 12834 solver.cpp:261]     Train net output #0: loss = 0.934786 (* 1 = 0.934786 loss)
I0506 04:31:06.121697 12834 sgd_solver.cpp:106] Iteration 12400, lr = 8e-05
I0506 04:31:07.052664 12834 solver.cpp:362] Iteration 12500, Testing net (#0)
I0506 04:31:07.052693 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:07.175657 12834 solver.cpp:429]     Test net output #0: loss = 3.17469 (* 1 = 3.17469 loss)
I0506 04:31:07.178194 12834 solver.cpp:242] Iteration 12500 (94.23 iter/s, 1.06123s/100 iter), loss = 3.29196
I0506 04:31:07.178216 12834 solver.cpp:261]     Train net output #0: loss = 3.29196 (* 1 = 3.29196 loss)
I0506 04:31:07.178225 12834 sgd_solver.cpp:106] Iteration 12500, lr = 8e-05
I0506 04:31:07.180037 12834 solver.cpp:362] Iteration 12500, Testing net (#0)
I0506 04:31:07.180049 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:07.309161 12834 solver.cpp:429]     Test net output #0: accuracy = 0.589
I0506 04:31:07.309180 12834 solver.cpp:429]     Test net output #1: loss = 1.13187 (* 1 = 1.13187 loss)
I0506 04:31:07.311753 12834 solver.cpp:242] Iteration 12500 (84.0305 iter/s, 1.19004s/100 iter), loss = 1.49352
I0506 04:31:07.311774 12834 solver.cpp:261]     Train net output #0: loss = 1.49352 (* 1 = 1.49352 loss)
I0506 04:31:07.311782 12834 sgd_solver.cpp:106] Iteration 12500, lr = 8e-05
I0506 04:31:08.246233 12834 solver.cpp:242] Iteration 12600 (93.6344 iter/s, 1.06798s/100 iter), loss = 4.85246
I0506 04:31:08.246273 12834 solver.cpp:261]     Train net output #0: loss = 4.85246 (* 1 = 4.85246 loss)
I0506 04:31:08.246282 12834 sgd_solver.cpp:106] Iteration 12600, lr = 8e-05
I0506 04:31:08.251027 12834 solver.cpp:242] Iteration 12600 (106.47 iter/s, 0.939234s/100 iter), loss = 1.31145
I0506 04:31:08.251054 12834 solver.cpp:261]     Train net output #0: loss = 1.31145 (* 1 = 1.31145 loss)
I0506 04:31:08.251062 12834 sgd_solver.cpp:106] Iteration 12600, lr = 8e-05
I0506 04:31:09.198832 12834 solver.cpp:242] Iteration 12700 (104.983 iter/s, 0.952534s/100 iter), loss = 6.8923
I0506 04:31:09.198874 12834 solver.cpp:261]     Train net output #0: loss = 6.8923 (* 1 = 6.8923 loss)
I0506 04:31:09.198884 12834 sgd_solver.cpp:106] Iteration 12700, lr = 8e-05
I0506 04:31:09.203717 12834 solver.cpp:242] Iteration 12700 (104.972 iter/s, 0.952635s/100 iter), loss = 1.46395
I0506 04:31:09.203742 12834 solver.cpp:261]     Train net output #0: loss = 1.46395 (* 1 = 1.46395 loss)
I0506 04:31:09.203752 12834 sgd_solver.cpp:106] Iteration 12700, lr = 8e-05
I0506 04:31:10.138206 12834 solver.cpp:242] Iteration 12800 (106.462 iter/s, 0.939306s/100 iter), loss = 4.81159
I0506 04:31:10.138245 12834 solver.cpp:261]     Train net output #0: loss = 4.81159 (* 1 = 4.81159 loss)
I0506 04:31:10.138255 12834 sgd_solver.cpp:106] Iteration 12800, lr = 8e-05
I0506 04:31:10.142995 12834 solver.cpp:242] Iteration 12800 (106.47 iter/s, 0.939235s/100 iter), loss = 1.08914
I0506 04:31:10.143021 12834 solver.cpp:261]     Train net output #0: loss = 1.08914 (* 1 = 1.08914 loss)
I0506 04:31:10.143030 12834 sgd_solver.cpp:106] Iteration 12800, lr = 8e-05
I0506 04:31:11.128979 12834 solver.cpp:242] Iteration 12900 (100.938 iter/s, 0.990709s/100 iter), loss = 2.38987
I0506 04:31:11.129024 12834 solver.cpp:261]     Train net output #0: loss = 2.38987 (* 1 = 2.38987 loss)
I0506 04:31:11.129035 12834 sgd_solver.cpp:106] Iteration 12900, lr = 8e-05
I0506 04:31:11.134344 12834 solver.cpp:242] Iteration 12900 (100.878 iter/s, 0.991293s/100 iter), loss = 1.56323
I0506 04:31:11.134376 12834 solver.cpp:261]     Train net output #0: loss = 1.56323 (* 1 = 1.56323 loss)
I0506 04:31:11.134387 12834 sgd_solver.cpp:106] Iteration 12900, lr = 8e-05
I0506 04:31:12.083580 12834 solver.cpp:362] Iteration 13000, Testing net (#0)
I0506 04:31:12.083607 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:12.206481 12834 solver.cpp:429]     Test net output #0: loss = 3.72777 (* 1 = 3.72777 loss)
I0506 04:31:12.209008 12834 solver.cpp:242] Iteration 13000 (92.5955 iter/s, 1.07997s/100 iter), loss = 2.74305
I0506 04:31:12.209029 12834 solver.cpp:261]     Train net output #0: loss = 2.74305 (* 1 = 2.74305 loss)
I0506 04:31:12.209038 12834 sgd_solver.cpp:106] Iteration 13000, lr = 8e-05
I0506 04:31:12.210856 12834 solver.cpp:362] Iteration 13000, Testing net (#0)
I0506 04:31:12.210871 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:12.339762 12834 solver.cpp:429]     Test net output #0: accuracy = 0.533
I0506 04:31:12.339782 12834 solver.cpp:429]     Test net output #1: loss = 1.26181 (* 1 = 1.26181 loss)
I0506 04:31:12.342377 12834 solver.cpp:242] Iteration 13000 (82.7827 iter/s, 1.20798s/100 iter), loss = 1.47486
I0506 04:31:12.342397 12834 solver.cpp:261]     Train net output #0: loss = 1.47486 (* 1 = 1.47486 loss)
I0506 04:31:12.342406 12834 sgd_solver.cpp:106] Iteration 13000, lr = 8e-05
I0506 04:31:13.276075 12834 solver.cpp:242] Iteration 13100 (93.7197 iter/s, 1.06701s/100 iter), loss = 2.28645
I0506 04:31:13.276115 12834 solver.cpp:261]     Train net output #0: loss = 2.28645 (* 1 = 2.28645 loss)
I0506 04:31:13.276134 12834 sgd_solver.cpp:106] Iteration 13100, lr = 8e-05
I0506 04:31:13.280854 12834 solver.cpp:242] Iteration 13100 (106.56 iter/s, 0.938438s/100 iter), loss = 1.12967
I0506 04:31:13.280879 12834 solver.cpp:261]     Train net output #0: loss = 1.12967 (* 1 = 1.12967 loss)
I0506 04:31:13.280889 12834 sgd_solver.cpp:106] Iteration 13100, lr = 8e-05
I0506 04:31:14.230772 12834 solver.cpp:242] Iteration 13200 (104.753 iter/s, 0.95463s/100 iter), loss = 4.51598
I0506 04:31:14.230813 12834 solver.cpp:261]     Train net output #0: loss = 4.51598 (* 1 = 4.51598 loss)
I0506 04:31:14.230823 12834 sgd_solver.cpp:106] Iteration 13200, lr = 8e-05
I0506 04:31:14.235560 12834 solver.cpp:242] Iteration 13200 (104.749 iter/s, 0.954661s/100 iter), loss = 1.3582
I0506 04:31:14.235585 12834 solver.cpp:261]     Train net output #0: loss = 1.3582 (* 1 = 1.3582 loss)
I0506 04:31:14.235594 12834 sgd_solver.cpp:106] Iteration 13200, lr = 8e-05
I0506 04:31:15.183442 12834 solver.cpp:242] Iteration 13300 (104.976 iter/s, 0.952599s/100 iter), loss = 1.9197
I0506 04:31:15.183480 12834 solver.cpp:261]     Train net output #0: loss = 1.9197 (* 1 = 1.9197 loss)
I0506 04:31:15.183488 12834 sgd_solver.cpp:106] Iteration 13300, lr = 8e-05
I0506 04:31:15.188215 12834 solver.cpp:242] Iteration 13300 (104.975 iter/s, 0.95261s/100 iter), loss = 1.36196
I0506 04:31:15.188241 12834 solver.cpp:261]     Train net output #0: loss = 1.36196 (* 1 = 1.36196 loss)
I0506 04:31:15.188249 12834 sgd_solver.cpp:106] Iteration 13300, lr = 8e-05
I0506 04:31:16.121500 12834 solver.cpp:242] Iteration 13400 (106.61 iter/s, 0.937995s/100 iter), loss = 4.71648
I0506 04:31:16.121534 12834 solver.cpp:261]     Train net output #0: loss = 4.71648 (* 1 = 4.71648 loss)
I0506 04:31:16.121543 12834 sgd_solver.cpp:106] Iteration 13400, lr = 8e-05
I0506 04:31:16.126278 12834 solver.cpp:242] Iteration 13400 (106.608 iter/s, 0.93802s/100 iter), loss = 1.2515
I0506 04:31:16.126302 12834 solver.cpp:261]     Train net output #0: loss = 1.2515 (* 1 = 1.2515 loss)
I0506 04:31:16.126312 12834 sgd_solver.cpp:106] Iteration 13400, lr = 8e-05
I0506 04:31:17.056675 12834 solver.cpp:362] Iteration 13500, Testing net (#0)
I0506 04:31:17.056696 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:17.179450 12834 solver.cpp:429]     Test net output #0: loss = 3.44284 (* 1 = 3.44284 loss)
I0506 04:31:17.181969 12834 solver.cpp:242] Iteration 13500 (94.3025 iter/s, 1.06042s/100 iter), loss = 2.61959
I0506 04:31:17.181990 12834 solver.cpp:261]     Train net output #0: loss = 2.61959 (* 1 = 2.61959 loss)
I0506 04:31:17.181998 12834 sgd_solver.cpp:106] Iteration 13500, lr = 8e-05
I0506 04:31:17.183820 12834 solver.cpp:362] Iteration 13500, Testing net (#0)
I0506 04:31:17.183832 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:17.312639 12834 solver.cpp:429]     Test net output #0: accuracy = 0.561
I0506 04:31:17.312657 12834 solver.cpp:429]     Test net output #1: loss = 1.14353 (* 1 = 1.14353 loss)
I0506 04:31:17.315207 12834 solver.cpp:242] Iteration 13500 (84.1125 iter/s, 1.18888s/100 iter), loss = 1.11607
I0506 04:31:17.315227 12834 solver.cpp:261]     Train net output #0: loss = 1.11607 (* 1 = 1.11607 loss)
I0506 04:31:17.315234 12834 sgd_solver.cpp:106] Iteration 13500, lr = 8e-05
I0506 04:31:18.248312 12834 solver.cpp:242] Iteration 13600 (93.7826 iter/s, 1.0663s/100 iter), loss = 3.46246
I0506 04:31:18.248347 12834 solver.cpp:261]     Train net output #0: loss = 3.46246 (* 1 = 3.46246 loss)
I0506 04:31:18.248356 12834 sgd_solver.cpp:106] Iteration 13600, lr = 8e-05
I0506 04:31:18.253175 12834 solver.cpp:242] Iteration 13600 (106.619 iter/s, 0.937921s/100 iter), loss = 1.02345
I0506 04:31:18.253198 12834 solver.cpp:261]     Train net output #0: loss = 1.02345 (* 1 = 1.02345 loss)
I0506 04:31:18.253207 12834 sgd_solver.cpp:106] Iteration 13600, lr = 8e-05
I0506 04:31:19.186832 12834 solver.cpp:242] Iteration 13700 (106.558 iter/s, 0.938459s/100 iter), loss = 4.31127
I0506 04:31:19.186864 12834 solver.cpp:261]     Train net output #0: loss = 4.31127 (* 1 = 4.31127 loss)
I0506 04:31:19.186883 12834 sgd_solver.cpp:106] Iteration 13700, lr = 8e-05
I0506 04:31:19.191624 12834 solver.cpp:242] Iteration 13700 (106.564 iter/s, 0.938407s/100 iter), loss = 0.76711
I0506 04:31:19.191648 12834 solver.cpp:261]     Train net output #0: loss = 0.76711 (* 1 = 0.76711 loss)
I0506 04:31:19.191658 12834 sgd_solver.cpp:106] Iteration 13700, lr = 8e-05
I0506 04:31:20.124843 12834 solver.cpp:242] Iteration 13800 (106.615 iter/s, 0.937956s/100 iter), loss = 4.77703
I0506 04:31:20.124876 12834 solver.cpp:261]     Train net output #0: loss = 4.77703 (* 1 = 4.77703 loss)
I0506 04:31:20.124886 12834 sgd_solver.cpp:106] Iteration 13800, lr = 8e-05
I0506 04:31:20.129683 12834 solver.cpp:242] Iteration 13800 (106.609 iter/s, 0.938009s/100 iter), loss = 1.29138
I0506 04:31:20.129706 12834 solver.cpp:261]     Train net output #0: loss = 1.29138 (* 1 = 1.29138 loss)
I0506 04:31:20.129715 12834 sgd_solver.cpp:106] Iteration 13800, lr = 8e-05
I0506 04:31:21.063196 12834 solver.cpp:242] Iteration 13900 (106.576 iter/s, 0.938293s/100 iter), loss = 2.91892
I0506 04:31:21.063236 12834 solver.cpp:261]     Train net output #0: loss = 2.91892 (* 1 = 2.91892 loss)
I0506 04:31:21.063246 12834 sgd_solver.cpp:106] Iteration 13900, lr = 8e-05
I0506 04:31:21.068001 12834 solver.cpp:242] Iteration 13900 (106.578 iter/s, 0.938276s/100 iter), loss = 1.3475
I0506 04:31:21.068027 12834 solver.cpp:261]     Train net output #0: loss = 1.3475 (* 1 = 1.3475 loss)
I0506 04:31:21.068035 12834 sgd_solver.cpp:106] Iteration 13900, lr = 8e-05
I0506 04:31:21.998759 12834 solver.cpp:362] Iteration 14000, Testing net (#0)
I0506 04:31:21.998785 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:22.121672 12834 solver.cpp:429]     Test net output #0: loss = 3.39884 (* 1 = 3.39884 loss)
I0506 04:31:22.124239 12834 solver.cpp:242] Iteration 14000 (94.2522 iter/s, 1.06098s/100 iter), loss = 3.81189
I0506 04:31:22.124263 12834 solver.cpp:261]     Train net output #0: loss = 3.81189 (* 1 = 3.81189 loss)
I0506 04:31:22.124271 12834 sgd_solver.cpp:106] Iteration 14000, lr = 8e-05
I0506 04:31:22.126118 12834 solver.cpp:362] Iteration 14000, Testing net (#0)
I0506 04:31:22.126133 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:22.255228 12834 solver.cpp:429]     Test net output #0: accuracy = 0.576
I0506 04:31:22.255250 12834 solver.cpp:429]     Test net output #1: loss = 1.0999 (* 1 = 1.0999 loss)
I0506 04:31:22.257840 12834 solver.cpp:242] Iteration 14000 (84.0482 iter/s, 1.18979s/100 iter), loss = 0.747321
I0506 04:31:22.257861 12834 solver.cpp:261]     Train net output #0: loss = 0.747321 (* 1 = 0.747321 loss)
I0506 04:31:22.257869 12834 sgd_solver.cpp:106] Iteration 14000, lr = 8e-05
I0506 04:31:23.191628 12834 solver.cpp:242] Iteration 14100 (93.6911 iter/s, 1.06734s/100 iter), loss = 3.99721
I0506 04:31:23.191668 12834 solver.cpp:261]     Train net output #0: loss = 3.99721 (* 1 = 3.99721 loss)
I0506 04:31:23.191679 12834 sgd_solver.cpp:106] Iteration 14100, lr = 8e-05
I0506 04:31:23.196404 12834 solver.cpp:242] Iteration 14100 (106.55 iter/s, 0.938525s/100 iter), loss = 1.61418
I0506 04:31:23.196430 12834 solver.cpp:261]     Train net output #0: loss = 1.61418 (* 1 = 1.61418 loss)
I0506 04:31:23.196439 12834 sgd_solver.cpp:106] Iteration 14100, lr = 8e-05
I0506 04:31:24.130143 12834 solver.cpp:242] Iteration 14200 (106.56 iter/s, 0.938443s/100 iter), loss = 2.35855
I0506 04:31:24.130189 12834 solver.cpp:261]     Train net output #0: loss = 2.35855 (* 1 = 2.35855 loss)
I0506 04:31:24.130198 12834 sgd_solver.cpp:106] Iteration 14200, lr = 8e-05
I0506 04:31:24.134938 12834 solver.cpp:242] Iteration 14200 (106.554 iter/s, 0.938489s/100 iter), loss = 1.2375
I0506 04:31:24.134964 12834 solver.cpp:261]     Train net output #0: loss = 1.2375 (* 1 = 1.2375 loss)
I0506 04:31:24.134973 12834 sgd_solver.cpp:106] Iteration 14200, lr = 8e-05
I0506 04:31:25.068194 12834 solver.cpp:242] Iteration 14300 (106.612 iter/s, 0.93798s/100 iter), loss = 1.92043
I0506 04:31:25.068233 12834 solver.cpp:261]     Train net output #0: loss = 1.92043 (* 1 = 1.92043 loss)
I0506 04:31:25.068250 12834 sgd_solver.cpp:106] Iteration 14300, lr = 8e-05
I0506 04:31:25.072986 12834 solver.cpp:242] Iteration 14300 (106.609 iter/s, 0.938003s/100 iter), loss = 1.24442
I0506 04:31:25.073012 12834 solver.cpp:261]     Train net output #0: loss = 1.24442 (* 1 = 1.24442 loss)
I0506 04:31:25.073031 12834 sgd_solver.cpp:106] Iteration 14300, lr = 8e-05
I0506 04:31:26.006842 12834 solver.cpp:242] Iteration 14400 (106.544 iter/s, 0.938581s/100 iter), loss = 1.62459
I0506 04:31:26.006880 12834 solver.cpp:261]     Train net output #0: loss = 1.62459 (* 1 = 1.62459 loss)
I0506 04:31:26.006888 12834 sgd_solver.cpp:106] Iteration 14400, lr = 8e-05
I0506 04:31:26.011629 12834 solver.cpp:242] Iteration 14400 (106.542 iter/s, 0.938598s/100 iter), loss = 1.03112
I0506 04:31:26.011654 12834 solver.cpp:261]     Train net output #0: loss = 1.03112 (* 1 = 1.03112 loss)
I0506 04:31:26.011663 12834 sgd_solver.cpp:106] Iteration 14400, lr = 8e-05
I0506 04:31:26.954922 12834 solver.cpp:362] Iteration 14500, Testing net (#0)
I0506 04:31:26.954946 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:27.077914 12834 solver.cpp:429]     Test net output #0: loss = 3.24177 (* 1 = 3.24177 loss)
I0506 04:31:27.080430 12834 solver.cpp:242] Iteration 14500 (93.1505 iter/s, 1.07353s/100 iter), loss = 1.39476
I0506 04:31:27.080451 12834 solver.cpp:261]     Train net output #0: loss = 1.39476 (* 1 = 1.39476 loss)
I0506 04:31:27.080458 12834 sgd_solver.cpp:106] Iteration 14500, lr = 8e-05
I0506 04:31:27.082341 12834 solver.cpp:362] Iteration 14500, Testing net (#0)
I0506 04:31:27.082355 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:27.211633 12834 solver.cpp:429]     Test net output #0: accuracy = 0.548
I0506 04:31:27.211658 12834 solver.cpp:429]     Test net output #1: loss = 1.14142 (* 1 = 1.14142 loss)
I0506 04:31:27.214371 12834 solver.cpp:242] Iteration 14500 (83.1466 iter/s, 1.2027s/100 iter), loss = 0.927028
I0506 04:31:27.214393 12834 solver.cpp:261]     Train net output #0: loss = 0.927028 (* 1 = 0.927028 loss)
I0506 04:31:27.214402 12834 sgd_solver.cpp:106] Iteration 14500, lr = 8e-05
I0506 04:31:28.147619 12834 solver.cpp:242] Iteration 14600 (93.7087 iter/s, 1.06714s/100 iter), loss = 3.29275
I0506 04:31:28.147655 12834 solver.cpp:261]     Train net output #0: loss = 3.29275 (* 1 = 3.29275 loss)
I0506 04:31:28.147663 12834 sgd_solver.cpp:106] Iteration 14600, lr = 8e-05
I0506 04:31:28.152396 12834 solver.cpp:242] Iteration 14600 (106.612 iter/s, 0.937985s/100 iter), loss = 0.994126
I0506 04:31:28.152422 12834 solver.cpp:261]     Train net output #0: loss = 0.994126 (* 1 = 0.994126 loss)
I0506 04:31:28.152431 12834 sgd_solver.cpp:106] Iteration 14600, lr = 8e-05
I0506 04:31:29.085140 12834 solver.cpp:242] Iteration 14700 (106.671 iter/s, 0.937463s/100 iter), loss = 3.61155
I0506 04:31:29.085177 12834 solver.cpp:261]     Train net output #0: loss = 3.61155 (* 1 = 3.61155 loss)
I0506 04:31:29.085186 12834 sgd_solver.cpp:106] Iteration 14700, lr = 8e-05
I0506 04:31:29.089988 12834 solver.cpp:242] Iteration 14700 (106.662 iter/s, 0.937539s/100 iter), loss = 0.893067
I0506 04:31:29.090015 12834 solver.cpp:261]     Train net output #0: loss = 0.893067 (* 1 = 0.893067 loss)
I0506 04:31:29.090024 12834 sgd_solver.cpp:106] Iteration 14700, lr = 8e-05
I0506 04:31:30.024132 12834 solver.cpp:242] Iteration 14800 (106.504 iter/s, 0.93893s/100 iter), loss = 3.94013
I0506 04:31:30.024166 12834 solver.cpp:261]     Train net output #0: loss = 3.94013 (* 1 = 3.94013 loss)
I0506 04:31:30.024175 12834 sgd_solver.cpp:106] Iteration 14800, lr = 8e-05
I0506 04:31:30.028899 12834 solver.cpp:242] Iteration 14800 (106.512 iter/s, 0.938866s/100 iter), loss = 1.1775
I0506 04:31:30.028923 12834 solver.cpp:261]     Train net output #0: loss = 1.1775 (* 1 = 1.1775 loss)
I0506 04:31:30.028931 12834 sgd_solver.cpp:106] Iteration 14800, lr = 8e-05
I0506 04:31:31.002367 12834 solver.cpp:242] Iteration 14900 (102.232 iter/s, 0.978168s/100 iter), loss = 2.47548
I0506 04:31:31.002400 12834 solver.cpp:261]     Train net output #0: loss = 2.47548 (* 1 = 2.47548 loss)
I0506 04:31:31.002423 12834 sgd_solver.cpp:106] Iteration 14900, lr = 8e-05
I0506 04:31:31.007670 12834 solver.cpp:242] Iteration 14900 (102.173 iter/s, 0.978728s/100 iter), loss = 0.926452
I0506 04:31:31.007699 12834 solver.cpp:261]     Train net output #0: loss = 0.926452 (* 1 = 0.926452 loss)
I0506 04:31:31.007709 12834 sgd_solver.cpp:106] Iteration 14900, lr = 8e-05
I0506 04:31:32.034826 12834 solver.cpp:362] Iteration 15000, Testing net (#0)
I0506 04:31:32.034858 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:32.168220 12834 solver.cpp:429]     Test net output #0: loss = 3.13207 (* 1 = 3.13207 loss)
I0506 04:31:32.170869 12834 solver.cpp:242] Iteration 15000 (85.5836 iter/s, 1.16845s/100 iter), loss = 3.88119
I0506 04:31:32.170894 12834 solver.cpp:261]     Train net output #0: loss = 3.88119 (* 1 = 3.88119 loss)
I0506 04:31:32.170904 12834 sgd_solver.cpp:106] Iteration 15000, lr = 8e-05
I0506 04:31:32.173108 12834 solver.cpp:362] Iteration 15000, Testing net (#0)
I0506 04:31:32.173125 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:32.313755 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5495
I0506 04:31:32.313777 12834 solver.cpp:429]     Test net output #1: loss = 1.13766 (* 1 = 1.13766 loss)
I0506 04:31:32.316414 12834 solver.cpp:242] Iteration 15000 (76.412 iter/s, 1.30869s/100 iter), loss = 1.30538
I0506 04:31:32.316437 12834 solver.cpp:261]     Train net output #0: loss = 1.30538 (* 1 = 1.30538 loss)
I0506 04:31:32.316444 12834 sgd_solver.cpp:106] Iteration 15000, lr = 8e-05
I0506 04:31:33.250186 12834 solver.cpp:242] Iteration 15100 (92.6561 iter/s, 1.07926s/100 iter), loss = 1.72059
I0506 04:31:33.250218 12834 solver.cpp:261]     Train net output #0: loss = 1.72059 (* 1 = 1.72059 loss)
I0506 04:31:33.250227 12834 sgd_solver.cpp:106] Iteration 15100, lr = 8e-05
I0506 04:31:33.254967 12834 solver.cpp:242] Iteration 15100 (106.552 iter/s, 0.938513s/100 iter), loss = 1.1942
I0506 04:31:33.254992 12834 solver.cpp:261]     Train net output #0: loss = 1.1942 (* 1 = 1.1942 loss)
I0506 04:31:33.255000 12834 sgd_solver.cpp:106] Iteration 15100, lr = 8e-05
I0506 04:31:34.189152 12834 solver.cpp:242] Iteration 15200 (106.507 iter/s, 0.938905s/100 iter), loss = 1.67934
I0506 04:31:34.189198 12834 solver.cpp:261]     Train net output #0: loss = 1.67934 (* 1 = 1.67934 loss)
I0506 04:31:34.189208 12834 sgd_solver.cpp:106] Iteration 15200, lr = 8e-05
I0506 04:31:34.193930 12834 solver.cpp:242] Iteration 15200 (106.505 iter/s, 0.938919s/100 iter), loss = 1.06247
I0506 04:31:34.193956 12834 solver.cpp:261]     Train net output #0: loss = 1.06247 (* 1 = 1.06247 loss)
I0506 04:31:34.193964 12834 sgd_solver.cpp:106] Iteration 15200, lr = 8e-05
I0506 04:31:35.184880 12834 solver.cpp:242] Iteration 15300 (100.437 iter/s, 0.99565s/100 iter), loss = 1.62262
I0506 04:31:35.184931 12834 solver.cpp:261]     Train net output #0: loss = 1.62262 (* 1 = 1.62262 loss)
I0506 04:31:35.184942 12834 sgd_solver.cpp:106] Iteration 15300, lr = 8e-05
I0506 04:31:35.190155 12834 solver.cpp:242] Iteration 15300 (100.384 iter/s, 0.996178s/100 iter), loss = 1.1688
I0506 04:31:35.190186 12834 solver.cpp:261]     Train net output #0: loss = 1.1688 (* 1 = 1.1688 loss)
I0506 04:31:35.190196 12834 sgd_solver.cpp:106] Iteration 15300, lr = 8e-05
I0506 04:31:36.220582 12834 solver.cpp:242] Iteration 15400 (96.5616 iter/s, 1.03561s/100 iter), loss = 2.72251
I0506 04:31:36.220630 12834 solver.cpp:261]     Train net output #0: loss = 2.72251 (* 1 = 2.72251 loss)
I0506 04:31:36.220643 12834 sgd_solver.cpp:106] Iteration 15400, lr = 8e-05
I0506 04:31:36.225858 12834 solver.cpp:242] Iteration 15400 (96.5574 iter/s, 1.03565s/100 iter), loss = 1.07414
I0506 04:31:36.225888 12834 solver.cpp:261]     Train net output #0: loss = 1.07414 (* 1 = 1.07414 loss)
I0506 04:31:36.225899 12834 sgd_solver.cpp:106] Iteration 15400, lr = 8e-05
I0506 04:31:37.185066 12834 solver.cpp:362] Iteration 15500, Testing net (#0)
I0506 04:31:37.185093 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:37.307940 12834 solver.cpp:429]     Test net output #0: loss = 3.64555 (* 1 = 3.64555 loss)
I0506 04:31:37.310467 12834 solver.cpp:242] Iteration 15500 (91.7582 iter/s, 1.08982s/100 iter), loss = 2.73406
I0506 04:31:37.310489 12834 solver.cpp:261]     Train net output #0: loss = 2.73406 (* 1 = 2.73406 loss)
I0506 04:31:37.310497 12834 sgd_solver.cpp:106] Iteration 15500, lr = 8e-05
I0506 04:31:37.312300 12834 solver.cpp:362] Iteration 15500, Testing net (#0)
I0506 04:31:37.312315 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:37.441509 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5255
I0506 04:31:37.441532 12834 solver.cpp:429]     Test net output #1: loss = 1.16197 (* 1 = 1.16197 loss)
I0506 04:31:37.444100 12834 solver.cpp:242] Iteration 15500 (82.0889 iter/s, 1.21819s/100 iter), loss = 0.975708
I0506 04:31:37.444121 12834 solver.cpp:261]     Train net output #0: loss = 0.975708 (* 1 = 0.975708 loss)
I0506 04:31:37.444129 12834 sgd_solver.cpp:106] Iteration 15500, lr = 8e-05
I0506 04:31:38.377892 12834 solver.cpp:242] Iteration 15600 (93.6877 iter/s, 1.06738s/100 iter), loss = 6.03787
I0506 04:31:38.377935 12834 solver.cpp:261]     Train net output #0: loss = 6.03787 (* 1 = 6.03787 loss)
I0506 04:31:38.377944 12834 sgd_solver.cpp:106] Iteration 15600, lr = 8e-05
I0506 04:31:38.382751 12834 solver.cpp:242] Iteration 15600 (106.541 iter/s, 0.938604s/100 iter), loss = 0.965321
I0506 04:31:38.382778 12834 solver.cpp:261]     Train net output #0: loss = 0.965321 (* 1 = 0.965321 loss)
I0506 04:31:38.382787 12834 sgd_solver.cpp:106] Iteration 15600, lr = 8e-05
I0506 04:31:39.329809 12834 solver.cpp:242] Iteration 15700 (105.059 iter/s, 0.951846s/100 iter), loss = 3.15793
I0506 04:31:39.329849 12834 solver.cpp:261]     Train net output #0: loss = 3.15793 (* 1 = 3.15793 loss)
I0506 04:31:39.329859 12834 sgd_solver.cpp:106] Iteration 15700, lr = 8e-05
I0506 04:31:39.334630 12834 solver.cpp:242] Iteration 15700 (105.06 iter/s, 0.951833s/100 iter), loss = 1.15341
I0506 04:31:39.334657 12834 solver.cpp:261]     Train net output #0: loss = 1.15341 (* 1 = 1.15341 loss)
I0506 04:31:39.334666 12834 sgd_solver.cpp:106] Iteration 15700, lr = 8e-05
I0506 04:31:40.267974 12834 solver.cpp:242] Iteration 15800 (106.599 iter/s, 0.938094s/100 iter), loss = 4.22985
I0506 04:31:40.268013 12834 solver.cpp:261]     Train net output #0: loss = 4.22985 (* 1 = 4.22985 loss)
I0506 04:31:40.268023 12834 sgd_solver.cpp:106] Iteration 15800, lr = 8e-05
I0506 04:31:40.272810 12834 solver.cpp:242] Iteration 15800 (106.595 iter/s, 0.938135s/100 iter), loss = 1.05855
I0506 04:31:40.272835 12834 solver.cpp:261]     Train net output #0: loss = 1.05855 (* 1 = 1.05855 loss)
I0506 04:31:40.272845 12834 sgd_solver.cpp:106] Iteration 15800, lr = 8e-05
I0506 04:31:41.270866 12834 solver.cpp:242] Iteration 15900 (99.7183 iter/s, 1.00282s/100 iter), loss = 1.9673
I0506 04:31:41.270912 12834 solver.cpp:261]     Train net output #0: loss = 1.9673 (* 1 = 1.9673 loss)
I0506 04:31:41.270923 12834 sgd_solver.cpp:106] Iteration 15900, lr = 8e-05
I0506 04:31:41.276154 12834 solver.cpp:242] Iteration 15900 (99.6712 iter/s, 1.0033s/100 iter), loss = 0.836518
I0506 04:31:41.276185 12834 solver.cpp:261]     Train net output #0: loss = 0.836518 (* 1 = 0.836518 loss)
I0506 04:31:41.276196 12834 sgd_solver.cpp:106] Iteration 15900, lr = 8e-05
I0506 04:31:42.246521 12834 solver.cpp:362] Iteration 16000, Testing net (#0)
I0506 04:31:42.246547 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:42.369474 12834 solver.cpp:429]     Test net output #0: loss = 3.32543 (* 1 = 3.32543 loss)
I0506 04:31:42.371999 12834 solver.cpp:242] Iteration 16000 (90.8208 iter/s, 1.10107s/100 iter), loss = 2.9836
I0506 04:31:42.372022 12834 solver.cpp:261]     Train net output #0: loss = 2.9836 (* 1 = 2.9836 loss)
I0506 04:31:42.372031 12834 sgd_solver.cpp:106] Iteration 16000, lr = 8e-05
I0506 04:31:42.373880 12834 solver.cpp:362] Iteration 16000, Testing net (#0)
I0506 04:31:42.373893 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:42.502745 12834 solver.cpp:429]     Test net output #0: accuracy = 0.547
I0506 04:31:42.502769 12834 solver.cpp:429]     Test net output #1: loss = 1.10301 (* 1 = 1.10301 loss)
I0506 04:31:42.505686 12834 solver.cpp:242] Iteration 16000 (81.3351 iter/s, 1.22948s/100 iter), loss = 1.2681
I0506 04:31:42.505708 12834 solver.cpp:261]     Train net output #0: loss = 1.2681 (* 1 = 1.2681 loss)
I0506 04:31:42.505717 12834 sgd_solver.cpp:106] Iteration 16000, lr = 8e-05
I0506 04:31:43.439273 12834 solver.cpp:242] Iteration 16100 (93.7012 iter/s, 1.06722s/100 iter), loss = 5.00738
I0506 04:31:43.439313 12834 solver.cpp:261]     Train net output #0: loss = 5.00738 (* 1 = 5.00738 loss)
I0506 04:31:43.439322 12834 sgd_solver.cpp:106] Iteration 16100, lr = 8e-05
I0506 04:31:43.444093 12834 solver.cpp:242] Iteration 16100 (106.568 iter/s, 0.938367s/100 iter), loss = 1.69017
I0506 04:31:43.444118 12834 solver.cpp:261]     Train net output #0: loss = 1.69017 (* 1 = 1.69017 loss)
I0506 04:31:43.444126 12834 sgd_solver.cpp:106] Iteration 16100, lr = 8e-05
I0506 04:31:44.378129 12834 solver.cpp:242] Iteration 16200 (106.521 iter/s, 0.938783s/100 iter), loss = 4.73165
I0506 04:31:44.378170 12834 solver.cpp:261]     Train net output #0: loss = 4.73165 (* 1 = 4.73165 loss)
I0506 04:31:44.378178 12834 sgd_solver.cpp:106] Iteration 16200, lr = 8e-05
I0506 04:31:44.382915 12834 solver.cpp:242] Iteration 16200 (106.522 iter/s, 0.938777s/100 iter), loss = 1.01531
I0506 04:31:44.382942 12834 solver.cpp:261]     Train net output #0: loss = 1.01531 (* 1 = 1.01531 loss)
I0506 04:31:44.382951 12834 sgd_solver.cpp:106] Iteration 16200, lr = 8e-05
I0506 04:31:45.315882 12834 solver.cpp:242] Iteration 16300 (106.645 iter/s, 0.937688s/100 iter), loss = 4.84268
I0506 04:31:45.315917 12834 solver.cpp:261]     Train net output #0: loss = 4.84268 (* 1 = 4.84268 loss)
I0506 04:31:45.315927 12834 sgd_solver.cpp:106] Iteration 16300, lr = 8e-05
I0506 04:31:45.320696 12834 solver.cpp:242] Iteration 16300 (106.64 iter/s, 0.937736s/100 iter), loss = 0.955022
I0506 04:31:45.320722 12834 solver.cpp:261]     Train net output #0: loss = 0.955022 (* 1 = 0.955022 loss)
I0506 04:31:45.320730 12834 sgd_solver.cpp:106] Iteration 16300, lr = 8e-05
I0506 04:31:46.254428 12834 solver.cpp:242] Iteration 16400 (106.555 iter/s, 0.938482s/100 iter), loss = 3.56849
I0506 04:31:46.254465 12834 solver.cpp:261]     Train net output #0: loss = 3.56849 (* 1 = 3.56849 loss)
I0506 04:31:46.254473 12834 sgd_solver.cpp:106] Iteration 16400, lr = 8e-05
I0506 04:31:46.259219 12834 solver.cpp:242] Iteration 16400 (106.555 iter/s, 0.938479s/100 iter), loss = 1.38049
I0506 04:31:46.259244 12834 solver.cpp:261]     Train net output #0: loss = 1.38049 (* 1 = 1.38049 loss)
I0506 04:31:46.259253 12834 sgd_solver.cpp:106] Iteration 16400, lr = 8e-05
I0506 04:31:47.253521 12834 solver.cpp:362] Iteration 16500, Testing net (#0)
I0506 04:31:47.253543 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:47.387075 12834 solver.cpp:429]     Test net output #0: loss = 2.95916 (* 1 = 2.95916 loss)
I0506 04:31:47.389744 12834 solver.cpp:242] Iteration 16500 (88.0859 iter/s, 1.13526s/100 iter), loss = 6.03884
I0506 04:31:47.389770 12834 solver.cpp:261]     Train net output #0: loss = 6.03884 (* 1 = 6.03884 loss)
I0506 04:31:47.389780 12834 sgd_solver.cpp:106] Iteration 16500, lr = 8e-05
I0506 04:31:47.392061 12834 solver.cpp:362] Iteration 16500, Testing net (#0)
I0506 04:31:47.392076 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:47.533282 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6125
I0506 04:31:47.533308 12834 solver.cpp:429]     Test net output #1: loss = 1.02297 (* 1 = 1.02297 loss)
I0506 04:31:47.536047 12834 solver.cpp:242] Iteration 16500 (78.322 iter/s, 1.27678s/100 iter), loss = 0.984578
I0506 04:31:47.536068 12834 solver.cpp:261]     Train net output #0: loss = 0.984578 (* 1 = 0.984578 loss)
I0506 04:31:47.536077 12834 sgd_solver.cpp:106] Iteration 16500, lr = 8e-05
I0506 04:31:48.469933 12834 solver.cpp:242] Iteration 16600 (92.5811 iter/s, 1.08013s/100 iter), loss = 1.31268
I0506 04:31:48.469975 12834 solver.cpp:261]     Train net output #0: loss = 1.31268 (* 1 = 1.31268 loss)
I0506 04:31:48.469986 12834 sgd_solver.cpp:106] Iteration 16600, lr = 8e-05
I0506 04:31:48.474714 12834 solver.cpp:242] Iteration 16600 (106.538 iter/s, 0.938628s/100 iter), loss = 1.13254
I0506 04:31:48.474740 12834 solver.cpp:261]     Train net output #0: loss = 1.13254 (* 1 = 1.13254 loss)
I0506 04:31:48.474747 12834 sgd_solver.cpp:106] Iteration 16600, lr = 8e-05
I0506 04:31:49.407841 12834 solver.cpp:242] Iteration 16700 (106.628 iter/s, 0.937837s/100 iter), loss = 2.7329
I0506 04:31:49.407873 12834 solver.cpp:261]     Train net output #0: loss = 2.7329 (* 1 = 2.7329 loss)
I0506 04:31:49.407882 12834 sgd_solver.cpp:106] Iteration 16700, lr = 8e-05
I0506 04:31:49.412624 12834 solver.cpp:242] Iteration 16700 (106.625 iter/s, 0.937866s/100 iter), loss = 1.19986
I0506 04:31:49.412649 12834 solver.cpp:261]     Train net output #0: loss = 1.19986 (* 1 = 1.19986 loss)
I0506 04:31:49.412657 12834 sgd_solver.cpp:106] Iteration 16700, lr = 8e-05
I0506 04:31:50.346398 12834 solver.cpp:242] Iteration 16800 (106.553 iter/s, 0.938499s/100 iter), loss = 4.35083
I0506 04:31:50.346426 12834 solver.cpp:261]     Train net output #0: loss = 4.35083 (* 1 = 4.35083 loss)
I0506 04:31:50.346436 12834 sgd_solver.cpp:106] Iteration 16800, lr = 8e-05
I0506 04:31:50.351152 12834 solver.cpp:242] Iteration 16800 (106.555 iter/s, 0.938485s/100 iter), loss = 1.05379
I0506 04:31:50.351176 12834 solver.cpp:261]     Train net output #0: loss = 1.05379 (* 1 = 1.05379 loss)
I0506 04:31:50.351184 12834 sgd_solver.cpp:106] Iteration 16800, lr = 8e-05
I0506 04:31:51.284237 12834 solver.cpp:242] Iteration 16900 (106.635 iter/s, 0.937779s/100 iter), loss = 3.34842
I0506 04:31:51.284278 12834 solver.cpp:261]     Train net output #0: loss = 3.34842 (* 1 = 3.34842 loss)
I0506 04:31:51.284287 12834 sgd_solver.cpp:106] Iteration 16900, lr = 8e-05
I0506 04:31:51.289042 12834 solver.cpp:242] Iteration 16900 (106.627 iter/s, 0.937848s/100 iter), loss = 1.36783
I0506 04:31:51.289067 12834 solver.cpp:261]     Train net output #0: loss = 1.36783 (* 1 = 1.36783 loss)
I0506 04:31:51.289075 12834 sgd_solver.cpp:106] Iteration 16900, lr = 8e-05
I0506 04:31:52.219414 12834 solver.cpp:362] Iteration 17000, Testing net (#0)
I0506 04:31:52.219440 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:52.342257 12834 solver.cpp:429]     Test net output #0: loss = 2.93172 (* 1 = 2.93172 loss)
I0506 04:31:52.344789 12834 solver.cpp:242] Iteration 17000 (94.2958 iter/s, 1.06049s/100 iter), loss = 3.66385
I0506 04:31:52.344810 12834 solver.cpp:261]     Train net output #0: loss = 3.66385 (* 1 = 3.66385 loss)
I0506 04:31:52.344817 12834 sgd_solver.cpp:106] Iteration 17000, lr = 8e-05
I0506 04:31:52.346626 12834 solver.cpp:362] Iteration 17000, Testing net (#0)
I0506 04:31:52.346639 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:52.475610 12834 solver.cpp:429]     Test net output #0: accuracy = 0.608
I0506 04:31:52.475630 12834 solver.cpp:429]     Test net output #1: loss = 0.985835 (* 1 = 0.985835 loss)
I0506 04:31:52.478196 12834 solver.cpp:242] Iteration 17000 (84.0966 iter/s, 1.18911s/100 iter), loss = 0.891032
I0506 04:31:52.478216 12834 solver.cpp:261]     Train net output #0: loss = 0.891032 (* 1 = 0.891032 loss)
I0506 04:31:52.478225 12834 sgd_solver.cpp:106] Iteration 17000, lr = 8e-05
I0506 04:31:53.412573 12834 solver.cpp:242] Iteration 17100 (93.6568 iter/s, 1.06773s/100 iter), loss = 4.12299
I0506 04:31:53.412616 12834 solver.cpp:261]     Train net output #0: loss = 4.12299 (* 1 = 4.12299 loss)
I0506 04:31:53.412624 12834 sgd_solver.cpp:106] Iteration 17100, lr = 8e-05
I0506 04:31:53.417354 12834 solver.cpp:242] Iteration 17100 (106.483 iter/s, 0.93912s/100 iter), loss = 0.867569
I0506 04:31:53.417379 12834 solver.cpp:261]     Train net output #0: loss = 0.867569 (* 1 = 0.867569 loss)
I0506 04:31:53.417388 12834 sgd_solver.cpp:106] Iteration 17100, lr = 8e-05
I0506 04:31:54.351478 12834 solver.cpp:242] Iteration 17200 (106.515 iter/s, 0.938838s/100 iter), loss = 1.9055
I0506 04:31:54.351532 12834 solver.cpp:261]     Train net output #0: loss = 1.9055 (* 1 = 1.9055 loss)
I0506 04:31:54.351542 12834 sgd_solver.cpp:106] Iteration 17200, lr = 8e-05
I0506 04:31:54.356299 12834 solver.cpp:242] Iteration 17200 (106.508 iter/s, 0.938901s/100 iter), loss = 0.909142
I0506 04:31:54.356326 12834 solver.cpp:261]     Train net output #0: loss = 0.909142 (* 1 = 0.909142 loss)
I0506 04:31:54.356334 12834 sgd_solver.cpp:106] Iteration 17200, lr = 8e-05
I0506 04:31:55.289624 12834 solver.cpp:242] Iteration 17300 (106.603 iter/s, 0.938062s/100 iter), loss = 3.64525
I0506 04:31:55.289664 12834 solver.cpp:261]     Train net output #0: loss = 3.64525 (* 1 = 3.64525 loss)
I0506 04:31:55.289674 12834 sgd_solver.cpp:106] Iteration 17300, lr = 8e-05
I0506 04:31:55.294387 12834 solver.cpp:242] Iteration 17300 (106.605 iter/s, 0.938043s/100 iter), loss = 0.911551
I0506 04:31:55.294411 12834 solver.cpp:261]     Train net output #0: loss = 0.911551 (* 1 = 0.911551 loss)
I0506 04:31:55.294420 12834 sgd_solver.cpp:106] Iteration 17300, lr = 8e-05
I0506 04:31:56.248019 12834 solver.cpp:242] Iteration 17400 (104.348 iter/s, 0.958329s/100 iter), loss = 3.5711
I0506 04:31:56.248065 12834 solver.cpp:261]     Train net output #0: loss = 3.5711 (* 1 = 3.5711 loss)
I0506 04:31:56.248075 12834 sgd_solver.cpp:106] Iteration 17400, lr = 8e-05
I0506 04:31:56.252871 12834 solver.cpp:242] Iteration 17400 (104.337 iter/s, 0.958431s/100 iter), loss = 0.699233
I0506 04:31:56.252899 12834 solver.cpp:261]     Train net output #0: loss = 0.699233 (* 1 = 0.699233 loss)
I0506 04:31:56.252908 12834 sgd_solver.cpp:106] Iteration 17400, lr = 8e-05
I0506 04:31:57.184123 12834 solver.cpp:362] Iteration 17500, Testing net (#0)
I0506 04:31:57.184149 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:57.306951 12834 solver.cpp:429]     Test net output #0: loss = 3.35768 (* 1 = 3.35768 loss)
I0506 04:31:57.309478 12834 solver.cpp:242] Iteration 17500 (94.2157 iter/s, 1.06139s/100 iter), loss = 1.78325
I0506 04:31:57.309501 12834 solver.cpp:261]     Train net output #0: loss = 1.78325 (* 1 = 1.78325 loss)
I0506 04:31:57.309509 12834 sgd_solver.cpp:106] Iteration 17500, lr = 8e-05
I0506 04:31:57.311332 12834 solver.cpp:362] Iteration 17500, Testing net (#0)
I0506 04:31:57.311345 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:31:57.440348 12834 solver.cpp:429]     Test net output #0: accuracy = 0.555
I0506 04:31:57.440369 12834 solver.cpp:429]     Test net output #1: loss = 1.11952 (* 1 = 1.11952 loss)
I0506 04:31:57.442935 12834 solver.cpp:242] Iteration 17500 (84.0326 iter/s, 1.19001s/100 iter), loss = 1.14272
I0506 04:31:57.442957 12834 solver.cpp:261]     Train net output #0: loss = 1.14272 (* 1 = 1.14272 loss)
I0506 04:31:57.442965 12834 sgd_solver.cpp:106] Iteration 17500, lr = 8e-05
I0506 04:31:58.376924 12834 solver.cpp:242] Iteration 17600 (93.6859 iter/s, 1.0674s/100 iter), loss = 1.97609
I0506 04:31:58.376960 12834 solver.cpp:261]     Train net output #0: loss = 1.97609 (* 1 = 1.97609 loss)
I0506 04:31:58.376971 12834 sgd_solver.cpp:106] Iteration 17600, lr = 8e-05
I0506 04:31:58.381696 12834 solver.cpp:242] Iteration 17600 (106.529 iter/s, 0.938713s/100 iter), loss = 1.36277
I0506 04:31:58.381723 12834 solver.cpp:261]     Train net output #0: loss = 1.36277 (* 1 = 1.36277 loss)
I0506 04:31:58.381732 12834 sgd_solver.cpp:106] Iteration 17600, lr = 8e-05
I0506 04:31:59.315250 12834 solver.cpp:242] Iteration 17700 (106.58 iter/s, 0.938263s/100 iter), loss = 1.49361
I0506 04:31:59.315286 12834 solver.cpp:261]     Train net output #0: loss = 1.49361 (* 1 = 1.49361 loss)
I0506 04:31:59.315295 12834 sgd_solver.cpp:106] Iteration 17700, lr = 8e-05
I0506 04:31:59.320036 12834 solver.cpp:242] Iteration 17700 (106.576 iter/s, 0.938293s/100 iter), loss = 1.22259
I0506 04:31:59.320061 12834 solver.cpp:261]     Train net output #0: loss = 1.22259 (* 1 = 1.22259 loss)
I0506 04:31:59.320070 12834 sgd_solver.cpp:106] Iteration 17700, lr = 8e-05
I0506 04:32:00.256320 12834 solver.cpp:242] Iteration 17800 (106.27 iter/s, 0.940997s/100 iter), loss = 4.22005
I0506 04:32:00.256387 12834 solver.cpp:261]     Train net output #0: loss = 4.22005 (* 1 = 4.22005 loss)
I0506 04:32:00.256398 12834 sgd_solver.cpp:106] Iteration 17800, lr = 8e-05
I0506 04:32:00.261379 12834 solver.cpp:242] Iteration 17800 (106.237 iter/s, 0.941295s/100 iter), loss = 1.16914
I0506 04:32:00.261425 12834 solver.cpp:261]     Train net output #0: loss = 1.16914 (* 1 = 1.16914 loss)
I0506 04:32:00.261448 12834 sgd_solver.cpp:106] Iteration 17800, lr = 8e-05
I0506 04:32:01.196745 12834 solver.cpp:242] Iteration 17900 (106.345 iter/s, 0.940334s/100 iter), loss = 1.86262
I0506 04:32:01.196779 12834 solver.cpp:261]     Train net output #0: loss = 1.86262 (* 1 = 1.86262 loss)
I0506 04:32:01.196789 12834 sgd_solver.cpp:106] Iteration 17900, lr = 8e-05
I0506 04:32:01.201508 12834 solver.cpp:242] Iteration 17900 (106.376 iter/s, 0.940065s/100 iter), loss = 0.994331
I0506 04:32:01.201534 12834 solver.cpp:261]     Train net output #0: loss = 0.994331 (* 1 = 0.994331 loss)
I0506 04:32:01.201542 12834 sgd_solver.cpp:106] Iteration 17900, lr = 8e-05
I0506 04:32:02.132030 12834 solver.cpp:362] Iteration 18000, Testing net (#0)
I0506 04:32:02.132057 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:02.254820 12834 solver.cpp:429]     Test net output #0: loss = 3.11591 (* 1 = 3.11591 loss)
I0506 04:32:02.257347 12834 solver.cpp:242] Iteration 18000 (94.2906 iter/s, 1.06055s/100 iter), loss = 2.09404
I0506 04:32:02.257367 12834 solver.cpp:261]     Train net output #0: loss = 2.09404 (* 1 = 2.09404 loss)
I0506 04:32:02.257376 12834 sgd_solver.cpp:106] Iteration 18000, lr = 8e-05
I0506 04:32:02.259201 12834 solver.cpp:362] Iteration 18000, Testing net (#0)
I0506 04:32:02.259213 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:02.388259 12834 solver.cpp:429]     Test net output #0: accuracy = 0.587
I0506 04:32:02.388279 12834 solver.cpp:429]     Test net output #1: loss = 1.0544 (* 1 = 1.0544 loss)
I0506 04:32:02.390842 12834 solver.cpp:242] Iteration 18000 (84.0839 iter/s, 1.18929s/100 iter), loss = 1.13227
I0506 04:32:02.390862 12834 solver.cpp:261]     Train net output #0: loss = 1.13227 (* 1 = 1.13227 loss)
I0506 04:32:02.390871 12834 sgd_solver.cpp:106] Iteration 18000, lr = 8e-05
I0506 04:32:03.337882 12834 solver.cpp:242] Iteration 18100 (92.5508 iter/s, 1.08049s/100 iter), loss = 1.95231
I0506 04:32:03.337913 12834 solver.cpp:261]     Train net output #0: loss = 1.95231 (* 1 = 1.95231 loss)
I0506 04:32:03.337921 12834 sgd_solver.cpp:106] Iteration 18100, lr = 8e-05
I0506 04:32:03.342661 12834 solver.cpp:242] Iteration 18100 (105.066 iter/s, 0.951779s/100 iter), loss = 0.964691
I0506 04:32:03.342686 12834 solver.cpp:261]     Train net output #0: loss = 0.964691 (* 1 = 0.964691 loss)
I0506 04:32:03.342694 12834 sgd_solver.cpp:106] Iteration 18100, lr = 8e-05
I0506 04:32:04.276449 12834 solver.cpp:242] Iteration 18200 (106.553 iter/s, 0.938504s/100 iter), loss = 4.13112
I0506 04:32:04.276494 12834 solver.cpp:261]     Train net output #0: loss = 4.13112 (* 1 = 4.13112 loss)
I0506 04:32:04.276504 12834 sgd_solver.cpp:106] Iteration 18200, lr = 8e-05
I0506 04:32:04.281226 12834 solver.cpp:242] Iteration 18200 (106.551 iter/s, 0.938522s/100 iter), loss = 0.880388
I0506 04:32:04.281251 12834 solver.cpp:261]     Train net output #0: loss = 0.880388 (* 1 = 0.880388 loss)
I0506 04:32:04.281260 12834 sgd_solver.cpp:106] Iteration 18200, lr = 8e-05
I0506 04:32:05.214998 12834 solver.cpp:242] Iteration 18300 (106.555 iter/s, 0.938479s/100 iter), loss = 1.3016
I0506 04:32:05.215037 12834 solver.cpp:261]     Train net output #0: loss = 1.3016 (* 1 = 1.3016 loss)
I0506 04:32:05.215046 12834 sgd_solver.cpp:106] Iteration 18300, lr = 8e-05
I0506 04:32:05.219920 12834 solver.cpp:242] Iteration 18300 (106.537 iter/s, 0.93864s/100 iter), loss = 1.54494
I0506 04:32:05.219945 12834 solver.cpp:261]     Train net output #0: loss = 1.54494 (* 1 = 1.54494 loss)
I0506 04:32:05.219954 12834 sgd_solver.cpp:106] Iteration 18300, lr = 8e-05
I0506 04:32:06.153578 12834 solver.cpp:242] Iteration 18400 (106.552 iter/s, 0.938512s/100 iter), loss = 2.14169
I0506 04:32:06.153619 12834 solver.cpp:261]     Train net output #0: loss = 2.14169 (* 1 = 2.14169 loss)
I0506 04:32:06.153627 12834 sgd_solver.cpp:106] Iteration 18400, lr = 8e-05
I0506 04:32:06.158372 12834 solver.cpp:242] Iteration 18400 (106.563 iter/s, 0.938409s/100 iter), loss = 0.687268
I0506 04:32:06.158398 12834 solver.cpp:261]     Train net output #0: loss = 0.687268 (* 1 = 0.687268 loss)
I0506 04:32:06.158406 12834 sgd_solver.cpp:106] Iteration 18400, lr = 8e-05
I0506 04:32:07.141938 12834 solver.cpp:362] Iteration 18500, Testing net (#0)
I0506 04:32:07.141968 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:07.275326 12834 solver.cpp:429]     Test net output #0: loss = 3.12402 (* 1 = 3.12402 loss)
I0506 04:32:07.277995 12834 solver.cpp:242] Iteration 18500 (88.9397 iter/s, 1.12436s/100 iter), loss = 3.47373
I0506 04:32:07.278022 12834 solver.cpp:261]     Train net output #0: loss = 3.47373 (* 1 = 3.47373 loss)
I0506 04:32:07.278031 12834 sgd_solver.cpp:106] Iteration 18500, lr = 8e-05
I0506 04:32:07.280303 12834 solver.cpp:362] Iteration 18500, Testing net (#0)
I0506 04:32:07.280320 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:07.421360 12834 solver.cpp:429]     Test net output #0: accuracy = 0.565
I0506 04:32:07.421386 12834 solver.cpp:429]     Test net output #1: loss = 1.02391 (* 1 = 1.02391 loss)
I0506 04:32:07.424077 12834 solver.cpp:242] Iteration 18500 (79.0104 iter/s, 1.26566s/100 iter), loss = 1.12009
I0506 04:32:07.424104 12834 solver.cpp:261]     Train net output #0: loss = 1.12009 (* 1 = 1.12009 loss)
I0506 04:32:07.424114 12834 sgd_solver.cpp:106] Iteration 18500, lr = 8e-05
I0506 04:32:08.442726 12834 solver.cpp:242] Iteration 18600 (85.8609 iter/s, 1.16467s/100 iter), loss = 2.74332
I0506 04:32:08.442767 12834 solver.cpp:261]     Train net output #0: loss = 2.74332 (* 1 = 2.74332 loss)
I0506 04:32:08.442776 12834 sgd_solver.cpp:106] Iteration 18600, lr = 8e-05
I0506 04:32:08.447494 12834 solver.cpp:242] Iteration 18600 (97.7163 iter/s, 1.02337s/100 iter), loss = 0.900621
I0506 04:32:08.447521 12834 solver.cpp:261]     Train net output #0: loss = 0.900621 (* 1 = 0.900621 loss)
I0506 04:32:08.447530 12834 sgd_solver.cpp:106] Iteration 18600, lr = 8e-05
I0506 04:32:09.381194 12834 solver.cpp:242] Iteration 18700 (106.565 iter/s, 0.938396s/100 iter), loss = 6.49057
I0506 04:32:09.381234 12834 solver.cpp:261]     Train net output #0: loss = 6.49057 (* 1 = 6.49057 loss)
I0506 04:32:09.381243 12834 sgd_solver.cpp:106] Iteration 18700, lr = 8e-05
I0506 04:32:09.385979 12834 solver.cpp:242] Iteration 18700 (106.56 iter/s, 0.93844s/100 iter), loss = 1.00665
I0506 04:32:09.386005 12834 solver.cpp:261]     Train net output #0: loss = 1.00665 (* 1 = 1.00665 loss)
I0506 04:32:09.386014 12834 sgd_solver.cpp:106] Iteration 18700, lr = 8e-05
I0506 04:32:10.319703 12834 solver.cpp:242] Iteration 18800 (106.559 iter/s, 0.938445s/100 iter), loss = 1.63829
I0506 04:32:10.319742 12834 solver.cpp:261]     Train net output #0: loss = 1.63829 (* 1 = 1.63829 loss)
I0506 04:32:10.319751 12834 sgd_solver.cpp:106] Iteration 18800, lr = 8e-05
I0506 04:32:10.324525 12834 solver.cpp:242] Iteration 18800 (106.553 iter/s, 0.938501s/100 iter), loss = 1.16698
I0506 04:32:10.324566 12834 solver.cpp:261]     Train net output #0: loss = 1.16698 (* 1 = 1.16698 loss)
I0506 04:32:10.324578 12834 sgd_solver.cpp:106] Iteration 18800, lr = 8e-05
I0506 04:32:11.258180 12834 solver.cpp:242] Iteration 18900 (106.563 iter/s, 0.93841s/100 iter), loss = 4.74129
I0506 04:32:11.258219 12834 solver.cpp:261]     Train net output #0: loss = 4.74129 (* 1 = 4.74129 loss)
I0506 04:32:11.258229 12834 sgd_solver.cpp:106] Iteration 18900, lr = 8e-05
I0506 04:32:11.262955 12834 solver.cpp:242] Iteration 18900 (106.566 iter/s, 0.938386s/100 iter), loss = 0.792512
I0506 04:32:11.262980 12834 solver.cpp:261]     Train net output #0: loss = 0.792512 (* 1 = 0.792512 loss)
I0506 04:32:11.262989 12834 sgd_solver.cpp:106] Iteration 18900, lr = 8e-05
I0506 04:32:12.194883 12834 solver.cpp:362] Iteration 19000, Testing net (#0)
I0506 04:32:12.194911 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:12.317729 12834 solver.cpp:429]     Test net output #0: loss = 2.73576 (* 1 = 2.73576 loss)
I0506 04:32:12.320255 12834 solver.cpp:242] Iteration 19000 (94.1605 iter/s, 1.06202s/100 iter), loss = 2.26651
I0506 04:32:12.320274 12834 solver.cpp:261]     Train net output #0: loss = 2.26651 (* 1 = 2.26651 loss)
I0506 04:32:12.320283 12834 sgd_solver.cpp:106] Iteration 19000, lr = 8e-05
I0506 04:32:12.322110 12834 solver.cpp:362] Iteration 19000, Testing net (#0)
I0506 04:32:12.322125 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:12.451119 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6185
I0506 04:32:12.451139 12834 solver.cpp:429]     Test net output #1: loss = 0.985958 (* 1 = 0.985958 loss)
I0506 04:32:12.453713 12834 solver.cpp:242] Iteration 19000 (83.9833 iter/s, 1.19071s/100 iter), loss = 0.986359
I0506 04:32:12.453733 12834 solver.cpp:261]     Train net output #0: loss = 0.986359 (* 1 = 0.986359 loss)
I0506 04:32:12.453742 12834 sgd_solver.cpp:106] Iteration 19000, lr = 8e-05
I0506 04:32:13.387395 12834 solver.cpp:242] Iteration 19100 (93.713 iter/s, 1.06709s/100 iter), loss = 4.23807
I0506 04:32:13.387432 12834 solver.cpp:261]     Train net output #0: loss = 4.23807 (* 1 = 4.23807 loss)
I0506 04:32:13.387441 12834 sgd_solver.cpp:106] Iteration 19100, lr = 8e-05
I0506 04:32:13.392180 12834 solver.cpp:242] Iteration 19100 (106.561 iter/s, 0.938428s/100 iter), loss = 1.13921
I0506 04:32:13.392208 12834 solver.cpp:261]     Train net output #0: loss = 1.13921 (* 1 = 1.13921 loss)
I0506 04:32:13.392216 12834 sgd_solver.cpp:106] Iteration 19100, lr = 8e-05
I0506 04:32:14.325700 12834 solver.cpp:242] Iteration 19200 (106.582 iter/s, 0.938244s/100 iter), loss = 1.21342
I0506 04:32:14.325736 12834 solver.cpp:261]     Train net output #0: loss = 1.21342 (* 1 = 1.21342 loss)
I0506 04:32:14.325745 12834 sgd_solver.cpp:106] Iteration 19200, lr = 8e-05
I0506 04:32:14.330557 12834 solver.cpp:242] Iteration 19200 (106.573 iter/s, 0.938322s/100 iter), loss = 1.06741
I0506 04:32:14.330584 12834 solver.cpp:261]     Train net output #0: loss = 1.06741 (* 1 = 1.06741 loss)
I0506 04:32:14.330591 12834 sgd_solver.cpp:106] Iteration 19200, lr = 8e-05
I0506 04:32:15.277248 12834 solver.cpp:242] Iteration 19300 (105.099 iter/s, 0.951485s/100 iter), loss = 1.19123
I0506 04:32:15.277279 12834 solver.cpp:261]     Train net output #0: loss = 1.19123 (* 1 = 1.19123 loss)
I0506 04:32:15.277288 12834 sgd_solver.cpp:106] Iteration 19300, lr = 8e-05
I0506 04:32:15.282025 12834 solver.cpp:242] Iteration 19300 (105.106 iter/s, 0.951424s/100 iter), loss = 0.649684
I0506 04:32:15.282050 12834 solver.cpp:261]     Train net output #0: loss = 0.649684 (* 1 = 0.649684 loss)
I0506 04:32:15.282058 12834 sgd_solver.cpp:106] Iteration 19300, lr = 8e-05
I0506 04:32:16.215497 12834 solver.cpp:242] Iteration 19400 (106.588 iter/s, 0.938193s/100 iter), loss = 4.62178
I0506 04:32:16.215535 12834 solver.cpp:261]     Train net output #0: loss = 4.62178 (* 1 = 4.62178 loss)
I0506 04:32:16.215544 12834 sgd_solver.cpp:106] Iteration 19400, lr = 8e-05
I0506 04:32:16.220331 12834 solver.cpp:242] Iteration 19400 (106.581 iter/s, 0.938255s/100 iter), loss = 1.4471
I0506 04:32:16.220356 12834 solver.cpp:261]     Train net output #0: loss = 1.4471 (* 1 = 1.4471 loss)
I0506 04:32:16.220365 12834 sgd_solver.cpp:106] Iteration 19400, lr = 8e-05
I0506 04:32:17.151085 12834 solver.cpp:362] Iteration 19500, Testing net (#0)
I0506 04:32:17.151113 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:17.273978 12834 solver.cpp:429]     Test net output #0: loss = 3.31681 (* 1 = 3.31681 loss)
I0506 04:32:17.276499 12834 solver.cpp:242] Iteration 19500 (94.2556 iter/s, 1.06094s/100 iter), loss = 3.19286
I0506 04:32:17.276520 12834 solver.cpp:261]     Train net output #0: loss = 3.19286 (* 1 = 3.19286 loss)
I0506 04:32:17.276528 12834 sgd_solver.cpp:106] Iteration 19500, lr = 8e-05
I0506 04:32:17.278344 12834 solver.cpp:362] Iteration 19500, Testing net (#0)
I0506 04:32:17.278358 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:17.407366 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5675
I0506 04:32:17.407385 12834 solver.cpp:429]     Test net output #1: loss = 1.10572 (* 1 = 1.10572 loss)
I0506 04:32:17.409946 12834 solver.cpp:242] Iteration 19500 (84.064 iter/s, 1.18957s/100 iter), loss = 1.28067
I0506 04:32:17.409967 12834 solver.cpp:261]     Train net output #0: loss = 1.28067 (* 1 = 1.28067 loss)
I0506 04:32:17.409976 12834 sgd_solver.cpp:106] Iteration 19500, lr = 8e-05
I0506 04:32:18.344064 12834 solver.cpp:242] Iteration 19600 (93.6759 iter/s, 1.06751s/100 iter), loss = 3.90426
I0506 04:32:18.344096 12834 solver.cpp:261]     Train net output #0: loss = 3.90426 (* 1 = 3.90426 loss)
I0506 04:32:18.344105 12834 sgd_solver.cpp:106] Iteration 19600, lr = 8e-05
I0506 04:32:18.348860 12834 solver.cpp:242] Iteration 19600 (106.511 iter/s, 0.938874s/100 iter), loss = 1.45551
I0506 04:32:18.348884 12834 solver.cpp:261]     Train net output #0: loss = 1.45551 (* 1 = 1.45551 loss)
I0506 04:32:18.348892 12834 sgd_solver.cpp:106] Iteration 19600, lr = 8e-05
I0506 04:32:19.282088 12834 solver.cpp:242] Iteration 19700 (106.614 iter/s, 0.937965s/100 iter), loss = 1.50625
I0506 04:32:19.282135 12834 solver.cpp:261]     Train net output #0: loss = 1.50625 (* 1 = 1.50625 loss)
I0506 04:32:19.282371 12834 sgd_solver.cpp:106] Iteration 19700, lr = 8e-05
I0506 04:32:19.287216 12834 solver.cpp:242] Iteration 19700 (106.574 iter/s, 0.938314s/100 iter), loss = 1.05239
I0506 04:32:19.287240 12834 solver.cpp:261]     Train net output #0: loss = 1.05239 (* 1 = 1.05239 loss)
I0506 04:32:19.287248 12834 sgd_solver.cpp:106] Iteration 19700, lr = 8e-05
I0506 04:32:20.221653 12834 solver.cpp:242] Iteration 19800 (106.441 iter/s, 0.939489s/100 iter), loss = 3.34405
I0506 04:32:20.221693 12834 solver.cpp:261]     Train net output #0: loss = 3.34405 (* 1 = 3.34405 loss)
I0506 04:32:20.221704 12834 sgd_solver.cpp:106] Iteration 19800, lr = 8e-05
I0506 04:32:20.226431 12834 solver.cpp:242] Iteration 19800 (106.477 iter/s, 0.939173s/100 iter), loss = 0.640526
I0506 04:32:20.226457 12834 solver.cpp:261]     Train net output #0: loss = 0.640526 (* 1 = 0.640526 loss)
I0506 04:32:20.226466 12834 sgd_solver.cpp:106] Iteration 19800, lr = 8e-05
I0506 04:32:21.160012 12834 solver.cpp:242] Iteration 19900 (106.576 iter/s, 0.938293s/100 iter), loss = 1.33974
I0506 04:32:21.160048 12834 solver.cpp:261]     Train net output #0: loss = 1.33974 (* 1 = 1.33974 loss)
I0506 04:32:21.160058 12834 sgd_solver.cpp:106] Iteration 19900, lr = 8e-05
I0506 04:32:21.164800 12834 solver.cpp:242] Iteration 19900 (106.573 iter/s, 0.938323s/100 iter), loss = 1.08201
I0506 04:32:21.164825 12834 solver.cpp:261]     Train net output #0: loss = 1.08201 (* 1 = 1.08201 loss)
I0506 04:32:21.164834 12834 sgd_solver.cpp:106] Iteration 19900, lr = 8e-05
I0506 04:32:22.096112 12834 solver.cpp:362] Iteration 20000, Testing net (#0)
I0506 04:32:22.096138 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:22.218940 12834 solver.cpp:429]     Test net output #0: loss = 3.10921 (* 1 = 3.10921 loss)
I0506 04:32:22.221468 12834 solver.cpp:242] Iteration 20000 (94.2151 iter/s, 1.0614s/100 iter), loss = 0.90779
I0506 04:32:22.221489 12834 solver.cpp:261]     Train net output #0: loss = 0.90779 (* 1 = 0.90779 loss)
I0506 04:32:22.221498 12834 sgd_solver.cpp:106] Iteration 20000, lr = 6.4e-05
I0506 04:32:22.223323 12834 solver.cpp:362] Iteration 20000, Testing net (#0)
I0506 04:32:22.223337 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:22.352450 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5995
I0506 04:32:22.352470 12834 solver.cpp:429]     Test net output #1: loss = 1.0006 (* 1 = 1.0006 loss)
I0506 04:32:22.355043 12834 solver.cpp:242] Iteration 20000 (84.0197 iter/s, 1.1902s/100 iter), loss = 1.01266
I0506 04:32:22.355064 12834 solver.cpp:261]     Train net output #0: loss = 1.01266 (* 1 = 1.01266 loss)
I0506 04:32:22.355080 12834 sgd_solver.cpp:106] Iteration 20000, lr = 6.4e-05
I0506 04:32:23.362231 12834 solver.cpp:242] Iteration 20100 (87.6646 iter/s, 1.14071s/100 iter), loss = 2.14358
I0506 04:32:23.362277 12834 solver.cpp:261]     Train net output #0: loss = 2.14358 (* 1 = 2.14358 loss)
I0506 04:32:23.362287 12834 sgd_solver.cpp:106] Iteration 20100, lr = 6.4e-05
I0506 04:32:23.367683 12834 solver.cpp:242] Iteration 20100 (98.757 iter/s, 1.01259s/100 iter), loss = 0.936016
I0506 04:32:23.367717 12834 solver.cpp:261]     Train net output #0: loss = 0.936016 (* 1 = 0.936016 loss)
I0506 04:32:23.367728 12834 sgd_solver.cpp:106] Iteration 20100, lr = 6.4e-05
I0506 04:32:24.397593 12834 solver.cpp:242] Iteration 20200 (96.5914 iter/s, 1.03529s/100 iter), loss = 5.2994
I0506 04:32:24.397630 12834 solver.cpp:261]     Train net output #0: loss = 5.2994 (* 1 = 5.2994 loss)
I0506 04:32:24.397640 12834 sgd_solver.cpp:106] Iteration 20200, lr = 6.4e-05
I0506 04:32:24.402360 12834 solver.cpp:242] Iteration 20200 (96.6534 iter/s, 1.03463s/100 iter), loss = 1.17698
I0506 04:32:24.402387 12834 solver.cpp:261]     Train net output #0: loss = 1.17698 (* 1 = 1.17698 loss)
I0506 04:32:24.402395 12834 sgd_solver.cpp:106] Iteration 20200, lr = 6.4e-05
I0506 04:32:25.335849 12834 solver.cpp:242] Iteration 20300 (106.588 iter/s, 0.938192s/100 iter), loss = 4.09189
I0506 04:32:25.335886 12834 solver.cpp:261]     Train net output #0: loss = 4.09189 (* 1 = 4.09189 loss)
I0506 04:32:25.335896 12834 sgd_solver.cpp:106] Iteration 20300, lr = 6.4e-05
I0506 04:32:25.340734 12834 solver.cpp:242] Iteration 20300 (106.574 iter/s, 0.938319s/100 iter), loss = 1.03468
I0506 04:32:25.340759 12834 solver.cpp:261]     Train net output #0: loss = 1.03468 (* 1 = 1.03468 loss)
I0506 04:32:25.340767 12834 sgd_solver.cpp:106] Iteration 20300, lr = 6.4e-05
I0506 04:32:26.274510 12834 solver.cpp:242] Iteration 20400 (106.542 iter/s, 0.938597s/100 iter), loss = 2.98374
I0506 04:32:26.274546 12834 solver.cpp:261]     Train net output #0: loss = 2.98374 (* 1 = 2.98374 loss)
I0506 04:32:26.274555 12834 sgd_solver.cpp:106] Iteration 20400, lr = 6.4e-05
I0506 04:32:26.279270 12834 solver.cpp:242] Iteration 20400 (106.554 iter/s, 0.938493s/100 iter), loss = 0.553614
I0506 04:32:26.279294 12834 solver.cpp:261]     Train net output #0: loss = 0.553614 (* 1 = 0.553614 loss)
I0506 04:32:26.279302 12834 sgd_solver.cpp:106] Iteration 20400, lr = 6.4e-05
I0506 04:32:27.223390 12834 solver.cpp:362] Iteration 20500, Testing net (#0)
I0506 04:32:27.223413 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:27.346325 12834 solver.cpp:429]     Test net output #0: loss = 2.81027 (* 1 = 2.81027 loss)
I0506 04:32:27.348839 12834 solver.cpp:242] Iteration 20500 (93.0861 iter/s, 1.07427s/100 iter), loss = 2.87282
I0506 04:32:27.348860 12834 solver.cpp:261]     Train net output #0: loss = 2.87282 (* 1 = 2.87282 loss)
I0506 04:32:27.348867 12834 sgd_solver.cpp:106] Iteration 20500, lr = 6.4e-05
I0506 04:32:27.350688 12834 solver.cpp:362] Iteration 20500, Testing net (#0)
I0506 04:32:27.350702 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:27.479969 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5195
I0506 04:32:27.479990 12834 solver.cpp:429]     Test net output #1: loss = 1.18447 (* 1 = 1.18447 loss)
I0506 04:32:27.482556 12834 solver.cpp:242] Iteration 20500 (83.1089 iter/s, 1.20324s/100 iter), loss = 0.947902
I0506 04:32:27.482576 12834 solver.cpp:261]     Train net output #0: loss = 0.947902 (* 1 = 0.947902 loss)
I0506 04:32:27.482585 12834 sgd_solver.cpp:106] Iteration 20500, lr = 6.4e-05
I0506 04:32:28.415565 12834 solver.cpp:242] Iteration 20600 (93.7491 iter/s, 1.06668s/100 iter), loss = 1.90425
I0506 04:32:28.415601 12834 solver.cpp:261]     Train net output #0: loss = 1.90425 (* 1 = 1.90425 loss)
I0506 04:32:28.415609 12834 sgd_solver.cpp:106] Iteration 20600, lr = 6.4e-05
I0506 04:32:28.420354 12834 solver.cpp:242] Iteration 20600 (106.637 iter/s, 0.937759s/100 iter), loss = 0.78472
I0506 04:32:28.420382 12834 solver.cpp:261]     Train net output #0: loss = 0.78472 (* 1 = 0.78472 loss)
I0506 04:32:28.420400 12834 sgd_solver.cpp:106] Iteration 20600, lr = 6.4e-05
I0506 04:32:29.434139 12834 solver.cpp:242] Iteration 20700 (98.1829 iter/s, 1.01851s/100 iter), loss = 3.06583
I0506 04:32:29.434186 12834 solver.cpp:261]     Train net output #0: loss = 3.06583 (* 1 = 3.06583 loss)
I0506 04:32:29.434267 12834 sgd_solver.cpp:106] Iteration 20700, lr = 6.4e-05
I0506 04:32:29.439041 12834 solver.cpp:242] Iteration 20700 (98.1701 iter/s, 1.01864s/100 iter), loss = 1.0268
I0506 04:32:29.439065 12834 solver.cpp:261]     Train net output #0: loss = 1.0268 (* 1 = 1.0268 loss)
I0506 04:32:29.439074 12834 sgd_solver.cpp:106] Iteration 20700, lr = 6.4e-05
I0506 04:32:30.372685 12834 solver.cpp:242] Iteration 20800 (106.556 iter/s, 0.938476s/100 iter), loss = 2.59593
I0506 04:32:30.372719 12834 solver.cpp:261]     Train net output #0: loss = 2.59593 (* 1 = 2.59593 loss)
I0506 04:32:30.372727 12834 sgd_solver.cpp:106] Iteration 20800, lr = 6.4e-05
I0506 04:32:30.377594 12834 solver.cpp:242] Iteration 20800 (106.552 iter/s, 0.93851s/100 iter), loss = 0.972701
I0506 04:32:30.377619 12834 solver.cpp:261]     Train net output #0: loss = 0.972701 (* 1 = 0.972701 loss)
I0506 04:32:30.377627 12834 sgd_solver.cpp:106] Iteration 20800, lr = 6.4e-05
I0506 04:32:31.310887 12834 solver.cpp:242] Iteration 20900 (106.594 iter/s, 0.93814s/100 iter), loss = 3.31798
I0506 04:32:31.310928 12834 solver.cpp:261]     Train net output #0: loss = 3.31798 (* 1 = 3.31798 loss)
I0506 04:32:31.310937 12834 sgd_solver.cpp:106] Iteration 20900, lr = 6.4e-05
I0506 04:32:31.315692 12834 solver.cpp:242] Iteration 20900 (106.604 iter/s, 0.938055s/100 iter), loss = 1.16606
I0506 04:32:31.315717 12834 solver.cpp:261]     Train net output #0: loss = 1.16606 (* 1 = 1.16606 loss)
I0506 04:32:31.315726 12834 sgd_solver.cpp:106] Iteration 20900, lr = 6.4e-05
I0506 04:32:32.246393 12834 solver.cpp:362] Iteration 21000, Testing net (#0)
I0506 04:32:32.246419 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:32.369350 12834 solver.cpp:429]     Test net output #0: loss = 2.79455 (* 1 = 2.79455 loss)
I0506 04:32:32.371881 12834 solver.cpp:242] Iteration 21000 (94.2565 iter/s, 1.06093s/100 iter), loss = 2.40251
I0506 04:32:32.371901 12834 solver.cpp:261]     Train net output #0: loss = 2.40251 (* 1 = 2.40251 loss)
I0506 04:32:32.371909 12834 sgd_solver.cpp:106] Iteration 21000, lr = 6.4e-05
I0506 04:32:32.373906 12834 solver.cpp:362] Iteration 21000, Testing net (#0)
I0506 04:32:32.373922 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:32.502619 12834 solver.cpp:429]     Test net output #0: accuracy = 0.625
I0506 04:32:32.502638 12834 solver.cpp:429]     Test net output #1: loss = 0.960373 (* 1 = 0.960373 loss)
I0506 04:32:32.505184 12834 solver.cpp:242] Iteration 21000 (84.0727 iter/s, 1.18945s/100 iter), loss = 1.19199
I0506 04:32:32.505205 12834 solver.cpp:261]     Train net output #0: loss = 1.19199 (* 1 = 1.19199 loss)
I0506 04:32:32.505213 12834 sgd_solver.cpp:106] Iteration 21000, lr = 6.4e-05
I0506 04:32:33.438724 12834 solver.cpp:242] Iteration 21100 (93.7388 iter/s, 1.06679s/100 iter), loss = 2.79959
I0506 04:32:33.438755 12834 solver.cpp:261]     Train net output #0: loss = 2.79959 (* 1 = 2.79959 loss)
I0506 04:32:33.438763 12834 sgd_solver.cpp:106] Iteration 21100, lr = 6.4e-05
I0506 04:32:33.443500 12834 solver.cpp:242] Iteration 21100 (106.578 iter/s, 0.938277s/100 iter), loss = 0.966034
I0506 04:32:33.443523 12834 solver.cpp:261]     Train net output #0: loss = 0.966034 (* 1 = 0.966034 loss)
I0506 04:32:33.443532 12834 sgd_solver.cpp:106] Iteration 21100, lr = 6.4e-05
I0506 04:32:34.377326 12834 solver.cpp:242] Iteration 21200 (106.548 iter/s, 0.938547s/100 iter), loss = 4.06762
I0506 04:32:34.377368 12834 solver.cpp:261]     Train net output #0: loss = 4.06762 (* 1 = 4.06762 loss)
I0506 04:32:34.377377 12834 sgd_solver.cpp:106] Iteration 21200, lr = 6.4e-05
I0506 04:32:34.382184 12834 solver.cpp:242] Iteration 21200 (106.538 iter/s, 0.938634s/100 iter), loss = 1.59887
I0506 04:32:34.382218 12834 solver.cpp:261]     Train net output #0: loss = 1.59887 (* 1 = 1.59887 loss)
I0506 04:32:34.382228 12834 sgd_solver.cpp:106] Iteration 21200, lr = 6.4e-05
I0506 04:32:35.316226 12834 solver.cpp:242] Iteration 21300 (106.515 iter/s, 0.938833s/100 iter), loss = 1.93534
I0506 04:32:35.316270 12834 solver.cpp:261]     Train net output #0: loss = 1.93534 (* 1 = 1.93534 loss)
I0506 04:32:35.316280 12834 sgd_solver.cpp:106] Iteration 21300, lr = 6.4e-05
I0506 04:32:35.321035 12834 solver.cpp:242] Iteration 21300 (106.519 iter/s, 0.938798s/100 iter), loss = 1.31795
I0506 04:32:35.321060 12834 solver.cpp:261]     Train net output #0: loss = 1.31795 (* 1 = 1.31795 loss)
I0506 04:32:35.321069 12834 sgd_solver.cpp:106] Iteration 21300, lr = 6.4e-05
I0506 04:32:36.254758 12834 solver.cpp:242] Iteration 21400 (106.558 iter/s, 0.938458s/100 iter), loss = 3.00289
I0506 04:32:36.254798 12834 solver.cpp:261]     Train net output #0: loss = 3.00289 (* 1 = 3.00289 loss)
I0506 04:32:36.254807 12834 sgd_solver.cpp:106] Iteration 21400, lr = 6.4e-05
I0506 04:32:36.259527 12834 solver.cpp:242] Iteration 21400 (106.559 iter/s, 0.938448s/100 iter), loss = 1.03097
I0506 04:32:36.259553 12834 solver.cpp:261]     Train net output #0: loss = 1.03097 (* 1 = 1.03097 loss)
I0506 04:32:36.259562 12834 sgd_solver.cpp:106] Iteration 21400, lr = 6.4e-05
I0506 04:32:37.189875 12834 solver.cpp:362] Iteration 21500, Testing net (#0)
I0506 04:32:37.189899 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:37.312638 12834 solver.cpp:429]     Test net output #0: loss = 2.73266 (* 1 = 2.73266 loss)
I0506 04:32:37.315168 12834 solver.cpp:242] Iteration 21500 (94.3086 iter/s, 1.06035s/100 iter), loss = 2.83188
I0506 04:32:37.315187 12834 solver.cpp:261]     Train net output #0: loss = 2.83188 (* 1 = 2.83188 loss)
I0506 04:32:37.315196 12834 sgd_solver.cpp:106] Iteration 21500, lr = 6.4e-05
I0506 04:32:37.317034 12834 solver.cpp:362] Iteration 21500, Testing net (#0)
I0506 04:32:37.317049 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:37.446102 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6355
I0506 04:32:37.446122 12834 solver.cpp:429]     Test net output #1: loss = 0.932347 (* 1 = 0.932347 loss)
I0506 04:32:37.448674 12834 solver.cpp:242] Iteration 21500 (84.0972 iter/s, 1.1891s/100 iter), loss = 1.28908
I0506 04:32:37.448694 12834 solver.cpp:261]     Train net output #0: loss = 1.28908 (* 1 = 1.28908 loss)
I0506 04:32:37.448703 12834 sgd_solver.cpp:106] Iteration 21500, lr = 6.4e-05
I0506 04:32:38.382001 12834 solver.cpp:242] Iteration 21600 (93.74 iter/s, 1.06678s/100 iter), loss = 2.61871
I0506 04:32:38.382040 12834 solver.cpp:261]     Train net output #0: loss = 2.61871 (* 1 = 2.61871 loss)
I0506 04:32:38.382050 12834 sgd_solver.cpp:106] Iteration 21600, lr = 6.4e-05
I0506 04:32:38.386822 12834 solver.cpp:242] Iteration 21600 (106.597 iter/s, 0.93811s/100 iter), loss = 0.686904
I0506 04:32:38.386849 12834 solver.cpp:261]     Train net output #0: loss = 0.686904 (* 1 = 0.686904 loss)
I0506 04:32:38.386858 12834 sgd_solver.cpp:106] Iteration 21600, lr = 6.4e-05
I0506 04:32:39.319768 12834 solver.cpp:242] Iteration 21700 (106.644 iter/s, 0.937703s/100 iter), loss = 2.17346
I0506 04:32:39.319806 12834 solver.cpp:261]     Train net output #0: loss = 2.17346 (* 1 = 2.17346 loss)
I0506 04:32:39.319815 12834 sgd_solver.cpp:106] Iteration 21700, lr = 6.4e-05
I0506 04:32:39.324534 12834 solver.cpp:242] Iteration 21700 (106.648 iter/s, 0.937667s/100 iter), loss = 0.92324
I0506 04:32:39.324564 12834 solver.cpp:261]     Train net output #0: loss = 0.92324 (* 1 = 0.92324 loss)
I0506 04:32:39.324573 12834 sgd_solver.cpp:106] Iteration 21700, lr = 6.4e-05
I0506 04:32:40.258433 12834 solver.cpp:242] Iteration 21800 (106.542 iter/s, 0.938597s/100 iter), loss = 3.55079
I0506 04:32:40.258472 12834 solver.cpp:261]     Train net output #0: loss = 3.55079 (* 1 = 3.55079 loss)
I0506 04:32:40.258482 12834 sgd_solver.cpp:106] Iteration 21800, lr = 6.4e-05
I0506 04:32:40.263207 12834 solver.cpp:242] Iteration 21800 (106.539 iter/s, 0.938624s/100 iter), loss = 0.906547
I0506 04:32:40.263240 12834 solver.cpp:261]     Train net output #0: loss = 0.906547 (* 1 = 0.906547 loss)
I0506 04:32:40.263249 12834 sgd_solver.cpp:106] Iteration 21800, lr = 6.4e-05
I0506 04:32:41.196720 12834 solver.cpp:242] Iteration 21900 (106.584 iter/s, 0.938224s/100 iter), loss = 1.08383
I0506 04:32:41.196755 12834 solver.cpp:261]     Train net output #0: loss = 1.08383 (* 1 = 1.08383 loss)
I0506 04:32:41.196764 12834 sgd_solver.cpp:106] Iteration 21900, lr = 6.4e-05
I0506 04:32:41.201566 12834 solver.cpp:242] Iteration 21900 (106.576 iter/s, 0.938299s/100 iter), loss = 1.58746
I0506 04:32:41.201591 12834 solver.cpp:261]     Train net output #0: loss = 1.58746 (* 1 = 1.58746 loss)
I0506 04:32:41.201599 12834 sgd_solver.cpp:106] Iteration 21900, lr = 6.4e-05
I0506 04:32:42.132390 12834 solver.cpp:362] Iteration 22000, Testing net (#0)
I0506 04:32:42.132411 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:42.255100 12834 solver.cpp:429]     Test net output #0: loss = 2.56292 (* 1 = 2.56292 loss)
I0506 04:32:42.257629 12834 solver.cpp:242] Iteration 22000 (94.2636 iter/s, 1.06085s/100 iter), loss = 1.82507
I0506 04:32:42.257650 12834 solver.cpp:261]     Train net output #0: loss = 1.82507 (* 1 = 1.82507 loss)
I0506 04:32:42.257658 12834 sgd_solver.cpp:106] Iteration 22000, lr = 6.4e-05
I0506 04:32:42.259471 12834 solver.cpp:362] Iteration 22000, Testing net (#0)
I0506 04:32:42.259483 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:42.388622 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6225
I0506 04:32:42.388640 12834 solver.cpp:429]     Test net output #1: loss = 0.927335 (* 1 = 0.927335 loss)
I0506 04:32:42.391194 12834 solver.cpp:242] Iteration 22000 (84.0631 iter/s, 1.18958s/100 iter), loss = 0.736872
I0506 04:32:42.391214 12834 solver.cpp:261]     Train net output #0: loss = 0.736872 (* 1 = 0.736872 loss)
I0506 04:32:42.391223 12834 sgd_solver.cpp:106] Iteration 22000, lr = 6.4e-05
I0506 04:32:43.402495 12834 solver.cpp:242] Iteration 22100 (87.3503 iter/s, 1.14482s/100 iter), loss = 4.22737
I0506 04:32:43.402536 12834 solver.cpp:261]     Train net output #0: loss = 4.22737 (* 1 = 4.22737 loss)
I0506 04:32:43.402549 12834 sgd_solver.cpp:106] Iteration 22100, lr = 6.4e-05
I0506 04:32:43.407877 12834 solver.cpp:242] Iteration 22100 (98.364 iter/s, 1.01663s/100 iter), loss = 1.11633
I0506 04:32:43.407905 12834 solver.cpp:261]     Train net output #0: loss = 1.11633 (* 1 = 1.11633 loss)
I0506 04:32:43.407915 12834 sgd_solver.cpp:106] Iteration 22100, lr = 6.4e-05
I0506 04:32:44.438141 12834 solver.cpp:242] Iteration 22200 (96.5646 iter/s, 1.03558s/100 iter), loss = 2.42545
I0506 04:32:44.438184 12834 solver.cpp:261]     Train net output #0: loss = 2.42545 (* 1 = 2.42545 loss)
I0506 04:32:44.438194 12834 sgd_solver.cpp:106] Iteration 22200, lr = 6.4e-05
I0506 04:32:44.443415 12834 solver.cpp:242] Iteration 22200 (96.5725 iter/s, 1.03549s/100 iter), loss = 0.630054
I0506 04:32:44.443444 12834 solver.cpp:261]     Train net output #0: loss = 0.630054 (* 1 = 0.630054 loss)
I0506 04:32:44.443455 12834 sgd_solver.cpp:106] Iteration 22200, lr = 6.4e-05
I0506 04:32:45.403138 12834 solver.cpp:242] Iteration 22300 (103.635 iter/s, 0.964926s/100 iter), loss = 3.00318
I0506 04:32:45.403177 12834 solver.cpp:261]     Train net output #0: loss = 3.00318 (* 1 = 3.00318 loss)
I0506 04:32:45.403185 12834 sgd_solver.cpp:106] Iteration 22300, lr = 6.4e-05
I0506 04:32:45.407939 12834 solver.cpp:242] Iteration 22300 (103.683 iter/s, 0.964476s/100 iter), loss = 1.16042
I0506 04:32:45.407965 12834 solver.cpp:261]     Train net output #0: loss = 1.16042 (* 1 = 1.16042 loss)
I0506 04:32:45.407974 12834 sgd_solver.cpp:106] Iteration 22300, lr = 6.4e-05
I0506 04:32:46.341713 12834 solver.cpp:242] Iteration 22400 (106.552 iter/s, 0.938512s/100 iter), loss = 3.10952
I0506 04:32:46.341740 12834 solver.cpp:261]     Train net output #0: loss = 3.10952 (* 1 = 3.10952 loss)
I0506 04:32:46.341749 12834 sgd_solver.cpp:106] Iteration 22400, lr = 6.4e-05
I0506 04:32:46.346480 12834 solver.cpp:242] Iteration 22400 (106.554 iter/s, 0.938495s/100 iter), loss = 0.864211
I0506 04:32:46.346503 12834 solver.cpp:261]     Train net output #0: loss = 0.864211 (* 1 = 0.864211 loss)
I0506 04:32:46.346511 12834 sgd_solver.cpp:106] Iteration 22400, lr = 6.4e-05
I0506 04:32:47.333300 12834 solver.cpp:362] Iteration 22500, Testing net (#0)
I0506 04:32:47.333328 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:47.456410 12834 solver.cpp:429]     Test net output #0: loss = 2.81548 (* 1 = 2.81548 loss)
I0506 04:32:47.458948 12834 solver.cpp:242] Iteration 22500 (89.5104 iter/s, 1.11719s/100 iter), loss = 3.82824
I0506 04:32:47.458968 12834 solver.cpp:261]     Train net output #0: loss = 3.82824 (* 1 = 3.82824 loss)
I0506 04:32:47.458977 12834 sgd_solver.cpp:106] Iteration 22500, lr = 6.4e-05
I0506 04:32:47.460804 12834 solver.cpp:362] Iteration 22500, Testing net (#0)
I0506 04:32:47.460819 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:47.589709 12834 solver.cpp:429]     Test net output #0: accuracy = 0.638
I0506 04:32:47.589727 12834 solver.cpp:429]     Test net output #1: loss = 0.8737 (* 1 = 0.8737 loss)
I0506 04:32:47.592295 12834 solver.cpp:242] Iteration 22500 (80.2716 iter/s, 1.24577s/100 iter), loss = 1.0131
I0506 04:32:47.592314 12834 solver.cpp:261]     Train net output #0: loss = 1.0131 (* 1 = 1.0131 loss)
I0506 04:32:47.592322 12834 sgd_solver.cpp:106] Iteration 22500, lr = 6.4e-05
I0506 04:32:48.525974 12834 solver.cpp:242] Iteration 22600 (93.7225 iter/s, 1.06698s/100 iter), loss = 1.81312
I0506 04:32:48.526002 12834 solver.cpp:261]     Train net output #0: loss = 1.81312 (* 1 = 1.81312 loss)
I0506 04:32:48.526011 12834 sgd_solver.cpp:106] Iteration 22600, lr = 6.4e-05
I0506 04:32:48.530730 12834 solver.cpp:242] Iteration 22600 (106.565 iter/s, 0.938397s/100 iter), loss = 0.901869
I0506 04:32:48.530753 12834 solver.cpp:261]     Train net output #0: loss = 0.901869 (* 1 = 0.901869 loss)
I0506 04:32:48.530762 12834 sgd_solver.cpp:106] Iteration 22600, lr = 6.4e-05
I0506 04:32:49.464010 12834 solver.cpp:242] Iteration 22700 (106.612 iter/s, 0.937977s/100 iter), loss = 1.53027
I0506 04:32:49.464051 12834 solver.cpp:261]     Train net output #0: loss = 1.53027 (* 1 = 1.53027 loss)
I0506 04:32:49.464059 12834 sgd_solver.cpp:106] Iteration 22700, lr = 6.4e-05
I0506 04:32:49.468807 12834 solver.cpp:242] Iteration 22700 (106.606 iter/s, 0.938036s/100 iter), loss = 0.920487
I0506 04:32:49.468832 12834 solver.cpp:261]     Train net output #0: loss = 0.920487 (* 1 = 0.920487 loss)
I0506 04:32:49.468840 12834 sgd_solver.cpp:106] Iteration 22700, lr = 6.4e-05
I0506 04:32:50.402513 12834 solver.cpp:242] Iteration 22800 (106.56 iter/s, 0.93844s/100 iter), loss = 3.11755
I0506 04:32:50.402555 12834 solver.cpp:261]     Train net output #0: loss = 3.11755 (* 1 = 3.11755 loss)
I0506 04:32:50.402565 12834 sgd_solver.cpp:106] Iteration 22800, lr = 6.4e-05
I0506 04:32:50.407353 12834 solver.cpp:242] Iteration 22800 (106.554 iter/s, 0.938494s/100 iter), loss = 1.09325
I0506 04:32:50.407380 12834 solver.cpp:261]     Train net output #0: loss = 1.09325 (* 1 = 1.09325 loss)
I0506 04:32:50.407389 12834 sgd_solver.cpp:106] Iteration 22800, lr = 6.4e-05
I0506 04:32:51.341058 12834 solver.cpp:242] Iteration 22900 (106.556 iter/s, 0.938475s/100 iter), loss = 5.49887
I0506 04:32:51.341100 12834 solver.cpp:261]     Train net output #0: loss = 5.49887 (* 1 = 5.49887 loss)
I0506 04:32:51.341109 12834 sgd_solver.cpp:106] Iteration 22900, lr = 6.4e-05
I0506 04:32:51.345824 12834 solver.cpp:242] Iteration 22900 (106.562 iter/s, 0.938424s/100 iter), loss = 1.58168
I0506 04:32:51.345849 12834 solver.cpp:261]     Train net output #0: loss = 1.58168 (* 1 = 1.58168 loss)
I0506 04:32:51.345857 12834 sgd_solver.cpp:106] Iteration 22900, lr = 6.4e-05
I0506 04:32:52.276420 12834 solver.cpp:362] Iteration 23000, Testing net (#0)
I0506 04:32:52.276446 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:52.399500 12834 solver.cpp:429]     Test net output #0: loss = 2.89766 (* 1 = 2.89766 loss)
I0506 04:32:52.402045 12834 solver.cpp:242] Iteration 23000 (94.2573 iter/s, 1.06093s/100 iter), loss = 1.82036
I0506 04:32:52.402066 12834 solver.cpp:261]     Train net output #0: loss = 1.82036 (* 1 = 1.82036 loss)
I0506 04:32:52.402074 12834 sgd_solver.cpp:106] Iteration 23000, lr = 6.4e-05
I0506 04:32:52.403961 12834 solver.cpp:362] Iteration 23000, Testing net (#0)
I0506 04:32:52.403977 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:52.533141 12834 solver.cpp:429]     Test net output #0: accuracy = 0.629
I0506 04:32:52.533164 12834 solver.cpp:429]     Test net output #1: loss = 0.89821 (* 1 = 0.89821 loss)
I0506 04:32:52.535717 12834 solver.cpp:242] Iteration 23000 (84.0445 iter/s, 1.18985s/100 iter), loss = 0.940691
I0506 04:32:52.535737 12834 solver.cpp:261]     Train net output #0: loss = 0.940691 (* 1 = 0.940691 loss)
I0506 04:32:52.535744 12834 sgd_solver.cpp:106] Iteration 23000, lr = 6.4e-05
I0506 04:32:53.469625 12834 solver.cpp:242] Iteration 23100 (93.6743 iter/s, 1.06753s/100 iter), loss = 3.12391
I0506 04:32:53.469666 12834 solver.cpp:261]     Train net output #0: loss = 3.12391 (* 1 = 3.12391 loss)
I0506 04:32:53.469676 12834 sgd_solver.cpp:106] Iteration 23100, lr = 6.4e-05
I0506 04:32:53.474398 12834 solver.cpp:242] Iteration 23100 (106.537 iter/s, 0.938643s/100 iter), loss = 0.777504
I0506 04:32:53.474424 12834 solver.cpp:261]     Train net output #0: loss = 0.777504 (* 1 = 0.777504 loss)
I0506 04:32:53.474433 12834 sgd_solver.cpp:106] Iteration 23100, lr = 6.4e-05
I0506 04:32:54.407974 12834 solver.cpp:242] Iteration 23200 (106.578 iter/s, 0.938277s/100 iter), loss = 2.25483
I0506 04:32:54.408013 12834 solver.cpp:261]     Train net output #0: loss = 2.25483 (* 1 = 2.25483 loss)
I0506 04:32:54.408022 12834 sgd_solver.cpp:106] Iteration 23200, lr = 6.4e-05
I0506 04:32:54.412762 12834 solver.cpp:242] Iteration 23200 (106.573 iter/s, 0.938321s/100 iter), loss = 0.959104
I0506 04:32:54.412789 12834 solver.cpp:261]     Train net output #0: loss = 0.959104 (* 1 = 0.959104 loss)
I0506 04:32:54.412798 12834 sgd_solver.cpp:106] Iteration 23200, lr = 6.4e-05
I0506 04:32:55.345988 12834 solver.cpp:242] Iteration 23300 (106.616 iter/s, 0.937949s/100 iter), loss = 4.32668
I0506 04:32:55.346026 12834 solver.cpp:261]     Train net output #0: loss = 4.32668 (* 1 = 4.32668 loss)
I0506 04:32:55.346035 12834 sgd_solver.cpp:106] Iteration 23300, lr = 6.4e-05
I0506 04:32:55.350774 12834 solver.cpp:242] Iteration 23300 (106.614 iter/s, 0.937966s/100 iter), loss = 1.25837
I0506 04:32:55.350798 12834 solver.cpp:261]     Train net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I0506 04:32:55.350806 12834 sgd_solver.cpp:106] Iteration 23300, lr = 6.4e-05
I0506 04:32:56.284816 12834 solver.cpp:242] Iteration 23400 (106.524 iter/s, 0.938759s/100 iter), loss = 3.48296
I0506 04:32:56.284854 12834 solver.cpp:261]     Train net output #0: loss = 3.48296 (* 1 = 3.48296 loss)
I0506 04:32:56.284863 12834 sgd_solver.cpp:106] Iteration 23400, lr = 6.4e-05
I0506 04:32:56.289585 12834 solver.cpp:242] Iteration 23400 (106.523 iter/s, 0.938768s/100 iter), loss = 1.01517
I0506 04:32:56.289609 12834 solver.cpp:261]     Train net output #0: loss = 1.01517 (* 1 = 1.01517 loss)
I0506 04:32:56.289618 12834 sgd_solver.cpp:106] Iteration 23400, lr = 6.4e-05
I0506 04:32:57.220281 12834 solver.cpp:362] Iteration 23500, Testing net (#0)
I0506 04:32:57.220299 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:57.343138 12834 solver.cpp:429]     Test net output #0: loss = 2.73263 (* 1 = 2.73263 loss)
I0506 04:32:57.345669 12834 solver.cpp:242] Iteration 23500 (94.269 iter/s, 1.06079s/100 iter), loss = 3.65213
I0506 04:32:57.345688 12834 solver.cpp:261]     Train net output #0: loss = 3.65213 (* 1 = 3.65213 loss)
I0506 04:32:57.345696 12834 sgd_solver.cpp:106] Iteration 23500, lr = 6.4e-05
I0506 04:32:57.347517 12834 solver.cpp:362] Iteration 23500, Testing net (#0)
I0506 04:32:57.347529 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:32:57.476758 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6465
I0506 04:32:57.476785 12834 solver.cpp:429]     Test net output #1: loss = 0.862987 (* 1 = 0.862987 loss)
I0506 04:32:57.479353 12834 solver.cpp:242] Iteration 23500 (84.0532 iter/s, 1.18972s/100 iter), loss = 0.9735
I0506 04:32:57.479373 12834 solver.cpp:261]     Train net output #0: loss = 0.9735 (* 1 = 0.9735 loss)
I0506 04:32:57.479382 12834 sgd_solver.cpp:106] Iteration 23500, lr = 6.4e-05
I0506 04:32:58.413029 12834 solver.cpp:242] Iteration 23600 (93.6937 iter/s, 1.06731s/100 iter), loss = 1.44766
I0506 04:32:58.413064 12834 solver.cpp:261]     Train net output #0: loss = 1.44766 (* 1 = 1.44766 loss)
I0506 04:32:58.413072 12834 sgd_solver.cpp:106] Iteration 23600, lr = 6.4e-05
I0506 04:32:58.417801 12834 solver.cpp:242] Iteration 23600 (106.563 iter/s, 0.938409s/100 iter), loss = 0.983191
I0506 04:32:58.417826 12834 solver.cpp:261]     Train net output #0: loss = 0.983191 (* 1 = 0.983191 loss)
I0506 04:32:58.417835 12834 sgd_solver.cpp:106] Iteration 23600, lr = 6.4e-05
I0506 04:32:59.431078 12834 solver.cpp:242] Iteration 23700 (98.233 iter/s, 1.01799s/100 iter), loss = 2.63579
I0506 04:32:59.431121 12834 solver.cpp:261]     Train net output #0: loss = 2.63579 (* 1 = 2.63579 loss)
I0506 04:32:59.431133 12834 sgd_solver.cpp:106] Iteration 23700, lr = 6.4e-05
I0506 04:32:59.436362 12834 solver.cpp:242] Iteration 23700 (98.1821 iter/s, 1.01852s/100 iter), loss = 0.848583
I0506 04:32:59.436393 12834 solver.cpp:261]     Train net output #0: loss = 0.848583 (* 1 = 0.848583 loss)
I0506 04:32:59.436403 12834 sgd_solver.cpp:106] Iteration 23700, lr = 6.4e-05
I0506 04:33:00.473255 12834 solver.cpp:242] Iteration 23800 (95.96 iter/s, 1.0421s/100 iter), loss = 2.69005
I0506 04:33:00.473297 12834 solver.cpp:261]     Train net output #0: loss = 2.69005 (* 1 = 2.69005 loss)
I0506 04:33:00.473309 12834 sgd_solver.cpp:106] Iteration 23800, lr = 6.4e-05
I0506 04:33:00.478531 12834 solver.cpp:242] Iteration 23800 (95.9583 iter/s, 1.04212s/100 iter), loss = 1.0907
I0506 04:33:00.478559 12834 solver.cpp:261]     Train net output #0: loss = 1.0907 (* 1 = 1.0907 loss)
I0506 04:33:00.478569 12834 sgd_solver.cpp:106] Iteration 23800, lr = 6.4e-05
I0506 04:33:01.491076 12834 solver.cpp:242] Iteration 23900 (98.2554 iter/s, 1.01776s/100 iter), loss = 1.66012
I0506 04:33:01.491113 12834 solver.cpp:261]     Train net output #0: loss = 1.66012 (* 1 = 1.66012 loss)
I0506 04:33:01.491122 12834 sgd_solver.cpp:106] Iteration 23900, lr = 6.4e-05
I0506 04:33:01.495929 12834 solver.cpp:242] Iteration 23900 (98.2954 iter/s, 1.01734s/100 iter), loss = 0.616675
I0506 04:33:01.495955 12834 solver.cpp:261]     Train net output #0: loss = 0.616675 (* 1 = 0.616675 loss)
I0506 04:33:01.495965 12834 sgd_solver.cpp:106] Iteration 23900, lr = 6.4e-05
I0506 04:33:02.426163 12834 solver.cpp:362] Iteration 24000, Testing net (#0)
I0506 04:33:02.426183 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:02.549150 12834 solver.cpp:429]     Test net output #0: loss = 2.69138 (* 1 = 2.69138 loss)
I0506 04:33:02.551668 12834 solver.cpp:242] Iteration 24000 (94.292 iter/s, 1.06054s/100 iter), loss = 1.90643
I0506 04:33:02.551687 12834 solver.cpp:261]     Train net output #0: loss = 1.90643 (* 1 = 1.90643 loss)
I0506 04:33:02.551697 12834 sgd_solver.cpp:106] Iteration 24000, lr = 6.4e-05
I0506 04:33:02.553514 12834 solver.cpp:362] Iteration 24000, Testing net (#0)
I0506 04:33:02.553527 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:02.692453 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6355
I0506 04:33:02.692476 12834 solver.cpp:429]     Test net output #1: loss = 0.922922 (* 1 = 0.922922 loss)
I0506 04:33:02.695166 12834 solver.cpp:242] Iteration 24000 (83.3897 iter/s, 1.19919s/100 iter), loss = 1.13559
I0506 04:33:02.695191 12834 solver.cpp:261]     Train net output #0: loss = 1.13559 (* 1 = 1.13559 loss)
I0506 04:33:02.695201 12834 sgd_solver.cpp:106] Iteration 24000, lr = 6.4e-05
I0506 04:33:03.631711 12834 solver.cpp:242] Iteration 24100 (92.5935 iter/s, 1.07999s/100 iter), loss = 4.0548
I0506 04:33:03.631764 12834 solver.cpp:261]     Train net output #0: loss = 4.0548 (* 1 = 4.0548 loss)
I0506 04:33:03.631774 12834 sgd_solver.cpp:106] Iteration 24100, lr = 6.4e-05
I0506 04:33:03.636504 12834 solver.cpp:242] Iteration 24100 (106.237 iter/s, 0.941295s/100 iter), loss = 0.982004
I0506 04:33:03.636531 12834 solver.cpp:261]     Train net output #0: loss = 0.982004 (* 1 = 0.982004 loss)
I0506 04:33:03.636539 12834 sgd_solver.cpp:106] Iteration 24100, lr = 6.4e-05
I0506 04:33:04.569779 12834 solver.cpp:242] Iteration 24200 (106.611 iter/s, 0.937988s/100 iter), loss = 1.24234
I0506 04:33:04.569820 12834 solver.cpp:261]     Train net output #0: loss = 1.24234 (* 1 = 1.24234 loss)
I0506 04:33:04.569829 12834 sgd_solver.cpp:106] Iteration 24200, lr = 6.4e-05
I0506 04:33:04.574611 12834 solver.cpp:242] Iteration 24200 (106.603 iter/s, 0.938062s/100 iter), loss = 0.657401
I0506 04:33:04.574637 12834 solver.cpp:261]     Train net output #0: loss = 0.657401 (* 1 = 0.657401 loss)
I0506 04:33:04.574646 12834 sgd_solver.cpp:106] Iteration 24200, lr = 6.4e-05
I0506 04:33:05.508569 12834 solver.cpp:242] Iteration 24300 (106.529 iter/s, 0.938712s/100 iter), loss = 1.43179
I0506 04:33:05.508610 12834 solver.cpp:261]     Train net output #0: loss = 1.43179 (* 1 = 1.43179 loss)
I0506 04:33:05.508620 12834 sgd_solver.cpp:106] Iteration 24300, lr = 6.4e-05
I0506 04:33:05.513347 12834 solver.cpp:242] Iteration 24300 (106.531 iter/s, 0.938691s/100 iter), loss = 0.995607
I0506 04:33:05.513375 12834 solver.cpp:261]     Train net output #0: loss = 0.995607 (* 1 = 0.995607 loss)
I0506 04:33:05.513383 12834 sgd_solver.cpp:106] Iteration 24300, lr = 6.4e-05
I0506 04:33:06.447516 12834 solver.cpp:242] Iteration 24400 (106.51 iter/s, 0.938879s/100 iter), loss = 1.19343
I0506 04:33:06.447563 12834 solver.cpp:261]     Train net output #0: loss = 1.19343 (* 1 = 1.19343 loss)
I0506 04:33:06.447917 12834 sgd_solver.cpp:106] Iteration 24400, lr = 6.4e-05
I0506 04:33:06.452754 12834 solver.cpp:242] Iteration 24400 (106.455 iter/s, 0.939361s/100 iter), loss = 0.904984
I0506 04:33:06.452780 12834 solver.cpp:261]     Train net output #0: loss = 0.904984 (* 1 = 0.904984 loss)
I0506 04:33:06.452788 12834 sgd_solver.cpp:106] Iteration 24400, lr = 6.4e-05
I0506 04:33:07.383746 12834 solver.cpp:362] Iteration 24500, Testing net (#0)
I0506 04:33:07.383772 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:07.506748 12834 solver.cpp:429]     Test net output #0: loss = 2.54478 (* 1 = 2.54478 loss)
I0506 04:33:07.509266 12834 solver.cpp:242] Iteration 24500 (94.1897 iter/s, 1.06169s/100 iter), loss = 1.14739
I0506 04:33:07.509289 12834 solver.cpp:261]     Train net output #0: loss = 1.14739 (* 1 = 1.14739 loss)
I0506 04:33:07.509296 12834 sgd_solver.cpp:106] Iteration 24500, lr = 6.4e-05
I0506 04:33:07.511112 12834 solver.cpp:362] Iteration 24500, Testing net (#0)
I0506 04:33:07.511127 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:07.640184 12834 solver.cpp:429]     Test net output #0: accuracy = 0.642
I0506 04:33:07.640205 12834 solver.cpp:429]     Test net output #1: loss = 0.86404 (* 1 = 0.86404 loss)
I0506 04:33:07.642766 12834 solver.cpp:242] Iteration 24500 (84.0361 iter/s, 1.18996s/100 iter), loss = 0.984767
I0506 04:33:07.642787 12834 solver.cpp:261]     Train net output #0: loss = 0.984767 (* 1 = 0.984767 loss)
I0506 04:33:07.642796 12834 sgd_solver.cpp:106] Iteration 24500, lr = 6.4e-05
I0506 04:33:08.576640 12834 solver.cpp:242] Iteration 24600 (93.6922 iter/s, 1.06732s/100 iter), loss = 3.0384
I0506 04:33:08.576681 12834 solver.cpp:261]     Train net output #0: loss = 3.0384 (* 1 = 3.0384 loss)
I0506 04:33:08.576690 12834 sgd_solver.cpp:106] Iteration 24600, lr = 6.4e-05
I0506 04:33:08.581420 12834 solver.cpp:242] Iteration 24600 (106.54 iter/s, 0.938615s/100 iter), loss = 0.701574
I0506 04:33:08.581447 12834 solver.cpp:261]     Train net output #0: loss = 0.701574 (* 1 = 0.701574 loss)
I0506 04:33:08.581455 12834 sgd_solver.cpp:106] Iteration 24600, lr = 6.4e-05
I0506 04:33:09.514626 12834 solver.cpp:242] Iteration 24700 (106.619 iter/s, 0.937917s/100 iter), loss = 2.18317
I0506 04:33:09.514674 12834 solver.cpp:261]     Train net output #0: loss = 2.18317 (* 1 = 2.18317 loss)
I0506 04:33:09.514685 12834 sgd_solver.cpp:106] Iteration 24700, lr = 6.4e-05
I0506 04:33:09.519480 12834 solver.cpp:242] Iteration 24700 (106.608 iter/s, 0.938015s/100 iter), loss = 1.10839
I0506 04:33:09.519505 12834 solver.cpp:261]     Train net output #0: loss = 1.10839 (* 1 = 1.10839 loss)
I0506 04:33:09.519513 12834 sgd_solver.cpp:106] Iteration 24700, lr = 6.4e-05
I0506 04:33:10.452936 12834 solver.cpp:242] Iteration 24800 (106.583 iter/s, 0.93824s/100 iter), loss = 4.59462
I0506 04:33:10.452975 12834 solver.cpp:261]     Train net output #0: loss = 4.59462 (* 1 = 4.59462 loss)
I0506 04:33:10.452983 12834 sgd_solver.cpp:106] Iteration 24800, lr = 6.4e-05
I0506 04:33:10.457820 12834 solver.cpp:242] Iteration 24800 (106.577 iter/s, 0.938289s/100 iter), loss = 1.13663
I0506 04:33:10.457846 12834 solver.cpp:261]     Train net output #0: loss = 1.13663 (* 1 = 1.13663 loss)
I0506 04:33:10.457855 12834 sgd_solver.cpp:106] Iteration 24800, lr = 6.4e-05
I0506 04:33:11.475528 12834 solver.cpp:242] Iteration 24900 (97.7973 iter/s, 1.02252s/100 iter), loss = 1.60079
I0506 04:33:11.475575 12834 solver.cpp:261]     Train net output #0: loss = 1.60079 (* 1 = 1.60079 loss)
I0506 04:33:11.475795 12834 sgd_solver.cpp:106] Iteration 24900, lr = 6.4e-05
I0506 04:33:11.480618 12834 solver.cpp:242] Iteration 24900 (97.7754 iter/s, 1.02275s/100 iter), loss = 0.663476
I0506 04:33:11.480643 12834 solver.cpp:261]     Train net output #0: loss = 0.663476 (* 1 = 0.663476 loss)
I0506 04:33:11.480651 12834 sgd_solver.cpp:106] Iteration 24900, lr = 6.4e-05
I0506 04:33:12.410583 12834 solver.cpp:362] Iteration 25000, Testing net (#0)
I0506 04:33:12.410606 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:12.533573 12834 solver.cpp:429]     Test net output #0: loss = 2.58696 (* 1 = 2.58696 loss)
I0506 04:33:12.536111 12834 solver.cpp:242] Iteration 25000 (94.2935 iter/s, 1.06052s/100 iter), loss = 2.98058
I0506 04:33:12.536134 12834 solver.cpp:261]     Train net output #0: loss = 2.98058 (* 1 = 2.98058 loss)
I0506 04:33:12.536141 12834 sgd_solver.cpp:106] Iteration 25000, lr = 6.4e-05
I0506 04:33:12.537963 12834 solver.cpp:362] Iteration 25000, Testing net (#0)
I0506 04:33:12.537977 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:12.667450 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6205
I0506 04:33:12.667471 12834 solver.cpp:429]     Test net output #1: loss = 0.941302 (* 1 = 0.941302 loss)
I0506 04:33:12.670033 12834 solver.cpp:242] Iteration 25000 (84.0781 iter/s, 1.18937s/100 iter), loss = 0.988587
I0506 04:33:12.670054 12834 solver.cpp:261]     Train net output #0: loss = 0.988587 (* 1 = 0.988587 loss)
I0506 04:33:12.670063 12834 sgd_solver.cpp:106] Iteration 25000, lr = 6.4e-05
I0506 04:33:13.603976 12834 solver.cpp:242] Iteration 25100 (93.6492 iter/s, 1.06781s/100 iter), loss = 0.71377
I0506 04:33:13.604014 12834 solver.cpp:261]     Train net output #0: loss = 0.71377 (* 1 = 0.71377 loss)
I0506 04:33:13.604023 12834 sgd_solver.cpp:106] Iteration 25100, lr = 6.4e-05
I0506 04:33:13.608747 12834 solver.cpp:242] Iteration 25100 (106.533 iter/s, 0.938674s/100 iter), loss = 0.890969
I0506 04:33:13.608772 12834 solver.cpp:261]     Train net output #0: loss = 0.890969 (* 1 = 0.890969 loss)
I0506 04:33:13.608779 12834 sgd_solver.cpp:106] Iteration 25100, lr = 6.4e-05
I0506 04:33:14.541976 12834 solver.cpp:242] Iteration 25200 (106.618 iter/s, 0.937932s/100 iter), loss = 0.769182
I0506 04:33:14.542011 12834 solver.cpp:261]     Train net output #0: loss = 0.769182 (* 1 = 0.769182 loss)
I0506 04:33:14.542021 12834 sgd_solver.cpp:106] Iteration 25200, lr = 6.4e-05
I0506 04:33:14.546756 12834 solver.cpp:242] Iteration 25200 (106.613 iter/s, 0.937968s/100 iter), loss = 0.813013
I0506 04:33:14.546782 12834 solver.cpp:261]     Train net output #0: loss = 0.813013 (* 1 = 0.813013 loss)
I0506 04:33:14.546790 12834 sgd_solver.cpp:106] Iteration 25200, lr = 6.4e-05
I0506 04:33:15.480067 12834 solver.cpp:242] Iteration 25300 (106.606 iter/s, 0.938031s/100 iter), loss = 0.79551
I0506 04:33:15.480098 12834 solver.cpp:261]     Train net output #0: loss = 0.79551 (* 1 = 0.79551 loss)
I0506 04:33:15.480108 12834 sgd_solver.cpp:106] Iteration 25300, lr = 6.4e-05
I0506 04:33:15.484875 12834 solver.cpp:242] Iteration 25300 (106.602 iter/s, 0.938065s/100 iter), loss = 0.461726
I0506 04:33:15.484899 12834 solver.cpp:261]     Train net output #0: loss = 0.461726 (* 1 = 0.461726 loss)
I0506 04:33:15.484908 12834 sgd_solver.cpp:106] Iteration 25300, lr = 6.4e-05
I0506 04:33:16.417691 12834 solver.cpp:242] Iteration 25400 (106.659 iter/s, 0.937563s/100 iter), loss = 1.43412
I0506 04:33:16.417732 12834 solver.cpp:261]     Train net output #0: loss = 1.43412 (* 1 = 1.43412 loss)
I0506 04:33:16.417742 12834 sgd_solver.cpp:106] Iteration 25400, lr = 6.4e-05
I0506 04:33:16.422466 12834 solver.cpp:242] Iteration 25400 (106.661 iter/s, 0.937547s/100 iter), loss = 0.770433
I0506 04:33:16.422493 12834 solver.cpp:261]     Train net output #0: loss = 0.770433 (* 1 = 0.770433 loss)
I0506 04:33:16.422502 12834 sgd_solver.cpp:106] Iteration 25400, lr = 6.4e-05
I0506 04:33:17.352886 12834 solver.cpp:362] Iteration 25500, Testing net (#0)
I0506 04:33:17.352919 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:17.476217 12834 solver.cpp:429]     Test net output #0: loss = 2.49563 (* 1 = 2.49563 loss)
I0506 04:33:17.478737 12834 solver.cpp:242] Iteration 25500 (94.2518 iter/s, 1.06099s/100 iter), loss = 0.998935
I0506 04:33:17.478760 12834 solver.cpp:261]     Train net output #0: loss = 0.998935 (* 1 = 0.998935 loss)
I0506 04:33:17.478767 12834 sgd_solver.cpp:106] Iteration 25500, lr = 6.4e-05
I0506 04:33:17.480600 12834 solver.cpp:362] Iteration 25500, Testing net (#0)
I0506 04:33:17.480615 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:17.609827 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6175
I0506 04:33:17.609848 12834 solver.cpp:429]     Test net output #1: loss = 0.941485 (* 1 = 0.941485 loss)
I0506 04:33:17.612414 12834 solver.cpp:242] Iteration 25500 (84.0406 iter/s, 1.1899s/100 iter), loss = 0.874253
I0506 04:33:17.612434 12834 solver.cpp:261]     Train net output #0: loss = 0.874253 (* 1 = 0.874253 loss)
I0506 04:33:17.612443 12834 sgd_solver.cpp:106] Iteration 25500, lr = 6.4e-05
I0506 04:33:18.545199 12834 solver.cpp:242] Iteration 25600 (93.7727 iter/s, 1.06641s/100 iter), loss = 2.79048
I0506 04:33:18.545233 12834 solver.cpp:261]     Train net output #0: loss = 2.79048 (* 1 = 2.79048 loss)
I0506 04:33:18.545243 12834 sgd_solver.cpp:106] Iteration 25600, lr = 6.4e-05
I0506 04:33:18.549988 12834 solver.cpp:242] Iteration 25600 (106.663 iter/s, 0.937534s/100 iter), loss = 0.893531
I0506 04:33:18.550011 12834 solver.cpp:261]     Train net output #0: loss = 0.893531 (* 1 = 0.893531 loss)
I0506 04:33:18.550020 12834 sgd_solver.cpp:106] Iteration 25600, lr = 6.4e-05
I0506 04:33:19.577286 12834 solver.cpp:242] Iteration 25700 (96.8969 iter/s, 1.03203s/100 iter), loss = 3.8615
I0506 04:33:19.577335 12834 solver.cpp:261]     Train net output #0: loss = 3.8615 (* 1 = 3.8615 loss)
I0506 04:33:19.577347 12834 sgd_solver.cpp:106] Iteration 25700, lr = 6.4e-05
I0506 04:33:19.582669 12834 solver.cpp:242] Iteration 25700 (96.8405 iter/s, 1.03263s/100 iter), loss = 0.986403
I0506 04:33:19.582700 12834 solver.cpp:261]     Train net output #0: loss = 0.986403 (* 1 = 0.986403 loss)
I0506 04:33:19.582710 12834 sgd_solver.cpp:106] Iteration 25700, lr = 6.4e-05
I0506 04:33:20.613374 12834 solver.cpp:242] Iteration 25800 (96.5242 iter/s, 1.03601s/100 iter), loss = 2.19962
I0506 04:33:20.613422 12834 solver.cpp:261]     Train net output #0: loss = 2.19962 (* 1 = 2.19962 loss)
I0506 04:33:20.613433 12834 sgd_solver.cpp:106] Iteration 25800, lr = 6.4e-05
I0506 04:33:20.618679 12834 solver.cpp:242] Iteration 25800 (96.5288 iter/s, 1.03596s/100 iter), loss = 0.957426
I0506 04:33:20.618710 12834 solver.cpp:261]     Train net output #0: loss = 0.957426 (* 1 = 0.957426 loss)
I0506 04:33:20.618731 12834 sgd_solver.cpp:106] Iteration 25800, lr = 6.4e-05
I0506 04:33:21.561298 12834 solver.cpp:242] Iteration 25900 (105.502 iter/s, 0.947853s/100 iter), loss = 2.55096
I0506 04:33:21.561339 12834 solver.cpp:261]     Train net output #0: loss = 2.55096 (* 1 = 2.55096 loss)
I0506 04:33:21.561348 12834 sgd_solver.cpp:106] Iteration 25900, lr = 6.4e-05
I0506 04:33:21.566083 12834 solver.cpp:242] Iteration 25900 (105.558 iter/s, 0.947349s/100 iter), loss = 1.58883
I0506 04:33:21.566109 12834 solver.cpp:261]     Train net output #0: loss = 1.58883 (* 1 = 1.58883 loss)
I0506 04:33:21.566118 12834 sgd_solver.cpp:106] Iteration 25900, lr = 6.4e-05
I0506 04:33:22.518299 12834 solver.cpp:362] Iteration 26000, Testing net (#0)
I0506 04:33:22.518331 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:22.641254 12834 solver.cpp:429]     Test net output #0: loss = 3.00024 (* 1 = 3.00024 loss)
I0506 04:33:22.643784 12834 solver.cpp:242] Iteration 26000 (92.3851 iter/s, 1.08243s/100 iter), loss = 2.76351
I0506 04:33:22.643805 12834 solver.cpp:261]     Train net output #0: loss = 2.76351 (* 1 = 2.76351 loss)
I0506 04:33:22.643813 12834 sgd_solver.cpp:106] Iteration 26000, lr = 6.4e-05
I0506 04:33:22.645630 12834 solver.cpp:362] Iteration 26000, Testing net (#0)
I0506 04:33:22.645648 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:22.774564 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5995
I0506 04:33:22.774586 12834 solver.cpp:429]     Test net output #1: loss = 1.00715 (* 1 = 1.00715 loss)
I0506 04:33:22.777146 12834 solver.cpp:242] Iteration 26000 (82.5752 iter/s, 1.21102s/100 iter), loss = 0.858759
I0506 04:33:22.777168 12834 solver.cpp:261]     Train net output #0: loss = 0.858759 (* 1 = 0.858759 loss)
I0506 04:33:22.777175 12834 sgd_solver.cpp:106] Iteration 26000, lr = 6.4e-05
I0506 04:33:23.710891 12834 solver.cpp:242] Iteration 26100 (93.7163 iter/s, 1.06705s/100 iter), loss = 4.76807
I0506 04:33:23.710933 12834 solver.cpp:261]     Train net output #0: loss = 4.76807 (* 1 = 4.76807 loss)
I0506 04:33:23.710943 12834 sgd_solver.cpp:106] Iteration 26100, lr = 6.4e-05
I0506 04:33:23.715674 12834 solver.cpp:242] Iteration 26100 (106.554 iter/s, 0.93849s/100 iter), loss = 0.966989
I0506 04:33:23.715699 12834 solver.cpp:261]     Train net output #0: loss = 0.966989 (* 1 = 0.966989 loss)
I0506 04:33:23.715708 12834 sgd_solver.cpp:106] Iteration 26100, lr = 6.4e-05
I0506 04:33:24.649374 12834 solver.cpp:242] Iteration 26200 (106.563 iter/s, 0.938416s/100 iter), loss = 1.99848
I0506 04:33:24.649415 12834 solver.cpp:261]     Train net output #0: loss = 1.99848 (* 1 = 1.99848 loss)
I0506 04:33:24.649423 12834 sgd_solver.cpp:106] Iteration 26200, lr = 6.4e-05
I0506 04:33:24.654135 12834 solver.cpp:242] Iteration 26200 (106.562 iter/s, 0.938418s/100 iter), loss = 0.708943
I0506 04:33:24.654161 12834 solver.cpp:261]     Train net output #0: loss = 0.708943 (* 1 = 0.708943 loss)
I0506 04:33:24.654170 12834 sgd_solver.cpp:106] Iteration 26200, lr = 6.4e-05
I0506 04:33:25.587342 12834 solver.cpp:242] Iteration 26300 (106.621 iter/s, 0.937898s/100 iter), loss = 1.97703
I0506 04:33:25.587378 12834 solver.cpp:261]     Train net output #0: loss = 1.97703 (* 1 = 1.97703 loss)
I0506 04:33:25.587388 12834 sgd_solver.cpp:106] Iteration 26300, lr = 6.4e-05
I0506 04:33:25.592131 12834 solver.cpp:242] Iteration 26300 (106.615 iter/s, 0.937952s/100 iter), loss = 1.0407
I0506 04:33:25.592157 12834 solver.cpp:261]     Train net output #0: loss = 1.0407 (* 1 = 1.0407 loss)
I0506 04:33:25.592165 12834 sgd_solver.cpp:106] Iteration 26300, lr = 6.4e-05
I0506 04:33:26.526026 12834 solver.cpp:242] Iteration 26400 (106.539 iter/s, 0.938623s/100 iter), loss = 2.62288
I0506 04:33:26.526063 12834 solver.cpp:261]     Train net output #0: loss = 2.62288 (* 1 = 2.62288 loss)
I0506 04:33:26.526072 12834 sgd_solver.cpp:106] Iteration 26400, lr = 6.4e-05
I0506 04:33:26.530813 12834 solver.cpp:242] Iteration 26400 (106.538 iter/s, 0.938636s/100 iter), loss = 0.67406
I0506 04:33:26.530839 12834 solver.cpp:261]     Train net output #0: loss = 0.67406 (* 1 = 0.67406 loss)
I0506 04:33:26.530856 12834 sgd_solver.cpp:106] Iteration 26400, lr = 6.4e-05
I0506 04:33:27.475034 12834 solver.cpp:362] Iteration 26500, Testing net (#0)
I0506 04:33:27.475057 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:27.597960 12834 solver.cpp:429]     Test net output #0: loss = 2.70785 (* 1 = 2.70785 loss)
I0506 04:33:27.600527 12834 solver.cpp:242] Iteration 26500 (93.0715 iter/s, 1.07444s/100 iter), loss = 3.32078
I0506 04:33:27.600556 12834 solver.cpp:261]     Train net output #0: loss = 3.32078 (* 1 = 3.32078 loss)
I0506 04:33:27.600567 12834 sgd_solver.cpp:106] Iteration 26500, lr = 6.4e-05
I0506 04:33:27.602394 12834 solver.cpp:362] Iteration 26500, Testing net (#0)
I0506 04:33:27.602407 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:27.731580 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6045
I0506 04:33:27.731600 12834 solver.cpp:429]     Test net output #1: loss = 0.974959 (* 1 = 0.974959 loss)
I0506 04:33:27.734154 12834 solver.cpp:242] Iteration 26500 (83.1052 iter/s, 1.20329s/100 iter), loss = 1.09778
I0506 04:33:27.734176 12834 solver.cpp:261]     Train net output #0: loss = 1.09778 (* 1 = 1.09778 loss)
I0506 04:33:27.734184 12834 sgd_solver.cpp:106] Iteration 26500, lr = 6.4e-05
I0506 04:33:28.667225 12834 solver.cpp:242] Iteration 26600 (93.7518 iter/s, 1.06665s/100 iter), loss = 1.17307
I0506 04:33:28.667263 12834 solver.cpp:261]     Train net output #0: loss = 1.17307 (* 1 = 1.17307 loss)
I0506 04:33:28.667273 12834 sgd_solver.cpp:106] Iteration 26600, lr = 6.4e-05
I0506 04:33:28.672089 12834 solver.cpp:242] Iteration 26600 (106.623 iter/s, 0.937886s/100 iter), loss = 0.947172
I0506 04:33:28.672116 12834 solver.cpp:261]     Train net output #0: loss = 0.947172 (* 1 = 0.947172 loss)
I0506 04:33:28.672123 12834 sgd_solver.cpp:106] Iteration 26600, lr = 6.4e-05
I0506 04:33:29.605504 12834 solver.cpp:242] Iteration 26700 (106.585 iter/s, 0.938215s/100 iter), loss = 1.96761
I0506 04:33:29.605537 12834 solver.cpp:261]     Train net output #0: loss = 1.96761 (* 1 = 1.96761 loss)
I0506 04:33:29.605546 12834 sgd_solver.cpp:106] Iteration 26700, lr = 6.4e-05
I0506 04:33:29.610282 12834 solver.cpp:242] Iteration 26700 (106.593 iter/s, 0.938149s/100 iter), loss = 0.674913
I0506 04:33:29.610307 12834 solver.cpp:261]     Train net output #0: loss = 0.674913 (* 1 = 0.674913 loss)
I0506 04:33:29.610316 12834 sgd_solver.cpp:106] Iteration 26700, lr = 6.4e-05
I0506 04:33:30.542899 12834 solver.cpp:242] Iteration 26800 (106.685 iter/s, 0.93734s/100 iter), loss = 2.20075
I0506 04:33:30.542928 12834 solver.cpp:261]     Train net output #0: loss = 2.20075 (* 1 = 2.20075 loss)
I0506 04:33:30.542937 12834 sgd_solver.cpp:106] Iteration 26800, lr = 6.4e-05
I0506 04:33:30.547809 12834 solver.cpp:242] Iteration 26800 (106.669 iter/s, 0.937477s/100 iter), loss = 1.24441
I0506 04:33:30.547832 12834 solver.cpp:261]     Train net output #0: loss = 1.24441 (* 1 = 1.24441 loss)
I0506 04:33:30.547842 12834 sgd_solver.cpp:106] Iteration 26800, lr = 6.4e-05
I0506 04:33:31.481117 12834 solver.cpp:242] Iteration 26900 (106.591 iter/s, 0.938161s/100 iter), loss = 3.9065
I0506 04:33:31.481156 12834 solver.cpp:261]     Train net output #0: loss = 3.9065 (* 1 = 3.9065 loss)
I0506 04:33:31.481165 12834 sgd_solver.cpp:106] Iteration 26900, lr = 6.4e-05
I0506 04:33:31.485895 12834 solver.cpp:242] Iteration 26900 (106.605 iter/s, 0.938044s/100 iter), loss = 1.15379
I0506 04:33:31.485921 12834 solver.cpp:261]     Train net output #0: loss = 1.15379 (* 1 = 1.15379 loss)
I0506 04:33:31.485929 12834 sgd_solver.cpp:106] Iteration 26900, lr = 6.4e-05
I0506 04:33:32.416209 12834 solver.cpp:362] Iteration 27000, Testing net (#0)
I0506 04:33:32.416239 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:32.539116 12834 solver.cpp:429]     Test net output #0: loss = 2.36142 (* 1 = 2.36142 loss)
I0506 04:33:32.541648 12834 solver.cpp:242] Iteration 27000 (94.2975 iter/s, 1.06047s/100 iter), loss = 1.38644
I0506 04:33:32.541669 12834 solver.cpp:261]     Train net output #0: loss = 1.38644 (* 1 = 1.38644 loss)
I0506 04:33:32.541687 12834 sgd_solver.cpp:106] Iteration 27000, lr = 6.4e-05
I0506 04:33:32.543509 12834 solver.cpp:362] Iteration 27000, Testing net (#0)
I0506 04:33:32.543525 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:32.674237 12834 solver.cpp:429]     Test net output #0: accuracy = 0.634
I0506 04:33:32.674257 12834 solver.cpp:429]     Test net output #1: loss = 1.00237 (* 1 = 1.00237 loss)
I0506 04:33:32.676820 12834 solver.cpp:242] Iteration 27000 (83.9717 iter/s, 1.19088s/100 iter), loss = 0.923346
I0506 04:33:32.676841 12834 solver.cpp:261]     Train net output #0: loss = 0.923346 (* 1 = 0.923346 loss)
I0506 04:33:32.676849 12834 sgd_solver.cpp:106] Iteration 27000, lr = 6.4e-05
I0506 04:33:33.610389 12834 solver.cpp:242] Iteration 27100 (93.5724 iter/s, 1.06869s/100 iter), loss = 1.83956
I0506 04:33:33.610430 12834 solver.cpp:261]     Train net output #0: loss = 1.83956 (* 1 = 1.83956 loss)
I0506 04:33:33.610438 12834 sgd_solver.cpp:106] Iteration 27100, lr = 6.4e-05
I0506 04:33:33.615165 12834 solver.cpp:242] Iteration 27100 (106.575 iter/s, 0.938306s/100 iter), loss = 1.4066
I0506 04:33:33.615190 12834 solver.cpp:261]     Train net output #0: loss = 1.4066 (* 1 = 1.4066 loss)
I0506 04:33:33.615200 12834 sgd_solver.cpp:106] Iteration 27100, lr = 6.4e-05
I0506 04:33:34.548991 12834 solver.cpp:242] Iteration 27200 (106.55 iter/s, 0.93853s/100 iter), loss = 2.44379
I0506 04:33:34.549033 12834 solver.cpp:261]     Train net output #0: loss = 2.44379 (* 1 = 2.44379 loss)
I0506 04:33:34.549042 12834 sgd_solver.cpp:106] Iteration 27200, lr = 6.4e-05
I0506 04:33:34.553779 12834 solver.cpp:242] Iteration 27200 (106.545 iter/s, 0.93857s/100 iter), loss = 1.24767
I0506 04:33:34.553805 12834 solver.cpp:261]     Train net output #0: loss = 1.24767 (* 1 = 1.24767 loss)
I0506 04:33:34.553814 12834 sgd_solver.cpp:106] Iteration 27200, lr = 6.4e-05
I0506 04:33:35.582528 12834 solver.cpp:242] Iteration 27300 (96.7617 iter/s, 1.03347s/100 iter), loss = 2.25782
I0506 04:33:35.582576 12834 solver.cpp:261]     Train net output #0: loss = 2.25782 (* 1 = 2.25782 loss)
I0506 04:33:35.582587 12834 sgd_solver.cpp:106] Iteration 27300, lr = 6.4e-05
I0506 04:33:35.587806 12834 solver.cpp:242] Iteration 27300 (96.7137 iter/s, 1.03398s/100 iter), loss = 0.520496
I0506 04:33:35.587839 12834 solver.cpp:261]     Train net output #0: loss = 0.520496 (* 1 = 0.520496 loss)
I0506 04:33:35.587851 12834 sgd_solver.cpp:106] Iteration 27300, lr = 6.4e-05
I0506 04:33:36.552618 12834 solver.cpp:242] Iteration 27400 (103.092 iter/s, 0.970012s/100 iter), loss = 3.91354
I0506 04:33:36.552656 12834 solver.cpp:261]     Train net output #0: loss = 3.91354 (* 1 = 3.91354 loss)
I0506 04:33:36.552665 12834 sgd_solver.cpp:106] Iteration 27400, lr = 6.4e-05
I0506 04:33:36.557395 12834 solver.cpp:242] Iteration 27400 (103.142 iter/s, 0.96954s/100 iter), loss = 0.807075
I0506 04:33:36.557421 12834 solver.cpp:261]     Train net output #0: loss = 0.807075 (* 1 = 0.807075 loss)
I0506 04:33:36.557430 12834 sgd_solver.cpp:106] Iteration 27400, lr = 6.4e-05
I0506 04:33:37.583626 12834 solver.cpp:362] Iteration 27500, Testing net (#0)
I0506 04:33:37.583657 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:37.714990 12834 solver.cpp:429]     Test net output #0: loss = 2.33051 (* 1 = 2.33051 loss)
I0506 04:33:37.717571 12834 solver.cpp:242] Iteration 27500 (85.8448 iter/s, 1.16489s/100 iter), loss = 0.9943
I0506 04:33:37.717595 12834 solver.cpp:261]     Train net output #0: loss = 0.9943 (* 1 = 0.9943 loss)
I0506 04:33:37.717604 12834 sgd_solver.cpp:106] Iteration 27500, lr = 6.4e-05
I0506 04:33:37.719523 12834 solver.cpp:362] Iteration 27500, Testing net (#0)
I0506 04:33:37.719538 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:37.848508 12834 solver.cpp:429]     Test net output #0: accuracy = 0.64
I0506 04:33:37.848529 12834 solver.cpp:429]     Test net output #1: loss = 0.895558 (* 1 = 0.895558 loss)
I0506 04:33:37.851104 12834 solver.cpp:242] Iteration 27500 (77.3001 iter/s, 1.29366s/100 iter), loss = 1.33203
I0506 04:33:37.851132 12834 solver.cpp:261]     Train net output #0: loss = 1.33203 (* 1 = 1.33203 loss)
I0506 04:33:37.851141 12834 sgd_solver.cpp:106] Iteration 27500, lr = 6.4e-05
I0506 04:33:38.785372 12834 solver.cpp:242] Iteration 27600 (93.6553 iter/s, 1.06775s/100 iter), loss = 2.65156
I0506 04:33:38.785413 12834 solver.cpp:261]     Train net output #0: loss = 2.65156 (* 1 = 2.65156 loss)
I0506 04:33:38.785421 12834 sgd_solver.cpp:106] Iteration 27600, lr = 6.4e-05
I0506 04:33:38.790161 12834 solver.cpp:242] Iteration 27600 (106.495 iter/s, 0.93901s/100 iter), loss = 0.967363
I0506 04:33:38.790185 12834 solver.cpp:261]     Train net output #0: loss = 0.967363 (* 1 = 0.967363 loss)
I0506 04:33:38.790194 12834 sgd_solver.cpp:106] Iteration 27600, lr = 6.4e-05
I0506 04:33:39.723995 12834 solver.cpp:242] Iteration 27700 (106.546 iter/s, 0.93856s/100 iter), loss = 3.97277
I0506 04:33:39.724037 12834 solver.cpp:261]     Train net output #0: loss = 3.97277 (* 1 = 3.97277 loss)
I0506 04:33:39.724046 12834 sgd_solver.cpp:106] Iteration 27700, lr = 6.4e-05
I0506 04:33:39.728829 12834 solver.cpp:242] Iteration 27700 (106.54 iter/s, 0.938619s/100 iter), loss = 0.712023
I0506 04:33:39.728857 12834 solver.cpp:261]     Train net output #0: loss = 0.712023 (* 1 = 0.712023 loss)
I0506 04:33:39.728865 12834 sgd_solver.cpp:106] Iteration 27700, lr = 6.4e-05
I0506 04:33:40.663383 12834 solver.cpp:242] Iteration 27800 (106.46 iter/s, 0.939319s/100 iter), loss = 2.7723
I0506 04:33:40.663421 12834 solver.cpp:261]     Train net output #0: loss = 2.7723 (* 1 = 2.7723 loss)
I0506 04:33:40.663430 12834 sgd_solver.cpp:106] Iteration 27800, lr = 6.4e-05
I0506 04:33:40.668179 12834 solver.cpp:242] Iteration 27800 (106.462 iter/s, 0.939303s/100 iter), loss = 0.902686
I0506 04:33:40.668205 12834 solver.cpp:261]     Train net output #0: loss = 0.902686 (* 1 = 0.902686 loss)
I0506 04:33:40.668213 12834 sgd_solver.cpp:106] Iteration 27800, lr = 6.4e-05
I0506 04:33:41.602424 12834 solver.cpp:242] Iteration 27900 (106.499 iter/s, 0.938972s/100 iter), loss = 2.04845
I0506 04:33:41.602463 12834 solver.cpp:261]     Train net output #0: loss = 2.04845 (* 1 = 2.04845 loss)
I0506 04:33:41.602471 12834 sgd_solver.cpp:106] Iteration 27900, lr = 6.4e-05
I0506 04:33:41.607219 12834 solver.cpp:242] Iteration 27900 (106.497 iter/s, 0.938997s/100 iter), loss = 0.913728
I0506 04:33:41.607244 12834 solver.cpp:261]     Train net output #0: loss = 0.913728 (* 1 = 0.913728 loss)
I0506 04:33:41.607254 12834 sgd_solver.cpp:106] Iteration 27900, lr = 6.4e-05
I0506 04:33:42.538094 12834 solver.cpp:362] Iteration 28000, Testing net (#0)
I0506 04:33:42.538117 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:42.668474 12834 solver.cpp:429]     Test net output #0: loss = 2.3983 (* 1 = 2.3983 loss)
I0506 04:33:42.671141 12834 solver.cpp:242] Iteration 28000 (93.5753 iter/s, 1.06866s/100 iter), loss = 3.20052
I0506 04:33:42.671166 12834 solver.cpp:261]     Train net output #0: loss = 3.20052 (* 1 = 3.20052 loss)
I0506 04:33:42.671176 12834 sgd_solver.cpp:106] Iteration 28000, lr = 6.4e-05
I0506 04:33:42.673418 12834 solver.cpp:362] Iteration 28000, Testing net (#0)
I0506 04:33:42.673434 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:42.814677 12834 solver.cpp:429]     Test net output #0: accuracy = 0.686
I0506 04:33:42.814704 12834 solver.cpp:429]     Test net output #1: loss = 0.781623 (* 1 = 0.781623 loss)
I0506 04:33:42.817407 12834 solver.cpp:242] Iteration 28000 (82.6349 iter/s, 1.21014s/100 iter), loss = 0.736773
I0506 04:33:42.817430 12834 solver.cpp:261]     Train net output #0: loss = 0.736773 (* 1 = 0.736773 loss)
I0506 04:33:42.817438 12834 sgd_solver.cpp:106] Iteration 28000, lr = 6.4e-05
I0506 04:33:43.750814 12834 solver.cpp:242] Iteration 28100 (92.6255 iter/s, 1.07962s/100 iter), loss = 1.10363
I0506 04:33:43.750851 12834 solver.cpp:261]     Train net output #0: loss = 1.10363 (* 1 = 1.10363 loss)
I0506 04:33:43.750860 12834 sgd_solver.cpp:106] Iteration 28100, lr = 6.4e-05
I0506 04:33:43.755596 12834 solver.cpp:242] Iteration 28100 (106.593 iter/s, 0.938149s/100 iter), loss = 0.673713
I0506 04:33:43.755622 12834 solver.cpp:261]     Train net output #0: loss = 0.673713 (* 1 = 0.673713 loss)
I0506 04:33:43.755631 12834 sgd_solver.cpp:106] Iteration 28100, lr = 6.4e-05
I0506 04:33:44.689766 12834 solver.cpp:242] Iteration 28200 (106.509 iter/s, 0.938888s/100 iter), loss = 4.70866
I0506 04:33:44.689803 12834 solver.cpp:261]     Train net output #0: loss = 4.70866 (* 1 = 4.70866 loss)
I0506 04:33:44.689813 12834 sgd_solver.cpp:106] Iteration 28200, lr = 6.4e-05
I0506 04:33:44.694550 12834 solver.cpp:242] Iteration 28200 (106.507 iter/s, 0.93891s/100 iter), loss = 1.1054
I0506 04:33:44.694574 12834 solver.cpp:261]     Train net output #0: loss = 1.1054 (* 1 = 1.1054 loss)
I0506 04:33:44.694582 12834 sgd_solver.cpp:106] Iteration 28200, lr = 6.4e-05
I0506 04:33:45.628407 12834 solver.cpp:242] Iteration 28300 (106.544 iter/s, 0.938575s/100 iter), loss = 2.21619
I0506 04:33:45.628439 12834 solver.cpp:261]     Train net output #0: loss = 2.21619 (* 1 = 2.21619 loss)
I0506 04:33:45.628448 12834 sgd_solver.cpp:106] Iteration 28300, lr = 6.4e-05
I0506 04:33:45.633170 12834 solver.cpp:242] Iteration 28300 (106.544 iter/s, 0.938577s/100 iter), loss = 0.898305
I0506 04:33:45.633193 12834 solver.cpp:261]     Train net output #0: loss = 0.898305 (* 1 = 0.898305 loss)
I0506 04:33:45.633203 12834 sgd_solver.cpp:106] Iteration 28300, lr = 6.4e-05
I0506 04:33:46.566228 12834 solver.cpp:242] Iteration 28400 (106.637 iter/s, 0.937764s/100 iter), loss = 2.63031
I0506 04:33:46.566272 12834 solver.cpp:261]     Train net output #0: loss = 2.63031 (* 1 = 2.63031 loss)
I0506 04:33:46.566280 12834 sgd_solver.cpp:106] Iteration 28400, lr = 6.4e-05
I0506 04:33:46.571080 12834 solver.cpp:242] Iteration 28400 (106.626 iter/s, 0.937859s/100 iter), loss = 0.849257
I0506 04:33:46.571107 12834 solver.cpp:261]     Train net output #0: loss = 0.849257 (* 1 = 0.849257 loss)
I0506 04:33:46.571116 12834 sgd_solver.cpp:106] Iteration 28400, lr = 6.4e-05
I0506 04:33:47.597286 12834 solver.cpp:362] Iteration 28500, Testing net (#0)
I0506 04:33:47.597318 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:47.730613 12834 solver.cpp:429]     Test net output #0: loss = 2.32732 (* 1 = 2.32732 loss)
I0506 04:33:47.733280 12834 solver.cpp:242] Iteration 28500 (85.6907 iter/s, 1.16699s/100 iter), loss = 3.26426
I0506 04:33:47.733304 12834 solver.cpp:261]     Train net output #0: loss = 3.26426 (* 1 = 3.26426 loss)
I0506 04:33:47.733314 12834 sgd_solver.cpp:106] Iteration 28500, lr = 6.4e-05
I0506 04:33:47.735502 12834 solver.cpp:362] Iteration 28500, Testing net (#0)
I0506 04:33:47.735517 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:47.876734 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6575
I0506 04:33:47.876760 12834 solver.cpp:429]     Test net output #1: loss = 0.819752 (* 1 = 0.819752 loss)
I0506 04:33:47.879603 12834 solver.cpp:242] Iteration 28500 (76.4249 iter/s, 1.30847s/100 iter), loss = 0.708002
I0506 04:33:47.879624 12834 solver.cpp:261]     Train net output #0: loss = 0.708002 (* 1 = 0.708002 loss)
I0506 04:33:47.879633 12834 sgd_solver.cpp:106] Iteration 28500, lr = 6.4e-05
I0506 04:33:48.837534 12834 solver.cpp:242] Iteration 28600 (90.5631 iter/s, 1.1042s/100 iter), loss = 2.19403
I0506 04:33:48.837574 12834 solver.cpp:261]     Train net output #0: loss = 2.19403 (* 1 = 2.19403 loss)
I0506 04:33:48.837585 12834 sgd_solver.cpp:106] Iteration 28600, lr = 6.4e-05
I0506 04:33:48.842922 12834 solver.cpp:242] Iteration 28600 (103.813 iter/s, 0.963269s/100 iter), loss = 0.926499
I0506 04:33:48.842952 12834 solver.cpp:261]     Train net output #0: loss = 0.926499 (* 1 = 0.926499 loss)
I0506 04:33:48.842963 12834 sgd_solver.cpp:106] Iteration 28600, lr = 6.4e-05
I0506 04:33:49.855938 12834 solver.cpp:242] Iteration 28700 (98.1992 iter/s, 1.01834s/100 iter), loss = 1.67129
I0506 04:33:49.855970 12834 solver.cpp:261]     Train net output #0: loss = 1.67129 (* 1 = 1.67129 loss)
I0506 04:33:49.855979 12834 sgd_solver.cpp:106] Iteration 28700, lr = 6.4e-05
I0506 04:33:49.860725 12834 solver.cpp:242] Iteration 28700 (98.2555 iter/s, 1.01775s/100 iter), loss = 0.729054
I0506 04:33:49.860750 12834 solver.cpp:261]     Train net output #0: loss = 0.729054 (* 1 = 0.729054 loss)
I0506 04:33:49.860759 12834 sgd_solver.cpp:106] Iteration 28700, lr = 6.4e-05
I0506 04:33:50.794028 12834 solver.cpp:242] Iteration 28800 (106.607 iter/s, 0.938027s/100 iter), loss = 1.33441
I0506 04:33:50.794070 12834 solver.cpp:261]     Train net output #0: loss = 1.33441 (* 1 = 1.33441 loss)
I0506 04:33:50.794080 12834 sgd_solver.cpp:106] Iteration 28800, lr = 6.4e-05
I0506 04:33:50.798810 12834 solver.cpp:242] Iteration 28800 (106.605 iter/s, 0.938041s/100 iter), loss = 0.881644
I0506 04:33:50.798835 12834 solver.cpp:261]     Train net output #0: loss = 0.881644 (* 1 = 0.881644 loss)
I0506 04:33:50.798844 12834 sgd_solver.cpp:106] Iteration 28800, lr = 6.4e-05
I0506 04:33:51.732620 12834 solver.cpp:242] Iteration 28900 (106.55 iter/s, 0.938523s/100 iter), loss = 3.58071
I0506 04:33:51.732659 12834 solver.cpp:261]     Train net output #0: loss = 3.58071 (* 1 = 3.58071 loss)
I0506 04:33:51.732668 12834 sgd_solver.cpp:106] Iteration 28900, lr = 6.4e-05
I0506 04:33:51.737404 12834 solver.cpp:242] Iteration 28900 (106.547 iter/s, 0.938551s/100 iter), loss = 0.830676
I0506 04:33:51.737432 12834 solver.cpp:261]     Train net output #0: loss = 0.830676 (* 1 = 0.830676 loss)
I0506 04:33:51.737440 12834 sgd_solver.cpp:106] Iteration 28900, lr = 6.4e-05
I0506 04:33:52.668630 12834 solver.cpp:362] Iteration 29000, Testing net (#0)
I0506 04:33:52.668658 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:52.791499 12834 solver.cpp:429]     Test net output #0: loss = 2.33104 (* 1 = 2.33104 loss)
I0506 04:33:52.794013 12834 solver.cpp:242] Iteration 29000 (94.2209 iter/s, 1.06134s/100 iter), loss = 3.17678
I0506 04:33:52.794039 12834 solver.cpp:261]     Train net output #0: loss = 3.17678 (* 1 = 3.17678 loss)
I0506 04:33:52.794046 12834 sgd_solver.cpp:106] Iteration 29000, lr = 6.4e-05
I0506 04:33:52.795866 12834 solver.cpp:362] Iteration 29000, Testing net (#0)
I0506 04:33:52.795878 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:52.924741 12834 solver.cpp:429]     Test net output #0: accuracy = 0.651
I0506 04:33:52.924765 12834 solver.cpp:429]     Test net output #1: loss = 0.852918 (* 1 = 0.852918 loss)
I0506 04:33:52.927410 12834 solver.cpp:242] Iteration 29000 (84.0366 iter/s, 1.18996s/100 iter), loss = 0.777537
I0506 04:33:52.927433 12834 solver.cpp:261]     Train net output #0: loss = 0.777537 (* 1 = 0.777537 loss)
I0506 04:33:52.927441 12834 sgd_solver.cpp:106] Iteration 29000, lr = 6.4e-05
I0506 04:33:53.861106 12834 solver.cpp:242] Iteration 29100 (93.7172 iter/s, 1.06704s/100 iter), loss = 5.27731
I0506 04:33:53.861147 12834 solver.cpp:261]     Train net output #0: loss = 5.27731 (* 1 = 5.27731 loss)
I0506 04:33:53.861156 12834 sgd_solver.cpp:106] Iteration 29100, lr = 6.4e-05
I0506 04:33:53.865882 12834 solver.cpp:242] Iteration 29100 (106.561 iter/s, 0.938431s/100 iter), loss = 0.897614
I0506 04:33:53.865907 12834 solver.cpp:261]     Train net output #0: loss = 0.897614 (* 1 = 0.897614 loss)
I0506 04:33:53.865916 12834 sgd_solver.cpp:106] Iteration 29100, lr = 6.4e-05
I0506 04:33:54.821954 12834 solver.cpp:242] Iteration 29200 (104.083 iter/s, 0.960774s/100 iter), loss = 2.94513
I0506 04:33:54.822001 12834 solver.cpp:261]     Train net output #0: loss = 2.94513 (* 1 = 2.94513 loss)
I0506 04:33:54.822012 12834 sgd_solver.cpp:106] Iteration 29200, lr = 6.4e-05
I0506 04:33:54.827246 12834 solver.cpp:242] Iteration 29200 (104.024 iter/s, 0.961318s/100 iter), loss = 0.576889
I0506 04:33:54.827280 12834 solver.cpp:261]     Train net output #0: loss = 0.576889 (* 1 = 0.576889 loss)
I0506 04:33:54.827289 12834 sgd_solver.cpp:106] Iteration 29200, lr = 6.4e-05
I0506 04:33:55.858000 12834 solver.cpp:242] Iteration 29300 (96.5275 iter/s, 1.03597s/100 iter), loss = 1.77645
I0506 04:33:55.858047 12834 solver.cpp:261]     Train net output #0: loss = 1.77645 (* 1 = 1.77645 loss)
I0506 04:33:55.858068 12834 sgd_solver.cpp:106] Iteration 29300, lr = 6.4e-05
I0506 04:33:55.863399 12834 solver.cpp:242] Iteration 29300 (96.5168 iter/s, 1.03609s/100 iter), loss = 0.859818
I0506 04:33:55.863430 12834 solver.cpp:261]     Train net output #0: loss = 0.859818 (* 1 = 0.859818 loss)
I0506 04:33:55.863441 12834 sgd_solver.cpp:106] Iteration 29300, lr = 6.4e-05
I0506 04:33:56.877385 12834 solver.cpp:242] Iteration 29400 (98.1055 iter/s, 1.01931s/100 iter), loss = 3.18356
I0506 04:33:56.877424 12834 solver.cpp:261]     Train net output #0: loss = 3.18356 (* 1 = 3.18356 loss)
I0506 04:33:56.877434 12834 sgd_solver.cpp:106] Iteration 29400, lr = 6.4e-05
I0506 04:33:56.882149 12834 solver.cpp:242] Iteration 29400 (98.1642 iter/s, 1.0187s/100 iter), loss = 1.01641
I0506 04:33:56.882175 12834 solver.cpp:261]     Train net output #0: loss = 1.01641 (* 1 = 1.01641 loss)
I0506 04:33:56.882184 12834 sgd_solver.cpp:106] Iteration 29400, lr = 6.4e-05
I0506 04:33:57.813344 12834 solver.cpp:362] Iteration 29500, Testing net (#0)
I0506 04:33:57.813369 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:57.936275 12834 solver.cpp:429]     Test net output #0: loss = 2.81787 (* 1 = 2.81787 loss)
I0506 04:33:57.938839 12834 solver.cpp:242] Iteration 29500 (94.2156 iter/s, 1.0614s/100 iter), loss = 2.31298
I0506 04:33:57.938866 12834 solver.cpp:261]     Train net output #0: loss = 2.31298 (* 1 = 2.31298 loss)
I0506 04:33:57.938875 12834 sgd_solver.cpp:106] Iteration 29500, lr = 6.4e-05
I0506 04:33:57.940800 12834 solver.cpp:362] Iteration 29500, Testing net (#0)
I0506 04:33:57.940814 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:33:58.069785 12834 solver.cpp:429]     Test net output #0: accuracy = 0.5345
I0506 04:33:58.069805 12834 solver.cpp:429]     Test net output #1: loss = 1.21185 (* 1 = 1.21185 loss)
I0506 04:33:58.072366 12834 solver.cpp:242] Iteration 29500 (84.0216 iter/s, 1.19017s/100 iter), loss = 1.55328
I0506 04:33:58.072387 12834 solver.cpp:261]     Train net output #0: loss = 1.55328 (* 1 = 1.55328 loss)
I0506 04:33:58.072396 12834 sgd_solver.cpp:106] Iteration 29500, lr = 6.4e-05
I0506 04:33:59.050092 12834 solver.cpp:242] Iteration 29600 (89.9933 iter/s, 1.11119s/100 iter), loss = 0.830598
I0506 04:33:59.050137 12834 solver.cpp:261]     Train net output #0: loss = 0.830598 (* 1 = 0.830598 loss)
I0506 04:33:59.050149 12834 sgd_solver.cpp:106] Iteration 29600, lr = 6.4e-05
I0506 04:33:59.055378 12834 solver.cpp:242] Iteration 29600 (101.732 iter/s, 0.982971s/100 iter), loss = 0.615593
I0506 04:33:59.055408 12834 solver.cpp:261]     Train net output #0: loss = 0.615593 (* 1 = 0.615593 loss)
I0506 04:33:59.055418 12834 sgd_solver.cpp:106] Iteration 29600, lr = 6.4e-05
I0506 04:34:00.085564 12834 solver.cpp:242] Iteration 29700 (96.5817 iter/s, 1.03539s/100 iter), loss = 3.94994
I0506 04:34:00.085608 12834 solver.cpp:261]     Train net output #0: loss = 3.94994 (* 1 = 3.94994 loss)
I0506 04:34:00.085620 12834 sgd_solver.cpp:106] Iteration 29700, lr = 6.4e-05
I0506 04:34:00.090852 12834 solver.cpp:242] Iteration 29700 (96.5788 iter/s, 1.03542s/100 iter), loss = 0.58943
I0506 04:34:00.090879 12834 solver.cpp:261]     Train net output #0: loss = 0.58943 (* 1 = 0.58943 loss)
I0506 04:34:00.090890 12834 sgd_solver.cpp:106] Iteration 29700, lr = 6.4e-05
I0506 04:34:01.127372 12834 solver.cpp:242] Iteration 29800 (95.9938 iter/s, 1.04173s/100 iter), loss = 2.60546
I0506 04:34:01.127418 12834 solver.cpp:261]     Train net output #0: loss = 2.60546 (* 1 = 2.60546 loss)
I0506 04:34:01.127429 12834 sgd_solver.cpp:106] Iteration 29800, lr = 6.4e-05
I0506 04:34:01.132669 12834 solver.cpp:242] Iteration 29800 (95.9905 iter/s, 1.04177s/100 iter), loss = 1.02461
I0506 04:34:01.132699 12834 solver.cpp:261]     Train net output #0: loss = 1.02461 (* 1 = 1.02461 loss)
I0506 04:34:01.132710 12834 sgd_solver.cpp:106] Iteration 29800, lr = 6.4e-05
I0506 04:34:02.119710 12834 solver.cpp:242] Iteration 29900 (100.78 iter/s, 0.992261s/100 iter), loss = 3.70627
I0506 04:34:02.119756 12834 solver.cpp:261]     Train net output #0: loss = 3.70627 (* 1 = 3.70627 loss)
I0506 04:34:02.119766 12834 sgd_solver.cpp:106] Iteration 29900, lr = 6.4e-05
I0506 04:34:02.124497 12834 solver.cpp:242] Iteration 29900 (100.829 iter/s, 0.991779s/100 iter), loss = 1.15631
I0506 04:34:02.124521 12834 solver.cpp:261]     Train net output #0: loss = 1.15631 (* 1 = 1.15631 loss)
I0506 04:34:02.124531 12834 sgd_solver.cpp:106] Iteration 29900, lr = 6.4e-05
I0506 04:34:03.068789 12834 solver.cpp:362] Iteration 30000, Testing net (#0)
I0506 04:34:03.068815 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:03.191581 12834 solver.cpp:429]     Test net output #0: loss = 2.26042 (* 1 = 2.26042 loss)
I0506 04:34:03.194108 12834 solver.cpp:242] Iteration 30000 (93.0811 iter/s, 1.07433s/100 iter), loss = 0.749386
I0506 04:34:03.194128 12834 solver.cpp:261]     Train net output #0: loss = 0.749386 (* 1 = 0.749386 loss)
I0506 04:34:03.194139 12834 sgd_solver.cpp:106] Iteration 30000, lr = 5.12e-05
I0506 04:34:03.195960 12834 solver.cpp:362] Iteration 30000, Testing net (#0)
I0506 04:34:03.195976 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:03.325145 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6605
I0506 04:34:03.325165 12834 solver.cpp:429]     Test net output #1: loss = 0.833486 (* 1 = 0.833486 loss)
I0506 04:34:03.327713 12834 solver.cpp:242] Iteration 30000 (83.1138 iter/s, 1.20317s/100 iter), loss = 0.732633
I0506 04:34:03.327733 12834 solver.cpp:261]     Train net output #0: loss = 0.732633 (* 1 = 0.732633 loss)
I0506 04:34:03.327742 12834 sgd_solver.cpp:106] Iteration 30000, lr = 5.12e-05
I0506 04:34:04.261409 12834 solver.cpp:242] Iteration 30100 (93.6989 iter/s, 1.06725s/100 iter), loss = 3.06935
I0506 04:34:04.261446 12834 solver.cpp:261]     Train net output #0: loss = 3.06935 (* 1 = 3.06935 loss)
I0506 04:34:04.261456 12834 sgd_solver.cpp:106] Iteration 30100, lr = 5.12e-05
I0506 04:34:04.266171 12834 solver.cpp:242] Iteration 30100 (106.562 iter/s, 0.938419s/100 iter), loss = 0.748988
I0506 04:34:04.266197 12834 solver.cpp:261]     Train net output #0: loss = 0.748988 (* 1 = 0.748988 loss)
I0506 04:34:04.266206 12834 sgd_solver.cpp:106] Iteration 30100, lr = 5.12e-05
I0506 04:34:05.200600 12834 solver.cpp:242] Iteration 30200 (106.481 iter/s, 0.939131s/100 iter), loss = 2.93546
I0506 04:34:05.200637 12834 solver.cpp:261]     Train net output #0: loss = 2.93546 (* 1 = 2.93546 loss)
I0506 04:34:05.200646 12834 sgd_solver.cpp:106] Iteration 30200, lr = 5.12e-05
I0506 04:34:05.205425 12834 solver.cpp:242] Iteration 30200 (106.474 iter/s, 0.939201s/100 iter), loss = 0.61443
I0506 04:34:05.205451 12834 solver.cpp:261]     Train net output #0: loss = 0.61443 (* 1 = 0.61443 loss)
I0506 04:34:05.205461 12834 sgd_solver.cpp:106] Iteration 30200, lr = 5.12e-05
I0506 04:34:06.139287 12834 solver.cpp:242] Iteration 30300 (106.539 iter/s, 0.938622s/100 iter), loss = 6.01132
I0506 04:34:06.139322 12834 solver.cpp:261]     Train net output #0: loss = 6.01132 (* 1 = 6.01132 loss)
I0506 04:34:06.139333 12834 sgd_solver.cpp:106] Iteration 30300, lr = 5.12e-05
I0506 04:34:06.144045 12834 solver.cpp:242] Iteration 30300 (106.544 iter/s, 0.938577s/100 iter), loss = 0.547256
I0506 04:34:06.144070 12834 solver.cpp:261]     Train net output #0: loss = 0.547256 (* 1 = 0.547256 loss)
I0506 04:34:06.144079 12834 sgd_solver.cpp:106] Iteration 30300, lr = 5.12e-05
I0506 04:34:07.129544 12834 solver.cpp:242] Iteration 30400 (100.99 iter/s, 0.990197s/100 iter), loss = 3.74536
I0506 04:34:07.129580 12834 solver.cpp:261]     Train net output #0: loss = 3.74536 (* 1 = 3.74536 loss)
I0506 04:34:07.129591 12834 sgd_solver.cpp:106] Iteration 30400, lr = 5.12e-05
I0506 04:34:07.134907 12834 solver.cpp:242] Iteration 30400 (100.928 iter/s, 0.990807s/100 iter), loss = 1.09237
I0506 04:34:07.134935 12834 solver.cpp:261]     Train net output #0: loss = 1.09237 (* 1 = 1.09237 loss)
I0506 04:34:07.134948 12834 sgd_solver.cpp:106] Iteration 30400, lr = 5.12e-05
I0506 04:34:08.162333 12834 solver.cpp:362] Iteration 30500, Testing net (#0)
I0506 04:34:08.162382 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:08.285293 12834 solver.cpp:429]     Test net output #0: loss = 2.20024 (* 1 = 2.20024 loss)
I0506 04:34:08.287822 12834 solver.cpp:242] Iteration 30500 (86.3392 iter/s, 1.15822s/100 iter), loss = 2.43461
I0506 04:34:08.287842 12834 solver.cpp:261]     Train net output #0: loss = 2.43461 (* 1 = 2.43461 loss)
I0506 04:34:08.287850 12834 sgd_solver.cpp:106] Iteration 30500, lr = 5.12e-05
I0506 04:34:08.289675 12834 solver.cpp:362] Iteration 30500, Testing net (#0)
I0506 04:34:08.289690 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:08.418699 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6725
I0506 04:34:08.418718 12834 solver.cpp:429]     Test net output #1: loss = 0.812544 (* 1 = 0.812544 loss)
I0506 04:34:08.421285 12834 solver.cpp:242] Iteration 30500 (77.7407 iter/s, 1.28633s/100 iter), loss = 0.803155
I0506 04:34:08.421305 12834 solver.cpp:261]     Train net output #0: loss = 0.803155 (* 1 = 0.803155 loss)
I0506 04:34:08.421314 12834 sgd_solver.cpp:106] Iteration 30500, lr = 5.12e-05
I0506 04:34:09.355459 12834 solver.cpp:242] Iteration 30600 (93.6693 iter/s, 1.06759s/100 iter), loss = 1.46964
I0506 04:34:09.355491 12834 solver.cpp:261]     Train net output #0: loss = 1.46964 (* 1 = 1.46964 loss)
I0506 04:34:09.355501 12834 sgd_solver.cpp:106] Iteration 30600, lr = 5.12e-05
I0506 04:34:09.360244 12834 solver.cpp:242] Iteration 30600 (106.505 iter/s, 0.93892s/100 iter), loss = 0.531375
I0506 04:34:09.360267 12834 solver.cpp:261]     Train net output #0: loss = 0.531375 (* 1 = 0.531375 loss)
I0506 04:34:09.360276 12834 sgd_solver.cpp:106] Iteration 30600, lr = 5.12e-05
I0506 04:34:10.293925 12834 solver.cpp:242] Iteration 30700 (106.563 iter/s, 0.938409s/100 iter), loss = 1.02643
I0506 04:34:10.293951 12834 solver.cpp:261]     Train net output #0: loss = 1.02643 (* 1 = 1.02643 loss)
I0506 04:34:10.293961 12834 sgd_solver.cpp:106] Iteration 30700, lr = 5.12e-05
I0506 04:34:10.298710 12834 solver.cpp:242] Iteration 30700 (106.562 iter/s, 0.938424s/100 iter), loss = 0.763789
I0506 04:34:10.298733 12834 solver.cpp:261]     Train net output #0: loss = 0.763789 (* 1 = 0.763789 loss)
I0506 04:34:10.298743 12834 sgd_solver.cpp:106] Iteration 30700, lr = 5.12e-05
I0506 04:34:11.232053 12834 solver.cpp:242] Iteration 30800 (106.602 iter/s, 0.93807s/100 iter), loss = 2.40994
I0506 04:34:11.232092 12834 solver.cpp:261]     Train net output #0: loss = 2.40994 (* 1 = 2.40994 loss)
I0506 04:34:11.232101 12834 sgd_solver.cpp:106] Iteration 30800, lr = 5.12e-05
I0506 04:34:11.236871 12834 solver.cpp:242] Iteration 30800 (106.596 iter/s, 0.938117s/100 iter), loss = 1.01681
I0506 04:34:11.236896 12834 solver.cpp:261]     Train net output #0: loss = 1.01681 (* 1 = 1.01681 loss)
I0506 04:34:11.236905 12834 sgd_solver.cpp:106] Iteration 30800, lr = 5.12e-05
I0506 04:34:12.169932 12834 solver.cpp:242] Iteration 30900 (106.631 iter/s, 0.937815s/100 iter), loss = 2.0437
I0506 04:34:12.169973 12834 solver.cpp:261]     Train net output #0: loss = 2.0437 (* 1 = 2.0437 loss)
I0506 04:34:12.169982 12834 sgd_solver.cpp:106] Iteration 30900, lr = 5.12e-05
I0506 04:34:12.174718 12834 solver.cpp:242] Iteration 30900 (106.632 iter/s, 0.937803s/100 iter), loss = 0.749524
I0506 04:34:12.174743 12834 solver.cpp:261]     Train net output #0: loss = 0.749524 (* 1 = 0.749524 loss)
I0506 04:34:12.174752 12834 sgd_solver.cpp:106] Iteration 30900, lr = 5.12e-05
I0506 04:34:13.160401 12834 solver.cpp:362] Iteration 31000, Testing net (#0)
I0506 04:34:13.160431 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:13.293658 12834 solver.cpp:429]     Test net output #0: loss = 2.33727 (* 1 = 2.33727 loss)
I0506 04:34:13.296232 12834 solver.cpp:242] Iteration 31000 (88.7911 iter/s, 1.12624s/100 iter), loss = 3.92541
I0506 04:34:13.296257 12834 solver.cpp:261]     Train net output #0: loss = 3.92541 (* 1 = 3.92541 loss)
I0506 04:34:13.296267 12834 sgd_solver.cpp:106] Iteration 31000, lr = 5.12e-05
I0506 04:34:13.298115 12834 solver.cpp:362] Iteration 31000, Testing net (#0)
I0506 04:34:13.298130 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:13.427440 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6325
I0506 04:34:13.427460 12834 solver.cpp:429]     Test net output #1: loss = 0.843392 (* 1 = 0.843392 loss)
I0506 04:34:13.430033 12834 solver.cpp:242] Iteration 31000 (79.6642 iter/s, 1.25527s/100 iter), loss = 0.904947
I0506 04:34:13.430055 12834 solver.cpp:261]     Train net output #0: loss = 0.904947 (* 1 = 0.904947 loss)
I0506 04:34:13.430063 12834 sgd_solver.cpp:106] Iteration 31000, lr = 5.12e-05
I0506 04:34:14.363775 12834 solver.cpp:242] Iteration 31100 (93.6778 iter/s, 1.06749s/100 iter), loss = 2.64323
I0506 04:34:14.363814 12834 solver.cpp:261]     Train net output #0: loss = 2.64323 (* 1 = 2.64323 loss)
I0506 04:34:14.363824 12834 sgd_solver.cpp:106] Iteration 31100, lr = 5.12e-05
I0506 04:34:14.368643 12834 solver.cpp:242] Iteration 31100 (106.546 iter/s, 0.93856s/100 iter), loss = 0.899122
I0506 04:34:14.368669 12834 solver.cpp:261]     Train net output #0: loss = 0.899122 (* 1 = 0.899122 loss)
I0506 04:34:14.368679 12834 sgd_solver.cpp:106] Iteration 31100, lr = 5.12e-05
I0506 04:34:15.302263 12834 solver.cpp:242] Iteration 31200 (106.562 iter/s, 0.938422s/100 iter), loss = 1.62855
I0506 04:34:15.302304 12834 solver.cpp:261]     Train net output #0: loss = 1.62855 (* 1 = 1.62855 loss)
I0506 04:34:15.302314 12834 sgd_solver.cpp:106] Iteration 31200, lr = 5.12e-05
I0506 04:34:15.307039 12834 solver.cpp:242] Iteration 31200 (106.57 iter/s, 0.938352s/100 iter), loss = 1.07258
I0506 04:34:15.307065 12834 solver.cpp:261]     Train net output #0: loss = 1.07258 (* 1 = 1.07258 loss)
I0506 04:34:15.307075 12834 sgd_solver.cpp:106] Iteration 31200, lr = 5.12e-05
I0506 04:34:16.241307 12834 solver.cpp:242] Iteration 31300 (106.499 iter/s, 0.938979s/100 iter), loss = 1.13185
I0506 04:34:16.241346 12834 solver.cpp:261]     Train net output #0: loss = 1.13185 (* 1 = 1.13185 loss)
I0506 04:34:16.241355 12834 sgd_solver.cpp:106] Iteration 31300, lr = 5.12e-05
I0506 04:34:16.246171 12834 solver.cpp:242] Iteration 31300 (106.487 iter/s, 0.93908s/100 iter), loss = 0.821121
I0506 04:34:16.246197 12834 solver.cpp:261]     Train net output #0: loss = 0.821121 (* 1 = 0.821121 loss)
I0506 04:34:16.246206 12834 sgd_solver.cpp:106] Iteration 31300, lr = 5.12e-05
I0506 04:34:17.179157 12834 solver.cpp:242] Iteration 31400 (106.634 iter/s, 0.937784s/100 iter), loss = 1.8897
I0506 04:34:17.179195 12834 solver.cpp:261]     Train net output #0: loss = 1.8897 (* 1 = 1.8897 loss)
I0506 04:34:17.179204 12834 sgd_solver.cpp:106] Iteration 31400, lr = 5.12e-05
I0506 04:34:17.183929 12834 solver.cpp:242] Iteration 31400 (106.642 iter/s, 0.937714s/100 iter), loss = 0.706375
I0506 04:34:17.183954 12834 solver.cpp:261]     Train net output #0: loss = 0.706375 (* 1 = 0.706375 loss)
I0506 04:34:17.183964 12834 sgd_solver.cpp:106] Iteration 31400, lr = 5.12e-05
I0506 04:34:18.114971 12834 solver.cpp:362] Iteration 31500, Testing net (#0)
I0506 04:34:18.114995 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:18.237813 12834 solver.cpp:429]     Test net output #0: loss = 2.81102 (* 1 = 2.81102 loss)
I0506 04:34:18.240347 12834 solver.cpp:242] Iteration 31500 (94.2389 iter/s, 1.06113s/100 iter), loss = 1.39853
I0506 04:34:18.240370 12834 solver.cpp:261]     Train net output #0: loss = 1.39853 (* 1 = 1.39853 loss)
I0506 04:34:18.240378 12834 sgd_solver.cpp:106] Iteration 31500, lr = 5.12e-05
I0506 04:34:18.242183 12834 solver.cpp:362] Iteration 31500, Testing net (#0)
I0506 04:34:18.242197 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:18.371129 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6495
I0506 04:34:18.371155 12834 solver.cpp:429]     Test net output #1: loss = 0.949533 (* 1 = 0.949533 loss)
I0506 04:34:18.373809 12834 solver.cpp:242] Iteration 31500 (84.0453 iter/s, 1.18983s/100 iter), loss = 1.2378
I0506 04:34:18.373831 12834 solver.cpp:261]     Train net output #0: loss = 1.2378 (* 1 = 1.2378 loss)
I0506 04:34:18.373852 12834 sgd_solver.cpp:106] Iteration 31500, lr = 5.12e-05
I0506 04:34:19.307327 12834 solver.cpp:242] Iteration 31600 (93.7269 iter/s, 1.06693s/100 iter), loss = 0.951994
I0506 04:34:19.307365 12834 solver.cpp:261]     Train net output #0: loss = 0.951994 (* 1 = 0.951994 loss)
I0506 04:34:19.307375 12834 sgd_solver.cpp:106] Iteration 31600, lr = 5.12e-05
I0506 04:34:19.312125 12834 solver.cpp:242] Iteration 31600 (106.579 iter/s, 0.938275s/100 iter), loss = 0.651373
I0506 04:34:19.312150 12834 solver.cpp:261]     Train net output #0: loss = 0.651373 (* 1 = 0.651373 loss)
I0506 04:34:19.312160 12834 sgd_solver.cpp:106] Iteration 31600, lr = 5.12e-05
I0506 04:34:20.245398 12834 solver.cpp:242] Iteration 31700 (106.609 iter/s, 0.938003s/100 iter), loss = 2.49671
I0506 04:34:20.245434 12834 solver.cpp:261]     Train net output #0: loss = 2.49671 (* 1 = 2.49671 loss)
I0506 04:34:20.245443 12834 sgd_solver.cpp:106] Iteration 31700, lr = 5.12e-05
I0506 04:34:20.250202 12834 solver.cpp:242] Iteration 31700 (106.606 iter/s, 0.938033s/100 iter), loss = 0.754092
I0506 04:34:20.250227 12834 solver.cpp:261]     Train net output #0: loss = 0.754092 (* 1 = 0.754092 loss)
I0506 04:34:20.250236 12834 sgd_solver.cpp:106] Iteration 31700, lr = 5.12e-05
I0506 04:34:21.183815 12834 solver.cpp:242] Iteration 31800 (106.569 iter/s, 0.938356s/100 iter), loss = 6.4965
I0506 04:34:21.183848 12834 solver.cpp:261]     Train net output #0: loss = 6.4965 (* 1 = 6.4965 loss)
I0506 04:34:21.183857 12834 sgd_solver.cpp:106] Iteration 31800, lr = 5.12e-05
I0506 04:34:21.188598 12834 solver.cpp:242] Iteration 31800 (106.57 iter/s, 0.938353s/100 iter), loss = 0.627669
I0506 04:34:21.188622 12834 solver.cpp:261]     Train net output #0: loss = 0.627669 (* 1 = 0.627669 loss)
I0506 04:34:21.188632 12834 sgd_solver.cpp:106] Iteration 31800, lr = 5.12e-05
I0506 04:34:22.122041 12834 solver.cpp:242] Iteration 31900 (106.591 iter/s, 0.938164s/100 iter), loss = 2.39007
I0506 04:34:22.122073 12834 solver.cpp:261]     Train net output #0: loss = 2.39007 (* 1 = 2.39007 loss)
I0506 04:34:22.122083 12834 sgd_solver.cpp:106] Iteration 31900, lr = 5.12e-05
I0506 04:34:22.126806 12834 solver.cpp:242] Iteration 31900 (106.591 iter/s, 0.938165s/100 iter), loss = 0.668405
I0506 04:34:22.126829 12834 solver.cpp:261]     Train net output #0: loss = 0.668405 (* 1 = 0.668405 loss)
I0506 04:34:22.126838 12834 sgd_solver.cpp:106] Iteration 31900, lr = 5.12e-05
I0506 04:34:23.107323 12834 solver.cpp:362] Iteration 32000, Testing net (#0)
I0506 04:34:23.107345 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:23.240604 12834 solver.cpp:429]     Test net output #0: loss = 2.14496 (* 1 = 2.14496 loss)
I0506 04:34:23.243253 12834 solver.cpp:242] Iteration 32000 (89.1933 iter/s, 1.12116s/100 iter), loss = 3.12419
I0506 04:34:23.243278 12834 solver.cpp:261]     Train net output #0: loss = 3.12419 (* 1 = 3.12419 loss)
I0506 04:34:23.243288 12834 sgd_solver.cpp:106] Iteration 32000, lr = 5.12e-05
I0506 04:34:23.245467 12834 solver.cpp:362] Iteration 32000, Testing net (#0)
I0506 04:34:23.245493 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:23.385982 12834 solver.cpp:429]     Test net output #0: accuracy = 0.66
I0506 04:34:23.386003 12834 solver.cpp:429]     Test net output #1: loss = 0.831847 (* 1 = 0.831847 loss)
I0506 04:34:23.388581 12834 solver.cpp:242] Iteration 32000 (79.2563 iter/s, 1.26173s/100 iter), loss = 0.778602
I0506 04:34:23.388602 12834 solver.cpp:261]     Train net output #0: loss = 0.778602 (* 1 = 0.778602 loss)
I0506 04:34:23.388610 12834 sgd_solver.cpp:106] Iteration 32000, lr = 5.12e-05
I0506 04:34:24.322043 12834 solver.cpp:242] Iteration 32100 (92.7013 iter/s, 1.07873s/100 iter), loss = 2.50433
I0506 04:34:24.322084 12834 solver.cpp:261]     Train net output #0: loss = 2.50433 (* 1 = 2.50433 loss)
I0506 04:34:24.322093 12834 sgd_solver.cpp:106] Iteration 32100, lr = 5.12e-05
I0506 04:34:24.326814 12834 solver.cpp:242] Iteration 32100 (106.588 iter/s, 0.938196s/100 iter), loss = 0.668327
I0506 04:34:24.326855 12834 solver.cpp:261]     Train net output #0: loss = 0.668327 (* 1 = 0.668327 loss)
I0506 04:34:24.326864 12834 sgd_solver.cpp:106] Iteration 32100, lr = 5.12e-05
I0506 04:34:25.259802 12834 solver.cpp:242] Iteration 32200 (106.644 iter/s, 0.937696s/100 iter), loss = 5.10151
I0506 04:34:25.259843 12834 solver.cpp:261]     Train net output #0: loss = 5.10151 (* 1 = 5.10151 loss)
I0506 04:34:25.259852 12834 sgd_solver.cpp:106] Iteration 32200, lr = 5.12e-05
I0506 04:34:25.264665 12834 solver.cpp:242] Iteration 32200 (106.634 iter/s, 0.937784s/100 iter), loss = 0.960217
I0506 04:34:25.264691 12834 solver.cpp:261]     Train net output #0: loss = 0.960217 (* 1 = 0.960217 loss)
I0506 04:34:25.264700 12834 sgd_solver.cpp:106] Iteration 32200, lr = 5.12e-05
I0506 04:34:26.198817 12834 solver.cpp:242] Iteration 32300 (106.502 iter/s, 0.938948s/100 iter), loss = 1.07843
I0506 04:34:26.198858 12834 solver.cpp:261]     Train net output #0: loss = 1.07843 (* 1 = 1.07843 loss)
I0506 04:34:26.198868 12834 sgd_solver.cpp:106] Iteration 32300, lr = 5.12e-05
I0506 04:34:26.203585 12834 solver.cpp:242] Iteration 32300 (106.51 iter/s, 0.938876s/100 iter), loss = 1.05765
I0506 04:34:26.203611 12834 solver.cpp:261]     Train net output #0: loss = 1.05765 (* 1 = 1.05765 loss)
I0506 04:34:26.203620 12834 sgd_solver.cpp:106] Iteration 32300, lr = 5.12e-05
I0506 04:34:27.150987 12834 solver.cpp:242] Iteration 32400 (105.031 iter/s, 0.9521s/100 iter), loss = 1.31851
I0506 04:34:27.151027 12834 solver.cpp:261]     Train net output #0: loss = 1.31851 (* 1 = 1.31851 loss)
I0506 04:34:27.151036 12834 sgd_solver.cpp:106] Iteration 32400, lr = 5.12e-05
I0506 04:34:27.155802 12834 solver.cpp:242] Iteration 32400 (105.023 iter/s, 0.952172s/100 iter), loss = 1.07644
I0506 04:34:27.155827 12834 solver.cpp:261]     Train net output #0: loss = 1.07644 (* 1 = 1.07644 loss)
I0506 04:34:27.155835 12834 sgd_solver.cpp:106] Iteration 32400, lr = 5.12e-05
I0506 04:34:28.086313 12834 solver.cpp:362] Iteration 32500, Testing net (#0)
I0506 04:34:28.086338 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:28.209280 12834 solver.cpp:429]     Test net output #0: loss = 2.4421 (* 1 = 2.4421 loss)
I0506 04:34:28.211800 12834 solver.cpp:242] Iteration 32500 (94.2725 iter/s, 1.06075s/100 iter), loss = 1.95485
I0506 04:34:28.211820 12834 solver.cpp:261]     Train net output #0: loss = 1.95485 (* 1 = 1.95485 loss)
I0506 04:34:28.211829 12834 sgd_solver.cpp:106] Iteration 32500, lr = 5.12e-05
I0506 04:34:28.213675 12834 solver.cpp:362] Iteration 32500, Testing net (#0)
I0506 04:34:28.213690 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:28.342448 12834 solver.cpp:429]     Test net output #0: accuracy = 0.653
I0506 04:34:28.342469 12834 solver.cpp:429]     Test net output #1: loss = 0.813465 (* 1 = 0.813465 loss)
I0506 04:34:28.345041 12834 solver.cpp:242] Iteration 32500 (84.0905 iter/s, 1.18919s/100 iter), loss = 0.621363
I0506 04:34:28.345062 12834 solver.cpp:261]     Train net output #0: loss = 0.621363 (* 1 = 0.621363 loss)
I0506 04:34:28.345070 12834 sgd_solver.cpp:106] Iteration 32500, lr = 5.12e-05
I0506 04:34:29.278959 12834 solver.cpp:242] Iteration 32600 (93.7116 iter/s, 1.0671s/100 iter), loss = 2.19789
I0506 04:34:29.278998 12834 solver.cpp:261]     Train net output #0: loss = 2.19789 (* 1 = 2.19789 loss)
I0506 04:34:29.279007 12834 sgd_solver.cpp:106] Iteration 32600, lr = 5.12e-05
I0506 04:34:29.283758 12834 solver.cpp:242] Iteration 32600 (106.533 iter/s, 0.938678s/100 iter), loss = 0.845368
I0506 04:34:29.283785 12834 solver.cpp:261]     Train net output #0: loss = 0.845368 (* 1 = 0.845368 loss)
I0506 04:34:29.283794 12834 sgd_solver.cpp:106] Iteration 32600, lr = 5.12e-05
I0506 04:34:30.217773 12834 solver.cpp:242] Iteration 32700 (106.525 iter/s, 0.93875s/100 iter), loss = 1.30629
I0506 04:34:30.217810 12834 solver.cpp:261]     Train net output #0: loss = 1.30629 (* 1 = 1.30629 loss)
I0506 04:34:30.217819 12834 sgd_solver.cpp:106] Iteration 32700, lr = 5.12e-05
I0506 04:34:30.222527 12834 solver.cpp:242] Iteration 32700 (106.528 iter/s, 0.938724s/100 iter), loss = 0.865785
I0506 04:34:30.222561 12834 solver.cpp:261]     Train net output #0: loss = 0.865785 (* 1 = 0.865785 loss)
I0506 04:34:30.222571 12834 sgd_solver.cpp:106] Iteration 32700, lr = 5.12e-05
I0506 04:34:31.155843 12834 solver.cpp:242] Iteration 32800 (106.609 iter/s, 0.938004s/100 iter), loss = 1.62966
I0506 04:34:31.155881 12834 solver.cpp:261]     Train net output #0: loss = 1.62966 (* 1 = 1.62966 loss)
I0506 04:34:31.155890 12834 sgd_solver.cpp:106] Iteration 32800, lr = 5.12e-05
I0506 04:34:31.160640 12834 solver.cpp:242] Iteration 32800 (106.603 iter/s, 0.938061s/100 iter), loss = 0.661277
I0506 04:34:31.160665 12834 solver.cpp:261]     Train net output #0: loss = 0.661277 (* 1 = 0.661277 loss)
I0506 04:34:31.160675 12834 sgd_solver.cpp:106] Iteration 32800, lr = 5.12e-05
I0506 04:34:32.093722 12834 solver.cpp:242] Iteration 32900 (106.631 iter/s, 0.937816s/100 iter), loss = 1.95381
I0506 04:34:32.093758 12834 solver.cpp:261]     Train net output #0: loss = 1.95381 (* 1 = 1.95381 loss)
I0506 04:34:32.093768 12834 sgd_solver.cpp:106] Iteration 32900, lr = 5.12e-05
I0506 04:34:32.098516 12834 solver.cpp:242] Iteration 32900 (106.629 iter/s, 0.937833s/100 iter), loss = 0.984797
I0506 04:34:32.098541 12834 solver.cpp:261]     Train net output #0: loss = 0.984797 (* 1 = 0.984797 loss)
I0506 04:34:32.098551 12834 sgd_solver.cpp:106] Iteration 32900, lr = 5.12e-05
I0506 04:34:33.029223 12834 solver.cpp:362] Iteration 33000, Testing net (#0)
I0506 04:34:33.029247 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:33.152176 12834 solver.cpp:429]     Test net output #0: loss = 2.32449 (* 1 = 2.32449 loss)
I0506 04:34:33.154711 12834 solver.cpp:242] Iteration 33000 (94.2566 iter/s, 1.06093s/100 iter), loss = 1.32983
I0506 04:34:33.154731 12834 solver.cpp:261]     Train net output #0: loss = 1.32983 (* 1 = 1.32983 loss)
I0506 04:34:33.154741 12834 sgd_solver.cpp:106] Iteration 33000, lr = 5.12e-05
I0506 04:34:33.156561 12834 solver.cpp:362] Iteration 33000, Testing net (#0)
I0506 04:34:33.156574 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:33.285590 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6895
I0506 04:34:33.285610 12834 solver.cpp:429]     Test net output #1: loss = 0.752542 (* 1 = 0.752542 loss)
I0506 04:34:33.288164 12834 solver.cpp:242] Iteration 33000 (84.0618 iter/s, 1.1896s/100 iter), loss = 0.572627
I0506 04:34:33.288183 12834 solver.cpp:261]     Train net output #0: loss = 0.572627 (* 1 = 0.572627 loss)
I0506 04:34:33.288192 12834 sgd_solver.cpp:106] Iteration 33000, lr = 5.12e-05
I0506 04:34:34.222111 12834 solver.cpp:242] Iteration 33100 (93.6897 iter/s, 1.06735s/100 iter), loss = 0.753849
I0506 04:34:34.222146 12834 solver.cpp:261]     Train net output #0: loss = 0.753849 (* 1 = 0.753849 loss)
I0506 04:34:34.222156 12834 sgd_solver.cpp:106] Iteration 33100, lr = 5.12e-05
I0506 04:34:34.226965 12834 solver.cpp:242] Iteration 33100 (106.524 iter/s, 0.938755s/100 iter), loss = 0.869607
I0506 04:34:34.226991 12834 solver.cpp:261]     Train net output #0: loss = 0.869607 (* 1 = 0.869607 loss)
I0506 04:34:34.227000 12834 sgd_solver.cpp:106] Iteration 33100, lr = 5.12e-05
I0506 04:34:35.220908 12834 solver.cpp:242] Iteration 33200 (100.127 iter/s, 0.998734s/100 iter), loss = 2.80398
I0506 04:34:35.220947 12834 solver.cpp:261]     Train net output #0: loss = 2.80398 (* 1 = 2.80398 loss)
I0506 04:34:35.220958 12834 sgd_solver.cpp:106] Iteration 33200, lr = 5.12e-05
I0506 04:34:35.226210 12834 solver.cpp:242] Iteration 33200 (100.08 iter/s, 0.9992s/100 iter), loss = 0.925799
I0506 04:34:35.226238 12834 solver.cpp:261]     Train net output #0: loss = 0.925799 (* 1 = 0.925799 loss)
I0506 04:34:35.226249 12834 sgd_solver.cpp:106] Iteration 33200, lr = 5.12e-05
I0506 04:34:36.257658 12834 solver.cpp:242] Iteration 33300 (96.462 iter/s, 1.03668s/100 iter), loss = 2.77193
I0506 04:34:36.257695 12834 solver.cpp:261]     Train net output #0: loss = 2.77193 (* 1 = 2.77193 loss)
I0506 04:34:36.257706 12834 sgd_solver.cpp:106] Iteration 33300, lr = 5.12e-05
I0506 04:34:36.262943 12834 solver.cpp:242] Iteration 33300 (96.4613 iter/s, 1.03669s/100 iter), loss = 0.801063
I0506 04:34:36.262972 12834 solver.cpp:261]     Train net output #0: loss = 0.801063 (* 1 = 0.801063 loss)
I0506 04:34:36.262982 12834 sgd_solver.cpp:106] Iteration 33300, lr = 5.12e-05
I0506 04:34:37.293284 12834 solver.cpp:242] Iteration 33400 (96.5659 iter/s, 1.03556s/100 iter), loss = 1.5128
I0506 04:34:37.293321 12834 solver.cpp:261]     Train net output #0: loss = 1.5128 (* 1 = 1.5128 loss)
I0506 04:34:37.293332 12834 sgd_solver.cpp:106] Iteration 33400, lr = 5.12e-05
I0506 04:34:37.298542 12834 solver.cpp:242] Iteration 33400 (96.5671 iter/s, 1.03555s/100 iter), loss = 1.09299
I0506 04:34:37.298569 12834 solver.cpp:261]     Train net output #0: loss = 1.09299 (* 1 = 1.09299 loss)
I0506 04:34:37.298580 12834 sgd_solver.cpp:106] Iteration 33400, lr = 5.12e-05
I0506 04:34:38.266336 12834 solver.cpp:362] Iteration 33500, Testing net (#0)
I0506 04:34:38.266356 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:38.389469 12834 solver.cpp:429]     Test net output #0: loss = 2.58801 (* 1 = 2.58801 loss)
I0506 04:34:38.391983 12834 solver.cpp:242] Iteration 33500 (91.0213 iter/s, 1.09864s/100 iter), loss = 3.66411
I0506 04:34:38.392006 12834 solver.cpp:261]     Train net output #0: loss = 3.66411 (* 1 = 3.66411 loss)
I0506 04:34:38.392014 12834 sgd_solver.cpp:106] Iteration 33500, lr = 5.12e-05
I0506 04:34:38.393831 12834 solver.cpp:362] Iteration 33500, Testing net (#0)
I0506 04:34:38.393843 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:38.522986 12834 solver.cpp:429]     Test net output #0: accuracy = 0.702
I0506 04:34:38.523006 12834 solver.cpp:429]     Test net output #1: loss = 0.760457 (* 1 = 0.760457 loss)
I0506 04:34:38.525564 12834 solver.cpp:242] Iteration 33500 (81.5013 iter/s, 1.22697s/100 iter), loss = 0.756848
I0506 04:34:38.525585 12834 solver.cpp:261]     Train net output #0: loss = 0.756848 (* 1 = 0.756848 loss)
I0506 04:34:38.525594 12834 sgd_solver.cpp:106] Iteration 33500, lr = 5.12e-05
I0506 04:34:39.473006 12834 solver.cpp:242] Iteration 33600 (92.5091 iter/s, 1.08097s/100 iter), loss = 1.17019
I0506 04:34:39.473037 12834 solver.cpp:261]     Train net output #0: loss = 1.17019 (* 1 = 1.17019 loss)
I0506 04:34:39.473047 12834 sgd_solver.cpp:106] Iteration 33600, lr = 5.12e-05
I0506 04:34:39.477766 12834 solver.cpp:242] Iteration 33600 (105.024 iter/s, 0.952161s/100 iter), loss = 0.582123
I0506 04:34:39.477789 12834 solver.cpp:261]     Train net output #0: loss = 0.582123 (* 1 = 0.582123 loss)
I0506 04:34:39.477798 12834 sgd_solver.cpp:106] Iteration 33600, lr = 5.12e-05
I0506 04:34:40.411850 12834 solver.cpp:242] Iteration 33700 (106.521 iter/s, 0.938782s/100 iter), loss = 2.69604
I0506 04:34:40.411892 12834 solver.cpp:261]     Train net output #0: loss = 2.69604 (* 1 = 2.69604 loss)
I0506 04:34:40.411901 12834 sgd_solver.cpp:106] Iteration 33700, lr = 5.12e-05
I0506 04:34:40.416646 12834 solver.cpp:242] Iteration 33700 (106.515 iter/s, 0.938838s/100 iter), loss = 1.0651
I0506 04:34:40.416672 12834 solver.cpp:261]     Train net output #0: loss = 1.0651 (* 1 = 1.0651 loss)
I0506 04:34:40.416682 12834 sgd_solver.cpp:106] Iteration 33700, lr = 5.12e-05
I0506 04:34:41.350235 12834 solver.cpp:242] Iteration 33800 (106.574 iter/s, 0.938317s/100 iter), loss = 4.44704
I0506 04:34:41.350278 12834 solver.cpp:261]     Train net output #0: loss = 4.44704 (* 1 = 4.44704 loss)
I0506 04:34:41.350288 12834 sgd_solver.cpp:106] Iteration 33800, lr = 5.12e-05
I0506 04:34:41.355043 12834 solver.cpp:242] Iteration 33800 (106.57 iter/s, 0.938353s/100 iter), loss = 1.07759
I0506 04:34:41.355068 12834 solver.cpp:261]     Train net output #0: loss = 1.07759 (* 1 = 1.07759 loss)
I0506 04:34:41.355077 12834 sgd_solver.cpp:106] Iteration 33800, lr = 5.12e-05
I0506 04:34:42.289129 12834 solver.cpp:242] Iteration 33900 (106.517 iter/s, 0.938822s/100 iter), loss = 7.55624
I0506 04:34:42.289170 12834 solver.cpp:261]     Train net output #0: loss = 7.55624 (* 1 = 7.55624 loss)
I0506 04:34:42.289187 12834 sgd_solver.cpp:106] Iteration 33900, lr = 5.12e-05
I0506 04:34:42.293987 12834 solver.cpp:242] Iteration 33900 (106.508 iter/s, 0.938899s/100 iter), loss = 1.07555
I0506 04:34:42.294013 12834 solver.cpp:261]     Train net output #0: loss = 1.07555 (* 1 = 1.07555 loss)
I0506 04:34:42.294023 12834 sgd_solver.cpp:106] Iteration 33900, lr = 5.12e-05
I0506 04:34:43.291553 12834 solver.cpp:362] Iteration 34000, Testing net (#0)
I0506 04:34:43.291585 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:43.424907 12834 solver.cpp:429]     Test net output #0: loss = 2.20176 (* 1 = 2.20176 loss)
I0506 04:34:43.427577 12834 solver.cpp:242] Iteration 34000 (87.8437 iter/s, 1.13839s/100 iter), loss = 3.56804
I0506 04:34:43.427606 12834 solver.cpp:261]     Train net output #0: loss = 3.56804 (* 1 = 3.56804 loss)
I0506 04:34:43.427618 12834 sgd_solver.cpp:106] Iteration 34000, lr = 5.12e-05
I0506 04:34:43.429908 12834 solver.cpp:362] Iteration 34000, Testing net (#0)
I0506 04:34:43.429924 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:43.571239 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6855
I0506 04:34:43.571262 12834 solver.cpp:429]     Test net output #1: loss = 0.766137 (* 1 = 0.766137 loss)
I0506 04:34:43.573987 12834 solver.cpp:242] Iteration 34000 (78.128 iter/s, 1.27995s/100 iter), loss = 0.803064
I0506 04:34:43.574012 12834 solver.cpp:261]     Train net output #0: loss = 0.803064 (* 1 = 0.803064 loss)
I0506 04:34:43.574023 12834 sgd_solver.cpp:106] Iteration 34000, lr = 5.12e-05
I0506 04:34:44.580086 12834 solver.cpp:242] Iteration 34100 (86.7716 iter/s, 1.15245s/100 iter), loss = 1.86056
I0506 04:34:44.580128 12834 solver.cpp:261]     Train net output #0: loss = 1.86056 (* 1 = 1.86056 loss)
I0506 04:34:44.580137 12834 sgd_solver.cpp:106] Iteration 34100, lr = 5.12e-05
I0506 04:34:44.584874 12834 solver.cpp:242] Iteration 34100 (98.9272 iter/s, 1.01084s/100 iter), loss = 0.812209
I0506 04:34:44.584900 12834 solver.cpp:261]     Train net output #0: loss = 0.812209 (* 1 = 0.812209 loss)
I0506 04:34:44.584909 12834 sgd_solver.cpp:106] Iteration 34100, lr = 5.12e-05
I0506 04:34:45.518682 12834 solver.cpp:242] Iteration 34200 (106.55 iter/s, 0.938529s/100 iter), loss = 1.9052
I0506 04:34:45.518723 12834 solver.cpp:261]     Train net output #0: loss = 1.9052 (* 1 = 1.9052 loss)
I0506 04:34:45.518733 12834 sgd_solver.cpp:106] Iteration 34200, lr = 5.12e-05
I0506 04:34:45.523501 12834 solver.cpp:242] Iteration 34200 (106.544 iter/s, 0.938576s/100 iter), loss = 0.821895
I0506 04:34:45.523530 12834 solver.cpp:261]     Train net output #0: loss = 0.821895 (* 1 = 0.821895 loss)
I0506 04:34:45.523538 12834 sgd_solver.cpp:106] Iteration 34200, lr = 5.12e-05
I0506 04:34:46.457123 12834 solver.cpp:242] Iteration 34300 (106.567 iter/s, 0.938374s/100 iter), loss = 1.20319
I0506 04:34:46.457162 12834 solver.cpp:261]     Train net output #0: loss = 1.20319 (* 1 = 1.20319 loss)
I0506 04:34:46.457172 12834 sgd_solver.cpp:106] Iteration 34300, lr = 5.12e-05
I0506 04:34:46.461926 12834 solver.cpp:242] Iteration 34300 (106.567 iter/s, 0.938378s/100 iter), loss = 0.481655
I0506 04:34:46.461952 12834 solver.cpp:261]     Train net output #0: loss = 0.481655 (* 1 = 0.481655 loss)
I0506 04:34:46.461961 12834 sgd_solver.cpp:106] Iteration 34300, lr = 5.12e-05
I0506 04:34:47.395540 12834 solver.cpp:242] Iteration 34400 (106.57 iter/s, 0.938348s/100 iter), loss = 3.46814
I0506 04:34:47.395577 12834 solver.cpp:261]     Train net output #0: loss = 3.46814 (* 1 = 3.46814 loss)
I0506 04:34:47.395587 12834 sgd_solver.cpp:106] Iteration 34400, lr = 5.12e-05
I0506 04:34:47.400336 12834 solver.cpp:242] Iteration 34400 (106.568 iter/s, 0.938366s/100 iter), loss = 0.941136
I0506 04:34:47.400362 12834 solver.cpp:261]     Train net output #0: loss = 0.941136 (* 1 = 0.941136 loss)
I0506 04:34:47.400370 12834 sgd_solver.cpp:106] Iteration 34400, lr = 5.12e-05
I0506 04:34:48.330979 12834 solver.cpp:362] Iteration 34500, Testing net (#0)
I0506 04:34:48.331003 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:48.454061 12834 solver.cpp:429]     Test net output #0: loss = 2.25468 (* 1 = 2.25468 loss)
I0506 04:34:48.456598 12834 solver.cpp:242] Iteration 34500 (94.2507 iter/s, 1.061s/100 iter), loss = 1.66492
I0506 04:34:48.456617 12834 solver.cpp:261]     Train net output #0: loss = 1.66492 (* 1 = 1.66492 loss)
I0506 04:34:48.456625 12834 sgd_solver.cpp:106] Iteration 34500, lr = 5.12e-05
I0506 04:34:48.458447 12834 solver.cpp:362] Iteration 34500, Testing net (#0)
I0506 04:34:48.458461 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:48.588322 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6715
I0506 04:34:48.588347 12834 solver.cpp:429]     Test net output #1: loss = 0.791807 (* 1 = 0.791807 loss)
I0506 04:34:48.591048 12834 solver.cpp:242] Iteration 34500 (83.9868 iter/s, 1.19066s/100 iter), loss = 1.09281
I0506 04:34:48.591081 12834 solver.cpp:261]     Train net output #0: loss = 1.09281 (* 1 = 1.09281 loss)
I0506 04:34:48.591092 12834 sgd_solver.cpp:106] Iteration 34500, lr = 5.12e-05
I0506 04:34:49.646800 12834 solver.cpp:242] Iteration 34600 (84.0236 iter/s, 1.19014s/100 iter), loss = 3.57544
I0506 04:34:49.646862 12834 solver.cpp:261]     Train net output #0: loss = 3.57544 (* 1 = 3.57544 loss)
I0506 04:34:49.646927 12834 sgd_solver.cpp:106] Iteration 34600, lr = 5.12e-05
I0506 04:34:49.651734 12834 solver.cpp:242] Iteration 34600 (94.2824 iter/s, 1.06064s/100 iter), loss = 0.960099
I0506 04:34:49.651762 12834 solver.cpp:261]     Train net output #0: loss = 0.960099 (* 1 = 0.960099 loss)
I0506 04:34:49.651770 12834 sgd_solver.cpp:106] Iteration 34600, lr = 5.12e-05
I0506 04:34:50.585556 12834 solver.cpp:242] Iteration 34700 (106.533 iter/s, 0.938672s/100 iter), loss = 2.49861
I0506 04:34:50.585595 12834 solver.cpp:261]     Train net output #0: loss = 2.49861 (* 1 = 2.49861 loss)
I0506 04:34:50.585604 12834 sgd_solver.cpp:106] Iteration 34700, lr = 5.12e-05
I0506 04:34:50.590334 12834 solver.cpp:242] Iteration 34700 (106.547 iter/s, 0.938554s/100 iter), loss = 0.881534
I0506 04:34:50.590359 12834 solver.cpp:261]     Train net output #0: loss = 0.881534 (* 1 = 0.881534 loss)
I0506 04:34:50.590368 12834 sgd_solver.cpp:106] Iteration 34700, lr = 5.12e-05
I0506 04:34:51.524075 12834 solver.cpp:242] Iteration 34800 (106.559 iter/s, 0.938451s/100 iter), loss = 3.83231
I0506 04:34:51.524111 12834 solver.cpp:261]     Train net output #0: loss = 3.83231 (* 1 = 3.83231 loss)
I0506 04:34:51.524119 12834 sgd_solver.cpp:106] Iteration 34800, lr = 5.12e-05
I0506 04:34:51.528846 12834 solver.cpp:242] Iteration 34800 (106.557 iter/s, 0.938468s/100 iter), loss = 0.945389
I0506 04:34:51.528872 12834 solver.cpp:261]     Train net output #0: loss = 0.945389 (* 1 = 0.945389 loss)
I0506 04:34:51.528882 12834 sgd_solver.cpp:106] Iteration 34800, lr = 5.12e-05
I0506 04:34:52.461565 12834 solver.cpp:242] Iteration 34900 (106.675 iter/s, 0.937429s/100 iter), loss = 1.93564
I0506 04:34:52.461601 12834 solver.cpp:261]     Train net output #0: loss = 1.93564 (* 1 = 1.93564 loss)
I0506 04:34:52.461609 12834 sgd_solver.cpp:106] Iteration 34900, lr = 5.12e-05
I0506 04:34:52.466408 12834 solver.cpp:242] Iteration 34900 (106.666 iter/s, 0.937508s/100 iter), loss = 0.475364
I0506 04:34:52.466444 12834 solver.cpp:261]     Train net output #0: loss = 0.475364 (* 1 = 0.475364 loss)
I0506 04:34:52.466452 12834 sgd_solver.cpp:106] Iteration 34900, lr = 5.12e-05
I0506 04:34:53.397080 12834 solver.cpp:362] Iteration 35000, Testing net (#0)
I0506 04:34:53.397102 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:53.520051 12834 solver.cpp:429]     Test net output #0: loss = 2.26599 (* 1 = 2.26599 loss)
I0506 04:34:53.522581 12834 solver.cpp:242] Iteration 35000 (94.2541 iter/s, 1.06096s/100 iter), loss = 3.34523
I0506 04:34:53.522603 12834 solver.cpp:261]     Train net output #0: loss = 3.34523 (* 1 = 3.34523 loss)
I0506 04:34:53.522614 12834 sgd_solver.cpp:106] Iteration 35000, lr = 5.12e-05
I0506 04:34:53.524425 12834 solver.cpp:362] Iteration 35000, Testing net (#0)
I0506 04:34:53.524437 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:53.653600 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7075
I0506 04:34:53.653620 12834 solver.cpp:429]     Test net output #1: loss = 0.729939 (* 1 = 0.729939 loss)
I0506 04:34:53.656196 12834 solver.cpp:242] Iteration 35000 (84.0526 iter/s, 1.18973s/100 iter), loss = 0.841216
I0506 04:34:53.656217 12834 solver.cpp:261]     Train net output #0: loss = 0.841216 (* 1 = 0.841216 loss)
I0506 04:34:53.656226 12834 sgd_solver.cpp:106] Iteration 35000, lr = 5.12e-05
I0506 04:34:54.590860 12834 solver.cpp:242] Iteration 35100 (93.6129 iter/s, 1.06823s/100 iter), loss = 2.78222
I0506 04:34:54.590901 12834 solver.cpp:261]     Train net output #0: loss = 2.78222 (* 1 = 2.78222 loss)
I0506 04:34:54.590914 12834 sgd_solver.cpp:106] Iteration 35100, lr = 5.12e-05
I0506 04:34:54.596243 12834 solver.cpp:242] Iteration 35100 (106.383 iter/s, 0.939998s/100 iter), loss = 0.953895
I0506 04:34:54.596274 12834 solver.cpp:261]     Train net output #0: loss = 0.953895 (* 1 = 0.953895 loss)
I0506 04:34:54.596287 12834 sgd_solver.cpp:106] Iteration 35100, lr = 5.12e-05
I0506 04:34:55.598176 12834 solver.cpp:242] Iteration 35200 (99.2803 iter/s, 1.00725s/100 iter), loss = 1.96381
I0506 04:34:55.598206 12834 solver.cpp:261]     Train net output #0: loss = 1.96381 (* 1 = 1.96381 loss)
I0506 04:34:55.598215 12834 sgd_solver.cpp:106] Iteration 35200, lr = 5.12e-05
I0506 04:34:55.602962 12834 solver.cpp:242] Iteration 35200 (99.3376 iter/s, 1.00667s/100 iter), loss = 0.368398
I0506 04:34:55.602985 12834 solver.cpp:261]     Train net output #0: loss = 0.368398 (* 1 = 0.368398 loss)
I0506 04:34:55.602994 12834 sgd_solver.cpp:106] Iteration 35200, lr = 5.12e-05
I0506 04:34:56.535936 12834 solver.cpp:242] Iteration 35300 (106.644 iter/s, 0.937698s/100 iter), loss = 3.40236
I0506 04:34:56.535977 12834 solver.cpp:261]     Train net output #0: loss = 3.40236 (* 1 = 3.40236 loss)
I0506 04:34:56.535987 12834 sgd_solver.cpp:106] Iteration 35300, lr = 5.12e-05
I0506 04:34:56.540720 12834 solver.cpp:242] Iteration 35300 (106.642 iter/s, 0.937716s/100 iter), loss = 0.987048
I0506 04:34:56.540746 12834 solver.cpp:261]     Train net output #0: loss = 0.987048 (* 1 = 0.987048 loss)
I0506 04:34:56.540755 12834 sgd_solver.cpp:106] Iteration 35300, lr = 5.12e-05
I0506 04:34:57.473788 12834 solver.cpp:242] Iteration 35400 (106.634 iter/s, 0.937785s/100 iter), loss = 3.05368
I0506 04:34:57.473826 12834 solver.cpp:261]     Train net output #0: loss = 3.05368 (* 1 = 3.05368 loss)
I0506 04:34:57.473836 12834 sgd_solver.cpp:106] Iteration 35400, lr = 5.12e-05
I0506 04:34:57.478556 12834 solver.cpp:242] Iteration 35400 (106.633 iter/s, 0.937793s/100 iter), loss = 0.89888
I0506 04:34:57.478582 12834 solver.cpp:261]     Train net output #0: loss = 0.89888 (* 1 = 0.89888 loss)
I0506 04:34:57.478591 12834 sgd_solver.cpp:106] Iteration 35400, lr = 5.12e-05
I0506 04:34:58.408921 12834 solver.cpp:362] Iteration 35500, Testing net (#0)
I0506 04:34:58.408944 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:58.531761 12834 solver.cpp:429]     Test net output #0: loss = 2.11955 (* 1 = 2.11955 loss)
I0506 04:34:58.534293 12834 solver.cpp:242] Iteration 35500 (94.2997 iter/s, 1.06045s/100 iter), loss = 1.04411
I0506 04:34:58.534313 12834 solver.cpp:261]     Train net output #0: loss = 1.04411 (* 1 = 1.04411 loss)
I0506 04:34:58.534322 12834 sgd_solver.cpp:106] Iteration 35500, lr = 5.12e-05
I0506 04:34:58.536150 12834 solver.cpp:362] Iteration 35500, Testing net (#0)
I0506 04:34:58.536166 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:34:58.673271 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6795
I0506 04:34:58.673297 12834 solver.cpp:429]     Test net output #1: loss = 0.804622 (* 1 = 0.804622 loss)
I0506 04:34:58.675993 12834 solver.cpp:242] Iteration 35500 (83.5151 iter/s, 1.19739s/100 iter), loss = 1.15444
I0506 04:34:58.676018 12834 solver.cpp:261]     Train net output #0: loss = 1.15444 (* 1 = 1.15444 loss)
I0506 04:34:58.676029 12834 sgd_solver.cpp:106] Iteration 35500, lr = 5.12e-05
I0506 04:34:59.706403 12834 solver.cpp:242] Iteration 35600 (85.32 iter/s, 1.17206s/100 iter), loss = 1.5603
I0506 04:34:59.706451 12834 solver.cpp:261]     Train net output #0: loss = 1.5603 (* 1 = 1.5603 loss)
I0506 04:34:59.706462 12834 sgd_solver.cpp:106] Iteration 35600, lr = 5.12e-05
I0506 04:34:59.711724 12834 solver.cpp:242] Iteration 35600 (96.5546 iter/s, 1.03568s/100 iter), loss = 0.682745
I0506 04:34:59.711753 12834 solver.cpp:261]     Train net output #0: loss = 0.682745 (* 1 = 0.682745 loss)
I0506 04:34:59.711765 12834 sgd_solver.cpp:106] Iteration 35600, lr = 5.12e-05
I0506 04:35:00.750638 12834 solver.cpp:242] Iteration 35700 (95.7717 iter/s, 1.04415s/100 iter), loss = 1.20719
I0506 04:35:00.750697 12834 solver.cpp:261]     Train net output #0: loss = 1.20719 (* 1 = 1.20719 loss)
I0506 04:35:00.750876 12834 sgd_solver.cpp:106] Iteration 35700, lr = 5.12e-05
I0506 04:35:00.755682 12834 solver.cpp:242] Iteration 35700 (95.7938 iter/s, 1.04391s/100 iter), loss = 0.543507
I0506 04:35:00.755710 12834 solver.cpp:261]     Train net output #0: loss = 0.543507 (* 1 = 0.543507 loss)
I0506 04:35:00.755719 12834 sgd_solver.cpp:106] Iteration 35700, lr = 5.12e-05
I0506 04:35:01.693106 12834 solver.cpp:242] Iteration 35800 (106.114 iter/s, 0.942386s/100 iter), loss = 2.90282
I0506 04:35:01.693147 12834 solver.cpp:261]     Train net output #0: loss = 2.90282 (* 1 = 2.90282 loss)
I0506 04:35:01.693156 12834 sgd_solver.cpp:106] Iteration 35800, lr = 5.12e-05
I0506 04:35:01.697966 12834 solver.cpp:242] Iteration 35800 (106.131 iter/s, 0.94223s/100 iter), loss = 0.825003
I0506 04:35:01.697993 12834 solver.cpp:261]     Train net output #0: loss = 0.825003 (* 1 = 0.825003 loss)
I0506 04:35:01.698002 12834 sgd_solver.cpp:106] Iteration 35800, lr = 5.12e-05
I0506 04:35:02.631247 12834 solver.cpp:242] Iteration 35900 (106.602 iter/s, 0.938071s/100 iter), loss = 1.99728
I0506 04:35:02.631284 12834 solver.cpp:261]     Train net output #0: loss = 1.99728 (* 1 = 1.99728 loss)
I0506 04:35:02.631294 12834 sgd_solver.cpp:106] Iteration 35900, lr = 5.12e-05
I0506 04:35:02.636020 12834 solver.cpp:242] Iteration 35900 (106.609 iter/s, 0.93801s/100 iter), loss = 0.710094
I0506 04:35:02.636046 12834 solver.cpp:261]     Train net output #0: loss = 0.710094 (* 1 = 0.710094 loss)
I0506 04:35:02.636055 12834 sgd_solver.cpp:106] Iteration 35900, lr = 5.12e-05
I0506 04:35:03.566761 12834 solver.cpp:362] Iteration 36000, Testing net (#0)
I0506 04:35:03.566786 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:03.689574 12834 solver.cpp:429]     Test net output #0: loss = 2.08155 (* 1 = 2.08155 loss)
I0506 04:35:03.692096 12834 solver.cpp:242] Iteration 36000 (94.2691 iter/s, 1.06079s/100 iter), loss = 1.93217
I0506 04:35:03.692121 12834 solver.cpp:261]     Train net output #0: loss = 1.93217 (* 1 = 1.93217 loss)
I0506 04:35:03.692129 12834 sgd_solver.cpp:106] Iteration 36000, lr = 5.12e-05
I0506 04:35:03.694011 12834 solver.cpp:362] Iteration 36000, Testing net (#0)
I0506 04:35:03.694026 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:03.823148 12834 solver.cpp:429]     Test net output #0: accuracy = 0.664
I0506 04:35:03.823168 12834 solver.cpp:429]     Test net output #1: loss = 0.830299 (* 1 = 0.830299 loss)
I0506 04:35:03.825729 12834 solver.cpp:242] Iteration 36000 (84.0574 iter/s, 1.18966s/100 iter), loss = 0.589121
I0506 04:35:03.825752 12834 solver.cpp:261]     Train net output #0: loss = 0.589121 (* 1 = 0.589121 loss)
I0506 04:35:03.825762 12834 sgd_solver.cpp:106] Iteration 36000, lr = 5.12e-05
I0506 04:35:04.760049 12834 solver.cpp:242] Iteration 36100 (93.6416 iter/s, 1.0679s/100 iter), loss = 4.24191
I0506 04:35:04.760088 12834 solver.cpp:261]     Train net output #0: loss = 4.24191 (* 1 = 4.24191 loss)
I0506 04:35:04.760098 12834 sgd_solver.cpp:106] Iteration 36100, lr = 5.12e-05
I0506 04:35:04.764823 12834 solver.cpp:242] Iteration 36100 (106.49 iter/s, 0.939053s/100 iter), loss = 0.823337
I0506 04:35:04.764847 12834 solver.cpp:261]     Train net output #0: loss = 0.823337 (* 1 = 0.823337 loss)
I0506 04:35:04.764865 12834 sgd_solver.cpp:106] Iteration 36100, lr = 5.12e-05
I0506 04:35:05.698338 12834 solver.cpp:242] Iteration 36200 (106.585 iter/s, 0.938219s/100 iter), loss = 3.41491
I0506 04:35:05.698375 12834 solver.cpp:261]     Train net output #0: loss = 3.41491 (* 1 = 3.41491 loss)
I0506 04:35:05.698385 12834 sgd_solver.cpp:106] Iteration 36200, lr = 5.12e-05
I0506 04:35:05.703137 12834 solver.cpp:242] Iteration 36200 (106.579 iter/s, 0.938271s/100 iter), loss = 1.36811
I0506 04:35:05.703163 12834 solver.cpp:261]     Train net output #0: loss = 1.36811 (* 1 = 1.36811 loss)
I0506 04:35:05.703171 12834 sgd_solver.cpp:106] Iteration 36200, lr = 5.12e-05
I0506 04:35:06.637282 12834 solver.cpp:242] Iteration 36300 (106.51 iter/s, 0.938881s/100 iter), loss = 0.727658
I0506 04:35:06.637321 12834 solver.cpp:261]     Train net output #0: loss = 0.727658 (* 1 = 0.727658 loss)
I0506 04:35:06.637331 12834 sgd_solver.cpp:106] Iteration 36300, lr = 5.12e-05
I0506 04:35:06.642061 12834 solver.cpp:242] Iteration 36300 (106.51 iter/s, 0.93888s/100 iter), loss = 0.755922
I0506 04:35:06.642086 12834 solver.cpp:261]     Train net output #0: loss = 0.755922 (* 1 = 0.755922 loss)
I0506 04:35:06.642096 12834 sgd_solver.cpp:106] Iteration 36300, lr = 5.12e-05
I0506 04:35:07.575384 12834 solver.cpp:242] Iteration 36400 (106.606 iter/s, 0.938034s/100 iter), loss = 1.47386
I0506 04:35:07.575418 12834 solver.cpp:261]     Train net output #0: loss = 1.47386 (* 1 = 1.47386 loss)
I0506 04:35:07.575428 12834 sgd_solver.cpp:106] Iteration 36400, lr = 5.12e-05
I0506 04:35:07.580456 12834 solver.cpp:242] Iteration 36400 (106.57 iter/s, 0.93835s/100 iter), loss = 0.64245
I0506 04:35:07.580484 12834 solver.cpp:261]     Train net output #0: loss = 0.64245 (* 1 = 0.64245 loss)
I0506 04:35:07.580495 12834 sgd_solver.cpp:106] Iteration 36400, lr = 5.12e-05
I0506 04:35:08.607727 12834 solver.cpp:362] Iteration 36500, Testing net (#0)
I0506 04:35:08.607754 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:08.739434 12834 solver.cpp:429]     Test net output #0: loss = 2.37131 (* 1 = 2.37131 loss)
I0506 04:35:08.741956 12834 solver.cpp:242] Iteration 36500 (85.7253 iter/s, 1.16652s/100 iter), loss = 1.25718
I0506 04:35:08.741978 12834 solver.cpp:261]     Train net output #0: loss = 1.25718 (* 1 = 1.25718 loss)
I0506 04:35:08.741986 12834 sgd_solver.cpp:106] Iteration 36500, lr = 5.12e-05
I0506 04:35:08.743799 12834 solver.cpp:362] Iteration 36500, Testing net (#0)
I0506 04:35:08.743813 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:08.872658 12834 solver.cpp:429]     Test net output #0: accuracy = 0.656
I0506 04:35:08.872678 12834 solver.cpp:429]     Test net output #1: loss = 0.829826 (* 1 = 0.829826 loss)
I0506 04:35:08.875234 12834 solver.cpp:242] Iteration 36500 (77.2363 iter/s, 1.29473s/100 iter), loss = 1.2469
I0506 04:35:08.875254 12834 solver.cpp:261]     Train net output #0: loss = 1.2469 (* 1 = 1.2469 loss)
I0506 04:35:08.875262 12834 sgd_solver.cpp:106] Iteration 36500, lr = 5.12e-05
I0506 04:35:09.808732 12834 solver.cpp:242] Iteration 36600 (93.7452 iter/s, 1.06672s/100 iter), loss = 2.0713
I0506 04:35:09.808768 12834 solver.cpp:261]     Train net output #0: loss = 2.0713 (* 1 = 2.0713 loss)
I0506 04:35:09.808778 12834 sgd_solver.cpp:106] Iteration 36600, lr = 5.12e-05
I0506 04:35:09.813503 12834 solver.cpp:242] Iteration 36600 (106.584 iter/s, 0.938231s/100 iter), loss = 0.602383
I0506 04:35:09.813529 12834 solver.cpp:261]     Train net output #0: loss = 0.602383 (* 1 = 0.602383 loss)
I0506 04:35:09.813539 12834 sgd_solver.cpp:106] Iteration 36600, lr = 5.12e-05
I0506 04:35:10.764174 12834 solver.cpp:242] Iteration 36700 (104.67 iter/s, 0.955381s/100 iter), loss = 1.61008
I0506 04:35:10.764217 12834 solver.cpp:261]     Train net output #0: loss = 1.61008 (* 1 = 1.61008 loss)
I0506 04:35:10.764230 12834 sgd_solver.cpp:106] Iteration 36700, lr = 5.12e-05
I0506 04:35:10.769544 12834 solver.cpp:242] Iteration 36700 (104.604 iter/s, 0.955985s/100 iter), loss = 0.903608
I0506 04:35:10.769575 12834 solver.cpp:261]     Train net output #0: loss = 0.903608 (* 1 = 0.903608 loss)
I0506 04:35:10.769598 12834 sgd_solver.cpp:106] Iteration 36700, lr = 5.12e-05
I0506 04:35:11.754789 12834 solver.cpp:242] Iteration 36800 (100.954 iter/s, 0.990547s/100 iter), loss = 4.15331
I0506 04:35:11.754818 12834 solver.cpp:261]     Train net output #0: loss = 4.15331 (* 1 = 4.15331 loss)
I0506 04:35:11.754827 12834 sgd_solver.cpp:106] Iteration 36800, lr = 5.12e-05
I0506 04:35:11.759560 12834 solver.cpp:242] Iteration 36800 (101.014 iter/s, 0.989966s/100 iter), loss = 0.749534
I0506 04:35:11.759583 12834 solver.cpp:261]     Train net output #0: loss = 0.749534 (* 1 = 0.749534 loss)
I0506 04:35:11.759593 12834 sgd_solver.cpp:106] Iteration 36800, lr = 5.12e-05
I0506 04:35:12.692852 12834 solver.cpp:242] Iteration 36900 (106.609 iter/s, 0.938008s/100 iter), loss = 3.4043
I0506 04:35:12.692893 12834 solver.cpp:261]     Train net output #0: loss = 3.4043 (* 1 = 3.4043 loss)
I0506 04:35:12.692903 12834 sgd_solver.cpp:106] Iteration 36900, lr = 5.12e-05
I0506 04:35:12.697688 12834 solver.cpp:242] Iteration 36900 (106.601 iter/s, 0.938079s/100 iter), loss = 0.813813
I0506 04:35:12.697713 12834 solver.cpp:261]     Train net output #0: loss = 0.813813 (* 1 = 0.813813 loss)
I0506 04:35:12.697722 12834 sgd_solver.cpp:106] Iteration 36900, lr = 5.12e-05
I0506 04:35:13.628983 12834 solver.cpp:362] Iteration 37000, Testing net (#0)
I0506 04:35:13.629009 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:13.751863 12834 solver.cpp:429]     Test net output #0: loss = 2.1159 (* 1 = 2.1159 loss)
I0506 04:35:13.754389 12834 solver.cpp:242] Iteration 37000 (94.2084 iter/s, 1.06148s/100 iter), loss = 4.92518
I0506 04:35:13.754410 12834 solver.cpp:261]     Train net output #0: loss = 4.92518 (* 1 = 4.92518 loss)
I0506 04:35:13.754417 12834 sgd_solver.cpp:106] Iteration 37000, lr = 5.12e-05
I0506 04:35:13.756232 12834 solver.cpp:362] Iteration 37000, Testing net (#0)
I0506 04:35:13.756247 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:13.885176 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6785
I0506 04:35:13.885196 12834 solver.cpp:429]     Test net output #1: loss = 0.769514 (* 1 = 0.769514 loss)
I0506 04:35:13.887756 12834 solver.cpp:242] Iteration 37000 (84.0321 iter/s, 1.19002s/100 iter), loss = 0.92474
I0506 04:35:13.887778 12834 solver.cpp:261]     Train net output #0: loss = 0.92474 (* 1 = 0.92474 loss)
I0506 04:35:13.887786 12834 sgd_solver.cpp:106] Iteration 37000, lr = 5.12e-05
I0506 04:35:14.835314 12834 solver.cpp:242] Iteration 37100 (92.5182 iter/s, 1.08087s/100 iter), loss = 1.90428
I0506 04:35:14.835353 12834 solver.cpp:261]     Train net output #0: loss = 1.90428 (* 1 = 1.90428 loss)
I0506 04:35:14.835363 12834 sgd_solver.cpp:106] Iteration 37100, lr = 5.12e-05
I0506 04:35:14.840080 12834 solver.cpp:242] Iteration 37100 (105.011 iter/s, 0.952285s/100 iter), loss = 0.62172
I0506 04:35:14.840106 12834 solver.cpp:261]     Train net output #0: loss = 0.62172 (* 1 = 0.62172 loss)
I0506 04:35:14.840114 12834 sgd_solver.cpp:106] Iteration 37100, lr = 5.12e-05
I0506 04:35:15.773306 12834 solver.cpp:242] Iteration 37200 (106.618 iter/s, 0.937927s/100 iter), loss = 2.84007
I0506 04:35:15.773347 12834 solver.cpp:261]     Train net output #0: loss = 2.84007 (* 1 = 2.84007 loss)
I0506 04:35:15.773356 12834 sgd_solver.cpp:106] Iteration 37200, lr = 5.12e-05
I0506 04:35:15.778098 12834 solver.cpp:242] Iteration 37200 (106.613 iter/s, 0.937976s/100 iter), loss = 0.768728
I0506 04:35:15.778125 12834 solver.cpp:261]     Train net output #0: loss = 0.768728 (* 1 = 0.768728 loss)
I0506 04:35:15.778134 12834 sgd_solver.cpp:106] Iteration 37200, lr = 5.12e-05
I0506 04:35:16.712805 12834 solver.cpp:242] Iteration 37300 (106.448 iter/s, 0.939426s/100 iter), loss = 3.86274
I0506 04:35:16.712857 12834 solver.cpp:261]     Train net output #0: loss = 3.86274 (* 1 = 3.86274 loss)
I0506 04:35:16.712927 12834 sgd_solver.cpp:106] Iteration 37300, lr = 5.12e-05
I0506 04:35:16.717737 12834 solver.cpp:242] Iteration 37300 (106.429 iter/s, 0.939595s/100 iter), loss = 1.15275
I0506 04:35:16.717770 12834 solver.cpp:261]     Train net output #0: loss = 1.15275 (* 1 = 1.15275 loss)
I0506 04:35:16.717780 12834 sgd_solver.cpp:106] Iteration 37300, lr = 5.12e-05
I0506 04:35:17.651345 12834 solver.cpp:242] Iteration 37400 (106.557 iter/s, 0.938466s/100 iter), loss = 1.41351
I0506 04:35:17.651387 12834 solver.cpp:261]     Train net output #0: loss = 1.41351 (* 1 = 1.41351 loss)
I0506 04:35:17.651397 12834 sgd_solver.cpp:106] Iteration 37400, lr = 5.12e-05
I0506 04:35:17.656152 12834 solver.cpp:242] Iteration 37400 (106.568 iter/s, 0.938364s/100 iter), loss = 0.682324
I0506 04:35:17.656177 12834 solver.cpp:261]     Train net output #0: loss = 0.682324 (* 1 = 0.682324 loss)
I0506 04:35:17.656188 12834 sgd_solver.cpp:106] Iteration 37400, lr = 5.12e-05
I0506 04:35:18.586272 12834 solver.cpp:362] Iteration 37500, Testing net (#0)
I0506 04:35:18.586297 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:18.709142 12834 solver.cpp:429]     Test net output #0: loss = 2.01043 (* 1 = 2.01043 loss)
I0506 04:35:18.711666 12834 solver.cpp:242] Iteration 37500 (94.3164 iter/s, 1.06026s/100 iter), loss = 2.37741
I0506 04:35:18.711688 12834 solver.cpp:261]     Train net output #0: loss = 2.37741 (* 1 = 2.37741 loss)
I0506 04:35:18.711696 12834 sgd_solver.cpp:106] Iteration 37500, lr = 5.12e-05
I0506 04:35:18.713511 12834 solver.cpp:362] Iteration 37500, Testing net (#0)
I0506 04:35:18.713526 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:18.842617 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6765
I0506 04:35:18.842636 12834 solver.cpp:429]     Test net output #1: loss = 0.80408 (* 1 = 0.80408 loss)
I0506 04:35:18.845187 12834 solver.cpp:242] Iteration 37500 (84.1051 iter/s, 1.18899s/100 iter), loss = 0.648345
I0506 04:35:18.845208 12834 solver.cpp:261]     Train net output #0: loss = 0.648345 (* 1 = 0.648345 loss)
I0506 04:35:18.845217 12834 sgd_solver.cpp:106] Iteration 37500, lr = 5.12e-05
I0506 04:35:19.778542 12834 solver.cpp:242] Iteration 37600 (93.7361 iter/s, 1.06682s/100 iter), loss = 1.59144
I0506 04:35:19.778580 12834 solver.cpp:261]     Train net output #0: loss = 1.59144 (* 1 = 1.59144 loss)
I0506 04:35:19.778590 12834 sgd_solver.cpp:106] Iteration 37600, lr = 5.12e-05
I0506 04:35:19.783401 12834 solver.cpp:242] Iteration 37600 (106.591 iter/s, 0.938163s/100 iter), loss = 0.776982
I0506 04:35:19.783427 12834 solver.cpp:261]     Train net output #0: loss = 0.776982 (* 1 = 0.776982 loss)
I0506 04:35:19.783435 12834 sgd_solver.cpp:106] Iteration 37600, lr = 5.12e-05
I0506 04:35:20.716716 12834 solver.cpp:242] Iteration 37700 (106.598 iter/s, 0.938108s/100 iter), loss = 5.07774
I0506 04:35:20.716753 12834 solver.cpp:261]     Train net output #0: loss = 5.07774 (* 1 = 5.07774 loss)
I0506 04:35:20.716763 12834 sgd_solver.cpp:106] Iteration 37700, lr = 5.12e-05
I0506 04:35:20.721494 12834 solver.cpp:242] Iteration 37700 (106.604 iter/s, 0.93805s/100 iter), loss = 0.913833
I0506 04:35:20.721519 12834 solver.cpp:261]     Train net output #0: loss = 0.913833 (* 1 = 0.913833 loss)
I0506 04:35:20.721529 12834 sgd_solver.cpp:106] Iteration 37700, lr = 5.12e-05
I0506 04:35:21.654556 12834 solver.cpp:242] Iteration 37800 (106.635 iter/s, 0.937777s/100 iter), loss = 1.63115
I0506 04:35:21.654593 12834 solver.cpp:261]     Train net output #0: loss = 1.63115 (* 1 = 1.63115 loss)
I0506 04:35:21.654603 12834 sgd_solver.cpp:106] Iteration 37800, lr = 5.12e-05
I0506 04:35:21.659394 12834 solver.cpp:242] Iteration 37800 (106.627 iter/s, 0.937849s/100 iter), loss = 0.9228
I0506 04:35:21.659421 12834 solver.cpp:261]     Train net output #0: loss = 0.9228 (* 1 = 0.9228 loss)
I0506 04:35:21.659430 12834 sgd_solver.cpp:106] Iteration 37800, lr = 5.12e-05
I0506 04:35:22.593184 12834 solver.cpp:242] Iteration 37900 (106.546 iter/s, 0.938565s/100 iter), loss = 1.16097
I0506 04:35:22.593215 12834 solver.cpp:261]     Train net output #0: loss = 1.16097 (* 1 = 1.16097 loss)
I0506 04:35:22.593225 12834 sgd_solver.cpp:106] Iteration 37900, lr = 5.12e-05
I0506 04:35:22.597975 12834 solver.cpp:242] Iteration 37900 (106.549 iter/s, 0.938535s/100 iter), loss = 0.878361
I0506 04:35:22.597997 12834 solver.cpp:261]     Train net output #0: loss = 0.878361 (* 1 = 0.878361 loss)
I0506 04:35:22.598007 12834 sgd_solver.cpp:106] Iteration 37900, lr = 5.12e-05
I0506 04:35:23.533473 12834 solver.cpp:362] Iteration 38000, Testing net (#0)
I0506 04:35:23.533501 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:23.656432 12834 solver.cpp:429]     Test net output #0: loss = 2.19697 (* 1 = 2.19697 loss)
I0506 04:35:23.658975 12834 solver.cpp:242] Iteration 38000 (93.8315 iter/s, 1.06574s/100 iter), loss = 4.15534
I0506 04:35:23.658998 12834 solver.cpp:261]     Train net output #0: loss = 4.15534 (* 1 = 4.15534 loss)
I0506 04:35:23.659008 12834 sgd_solver.cpp:106] Iteration 38000, lr = 5.12e-05
I0506 04:35:23.660830 12834 solver.cpp:362] Iteration 38000, Testing net (#0)
I0506 04:35:23.660843 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:23.789654 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6715
I0506 04:35:23.789674 12834 solver.cpp:429]     Test net output #1: loss = 0.809432 (* 1 = 0.809432 loss)
I0506 04:35:23.792237 12834 solver.cpp:242] Iteration 38000 (83.7368 iter/s, 1.19422s/100 iter), loss = 0.82709
I0506 04:35:23.792258 12834 solver.cpp:261]     Train net output #0: loss = 0.82709 (* 1 = 0.82709 loss)
I0506 04:35:23.792266 12834 sgd_solver.cpp:106] Iteration 38000, lr = 5.12e-05
I0506 04:35:24.726302 12834 solver.cpp:242] Iteration 38100 (93.6965 iter/s, 1.06728s/100 iter), loss = 3.77694
I0506 04:35:24.726336 12834 solver.cpp:261]     Train net output #0: loss = 3.77694 (* 1 = 3.77694 loss)
I0506 04:35:24.726346 12834 sgd_solver.cpp:106] Iteration 38100, lr = 5.12e-05
I0506 04:35:24.731071 12834 solver.cpp:242] Iteration 38100 (106.52 iter/s, 0.938795s/100 iter), loss = 0.890481
I0506 04:35:24.731096 12834 solver.cpp:261]     Train net output #0: loss = 0.890481 (* 1 = 0.890481 loss)
I0506 04:35:24.731104 12834 sgd_solver.cpp:106] Iteration 38100, lr = 5.12e-05
I0506 04:35:25.664997 12834 solver.cpp:242] Iteration 38200 (106.538 iter/s, 0.938632s/100 iter), loss = 3.01123
I0506 04:35:25.665025 12834 solver.cpp:261]     Train net output #0: loss = 3.01123 (* 1 = 3.01123 loss)
I0506 04:35:25.665035 12834 sgd_solver.cpp:106] Iteration 38200, lr = 5.12e-05
I0506 04:35:25.669759 12834 solver.cpp:242] Iteration 38200 (106.536 iter/s, 0.938645s/100 iter), loss = 0.842366
I0506 04:35:25.669781 12834 solver.cpp:261]     Train net output #0: loss = 0.842366 (* 1 = 0.842366 loss)
I0506 04:35:25.669790 12834 sgd_solver.cpp:106] Iteration 38200, lr = 5.12e-05
I0506 04:35:26.606629 12834 solver.cpp:242] Iteration 38300 (106.205 iter/s, 0.941575s/100 iter), loss = 3.83503
I0506 04:35:26.606679 12834 solver.cpp:261]     Train net output #0: loss = 3.83503 (* 1 = 3.83503 loss)
I0506 04:35:26.606691 12834 sgd_solver.cpp:106] Iteration 38300, lr = 5.12e-05
I0506 04:35:26.611898 12834 solver.cpp:242] Iteration 38300 (106.146 iter/s, 0.942097s/100 iter), loss = 0.573639
I0506 04:35:26.611929 12834 solver.cpp:261]     Train net output #0: loss = 0.573639 (* 1 = 0.573639 loss)
I0506 04:35:26.611940 12834 sgd_solver.cpp:106] Iteration 38300, lr = 5.12e-05
I0506 04:35:27.555392 12834 solver.cpp:242] Iteration 38400 (105.409 iter/s, 0.948685s/100 iter), loss = 1.02292
I0506 04:35:27.555436 12834 solver.cpp:261]     Train net output #0: loss = 1.02292 (* 1 = 1.02292 loss)
I0506 04:35:27.555446 12834 sgd_solver.cpp:106] Iteration 38400, lr = 5.12e-05
I0506 04:35:27.560173 12834 solver.cpp:242] Iteration 38400 (105.46 iter/s, 0.948225s/100 iter), loss = 0.577111
I0506 04:35:27.560199 12834 solver.cpp:261]     Train net output #0: loss = 0.577111 (* 1 = 0.577111 loss)
I0506 04:35:27.560207 12834 sgd_solver.cpp:106] Iteration 38400, lr = 5.12e-05
I0506 04:35:28.491020 12834 solver.cpp:362] Iteration 38500, Testing net (#0)
I0506 04:35:28.491047 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:28.613965 12834 solver.cpp:429]     Test net output #0: loss = 2.12105 (* 1 = 2.12105 loss)
I0506 04:35:28.616503 12834 solver.cpp:242] Iteration 38500 (94.2466 iter/s, 1.06105s/100 iter), loss = 1.85321
I0506 04:35:28.616523 12834 solver.cpp:261]     Train net output #0: loss = 1.85321 (* 1 = 1.85321 loss)
I0506 04:35:28.616530 12834 sgd_solver.cpp:106] Iteration 38500, lr = 5.12e-05
I0506 04:35:28.618418 12834 solver.cpp:362] Iteration 38500, Testing net (#0)
I0506 04:35:28.618433 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:28.747499 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6895
I0506 04:35:28.747521 12834 solver.cpp:429]     Test net output #1: loss = 0.742174 (* 1 = 0.742174 loss)
I0506 04:35:28.750084 12834 solver.cpp:242] Iteration 38500 (84.0431 iter/s, 1.18987s/100 iter), loss = 0.795408
I0506 04:35:28.750105 12834 solver.cpp:261]     Train net output #0: loss = 0.795408 (* 1 = 0.795408 loss)
I0506 04:35:28.750113 12834 sgd_solver.cpp:106] Iteration 38500, lr = 5.12e-05
I0506 04:35:29.683109 12834 solver.cpp:242] Iteration 38600 (93.7599 iter/s, 1.06655s/100 iter), loss = 2.14832
I0506 04:35:29.683148 12834 solver.cpp:261]     Train net output #0: loss = 2.14832 (* 1 = 2.14832 loss)
I0506 04:35:29.683158 12834 sgd_solver.cpp:106] Iteration 38600, lr = 5.12e-05
I0506 04:35:29.687925 12834 solver.cpp:242] Iteration 38600 (106.632 iter/s, 0.937802s/100 iter), loss = 0.554333
I0506 04:35:29.687952 12834 solver.cpp:261]     Train net output #0: loss = 0.554333 (* 1 = 0.554333 loss)
I0506 04:35:29.687960 12834 sgd_solver.cpp:106] Iteration 38600, lr = 5.12e-05
I0506 04:35:30.625903 12834 solver.cpp:242] Iteration 38700 (106.075 iter/s, 0.94273s/100 iter), loss = 1.71688
I0506 04:35:30.625949 12834 solver.cpp:261]     Train net output #0: loss = 1.71688 (* 1 = 1.71688 loss)
I0506 04:35:30.625960 12834 sgd_solver.cpp:106] Iteration 38700, lr = 5.12e-05
I0506 04:35:30.631281 12834 solver.cpp:242] Iteration 38700 (106.011 iter/s, 0.943303s/100 iter), loss = 0.695693
I0506 04:35:30.631312 12834 solver.cpp:261]     Train net output #0: loss = 0.695693 (* 1 = 0.695693 loss)
I0506 04:35:30.631325 12834 sgd_solver.cpp:106] Iteration 38700, lr = 5.12e-05
I0506 04:35:31.572753 12834 solver.cpp:242] Iteration 38800 (105.621 iter/s, 0.946777s/100 iter), loss = 1.68035
I0506 04:35:31.572793 12834 solver.cpp:261]     Train net output #0: loss = 1.68035 (* 1 = 1.68035 loss)
I0506 04:35:31.572803 12834 sgd_solver.cpp:106] Iteration 38800, lr = 5.12e-05
I0506 04:35:31.577551 12834 solver.cpp:242] Iteration 38800 (105.684 iter/s, 0.946221s/100 iter), loss = 1.17062
I0506 04:35:31.577575 12834 solver.cpp:261]     Train net output #0: loss = 1.17062 (* 1 = 1.17062 loss)
I0506 04:35:31.577584 12834 sgd_solver.cpp:106] Iteration 38800, lr = 5.12e-05
I0506 04:35:32.511279 12834 solver.cpp:242] Iteration 38900 (106.558 iter/s, 0.938455s/100 iter), loss = 1.76995
I0506 04:35:32.511319 12834 solver.cpp:261]     Train net output #0: loss = 1.76995 (* 1 = 1.76995 loss)
I0506 04:35:32.511328 12834 sgd_solver.cpp:106] Iteration 38900, lr = 5.12e-05
I0506 04:35:32.516060 12834 solver.cpp:242] Iteration 38900 (106.557 iter/s, 0.938466s/100 iter), loss = 0.925676
I0506 04:35:32.516084 12834 solver.cpp:261]     Train net output #0: loss = 0.925676 (* 1 = 0.925676 loss)
I0506 04:35:32.516093 12834 sgd_solver.cpp:106] Iteration 38900, lr = 5.12e-05
I0506 04:35:33.446537 12834 solver.cpp:362] Iteration 39000, Testing net (#0)
I0506 04:35:33.446559 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:33.569439 12834 solver.cpp:429]     Test net output #0: loss = 2.2449 (* 1 = 2.2449 loss)
I0506 04:35:33.571965 12834 solver.cpp:242] Iteration 39000 (94.2838 iter/s, 1.06063s/100 iter), loss = 2.87471
I0506 04:35:33.571985 12834 solver.cpp:261]     Train net output #0: loss = 2.87471 (* 1 = 2.87471 loss)
I0506 04:35:33.571993 12834 sgd_solver.cpp:106] Iteration 39000, lr = 5.12e-05
I0506 04:35:33.573848 12834 solver.cpp:362] Iteration 39000, Testing net (#0)
I0506 04:35:33.573863 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:33.702744 12834 solver.cpp:429]     Test net output #0: accuracy = 0.658
I0506 04:35:33.702776 12834 solver.cpp:429]     Test net output #1: loss = 0.781752 (* 1 = 0.781752 loss)
I0506 04:35:33.705332 12834 solver.cpp:242] Iteration 39000 (84.0882 iter/s, 1.18923s/100 iter), loss = 0.700503
I0506 04:35:33.705353 12834 solver.cpp:261]     Train net output #0: loss = 0.700503 (* 1 = 0.700503 loss)
I0506 04:35:33.705361 12834 sgd_solver.cpp:106] Iteration 39000, lr = 5.12e-05
I0506 04:35:34.638695 12834 solver.cpp:242] Iteration 39100 (93.7491 iter/s, 1.06668s/100 iter), loss = 1.74243
I0506 04:35:34.638731 12834 solver.cpp:261]     Train net output #0: loss = 1.74243 (* 1 = 1.74243 loss)
I0506 04:35:34.638741 12834 sgd_solver.cpp:106] Iteration 39100, lr = 5.12e-05
I0506 04:35:34.643489 12834 solver.cpp:242] Iteration 39100 (106.596 iter/s, 0.938118s/100 iter), loss = 0.903406
I0506 04:35:34.643514 12834 solver.cpp:261]     Train net output #0: loss = 0.903406 (* 1 = 0.903406 loss)
I0506 04:35:34.643523 12834 sgd_solver.cpp:106] Iteration 39100, lr = 5.12e-05
I0506 04:35:35.577213 12834 solver.cpp:242] Iteration 39200 (106.558 iter/s, 0.938458s/100 iter), loss = 2.50199
I0506 04:35:35.577249 12834 solver.cpp:261]     Train net output #0: loss = 2.50199 (* 1 = 2.50199 loss)
I0506 04:35:35.577258 12834 sgd_solver.cpp:106] Iteration 39200, lr = 5.12e-05
I0506 04:35:35.582008 12834 solver.cpp:242] Iteration 39200 (106.556 iter/s, 0.938474s/100 iter), loss = 0.996241
I0506 04:35:35.582034 12834 solver.cpp:261]     Train net output #0: loss = 0.996241 (* 1 = 0.996241 loss)
I0506 04:35:35.582043 12834 sgd_solver.cpp:106] Iteration 39200, lr = 5.12e-05
I0506 04:35:36.516175 12834 solver.cpp:242] Iteration 39300 (106.508 iter/s, 0.938899s/100 iter), loss = 0.836365
I0506 04:35:36.516207 12834 solver.cpp:261]     Train net output #0: loss = 0.836365 (* 1 = 0.836365 loss)
I0506 04:35:36.516217 12834 sgd_solver.cpp:106] Iteration 39300, lr = 5.12e-05
I0506 04:35:36.520954 12834 solver.cpp:242] Iteration 39300 (106.507 iter/s, 0.938901s/100 iter), loss = 1.27609
I0506 04:35:36.520978 12834 solver.cpp:261]     Train net output #0: loss = 1.27609 (* 1 = 1.27609 loss)
I0506 04:35:36.520987 12834 sgd_solver.cpp:106] Iteration 39300, lr = 5.12e-05
I0506 04:35:37.455559 12834 solver.cpp:242] Iteration 39400 (106.459 iter/s, 0.939326s/100 iter), loss = 2.60253
I0506 04:35:37.455586 12834 solver.cpp:261]     Train net output #0: loss = 2.60253 (* 1 = 2.60253 loss)
I0506 04:35:37.455596 12834 sgd_solver.cpp:106] Iteration 39400, lr = 5.12e-05
I0506 04:35:37.460409 12834 solver.cpp:242] Iteration 39400 (106.451 iter/s, 0.939403s/100 iter), loss = 0.74208
I0506 04:35:37.460433 12834 solver.cpp:261]     Train net output #0: loss = 0.74208 (* 1 = 0.74208 loss)
I0506 04:35:37.460443 12834 sgd_solver.cpp:106] Iteration 39400, lr = 5.12e-05
I0506 04:35:38.391494 12834 solver.cpp:362] Iteration 39500, Testing net (#0)
I0506 04:35:38.391523 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:38.514415 12834 solver.cpp:429]     Test net output #0: loss = 2.12037 (* 1 = 2.12037 loss)
I0506 04:35:38.516934 12834 solver.cpp:242] Iteration 39500 (94.2215 iter/s, 1.06133s/100 iter), loss = 1.29106
I0506 04:35:38.516954 12834 solver.cpp:261]     Train net output #0: loss = 1.29106 (* 1 = 1.29106 loss)
I0506 04:35:38.516963 12834 sgd_solver.cpp:106] Iteration 39500, lr = 5.12e-05
I0506 04:35:38.518777 12834 solver.cpp:362] Iteration 39500, Testing net (#0)
I0506 04:35:38.518790 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:38.647683 12834 solver.cpp:429]     Test net output #0: accuracy = 0.686
I0506 04:35:38.647701 12834 solver.cpp:429]     Test net output #1: loss = 0.735653 (* 1 = 0.735653 loss)
I0506 04:35:38.650269 12834 solver.cpp:242] Iteration 39500 (84.0467 iter/s, 1.18982s/100 iter), loss = 1.04845
I0506 04:35:38.650288 12834 solver.cpp:261]     Train net output #0: loss = 1.04845 (* 1 = 1.04845 loss)
I0506 04:35:38.650297 12834 sgd_solver.cpp:106] Iteration 39500, lr = 5.12e-05
I0506 04:35:39.584197 12834 solver.cpp:242] Iteration 39600 (93.7019 iter/s, 1.06721s/100 iter), loss = 0.993666
I0506 04:35:39.584247 12834 solver.cpp:261]     Train net output #0: loss = 0.993666 (* 1 = 0.993666 loss)
I0506 04:35:39.584257 12834 sgd_solver.cpp:106] Iteration 39600, lr = 5.12e-05
I0506 04:35:39.589089 12834 solver.cpp:242] Iteration 39600 (106.522 iter/s, 0.938773s/100 iter), loss = 0.589978
I0506 04:35:39.589117 12834 solver.cpp:261]     Train net output #0: loss = 0.589978 (* 1 = 0.589978 loss)
I0506 04:35:39.589125 12834 sgd_solver.cpp:106] Iteration 39600, lr = 5.12e-05
I0506 04:35:40.522425 12834 solver.cpp:242] Iteration 39700 (106.593 iter/s, 0.938152s/100 iter), loss = 3.17568
I0506 04:35:40.522464 12834 solver.cpp:261]     Train net output #0: loss = 3.17568 (* 1 = 3.17568 loss)
I0506 04:35:40.522474 12834 sgd_solver.cpp:106] Iteration 39700, lr = 5.12e-05
I0506 04:35:40.527205 12834 solver.cpp:242] Iteration 39700 (106.602 iter/s, 0.938071s/100 iter), loss = 0.944945
I0506 04:35:40.527230 12834 solver.cpp:261]     Train net output #0: loss = 0.944945 (* 1 = 0.944945 loss)
I0506 04:35:40.527240 12834 sgd_solver.cpp:106] Iteration 39700, lr = 5.12e-05
I0506 04:35:41.461133 12834 solver.cpp:242] Iteration 39800 (106.537 iter/s, 0.938637s/100 iter), loss = 1.33235
I0506 04:35:41.461172 12834 solver.cpp:261]     Train net output #0: loss = 1.33235 (* 1 = 1.33235 loss)
I0506 04:35:41.461182 12834 sgd_solver.cpp:106] Iteration 39800, lr = 5.12e-05
I0506 04:35:41.465940 12834 solver.cpp:242] Iteration 39800 (106.531 iter/s, 0.938691s/100 iter), loss = 0.609362
I0506 04:35:41.465967 12834 solver.cpp:261]     Train net output #0: loss = 0.609362 (* 1 = 0.609362 loss)
I0506 04:35:41.465977 12834 sgd_solver.cpp:106] Iteration 39800, lr = 5.12e-05
I0506 04:35:42.409802 12834 solver.cpp:242] Iteration 39900 (105.418 iter/s, 0.948603s/100 iter), loss = 3.15799
I0506 04:35:42.409843 12834 solver.cpp:261]     Train net output #0: loss = 3.15799 (* 1 = 3.15799 loss)
I0506 04:35:42.409852 12834 sgd_solver.cpp:106] Iteration 39900, lr = 5.12e-05
I0506 04:35:42.414587 12834 solver.cpp:242] Iteration 39900 (105.419 iter/s, 0.9486s/100 iter), loss = 0.620801
I0506 04:35:42.414610 12834 solver.cpp:261]     Train net output #0: loss = 0.620801 (* 1 = 0.620801 loss)
I0506 04:35:42.414619 12834 sgd_solver.cpp:106] Iteration 39900, lr = 5.12e-05
I0506 04:35:43.425158 12834 solver.cpp:362] Iteration 40000, Testing net (#0)
I0506 04:35:43.425191 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:43.548247 12834 solver.cpp:429]     Test net output #0: loss = 2.36494 (* 1 = 2.36494 loss)
I0506 04:35:43.550771 12834 solver.cpp:242] Iteration 40000 (87.6494 iter/s, 1.14091s/100 iter), loss = 1.87639
I0506 04:35:43.550792 12834 solver.cpp:261]     Train net output #0: loss = 1.87639 (* 1 = 1.87639 loss)
I0506 04:35:43.550801 12834 sgd_solver.cpp:106] Iteration 40000, lr = 4.096e-05
I0506 04:35:43.552641 12834 solver.cpp:362] Iteration 40000, Testing net (#0)
I0506 04:35:43.552656 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:43.681989 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6785
I0506 04:35:43.682009 12834 solver.cpp:429]     Test net output #1: loss = 0.782132 (* 1 = 0.782132 loss)
I0506 04:35:43.684573 12834 solver.cpp:242] Iteration 40000 (78.7439 iter/s, 1.26994s/100 iter), loss = 0.794028
I0506 04:35:43.684595 12834 solver.cpp:261]     Train net output #0: loss = 0.794028 (* 1 = 0.794028 loss)
I0506 04:35:43.684604 12834 sgd_solver.cpp:106] Iteration 40000, lr = 4.096e-05
I0506 04:35:44.617609 12834 solver.cpp:242] Iteration 40100 (93.7393 iter/s, 1.06679s/100 iter), loss = 3.05433
I0506 04:35:44.617646 12834 solver.cpp:261]     Train net output #0: loss = 3.05433 (* 1 = 3.05433 loss)
I0506 04:35:44.617655 12834 sgd_solver.cpp:106] Iteration 40100, lr = 4.096e-05
I0506 04:35:44.622395 12834 solver.cpp:242] Iteration 40100 (106.635 iter/s, 0.937781s/100 iter), loss = 0.688272
I0506 04:35:44.622421 12834 solver.cpp:261]     Train net output #0: loss = 0.688272 (* 1 = 0.688272 loss)
I0506 04:35:44.622429 12834 sgd_solver.cpp:106] Iteration 40100, lr = 4.096e-05
I0506 04:35:45.555295 12834 solver.cpp:242] Iteration 40200 (106.653 iter/s, 0.937619s/100 iter), loss = 1.47614
I0506 04:35:45.555333 12834 solver.cpp:261]     Train net output #0: loss = 1.47614 (* 1 = 1.47614 loss)
I0506 04:35:45.555342 12834 sgd_solver.cpp:106] Iteration 40200, lr = 4.096e-05
I0506 04:35:45.560101 12834 solver.cpp:242] Iteration 40200 (106.648 iter/s, 0.937661s/100 iter), loss = 0.887879
I0506 04:35:45.560125 12834 solver.cpp:261]     Train net output #0: loss = 0.887879 (* 1 = 0.887879 loss)
I0506 04:35:45.560134 12834 sgd_solver.cpp:106] Iteration 40200, lr = 4.096e-05
I0506 04:35:46.493988 12834 solver.cpp:242] Iteration 40300 (106.538 iter/s, 0.938628s/100 iter), loss = 3.95056
I0506 04:35:46.494024 12834 solver.cpp:261]     Train net output #0: loss = 3.95056 (* 1 = 3.95056 loss)
I0506 04:35:46.494035 12834 sgd_solver.cpp:106] Iteration 40300, lr = 4.096e-05
I0506 04:35:46.498752 12834 solver.cpp:242] Iteration 40300 (106.541 iter/s, 0.938609s/100 iter), loss = 1.00516
I0506 04:35:46.498777 12834 solver.cpp:261]     Train net output #0: loss = 1.00516 (* 1 = 1.00516 loss)
I0506 04:35:46.498785 12834 sgd_solver.cpp:106] Iteration 40300, lr = 4.096e-05
I0506 04:35:47.520680 12834 solver.cpp:242] Iteration 40400 (97.4067 iter/s, 1.02662s/100 iter), loss = 0.831937
I0506 04:35:47.520725 12834 solver.cpp:261]     Train net output #0: loss = 0.831937 (* 1 = 0.831937 loss)
I0506 04:35:47.520736 12834 sgd_solver.cpp:106] Iteration 40400, lr = 4.096e-05
I0506 04:35:47.525962 12834 solver.cpp:242] Iteration 40400 (97.3555 iter/s, 1.02716s/100 iter), loss = 0.704008
I0506 04:35:47.525992 12834 solver.cpp:261]     Train net output #0: loss = 0.704008 (* 1 = 0.704008 loss)
I0506 04:35:47.526003 12834 sgd_solver.cpp:106] Iteration 40400, lr = 4.096e-05
I0506 04:35:48.553537 12834 solver.cpp:362] Iteration 40500, Testing net (#0)
I0506 04:35:48.553571 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:48.676643 12834 solver.cpp:429]     Test net output #0: loss = 2.29945 (* 1 = 2.29945 loss)
I0506 04:35:48.679173 12834 solver.cpp:242] Iteration 40500 (86.3238 iter/s, 1.15843s/100 iter), loss = 0.76179
I0506 04:35:48.679193 12834 solver.cpp:261]     Train net output #0: loss = 0.76179 (* 1 = 0.76179 loss)
I0506 04:35:48.679203 12834 sgd_solver.cpp:106] Iteration 40500, lr = 4.096e-05
I0506 04:35:48.681110 12834 solver.cpp:362] Iteration 40500, Testing net (#0)
I0506 04:35:48.681125 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:48.810086 12834 solver.cpp:429]     Test net output #0: accuracy = 0.674
I0506 04:35:48.810104 12834 solver.cpp:429]     Test net output #1: loss = 0.773875 (* 1 = 0.773875 loss)
I0506 04:35:48.812665 12834 solver.cpp:242] Iteration 40500 (77.7212 iter/s, 1.28665s/100 iter), loss = 0.628671
I0506 04:35:48.812685 12834 solver.cpp:261]     Train net output #0: loss = 0.628671 (* 1 = 0.628671 loss)
I0506 04:35:48.812695 12834 sgd_solver.cpp:106] Iteration 40500, lr = 4.096e-05
I0506 04:35:49.746543 12834 solver.cpp:242] Iteration 40600 (93.6926 iter/s, 1.06732s/100 iter), loss = 2.95857
I0506 04:35:49.746578 12834 solver.cpp:261]     Train net output #0: loss = 2.95857 (* 1 = 2.95857 loss)
I0506 04:35:49.746588 12834 sgd_solver.cpp:106] Iteration 40600, lr = 4.096e-05
I0506 04:35:49.751322 12834 solver.cpp:242] Iteration 40600 (106.54 iter/s, 0.938619s/100 iter), loss = 1.25708
I0506 04:35:49.751348 12834 solver.cpp:261]     Train net output #0: loss = 1.25708 (* 1 = 1.25708 loss)
I0506 04:35:49.751356 12834 sgd_solver.cpp:106] Iteration 40600, lr = 4.096e-05
I0506 04:35:50.696640 12834 solver.cpp:242] Iteration 40700 (105.26 iter/s, 0.950028s/100 iter), loss = 1.99706
I0506 04:35:50.696684 12834 solver.cpp:261]     Train net output #0: loss = 1.99706 (* 1 = 1.99706 loss)
I0506 04:35:50.696696 12834 sgd_solver.cpp:106] Iteration 40700, lr = 4.096e-05
I0506 04:35:50.701918 12834 solver.cpp:242] Iteration 40700 (105.202 iter/s, 0.950551s/100 iter), loss = 0.98448
I0506 04:35:50.701947 12834 solver.cpp:261]     Train net output #0: loss = 0.98448 (* 1 = 0.98448 loss)
I0506 04:35:50.701968 12834 sgd_solver.cpp:106] Iteration 40700, lr = 4.096e-05
I0506 04:35:51.637015 12834 solver.cpp:242] Iteration 40800 (106.348 iter/s, 0.940307s/100 iter), loss = 1.98485
I0506 04:35:51.637049 12834 solver.cpp:261]     Train net output #0: loss = 1.98485 (* 1 = 1.98485 loss)
I0506 04:35:51.637059 12834 sgd_solver.cpp:106] Iteration 40800, lr = 4.096e-05
I0506 04:35:51.641775 12834 solver.cpp:242] Iteration 40800 (106.404 iter/s, 0.939811s/100 iter), loss = 1.23659
I0506 04:35:51.641800 12834 solver.cpp:261]     Train net output #0: loss = 1.23659 (* 1 = 1.23659 loss)
I0506 04:35:51.641808 12834 sgd_solver.cpp:106] Iteration 40800, lr = 4.096e-05
I0506 04:35:52.575012 12834 solver.cpp:242] Iteration 40900 (106.617 iter/s, 0.937933s/100 iter), loss = 1.63975
I0506 04:35:52.575042 12834 solver.cpp:261]     Train net output #0: loss = 1.63975 (* 1 = 1.63975 loss)
I0506 04:35:52.575052 12834 sgd_solver.cpp:106] Iteration 40900, lr = 4.096e-05
I0506 04:35:52.579793 12834 solver.cpp:242] Iteration 40900 (106.613 iter/s, 0.937975s/100 iter), loss = 0.773192
I0506 04:35:52.579816 12834 solver.cpp:261]     Train net output #0: loss = 0.773192 (* 1 = 0.773192 loss)
I0506 04:35:52.579825 12834 sgd_solver.cpp:106] Iteration 40900, lr = 4.096e-05
I0506 04:35:53.510493 12834 solver.cpp:362] Iteration 41000, Testing net (#0)
I0506 04:35:53.510519 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:53.634371 12834 solver.cpp:429]     Test net output #0: loss = 1.80236 (* 1 = 1.80236 loss)
I0506 04:35:53.636899 12834 solver.cpp:242] Iteration 41000 (94.1763 iter/s, 1.06184s/100 iter), loss = 1.41134
I0506 04:35:53.636922 12834 solver.cpp:261]     Train net output #0: loss = 1.41134 (* 1 = 1.41134 loss)
I0506 04:35:53.636931 12834 sgd_solver.cpp:106] Iteration 41000, lr = 4.096e-05
I0506 04:35:53.638744 12834 solver.cpp:362] Iteration 41000, Testing net (#0)
I0506 04:35:53.638757 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:53.767684 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6985
I0506 04:35:53.767704 12834 solver.cpp:429]     Test net output #1: loss = 0.711713 (* 1 = 0.711713 loss)
I0506 04:35:53.770267 12834 solver.cpp:242] Iteration 41000 (84.0032 iter/s, 1.19043s/100 iter), loss = 0.583887
I0506 04:35:53.770289 12834 solver.cpp:261]     Train net output #0: loss = 0.583887 (* 1 = 0.583887 loss)
I0506 04:35:53.770298 12834 sgd_solver.cpp:106] Iteration 41000, lr = 4.096e-05
I0506 04:35:54.704144 12834 solver.cpp:242] Iteration 41100 (93.7039 iter/s, 1.06719s/100 iter), loss = 1.01756
I0506 04:35:54.704180 12834 solver.cpp:261]     Train net output #0: loss = 1.01756 (* 1 = 1.01756 loss)
I0506 04:35:54.704188 12834 sgd_solver.cpp:106] Iteration 41100, lr = 4.096e-05
I0506 04:35:54.708927 12834 solver.cpp:242] Iteration 41100 (106.54 iter/s, 0.938619s/100 iter), loss = 0.563504
I0506 04:35:54.708951 12834 solver.cpp:261]     Train net output #0: loss = 0.563504 (* 1 = 0.563504 loss)
I0506 04:35:54.708961 12834 sgd_solver.cpp:106] Iteration 41100, lr = 4.096e-05
I0506 04:35:55.649624 12834 solver.cpp:242] Iteration 41200 (105.773 iter/s, 0.945418s/100 iter), loss = 1.04003
I0506 04:35:55.649674 12834 solver.cpp:261]     Train net output #0: loss = 1.04003 (* 1 = 1.04003 loss)
I0506 04:35:55.649686 12834 sgd_solver.cpp:106] Iteration 41200, lr = 4.096e-05
I0506 04:35:55.654902 12834 solver.cpp:242] Iteration 41200 (105.716 iter/s, 0.945931s/100 iter), loss = 0.672156
I0506 04:35:55.654933 12834 solver.cpp:261]     Train net output #0: loss = 0.672156 (* 1 = 0.672156 loss)
I0506 04:35:55.654944 12834 sgd_solver.cpp:106] Iteration 41200, lr = 4.096e-05
I0506 04:35:56.685261 12834 solver.cpp:242] Iteration 41300 (96.5666 iter/s, 1.03555s/100 iter), loss = 2.04146
I0506 04:35:56.685305 12834 solver.cpp:261]     Train net output #0: loss = 2.04146 (* 1 = 2.04146 loss)
I0506 04:35:56.685317 12834 sgd_solver.cpp:106] Iteration 41300, lr = 4.096e-05
I0506 04:35:56.690547 12834 solver.cpp:242] Iteration 41300 (96.5629 iter/s, 1.03559s/100 iter), loss = 0.79945
I0506 04:35:56.690588 12834 solver.cpp:261]     Train net output #0: loss = 0.79945 (* 1 = 0.79945 loss)
I0506 04:35:56.690599 12834 sgd_solver.cpp:106] Iteration 41300, lr = 4.096e-05
I0506 04:35:57.627532 12834 solver.cpp:242] Iteration 41400 (106.134 iter/s, 0.942205s/100 iter), loss = 2.99631
I0506 04:35:57.627571 12834 solver.cpp:261]     Train net output #0: loss = 2.99631 (* 1 = 2.99631 loss)
I0506 04:35:57.627581 12834 sgd_solver.cpp:106] Iteration 41400, lr = 4.096e-05
I0506 04:35:57.632393 12834 solver.cpp:242] Iteration 41400 (106.182 iter/s, 0.941779s/100 iter), loss = 0.859246
I0506 04:35:57.632418 12834 solver.cpp:261]     Train net output #0: loss = 0.859246 (* 1 = 0.859246 loss)
I0506 04:35:57.632427 12834 sgd_solver.cpp:106] Iteration 41400, lr = 4.096e-05
I0506 04:35:58.563267 12834 solver.cpp:362] Iteration 41500, Testing net (#0)
I0506 04:35:58.563294 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:58.686255 12834 solver.cpp:429]     Test net output #0: loss = 2.42796 (* 1 = 2.42796 loss)
I0506 04:35:58.688827 12834 solver.cpp:242] Iteration 41500 (94.2299 iter/s, 1.06123s/100 iter), loss = 3.40358
I0506 04:35:58.688853 12834 solver.cpp:261]     Train net output #0: loss = 3.40358 (* 1 = 3.40358 loss)
I0506 04:35:58.688863 12834 sgd_solver.cpp:106] Iteration 41500, lr = 4.096e-05
I0506 04:35:58.690675 12834 solver.cpp:362] Iteration 41500, Testing net (#0)
I0506 04:35:58.690686 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:35:58.819970 12834 solver.cpp:429]     Test net output #0: accuracy = 0.631
I0506 04:35:58.819990 12834 solver.cpp:429]     Test net output #1: loss = 0.92735 (* 1 = 0.92735 loss)
I0506 04:35:58.822543 12834 solver.cpp:242] Iteration 41500 (84.0263 iter/s, 1.1901s/100 iter), loss = 1.15682
I0506 04:35:58.822566 12834 solver.cpp:261]     Train net output #0: loss = 1.15682 (* 1 = 1.15682 loss)
I0506 04:35:58.822574 12834 sgd_solver.cpp:106] Iteration 41500, lr = 4.096e-05
I0506 04:35:59.756278 12834 solver.cpp:242] Iteration 41600 (93.6865 iter/s, 1.06739s/100 iter), loss = 1.69253
I0506 04:35:59.756317 12834 solver.cpp:261]     Train net output #0: loss = 1.69253 (* 1 = 1.69253 loss)
I0506 04:35:59.756327 12834 sgd_solver.cpp:106] Iteration 41600, lr = 4.096e-05
I0506 04:35:59.761066 12834 solver.cpp:242] Iteration 41600 (106.555 iter/s, 0.938483s/100 iter), loss = 0.295651
I0506 04:35:59.761092 12834 solver.cpp:261]     Train net output #0: loss = 0.295651 (* 1 = 0.295651 loss)
I0506 04:35:59.761101 12834 sgd_solver.cpp:106] Iteration 41600, lr = 4.096e-05
I0506 04:36:00.699437 12834 solver.cpp:242] Iteration 41700 (106.034 iter/s, 0.943092s/100 iter), loss = 1.05022
I0506 04:36:00.699483 12834 solver.cpp:261]     Train net output #0: loss = 1.05022 (* 1 = 1.05022 loss)
I0506 04:36:00.699493 12834 sgd_solver.cpp:106] Iteration 41700, lr = 4.096e-05
I0506 04:36:00.704222 12834 solver.cpp:242] Iteration 41700 (106.032 iter/s, 0.943111s/100 iter), loss = 0.623891
I0506 04:36:00.704248 12834 solver.cpp:261]     Train net output #0: loss = 0.623891 (* 1 = 0.623891 loss)
I0506 04:36:00.704257 12834 sgd_solver.cpp:106] Iteration 41700, lr = 4.096e-05
I0506 04:36:01.637970 12834 solver.cpp:242] Iteration 41800 (106.558 iter/s, 0.938458s/100 iter), loss = 1.3137
I0506 04:36:01.638008 12834 solver.cpp:261]     Train net output #0: loss = 1.3137 (* 1 = 1.3137 loss)
I0506 04:36:01.638018 12834 sgd_solver.cpp:106] Iteration 41800, lr = 4.096e-05
I0506 04:36:01.642761 12834 solver.cpp:242] Iteration 41800 (106.554 iter/s, 0.938495s/100 iter), loss = 0.4862
I0506 04:36:01.642786 12834 solver.cpp:261]     Train net output #0: loss = 0.4862 (* 1 = 0.4862 loss)
I0506 04:36:01.642796 12834 sgd_solver.cpp:106] Iteration 41800, lr = 4.096e-05
I0506 04:36:02.577136 12834 solver.cpp:242] Iteration 41900 (106.485 iter/s, 0.9391s/100 iter), loss = 2.02549
I0506 04:36:02.577179 12834 solver.cpp:261]     Train net output #0: loss = 2.02549 (* 1 = 2.02549 loss)
I0506 04:36:02.577191 12834 sgd_solver.cpp:106] Iteration 41900, lr = 4.096e-05
I0506 04:36:02.582443 12834 solver.cpp:242] Iteration 41900 (106.424 iter/s, 0.939638s/100 iter), loss = 0.737169
I0506 04:36:02.582482 12834 solver.cpp:261]     Train net output #0: loss = 0.737169 (* 1 = 0.737169 loss)
I0506 04:36:02.582494 12834 sgd_solver.cpp:106] Iteration 41900, lr = 4.096e-05
I0506 04:36:03.526511 12834 solver.cpp:362] Iteration 42000, Testing net (#0)
I0506 04:36:03.526533 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:03.649360 12834 solver.cpp:429]     Test net output #0: loss = 2.45877 (* 1 = 2.45877 loss)
I0506 04:36:03.651882 12834 solver.cpp:242] Iteration 42000 (93.0505 iter/s, 1.07469s/100 iter), loss = 1.27878
I0506 04:36:03.651901 12834 solver.cpp:261]     Train net output #0: loss = 1.27878 (* 1 = 1.27878 loss)
I0506 04:36:03.651911 12834 sgd_solver.cpp:106] Iteration 42000, lr = 4.096e-05
I0506 04:36:03.653758 12834 solver.cpp:362] Iteration 42000, Testing net (#0)
I0506 04:36:03.653772 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:03.782569 12834 solver.cpp:429]     Test net output #0: accuracy = 0.656
I0506 04:36:03.782593 12834 solver.cpp:429]     Test net output #1: loss = 0.815751 (* 1 = 0.815751 loss)
I0506 04:36:03.785274 12834 solver.cpp:242] Iteration 42000 (83.1413 iter/s, 1.20277s/100 iter), loss = 0.7277
I0506 04:36:03.785295 12834 solver.cpp:261]     Train net output #0: loss = 0.7277 (* 1 = 0.7277 loss)
I0506 04:36:03.785305 12834 sgd_solver.cpp:106] Iteration 42000, lr = 4.096e-05
I0506 04:36:04.719203 12834 solver.cpp:242] Iteration 42100 (93.6966 iter/s, 1.06727s/100 iter), loss = 2.72615
I0506 04:36:04.719241 12834 solver.cpp:261]     Train net output #0: loss = 2.72615 (* 1 = 2.72615 loss)
I0506 04:36:04.719250 12834 sgd_solver.cpp:106] Iteration 42100, lr = 4.096e-05
I0506 04:36:04.724011 12834 solver.cpp:242] Iteration 42100 (106.531 iter/s, 0.938698s/100 iter), loss = 0.880745
I0506 04:36:04.724038 12834 solver.cpp:261]     Train net output #0: loss = 0.880745 (* 1 = 0.880745 loss)
I0506 04:36:04.724047 12834 sgd_solver.cpp:106] Iteration 42100, lr = 4.096e-05
I0506 04:36:05.657996 12834 solver.cpp:242] Iteration 42200 (106.527 iter/s, 0.938727s/100 iter), loss = 2.46017
I0506 04:36:05.658027 12834 solver.cpp:261]     Train net output #0: loss = 2.46017 (* 1 = 2.46017 loss)
I0506 04:36:05.658036 12834 sgd_solver.cpp:106] Iteration 42200, lr = 4.096e-05
I0506 04:36:05.662781 12834 solver.cpp:242] Iteration 42200 (106.528 iter/s, 0.938723s/100 iter), loss = 0.734022
I0506 04:36:05.662804 12834 solver.cpp:261]     Train net output #0: loss = 0.734022 (* 1 = 0.734022 loss)
I0506 04:36:05.662813 12834 sgd_solver.cpp:106] Iteration 42200, lr = 4.096e-05
I0506 04:36:06.597782 12834 solver.cpp:242] Iteration 42300 (106.414 iter/s, 0.93973s/100 iter), loss = 2.3274
I0506 04:36:06.597832 12834 solver.cpp:261]     Train net output #0: loss = 2.3274 (* 1 = 2.3274 loss)
I0506 04:36:06.597844 12834 sgd_solver.cpp:106] Iteration 42300, lr = 4.096e-05
I0506 04:36:06.603162 12834 solver.cpp:242] Iteration 42300 (106.346 iter/s, 0.940326s/100 iter), loss = 0.761506
I0506 04:36:06.603193 12834 solver.cpp:261]     Train net output #0: loss = 0.761506 (* 1 = 0.761506 loss)
I0506 04:36:06.603204 12834 sgd_solver.cpp:106] Iteration 42300, lr = 4.096e-05
I0506 04:36:07.633918 12834 solver.cpp:242] Iteration 42400 (96.52 iter/s, 1.03605s/100 iter), loss = 3.74346
I0506 04:36:07.633965 12834 solver.cpp:261]     Train net output #0: loss = 3.74346 (* 1 = 3.74346 loss)
I0506 04:36:07.633976 12834 sgd_solver.cpp:106] Iteration 42400, lr = 4.096e-05
I0506 04:36:07.639202 12834 solver.cpp:242] Iteration 42400 (96.5259 iter/s, 1.03599s/100 iter), loss = 0.996476
I0506 04:36:07.639231 12834 solver.cpp:261]     Train net output #0: loss = 0.996476 (* 1 = 0.996476 loss)
I0506 04:36:07.639242 12834 sgd_solver.cpp:106] Iteration 42400, lr = 4.096e-05
I0506 04:36:08.667968 12834 solver.cpp:362] Iteration 42500, Testing net (#0)
I0506 04:36:08.668001 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:08.795053 12834 solver.cpp:429]     Test net output #0: loss = 1.8769 (* 1 = 1.8769 loss)
I0506 04:36:08.797703 12834 solver.cpp:242] Iteration 42500 (85.9314 iter/s, 1.16372s/100 iter), loss = 1.23739
I0506 04:36:08.797724 12834 solver.cpp:261]     Train net output #0: loss = 1.23739 (* 1 = 1.23739 loss)
I0506 04:36:08.797734 12834 sgd_solver.cpp:106] Iteration 42500, lr = 4.096e-05
I0506 04:36:08.799579 12834 solver.cpp:362] Iteration 42500, Testing net (#0)
I0506 04:36:08.799593 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:08.928316 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6715
I0506 04:36:08.928335 12834 solver.cpp:429]     Test net output #1: loss = 0.787845 (* 1 = 0.787845 loss)
I0506 04:36:08.930901 12834 solver.cpp:242] Iteration 42500 (77.4205 iter/s, 1.29165s/100 iter), loss = 1.06173
I0506 04:36:08.930920 12834 solver.cpp:261]     Train net output #0: loss = 1.06173 (* 1 = 1.06173 loss)
I0506 04:36:08.930929 12834 sgd_solver.cpp:106] Iteration 42500, lr = 4.096e-05
I0506 04:36:09.864470 12834 solver.cpp:242] Iteration 42600 (93.7456 iter/s, 1.06672s/100 iter), loss = 2.14523
I0506 04:36:09.864502 12834 solver.cpp:261]     Train net output #0: loss = 2.14523 (* 1 = 2.14523 loss)
I0506 04:36:09.864512 12834 sgd_solver.cpp:106] Iteration 42600, lr = 4.096e-05
I0506 04:36:09.869244 12834 solver.cpp:242] Iteration 42600 (106.575 iter/s, 0.938304s/100 iter), loss = 0.931177
I0506 04:36:09.869271 12834 solver.cpp:261]     Train net output #0: loss = 0.931177 (* 1 = 0.931177 loss)
I0506 04:36:09.869279 12834 sgd_solver.cpp:106] Iteration 42600, lr = 4.096e-05
I0506 04:36:10.826200 12834 solver.cpp:242] Iteration 42700 (103.986 iter/s, 0.961666s/100 iter), loss = 1.35429
I0506 04:36:10.826241 12834 solver.cpp:261]     Train net output #0: loss = 1.35429 (* 1 = 1.35429 loss)
I0506 04:36:10.826253 12834 sgd_solver.cpp:106] Iteration 42700, lr = 4.096e-05
I0506 04:36:10.831506 12834 solver.cpp:242] Iteration 42700 (103.927 iter/s, 0.962215s/100 iter), loss = 0.91824
I0506 04:36:10.831535 12834 solver.cpp:261]     Train net output #0: loss = 0.91824 (* 1 = 0.91824 loss)
I0506 04:36:10.831547 12834 sgd_solver.cpp:106] Iteration 42700, lr = 4.096e-05
I0506 04:36:11.862902 12834 solver.cpp:242] Iteration 42800 (96.4662 iter/s, 1.03663s/100 iter), loss = 1.1187
I0506 04:36:11.862949 12834 solver.cpp:261]     Train net output #0: loss = 1.1187 (* 1 = 1.1187 loss)
I0506 04:36:11.862962 12834 sgd_solver.cpp:106] Iteration 42800, lr = 4.096e-05
I0506 04:36:11.868192 12834 solver.cpp:242] Iteration 42800 (96.4658 iter/s, 1.03664s/100 iter), loss = 0.320003
I0506 04:36:11.868222 12834 solver.cpp:261]     Train net output #0: loss = 0.320003 (* 1 = 0.320003 loss)
I0506 04:36:11.868233 12834 sgd_solver.cpp:106] Iteration 42800, lr = 4.096e-05
I0506 04:36:12.848438 12834 solver.cpp:242] Iteration 42900 (101.476 iter/s, 0.985457s/100 iter), loss = 2.81416
I0506 04:36:12.848476 12834 solver.cpp:261]     Train net output #0: loss = 2.81416 (* 1 = 2.81416 loss)
I0506 04:36:12.848486 12834 sgd_solver.cpp:106] Iteration 42900, lr = 4.096e-05
I0506 04:36:12.853210 12834 solver.cpp:242] Iteration 42900 (101.526 iter/s, 0.98497s/100 iter), loss = 0.819478
I0506 04:36:12.853235 12834 solver.cpp:261]     Train net output #0: loss = 0.819478 (* 1 = 0.819478 loss)
I0506 04:36:12.853243 12834 sgd_solver.cpp:106] Iteration 42900, lr = 4.096e-05
I0506 04:36:13.784209 12834 solver.cpp:362] Iteration 43000, Testing net (#0)
I0506 04:36:13.784237 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:13.907219 12834 solver.cpp:429]     Test net output #0: loss = 2.05033 (* 1 = 2.05033 loss)
I0506 04:36:13.909795 12834 solver.cpp:242] Iteration 43000 (94.2241 iter/s, 1.0613s/100 iter), loss = 2.91221
I0506 04:36:13.909821 12834 solver.cpp:261]     Train net output #0: loss = 2.91221 (* 1 = 2.91221 loss)
I0506 04:36:13.909831 12834 sgd_solver.cpp:106] Iteration 43000, lr = 4.096e-05
I0506 04:36:13.911650 12834 solver.cpp:362] Iteration 43000, Testing net (#0)
I0506 04:36:13.911664 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:14.040592 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7175
I0506 04:36:14.040621 12834 solver.cpp:429]     Test net output #1: loss = 0.682658 (* 1 = 0.682658 loss)
I0506 04:36:14.043187 12834 solver.cpp:242] Iteration 43000 (84.0384 iter/s, 1.18993s/100 iter), loss = 0.721978
I0506 04:36:14.043208 12834 solver.cpp:261]     Train net output #0: loss = 0.721978 (* 1 = 0.721978 loss)
I0506 04:36:14.043217 12834 sgd_solver.cpp:106] Iteration 43000, lr = 4.096e-05
I0506 04:36:14.976768 12834 solver.cpp:242] Iteration 43100 (93.7284 iter/s, 1.06691s/100 iter), loss = 0.779934
I0506 04:36:14.976809 12834 solver.cpp:261]     Train net output #0: loss = 0.779934 (* 1 = 0.779934 loss)
I0506 04:36:14.976817 12834 sgd_solver.cpp:106] Iteration 43100, lr = 4.096e-05
I0506 04:36:14.981541 12834 solver.cpp:242] Iteration 43100 (106.574 iter/s, 0.938316s/100 iter), loss = 1.07186
I0506 04:36:14.981567 12834 solver.cpp:261]     Train net output #0: loss = 1.07186 (* 1 = 1.07186 loss)
I0506 04:36:14.981576 12834 sgd_solver.cpp:106] Iteration 43100, lr = 4.096e-05
I0506 04:36:15.935501 12834 solver.cpp:242] Iteration 43200 (104.312 iter/s, 0.958667s/100 iter), loss = 1.37675
I0506 04:36:15.935547 12834 solver.cpp:261]     Train net output #0: loss = 1.37675 (* 1 = 1.37675 loss)
I0506 04:36:15.935557 12834 sgd_solver.cpp:106] Iteration 43200, lr = 4.096e-05
I0506 04:36:15.940357 12834 solver.cpp:242] Iteration 43200 (104.301 iter/s, 0.958763s/100 iter), loss = 0.737926
I0506 04:36:15.940385 12834 solver.cpp:261]     Train net output #0: loss = 0.737926 (* 1 = 0.737926 loss)
I0506 04:36:15.940394 12834 sgd_solver.cpp:106] Iteration 43200, lr = 4.096e-05
I0506 04:36:16.874326 12834 solver.cpp:242] Iteration 43300 (106.524 iter/s, 0.938753s/100 iter), loss = 1.91804
I0506 04:36:16.874366 12834 solver.cpp:261]     Train net output #0: loss = 1.91804 (* 1 = 1.91804 loss)
I0506 04:36:16.874374 12834 sgd_solver.cpp:106] Iteration 43300, lr = 4.096e-05
I0506 04:36:16.879091 12834 solver.cpp:242] Iteration 43300 (106.532 iter/s, 0.938688s/100 iter), loss = 0.933864
I0506 04:36:16.879117 12834 solver.cpp:261]     Train net output #0: loss = 0.933864 (* 1 = 0.933864 loss)
I0506 04:36:16.879125 12834 sgd_solver.cpp:106] Iteration 43300, lr = 4.096e-05
I0506 04:36:17.812629 12834 solver.cpp:242] Iteration 43400 (106.582 iter/s, 0.938242s/100 iter), loss = 1.44716
I0506 04:36:17.812669 12834 solver.cpp:261]     Train net output #0: loss = 1.44716 (* 1 = 1.44716 loss)
I0506 04:36:17.812677 12834 sgd_solver.cpp:106] Iteration 43400, lr = 4.096e-05
I0506 04:36:17.817479 12834 solver.cpp:242] Iteration 43400 (106.571 iter/s, 0.938338s/100 iter), loss = 0.586821
I0506 04:36:17.817504 12834 solver.cpp:261]     Train net output #0: loss = 0.586821 (* 1 = 0.586821 loss)
I0506 04:36:17.817513 12834 sgd_solver.cpp:106] Iteration 43400, lr = 4.096e-05
I0506 04:36:18.766090 12834 solver.cpp:362] Iteration 43500, Testing net (#0)
I0506 04:36:18.766118 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:18.899513 12834 solver.cpp:429]     Test net output #0: loss = 2.1511 (* 1 = 2.1511 loss)
I0506 04:36:18.902165 12834 solver.cpp:242] Iteration 43500 (91.7872 iter/s, 1.08948s/100 iter), loss = 1.69664
I0506 04:36:18.902192 12834 solver.cpp:261]     Train net output #0: loss = 1.69664 (* 1 = 1.69664 loss)
I0506 04:36:18.902204 12834 sgd_solver.cpp:106] Iteration 43500, lr = 4.096e-05
I0506 04:36:18.904392 12834 solver.cpp:362] Iteration 43500, Testing net (#0)
I0506 04:36:18.904408 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:19.045594 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7195
I0506 04:36:19.045620 12834 solver.cpp:429]     Test net output #1: loss = 0.70102 (* 1 = 0.70102 loss)
I0506 04:36:19.048274 12834 solver.cpp:242] Iteration 43500 (81.2514 iter/s, 1.23075s/100 iter), loss = 0.897503
I0506 04:36:19.048295 12834 solver.cpp:261]     Train net output #0: loss = 0.897503 (* 1 = 0.897503 loss)
I0506 04:36:19.048303 12834 sgd_solver.cpp:106] Iteration 43500, lr = 4.096e-05
I0506 04:36:19.982913 12834 solver.cpp:242] Iteration 43600 (92.5337 iter/s, 1.08069s/100 iter), loss = 1.97338
I0506 04:36:19.982960 12834 solver.cpp:261]     Train net output #0: loss = 1.97338 (* 1 = 1.97338 loss)
I0506 04:36:19.982970 12834 sgd_solver.cpp:106] Iteration 43600, lr = 4.096e-05
I0506 04:36:19.987699 12834 solver.cpp:242] Iteration 43600 (106.452 iter/s, 0.939387s/100 iter), loss = 0.582754
I0506 04:36:19.987725 12834 solver.cpp:261]     Train net output #0: loss = 0.582754 (* 1 = 0.582754 loss)
I0506 04:36:19.987733 12834 sgd_solver.cpp:106] Iteration 43600, lr = 4.096e-05
I0506 04:36:20.921335 12834 solver.cpp:242] Iteration 43700 (106.57 iter/s, 0.938349s/100 iter), loss = 3.71894
I0506 04:36:20.921373 12834 solver.cpp:261]     Train net output #0: loss = 3.71894 (* 1 = 3.71894 loss)
I0506 04:36:20.921382 12834 sgd_solver.cpp:106] Iteration 43700, lr = 4.096e-05
I0506 04:36:20.926123 12834 solver.cpp:242] Iteration 43700 (106.566 iter/s, 0.938381s/100 iter), loss = 0.775681
I0506 04:36:20.926148 12834 solver.cpp:261]     Train net output #0: loss = 0.775681 (* 1 = 0.775681 loss)
I0506 04:36:20.926157 12834 sgd_solver.cpp:106] Iteration 43700, lr = 4.096e-05
I0506 04:36:21.860828 12834 solver.cpp:242] Iteration 43800 (106.448 iter/s, 0.939426s/100 iter), loss = 2.02723
I0506 04:36:21.860862 12834 solver.cpp:261]     Train net output #0: loss = 2.02723 (* 1 = 2.02723 loss)
I0506 04:36:21.860872 12834 sgd_solver.cpp:106] Iteration 43800, lr = 4.096e-05
I0506 04:36:21.865614 12834 solver.cpp:242] Iteration 43800 (106.445 iter/s, 0.939448s/100 iter), loss = 0.738336
I0506 04:36:21.865639 12834 solver.cpp:261]     Train net output #0: loss = 0.738336 (* 1 = 0.738336 loss)
I0506 04:36:21.865648 12834 sgd_solver.cpp:106] Iteration 43800, lr = 4.096e-05
I0506 04:36:22.822824 12834 solver.cpp:242] Iteration 43900 (103.957 iter/s, 0.961935s/100 iter), loss = 1.70262
I0506 04:36:22.822859 12834 solver.cpp:261]     Train net output #0: loss = 1.70262 (* 1 = 1.70262 loss)
I0506 04:36:22.822870 12834 sgd_solver.cpp:106] Iteration 43900, lr = 4.096e-05
I0506 04:36:22.828148 12834 solver.cpp:242] Iteration 43900 (103.897 iter/s, 0.962489s/100 iter), loss = 1.03766
I0506 04:36:22.828176 12834 solver.cpp:261]     Train net output #0: loss = 1.03766 (* 1 = 1.03766 loss)
I0506 04:36:22.828187 12834 sgd_solver.cpp:106] Iteration 43900, lr = 4.096e-05
I0506 04:36:23.856220 12834 solver.cpp:362] Iteration 44000, Testing net (#0)
I0506 04:36:23.856243 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:23.989593 12834 solver.cpp:429]     Test net output #0: loss = 2.05724 (* 1 = 2.05724 loss)
I0506 04:36:23.992244 12834 solver.cpp:242] Iteration 44000 (85.5165 iter/s, 1.16937s/100 iter), loss = 1.84836
I0506 04:36:23.992267 12834 solver.cpp:261]     Train net output #0: loss = 1.84836 (* 1 = 1.84836 loss)
I0506 04:36:23.992278 12834 sgd_solver.cpp:106] Iteration 44000, lr = 4.096e-05
I0506 04:36:23.994467 12834 solver.cpp:362] Iteration 44000, Testing net (#0)
I0506 04:36:23.994483 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:24.135624 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7065
I0506 04:36:24.135651 12834 solver.cpp:429]     Test net output #1: loss = 0.718578 (* 1 = 0.718578 loss)
I0506 04:36:24.138447 12834 solver.cpp:242] Iteration 44000 (76.3214 iter/s, 1.31025s/100 iter), loss = 0.908647
I0506 04:36:24.138470 12834 solver.cpp:261]     Train net output #0: loss = 0.908647 (* 1 = 0.908647 loss)
I0506 04:36:24.138479 12834 sgd_solver.cpp:106] Iteration 44000, lr = 4.096e-05
I0506 04:36:25.072944 12834 solver.cpp:242] Iteration 44100 (92.5368 iter/s, 1.08065s/100 iter), loss = 5.5335
I0506 04:36:25.072980 12834 solver.cpp:261]     Train net output #0: loss = 5.5335 (* 1 = 5.5335 loss)
I0506 04:36:25.072989 12834 sgd_solver.cpp:106] Iteration 44100, lr = 4.096e-05
I0506 04:36:25.077780 12834 solver.cpp:242] Iteration 44100 (106.464 iter/s, 0.939283s/100 iter), loss = 1.53611
I0506 04:36:25.077805 12834 solver.cpp:261]     Train net output #0: loss = 1.53611 (* 1 = 1.53611 loss)
I0506 04:36:25.077814 12834 sgd_solver.cpp:106] Iteration 44100, lr = 4.096e-05
I0506 04:36:26.011600 12834 solver.cpp:242] Iteration 44200 (106.543 iter/s, 0.938592s/100 iter), loss = 0.753765
I0506 04:36:26.011633 12834 solver.cpp:261]     Train net output #0: loss = 0.753765 (* 1 = 0.753765 loss)
I0506 04:36:26.011643 12834 sgd_solver.cpp:106] Iteration 44200, lr = 4.096e-05
I0506 04:36:26.016376 12834 solver.cpp:242] Iteration 44200 (106.547 iter/s, 0.938552s/100 iter), loss = 0.693905
I0506 04:36:26.016399 12834 solver.cpp:261]     Train net output #0: loss = 0.693905 (* 1 = 0.693905 loss)
I0506 04:36:26.016408 12834 sgd_solver.cpp:106] Iteration 44200, lr = 4.096e-05
I0506 04:36:26.950944 12834 solver.cpp:242] Iteration 44300 (106.464 iter/s, 0.939289s/100 iter), loss = 2.26203
I0506 04:36:26.950978 12834 solver.cpp:261]     Train net output #0: loss = 2.26203 (* 1 = 2.26203 loss)
I0506 04:36:26.950987 12834 sgd_solver.cpp:106] Iteration 44300, lr = 4.096e-05
I0506 04:36:26.955819 12834 solver.cpp:242] Iteration 44300 (106.452 iter/s, 0.939394s/100 iter), loss = 0.60136
I0506 04:36:26.955843 12834 solver.cpp:261]     Train net output #0: loss = 0.60136 (* 1 = 0.60136 loss)
I0506 04:36:26.955852 12834 sgd_solver.cpp:106] Iteration 44300, lr = 4.096e-05
I0506 04:36:27.889844 12834 solver.cpp:242] Iteration 44400 (106.514 iter/s, 0.93884s/100 iter), loss = 1.84196
I0506 04:36:27.889886 12834 solver.cpp:261]     Train net output #0: loss = 1.84196 (* 1 = 1.84196 loss)
I0506 04:36:27.889896 12834 sgd_solver.cpp:106] Iteration 44400, lr = 4.096e-05
I0506 04:36:27.894624 12834 solver.cpp:242] Iteration 44400 (106.523 iter/s, 0.938763s/100 iter), loss = 0.596863
I0506 04:36:27.894651 12834 solver.cpp:261]     Train net output #0: loss = 0.596863 (* 1 = 0.596863 loss)
I0506 04:36:27.894659 12834 sgd_solver.cpp:106] Iteration 44400, lr = 4.096e-05
I0506 04:36:28.825052 12834 solver.cpp:362] Iteration 44500, Testing net (#0)
I0506 04:36:28.825078 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:28.947860 12834 solver.cpp:429]     Test net output #0: loss = 1.66136 (* 1 = 1.66136 loss)
I0506 04:36:28.950374 12834 solver.cpp:242] Iteration 44500 (94.2978 iter/s, 1.06047s/100 iter), loss = 1.79123
I0506 04:36:28.950397 12834 solver.cpp:261]     Train net output #0: loss = 1.79123 (* 1 = 1.79123 loss)
I0506 04:36:28.950405 12834 sgd_solver.cpp:106] Iteration 44500, lr = 4.096e-05
I0506 04:36:28.952221 12834 solver.cpp:362] Iteration 44500, Testing net (#0)
I0506 04:36:28.952234 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:29.081233 12834 solver.cpp:429]     Test net output #0: accuracy = 0.719
I0506 04:36:29.081252 12834 solver.cpp:429]     Test net output #1: loss = 0.692788 (* 1 = 0.692788 loss)
I0506 04:36:29.083809 12834 solver.cpp:242] Iteration 44500 (84.0945 iter/s, 1.18914s/100 iter), loss = 0.567424
I0506 04:36:29.083830 12834 solver.cpp:261]     Train net output #0: loss = 0.567424 (* 1 = 0.567424 loss)
I0506 04:36:29.083839 12834 sgd_solver.cpp:106] Iteration 44500, lr = 4.096e-05
I0506 04:36:30.017973 12834 solver.cpp:242] Iteration 44600 (93.6727 iter/s, 1.06755s/100 iter), loss = 3.28167
I0506 04:36:30.018016 12834 solver.cpp:261]     Train net output #0: loss = 3.28167 (* 1 = 3.28167 loss)
I0506 04:36:30.018026 12834 sgd_solver.cpp:106] Iteration 44600, lr = 4.096e-05
I0506 04:36:30.022768 12834 solver.cpp:242] Iteration 44600 (106.505 iter/s, 0.938919s/100 iter), loss = 0.736993
I0506 04:36:30.022792 12834 solver.cpp:261]     Train net output #0: loss = 0.736993 (* 1 = 0.736993 loss)
I0506 04:36:30.022801 12834 sgd_solver.cpp:106] Iteration 44600, lr = 4.096e-05
I0506 04:36:30.956269 12834 solver.cpp:242] Iteration 44700 (106.585 iter/s, 0.938223s/100 iter), loss = 1.11388
I0506 04:36:30.956310 12834 solver.cpp:261]     Train net output #0: loss = 1.11388 (* 1 = 1.11388 loss)
I0506 04:36:30.956318 12834 sgd_solver.cpp:106] Iteration 44700, lr = 4.096e-05
I0506 04:36:30.961057 12834 solver.cpp:242] Iteration 44700 (106.582 iter/s, 0.938247s/100 iter), loss = 0.689979
I0506 04:36:30.961083 12834 solver.cpp:261]     Train net output #0: loss = 0.689979 (* 1 = 0.689979 loss)
I0506 04:36:30.961102 12834 sgd_solver.cpp:106] Iteration 44700, lr = 4.096e-05
I0506 04:36:31.894628 12834 solver.cpp:242] Iteration 44800 (106.577 iter/s, 0.938293s/100 iter), loss = 1.09418
I0506 04:36:31.894666 12834 solver.cpp:261]     Train net output #0: loss = 1.09418 (* 1 = 1.09418 loss)
I0506 04:36:31.894675 12834 sgd_solver.cpp:106] Iteration 44800, lr = 4.096e-05
I0506 04:36:31.899408 12834 solver.cpp:242] Iteration 44800 (106.575 iter/s, 0.938306s/100 iter), loss = 0.890396
I0506 04:36:31.899432 12834 solver.cpp:261]     Train net output #0: loss = 0.890396 (* 1 = 0.890396 loss)
I0506 04:36:31.899441 12834 sgd_solver.cpp:106] Iteration 44800, lr = 4.096e-05
I0506 04:36:32.846393 12834 solver.cpp:242] Iteration 44900 (105.075 iter/s, 0.951697s/100 iter), loss = 2.23674
I0506 04:36:32.846429 12834 solver.cpp:261]     Train net output #0: loss = 2.23674 (* 1 = 2.23674 loss)
I0506 04:36:32.846438 12834 sgd_solver.cpp:106] Iteration 44900, lr = 4.096e-05
I0506 04:36:32.851186 12834 solver.cpp:242] Iteration 44900 (105.071 iter/s, 0.951734s/100 iter), loss = 0.772172
I0506 04:36:32.851209 12834 solver.cpp:261]     Train net output #0: loss = 0.772172 (* 1 = 0.772172 loss)
I0506 04:36:32.851219 12834 sgd_solver.cpp:106] Iteration 44900, lr = 4.096e-05
I0506 04:36:33.782676 12834 solver.cpp:362] Iteration 45000, Testing net (#0)
I0506 04:36:33.782701 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:33.905525 12834 solver.cpp:429]     Test net output #0: loss = 1.90786 (* 1 = 1.90786 loss)
I0506 04:36:33.908041 12834 solver.cpp:242] Iteration 45000 (94.198 iter/s, 1.06159s/100 iter), loss = 2.16544
I0506 04:36:33.908061 12834 solver.cpp:261]     Train net output #0: loss = 2.16544 (* 1 = 2.16544 loss)
I0506 04:36:33.908069 12834 sgd_solver.cpp:106] Iteration 45000, lr = 4.096e-05
I0506 04:36:33.909972 12834 solver.cpp:362] Iteration 45000, Testing net (#0)
I0506 04:36:33.909987 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:34.038838 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6915
I0506 04:36:34.038859 12834 solver.cpp:429]     Test net output #1: loss = 0.724001 (* 1 = 0.724001 loss)
I0506 04:36:34.041414 12834 solver.cpp:242] Iteration 45000 (84.0206 iter/s, 1.19018s/100 iter), loss = 0.685559
I0506 04:36:34.041435 12834 solver.cpp:261]     Train net output #0: loss = 0.685559 (* 1 = 0.685559 loss)
I0506 04:36:34.041443 12834 sgd_solver.cpp:106] Iteration 45000, lr = 4.096e-05
I0506 04:36:34.975317 12834 solver.cpp:242] Iteration 45100 (93.7009 iter/s, 1.06723s/100 iter), loss = 0.901302
I0506 04:36:34.975355 12834 solver.cpp:261]     Train net output #0: loss = 0.901302 (* 1 = 0.901302 loss)
I0506 04:36:34.975365 12834 sgd_solver.cpp:106] Iteration 45100, lr = 4.096e-05
I0506 04:36:34.980099 12834 solver.cpp:242] Iteration 45100 (106.536 iter/s, 0.938645s/100 iter), loss = 0.537882
I0506 04:36:34.980125 12834 solver.cpp:261]     Train net output #0: loss = 0.537882 (* 1 = 0.537882 loss)
I0506 04:36:34.980134 12834 sgd_solver.cpp:106] Iteration 45100, lr = 4.096e-05
I0506 04:36:35.914360 12834 solver.cpp:242] Iteration 45200 (106.499 iter/s, 0.93898s/100 iter), loss = 1.44482
I0506 04:36:35.914396 12834 solver.cpp:261]     Train net output #0: loss = 1.44482 (* 1 = 1.44482 loss)
I0506 04:36:35.914404 12834 sgd_solver.cpp:106] Iteration 45200, lr = 4.096e-05
I0506 04:36:35.919222 12834 solver.cpp:242] Iteration 45200 (106.488 iter/s, 0.939072s/100 iter), loss = 0.857653
I0506 04:36:35.919247 12834 solver.cpp:261]     Train net output #0: loss = 0.857653 (* 1 = 0.857653 loss)
I0506 04:36:35.919256 12834 sgd_solver.cpp:106] Iteration 45200, lr = 4.096e-05
I0506 04:36:36.852906 12834 solver.cpp:242] Iteration 45300 (106.555 iter/s, 0.938486s/100 iter), loss = 3.63083
I0506 04:36:36.852941 12834 solver.cpp:261]     Train net output #0: loss = 3.63083 (* 1 = 3.63083 loss)
I0506 04:36:36.852951 12834 sgd_solver.cpp:106] Iteration 45300, lr = 4.096e-05
I0506 04:36:36.857683 12834 solver.cpp:242] Iteration 45300 (106.563 iter/s, 0.938416s/100 iter), loss = 1.02831
I0506 04:36:36.857719 12834 solver.cpp:261]     Train net output #0: loss = 1.02831 (* 1 = 1.02831 loss)
I0506 04:36:36.857729 12834 sgd_solver.cpp:106] Iteration 45300, lr = 4.096e-05
I0506 04:36:37.792812 12834 solver.cpp:242] Iteration 45400 (106.401 iter/s, 0.93984s/100 iter), loss = 1.05691
I0506 04:36:37.792847 12834 solver.cpp:261]     Train net output #0: loss = 1.05691 (* 1 = 1.05691 loss)
I0506 04:36:37.792856 12834 sgd_solver.cpp:106] Iteration 45400, lr = 4.096e-05
I0506 04:36:37.797597 12834 solver.cpp:242] Iteration 45400 (106.399 iter/s, 0.939859s/100 iter), loss = 0.492699
I0506 04:36:37.797622 12834 solver.cpp:261]     Train net output #0: loss = 0.492699 (* 1 = 0.492699 loss)
I0506 04:36:37.797631 12834 sgd_solver.cpp:106] Iteration 45400, lr = 4.096e-05
I0506 04:36:38.743273 12834 solver.cpp:362] Iteration 45500, Testing net (#0)
I0506 04:36:38.743300 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:38.866086 12834 solver.cpp:429]     Test net output #0: loss = 2.38726 (* 1 = 2.38726 loss)
I0506 04:36:38.868618 12834 solver.cpp:242] Iteration 45500 (92.9583 iter/s, 1.07575s/100 iter), loss = 1.7405
I0506 04:36:38.868638 12834 solver.cpp:261]     Train net output #0: loss = 1.7405 (* 1 = 1.7405 loss)
I0506 04:36:38.868646 12834 sgd_solver.cpp:106] Iteration 45500, lr = 4.096e-05
I0506 04:36:38.870486 12834 solver.cpp:362] Iteration 45500, Testing net (#0)
I0506 04:36:38.870501 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:38.999483 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6875
I0506 04:36:38.999502 12834 solver.cpp:429]     Test net output #1: loss = 0.734582 (* 1 = 0.734582 loss)
I0506 04:36:39.002066 12834 solver.cpp:242] Iteration 45500 (83.0273 iter/s, 1.20442s/100 iter), loss = 1.00505
I0506 04:36:39.002086 12834 solver.cpp:261]     Train net output #0: loss = 1.00505 (* 1 = 1.00505 loss)
I0506 04:36:39.002095 12834 sgd_solver.cpp:106] Iteration 45500, lr = 4.096e-05
I0506 04:36:39.936192 12834 solver.cpp:242] Iteration 45600 (93.675 iter/s, 1.06752s/100 iter), loss = 1.08293
I0506 04:36:39.936241 12834 solver.cpp:261]     Train net output #0: loss = 1.08293 (* 1 = 1.08293 loss)
I0506 04:36:39.936390 12834 sgd_solver.cpp:106] Iteration 45600, lr = 4.096e-05
I0506 04:36:39.941191 12834 solver.cpp:242] Iteration 45600 (106.487 iter/s, 0.939086s/100 iter), loss = 0.893765
I0506 04:36:39.941217 12834 solver.cpp:261]     Train net output #0: loss = 0.893765 (* 1 = 0.893765 loss)
I0506 04:36:39.941226 12834 sgd_solver.cpp:106] Iteration 45600, lr = 4.096e-05
I0506 04:36:40.875645 12834 solver.cpp:242] Iteration 45700 (106.453 iter/s, 0.939382s/100 iter), loss = 0.749864
I0506 04:36:40.875686 12834 solver.cpp:261]     Train net output #0: loss = 0.749864 (* 1 = 0.749864 loss)
I0506 04:36:40.875696 12834 sgd_solver.cpp:106] Iteration 45700, lr = 4.096e-05
I0506 04:36:40.880456 12834 solver.cpp:242] Iteration 45700 (106.471 iter/s, 0.93922s/100 iter), loss = 0.93163
I0506 04:36:40.880482 12834 solver.cpp:261]     Train net output #0: loss = 0.93163 (* 1 = 0.93163 loss)
I0506 04:36:40.880491 12834 sgd_solver.cpp:106] Iteration 45700, lr = 4.096e-05
I0506 04:36:41.825162 12834 solver.cpp:242] Iteration 45800 (105.325 iter/s, 0.949446s/100 iter), loss = 2.60183
I0506 04:36:41.825203 12834 solver.cpp:261]     Train net output #0: loss = 2.60183 (* 1 = 2.60183 loss)
I0506 04:36:41.825212 12834 sgd_solver.cpp:106] Iteration 45800, lr = 4.096e-05
I0506 04:36:41.829928 12834 solver.cpp:242] Iteration 45800 (105.327 iter/s, 0.949427s/100 iter), loss = 0.620341
I0506 04:36:41.829953 12834 solver.cpp:261]     Train net output #0: loss = 0.620341 (* 1 = 0.620341 loss)
I0506 04:36:41.829962 12834 sgd_solver.cpp:106] Iteration 45800, lr = 4.096e-05
I0506 04:36:42.783237 12834 solver.cpp:242] Iteration 45900 (104.383 iter/s, 0.958006s/100 iter), loss = 1.77014
I0506 04:36:42.783287 12834 solver.cpp:261]     Train net output #0: loss = 1.77014 (* 1 = 1.77014 loss)
I0506 04:36:42.783298 12834 sgd_solver.cpp:106] Iteration 45900, lr = 4.096e-05
I0506 04:36:42.788635 12834 solver.cpp:242] Iteration 45900 (104.313 iter/s, 0.958652s/100 iter), loss = 0.809287
I0506 04:36:42.788676 12834 solver.cpp:261]     Train net output #0: loss = 0.809287 (* 1 = 0.809287 loss)
I0506 04:36:42.788688 12834 sgd_solver.cpp:106] Iteration 45900, lr = 4.096e-05
I0506 04:36:43.816876 12834 solver.cpp:362] Iteration 46000, Testing net (#0)
I0506 04:36:43.816905 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:43.950143 12834 solver.cpp:429]     Test net output #0: loss = 2.25896 (* 1 = 2.25896 loss)
I0506 04:36:43.952803 12834 solver.cpp:242] Iteration 46000 (85.5069 iter/s, 1.1695s/100 iter), loss = 2.89878
I0506 04:36:43.952828 12834 solver.cpp:261]     Train net output #0: loss = 2.89878 (* 1 = 2.89878 loss)
I0506 04:36:43.952838 12834 sgd_solver.cpp:106] Iteration 46000, lr = 4.096e-05
I0506 04:36:43.955023 12834 solver.cpp:362] Iteration 46000, Testing net (#0)
I0506 04:36:43.955039 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:44.096343 12834 solver.cpp:429]     Test net output #0: accuracy = 0.673
I0506 04:36:44.096369 12834 solver.cpp:429]     Test net output #1: loss = 0.811971 (* 1 = 0.811971 loss)
I0506 04:36:44.099067 12834 solver.cpp:242] Iteration 46000 (76.3144 iter/s, 1.31037s/100 iter), loss = 0.72049
I0506 04:36:44.099097 12834 solver.cpp:261]     Train net output #0: loss = 0.72049 (* 1 = 0.72049 loss)
I0506 04:36:44.099107 12834 sgd_solver.cpp:106] Iteration 46000, lr = 4.096e-05
I0506 04:36:45.091475 12834 solver.cpp:242] Iteration 46100 (87.8257 iter/s, 1.13862s/100 iter), loss = 1.00256
I0506 04:36:45.091519 12834 solver.cpp:261]     Train net output #0: loss = 1.00256 (* 1 = 1.00256 loss)
I0506 04:36:45.091614 12834 sgd_solver.cpp:106] Iteration 46100, lr = 4.096e-05
I0506 04:36:45.096482 12834 solver.cpp:242] Iteration 46100 (100.265 iter/s, 0.997353s/100 iter), loss = 0.457141
I0506 04:36:45.096509 12834 solver.cpp:261]     Train net output #0: loss = 0.457141 (* 1 = 0.457141 loss)
I0506 04:36:45.096519 12834 sgd_solver.cpp:106] Iteration 46100, lr = 4.096e-05
I0506 04:36:46.030616 12834 solver.cpp:242] Iteration 46200 (106.488 iter/s, 0.939071s/100 iter), loss = 3.10521
I0506 04:36:46.030656 12834 solver.cpp:261]     Train net output #0: loss = 3.10521 (* 1 = 3.10521 loss)
I0506 04:36:46.030665 12834 sgd_solver.cpp:106] Iteration 46200, lr = 4.096e-05
I0506 04:36:46.035394 12834 solver.cpp:242] Iteration 46200 (106.511 iter/s, 0.938867s/100 iter), loss = 0.708175
I0506 04:36:46.035419 12834 solver.cpp:261]     Train net output #0: loss = 0.708175 (* 1 = 0.708175 loss)
I0506 04:36:46.035429 12834 sgd_solver.cpp:106] Iteration 46200, lr = 4.096e-05
I0506 04:36:46.969514 12834 solver.cpp:242] Iteration 46300 (106.516 iter/s, 0.938828s/100 iter), loss = 0.799499
I0506 04:36:46.969553 12834 solver.cpp:261]     Train net output #0: loss = 0.799499 (* 1 = 0.799499 loss)
I0506 04:36:46.969563 12834 sgd_solver.cpp:106] Iteration 46300, lr = 4.096e-05
I0506 04:36:46.974303 12834 solver.cpp:242] Iteration 46300 (106.512 iter/s, 0.938865s/100 iter), loss = 0.644464
I0506 04:36:46.974329 12834 solver.cpp:261]     Train net output #0: loss = 0.644464 (* 1 = 0.644464 loss)
I0506 04:36:46.974339 12834 sgd_solver.cpp:106] Iteration 46300, lr = 4.096e-05
I0506 04:36:47.907663 12834 solver.cpp:242] Iteration 46400 (106.6 iter/s, 0.938083s/100 iter), loss = 0.306796
I0506 04:36:47.907701 12834 solver.cpp:261]     Train net output #0: loss = 0.306796 (* 1 = 0.306796 loss)
I0506 04:36:47.907711 12834 sgd_solver.cpp:106] Iteration 46400, lr = 4.096e-05
I0506 04:36:47.912475 12834 solver.cpp:242] Iteration 46400 (106.595 iter/s, 0.938128s/100 iter), loss = 0.712851
I0506 04:36:47.912502 12834 solver.cpp:261]     Train net output #0: loss = 0.712851 (* 1 = 0.712851 loss)
I0506 04:36:47.912510 12834 sgd_solver.cpp:106] Iteration 46400, lr = 4.096e-05
I0506 04:36:48.843106 12834 solver.cpp:362] Iteration 46500, Testing net (#0)
I0506 04:36:48.843129 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:48.965929 12834 solver.cpp:429]     Test net output #0: loss = 1.77337 (* 1 = 1.77337 loss)
I0506 04:36:48.968471 12834 solver.cpp:242] Iteration 46500 (94.2728 iter/s, 1.06075s/100 iter), loss = 0.267787
I0506 04:36:48.968492 12834 solver.cpp:261]     Train net output #0: loss = 0.267787 (* 1 = 0.267787 loss)
I0506 04:36:48.968502 12834 sgd_solver.cpp:106] Iteration 46500, lr = 4.096e-05
I0506 04:36:48.970317 12834 solver.cpp:362] Iteration 46500, Testing net (#0)
I0506 04:36:48.970330 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:49.099329 12834 solver.cpp:429]     Test net output #0: accuracy = 0.713
I0506 04:36:49.099349 12834 solver.cpp:429]     Test net output #1: loss = 0.694143 (* 1 = 0.694143 loss)
I0506 04:36:49.101912 12834 solver.cpp:242] Iteration 46500 (84.0768 iter/s, 1.18939s/100 iter), loss = 0.257742
I0506 04:36:49.101933 12834 solver.cpp:261]     Train net output #0: loss = 0.257742 (* 1 = 0.257742 loss)
I0506 04:36:49.101941 12834 sgd_solver.cpp:106] Iteration 46500, lr = 4.096e-05
I0506 04:36:50.037191 12834 solver.cpp:242] Iteration 46600 (93.5744 iter/s, 1.06867s/100 iter), loss = 1.28782
I0506 04:36:50.037230 12834 solver.cpp:261]     Train net output #0: loss = 1.28782 (* 1 = 1.28782 loss)
I0506 04:36:50.037240 12834 sgd_solver.cpp:106] Iteration 46600, lr = 4.096e-05
I0506 04:36:50.041970 12834 solver.cpp:242] Iteration 46600 (106.381 iter/s, 0.940019s/100 iter), loss = 0.591827
I0506 04:36:50.041996 12834 solver.cpp:261]     Train net output #0: loss = 0.591827 (* 1 = 0.591827 loss)
I0506 04:36:50.042004 12834 sgd_solver.cpp:106] Iteration 46600, lr = 4.096e-05
I0506 04:36:50.976420 12834 solver.cpp:242] Iteration 46700 (106.478 iter/s, 0.939163s/100 iter), loss = 1.17841
I0506 04:36:50.976457 12834 solver.cpp:261]     Train net output #0: loss = 1.17841 (* 1 = 1.17841 loss)
I0506 04:36:50.976466 12834 sgd_solver.cpp:106] Iteration 46700, lr = 4.096e-05
I0506 04:36:50.981209 12834 solver.cpp:242] Iteration 46700 (106.474 iter/s, 0.939194s/100 iter), loss = 0.646893
I0506 04:36:50.981235 12834 solver.cpp:261]     Train net output #0: loss = 0.646893 (* 1 = 0.646893 loss)
I0506 04:36:50.981245 12834 sgd_solver.cpp:106] Iteration 46700, lr = 4.096e-05
I0506 04:36:51.914450 12834 solver.cpp:242] Iteration 46800 (106.613 iter/s, 0.93797s/100 iter), loss = 1.55287
I0506 04:36:51.914484 12834 solver.cpp:261]     Train net output #0: loss = 1.55287 (* 1 = 1.55287 loss)
I0506 04:36:51.914494 12834 sgd_solver.cpp:106] Iteration 46800, lr = 4.096e-05
I0506 04:36:51.919298 12834 solver.cpp:242] Iteration 46800 (106.606 iter/s, 0.938036s/100 iter), loss = 0.77687
I0506 04:36:51.919322 12834 solver.cpp:261]     Train net output #0: loss = 0.77687 (* 1 = 0.77687 loss)
I0506 04:36:51.919332 12834 sgd_solver.cpp:106] Iteration 46800, lr = 4.096e-05
I0506 04:36:52.852695 12834 solver.cpp:242] Iteration 46900 (106.589 iter/s, 0.938185s/100 iter), loss = 2.26054
I0506 04:36:52.852728 12834 solver.cpp:261]     Train net output #0: loss = 2.26054 (* 1 = 2.26054 loss)
I0506 04:36:52.852737 12834 sgd_solver.cpp:106] Iteration 46900, lr = 4.096e-05
I0506 04:36:52.857458 12834 solver.cpp:242] Iteration 46900 (106.596 iter/s, 0.938117s/100 iter), loss = 0.596922
I0506 04:36:52.857483 12834 solver.cpp:261]     Train net output #0: loss = 0.596922 (* 1 = 0.596922 loss)
I0506 04:36:52.857492 12834 sgd_solver.cpp:106] Iteration 46900, lr = 4.096e-05
I0506 04:36:53.799743 12834 solver.cpp:362] Iteration 47000, Testing net (#0)
I0506 04:36:53.799772 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:53.922731 12834 solver.cpp:429]     Test net output #0: loss = 2.10735 (* 1 = 2.10735 loss)
I0506 04:36:53.925256 12834 solver.cpp:242] Iteration 47000 (93.2394 iter/s, 1.07251s/100 iter), loss = 0.968672
I0506 04:36:53.925276 12834 solver.cpp:261]     Train net output #0: loss = 0.968672 (* 1 = 0.968672 loss)
I0506 04:36:53.925285 12834 sgd_solver.cpp:106] Iteration 47000, lr = 4.096e-05
I0506 04:36:53.927176 12834 solver.cpp:362] Iteration 47000, Testing net (#0)
I0506 04:36:53.927191 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:54.056208 12834 solver.cpp:429]     Test net output #0: accuracy = 0.692
I0506 04:36:54.056237 12834 solver.cpp:429]     Test net output #1: loss = 0.719031 (* 1 = 0.719031 loss)
I0506 04:36:54.058815 12834 solver.cpp:242] Iteration 47000 (83.2424 iter/s, 1.20131s/100 iter), loss = 0.784444
I0506 04:36:54.058835 12834 solver.cpp:261]     Train net output #0: loss = 0.784444 (* 1 = 0.784444 loss)
I0506 04:36:54.058845 12834 sgd_solver.cpp:106] Iteration 47000, lr = 4.096e-05
I0506 04:36:55.035542 12834 solver.cpp:242] Iteration 47100 (90.0713 iter/s, 1.11023s/100 iter), loss = 1.05634
I0506 04:36:55.035588 12834 solver.cpp:261]     Train net output #0: loss = 1.05634 (* 1 = 1.05634 loss)
I0506 04:36:55.035600 12834 sgd_solver.cpp:106] Iteration 47100, lr = 4.096e-05
I0506 04:36:55.040820 12834 solver.cpp:242] Iteration 47100 (101.837 iter/s, 0.981965s/100 iter), loss = 0.583694
I0506 04:36:55.040850 12834 solver.cpp:261]     Train net output #0: loss = 0.583694 (* 1 = 0.583694 loss)
I0506 04:36:55.040863 12834 sgd_solver.cpp:106] Iteration 47100, lr = 4.096e-05
I0506 04:36:56.071223 12834 solver.cpp:242] Iteration 47200 (96.5623 iter/s, 1.0356s/100 iter), loss = 1.84965
I0506 04:36:56.071276 12834 solver.cpp:261]     Train net output #0: loss = 1.84965 (* 1 = 1.84965 loss)
I0506 04:36:56.071542 12834 sgd_solver.cpp:106] Iteration 47200, lr = 4.096e-05
I0506 04:36:56.076352 12834 solver.cpp:242] Iteration 47200 (96.5733 iter/s, 1.03548s/100 iter), loss = 0.683874
I0506 04:36:56.076378 12834 solver.cpp:261]     Train net output #0: loss = 0.683874 (* 1 = 0.683874 loss)
I0506 04:36:56.076387 12834 sgd_solver.cpp:106] Iteration 47200, lr = 4.096e-05
I0506 04:36:57.010180 12834 solver.cpp:242] Iteration 47300 (106.51 iter/s, 0.938878s/100 iter), loss = 2.97691
I0506 04:36:57.010223 12834 solver.cpp:261]     Train net output #0: loss = 2.97691 (* 1 = 2.97691 loss)
I0506 04:36:57.010233 12834 sgd_solver.cpp:106] Iteration 47300, lr = 4.096e-05
I0506 04:36:57.014969 12834 solver.cpp:242] Iteration 47300 (106.545 iter/s, 0.938573s/100 iter), loss = 0.667964
I0506 04:36:57.014997 12834 solver.cpp:261]     Train net output #0: loss = 0.667964 (* 1 = 0.667964 loss)
I0506 04:36:57.015007 12834 sgd_solver.cpp:106] Iteration 47300, lr = 4.096e-05
I0506 04:36:57.949546 12834 solver.cpp:242] Iteration 47400 (106.463 iter/s, 0.939292s/100 iter), loss = 0.580798
I0506 04:36:57.949584 12834 solver.cpp:261]     Train net output #0: loss = 0.580798 (* 1 = 0.580798 loss)
I0506 04:36:57.949594 12834 sgd_solver.cpp:106] Iteration 47400, lr = 4.096e-05
I0506 04:36:57.954330 12834 solver.cpp:242] Iteration 47400 (106.461 iter/s, 0.939314s/100 iter), loss = 0.510945
I0506 04:36:57.954356 12834 solver.cpp:261]     Train net output #0: loss = 0.510945 (* 1 = 0.510945 loss)
I0506 04:36:57.954365 12834 sgd_solver.cpp:106] Iteration 47400, lr = 4.096e-05
I0506 04:36:58.916391 12834 solver.cpp:362] Iteration 47500, Testing net (#0)
I0506 04:36:58.916424 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:59.049661 12834 solver.cpp:429]     Test net output #0: loss = 2.01012 (* 1 = 2.01012 loss)
I0506 04:36:59.052323 12834 solver.cpp:242] Iteration 47500 (90.685 iter/s, 1.10272s/100 iter), loss = 2.19774
I0506 04:36:59.052351 12834 solver.cpp:261]     Train net output #0: loss = 2.19774 (* 1 = 2.19774 loss)
I0506 04:36:59.052361 12834 sgd_solver.cpp:106] Iteration 47500, lr = 4.096e-05
I0506 04:36:59.054558 12834 solver.cpp:362] Iteration 47500, Testing net (#0)
I0506 04:36:59.054574 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:36:59.195598 12834 solver.cpp:429]     Test net output #0: accuracy = 0.702
I0506 04:36:59.195622 12834 solver.cpp:429]     Test net output #1: loss = 0.7266 (* 1 = 0.7266 loss)
I0506 04:36:59.198324 12834 solver.cpp:242] Iteration 47500 (80.3893 iter/s, 1.24395s/100 iter), loss = 0.836464
I0506 04:36:59.198348 12834 solver.cpp:261]     Train net output #0: loss = 0.836464 (* 1 = 0.836464 loss)
I0506 04:36:59.198359 12834 sgd_solver.cpp:106] Iteration 47500, lr = 4.096e-05
I0506 04:37:00.230754 12834 solver.cpp:242] Iteration 47600 (84.8671 iter/s, 1.17831s/100 iter), loss = 2.14985
I0506 04:37:00.230829 12834 solver.cpp:261]     Train net output #0: loss = 2.14985 (* 1 = 2.14985 loss)
I0506 04:37:00.230844 12834 sgd_solver.cpp:106] Iteration 47600, lr = 4.096e-05
I0506 04:37:00.237138 12834 solver.cpp:242] Iteration 47600 (96.2683 iter/s, 1.03876s/100 iter), loss = 0.54456
I0506 04:37:00.237193 12834 solver.cpp:261]     Train net output #0: loss = 0.54456 (* 1 = 0.54456 loss)
I0506 04:37:00.237206 12834 sgd_solver.cpp:106] Iteration 47600, lr = 4.096e-05
I0506 04:37:01.219089 12834 solver.cpp:242] Iteration 47700 (101.191 iter/s, 0.988234s/100 iter), loss = 2.69724
I0506 04:37:01.219136 12834 solver.cpp:261]     Train net output #0: loss = 2.69724 (* 1 = 2.69724 loss)
I0506 04:37:01.219365 12834 sgd_solver.cpp:106] Iteration 47700, lr = 4.096e-05
I0506 04:37:01.224267 12834 solver.cpp:242] Iteration 47700 (101.312 iter/s, 0.987048s/100 iter), loss = 0.822843
I0506 04:37:01.224293 12834 solver.cpp:261]     Train net output #0: loss = 0.822843 (* 1 = 0.822843 loss)
I0506 04:37:01.224303 12834 sgd_solver.cpp:106] Iteration 47700, lr = 4.096e-05
I0506 04:37:02.156260 12834 solver.cpp:242] Iteration 47800 (106.712 iter/s, 0.9371s/100 iter), loss = 1.21799
I0506 04:37:02.156301 12834 solver.cpp:261]     Train net output #0: loss = 1.21799 (* 1 = 1.21799 loss)
I0506 04:37:02.156311 12834 sgd_solver.cpp:106] Iteration 47800, lr = 4.096e-05
I0506 04:37:02.161042 12834 solver.cpp:242] Iteration 47800 (106.754 iter/s, 0.93673s/100 iter), loss = 0.931104
I0506 04:37:02.161067 12834 solver.cpp:261]     Train net output #0: loss = 0.931104 (* 1 = 0.931104 loss)
I0506 04:37:02.161077 12834 sgd_solver.cpp:106] Iteration 47800, lr = 4.096e-05
I0506 04:37:03.093005 12834 solver.cpp:242] Iteration 47900 (106.76 iter/s, 0.93668s/100 iter), loss = 1.96646
I0506 04:37:03.093046 12834 solver.cpp:261]     Train net output #0: loss = 1.96646 (* 1 = 1.96646 loss)
I0506 04:37:03.093056 12834 sgd_solver.cpp:106] Iteration 47900, lr = 4.096e-05
I0506 04:37:03.097856 12834 solver.cpp:242] Iteration 47900 (106.751 iter/s, 0.936763s/100 iter), loss = 0.595339
I0506 04:37:03.097882 12834 solver.cpp:261]     Train net output #0: loss = 0.595339 (* 1 = 0.595339 loss)
I0506 04:37:03.097892 12834 sgd_solver.cpp:106] Iteration 47900, lr = 4.096e-05
I0506 04:37:04.027138 12834 solver.cpp:362] Iteration 48000, Testing net (#0)
I0506 04:37:04.027163 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:04.149911 12834 solver.cpp:429]     Test net output #0: loss = 1.90914 (* 1 = 1.90914 loss)
I0506 04:37:04.152420 12834 solver.cpp:242] Iteration 48000 (94.3971 iter/s, 1.05935s/100 iter), loss = 1.61657
I0506 04:37:04.152441 12834 solver.cpp:261]     Train net output #0: loss = 1.61657 (* 1 = 1.61657 loss)
I0506 04:37:04.152451 12834 sgd_solver.cpp:106] Iteration 48000, lr = 4.096e-05
I0506 04:37:04.154258 12834 solver.cpp:362] Iteration 48000, Testing net (#0)
I0506 04:37:04.154270 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:04.282907 12834 solver.cpp:429]     Test net output #0: accuracy = 0.683
I0506 04:37:04.282927 12834 solver.cpp:429]     Test net output #1: loss = 0.811821 (* 1 = 0.811821 loss)
I0506 04:37:04.285473 12834 solver.cpp:242] Iteration 48000 (84.2055 iter/s, 1.18757s/100 iter), loss = 0.829959
I0506 04:37:04.285493 12834 solver.cpp:261]     Train net output #0: loss = 0.829959 (* 1 = 0.829959 loss)
I0506 04:37:04.285502 12834 sgd_solver.cpp:106] Iteration 48000, lr = 4.096e-05
I0506 04:37:05.218014 12834 solver.cpp:242] Iteration 48100 (93.8493 iter/s, 1.06554s/100 iter), loss = 4.46296
I0506 04:37:05.218060 12834 solver.cpp:261]     Train net output #0: loss = 4.46296 (* 1 = 4.46296 loss)
I0506 04:37:05.218070 12834 sgd_solver.cpp:106] Iteration 48100, lr = 4.096e-05
I0506 04:37:05.222825 12834 solver.cpp:242] Iteration 48100 (106.688 iter/s, 0.937311s/100 iter), loss = 0.79248
I0506 04:37:05.222849 12834 solver.cpp:261]     Train net output #0: loss = 0.79248 (* 1 = 0.79248 loss)
I0506 04:37:05.222859 12834 sgd_solver.cpp:106] Iteration 48100, lr = 4.096e-05
I0506 04:37:06.154882 12834 solver.cpp:242] Iteration 48200 (106.746 iter/s, 0.936806s/100 iter), loss = 0.651914
I0506 04:37:06.154918 12834 solver.cpp:261]     Train net output #0: loss = 0.651914 (* 1 = 0.651914 loss)
I0506 04:37:06.154928 12834 sgd_solver.cpp:106] Iteration 48200, lr = 4.096e-05
I0506 04:37:06.159651 12834 solver.cpp:242] Iteration 48200 (106.748 iter/s, 0.936784s/100 iter), loss = 0.721305
I0506 04:37:06.159677 12834 solver.cpp:261]     Train net output #0: loss = 0.721305 (* 1 = 0.721305 loss)
I0506 04:37:06.159684 12834 sgd_solver.cpp:106] Iteration 48200, lr = 4.096e-05
I0506 04:37:07.091636 12834 solver.cpp:242] Iteration 48300 (106.759 iter/s, 0.936688s/100 iter), loss = 2.20598
I0506 04:37:07.091671 12834 solver.cpp:261]     Train net output #0: loss = 2.20598 (* 1 = 2.20598 loss)
I0506 04:37:07.091681 12834 sgd_solver.cpp:106] Iteration 48300, lr = 4.096e-05
I0506 04:37:07.096381 12834 solver.cpp:242] Iteration 48300 (106.759 iter/s, 0.936687s/100 iter), loss = 0.679797
I0506 04:37:07.096407 12834 solver.cpp:261]     Train net output #0: loss = 0.679797 (* 1 = 0.679797 loss)
I0506 04:37:07.096417 12834 sgd_solver.cpp:106] Iteration 48300, lr = 4.096e-05
I0506 04:37:08.028358 12834 solver.cpp:242] Iteration 48400 (106.762 iter/s, 0.936663s/100 iter), loss = 2.55758
I0506 04:37:08.028390 12834 solver.cpp:261]     Train net output #0: loss = 2.55758 (* 1 = 2.55758 loss)
I0506 04:37:08.028399 12834 sgd_solver.cpp:106] Iteration 48400, lr = 4.096e-05
I0506 04:37:08.033105 12834 solver.cpp:242] Iteration 48400 (106.76 iter/s, 0.936679s/100 iter), loss = 0.726515
I0506 04:37:08.033129 12834 solver.cpp:261]     Train net output #0: loss = 0.726515 (* 1 = 0.726515 loss)
I0506 04:37:08.033139 12834 sgd_solver.cpp:106] Iteration 48400, lr = 4.096e-05
I0506 04:37:08.962323 12834 solver.cpp:362] Iteration 48500, Testing net (#0)
I0506 04:37:08.962350 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:09.085052 12834 solver.cpp:429]     Test net output #0: loss = 2.0201 (* 1 = 2.0201 loss)
I0506 04:37:09.087564 12834 solver.cpp:242] Iteration 48500 (94.4148 iter/s, 1.05916s/100 iter), loss = 2.71318
I0506 04:37:09.087584 12834 solver.cpp:261]     Train net output #0: loss = 2.71318 (* 1 = 2.71318 loss)
I0506 04:37:09.087592 12834 sgd_solver.cpp:106] Iteration 48500, lr = 4.096e-05
I0506 04:37:09.089417 12834 solver.cpp:362] Iteration 48500, Testing net (#0)
I0506 04:37:09.089431 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:09.218472 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6875
I0506 04:37:09.218492 12834 solver.cpp:429]     Test net output #1: loss = 0.716181 (* 1 = 0.716181 loss)
I0506 04:37:09.221050 12834 solver.cpp:242] Iteration 48500 (84.1822 iter/s, 1.1879s/100 iter), loss = 0.658689
I0506 04:37:09.221071 12834 solver.cpp:261]     Train net output #0: loss = 0.658689 (* 1 = 0.658689 loss)
I0506 04:37:09.221079 12834 sgd_solver.cpp:106] Iteration 48500, lr = 4.096e-05
I0506 04:37:10.153246 12834 solver.cpp:242] Iteration 48600 (93.8405 iter/s, 1.06564s/100 iter), loss = 1.8285
I0506 04:37:10.153275 12834 solver.cpp:261]     Train net output #0: loss = 1.8285 (* 1 = 1.8285 loss)
I0506 04:37:10.153285 12834 sgd_solver.cpp:106] Iteration 48600, lr = 4.096e-05
I0506 04:37:10.158021 12834 solver.cpp:242] Iteration 48600 (106.731 iter/s, 0.936933s/100 iter), loss = 0.575062
I0506 04:37:10.158044 12834 solver.cpp:261]     Train net output #0: loss = 0.575062 (* 1 = 0.575062 loss)
I0506 04:37:10.158054 12834 sgd_solver.cpp:106] Iteration 48600, lr = 4.096e-05
I0506 04:37:11.144162 12834 solver.cpp:242] Iteration 48700 (100.923 iter/s, 0.990854s/100 iter), loss = 0.709438
I0506 04:37:11.144212 12834 solver.cpp:261]     Train net output #0: loss = 0.709438 (* 1 = 0.709438 loss)
I0506 04:37:11.144223 12834 sgd_solver.cpp:106] Iteration 48700, lr = 4.096e-05
I0506 04:37:11.149444 12834 solver.cpp:242] Iteration 48700 (100.87 iter/s, 0.991379s/100 iter), loss = 0.869893
I0506 04:37:11.149476 12834 solver.cpp:261]     Train net output #0: loss = 0.869893 (* 1 = 0.869893 loss)
I0506 04:37:11.149497 12834 sgd_solver.cpp:106] Iteration 48700, lr = 4.096e-05
I0506 04:37:12.179100 12834 solver.cpp:242] Iteration 48800 (96.6311 iter/s, 1.03486s/100 iter), loss = 1.6945
I0506 04:37:12.179152 12834 solver.cpp:261]     Train net output #0: loss = 1.6945 (* 1 = 1.6945 loss)
I0506 04:37:12.179215 12834 sgd_solver.cpp:106] Iteration 48800, lr = 4.096e-05
I0506 04:37:12.184087 12834 solver.cpp:242] Iteration 48800 (96.6571 iter/s, 1.03459s/100 iter), loss = 0.93175
I0506 04:37:12.184113 12834 solver.cpp:261]     Train net output #0: loss = 0.93175 (* 1 = 0.93175 loss)
I0506 04:37:12.184121 12834 sgd_solver.cpp:106] Iteration 48800, lr = 4.096e-05
I0506 04:37:13.115631 12834 solver.cpp:242] Iteration 48900 (106.786 iter/s, 0.936453s/100 iter), loss = 2.42219
I0506 04:37:13.115672 12834 solver.cpp:261]     Train net output #0: loss = 2.42219 (* 1 = 2.42219 loss)
I0506 04:37:13.115682 12834 sgd_solver.cpp:106] Iteration 48900, lr = 4.096e-05
I0506 04:37:13.120440 12834 solver.cpp:242] Iteration 48900 (106.802 iter/s, 0.936308s/100 iter), loss = 0.514287
I0506 04:37:13.120465 12834 solver.cpp:261]     Train net output #0: loss = 0.514287 (* 1 = 0.514287 loss)
I0506 04:37:13.120473 12834 sgd_solver.cpp:106] Iteration 48900, lr = 4.096e-05
I0506 04:37:14.050102 12834 solver.cpp:362] Iteration 49000, Testing net (#0)
I0506 04:37:14.050129 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:14.172871 12834 solver.cpp:429]     Test net output #0: loss = 1.93805 (* 1 = 1.93805 loss)
I0506 04:37:14.175395 12834 solver.cpp:242] Iteration 49000 (94.366 iter/s, 1.0597s/100 iter), loss = 2.48628
I0506 04:37:14.175417 12834 solver.cpp:261]     Train net output #0: loss = 2.48628 (* 1 = 2.48628 loss)
I0506 04:37:14.175426 12834 sgd_solver.cpp:106] Iteration 49000, lr = 4.096e-05
I0506 04:37:14.177251 12834 solver.cpp:362] Iteration 49000, Testing net (#0)
I0506 04:37:14.177264 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:14.305778 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7065
I0506 04:37:14.305799 12834 solver.cpp:429]     Test net output #1: loss = 0.699368 (* 1 = 0.699368 loss)
I0506 04:37:14.308364 12834 solver.cpp:242] Iteration 49000 (84.1837 iter/s, 1.18788s/100 iter), loss = 0.489564
I0506 04:37:14.308384 12834 solver.cpp:261]     Train net output #0: loss = 0.489564 (* 1 = 0.489564 loss)
I0506 04:37:14.308393 12834 sgd_solver.cpp:106] Iteration 49000, lr = 4.096e-05
I0506 04:37:15.239809 12834 solver.cpp:242] Iteration 49100 (93.9529 iter/s, 1.06436s/100 iter), loss = 1.42935
I0506 04:37:15.239848 12834 solver.cpp:261]     Train net output #0: loss = 1.42935 (* 1 = 1.42935 loss)
I0506 04:37:15.239858 12834 sgd_solver.cpp:106] Iteration 49100, lr = 4.096e-05
I0506 04:37:15.244570 12834 solver.cpp:242] Iteration 49100 (106.819 iter/s, 0.936167s/100 iter), loss = 0.639734
I0506 04:37:15.244596 12834 solver.cpp:261]     Train net output #0: loss = 0.639734 (* 1 = 0.639734 loss)
I0506 04:37:15.244604 12834 sgd_solver.cpp:106] Iteration 49100, lr = 4.096e-05
I0506 04:37:16.176884 12834 solver.cpp:242] Iteration 49200 (106.723 iter/s, 0.937004s/100 iter), loss = 2.91187
I0506 04:37:16.176925 12834 solver.cpp:261]     Train net output #0: loss = 2.91187 (* 1 = 2.91187 loss)
I0506 04:37:16.176935 12834 sgd_solver.cpp:106] Iteration 49200, lr = 4.096e-05
I0506 04:37:16.181646 12834 solver.cpp:242] Iteration 49200 (106.72 iter/s, 0.937034s/100 iter), loss = 0.711961
I0506 04:37:16.181671 12834 solver.cpp:261]     Train net output #0: loss = 0.711961 (* 1 = 0.711961 loss)
I0506 04:37:16.181680 12834 sgd_solver.cpp:106] Iteration 49200, lr = 4.096e-05
I0506 04:37:17.113467 12834 solver.cpp:242] Iteration 49300 (106.779 iter/s, 0.936517s/100 iter), loss = 0.615213
I0506 04:37:17.113504 12834 solver.cpp:261]     Train net output #0: loss = 0.615213 (* 1 = 0.615213 loss)
I0506 04:37:17.113514 12834 sgd_solver.cpp:106] Iteration 49300, lr = 4.096e-05
I0506 04:37:17.118253 12834 solver.cpp:242] Iteration 49300 (106.773 iter/s, 0.936564s/100 iter), loss = 0.501747
I0506 04:37:17.118289 12834 solver.cpp:261]     Train net output #0: loss = 0.501747 (* 1 = 0.501747 loss)
I0506 04:37:17.118299 12834 sgd_solver.cpp:106] Iteration 49300, lr = 4.096e-05
I0506 04:37:18.050973 12834 solver.cpp:242] Iteration 49400 (106.673 iter/s, 0.93744s/100 iter), loss = 3.06944
I0506 04:37:18.051015 12834 solver.cpp:261]     Train net output #0: loss = 3.06944 (* 1 = 3.06944 loss)
I0506 04:37:18.051025 12834 sgd_solver.cpp:106] Iteration 49400, lr = 4.096e-05
I0506 04:37:18.055786 12834 solver.cpp:242] Iteration 49400 (106.669 iter/s, 0.937479s/100 iter), loss = 0.740913
I0506 04:37:18.055812 12834 solver.cpp:261]     Train net output #0: loss = 0.740913 (* 1 = 0.740913 loss)
I0506 04:37:18.055821 12834 sgd_solver.cpp:106] Iteration 49400, lr = 4.096e-05
I0506 04:37:18.984895 12834 solver.cpp:362] Iteration 49500, Testing net (#0)
I0506 04:37:18.984920 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:19.107522 12834 solver.cpp:429]     Test net output #0: loss = 2.17583 (* 1 = 2.17583 loss)
I0506 04:37:19.110049 12834 solver.cpp:242] Iteration 49500 (94.4272 iter/s, 1.05902s/100 iter), loss = 1.85162
I0506 04:37:19.110071 12834 solver.cpp:261]     Train net output #0: loss = 1.85162 (* 1 = 1.85162 loss)
I0506 04:37:19.110080 12834 sgd_solver.cpp:106] Iteration 49500, lr = 4.096e-05
I0506 04:37:19.111882 12834 solver.cpp:362] Iteration 49500, Testing net (#0)
I0506 04:37:19.111896 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:19.240995 12834 solver.cpp:429]     Test net output #0: accuracy = 0.683
I0506 04:37:19.241015 12834 solver.cpp:429]     Test net output #1: loss = 0.76709 (* 1 = 0.76709 loss)
I0506 04:37:19.243579 12834 solver.cpp:242] Iteration 49500 (84.1931 iter/s, 1.18775s/100 iter), loss = 0.733179
I0506 04:37:19.243599 12834 solver.cpp:261]     Train net output #0: loss = 0.733179 (* 1 = 0.733179 loss)
I0506 04:37:19.243608 12834 sgd_solver.cpp:106] Iteration 49500, lr = 4.096e-05
I0506 04:37:20.175943 12834 solver.cpp:242] Iteration 49600 (93.8226 iter/s, 1.06584s/100 iter), loss = 1.96082
I0506 04:37:20.175981 12834 solver.cpp:261]     Train net output #0: loss = 1.96082 (* 1 = 1.96082 loss)
I0506 04:37:20.175992 12834 sgd_solver.cpp:106] Iteration 49600, lr = 4.096e-05
I0506 04:37:20.180726 12834 solver.cpp:242] Iteration 49600 (106.711 iter/s, 0.937106s/100 iter), loss = 0.665485
I0506 04:37:20.180750 12834 solver.cpp:261]     Train net output #0: loss = 0.665485 (* 1 = 0.665485 loss)
I0506 04:37:20.180759 12834 sgd_solver.cpp:106] Iteration 49600, lr = 4.096e-05
I0506 04:37:21.112517 12834 solver.cpp:242] Iteration 49700 (106.779 iter/s, 0.936513s/100 iter), loss = 2.23615
I0506 04:37:21.112555 12834 solver.cpp:261]     Train net output #0: loss = 2.23615 (* 1 = 2.23615 loss)
I0506 04:37:21.112565 12834 sgd_solver.cpp:106] Iteration 49700, lr = 4.096e-05
I0506 04:37:21.117377 12834 solver.cpp:242] Iteration 49700 (106.769 iter/s, 0.936599s/100 iter), loss = 0.807451
I0506 04:37:21.117403 12834 solver.cpp:261]     Train net output #0: loss = 0.807451 (* 1 = 0.807451 loss)
I0506 04:37:21.117411 12834 sgd_solver.cpp:106] Iteration 49700, lr = 4.096e-05
I0506 04:37:22.049532 12834 solver.cpp:242] Iteration 49800 (106.729 iter/s, 0.936957s/100 iter), loss = 1.25673
I0506 04:37:22.049562 12834 solver.cpp:261]     Train net output #0: loss = 1.25673 (* 1 = 1.25673 loss)
I0506 04:37:22.049572 12834 sgd_solver.cpp:106] Iteration 49800, lr = 4.096e-05
I0506 04:37:22.054321 12834 solver.cpp:242] Iteration 49800 (106.735 iter/s, 0.9369s/100 iter), loss = 0.793787
I0506 04:37:22.054343 12834 solver.cpp:261]     Train net output #0: loss = 0.793787 (* 1 = 0.793787 loss)
I0506 04:37:22.054352 12834 sgd_solver.cpp:106] Iteration 49800, lr = 4.096e-05
I0506 04:37:23.029995 12834 solver.cpp:242] Iteration 49900 (101.999 iter/s, 0.980398s/100 iter), loss = 1.13384
I0506 04:37:23.030050 12834 solver.cpp:261]     Train net output #0: loss = 1.13384 (* 1 = 1.13384 loss)
I0506 04:37:23.030262 12834 sgd_solver.cpp:106] Iteration 49900, lr = 4.096e-05
I0506 04:37:23.035069 12834 solver.cpp:242] Iteration 49900 (101.967 iter/s, 0.980705s/100 iter), loss = 0.592708
I0506 04:37:23.035095 12834 solver.cpp:261]     Train net output #0: loss = 0.592708 (* 1 = 0.592708 loss)
I0506 04:37:23.035104 12834 sgd_solver.cpp:106] Iteration 49900, lr = 4.096e-05
I0506 04:37:23.957973 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_50000.caffemodel
I0506 04:37:23.980808 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_50000.solverstate
I0506 04:37:23.994195 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_50000.caffemodel
I0506 04:37:24.015530 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_50000.solverstate
I0506 04:37:24.025923 12834 solver.cpp:362] Iteration 50000, Testing net (#0)
I0506 04:37:24.025950 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:24.148888 12834 solver.cpp:429]     Test net output #0: loss = 1.86177 (* 1 = 1.86177 loss)
I0506 04:37:24.151415 12834 solver.cpp:242] Iteration 50000 (89.1783 iter/s, 1.12135s/100 iter), loss = 0.831272
I0506 04:37:24.151435 12834 solver.cpp:261]     Train net output #0: loss = 0.831272 (* 1 = 0.831272 loss)
I0506 04:37:24.151444 12834 sgd_solver.cpp:106] Iteration 50000, lr = 3.2768e-05
I0506 04:37:24.153331 12834 solver.cpp:362] Iteration 50000, Testing net (#0)
I0506 04:37:24.153342 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:24.282171 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6885
I0506 04:37:24.282188 12834 solver.cpp:429]     Test net output #1: loss = 0.726123 (* 1 = 0.726123 loss)
I0506 04:37:24.284755 12834 solver.cpp:242] Iteration 50000 (80.0231 iter/s, 1.24964s/100 iter), loss = 0.638531
I0506 04:37:24.284775 12834 solver.cpp:261]     Train net output #0: loss = 0.638531 (* 1 = 0.638531 loss)
I0506 04:37:24.284785 12834 sgd_solver.cpp:106] Iteration 50000, lr = 3.2768e-05
I0506 04:37:25.217162 12834 solver.cpp:242] Iteration 50100 (93.8357 iter/s, 1.06569s/100 iter), loss = 1.6002
I0506 04:37:25.217195 12834 solver.cpp:261]     Train net output #0: loss = 1.6002 (* 1 = 1.6002 loss)
I0506 04:37:25.217206 12834 sgd_solver.cpp:106] Iteration 50100, lr = 3.2768e-05
I0506 04:37:25.221932 12834 solver.cpp:242] Iteration 50100 (106.708 iter/s, 0.937137s/100 iter), loss = 0.55581
I0506 04:37:25.221957 12834 solver.cpp:261]     Train net output #0: loss = 0.55581 (* 1 = 0.55581 loss)
I0506 04:37:25.221966 12834 sgd_solver.cpp:106] Iteration 50100, lr = 3.2768e-05
I0506 04:37:26.154140 12834 solver.cpp:242] Iteration 50200 (106.733 iter/s, 0.93692s/100 iter), loss = 2.5486
I0506 04:37:26.154173 12834 solver.cpp:261]     Train net output #0: loss = 2.5486 (* 1 = 2.5486 loss)
I0506 04:37:26.154182 12834 sgd_solver.cpp:106] Iteration 50200, lr = 3.2768e-05
I0506 04:37:26.158916 12834 solver.cpp:242] Iteration 50200 (106.73 iter/s, 0.936941s/100 iter), loss = 0.683449
I0506 04:37:26.158939 12834 solver.cpp:261]     Train net output #0: loss = 0.683449 (* 1 = 0.683449 loss)
I0506 04:37:26.158947 12834 sgd_solver.cpp:106] Iteration 50200, lr = 3.2768e-05
I0506 04:37:27.105725 12834 solver.cpp:242] Iteration 50300 (105.095 iter/s, 0.95152s/100 iter), loss = 3.82632
I0506 04:37:27.105774 12834 solver.cpp:261]     Train net output #0: loss = 3.82632 (* 1 = 3.82632 loss)
I0506 04:37:27.105784 12834 sgd_solver.cpp:106] Iteration 50300, lr = 3.2768e-05
I0506 04:37:27.110502 12834 solver.cpp:242] Iteration 50300 (105.092 iter/s, 0.951544s/100 iter), loss = 0.771
I0506 04:37:27.110527 12834 solver.cpp:261]     Train net output #0: loss = 0.771 (* 1 = 0.771 loss)
I0506 04:37:27.110535 12834 sgd_solver.cpp:106] Iteration 50300, lr = 3.2768e-05
I0506 04:37:28.043254 12834 solver.cpp:242] Iteration 50400 (106.672 iter/s, 0.937456s/100 iter), loss = 1.34514
I0506 04:37:28.043304 12834 solver.cpp:261]     Train net output #0: loss = 1.34514 (* 1 = 1.34514 loss)
I0506 04:37:28.043632 12834 sgd_solver.cpp:106] Iteration 50400, lr = 3.2768e-05
I0506 04:37:28.048422 12834 solver.cpp:242] Iteration 50400 (106.624 iter/s, 0.937878s/100 iter), loss = 0.479597
I0506 04:37:28.048449 12834 solver.cpp:261]     Train net output #0: loss = 0.479597 (* 1 = 0.479597 loss)
I0506 04:37:28.048458 12834 sgd_solver.cpp:106] Iteration 50400, lr = 3.2768e-05
I0506 04:37:28.978366 12834 solver.cpp:362] Iteration 50500, Testing net (#0)
I0506 04:37:28.978394 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:29.101194 12834 solver.cpp:429]     Test net output #0: loss = 1.76225 (* 1 = 1.76225 loss)
I0506 04:37:29.103708 12834 solver.cpp:242] Iteration 50500 (94.3051 iter/s, 1.06039s/100 iter), loss = 1.1864
I0506 04:37:29.103732 12834 solver.cpp:261]     Train net output #0: loss = 1.1864 (* 1 = 1.1864 loss)
I0506 04:37:29.103742 12834 sgd_solver.cpp:106] Iteration 50500, lr = 3.2768e-05
I0506 04:37:29.105557 12834 solver.cpp:362] Iteration 50500, Testing net (#0)
I0506 04:37:29.105571 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:29.234230 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7245
I0506 04:37:29.234249 12834 solver.cpp:429]     Test net output #1: loss = 0.636084 (* 1 = 0.636084 loss)
I0506 04:37:29.236795 12834 solver.cpp:242] Iteration 50500 (84.152 iter/s, 1.18833s/100 iter), loss = 0.69265
I0506 04:37:29.236817 12834 solver.cpp:261]     Train net output #0: loss = 0.69265 (* 1 = 0.69265 loss)
I0506 04:37:29.236826 12834 sgd_solver.cpp:106] Iteration 50500, lr = 3.2768e-05
I0506 04:37:30.169332 12834 solver.cpp:242] Iteration 50600 (93.8463 iter/s, 1.06557s/100 iter), loss = 2.51065
I0506 04:37:30.169373 12834 solver.cpp:261]     Train net output #0: loss = 2.51065 (* 1 = 2.51065 loss)
I0506 04:37:30.169383 12834 sgd_solver.cpp:106] Iteration 50600, lr = 3.2768e-05
I0506 04:37:30.174196 12834 solver.cpp:242] Iteration 50600 (106.684 iter/s, 0.937351s/100 iter), loss = 0.711655
I0506 04:37:30.174222 12834 solver.cpp:261]     Train net output #0: loss = 0.711655 (* 1 = 0.711655 loss)
I0506 04:37:30.174232 12834 sgd_solver.cpp:106] Iteration 50600, lr = 3.2768e-05
I0506 04:37:31.161950 12834 solver.cpp:242] Iteration 50700 (100.751 iter/s, 0.992549s/100 iter), loss = 2.3025
I0506 04:37:31.161998 12834 solver.cpp:261]     Train net output #0: loss = 2.3025 (* 1 = 2.3025 loss)
I0506 04:37:31.162009 12834 sgd_solver.cpp:106] Iteration 50700, lr = 3.2768e-05
I0506 04:37:31.167237 12834 solver.cpp:242] Iteration 50700 (100.705 iter/s, 0.992995s/100 iter), loss = 0.993382
I0506 04:37:31.167269 12834 solver.cpp:261]     Train net output #0: loss = 0.993382 (* 1 = 0.993382 loss)
I0506 04:37:31.167280 12834 sgd_solver.cpp:106] Iteration 50700, lr = 3.2768e-05
I0506 04:37:32.197335 12834 solver.cpp:242] Iteration 50800 (96.5892 iter/s, 1.03531s/100 iter), loss = 0.767443
I0506 04:37:32.197381 12834 solver.cpp:261]     Train net output #0: loss = 0.767443 (* 1 = 0.767443 loss)
I0506 04:37:32.197393 12834 sgd_solver.cpp:106] Iteration 50800, lr = 3.2768e-05
I0506 04:37:32.202591 12834 solver.cpp:242] Iteration 50800 (96.591 iter/s, 1.03529s/100 iter), loss = 0.431706
I0506 04:37:32.202622 12834 solver.cpp:261]     Train net output #0: loss = 0.431706 (* 1 = 0.431706 loss)
I0506 04:37:32.202633 12834 sgd_solver.cpp:106] Iteration 50800, lr = 3.2768e-05
I0506 04:37:33.184259 12834 solver.cpp:242] Iteration 50900 (101.332 iter/s, 0.986852s/100 iter), loss = 2.82761
I0506 04:37:33.184303 12834 solver.cpp:261]     Train net output #0: loss = 2.82761 (* 1 = 2.82761 loss)
I0506 04:37:33.184370 12834 sgd_solver.cpp:106] Iteration 50900, lr = 3.2768e-05
I0506 04:37:33.189198 12834 solver.cpp:242] Iteration 50900 (101.363 iter/s, 0.986557s/100 iter), loss = 0.456697
I0506 04:37:33.189223 12834 solver.cpp:261]     Train net output #0: loss = 0.456697 (* 1 = 0.456697 loss)
I0506 04:37:33.189231 12834 sgd_solver.cpp:106] Iteration 50900, lr = 3.2768e-05
I0506 04:37:34.119037 12834 solver.cpp:362] Iteration 51000, Testing net (#0)
I0506 04:37:34.119061 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:34.241746 12834 solver.cpp:429]     Test net output #0: loss = 1.86092 (* 1 = 1.86092 loss)
I0506 04:37:34.244278 12834 solver.cpp:242] Iteration 51000 (94.3434 iter/s, 1.05996s/100 iter), loss = 2.22097
I0506 04:37:34.244299 12834 solver.cpp:261]     Train net output #0: loss = 2.22097 (* 1 = 2.22097 loss)
I0506 04:37:34.244308 12834 sgd_solver.cpp:106] Iteration 51000, lr = 3.2768e-05
I0506 04:37:34.246124 12834 solver.cpp:362] Iteration 51000, Testing net (#0)
I0506 04:37:34.246137 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:34.374959 12834 solver.cpp:429]     Test net output #0: accuracy = 0.704
I0506 04:37:34.374979 12834 solver.cpp:429]     Test net output #1: loss = 0.681955 (* 1 = 0.681955 loss)
I0506 04:37:34.377535 12834 solver.cpp:242] Iteration 51000 (84.1544 iter/s, 1.18829s/100 iter), loss = 0.897059
I0506 04:37:34.377557 12834 solver.cpp:261]     Train net output #0: loss = 0.897059 (* 1 = 0.897059 loss)
I0506 04:37:34.377565 12834 sgd_solver.cpp:106] Iteration 51000, lr = 3.2768e-05
I0506 04:37:35.386113 12834 solver.cpp:242] Iteration 51100 (87.5823 iter/s, 1.14178s/100 iter), loss = 2.96607
I0506 04:37:35.386149 12834 solver.cpp:261]     Train net output #0: loss = 2.96607 (* 1 = 2.96607 loss)
I0506 04:37:35.386159 12834 sgd_solver.cpp:106] Iteration 51100, lr = 3.2768e-05
I0506 04:37:35.390923 12834 solver.cpp:242] Iteration 51100 (98.6829 iter/s, 1.01335s/100 iter), loss = 0.936517
I0506 04:37:35.390949 12834 solver.cpp:261]     Train net output #0: loss = 0.936517 (* 1 = 0.936517 loss)
I0506 04:37:35.390959 12834 sgd_solver.cpp:106] Iteration 51100, lr = 3.2768e-05
I0506 04:37:36.323995 12834 solver.cpp:242] Iteration 51200 (106.631 iter/s, 0.937814s/100 iter), loss = 0.723789
I0506 04:37:36.324033 12834 solver.cpp:261]     Train net output #0: loss = 0.723789 (* 1 = 0.723789 loss)
I0506 04:37:36.324043 12834 sgd_solver.cpp:106] Iteration 51200, lr = 3.2768e-05
I0506 04:37:36.328856 12834 solver.cpp:242] Iteration 51200 (106.623 iter/s, 0.937888s/100 iter), loss = 0.769328
I0506 04:37:36.328881 12834 solver.cpp:261]     Train net output #0: loss = 0.769328 (* 1 = 0.769328 loss)
I0506 04:37:36.328891 12834 sgd_solver.cpp:106] Iteration 51200, lr = 3.2768e-05
I0506 04:37:37.261831 12834 solver.cpp:242] Iteration 51300 (106.636 iter/s, 0.937773s/100 iter), loss = 0.915184
I0506 04:37:37.261864 12834 solver.cpp:261]     Train net output #0: loss = 0.915184 (* 1 = 0.915184 loss)
I0506 04:37:37.261874 12834 sgd_solver.cpp:106] Iteration 51300, lr = 3.2768e-05
I0506 04:37:37.266602 12834 solver.cpp:242] Iteration 51300 (106.644 iter/s, 0.937702s/100 iter), loss = 0.468144
I0506 04:37:37.266625 12834 solver.cpp:261]     Train net output #0: loss = 0.468144 (* 1 = 0.468144 loss)
I0506 04:37:37.266634 12834 sgd_solver.cpp:106] Iteration 51300, lr = 3.2768e-05
I0506 04:37:38.199038 12834 solver.cpp:242] Iteration 51400 (106.707 iter/s, 0.937143s/100 iter), loss = 2.76442
I0506 04:37:38.199067 12834 solver.cpp:261]     Train net output #0: loss = 2.76442 (* 1 = 2.76442 loss)
I0506 04:37:38.199076 12834 sgd_solver.cpp:106] Iteration 51400, lr = 3.2768e-05
I0506 04:37:38.203797 12834 solver.cpp:242] Iteration 51400 (106.706 iter/s, 0.937153s/100 iter), loss = 0.578293
I0506 04:37:38.203820 12834 solver.cpp:261]     Train net output #0: loss = 0.578293 (* 1 = 0.578293 loss)
I0506 04:37:38.203837 12834 sgd_solver.cpp:106] Iteration 51400, lr = 3.2768e-05
I0506 04:37:39.133927 12834 solver.cpp:362] Iteration 51500, Testing net (#0)
I0506 04:37:39.133955 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:39.256566 12834 solver.cpp:429]     Test net output #0: loss = 1.61485 (* 1 = 1.61485 loss)
I0506 04:37:39.259080 12834 solver.cpp:242] Iteration 51500 (94.3402 iter/s, 1.05999s/100 iter), loss = 5.79279
I0506 04:37:39.259099 12834 solver.cpp:261]     Train net output #0: loss = 5.79279 (* 1 = 5.79279 loss)
I0506 04:37:39.259109 12834 sgd_solver.cpp:106] Iteration 51500, lr = 3.2768e-05
I0506 04:37:39.261024 12834 solver.cpp:362] Iteration 51500, Testing net (#0)
I0506 04:37:39.261039 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:39.389693 12834 solver.cpp:429]     Test net output #0: accuracy = 0.717
I0506 04:37:39.389713 12834 solver.cpp:429]     Test net output #1: loss = 0.677743 (* 1 = 0.677743 loss)
I0506 04:37:39.392272 12834 solver.cpp:242] Iteration 51500 (84.1445 iter/s, 1.18843s/100 iter), loss = 0.654557
I0506 04:37:39.392292 12834 solver.cpp:261]     Train net output #0: loss = 0.654557 (* 1 = 0.654557 loss)
I0506 04:37:39.392302 12834 sgd_solver.cpp:106] Iteration 51500, lr = 3.2768e-05
I0506 04:37:40.324985 12834 solver.cpp:242] Iteration 51600 (93.8214 iter/s, 1.06586s/100 iter), loss = 2.39521
I0506 04:37:40.325017 12834 solver.cpp:261]     Train net output #0: loss = 2.39521 (* 1 = 2.39521 loss)
I0506 04:37:40.325026 12834 sgd_solver.cpp:106] Iteration 51600, lr = 3.2768e-05
I0506 04:37:40.329751 12834 solver.cpp:242] Iteration 51600 (106.674 iter/s, 0.937439s/100 iter), loss = 0.671618
I0506 04:37:40.329777 12834 solver.cpp:261]     Train net output #0: loss = 0.671618 (* 1 = 0.671618 loss)
I0506 04:37:40.329785 12834 sgd_solver.cpp:106] Iteration 51600, lr = 3.2768e-05
I0506 04:37:41.262620 12834 solver.cpp:242] Iteration 51700 (106.658 iter/s, 0.937581s/100 iter), loss = 2.15733
I0506 04:37:41.262650 12834 solver.cpp:261]     Train net output #0: loss = 2.15733 (* 1 = 2.15733 loss)
I0506 04:37:41.262658 12834 sgd_solver.cpp:106] Iteration 51700, lr = 3.2768e-05
I0506 04:37:41.267455 12834 solver.cpp:242] Iteration 51700 (106.649 iter/s, 0.937652s/100 iter), loss = 0.6006
I0506 04:37:41.267478 12834 solver.cpp:261]     Train net output #0: loss = 0.6006 (* 1 = 0.6006 loss)
I0506 04:37:41.267488 12834 sgd_solver.cpp:106] Iteration 51700, lr = 3.2768e-05
I0506 04:37:42.221079 12834 solver.cpp:242] Iteration 51800 (104.341 iter/s, 0.958399s/100 iter), loss = 0.422901
I0506 04:37:42.221124 12834 solver.cpp:261]     Train net output #0: loss = 0.422901 (* 1 = 0.422901 loss)
I0506 04:37:42.221133 12834 sgd_solver.cpp:106] Iteration 51800, lr = 3.2768e-05
I0506 04:37:42.225847 12834 solver.cpp:242] Iteration 51800 (104.346 iter/s, 0.958349s/100 iter), loss = 0.398116
I0506 04:37:42.225875 12834 solver.cpp:261]     Train net output #0: loss = 0.398116 (* 1 = 0.398116 loss)
I0506 04:37:42.225885 12834 sgd_solver.cpp:106] Iteration 51800, lr = 3.2768e-05
I0506 04:37:43.158738 12834 solver.cpp:242] Iteration 51900 (106.657 iter/s, 0.937582s/100 iter), loss = 0.762212
I0506 04:37:43.158778 12834 solver.cpp:261]     Train net output #0: loss = 0.762212 (* 1 = 0.762212 loss)
I0506 04:37:43.158787 12834 sgd_solver.cpp:106] Iteration 51900, lr = 3.2768e-05
I0506 04:37:43.163555 12834 solver.cpp:242] Iteration 51900 (106.648 iter/s, 0.937662s/100 iter), loss = 0.568708
I0506 04:37:43.163581 12834 solver.cpp:261]     Train net output #0: loss = 0.568708 (* 1 = 0.568708 loss)
I0506 04:37:43.163590 12834 sgd_solver.cpp:106] Iteration 51900, lr = 3.2768e-05
I0506 04:37:44.093791 12834 solver.cpp:362] Iteration 52000, Testing net (#0)
I0506 04:37:44.093818 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:44.216471 12834 solver.cpp:429]     Test net output #0: loss = 1.75397 (* 1 = 1.75397 loss)
I0506 04:37:44.219009 12834 solver.cpp:242] Iteration 52000 (94.3207 iter/s, 1.06021s/100 iter), loss = 2.05909
I0506 04:37:44.219043 12834 solver.cpp:261]     Train net output #0: loss = 2.05909 (* 1 = 2.05909 loss)
I0506 04:37:44.219051 12834 sgd_solver.cpp:106] Iteration 52000, lr = 3.2768e-05
I0506 04:37:44.220911 12834 solver.cpp:362] Iteration 52000, Testing net (#0)
I0506 04:37:44.220927 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:44.349535 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7085
I0506 04:37:44.349556 12834 solver.cpp:429]     Test net output #1: loss = 0.704276 (* 1 = 0.704276 loss)
I0506 04:37:44.352110 12834 solver.cpp:242] Iteration 52000 (84.1391 iter/s, 1.18851s/100 iter), loss = 0.740804
I0506 04:37:44.352130 12834 solver.cpp:261]     Train net output #0: loss = 0.740804 (* 1 = 0.740804 loss)
I0506 04:37:44.352139 12834 sgd_solver.cpp:106] Iteration 52000, lr = 3.2768e-05
I0506 04:37:45.285507 12834 solver.cpp:242] Iteration 52100 (93.7708 iter/s, 1.06643s/100 iter), loss = 1.37126
I0506 04:37:45.285548 12834 solver.cpp:261]     Train net output #0: loss = 1.37126 (* 1 = 1.37126 loss)
I0506 04:37:45.285557 12834 sgd_solver.cpp:106] Iteration 52100, lr = 3.2768e-05
I0506 04:37:45.290293 12834 solver.cpp:242] Iteration 52100 (106.593 iter/s, 0.938144s/100 iter), loss = 0.557179
I0506 04:37:45.290320 12834 solver.cpp:261]     Train net output #0: loss = 0.557179 (* 1 = 0.557179 loss)
I0506 04:37:45.290329 12834 sgd_solver.cpp:106] Iteration 52100, lr = 3.2768e-05
I0506 04:37:46.223218 12834 solver.cpp:242] Iteration 52200 (106.65 iter/s, 0.937645s/100 iter), loss = 1.75237
I0506 04:37:46.223258 12834 solver.cpp:261]     Train net output #0: loss = 1.75237 (* 1 = 1.75237 loss)
I0506 04:37:46.223268 12834 sgd_solver.cpp:106] Iteration 52200, lr = 3.2768e-05
I0506 04:37:46.228019 12834 solver.cpp:242] Iteration 52200 (106.646 iter/s, 0.937681s/100 iter), loss = 0.468234
I0506 04:37:46.228044 12834 solver.cpp:261]     Train net output #0: loss = 0.468234 (* 1 = 0.468234 loss)
I0506 04:37:46.228052 12834 sgd_solver.cpp:106] Iteration 52200, lr = 3.2768e-05
I0506 04:37:47.222800 12834 solver.cpp:242] Iteration 52300 (100.049 iter/s, 0.999508s/100 iter), loss = 1.64224
I0506 04:37:47.222844 12834 solver.cpp:261]     Train net output #0: loss = 1.64224 (* 1 = 1.64224 loss)
I0506 04:37:47.222856 12834 sgd_solver.cpp:106] Iteration 52300, lr = 3.2768e-05
I0506 04:37:47.228081 12834 solver.cpp:242] Iteration 52300 (99.9982 iter/s, 1.00002s/100 iter), loss = 0.894831
I0506 04:37:47.228112 12834 solver.cpp:261]     Train net output #0: loss = 0.894831 (* 1 = 0.894831 loss)
I0506 04:37:47.228123 12834 sgd_solver.cpp:106] Iteration 52300, lr = 3.2768e-05
I0506 04:37:48.258919 12834 solver.cpp:242] Iteration 52400 (96.5205 iter/s, 1.03605s/100 iter), loss = 1.65587
I0506 04:37:48.258962 12834 solver.cpp:261]     Train net output #0: loss = 1.65587 (* 1 = 1.65587 loss)
I0506 04:37:48.258973 12834 sgd_solver.cpp:106] Iteration 52400, lr = 3.2768e-05
I0506 04:37:48.264323 12834 solver.cpp:242] Iteration 52400 (96.5085 iter/s, 1.03618s/100 iter), loss = 1.00056
I0506 04:37:48.264353 12834 solver.cpp:261]     Train net output #0: loss = 1.00056 (* 1 = 1.00056 loss)
I0506 04:37:48.264364 12834 sgd_solver.cpp:106] Iteration 52400, lr = 3.2768e-05
I0506 04:37:49.258921 12834 solver.cpp:362] Iteration 52500, Testing net (#0)
I0506 04:37:49.258949 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:49.381693 12834 solver.cpp:429]     Test net output #0: loss = 1.86147 (* 1 = 1.86147 loss)
I0506 04:37:49.384207 12834 solver.cpp:242] Iteration 52500 (88.8711 iter/s, 1.12523s/100 iter), loss = 0.780094
I0506 04:37:49.384230 12834 solver.cpp:261]     Train net output #0: loss = 0.780094 (* 1 = 0.780094 loss)
I0506 04:37:49.384238 12834 sgd_solver.cpp:106] Iteration 52500, lr = 3.2768e-05
I0506 04:37:49.386056 12834 solver.cpp:362] Iteration 52500, Testing net (#0)
I0506 04:37:49.386070 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:49.514772 12834 solver.cpp:429]     Test net output #0: accuracy = 0.731
I0506 04:37:49.514793 12834 solver.cpp:429]     Test net output #1: loss = 0.637998 (* 1 = 0.637998 loss)
I0506 04:37:49.517367 12834 solver.cpp:242] Iteration 52500 (79.8088 iter/s, 1.253s/100 iter), loss = 0.684052
I0506 04:37:49.517390 12834 solver.cpp:261]     Train net output #0: loss = 0.684052 (* 1 = 0.684052 loss)
I0506 04:37:49.517398 12834 sgd_solver.cpp:106] Iteration 52500, lr = 3.2768e-05
I0506 04:37:50.462335 12834 solver.cpp:242] Iteration 52600 (92.7575 iter/s, 1.07808s/100 iter), loss = 1.42658
I0506 04:37:50.462373 12834 solver.cpp:261]     Train net output #0: loss = 1.42658 (* 1 = 1.42658 loss)
I0506 04:37:50.462383 12834 sgd_solver.cpp:106] Iteration 52600, lr = 3.2768e-05
I0506 04:37:50.467175 12834 solver.cpp:242] Iteration 52600 (105.29 iter/s, 0.949758s/100 iter), loss = 0.62387
I0506 04:37:50.467201 12834 solver.cpp:261]     Train net output #0: loss = 0.62387 (* 1 = 0.62387 loss)
I0506 04:37:50.467211 12834 sgd_solver.cpp:106] Iteration 52600, lr = 3.2768e-05
I0506 04:37:51.413923 12834 solver.cpp:242] Iteration 52700 (105.095 iter/s, 0.951524s/100 iter), loss = 1.94156
I0506 04:37:51.413962 12834 solver.cpp:261]     Train net output #0: loss = 1.94156 (* 1 = 1.94156 loss)
I0506 04:37:51.413971 12834 sgd_solver.cpp:106] Iteration 52700, lr = 3.2768e-05
I0506 04:37:51.418699 12834 solver.cpp:242] Iteration 52700 (105.1 iter/s, 0.951478s/100 iter), loss = 0.673106
I0506 04:37:51.418725 12834 solver.cpp:261]     Train net output #0: loss = 0.673106 (* 1 = 0.673106 loss)
I0506 04:37:51.418733 12834 sgd_solver.cpp:106] Iteration 52700, lr = 3.2768e-05
I0506 04:37:52.351377 12834 solver.cpp:242] Iteration 52800 (106.68 iter/s, 0.937384s/100 iter), loss = 0.884831
I0506 04:37:52.351414 12834 solver.cpp:261]     Train net output #0: loss = 0.884831 (* 1 = 0.884831 loss)
I0506 04:37:52.351424 12834 sgd_solver.cpp:106] Iteration 52800, lr = 3.2768e-05
I0506 04:37:52.356160 12834 solver.cpp:242] Iteration 52800 (106.676 iter/s, 0.937419s/100 iter), loss = 0.489675
I0506 04:37:52.356185 12834 solver.cpp:261]     Train net output #0: loss = 0.489675 (* 1 = 0.489675 loss)
I0506 04:37:52.356194 12834 sgd_solver.cpp:106] Iteration 52800, lr = 3.2768e-05
I0506 04:37:53.289373 12834 solver.cpp:242] Iteration 52900 (106.617 iter/s, 0.937935s/100 iter), loss = 2.26434
I0506 04:37:53.289403 12834 solver.cpp:261]     Train net output #0: loss = 2.26434 (* 1 = 2.26434 loss)
I0506 04:37:53.289412 12834 sgd_solver.cpp:106] Iteration 52900, lr = 3.2768e-05
I0506 04:37:53.294152 12834 solver.cpp:242] Iteration 52900 (106.616 iter/s, 0.937947s/100 iter), loss = 0.728025
I0506 04:37:53.294174 12834 solver.cpp:261]     Train net output #0: loss = 0.728025 (* 1 = 0.728025 loss)
I0506 04:37:53.294183 12834 sgd_solver.cpp:106] Iteration 52900, lr = 3.2768e-05
I0506 04:37:54.315835 12834 solver.cpp:362] Iteration 53000, Testing net (#0)
I0506 04:37:54.315871 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:54.438947 12834 solver.cpp:429]     Test net output #0: loss = 1.76488 (* 1 = 1.76488 loss)
I0506 04:37:54.441470 12834 solver.cpp:242] Iteration 53000 (86.802 iter/s, 1.15205s/100 iter), loss = 2.7099
I0506 04:37:54.441493 12834 solver.cpp:261]     Train net output #0: loss = 2.7099 (* 1 = 2.7099 loss)
I0506 04:37:54.441501 12834 sgd_solver.cpp:106] Iteration 53000, lr = 3.2768e-05
I0506 04:37:54.443333 12834 solver.cpp:362] Iteration 53000, Testing net (#0)
I0506 04:37:54.443346 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:54.571921 12834 solver.cpp:429]     Test net output #0: accuracy = 0.713
I0506 04:37:54.571940 12834 solver.cpp:429]     Test net output #1: loss = 0.65913 (* 1 = 0.65913 loss)
I0506 04:37:54.574512 12834 solver.cpp:242] Iteration 53000 (78.1057 iter/s, 1.28032s/100 iter), loss = 0.529083
I0506 04:37:54.574533 12834 solver.cpp:261]     Train net output #0: loss = 0.529083 (* 1 = 0.529083 loss)
I0506 04:37:54.574542 12834 sgd_solver.cpp:106] Iteration 53000, lr = 3.2768e-05
I0506 04:37:55.507577 12834 solver.cpp:242] Iteration 53100 (93.8036 iter/s, 1.06606s/100 iter), loss = 3.05534
I0506 04:37:55.507611 12834 solver.cpp:261]     Train net output #0: loss = 3.05534 (* 1 = 3.05534 loss)
I0506 04:37:55.507632 12834 sgd_solver.cpp:106] Iteration 53100, lr = 3.2768e-05
I0506 04:37:55.512353 12834 solver.cpp:242] Iteration 53100 (106.632 iter/s, 0.937801s/100 iter), loss = 0.564487
I0506 04:37:55.512379 12834 solver.cpp:261]     Train net output #0: loss = 0.564487 (* 1 = 0.564487 loss)
I0506 04:37:55.512388 12834 sgd_solver.cpp:106] Iteration 53100, lr = 3.2768e-05
I0506 04:37:56.444957 12834 solver.cpp:242] Iteration 53200 (106.688 iter/s, 0.937315s/100 iter), loss = 1.75828
I0506 04:37:56.444988 12834 solver.cpp:261]     Train net output #0: loss = 1.75828 (* 1 = 1.75828 loss)
I0506 04:37:56.444998 12834 sgd_solver.cpp:106] Iteration 53200, lr = 3.2768e-05
I0506 04:37:56.449704 12834 solver.cpp:242] Iteration 53200 (106.689 iter/s, 0.937307s/100 iter), loss = 0.71937
I0506 04:37:56.449728 12834 solver.cpp:261]     Train net output #0: loss = 0.71937 (* 1 = 0.71937 loss)
I0506 04:37:56.449738 12834 sgd_solver.cpp:106] Iteration 53200, lr = 3.2768e-05
I0506 04:37:57.396035 12834 solver.cpp:242] Iteration 53300 (105.15 iter/s, 0.951021s/100 iter), loss = 2.87876
I0506 04:37:57.396077 12834 solver.cpp:261]     Train net output #0: loss = 2.87876 (* 1 = 2.87876 loss)
I0506 04:37:57.396086 12834 sgd_solver.cpp:106] Iteration 53300, lr = 3.2768e-05
I0506 04:37:57.400902 12834 solver.cpp:242] Iteration 53300 (105.136 iter/s, 0.951145s/100 iter), loss = 0.655533
I0506 04:37:57.400928 12834 solver.cpp:261]     Train net output #0: loss = 0.655533 (* 1 = 0.655533 loss)
I0506 04:37:57.400938 12834 sgd_solver.cpp:106] Iteration 53300, lr = 3.2768e-05
I0506 04:37:58.333456 12834 solver.cpp:242] Iteration 53400 (106.684 iter/s, 0.93735s/100 iter), loss = 4.21554
I0506 04:37:58.333497 12834 solver.cpp:261]     Train net output #0: loss = 4.21554 (* 1 = 4.21554 loss)
I0506 04:37:58.333506 12834 sgd_solver.cpp:106] Iteration 53400, lr = 3.2768e-05
I0506 04:37:58.338234 12834 solver.cpp:242] Iteration 53400 (106.691 iter/s, 0.937287s/100 iter), loss = 0.817883
I0506 04:37:58.338258 12834 solver.cpp:261]     Train net output #0: loss = 0.817883 (* 1 = 0.817883 loss)
I0506 04:37:58.338268 12834 sgd_solver.cpp:106] Iteration 53400, lr = 3.2768e-05
I0506 04:37:59.339993 12834 solver.cpp:362] Iteration 53500, Testing net (#0)
I0506 04:37:59.340026 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:59.462906 12834 solver.cpp:429]     Test net output #0: loss = 1.67238 (* 1 = 1.67238 loss)
I0506 04:37:59.465412 12834 solver.cpp:242] Iteration 53500 (88.3474 iter/s, 1.1319s/100 iter), loss = 1.34446
I0506 04:37:59.465437 12834 solver.cpp:261]     Train net output #0: loss = 1.34446 (* 1 = 1.34446 loss)
I0506 04:37:59.465445 12834 sgd_solver.cpp:106] Iteration 53500, lr = 3.2768e-05
I0506 04:37:59.467347 12834 solver.cpp:362] Iteration 53500, Testing net (#0)
I0506 04:37:59.467361 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:37:59.596503 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7115
I0506 04:37:59.596523 12834 solver.cpp:429]     Test net output #1: loss = 0.650033 (* 1 = 0.650033 loss)
I0506 04:37:59.599081 12834 solver.cpp:242] Iteration 53500 (79.3146 iter/s, 1.2608s/100 iter), loss = 0.849077
I0506 04:37:59.599103 12834 solver.cpp:261]     Train net output #0: loss = 0.849077 (* 1 = 0.849077 loss)
I0506 04:37:59.599112 12834 sgd_solver.cpp:106] Iteration 53500, lr = 3.2768e-05
I0506 04:38:00.537868 12834 solver.cpp:242] Iteration 53600 (93.2488 iter/s, 1.0724s/100 iter), loss = 1.3521
I0506 04:38:00.537914 12834 solver.cpp:261]     Train net output #0: loss = 1.3521 (* 1 = 1.3521 loss)
I0506 04:38:00.537925 12834 sgd_solver.cpp:106] Iteration 53600, lr = 3.2768e-05
I0506 04:38:00.542687 12834 solver.cpp:242] Iteration 53600 (105.981 iter/s, 0.943565s/100 iter), loss = 0.874699
I0506 04:38:00.542713 12834 solver.cpp:261]     Train net output #0: loss = 0.874699 (* 1 = 0.874699 loss)
I0506 04:38:00.542722 12834 sgd_solver.cpp:106] Iteration 53600, lr = 3.2768e-05
I0506 04:38:01.479748 12834 solver.cpp:242] Iteration 53700 (106.18 iter/s, 0.941801s/100 iter), loss = 0.924754
I0506 04:38:01.479795 12834 solver.cpp:261]     Train net output #0: loss = 0.924754 (* 1 = 0.924754 loss)
I0506 04:38:01.479805 12834 sgd_solver.cpp:106] Iteration 53700, lr = 3.2768e-05
I0506 04:38:01.484566 12834 solver.cpp:242] Iteration 53700 (106.176 iter/s, 0.941833s/100 iter), loss = 0.552448
I0506 04:38:01.484592 12834 solver.cpp:261]     Train net output #0: loss = 0.552448 (* 1 = 0.552448 loss)
I0506 04:38:01.484601 12834 sgd_solver.cpp:106] Iteration 53700, lr = 3.2768e-05
I0506 04:38:02.417620 12834 solver.cpp:242] Iteration 53800 (106.633 iter/s, 0.937799s/100 iter), loss = 3.09814
I0506 04:38:02.417660 12834 solver.cpp:261]     Train net output #0: loss = 3.09814 (* 1 = 3.09814 loss)
I0506 04:38:02.417670 12834 sgd_solver.cpp:106] Iteration 53800, lr = 3.2768e-05
I0506 04:38:02.422395 12834 solver.cpp:242] Iteration 53800 (106.634 iter/s, 0.937784s/100 iter), loss = 0.733708
I0506 04:38:02.422420 12834 solver.cpp:261]     Train net output #0: loss = 0.733708 (* 1 = 0.733708 loss)
I0506 04:38:02.422430 12834 sgd_solver.cpp:106] Iteration 53800, lr = 3.2768e-05
I0506 04:38:03.368247 12834 solver.cpp:242] Iteration 53900 (105.202 iter/s, 0.950554s/100 iter), loss = 1.47276
I0506 04:38:03.368288 12834 solver.cpp:261]     Train net output #0: loss = 1.47276 (* 1 = 1.47276 loss)
I0506 04:38:03.368297 12834 sgd_solver.cpp:106] Iteration 53900, lr = 3.2768e-05
I0506 04:38:03.373056 12834 solver.cpp:242] Iteration 53900 (105.195 iter/s, 0.950618s/100 iter), loss = 0.889714
I0506 04:38:03.373083 12834 solver.cpp:261]     Train net output #0: loss = 0.889714 (* 1 = 0.889714 loss)
I0506 04:38:03.373092 12834 sgd_solver.cpp:106] Iteration 53900, lr = 3.2768e-05
I0506 04:38:04.302660 12834 solver.cpp:362] Iteration 54000, Testing net (#0)
I0506 04:38:04.302685 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:04.425436 12834 solver.cpp:429]     Test net output #0: loss = 1.54374 (* 1 = 1.54374 loss)
I0506 04:38:04.427950 12834 solver.cpp:242] Iteration 54000 (94.3715 iter/s, 1.05964s/100 iter), loss = 1.03946
I0506 04:38:04.427971 12834 solver.cpp:261]     Train net output #0: loss = 1.03946 (* 1 = 1.03946 loss)
I0506 04:38:04.427981 12834 sgd_solver.cpp:106] Iteration 54000, lr = 3.2768e-05
I0506 04:38:04.429800 12834 solver.cpp:362] Iteration 54000, Testing net (#0)
I0506 04:38:04.429813 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:04.558329 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7165
I0506 04:38:04.558348 12834 solver.cpp:429]     Test net output #1: loss = 0.64258 (* 1 = 0.64258 loss)
I0506 04:38:04.560892 12834 solver.cpp:242] Iteration 54000 (84.1901 iter/s, 1.18779s/100 iter), loss = 0.538328
I0506 04:38:04.560914 12834 solver.cpp:261]     Train net output #0: loss = 0.538328 (* 1 = 0.538328 loss)
I0506 04:38:04.560922 12834 sgd_solver.cpp:106] Iteration 54000, lr = 3.2768e-05
I0506 04:38:05.494403 12834 solver.cpp:242] Iteration 54100 (93.7745 iter/s, 1.06639s/100 iter), loss = 2.80077
I0506 04:38:05.494442 12834 solver.cpp:261]     Train net output #0: loss = 2.80077 (* 1 = 2.80077 loss)
I0506 04:38:05.494451 12834 sgd_solver.cpp:106] Iteration 54100, lr = 3.2768e-05
I0506 04:38:05.499155 12834 solver.cpp:242] Iteration 54100 (106.584 iter/s, 0.938224s/100 iter), loss = 0.895574
I0506 04:38:05.499181 12834 solver.cpp:261]     Train net output #0: loss = 0.895574 (* 1 = 0.895574 loss)
I0506 04:38:05.499189 12834 sgd_solver.cpp:106] Iteration 54100, lr = 3.2768e-05
I0506 04:38:06.431586 12834 solver.cpp:242] Iteration 54200 (106.71 iter/s, 0.93712s/100 iter), loss = 1.1241
I0506 04:38:06.431622 12834 solver.cpp:261]     Train net output #0: loss = 1.1241 (* 1 = 1.1241 loss)
I0506 04:38:06.431632 12834 sgd_solver.cpp:106] Iteration 54200, lr = 3.2768e-05
I0506 04:38:06.436429 12834 solver.cpp:242] Iteration 54200 (106.699 iter/s, 0.93722s/100 iter), loss = 0.448818
I0506 04:38:06.436455 12834 solver.cpp:261]     Train net output #0: loss = 0.448818 (* 1 = 0.448818 loss)
I0506 04:38:06.436465 12834 sgd_solver.cpp:106] Iteration 54200, lr = 3.2768e-05
I0506 04:38:07.369031 12834 solver.cpp:242] Iteration 54300 (106.68 iter/s, 0.937382s/100 iter), loss = 0.655949
I0506 04:38:07.369067 12834 solver.cpp:261]     Train net output #0: loss = 0.655949 (* 1 = 0.655949 loss)
I0506 04:38:07.369077 12834 sgd_solver.cpp:106] Iteration 54300, lr = 3.2768e-05
I0506 04:38:07.373813 12834 solver.cpp:242] Iteration 54300 (106.685 iter/s, 0.93734s/100 iter), loss = 0.810786
I0506 04:38:07.373837 12834 solver.cpp:261]     Train net output #0: loss = 0.810786 (* 1 = 0.810786 loss)
I0506 04:38:07.373847 12834 sgd_solver.cpp:106] Iteration 54300, lr = 3.2768e-05
I0506 04:38:08.306232 12834 solver.cpp:242] Iteration 54400 (106.707 iter/s, 0.937142s/100 iter), loss = 3.71422
I0506 04:38:08.306267 12834 solver.cpp:261]     Train net output #0: loss = 3.71422 (* 1 = 3.71422 loss)
I0506 04:38:08.306277 12834 sgd_solver.cpp:106] Iteration 54400, lr = 3.2768e-05
I0506 04:38:08.311086 12834 solver.cpp:242] Iteration 54400 (106.698 iter/s, 0.937221s/100 iter), loss = 0.645087
I0506 04:38:08.311111 12834 solver.cpp:261]     Train net output #0: loss = 0.645087 (* 1 = 0.645087 loss)
I0506 04:38:08.311120 12834 sgd_solver.cpp:106] Iteration 54400, lr = 3.2768e-05
I0506 04:38:09.240361 12834 solver.cpp:362] Iteration 54500, Testing net (#0)
I0506 04:38:09.240381 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:09.363143 12834 solver.cpp:429]     Test net output #0: loss = 1.90866 (* 1 = 1.90866 loss)
I0506 04:38:09.365658 12834 solver.cpp:242] Iteration 54500 (94.3955 iter/s, 1.05937s/100 iter), loss = 1.32079
I0506 04:38:09.365679 12834 solver.cpp:261]     Train net output #0: loss = 1.32079 (* 1 = 1.32079 loss)
I0506 04:38:09.365686 12834 sgd_solver.cpp:106] Iteration 54500, lr = 3.2768e-05
I0506 04:38:09.367499 12834 solver.cpp:362] Iteration 54500, Testing net (#0)
I0506 04:38:09.367511 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:09.496299 12834 solver.cpp:429]     Test net output #0: accuracy = 0.666
I0506 04:38:09.496318 12834 solver.cpp:429]     Test net output #1: loss = 0.764363 (* 1 = 0.764363 loss)
I0506 04:38:09.498886 12834 solver.cpp:242] Iteration 54500 (84.1925 iter/s, 1.18775s/100 iter), loss = 0.592243
I0506 04:38:09.498908 12834 solver.cpp:261]     Train net output #0: loss = 0.592243 (* 1 = 0.592243 loss)
I0506 04:38:09.498915 12834 sgd_solver.cpp:106] Iteration 54500, lr = 3.2768e-05
I0506 04:38:10.431710 12834 solver.cpp:242] Iteration 54600 (93.8088 iter/s, 1.066s/100 iter), loss = 0.618916
I0506 04:38:10.431751 12834 solver.cpp:261]     Train net output #0: loss = 0.618916 (* 1 = 0.618916 loss)
I0506 04:38:10.431761 12834 sgd_solver.cpp:106] Iteration 54600, lr = 3.2768e-05
I0506 04:38:10.436523 12834 solver.cpp:242] Iteration 54600 (106.656 iter/s, 0.937597s/100 iter), loss = 0.742081
I0506 04:38:10.436548 12834 solver.cpp:261]     Train net output #0: loss = 0.742081 (* 1 = 0.742081 loss)
I0506 04:38:10.436563 12834 sgd_solver.cpp:106] Iteration 54600, lr = 3.2768e-05
I0506 04:38:11.451941 12834 solver.cpp:242] Iteration 54700 (98.0239 iter/s, 1.02016s/100 iter), loss = 0.700641
I0506 04:38:11.451990 12834 solver.cpp:261]     Train net output #0: loss = 0.700641 (* 1 = 0.700641 loss)
I0506 04:38:11.452002 12834 sgd_solver.cpp:106] Iteration 54700, lr = 3.2768e-05
I0506 04:38:11.457231 12834 solver.cpp:242] Iteration 54700 (97.9757 iter/s, 1.02066s/100 iter), loss = 0.603917
I0506 04:38:11.457262 12834 solver.cpp:261]     Train net output #0: loss = 0.603917 (* 1 = 0.603917 loss)
I0506 04:38:11.457273 12834 sgd_solver.cpp:106] Iteration 54700, lr = 3.2768e-05
I0506 04:38:12.392721 12834 solver.cpp:242] Iteration 54800 (106.304 iter/s, 0.940701s/100 iter), loss = 1.23499
I0506 04:38:12.392762 12834 solver.cpp:261]     Train net output #0: loss = 1.23499 (* 1 = 1.23499 loss)
I0506 04:38:12.392771 12834 sgd_solver.cpp:106] Iteration 54800, lr = 3.2768e-05
I0506 04:38:12.397485 12834 solver.cpp:242] Iteration 54800 (106.36 iter/s, 0.940205s/100 iter), loss = 0.439172
I0506 04:38:12.397511 12834 solver.cpp:261]     Train net output #0: loss = 0.439172 (* 1 = 0.439172 loss)
I0506 04:38:12.397529 12834 sgd_solver.cpp:106] Iteration 54800, lr = 3.2768e-05
I0506 04:38:13.329639 12834 solver.cpp:242] Iteration 54900 (106.74 iter/s, 0.936852s/100 iter), loss = 2.31024
I0506 04:38:13.329679 12834 solver.cpp:261]     Train net output #0: loss = 2.31024 (* 1 = 2.31024 loss)
I0506 04:38:13.329687 12834 sgd_solver.cpp:106] Iteration 54900, lr = 3.2768e-05
I0506 04:38:13.334434 12834 solver.cpp:242] Iteration 54900 (106.734 iter/s, 0.936905s/100 iter), loss = 0.816652
I0506 04:38:13.334460 12834 solver.cpp:261]     Train net output #0: loss = 0.816652 (* 1 = 0.816652 loss)
I0506 04:38:13.334468 12834 sgd_solver.cpp:106] Iteration 54900, lr = 3.2768e-05
I0506 04:38:14.274407 12834 solver.cpp:362] Iteration 55000, Testing net (#0)
I0506 04:38:14.274435 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:14.397112 12834 solver.cpp:429]     Test net output #0: loss = 1.74538 (* 1 = 1.74538 loss)
I0506 04:38:14.399631 12834 solver.cpp:242] Iteration 55000 (93.4637 iter/s, 1.06993s/100 iter), loss = 4.95292
I0506 04:38:14.399652 12834 solver.cpp:261]     Train net output #0: loss = 4.95292 (* 1 = 4.95292 loss)
I0506 04:38:14.399659 12834 sgd_solver.cpp:106] Iteration 55000, lr = 3.2768e-05
I0506 04:38:14.401489 12834 solver.cpp:362] Iteration 55000, Testing net (#0)
I0506 04:38:14.401504 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:14.530163 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6875
I0506 04:38:14.530185 12834 solver.cpp:429]     Test net output #1: loss = 0.724929 (* 1 = 0.724929 loss)
I0506 04:38:14.532786 12834 solver.cpp:242] Iteration 55000 (83.4511 iter/s, 1.19831s/100 iter), loss = 0.961378
I0506 04:38:14.532807 12834 solver.cpp:261]     Train net output #0: loss = 0.961378 (* 1 = 0.961378 loss)
I0506 04:38:14.532816 12834 sgd_solver.cpp:106] Iteration 55000, lr = 3.2768e-05
I0506 04:38:15.465399 12834 solver.cpp:242] Iteration 55100 (93.8334 iter/s, 1.06572s/100 iter), loss = 6.74216
I0506 04:38:15.465438 12834 solver.cpp:261]     Train net output #0: loss = 6.74216 (* 1 = 6.74216 loss)
I0506 04:38:15.465447 12834 sgd_solver.cpp:106] Iteration 55100, lr = 3.2768e-05
I0506 04:38:15.470245 12834 solver.cpp:242] Iteration 55100 (106.677 iter/s, 0.937409s/100 iter), loss = 0.93606
I0506 04:38:15.470271 12834 solver.cpp:261]     Train net output #0: loss = 0.93606 (* 1 = 0.93606 loss)
I0506 04:38:15.470280 12834 sgd_solver.cpp:106] Iteration 55100, lr = 3.2768e-05
I0506 04:38:16.402773 12834 solver.cpp:242] Iteration 55200 (106.688 iter/s, 0.937308s/100 iter), loss = 1.39945
I0506 04:38:16.402812 12834 solver.cpp:261]     Train net output #0: loss = 1.39945 (* 1 = 1.39945 loss)
I0506 04:38:16.402820 12834 sgd_solver.cpp:106] Iteration 55200, lr = 3.2768e-05
I0506 04:38:16.407651 12834 solver.cpp:242] Iteration 55200 (106.682 iter/s, 0.937362s/100 iter), loss = 0.659521
I0506 04:38:16.407675 12834 solver.cpp:261]     Train net output #0: loss = 0.659521 (* 1 = 0.659521 loss)
I0506 04:38:16.407683 12834 sgd_solver.cpp:106] Iteration 55200, lr = 3.2768e-05
I0506 04:38:17.339514 12834 solver.cpp:242] Iteration 55300 (106.76 iter/s, 0.936678s/100 iter), loss = 1.47708
I0506 04:38:17.339551 12834 solver.cpp:261]     Train net output #0: loss = 1.47708 (* 1 = 1.47708 loss)
I0506 04:38:17.339561 12834 sgd_solver.cpp:106] Iteration 55300, lr = 3.2768e-05
I0506 04:38:17.344390 12834 solver.cpp:242] Iteration 55300 (106.759 iter/s, 0.936687s/100 iter), loss = 0.580832
I0506 04:38:17.344415 12834 solver.cpp:261]     Train net output #0: loss = 0.580832 (* 1 = 0.580832 loss)
I0506 04:38:17.344424 12834 sgd_solver.cpp:106] Iteration 55300, lr = 3.2768e-05
I0506 04:38:18.276808 12834 solver.cpp:242] Iteration 55400 (106.697 iter/s, 0.937229s/100 iter), loss = 1.98516
I0506 04:38:18.276844 12834 solver.cpp:261]     Train net output #0: loss = 1.98516 (* 1 = 1.98516 loss)
I0506 04:38:18.276854 12834 sgd_solver.cpp:106] Iteration 55400, lr = 3.2768e-05
I0506 04:38:18.281585 12834 solver.cpp:242] Iteration 55400 (106.706 iter/s, 0.937151s/100 iter), loss = 0.583319
I0506 04:38:18.281622 12834 solver.cpp:261]     Train net output #0: loss = 0.583319 (* 1 = 0.583319 loss)
I0506 04:38:18.281632 12834 sgd_solver.cpp:106] Iteration 55400, lr = 3.2768e-05
I0506 04:38:19.211547 12834 solver.cpp:362] Iteration 55500, Testing net (#0)
I0506 04:38:19.211572 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:19.334156 12834 solver.cpp:429]     Test net output #0: loss = 1.61047 (* 1 = 1.61047 loss)
I0506 04:38:19.336669 12834 solver.cpp:242] Iteration 55500 (94.3569 iter/s, 1.05981s/100 iter), loss = 1.76512
I0506 04:38:19.336693 12834 solver.cpp:261]     Train net output #0: loss = 1.76512 (* 1 = 1.76512 loss)
I0506 04:38:19.336701 12834 sgd_solver.cpp:106] Iteration 55500, lr = 3.2768e-05
I0506 04:38:19.338516 12834 solver.cpp:362] Iteration 55500, Testing net (#0)
I0506 04:38:19.338528 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:19.467226 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7285
I0506 04:38:19.467245 12834 solver.cpp:429]     Test net output #1: loss = 0.64016 (* 1 = 0.64016 loss)
I0506 04:38:19.469791 12834 solver.cpp:242] Iteration 55500 (84.1646 iter/s, 1.18815s/100 iter), loss = 0.447391
I0506 04:38:19.469812 12834 solver.cpp:261]     Train net output #0: loss = 0.447391 (* 1 = 0.447391 loss)
I0506 04:38:19.469820 12834 sgd_solver.cpp:106] Iteration 55500, lr = 3.2768e-05
I0506 04:38:20.402420 12834 solver.cpp:242] Iteration 55600 (93.835 iter/s, 1.0657s/100 iter), loss = 3.3565
I0506 04:38:20.402456 12834 solver.cpp:261]     Train net output #0: loss = 3.3565 (* 1 = 3.3565 loss)
I0506 04:38:20.402465 12834 sgd_solver.cpp:106] Iteration 55600, lr = 3.2768e-05
I0506 04:38:20.407232 12834 solver.cpp:242] Iteration 55600 (106.678 iter/s, 0.9374s/100 iter), loss = 0.984231
I0506 04:38:20.407256 12834 solver.cpp:261]     Train net output #0: loss = 0.984231 (* 1 = 0.984231 loss)
I0506 04:38:20.407265 12834 sgd_solver.cpp:106] Iteration 55600, lr = 3.2768e-05
I0506 04:38:21.339118 12834 solver.cpp:242] Iteration 55700 (106.766 iter/s, 0.93663s/100 iter), loss = 1.6256
I0506 04:38:21.339149 12834 solver.cpp:261]     Train net output #0: loss = 1.6256 (* 1 = 1.6256 loss)
I0506 04:38:21.339159 12834 sgd_solver.cpp:106] Iteration 55700, lr = 3.2768e-05
I0506 04:38:21.343905 12834 solver.cpp:242] Iteration 55700 (106.766 iter/s, 0.93663s/100 iter), loss = 1.00119
I0506 04:38:21.343930 12834 solver.cpp:261]     Train net output #0: loss = 1.00119 (* 1 = 1.00119 loss)
I0506 04:38:21.343940 12834 sgd_solver.cpp:106] Iteration 55700, lr = 3.2768e-05
I0506 04:38:22.277611 12834 solver.cpp:242] Iteration 55800 (106.561 iter/s, 0.938434s/100 iter), loss = 1.92988
I0506 04:38:22.277657 12834 solver.cpp:261]     Train net output #0: loss = 1.92988 (* 1 = 1.92988 loss)
I0506 04:38:22.277667 12834 sgd_solver.cpp:106] Iteration 55800, lr = 3.2768e-05
I0506 04:38:22.282403 12834 solver.cpp:242] Iteration 55800 (106.558 iter/s, 0.938454s/100 iter), loss = 0.677909
I0506 04:38:22.282428 12834 solver.cpp:261]     Train net output #0: loss = 0.677909 (* 1 = 0.677909 loss)
I0506 04:38:22.282438 12834 sgd_solver.cpp:106] Iteration 55800, lr = 3.2768e-05
I0506 04:38:23.281657 12834 solver.cpp:242] Iteration 55900 (99.605 iter/s, 1.00397s/100 iter), loss = 2.57343
I0506 04:38:23.281707 12834 solver.cpp:261]     Train net output #0: loss = 2.57343 (* 1 = 2.57343 loss)
I0506 04:38:23.281718 12834 sgd_solver.cpp:106] Iteration 55900, lr = 3.2768e-05
I0506 04:38:23.286944 12834 solver.cpp:242] Iteration 55900 (99.5525 iter/s, 1.00449s/100 iter), loss = 0.931299
I0506 04:38:23.286974 12834 solver.cpp:261]     Train net output #0: loss = 0.931299 (* 1 = 0.931299 loss)
I0506 04:38:23.286984 12834 sgd_solver.cpp:106] Iteration 55900, lr = 3.2768e-05
I0506 04:38:24.314072 12834 solver.cpp:362] Iteration 56000, Testing net (#0)
I0506 04:38:24.314105 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:24.447190 12834 solver.cpp:429]     Test net output #0: loss = 1.82882 (* 1 = 1.82882 loss)
I0506 04:38:24.449837 12834 solver.cpp:242] Iteration 56000 (85.6083 iter/s, 1.16811s/100 iter), loss = 2.57489
I0506 04:38:24.449872 12834 solver.cpp:261]     Train net output #0: loss = 2.57489 (* 1 = 2.57489 loss)
I0506 04:38:24.449882 12834 sgd_solver.cpp:106] Iteration 56000, lr = 3.2768e-05
I0506 04:38:24.452172 12834 solver.cpp:362] Iteration 56000, Testing net (#0)
I0506 04:38:24.452188 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:24.592962 12834 solver.cpp:429]     Test net output #0: accuracy = 0.709
I0506 04:38:24.592986 12834 solver.cpp:429]     Test net output #1: loss = 0.664011 (* 1 = 0.664011 loss)
I0506 04:38:24.595676 12834 solver.cpp:242] Iteration 56000 (76.4129 iter/s, 1.30868s/100 iter), loss = 0.885318
I0506 04:38:24.595701 12834 solver.cpp:261]     Train net output #0: loss = 0.885318 (* 1 = 0.885318 loss)
I0506 04:38:24.595712 12834 sgd_solver.cpp:106] Iteration 56000, lr = 3.2768e-05
I0506 04:38:25.596693 12834 solver.cpp:242] Iteration 56100 (87.1996 iter/s, 1.14679s/100 iter), loss = 0.662496
I0506 04:38:25.596724 12834 solver.cpp:261]     Train net output #0: loss = 0.662496 (* 1 = 0.662496 loss)
I0506 04:38:25.596734 12834 sgd_solver.cpp:106] Iteration 56100, lr = 3.2768e-05
I0506 04:38:25.601444 12834 solver.cpp:242] Iteration 56100 (99.431 iter/s, 1.00572s/100 iter), loss = 0.324552
I0506 04:38:25.601467 12834 solver.cpp:261]     Train net output #0: loss = 0.324552 (* 1 = 0.324552 loss)
I0506 04:38:25.601476 12834 sgd_solver.cpp:106] Iteration 56100, lr = 3.2768e-05
I0506 04:38:26.534198 12834 solver.cpp:242] Iteration 56200 (106.673 iter/s, 0.937447s/100 iter), loss = 2.07149
I0506 04:38:26.534240 12834 solver.cpp:261]     Train net output #0: loss = 2.07149 (* 1 = 2.07149 loss)
I0506 04:38:26.534248 12834 sgd_solver.cpp:106] Iteration 56200, lr = 3.2768e-05
I0506 04:38:26.539026 12834 solver.cpp:242] Iteration 56200 (106.663 iter/s, 0.937532s/100 iter), loss = 0.627725
I0506 04:38:26.539052 12834 solver.cpp:261]     Train net output #0: loss = 0.627725 (* 1 = 0.627725 loss)
I0506 04:38:26.539060 12834 sgd_solver.cpp:106] Iteration 56200, lr = 3.2768e-05
I0506 04:38:27.484760 12834 solver.cpp:242] Iteration 56300 (105.209 iter/s, 0.950493s/100 iter), loss = 1.63934
I0506 04:38:27.484800 12834 solver.cpp:261]     Train net output #0: loss = 1.63934 (* 1 = 1.63934 loss)
I0506 04:38:27.484810 12834 sgd_solver.cpp:106] Iteration 56300, lr = 3.2768e-05
I0506 04:38:27.489540 12834 solver.cpp:242] Iteration 56300 (105.211 iter/s, 0.95047s/100 iter), loss = 0.665726
I0506 04:38:27.489564 12834 solver.cpp:261]     Train net output #0: loss = 0.665726 (* 1 = 0.665726 loss)
I0506 04:38:27.489573 12834 sgd_solver.cpp:106] Iteration 56300, lr = 3.2768e-05
I0506 04:38:28.422408 12834 solver.cpp:242] Iteration 56400 (106.658 iter/s, 0.937575s/100 iter), loss = 1.13534
I0506 04:38:28.422447 12834 solver.cpp:261]     Train net output #0: loss = 1.13534 (* 1 = 1.13534 loss)
I0506 04:38:28.422456 12834 sgd_solver.cpp:106] Iteration 56400, lr = 3.2768e-05
I0506 04:38:28.427181 12834 solver.cpp:242] Iteration 56400 (106.656 iter/s, 0.937597s/100 iter), loss = 0.291073
I0506 04:38:28.427204 12834 solver.cpp:261]     Train net output #0: loss = 0.291073 (* 1 = 0.291073 loss)
I0506 04:38:28.427213 12834 sgd_solver.cpp:106] Iteration 56400, lr = 3.2768e-05
I0506 04:38:29.438673 12834 solver.cpp:362] Iteration 56500, Testing net (#0)
I0506 04:38:29.438704 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:29.571914 12834 solver.cpp:429]     Test net output #0: loss = 1.97817 (* 1 = 1.97817 loss)
I0506 04:38:29.574579 12834 solver.cpp:242] Iteration 56500 (86.7972 iter/s, 1.15211s/100 iter), loss = 2.21584
I0506 04:38:29.574604 12834 solver.cpp:261]     Train net output #0: loss = 2.21584 (* 1 = 2.21584 loss)
I0506 04:38:29.574615 12834 sgd_solver.cpp:106] Iteration 56500, lr = 3.2768e-05
I0506 04:38:29.576817 12834 solver.cpp:362] Iteration 56500, Testing net (#0)
I0506 04:38:29.576834 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:29.715432 12834 solver.cpp:429]     Test net output #0: accuracy = 0.6935
I0506 04:38:29.715462 12834 solver.cpp:429]     Test net output #1: loss = 0.726981 (* 1 = 0.726981 loss)
I0506 04:38:29.718025 12834 solver.cpp:242] Iteration 56500 (77.4715 iter/s, 1.2908s/100 iter), loss = 0.697849
I0506 04:38:29.718045 12834 solver.cpp:261]     Train net output #0: loss = 0.697849 (* 1 = 0.697849 loss)
I0506 04:38:29.718055 12834 sgd_solver.cpp:106] Iteration 56500, lr = 3.2768e-05
I0506 04:38:30.658174 12834 solver.cpp:242] Iteration 56600 (92.2907 iter/s, 1.08353s/100 iter), loss = 2.6357
I0506 04:38:30.658229 12834 solver.cpp:261]     Train net output #0: loss = 2.6357 (* 1 = 2.6357 loss)
I0506 04:38:30.658359 12834 sgd_solver.cpp:106] Iteration 56600, lr = 3.2768e-05
I0506 04:38:30.663164 12834 solver.cpp:242] Iteration 56600 (105.809 iter/s, 0.9451s/100 iter), loss = 0.735875
I0506 04:38:30.663189 12834 solver.cpp:261]     Train net output #0: loss = 0.735875 (* 1 = 0.735875 loss)
I0506 04:38:30.663198 12834 sgd_solver.cpp:106] Iteration 56600, lr = 3.2768e-05
I0506 04:38:31.596509 12834 solver.cpp:242] Iteration 56700 (106.581 iter/s, 0.938256s/100 iter), loss = 0.961445
I0506 04:38:31.596554 12834 solver.cpp:261]     Train net output #0: loss = 0.961445 (* 1 = 0.961445 loss)
I0506 04:38:31.596565 12834 sgd_solver.cpp:106] Iteration 56700, lr = 3.2768e-05
I0506 04:38:31.601280 12834 solver.cpp:242] Iteration 56700 (106.601 iter/s, 0.938073s/100 iter), loss = 1.07413
I0506 04:38:31.601305 12834 solver.cpp:261]     Train net output #0: loss = 1.07413 (* 1 = 1.07413 loss)
I0506 04:38:31.601315 12834 sgd_solver.cpp:106] Iteration 56700, lr = 3.2768e-05
I0506 04:38:32.533255 12834 solver.cpp:242] Iteration 56800 (106.761 iter/s, 0.936673s/100 iter), loss = 1.18734
I0506 04:38:32.533293 12834 solver.cpp:261]     Train net output #0: loss = 1.18734 (* 1 = 1.18734 loss)
I0506 04:38:32.533303 12834 sgd_solver.cpp:106] Iteration 56800, lr = 3.2768e-05
I0506 04:38:32.538045 12834 solver.cpp:242] Iteration 56800 (106.755 iter/s, 0.936721s/100 iter), loss = 0.60614
I0506 04:38:32.538070 12834 solver.cpp:261]     Train net output #0: loss = 0.60614 (* 1 = 0.60614 loss)
I0506 04:38:32.538079 12834 sgd_solver.cpp:106] Iteration 56800, lr = 3.2768e-05
I0506 04:38:33.470732 12834 solver.cpp:242] Iteration 56900 (106.676 iter/s, 0.937416s/100 iter), loss = 0.708525
I0506 04:38:33.470768 12834 solver.cpp:261]     Train net output #0: loss = 0.708525 (* 1 = 0.708525 loss)
I0506 04:38:33.470778 12834 sgd_solver.cpp:106] Iteration 56900, lr = 3.2768e-05
I0506 04:38:33.475488 12834 solver.cpp:242] Iteration 56900 (106.678 iter/s, 0.937401s/100 iter), loss = 0.491648
I0506 04:38:33.475512 12834 solver.cpp:261]     Train net output #0: loss = 0.491648 (* 1 = 0.491648 loss)
I0506 04:38:33.475522 12834 sgd_solver.cpp:106] Iteration 56900, lr = 3.2768e-05
I0506 04:38:34.404706 12834 solver.cpp:362] Iteration 57000, Testing net (#0)
I0506 04:38:34.404731 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:34.527444 12834 solver.cpp:429]     Test net output #0: loss = 1.86839 (* 1 = 1.86839 loss)
I0506 04:38:34.529969 12834 solver.cpp:242] Iteration 57000 (94.4124 iter/s, 1.05918s/100 iter), loss = 1.86818
I0506 04:38:34.529989 12834 solver.cpp:261]     Train net output #0: loss = 1.86818 (* 1 = 1.86818 loss)
I0506 04:38:34.529999 12834 sgd_solver.cpp:106] Iteration 57000, lr = 3.2768e-05
I0506 04:38:34.531816 12834 solver.cpp:362] Iteration 57000, Testing net (#0)
I0506 04:38:34.531827 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:34.668452 12834 solver.cpp:429]     Test net output #0: accuracy = 0.695
I0506 04:38:34.668475 12834 solver.cpp:429]     Test net output #1: loss = 0.759299 (* 1 = 0.759299 loss)
I0506 04:38:34.671167 12834 solver.cpp:242] Iteration 57000 (83.6377 iter/s, 1.19563s/100 iter), loss = 0.479035
I0506 04:38:34.671192 12834 solver.cpp:261]     Train net output #0: loss = 0.479035 (* 1 = 0.479035 loss)
I0506 04:38:34.671202 12834 sgd_solver.cpp:106] Iteration 57000, lr = 3.2768e-05
I0506 04:38:35.702271 12834 solver.cpp:242] Iteration 57100 (85.3059 iter/s, 1.17225s/100 iter), loss = 2.05141
I0506 04:38:35.702335 12834 solver.cpp:261]     Train net output #0: loss = 2.05141 (* 1 = 2.05141 loss)
I0506 04:38:35.702350 12834 sgd_solver.cpp:106] Iteration 57100, lr = 3.2768e-05
I0506 04:38:35.707237 12834 solver.cpp:242] Iteration 57100 (96.5237 iter/s, 1.03602s/100 iter), loss = 0.587763
I0506 04:38:35.707263 12834 solver.cpp:261]     Train net output #0: loss = 0.587763 (* 1 = 0.587763 loss)
I0506 04:38:35.707273 12834 sgd_solver.cpp:106] Iteration 57100, lr = 3.2768e-05
I0506 04:38:36.640630 12834 solver.cpp:242] Iteration 57200 (106.579 iter/s, 0.93827s/100 iter), loss = 1.37906
I0506 04:38:36.640668 12834 solver.cpp:261]     Train net output #0: loss = 1.37906 (* 1 = 1.37906 loss)
I0506 04:38:36.640677 12834 sgd_solver.cpp:106] Iteration 57200, lr = 3.2768e-05
I0506 04:38:36.645424 12834 solver.cpp:242] Iteration 57200 (106.594 iter/s, 0.938143s/100 iter), loss = 0.534027
I0506 04:38:36.645448 12834 solver.cpp:261]     Train net output #0: loss = 0.534027 (* 1 = 0.534027 loss)
I0506 04:38:36.645457 12834 sgd_solver.cpp:106] Iteration 57200, lr = 3.2768e-05
I0506 04:38:37.577543 12834 solver.cpp:242] Iteration 57300 (106.741 iter/s, 0.936843s/100 iter), loss = 3.50398
I0506 04:38:37.577579 12834 solver.cpp:261]     Train net output #0: loss = 3.50398 (* 1 = 3.50398 loss)
I0506 04:38:37.577589 12834 sgd_solver.cpp:106] Iteration 57300, lr = 3.2768e-05
I0506 04:38:37.582329 12834 solver.cpp:242] Iteration 57300 (106.739 iter/s, 0.936861s/100 iter), loss = 0.835802
I0506 04:38:37.582353 12834 solver.cpp:261]     Train net output #0: loss = 0.835802 (* 1 = 0.835802 loss)
I0506 04:38:37.582362 12834 sgd_solver.cpp:106] Iteration 57300, lr = 3.2768e-05
I0506 04:38:38.514372 12834 solver.cpp:242] Iteration 57400 (106.75 iter/s, 0.936768s/100 iter), loss = 4.02409
I0506 04:38:38.514405 12834 solver.cpp:261]     Train net output #0: loss = 4.02409 (* 1 = 4.02409 loss)
I0506 04:38:38.514415 12834 sgd_solver.cpp:106] Iteration 57400, lr = 3.2768e-05
I0506 04:38:38.519134 12834 solver.cpp:242] Iteration 57400 (106.751 iter/s, 0.936763s/100 iter), loss = 1.22109
I0506 04:38:38.519160 12834 solver.cpp:261]     Train net output #0: loss = 1.22109 (* 1 = 1.22109 loss)
I0506 04:38:38.519168 12834 sgd_solver.cpp:106] Iteration 57400, lr = 3.2768e-05
I0506 04:38:39.462291 12834 solver.cpp:362] Iteration 57500, Testing net (#0)
I0506 04:38:39.462318 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:39.585008 12834 solver.cpp:429]     Test net output #0: loss = 1.73489 (* 1 = 1.73489 loss)
I0506 04:38:39.587527 12834 solver.cpp:242] Iteration 57500 (93.1877 iter/s, 1.0731s/100 iter), loss = 0.953255
I0506 04:38:39.587548 12834 solver.cpp:261]     Train net output #0: loss = 0.953255 (* 1 = 0.953255 loss)
I0506 04:38:39.587558 12834 sgd_solver.cpp:106] Iteration 57500, lr = 3.2768e-05
I0506 04:38:39.589388 12834 solver.cpp:362] Iteration 57500, Testing net (#0)
I0506 04:38:39.589401 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:39.718042 12834 solver.cpp:429]     Test net output #0: accuracy = 0.708
I0506 04:38:39.718060 12834 solver.cpp:429]     Test net output #1: loss = 0.702539 (* 1 = 0.702539 loss)
I0506 04:38:39.720629 12834 solver.cpp:242] Iteration 57500 (83.2328 iter/s, 1.20145s/100 iter), loss = 0.709891
I0506 04:38:39.720650 12834 solver.cpp:261]     Train net output #0: loss = 0.709891 (* 1 = 0.709891 loss)
I0506 04:38:39.720659 12834 sgd_solver.cpp:106] Iteration 57500, lr = 3.2768e-05
I0506 04:38:40.653525 12834 solver.cpp:242] Iteration 57600 (93.8131 iter/s, 1.06595s/100 iter), loss = 1.15656
I0506 04:38:40.653561 12834 solver.cpp:261]     Train net output #0: loss = 1.15656 (* 1 = 1.15656 loss)
I0506 04:38:40.653570 12834 sgd_solver.cpp:106] Iteration 57600, lr = 3.2768e-05
I0506 04:38:40.658298 12834 solver.cpp:242] Iteration 57600 (106.652 iter/s, 0.937628s/100 iter), loss = 0.635381
I0506 04:38:40.658321 12834 solver.cpp:261]     Train net output #0: loss = 0.635381 (* 1 = 0.635381 loss)
I0506 04:38:40.658330 12834 sgd_solver.cpp:106] Iteration 57600, lr = 3.2768e-05
I0506 04:38:41.592425 12834 solver.cpp:242] Iteration 57700 (106.515 iter/s, 0.938834s/100 iter), loss = 1.33625
I0506 04:38:41.592463 12834 solver.cpp:261]     Train net output #0: loss = 1.33625 (* 1 = 1.33625 loss)
I0506 04:38:41.592473 12834 sgd_solver.cpp:106] Iteration 57700, lr = 3.2768e-05
I0506 04:38:41.597193 12834 solver.cpp:242] Iteration 57700 (106.513 iter/s, 0.938852s/100 iter), loss = 0.889339
I0506 04:38:41.597218 12834 solver.cpp:261]     Train net output #0: loss = 0.889339 (* 1 = 0.889339 loss)
I0506 04:38:41.597226 12834 sgd_solver.cpp:106] Iteration 57700, lr = 3.2768e-05
I0506 04:38:42.529876 12834 solver.cpp:242] Iteration 57800 (106.679 iter/s, 0.937388s/100 iter), loss = 1.57919
I0506 04:38:42.529918 12834 solver.cpp:261]     Train net output #0: loss = 1.57919 (* 1 = 1.57919 loss)
I0506 04:38:42.529927 12834 sgd_solver.cpp:106] Iteration 57800, lr = 3.2768e-05
I0506 04:38:42.534648 12834 solver.cpp:242] Iteration 57800 (106.677 iter/s, 0.937413s/100 iter), loss = 0.547564
I0506 04:38:42.534674 12834 solver.cpp:261]     Train net output #0: loss = 0.547564 (* 1 = 0.547564 loss)
I0506 04:38:42.534683 12834 sgd_solver.cpp:106] Iteration 57800, lr = 3.2768e-05
I0506 04:38:43.467021 12834 solver.cpp:242] Iteration 57900 (106.715 iter/s, 0.937074s/100 iter), loss = 1.0216
I0506 04:38:43.467061 12834 solver.cpp:261]     Train net output #0: loss = 1.0216 (* 1 = 1.0216 loss)
I0506 04:38:43.467070 12834 sgd_solver.cpp:106] Iteration 57900, lr = 3.2768e-05
I0506 04:38:43.471792 12834 solver.cpp:242] Iteration 57900 (106.712 iter/s, 0.9371s/100 iter), loss = 0.993022
I0506 04:38:43.471817 12834 solver.cpp:261]     Train net output #0: loss = 0.993022 (* 1 = 0.993022 loss)
I0506 04:38:43.471825 12834 sgd_solver.cpp:106] Iteration 57900, lr = 3.2768e-05
I0506 04:38:44.401595 12834 solver.cpp:362] Iteration 58000, Testing net (#0)
I0506 04:38:44.401620 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:44.524255 12834 solver.cpp:429]     Test net output #0: loss = 1.84768 (* 1 = 1.84768 loss)
I0506 04:38:44.526780 12834 solver.cpp:242] Iteration 58000 (94.3663 iter/s, 1.0597s/100 iter), loss = 2.46708
I0506 04:38:44.526801 12834 solver.cpp:261]     Train net output #0: loss = 2.46708 (* 1 = 2.46708 loss)
I0506 04:38:44.526810 12834 sgd_solver.cpp:106] Iteration 58000, lr = 3.2768e-05
I0506 04:38:44.528717 12834 solver.cpp:362] Iteration 58000, Testing net (#0)
I0506 04:38:44.528730 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:44.657618 12834 solver.cpp:429]     Test net output #0: accuracy = 0.71
I0506 04:38:44.657637 12834 solver.cpp:429]     Test net output #1: loss = 0.695145 (* 1 = 0.695145 loss)
I0506 04:38:44.660197 12834 solver.cpp:242] Iteration 58000 (84.1496 iter/s, 1.18836s/100 iter), loss = 0.634199
I0506 04:38:44.660217 12834 solver.cpp:261]     Train net output #0: loss = 0.634199 (* 1 = 0.634199 loss)
I0506 04:38:44.660224 12834 sgd_solver.cpp:106] Iteration 58000, lr = 3.2768e-05
I0506 04:38:45.593014 12834 solver.cpp:242] Iteration 58100 (93.7926 iter/s, 1.06618s/100 iter), loss = 1.67284
I0506 04:38:45.593053 12834 solver.cpp:261]     Train net output #0: loss = 1.67284 (* 1 = 1.67284 loss)
I0506 04:38:45.593063 12834 sgd_solver.cpp:106] Iteration 58100, lr = 3.2768e-05
I0506 04:38:45.597769 12834 solver.cpp:242] Iteration 58100 (106.663 iter/s, 0.937533s/100 iter), loss = 0.762592
I0506 04:38:45.597792 12834 solver.cpp:261]     Train net output #0: loss = 0.762592 (* 1 = 0.762592 loss)
I0506 04:38:45.597800 12834 sgd_solver.cpp:106] Iteration 58100, lr = 3.2768e-05
I0506 04:38:46.530092 12834 solver.cpp:242] Iteration 58200 (106.723 iter/s, 0.937006s/100 iter), loss = 4.1575
I0506 04:38:46.530131 12834 solver.cpp:261]     Train net output #0: loss = 4.1575 (* 1 = 4.1575 loss)
I0506 04:38:46.530140 12834 sgd_solver.cpp:106] Iteration 58200, lr = 3.2768e-05
I0506 04:38:46.534870 12834 solver.cpp:242] Iteration 58200 (106.717 iter/s, 0.93706s/100 iter), loss = 0.905625
I0506 04:38:46.534896 12834 solver.cpp:261]     Train net output #0: loss = 0.905625 (* 1 = 0.905625 loss)
I0506 04:38:46.534914 12834 sgd_solver.cpp:106] Iteration 58200, lr = 3.2768e-05
I0506 04:38:47.499719 12834 solver.cpp:242] Iteration 58300 (103.14 iter/s, 0.96956s/100 iter), loss = 1.29499
I0506 04:38:47.499758 12834 solver.cpp:261]     Train net output #0: loss = 1.29499 (* 1 = 1.29499 loss)
I0506 04:38:47.499768 12834 sgd_solver.cpp:106] Iteration 58300, lr = 3.2768e-05
I0506 04:38:47.504490 12834 solver.cpp:242] Iteration 58300 (103.138 iter/s, 0.969574s/100 iter), loss = 0.477254
I0506 04:38:47.504516 12834 solver.cpp:261]     Train net output #0: loss = 0.477254 (* 1 = 0.477254 loss)
I0506 04:38:47.504525 12834 sgd_solver.cpp:106] Iteration 58300, lr = 3.2768e-05
I0506 04:38:48.437260 12834 solver.cpp:242] Iteration 58400 (106.67 iter/s, 0.937471s/100 iter), loss = 1.92691
I0506 04:38:48.437296 12834 solver.cpp:261]     Train net output #0: loss = 1.92691 (* 1 = 1.92691 loss)
I0506 04:38:48.437305 12834 sgd_solver.cpp:106] Iteration 58400, lr = 3.2768e-05
I0506 04:38:48.442015 12834 solver.cpp:242] Iteration 58400 (106.669 iter/s, 0.937481s/100 iter), loss = 0.672386
I0506 04:38:48.442039 12834 solver.cpp:261]     Train net output #0: loss = 0.672386 (* 1 = 0.672386 loss)
I0506 04:38:48.442049 12834 sgd_solver.cpp:106] Iteration 58400, lr = 3.2768e-05
I0506 04:38:49.371407 12834 solver.cpp:362] Iteration 58500, Testing net (#0)
I0506 04:38:49.371428 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:49.494058 12834 solver.cpp:429]     Test net output #0: loss = 1.75548 (* 1 = 1.75548 loss)
I0506 04:38:49.496574 12834 solver.cpp:242] Iteration 58500 (94.4057 iter/s, 1.05926s/100 iter), loss = 3.30389
I0506 04:38:49.496594 12834 solver.cpp:261]     Train net output #0: loss = 3.30389 (* 1 = 3.30389 loss)
I0506 04:38:49.496603 12834 sgd_solver.cpp:106] Iteration 58500, lr = 3.2768e-05
I0506 04:38:49.498442 12834 solver.cpp:362] Iteration 58500, Testing net (#0)
I0506 04:38:49.498456 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:49.627020 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7215
I0506 04:38:49.627039 12834 solver.cpp:429]     Test net output #1: loss = 0.682897 (* 1 = 0.682897 loss)
I0506 04:38:49.629592 12834 solver.cpp:242] Iteration 58500 (84.2083 iter/s, 1.18753s/100 iter), loss = 0.909048
I0506 04:38:49.629612 12834 solver.cpp:261]     Train net output #0: loss = 0.909048 (* 1 = 0.909048 loss)
I0506 04:38:49.629621 12834 sgd_solver.cpp:106] Iteration 58500, lr = 3.2768e-05
I0506 04:38:50.562418 12834 solver.cpp:242] Iteration 58600 (93.8271 iter/s, 1.06579s/100 iter), loss = 1.27415
I0506 04:38:50.562456 12834 solver.cpp:261]     Train net output #0: loss = 1.27415 (* 1 = 1.27415 loss)
I0506 04:38:50.562465 12834 sgd_solver.cpp:106] Iteration 58600, lr = 3.2768e-05
I0506 04:38:50.567209 12834 solver.cpp:242] Iteration 58600 (106.658 iter/s, 0.937577s/100 iter), loss = 0.514531
I0506 04:38:50.567232 12834 solver.cpp:261]     Train net output #0: loss = 0.514531 (* 1 = 0.514531 loss)
I0506 04:38:50.567241 12834 sgd_solver.cpp:106] Iteration 58600, lr = 3.2768e-05
I0506 04:38:51.513092 12834 solver.cpp:242] Iteration 58700 (105.196 iter/s, 0.950611s/100 iter), loss = 0.907006
I0506 04:38:51.513128 12834 solver.cpp:261]     Train net output #0: loss = 0.907006 (* 1 = 0.907006 loss)
I0506 04:38:51.513137 12834 sgd_solver.cpp:106] Iteration 58700, lr = 3.2768e-05
I0506 04:38:51.517871 12834 solver.cpp:242] Iteration 58700 (105.194 iter/s, 0.95062s/100 iter), loss = 0.570344
I0506 04:38:51.517896 12834 solver.cpp:261]     Train net output #0: loss = 0.570344 (* 1 = 0.570344 loss)
I0506 04:38:51.517905 12834 sgd_solver.cpp:106] Iteration 58700, lr = 3.2768e-05
I0506 04:38:52.450280 12834 solver.cpp:242] Iteration 58800 (106.709 iter/s, 0.937124s/100 iter), loss = 1.11186
I0506 04:38:52.450310 12834 solver.cpp:261]     Train net output #0: loss = 1.11186 (* 1 = 1.11186 loss)
I0506 04:38:52.450320 12834 sgd_solver.cpp:106] Iteration 58800, lr = 3.2768e-05
I0506 04:38:52.455037 12834 solver.cpp:242] Iteration 58800 (106.71 iter/s, 0.937123s/100 iter), loss = 0.745428
I0506 04:38:52.455067 12834 solver.cpp:261]     Train net output #0: loss = 0.745428 (* 1 = 0.745428 loss)
I0506 04:38:52.455077 12834 sgd_solver.cpp:106] Iteration 58800, lr = 3.2768e-05
I0506 04:38:53.387794 12834 solver.cpp:242] Iteration 58900 (106.671 iter/s, 0.93746s/100 iter), loss = 4.96656
I0506 04:38:53.387835 12834 solver.cpp:261]     Train net output #0: loss = 4.96656 (* 1 = 4.96656 loss)
I0506 04:38:53.387843 12834 sgd_solver.cpp:106] Iteration 58900, lr = 3.2768e-05
I0506 04:38:53.392673 12834 solver.cpp:242] Iteration 58900 (106.658 iter/s, 0.937577s/100 iter), loss = 0.697973
I0506 04:38:53.392698 12834 solver.cpp:261]     Train net output #0: loss = 0.697973 (* 1 = 0.697973 loss)
I0506 04:38:53.392707 12834 sgd_solver.cpp:106] Iteration 58900, lr = 3.2768e-05
I0506 04:38:54.348706 12834 solver.cpp:362] Iteration 59000, Testing net (#0)
I0506 04:38:54.348737 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:54.471506 12834 solver.cpp:429]     Test net output #0: loss = 1.57158 (* 1 = 1.57158 loss)
I0506 04:38:54.474023 12834 solver.cpp:242] Iteration 59000 (92.0667 iter/s, 1.08617s/100 iter), loss = 1.35622
I0506 04:38:54.474043 12834 solver.cpp:261]     Train net output #0: loss = 1.35622 (* 1 = 1.35622 loss)
I0506 04:38:54.474052 12834 sgd_solver.cpp:106] Iteration 59000, lr = 3.2768e-05
I0506 04:38:54.475875 12834 solver.cpp:362] Iteration 59000, Testing net (#0)
I0506 04:38:54.475890 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:54.604660 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7255
I0506 04:38:54.604681 12834 solver.cpp:429]     Test net output #1: loss = 0.660034 (* 1 = 0.660034 loss)
I0506 04:38:54.607228 12834 solver.cpp:242] Iteration 59000 (82.3378 iter/s, 1.21451s/100 iter), loss = 0.817358
I0506 04:38:54.607247 12834 solver.cpp:261]     Train net output #0: loss = 0.817358 (* 1 = 0.817358 loss)
I0506 04:38:54.607255 12834 sgd_solver.cpp:106] Iteration 59000, lr = 3.2768e-05
I0506 04:38:55.539727 12834 solver.cpp:242] Iteration 59100 (93.8388 iter/s, 1.06566s/100 iter), loss = 0.70862
I0506 04:38:55.539769 12834 solver.cpp:261]     Train net output #0: loss = 0.70862 (* 1 = 0.70862 loss)
I0506 04:38:55.539778 12834 sgd_solver.cpp:106] Iteration 59100, lr = 3.2768e-05
I0506 04:38:55.544522 12834 solver.cpp:242] Iteration 59100 (106.695 iter/s, 0.937247s/100 iter), loss = 0.569131
I0506 04:38:55.544548 12834 solver.cpp:261]     Train net output #0: loss = 0.569131 (* 1 = 0.569131 loss)
I0506 04:38:55.544561 12834 sgd_solver.cpp:106] Iteration 59100, lr = 3.2768e-05
I0506 04:38:56.477005 12834 solver.cpp:242] Iteration 59200 (106.7 iter/s, 0.937209s/100 iter), loss = 3.17254
I0506 04:38:56.477043 12834 solver.cpp:261]     Train net output #0: loss = 3.17254 (* 1 = 3.17254 loss)
I0506 04:38:56.477052 12834 sgd_solver.cpp:106] Iteration 59200, lr = 3.2768e-05
I0506 04:38:56.481767 12834 solver.cpp:242] Iteration 59200 (106.701 iter/s, 0.937203s/100 iter), loss = 0.591611
I0506 04:38:56.481793 12834 solver.cpp:261]     Train net output #0: loss = 0.591611 (* 1 = 0.591611 loss)
I0506 04:38:56.481802 12834 sgd_solver.cpp:106] Iteration 59200, lr = 3.2768e-05
I0506 04:38:57.414007 12834 solver.cpp:242] Iteration 59300 (106.731 iter/s, 0.936931s/100 iter), loss = 3.02869
I0506 04:38:57.414050 12834 solver.cpp:261]     Train net output #0: loss = 3.02869 (* 1 = 3.02869 loss)
I0506 04:38:57.414060 12834 sgd_solver.cpp:106] Iteration 59300, lr = 3.2768e-05
I0506 04:38:57.418781 12834 solver.cpp:242] Iteration 59300 (106.727 iter/s, 0.936969s/100 iter), loss = 0.711114
I0506 04:38:57.418804 12834 solver.cpp:261]     Train net output #0: loss = 0.711114 (* 1 = 0.711114 loss)
I0506 04:38:57.418813 12834 sgd_solver.cpp:106] Iteration 59300, lr = 3.2768e-05
I0506 04:38:58.351737 12834 solver.cpp:242] Iteration 59400 (106.648 iter/s, 0.937661s/100 iter), loss = 4.48199
I0506 04:38:58.351774 12834 solver.cpp:261]     Train net output #0: loss = 4.48199 (* 1 = 4.48199 loss)
I0506 04:38:58.351784 12834 sgd_solver.cpp:106] Iteration 59400, lr = 3.2768e-05
I0506 04:38:58.356530 12834 solver.cpp:242] Iteration 59400 (106.643 iter/s, 0.937708s/100 iter), loss = 0.817212
I0506 04:38:58.356572 12834 solver.cpp:261]     Train net output #0: loss = 0.817212 (* 1 = 0.817212 loss)
I0506 04:38:58.356583 12834 sgd_solver.cpp:106] Iteration 59400, lr = 3.2768e-05
I0506 04:38:59.360887 12834 solver.cpp:362] Iteration 59500, Testing net (#0)
I0506 04:38:59.360918 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:59.494123 12834 solver.cpp:429]     Test net output #0: loss = 1.87547 (* 1 = 1.87547 loss)
I0506 04:38:59.496773 12834 solver.cpp:242] Iteration 59500 (87.338 iter/s, 1.14498s/100 iter), loss = 2.16066
I0506 04:38:59.496796 12834 solver.cpp:261]     Train net output #0: loss = 2.16066 (* 1 = 2.16066 loss)
I0506 04:38:59.496807 12834 sgd_solver.cpp:106] Iteration 59500, lr = 3.2768e-05
I0506 04:38:59.499023 12834 solver.cpp:362] Iteration 59500, Testing net (#0)
I0506 04:38:59.499038 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:38:59.639816 12834 solver.cpp:429]     Test net output #0: accuracy = 0.724
I0506 04:38:59.639840 12834 solver.cpp:429]     Test net output #1: loss = 0.662809 (* 1 = 0.662809 loss)
I0506 04:38:59.642534 12834 solver.cpp:242] Iteration 59500 (77.7642 iter/s, 1.28594s/100 iter), loss = 0.483301
I0506 04:38:59.642560 12834 solver.cpp:261]     Train net output #0: loss = 0.483301 (* 1 = 0.483301 loss)
I0506 04:38:59.642570 12834 sgd_solver.cpp:106] Iteration 59500, lr = 3.2768e-05
I0506 04:39:00.680784 12834 solver.cpp:242] Iteration 59600 (84.4627 iter/s, 1.18395s/100 iter), loss = 1.22056
I0506 04:39:00.680841 12834 solver.cpp:261]     Train net output #0: loss = 1.22056 (* 1 = 1.22056 loss)
I0506 04:39:00.680853 12834 sgd_solver.cpp:106] Iteration 59600, lr = 3.2768e-05
I0506 04:39:00.686127 12834 solver.cpp:242] Iteration 59600 (95.8271 iter/s, 1.04355s/100 iter), loss = 0.625302
I0506 04:39:00.686161 12834 solver.cpp:261]     Train net output #0: loss = 0.625302 (* 1 = 0.625302 loss)
I0506 04:39:00.686172 12834 sgd_solver.cpp:106] Iteration 59600, lr = 3.2768e-05
I0506 04:39:01.714310 12834 solver.cpp:242] Iteration 59700 (96.7644 iter/s, 1.03344s/100 iter), loss = 2.96577
I0506 04:39:01.714349 12834 solver.cpp:261]     Train net output #0: loss = 2.96577 (* 1 = 2.96577 loss)
I0506 04:39:01.714359 12834 sgd_solver.cpp:106] Iteration 59700, lr = 3.2768e-05
I0506 04:39:01.719084 12834 solver.cpp:242] Iteration 59700 (96.8144 iter/s, 1.0329s/100 iter), loss = 0.987879
I0506 04:39:01.719110 12834 solver.cpp:261]     Train net output #0: loss = 0.987879 (* 1 = 0.987879 loss)
I0506 04:39:01.719120 12834 sgd_solver.cpp:106] Iteration 59700, lr = 3.2768e-05
I0506 04:39:02.659497 12834 solver.cpp:242] Iteration 59800 (105.807 iter/s, 0.945121s/100 iter), loss = 1.84802
I0506 04:39:02.659549 12834 solver.cpp:261]     Train net output #0: loss = 1.84802 (* 1 = 1.84802 loss)
I0506 04:39:02.659613 12834 sgd_solver.cpp:106] Iteration 59800, lr = 3.2768e-05
I0506 04:39:02.664494 12834 solver.cpp:242] Iteration 59800 (105.78 iter/s, 0.945356s/100 iter), loss = 0.463392
I0506 04:39:02.664520 12834 solver.cpp:261]     Train net output #0: loss = 0.463392 (* 1 = 0.463392 loss)
I0506 04:39:02.664530 12834 sgd_solver.cpp:106] Iteration 59800, lr = 3.2768e-05
I0506 04:39:03.597457 12834 solver.cpp:242] Iteration 59900 (106.623 iter/s, 0.937883s/100 iter), loss = 1.07389
I0506 04:39:03.597494 12834 solver.cpp:261]     Train net output #0: loss = 1.07389 (* 1 = 1.07389 loss)
I0506 04:39:03.597504 12834 sgd_solver.cpp:106] Iteration 59900, lr = 3.2768e-05
I0506 04:39:03.602217 12834 solver.cpp:242] Iteration 59900 (106.646 iter/s, 0.937679s/100 iter), loss = 0.6892
I0506 04:39:03.602242 12834 solver.cpp:261]     Train net output #0: loss = 0.6892 (* 1 = 0.6892 loss)
I0506 04:39:03.602252 12834 sgd_solver.cpp:106] Iteration 59900, lr = 3.2768e-05
I0506 04:39:04.532238 12834 solver.cpp:362] Iteration 60000, Testing net (#0)
I0506 04:39:04.532264 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:04.654968 12834 solver.cpp:429]     Test net output #0: loss = 1.90172 (* 1 = 1.90172 loss)
I0506 04:39:04.657502 12834 solver.cpp:242] Iteration 60000 (94.3407 iter/s, 1.05999s/100 iter), loss = 1.65392
I0506 04:39:04.657523 12834 solver.cpp:261]     Train net output #0: loss = 1.65392 (* 1 = 1.65392 loss)
I0506 04:39:04.657532 12834 sgd_solver.cpp:106] Iteration 60000, lr = 2.62144e-05
I0506 04:39:04.659422 12834 solver.cpp:362] Iteration 60000, Testing net (#0)
I0506 04:39:04.659435 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:04.788470 12834 solver.cpp:429]     Test net output #0: accuracy = 0.73
I0506 04:39:04.788488 12834 solver.cpp:429]     Test net output #1: loss = 0.664936 (* 1 = 0.664936 loss)
I0506 04:39:04.791041 12834 solver.cpp:242] Iteration 60000 (84.12 iter/s, 1.18878s/100 iter), loss = 1.38003
I0506 04:39:04.791062 12834 solver.cpp:261]     Train net output #0: loss = 1.38003 (* 1 = 1.38003 loss)
I0506 04:39:04.791071 12834 sgd_solver.cpp:106] Iteration 60000, lr = 2.62144e-05
I0506 04:39:05.734696 12834 solver.cpp:242] Iteration 60100 (92.8381 iter/s, 1.07714s/100 iter), loss = 2.08743
I0506 04:39:05.734735 12834 solver.cpp:261]     Train net output #0: loss = 2.08743 (* 1 = 2.08743 loss)
I0506 04:39:05.734745 12834 sgd_solver.cpp:106] Iteration 60100, lr = 2.62144e-05
I0506 04:39:05.739437 12834 solver.cpp:242] Iteration 60100 (105.446 iter/s, 0.948355s/100 iter), loss = 0.710002
I0506 04:39:05.739464 12834 solver.cpp:261]     Train net output #0: loss = 0.710002 (* 1 = 0.710002 loss)
I0506 04:39:05.739472 12834 sgd_solver.cpp:106] Iteration 60100, lr = 2.62144e-05
I0506 04:39:06.672266 12834 solver.cpp:242] Iteration 60200 (106.667 iter/s, 0.937501s/100 iter), loss = 2.37994
I0506 04:39:06.672303 12834 solver.cpp:261]     Train net output #0: loss = 2.37994 (* 1 = 2.37994 loss)
I0506 04:39:06.672312 12834 sgd_solver.cpp:106] Iteration 60200, lr = 2.62144e-05
I0506 04:39:06.677058 12834 solver.cpp:242] Iteration 60200 (106.658 iter/s, 0.937577s/100 iter), loss = 0.580408
I0506 04:39:06.677083 12834 solver.cpp:261]     Train net output #0: loss = 0.580408 (* 1 = 0.580408 loss)
I0506 04:39:06.677091 12834 sgd_solver.cpp:106] Iteration 60200, lr = 2.62144e-05
I0506 04:39:07.609553 12834 solver.cpp:242] Iteration 60300 (106.698 iter/s, 0.937225s/100 iter), loss = 1.22929
I0506 04:39:07.609588 12834 solver.cpp:261]     Train net output #0: loss = 1.22929 (* 1 = 1.22929 loss)
I0506 04:39:07.609597 12834 sgd_solver.cpp:106] Iteration 60300, lr = 2.62144e-05
I0506 04:39:07.614363 12834 solver.cpp:242] Iteration 60300 (106.694 iter/s, 0.937262s/100 iter), loss = 0.858564
I0506 04:39:07.614387 12834 solver.cpp:261]     Train net output #0: loss = 0.858564 (* 1 = 0.858564 loss)
I0506 04:39:07.614397 12834 sgd_solver.cpp:106] Iteration 60300, lr = 2.62144e-05
I0506 04:39:08.567214 12834 solver.cpp:242] Iteration 60400 (104.428 iter/s, 0.957595s/100 iter), loss = 0.92181
I0506 04:39:08.567253 12834 solver.cpp:261]     Train net output #0: loss = 0.92181 (* 1 = 0.92181 loss)
I0506 04:39:08.567263 12834 sgd_solver.cpp:106] Iteration 60400, lr = 2.62144e-05
I0506 04:39:08.571987 12834 solver.cpp:242] Iteration 60400 (104.43 iter/s, 0.957581s/100 iter), loss = 0.722415
I0506 04:39:08.572015 12834 solver.cpp:261]     Train net output #0: loss = 0.722415 (* 1 = 0.722415 loss)
I0506 04:39:08.572023 12834 sgd_solver.cpp:106] Iteration 60400, lr = 2.62144e-05
I0506 04:39:09.502014 12834 solver.cpp:362] Iteration 60500, Testing net (#0)
I0506 04:39:09.502043 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:09.624742 12834 solver.cpp:429]     Test net output #0: loss = 1.61973 (* 1 = 1.61973 loss)
I0506 04:39:09.627264 12834 solver.cpp:242] Iteration 60500 (94.3404 iter/s, 1.05999s/100 iter), loss = 0.747298
I0506 04:39:09.627285 12834 solver.cpp:261]     Train net output #0: loss = 0.747298 (* 1 = 0.747298 loss)
I0506 04:39:09.627292 12834 sgd_solver.cpp:106] Iteration 60500, lr = 2.62144e-05
I0506 04:39:09.629127 12834 solver.cpp:362] Iteration 60500, Testing net (#0)
I0506 04:39:09.629142 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:09.757872 12834 solver.cpp:429]     Test net output #0: accuracy = 0.745
I0506 04:39:09.757891 12834 solver.cpp:429]     Test net output #1: loss = 0.623333 (* 1 = 0.623333 loss)
I0506 04:39:09.760442 12834 solver.cpp:242] Iteration 60500 (84.1463 iter/s, 1.18841s/100 iter), loss = 0.635929
I0506 04:39:09.760462 12834 solver.cpp:261]     Train net output #0: loss = 0.635929 (* 1 = 0.635929 loss)
I0506 04:39:09.760469 12834 sgd_solver.cpp:106] Iteration 60500, lr = 2.62144e-05
I0506 04:39:10.693338 12834 solver.cpp:242] Iteration 60600 (93.8069 iter/s, 1.06602s/100 iter), loss = 3.00939
I0506 04:39:10.693378 12834 solver.cpp:261]     Train net output #0: loss = 3.00939 (* 1 = 3.00939 loss)
I0506 04:39:10.693388 12834 sgd_solver.cpp:106] Iteration 60600, lr = 2.62144e-05
I0506 04:39:10.698141 12834 solver.cpp:242] Iteration 60600 (106.648 iter/s, 0.937662s/100 iter), loss = 0.588727
I0506 04:39:10.698168 12834 solver.cpp:261]     Train net output #0: loss = 0.588727 (* 1 = 0.588727 loss)
I0506 04:39:10.698176 12834 sgd_solver.cpp:106] Iteration 60600, lr = 2.62144e-05
I0506 04:39:11.630720 12834 solver.cpp:242] Iteration 60700 (106.688 iter/s, 0.937316s/100 iter), loss = 1.2909
I0506 04:39:11.630760 12834 solver.cpp:261]     Train net output #0: loss = 1.2909 (* 1 = 1.2909 loss)
I0506 04:39:11.630770 12834 sgd_solver.cpp:106] Iteration 60700, lr = 2.62144e-05
I0506 04:39:11.635577 12834 solver.cpp:242] Iteration 60700 (106.68 iter/s, 0.937381s/100 iter), loss = 1.00844
I0506 04:39:11.635603 12834 solver.cpp:261]     Train net output #0: loss = 1.00844 (* 1 = 1.00844 loss)
I0506 04:39:11.635612 12834 sgd_solver.cpp:106] Iteration 60700, lr = 2.62144e-05
I0506 04:39:12.567845 12834 solver.cpp:242] Iteration 60800 (106.717 iter/s, 0.937057s/100 iter), loss = 1.02556
I0506 04:39:12.567884 12834 solver.cpp:261]     Train net output #0: loss = 1.02556 (* 1 = 1.02556 loss)
I0506 04:39:12.567894 12834 sgd_solver.cpp:106] Iteration 60800, lr = 2.62144e-05
I0506 04:39:12.572635 12834 solver.cpp:242] Iteration 60800 (106.722 iter/s, 0.937013s/100 iter), loss = 0.505105
I0506 04:39:12.572660 12834 solver.cpp:261]     Train net output #0: loss = 0.505105 (* 1 = 0.505105 loss)
I0506 04:39:12.572669 12834 sgd_solver.cpp:106] Iteration 60800, lr = 2.62144e-05
I0506 04:39:13.504797 12834 solver.cpp:242] Iteration 60900 (106.736 iter/s, 0.93689s/100 iter), loss = 1.7095
I0506 04:39:13.504849 12834 solver.cpp:261]     Train net output #0: loss = 1.7095 (* 1 = 1.7095 loss)
I0506 04:39:13.504932 12834 sgd_solver.cpp:106] Iteration 60900, lr = 2.62144e-05
I0506 04:39:13.509814 12834 solver.cpp:242] Iteration 60900 (106.709 iter/s, 0.937125s/100 iter), loss = 0.649206
I0506 04:39:13.509838 12834 solver.cpp:261]     Train net output #0: loss = 0.649206 (* 1 = 0.649206 loss)
I0506 04:39:13.509847 12834 sgd_solver.cpp:106] Iteration 60900, lr = 2.62144e-05
I0506 04:39:14.439749 12834 solver.cpp:362] Iteration 61000, Testing net (#0)
I0506 04:39:14.439774 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:14.562364 12834 solver.cpp:429]     Test net output #0: loss = 1.2958 (* 1 = 1.2958 loss)
I0506 04:39:14.564888 12834 solver.cpp:242] Iteration 61000 (94.3378 iter/s, 1.06002s/100 iter), loss = 0.879475
I0506 04:39:14.564911 12834 solver.cpp:261]     Train net output #0: loss = 0.879475 (* 1 = 0.879475 loss)
I0506 04:39:14.564920 12834 sgd_solver.cpp:106] Iteration 61000, lr = 2.62144e-05
I0506 04:39:14.566733 12834 solver.cpp:362] Iteration 61000, Testing net (#0)
I0506 04:39:14.566745 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:14.695497 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7525
I0506 04:39:14.695516 12834 solver.cpp:429]     Test net output #1: loss = 0.590941 (* 1 = 0.590941 loss)
I0506 04:39:14.698081 12834 solver.cpp:242] Iteration 61000 (84.1593 iter/s, 1.18822s/100 iter), loss = 0.495667
I0506 04:39:14.698103 12834 solver.cpp:261]     Train net output #0: loss = 0.495667 (* 1 = 0.495667 loss)
I0506 04:39:14.698112 12834 sgd_solver.cpp:106] Iteration 61000, lr = 2.62144e-05
I0506 04:39:15.630301 12834 solver.cpp:242] Iteration 61100 (93.8655 iter/s, 1.06535s/100 iter), loss = 3.92599
I0506 04:39:15.630340 12834 solver.cpp:261]     Train net output #0: loss = 3.92599 (* 1 = 3.92599 loss)
I0506 04:39:15.630349 12834 sgd_solver.cpp:106] Iteration 61100, lr = 2.62144e-05
I0506 04:39:15.635098 12834 solver.cpp:242] Iteration 61100 (106.726 iter/s, 0.936975s/100 iter), loss = 0.518743
I0506 04:39:15.635124 12834 solver.cpp:261]     Train net output #0: loss = 0.518743 (* 1 = 0.518743 loss)
I0506 04:39:15.635133 12834 sgd_solver.cpp:106] Iteration 61100, lr = 2.62144e-05
I0506 04:39:16.567585 12834 solver.cpp:242] Iteration 61200 (106.699 iter/s, 0.93722s/100 iter), loss = 1.35989
I0506 04:39:16.567622 12834 solver.cpp:261]     Train net output #0: loss = 1.35989 (* 1 = 1.35989 loss)
I0506 04:39:16.567632 12834 sgd_solver.cpp:106] Iteration 61200, lr = 2.62144e-05
I0506 04:39:16.572357 12834 solver.cpp:242] Iteration 61200 (106.699 iter/s, 0.937215s/100 iter), loss = 0.554787
I0506 04:39:16.572382 12834 solver.cpp:261]     Train net output #0: loss = 0.554787 (* 1 = 0.554787 loss)
I0506 04:39:16.572391 12834 sgd_solver.cpp:106] Iteration 61200, lr = 2.62144e-05
I0506 04:39:17.504536 12834 solver.cpp:242] Iteration 61300 (106.737 iter/s, 0.936881s/100 iter), loss = 3.02141
I0506 04:39:17.504588 12834 solver.cpp:261]     Train net output #0: loss = 3.02141 (* 1 = 3.02141 loss)
I0506 04:39:17.504598 12834 sgd_solver.cpp:106] Iteration 61300, lr = 2.62144e-05
I0506 04:39:17.509316 12834 solver.cpp:242] Iteration 61300 (106.733 iter/s, 0.936915s/100 iter), loss = 0.662169
I0506 04:39:17.509341 12834 solver.cpp:261]     Train net output #0: loss = 0.662169 (* 1 = 0.662169 loss)
I0506 04:39:17.509351 12834 sgd_solver.cpp:106] Iteration 61300, lr = 2.62144e-05
I0506 04:39:18.442042 12834 solver.cpp:242] Iteration 61400 (106.675 iter/s, 0.937428s/100 iter), loss = 0.902431
I0506 04:39:18.442080 12834 solver.cpp:261]     Train net output #0: loss = 0.902431 (* 1 = 0.902431 loss)
I0506 04:39:18.442090 12834 sgd_solver.cpp:106] Iteration 61400, lr = 2.62144e-05
I0506 04:39:18.446820 12834 solver.cpp:242] Iteration 61400 (106.671 iter/s, 0.93746s/100 iter), loss = 0.721773
I0506 04:39:18.446843 12834 solver.cpp:261]     Train net output #0: loss = 0.721773 (* 1 = 0.721773 loss)
I0506 04:39:18.446852 12834 sgd_solver.cpp:106] Iteration 61400, lr = 2.62144e-05
I0506 04:39:19.438765 12834 solver.cpp:362] Iteration 61500, Testing net (#0)
I0506 04:39:19.438794 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:19.561435 12834 solver.cpp:429]     Test net output #0: loss = 1.70559 (* 1 = 1.70559 loss)
I0506 04:39:19.563956 12834 solver.cpp:242] Iteration 61500 (89.138 iter/s, 1.12186s/100 iter), loss = 3.14649
I0506 04:39:19.563976 12834 solver.cpp:261]     Train net output #0: loss = 3.14649 (* 1 = 3.14649 loss)
I0506 04:39:19.563984 12834 sgd_solver.cpp:106] Iteration 61500, lr = 2.62144e-05
I0506 04:39:19.565807 12834 solver.cpp:362] Iteration 61500, Testing net (#0)
I0506 04:39:19.565819 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:19.694591 12834 solver.cpp:429]     Test net output #0: accuracy = 0.745
I0506 04:39:19.694609 12834 solver.cpp:429]     Test net output #1: loss = 0.625183 (* 1 = 0.625183 loss)
I0506 04:39:19.697177 12834 solver.cpp:242] Iteration 61500 (79.98 iter/s, 1.25031s/100 iter), loss = 0.964479
I0506 04:39:19.697197 12834 solver.cpp:261]     Train net output #0: loss = 0.964479 (* 1 = 0.964479 loss)
I0506 04:39:19.697206 12834 sgd_solver.cpp:106] Iteration 61500, lr = 2.62144e-05
I0506 04:39:20.630448 12834 solver.cpp:242] Iteration 61600 (93.7693 iter/s, 1.06645s/100 iter), loss = 0.868442
I0506 04:39:20.630482 12834 solver.cpp:261]     Train net output #0: loss = 0.868442 (* 1 = 0.868442 loss)
I0506 04:39:20.630492 12834 sgd_solver.cpp:106] Iteration 61600, lr = 2.62144e-05
I0506 04:39:20.635282 12834 solver.cpp:242] Iteration 61600 (106.604 iter/s, 0.938055s/100 iter), loss = 0.68295
I0506 04:39:20.635306 12834 solver.cpp:261]     Train net output #0: loss = 0.68295 (* 1 = 0.68295 loss)
I0506 04:39:20.635324 12834 sgd_solver.cpp:106] Iteration 61600, lr = 2.62144e-05
I0506 04:39:21.568428 12834 solver.cpp:242] Iteration 61700 (106.619 iter/s, 0.937921s/100 iter), loss = 0.66897
I0506 04:39:21.568459 12834 solver.cpp:261]     Train net output #0: loss = 0.66897 (* 1 = 0.66897 loss)
I0506 04:39:21.568469 12834 sgd_solver.cpp:106] Iteration 61700, lr = 2.62144e-05
I0506 04:39:21.573201 12834 solver.cpp:242] Iteration 61700 (106.624 iter/s, 0.937876s/100 iter), loss = 0.582711
I0506 04:39:21.573225 12834 solver.cpp:261]     Train net output #0: loss = 0.582711 (* 1 = 0.582711 loss)
I0506 04:39:21.573235 12834 sgd_solver.cpp:106] Iteration 61700, lr = 2.62144e-05
I0506 04:39:22.505195 12834 solver.cpp:242] Iteration 61800 (106.756 iter/s, 0.936711s/100 iter), loss = 2.85316
I0506 04:39:22.505235 12834 solver.cpp:261]     Train net output #0: loss = 2.85316 (* 1 = 2.85316 loss)
I0506 04:39:22.505245 12834 sgd_solver.cpp:106] Iteration 61800, lr = 2.62144e-05
I0506 04:39:22.510033 12834 solver.cpp:242] Iteration 61800 (106.749 iter/s, 0.936781s/100 iter), loss = 1.00034
I0506 04:39:22.510059 12834 solver.cpp:261]     Train net output #0: loss = 1.00034 (* 1 = 1.00034 loss)
I0506 04:39:22.510068 12834 sgd_solver.cpp:106] Iteration 61800, lr = 2.62144e-05
I0506 04:39:23.515359 12834 solver.cpp:242] Iteration 61900 (99.0005 iter/s, 1.0101s/100 iter), loss = 1.36222
I0506 04:39:23.515399 12834 solver.cpp:261]     Train net output #0: loss = 1.36222 (* 1 = 1.36222 loss)
I0506 04:39:23.515409 12834 sgd_solver.cpp:106] Iteration 61900, lr = 2.62144e-05
I0506 04:39:23.520156 12834 solver.cpp:242] Iteration 61900 (99.0023 iter/s, 1.01008s/100 iter), loss = 0.818304
I0506 04:39:23.520182 12834 solver.cpp:261]     Train net output #0: loss = 0.818304 (* 1 = 0.818304 loss)
I0506 04:39:23.520191 12834 sgd_solver.cpp:106] Iteration 61900, lr = 2.62144e-05
I0506 04:39:24.450990 12834 solver.cpp:362] Iteration 62000, Testing net (#0)
I0506 04:39:24.451017 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:24.573663 12834 solver.cpp:429]     Test net output #0: loss = 1.76596 (* 1 = 1.76596 loss)
I0506 04:39:24.576186 12834 solver.cpp:242] Iteration 62000 (94.2713 iter/s, 1.06077s/100 iter), loss = 1.6779
I0506 04:39:24.576206 12834 solver.cpp:261]     Train net output #0: loss = 1.6779 (* 1 = 1.6779 loss)
I0506 04:39:24.576215 12834 sgd_solver.cpp:106] Iteration 62000, lr = 2.62144e-05
I0506 04:39:24.578047 12834 solver.cpp:362] Iteration 62000, Testing net (#0)
I0506 04:39:24.578060 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:24.706861 12834 solver.cpp:429]     Test net output #0: accuracy = 0.726
I0506 04:39:24.706881 12834 solver.cpp:429]     Test net output #1: loss = 0.652414 (* 1 = 0.652414 loss)
I0506 04:39:24.709442 12834 solver.cpp:242] Iteration 62000 (84.0874 iter/s, 1.18924s/100 iter), loss = 1.09858
I0506 04:39:24.709462 12834 solver.cpp:261]     Train net output #0: loss = 1.09858 (* 1 = 1.09858 loss)
I0506 04:39:24.709470 12834 sgd_solver.cpp:106] Iteration 62000, lr = 2.62144e-05
I0506 04:39:25.648905 12834 solver.cpp:242] Iteration 62100 (93.2256 iter/s, 1.07267s/100 iter), loss = 1.50661
I0506 04:39:25.648954 12834 solver.cpp:261]     Train net output #0: loss = 1.50661 (* 1 = 1.50661 loss)
I0506 04:39:25.648965 12834 sgd_solver.cpp:106] Iteration 62100, lr = 2.62144e-05
I0506 04:39:25.654191 12834 solver.cpp:242] Iteration 62100 (105.853 iter/s, 0.944708s/100 iter), loss = 0.637195
I0506 04:39:25.654222 12834 solver.cpp:261]     Train net output #0: loss = 0.637195 (* 1 = 0.637195 loss)
I0506 04:39:25.654233 12834 sgd_solver.cpp:106] Iteration 62100, lr = 2.62144e-05
I0506 04:39:26.591464 12834 solver.cpp:242] Iteration 62200 (106.103 iter/s, 0.942478s/100 iter), loss = 2.16651
I0506 04:39:26.591506 12834 solver.cpp:261]     Train net output #0: loss = 2.16651 (* 1 = 2.16651 loss)
I0506 04:39:26.591516 12834 sgd_solver.cpp:106] Iteration 62200, lr = 2.62144e-05
I0506 04:39:26.596246 12834 solver.cpp:242] Iteration 62200 (106.156 iter/s, 0.942007s/100 iter), loss = 0.60502
I0506 04:39:26.596282 12834 solver.cpp:261]     Train net output #0: loss = 0.60502 (* 1 = 0.60502 loss)
I0506 04:39:26.596290 12834 sgd_solver.cpp:106] Iteration 62200, lr = 2.62144e-05
I0506 04:39:27.528698 12834 solver.cpp:242] Iteration 62300 (106.705 iter/s, 0.937167s/100 iter), loss = 0.668079
I0506 04:39:27.528736 12834 solver.cpp:261]     Train net output #0: loss = 0.668079 (* 1 = 0.668079 loss)
I0506 04:39:27.528746 12834 sgd_solver.cpp:106] Iteration 62300, lr = 2.62144e-05
I0506 04:39:27.533475 12834 solver.cpp:242] Iteration 62300 (106.704 iter/s, 0.937176s/100 iter), loss = 0.46221
I0506 04:39:27.533500 12834 solver.cpp:261]     Train net output #0: loss = 0.46221 (* 1 = 0.46221 loss)
I0506 04:39:27.533509 12834 sgd_solver.cpp:106] Iteration 62300, lr = 2.62144e-05
I0506 04:39:28.465677 12834 solver.cpp:242] Iteration 62400 (106.734 iter/s, 0.93691s/100 iter), loss = 0.618973
I0506 04:39:28.465715 12834 solver.cpp:261]     Train net output #0: loss = 0.618973 (* 1 = 0.618973 loss)
I0506 04:39:28.465724 12834 sgd_solver.cpp:106] Iteration 62400, lr = 2.62144e-05
I0506 04:39:28.470458 12834 solver.cpp:242] Iteration 62400 (106.73 iter/s, 0.93694s/100 iter), loss = 0.6282
I0506 04:39:28.470484 12834 solver.cpp:261]     Train net output #0: loss = 0.6282 (* 1 = 0.6282 loss)
I0506 04:39:28.470492 12834 sgd_solver.cpp:106] Iteration 62400, lr = 2.62144e-05
I0506 04:39:29.399819 12834 solver.cpp:362] Iteration 62500, Testing net (#0)
I0506 04:39:29.399847 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:29.522514 12834 solver.cpp:429]     Test net output #0: loss = 1.61256 (* 1 = 1.61256 loss)
I0506 04:39:29.525081 12834 solver.cpp:242] Iteration 62500 (94.3979 iter/s, 1.05935s/100 iter), loss = 1.6611
I0506 04:39:29.525105 12834 solver.cpp:261]     Train net output #0: loss = 1.6611 (* 1 = 1.6611 loss)
I0506 04:39:29.525115 12834 sgd_solver.cpp:106] Iteration 62500, lr = 2.62144e-05
I0506 04:39:29.527025 12834 solver.cpp:362] Iteration 62500, Testing net (#0)
I0506 04:39:29.527039 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:29.655622 12834 solver.cpp:429]     Test net output #0: accuracy = 0.735
I0506 04:39:29.655640 12834 solver.cpp:429]     Test net output #1: loss = 0.628759 (* 1 = 0.628759 loss)
I0506 04:39:29.658203 12834 solver.cpp:242] Iteration 62500 (84.1964 iter/s, 1.1877s/100 iter), loss = 0.767968
I0506 04:39:29.658224 12834 solver.cpp:261]     Train net output #0: loss = 0.767968 (* 1 = 0.767968 loss)
I0506 04:39:29.658233 12834 sgd_solver.cpp:106] Iteration 62500, lr = 2.62144e-05
I0506 04:39:30.590802 12834 solver.cpp:242] Iteration 62600 (93.8381 iter/s, 1.06567s/100 iter), loss = 2.46961
I0506 04:39:30.590840 12834 solver.cpp:261]     Train net output #0: loss = 2.46961 (* 1 = 2.46961 loss)
I0506 04:39:30.590850 12834 sgd_solver.cpp:106] Iteration 62600, lr = 2.62144e-05
I0506 04:39:30.595582 12834 solver.cpp:242] Iteration 62600 (106.685 iter/s, 0.937338s/100 iter), loss = 0.662539
I0506 04:39:30.595604 12834 solver.cpp:261]     Train net output #0: loss = 0.662539 (* 1 = 0.662539 loss)
I0506 04:39:30.595613 12834 sgd_solver.cpp:106] Iteration 62600, lr = 2.62144e-05
I0506 04:39:31.528044 12834 solver.cpp:242] Iteration 62700 (106.703 iter/s, 0.937181s/100 iter), loss = 2.1044
I0506 04:39:31.528079 12834 solver.cpp:261]     Train net output #0: loss = 2.1044 (* 1 = 2.1044 loss)
I0506 04:39:31.528090 12834 sgd_solver.cpp:106] Iteration 62700, lr = 2.62144e-05
I0506 04:39:31.532886 12834 solver.cpp:242] Iteration 62700 (106.695 iter/s, 0.937253s/100 iter), loss = 0.80196
I0506 04:39:31.532909 12834 solver.cpp:261]     Train net output #0: loss = 0.80196 (* 1 = 0.80196 loss)
I0506 04:39:31.532918 12834 sgd_solver.cpp:106] Iteration 62700, lr = 2.62144e-05
I0506 04:39:32.557822 12834 solver.cpp:242] Iteration 62800 (97.1144 iter/s, 1.02971s/100 iter), loss = 1.03001
I0506 04:39:32.557867 12834 solver.cpp:261]     Train net output #0: loss = 1.03001 (* 1 = 1.03001 loss)
I0506 04:39:32.557878 12834 sgd_solver.cpp:106] Iteration 62800, lr = 2.62144e-05
I0506 04:39:32.563166 12834 solver.cpp:242] Iteration 62800 (97.0651 iter/s, 1.03024s/100 iter), loss = 0.157836
I0506 04:39:32.563197 12834 solver.cpp:261]     Train net output #0: loss = 0.157836 (* 1 = 0.157836 loss)
I0506 04:39:32.563208 12834 sgd_solver.cpp:106] Iteration 62800, lr = 2.62144e-05
I0506 04:39:33.510818 12834 solver.cpp:242] Iteration 62900 (104.941 iter/s, 0.952921s/100 iter), loss = 1.23342
I0506 04:39:33.510854 12834 solver.cpp:261]     Train net output #0: loss = 1.23342 (* 1 = 1.23342 loss)
I0506 04:39:33.510864 12834 sgd_solver.cpp:106] Iteration 62900, lr = 2.62144e-05
I0506 04:39:33.515588 12834 solver.cpp:242] Iteration 62900 (105.001 iter/s, 0.952372s/100 iter), loss = 0.552216
I0506 04:39:33.515614 12834 solver.cpp:261]     Train net output #0: loss = 0.552216 (* 1 = 0.552216 loss)
I0506 04:39:33.515622 12834 sgd_solver.cpp:106] Iteration 62900, lr = 2.62144e-05
I0506 04:39:34.444972 12834 solver.cpp:362] Iteration 63000, Testing net (#0)
I0506 04:39:34.444993 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:34.567642 12834 solver.cpp:429]     Test net output #0: loss = 1.76052 (* 1 = 1.76052 loss)
I0506 04:39:34.570204 12834 solver.cpp:242] Iteration 63000 (94.3993 iter/s, 1.05933s/100 iter), loss = 1.04887
I0506 04:39:34.570226 12834 solver.cpp:261]     Train net output #0: loss = 1.04887 (* 1 = 1.04887 loss)
I0506 04:39:34.570235 12834 sgd_solver.cpp:106] Iteration 63000, lr = 2.62144e-05
I0506 04:39:34.572075 12834 solver.cpp:362] Iteration 63000, Testing net (#0)
I0506 04:39:34.572089 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:34.700758 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7085
I0506 04:39:34.700778 12834 solver.cpp:429]     Test net output #1: loss = 0.712325 (* 1 = 0.712325 loss)
I0506 04:39:34.703336 12834 solver.cpp:242] Iteration 63000 (84.1963 iter/s, 1.1877s/100 iter), loss = 0.429418
I0506 04:39:34.703356 12834 solver.cpp:261]     Train net output #0: loss = 0.429418 (* 1 = 0.429418 loss)
I0506 04:39:34.703364 12834 sgd_solver.cpp:106] Iteration 63000, lr = 2.62144e-05
I0506 04:39:35.638790 12834 solver.cpp:242] Iteration 63100 (93.5865 iter/s, 1.06853s/100 iter), loss = 1.68876
I0506 04:39:35.638819 12834 solver.cpp:261]     Train net output #0: loss = 1.68876 (* 1 = 1.68876 loss)
I0506 04:39:35.638828 12834 sgd_solver.cpp:106] Iteration 63100, lr = 2.62144e-05
I0506 04:39:35.643543 12834 solver.cpp:242] Iteration 63100 (106.364 iter/s, 0.940168s/100 iter), loss = 0.690535
I0506 04:39:35.643571 12834 solver.cpp:261]     Train net output #0: loss = 0.690535 (* 1 = 0.690535 loss)
I0506 04:39:35.643580 12834 sgd_solver.cpp:106] Iteration 63100, lr = 2.62144e-05
I0506 04:39:36.576205 12834 solver.cpp:242] Iteration 63200 (106.683 iter/s, 0.937359s/100 iter), loss = 0.754395
I0506 04:39:36.576246 12834 solver.cpp:261]     Train net output #0: loss = 0.754395 (* 1 = 0.754395 loss)
I0506 04:39:36.576256 12834 sgd_solver.cpp:106] Iteration 63200, lr = 2.62144e-05
I0506 04:39:36.580984 12834 solver.cpp:242] Iteration 63200 (106.679 iter/s, 0.937394s/100 iter), loss = 0.49493
I0506 04:39:36.581010 12834 solver.cpp:261]     Train net output #0: loss = 0.49493 (* 1 = 0.49493 loss)
I0506 04:39:36.581019 12834 sgd_solver.cpp:106] Iteration 63200, lr = 2.62144e-05
I0506 04:39:37.513893 12834 solver.cpp:242] Iteration 63300 (106.653 iter/s, 0.937617s/100 iter), loss = 1.64837
I0506 04:39:37.513937 12834 solver.cpp:261]     Train net output #0: loss = 1.64837 (* 1 = 1.64837 loss)
I0506 04:39:37.513947 12834 sgd_solver.cpp:106] Iteration 63300, lr = 2.62144e-05
I0506 04:39:37.518674 12834 solver.cpp:242] Iteration 63300 (106.65 iter/s, 0.937645s/100 iter), loss = 0.73054
I0506 04:39:37.518699 12834 solver.cpp:261]     Train net output #0: loss = 0.73054 (* 1 = 0.73054 loss)
I0506 04:39:37.518708 12834 sgd_solver.cpp:106] Iteration 63300, lr = 2.62144e-05
I0506 04:39:38.462870 12834 solver.cpp:242] Iteration 63400 (105.384 iter/s, 0.948909s/100 iter), loss = 1.95583
I0506 04:39:38.462913 12834 solver.cpp:261]     Train net output #0: loss = 1.95583 (* 1 = 1.95583 loss)
I0506 04:39:38.462932 12834 sgd_solver.cpp:106] Iteration 63400, lr = 2.62144e-05
I0506 04:39:38.467739 12834 solver.cpp:242] Iteration 63400 (105.373 iter/s, 0.949011s/100 iter), loss = 0.830826
I0506 04:39:38.467764 12834 solver.cpp:261]     Train net output #0: loss = 0.830826 (* 1 = 0.830826 loss)
I0506 04:39:38.467773 12834 sgd_solver.cpp:106] Iteration 63400, lr = 2.62144e-05
I0506 04:39:39.410565 12834 solver.cpp:362] Iteration 63500, Testing net (#0)
I0506 04:39:39.410593 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:39.533136 12834 solver.cpp:429]     Test net output #0: loss = 1.76208 (* 1 = 1.76208 loss)
I0506 04:39:39.535652 12834 solver.cpp:242] Iteration 63500 (93.2209 iter/s, 1.07272s/100 iter), loss = 2.52481
I0506 04:39:39.535672 12834 solver.cpp:261]     Train net output #0: loss = 2.52481 (* 1 = 2.52481 loss)
I0506 04:39:39.535681 12834 sgd_solver.cpp:106] Iteration 63500, lr = 2.62144e-05
I0506 04:39:39.537500 12834 solver.cpp:362] Iteration 63500, Testing net (#0)
I0506 04:39:39.537515 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:39.666095 12834 solver.cpp:429]     Test net output #0: accuracy = 0.736
I0506 04:39:39.666121 12834 solver.cpp:429]     Test net output #1: loss = 0.643737 (* 1 = 0.643737 loss)
I0506 04:39:39.668777 12834 solver.cpp:242] Iteration 63500 (83.2645 iter/s, 1.20099s/100 iter), loss = 0.745854
I0506 04:39:39.668798 12834 solver.cpp:261]     Train net output #0: loss = 0.745854 (* 1 = 0.745854 loss)
I0506 04:39:39.668807 12834 sgd_solver.cpp:106] Iteration 63500, lr = 2.62144e-05
I0506 04:39:40.601467 12834 solver.cpp:242] Iteration 63600 (93.829 iter/s, 1.06577s/100 iter), loss = 3.08649
I0506 04:39:40.601510 12834 solver.cpp:261]     Train net output #0: loss = 3.08649 (* 1 = 3.08649 loss)
I0506 04:39:40.601519 12834 sgd_solver.cpp:106] Iteration 63600, lr = 2.62144e-05
I0506 04:39:40.606307 12834 solver.cpp:242] Iteration 63600 (106.669 iter/s, 0.93748s/100 iter), loss = 0.853006
I0506 04:39:40.606331 12834 solver.cpp:261]     Train net output #0: loss = 0.853006 (* 1 = 0.853006 loss)
I0506 04:39:40.606340 12834 sgd_solver.cpp:106] Iteration 63600, lr = 2.62144e-05
I0506 04:39:41.539361 12834 solver.cpp:242] Iteration 63700 (106.63 iter/s, 0.937824s/100 iter), loss = 0.532961
I0506 04:39:41.539400 12834 solver.cpp:261]     Train net output #0: loss = 0.532961 (* 1 = 0.532961 loss)
I0506 04:39:41.539409 12834 sgd_solver.cpp:106] Iteration 63700, lr = 2.62144e-05
I0506 04:39:41.544159 12834 solver.cpp:242] Iteration 63700 (106.631 iter/s, 0.93781s/100 iter), loss = 0.766593
I0506 04:39:41.544185 12834 solver.cpp:261]     Train net output #0: loss = 0.766593 (* 1 = 0.766593 loss)
I0506 04:39:41.544194 12834 sgd_solver.cpp:106] Iteration 63700, lr = 2.62144e-05
I0506 04:39:42.477113 12834 solver.cpp:242] Iteration 63800 (106.646 iter/s, 0.937681s/100 iter), loss = 1.19186
I0506 04:39:42.477151 12834 solver.cpp:261]     Train net output #0: loss = 1.19186 (* 1 = 1.19186 loss)
I0506 04:39:42.477160 12834 sgd_solver.cpp:106] Iteration 63800, lr = 2.62144e-05
I0506 04:39:42.481875 12834 solver.cpp:242] Iteration 63800 (106.647 iter/s, 0.937672s/100 iter), loss = 0.702042
I0506 04:39:42.481899 12834 solver.cpp:261]     Train net output #0: loss = 0.702042 (* 1 = 0.702042 loss)
I0506 04:39:42.481909 12834 sgd_solver.cpp:106] Iteration 63800, lr = 2.62144e-05
I0506 04:39:43.486575 12834 solver.cpp:242] Iteration 63900 (99.0692 iter/s, 1.0094s/100 iter), loss = 1.028
I0506 04:39:43.486613 12834 solver.cpp:261]     Train net output #0: loss = 1.028 (* 1 = 1.028 loss)
I0506 04:39:43.486623 12834 sgd_solver.cpp:106] Iteration 63900, lr = 2.62144e-05
I0506 04:39:43.491354 12834 solver.cpp:242] Iteration 63900 (99.0653 iter/s, 1.00944s/100 iter), loss = 0.67879
I0506 04:39:43.491379 12834 solver.cpp:261]     Train net output #0: loss = 0.67879 (* 1 = 0.67879 loss)
I0506 04:39:43.491389 12834 sgd_solver.cpp:106] Iteration 63900, lr = 2.62144e-05
I0506 04:39:44.421066 12834 solver.cpp:362] Iteration 64000, Testing net (#0)
I0506 04:39:44.421099 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:44.543602 12834 solver.cpp:429]     Test net output #0: loss = 1.56004 (* 1 = 1.56004 loss)
I0506 04:39:44.546129 12834 solver.cpp:242] Iteration 64000 (94.3844 iter/s, 1.0595s/100 iter), loss = 0.810107
I0506 04:39:44.546151 12834 solver.cpp:261]     Train net output #0: loss = 0.810107 (* 1 = 0.810107 loss)
I0506 04:39:44.546160 12834 sgd_solver.cpp:106] Iteration 64000, lr = 2.62144e-05
I0506 04:39:44.548007 12834 solver.cpp:362] Iteration 64000, Testing net (#0)
I0506 04:39:44.548019 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:44.676815 12834 solver.cpp:429]     Test net output #0: accuracy = 0.732
I0506 04:39:44.676838 12834 solver.cpp:429]     Test net output #1: loss = 0.6367 (* 1 = 0.6367 loss)
I0506 04:39:44.679572 12834 solver.cpp:242] Iteration 64000 (84.1629 iter/s, 1.18817s/100 iter), loss = 0.239718
I0506 04:39:44.679594 12834 solver.cpp:261]     Train net output #0: loss = 0.239718 (* 1 = 0.239718 loss)
I0506 04:39:44.679602 12834 sgd_solver.cpp:106] Iteration 64000, lr = 2.62144e-05
I0506 04:39:45.613543 12834 solver.cpp:242] Iteration 64100 (93.689 iter/s, 1.06736s/100 iter), loss = 2.70178
I0506 04:39:45.613580 12834 solver.cpp:261]     Train net output #0: loss = 2.70178 (* 1 = 2.70178 loss)
I0506 04:39:45.613590 12834 sgd_solver.cpp:106] Iteration 64100, lr = 2.62144e-05
I0506 04:39:45.618386 12834 solver.cpp:242] Iteration 64100 (106.522 iter/s, 0.938774s/100 iter), loss = 0.795178
I0506 04:39:45.618412 12834 solver.cpp:261]     Train net output #0: loss = 0.795178 (* 1 = 0.795178 loss)
I0506 04:39:45.618420 12834 sgd_solver.cpp:106] Iteration 64100, lr = 2.62144e-05
I0506 04:39:46.551966 12834 solver.cpp:242] Iteration 64200 (106.57 iter/s, 0.938355s/100 iter), loss = 3.10666
I0506 04:39:46.552001 12834 solver.cpp:261]     Train net output #0: loss = 3.10666 (* 1 = 3.10666 loss)
I0506 04:39:46.552011 12834 sgd_solver.cpp:106] Iteration 64200, lr = 2.62144e-05
I0506 04:39:46.556740 12834 solver.cpp:242] Iteration 64200 (106.575 iter/s, 0.938311s/100 iter), loss = 0.695615
I0506 04:39:46.556766 12834 solver.cpp:261]     Train net output #0: loss = 0.695615 (* 1 = 0.695615 loss)
I0506 04:39:46.556776 12834 sgd_solver.cpp:106] Iteration 64200, lr = 2.62144e-05
I0506 04:39:47.489733 12834 solver.cpp:242] Iteration 64300 (106.643 iter/s, 0.937709s/100 iter), loss = 0.899689
I0506 04:39:47.489761 12834 solver.cpp:261]     Train net output #0: loss = 0.899689 (* 1 = 0.899689 loss)
I0506 04:39:47.489771 12834 sgd_solver.cpp:106] Iteration 64300, lr = 2.62144e-05
I0506 04:39:47.494586 12834 solver.cpp:242] Iteration 64300 (106.633 iter/s, 0.937793s/100 iter), loss = 1.0003
I0506 04:39:47.494612 12834 solver.cpp:261]     Train net output #0: loss = 1.0003 (* 1 = 1.0003 loss)
I0506 04:39:47.494621 12834 sgd_solver.cpp:106] Iteration 64300, lr = 2.62144e-05
I0506 04:39:48.426677 12834 solver.cpp:242] Iteration 64400 (106.736 iter/s, 0.936887s/100 iter), loss = 1.52092
I0506 04:39:48.426718 12834 solver.cpp:261]     Train net output #0: loss = 1.52092 (* 1 = 1.52092 loss)
I0506 04:39:48.426728 12834 sgd_solver.cpp:106] Iteration 64400, lr = 2.62144e-05
I0506 04:39:48.431433 12834 solver.cpp:242] Iteration 64400 (106.746 iter/s, 0.936802s/100 iter), loss = 0.5811
I0506 04:39:48.431457 12834 solver.cpp:261]     Train net output #0: loss = 0.5811 (* 1 = 0.5811 loss)
I0506 04:39:48.431466 12834 sgd_solver.cpp:106] Iteration 64400, lr = 2.62144e-05
I0506 04:39:49.443063 12834 solver.cpp:362] Iteration 64500, Testing net (#0)
I0506 04:39:49.443094 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:49.576084 12834 solver.cpp:429]     Test net output #0: loss = 1.66811 (* 1 = 1.66811 loss)
I0506 04:39:49.578737 12834 solver.cpp:242] Iteration 64500 (86.8057 iter/s, 1.152s/100 iter), loss = 1.31348
I0506 04:39:49.578761 12834 solver.cpp:261]     Train net output #0: loss = 1.31348 (* 1 = 1.31348 loss)
I0506 04:39:49.578773 12834 sgd_solver.cpp:106] Iteration 64500, lr = 2.62144e-05
I0506 04:39:49.581073 12834 solver.cpp:362] Iteration 64500, Testing net (#0)
I0506 04:39:49.581089 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:49.719149 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7195
I0506 04:39:49.719173 12834 solver.cpp:429]     Test net output #1: loss = 0.648317 (* 1 = 0.648317 loss)
I0506 04:39:49.722064 12834 solver.cpp:242] Iteration 64500 (77.4843 iter/s, 1.29058s/100 iter), loss = 0.791319
I0506 04:39:49.722085 12834 solver.cpp:261]     Train net output #0: loss = 0.791319 (* 1 = 0.791319 loss)
I0506 04:39:49.722095 12834 sgd_solver.cpp:106] Iteration 64500, lr = 2.62144e-05
I0506 04:39:50.655527 12834 solver.cpp:242] Iteration 64600 (92.8731 iter/s, 1.07674s/100 iter), loss = 1.02349
I0506 04:39:50.655560 12834 solver.cpp:261]     Train net output #0: loss = 1.02349 (* 1 = 1.02349 loss)
I0506 04:39:50.655570 12834 sgd_solver.cpp:106] Iteration 64600, lr = 2.62144e-05
I0506 04:39:50.660310 12834 solver.cpp:242] Iteration 64600 (106.586 iter/s, 0.938206s/100 iter), loss = 0.516873
I0506 04:39:50.660333 12834 solver.cpp:261]     Train net output #0: loss = 0.516873 (* 1 = 0.516873 loss)
I0506 04:39:50.660342 12834 sgd_solver.cpp:106] Iteration 64600, lr = 2.62144e-05
I0506 04:39:51.593120 12834 solver.cpp:242] Iteration 64700 (106.663 iter/s, 0.937529s/100 iter), loss = 1.61076
I0506 04:39:51.593150 12834 solver.cpp:261]     Train net output #0: loss = 1.61076 (* 1 = 1.61076 loss)
I0506 04:39:51.593160 12834 sgd_solver.cpp:106] Iteration 64700, lr = 2.62144e-05
I0506 04:39:51.597874 12834 solver.cpp:242] Iteration 64700 (106.664 iter/s, 0.937523s/100 iter), loss = 0.772474
I0506 04:39:51.597898 12834 solver.cpp:261]     Train net output #0: loss = 0.772474 (* 1 = 0.772474 loss)
I0506 04:39:51.597906 12834 sgd_solver.cpp:106] Iteration 64700, lr = 2.62144e-05
I0506 04:39:52.530861 12834 solver.cpp:242] Iteration 64800 (106.646 iter/s, 0.937683s/100 iter), loss = 1.92108
I0506 04:39:52.530902 12834 solver.cpp:261]     Train net output #0: loss = 1.92108 (* 1 = 1.92108 loss)
I0506 04:39:52.530912 12834 sgd_solver.cpp:106] Iteration 64800, lr = 2.62144e-05
I0506 04:39:52.535696 12834 solver.cpp:242] Iteration 64800 (106.635 iter/s, 0.937779s/100 iter), loss = 0.515741
I0506 04:39:52.535722 12834 solver.cpp:261]     Train net output #0: loss = 0.515741 (* 1 = 0.515741 loss)
I0506 04:39:52.535732 12834 sgd_solver.cpp:106] Iteration 64800, lr = 2.62144e-05
I0506 04:39:53.468793 12834 solver.cpp:242] Iteration 64900 (106.626 iter/s, 0.937859s/100 iter), loss = 3.13078
I0506 04:39:53.468833 12834 solver.cpp:261]     Train net output #0: loss = 3.13078 (* 1 = 3.13078 loss)
I0506 04:39:53.468842 12834 sgd_solver.cpp:106] Iteration 64900, lr = 2.62144e-05
I0506 04:39:53.473625 12834 solver.cpp:242] Iteration 64900 (106.623 iter/s, 0.937885s/100 iter), loss = 0.606308
I0506 04:39:53.473651 12834 solver.cpp:261]     Train net output #0: loss = 0.606308 (* 1 = 0.606308 loss)
I0506 04:39:53.473661 12834 sgd_solver.cpp:106] Iteration 64900, lr = 2.62144e-05
I0506 04:39:54.403738 12834 solver.cpp:362] Iteration 65000, Testing net (#0)
I0506 04:39:54.403766 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:54.526523 12834 solver.cpp:429]     Test net output #0: loss = 1.537 (* 1 = 1.537 loss)
I0506 04:39:54.529072 12834 solver.cpp:242] Iteration 65000 (94.3202 iter/s, 1.06022s/100 iter), loss = 1.97875
I0506 04:39:54.529091 12834 solver.cpp:261]     Train net output #0: loss = 1.97875 (* 1 = 1.97875 loss)
I0506 04:39:54.529101 12834 sgd_solver.cpp:106] Iteration 65000, lr = 2.62144e-05
I0506 04:39:54.531067 12834 solver.cpp:362] Iteration 65000, Testing net (#0)
I0506 04:39:54.531086 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:54.667559 12834 solver.cpp:429]     Test net output #0: accuracy = 0.746
I0506 04:39:54.667582 12834 solver.cpp:429]     Test net output #1: loss = 0.608311 (* 1 = 0.608311 loss)
I0506 04:39:54.670279 12834 solver.cpp:242] Iteration 65000 (83.5697 iter/s, 1.19661s/100 iter), loss = 0.515633
I0506 04:39:54.670305 12834 solver.cpp:261]     Train net output #0: loss = 0.515633 (* 1 = 0.515633 loss)
I0506 04:39:54.670326 12834 sgd_solver.cpp:106] Iteration 65000, lr = 2.62144e-05
I0506 04:39:55.629284 12834 solver.cpp:242] Iteration 65100 (90.896 iter/s, 1.10016s/100 iter), loss = 1.36017
I0506 04:39:55.629326 12834 solver.cpp:261]     Train net output #0: loss = 1.36017 (* 1 = 1.36017 loss)
I0506 04:39:55.629336 12834 sgd_solver.cpp:106] Iteration 65100, lr = 2.62144e-05
I0506 04:39:55.634052 12834 solver.cpp:242] Iteration 65100 (103.764 iter/s, 0.963729s/100 iter), loss = 0.866238
I0506 04:39:55.634078 12834 solver.cpp:261]     Train net output #0: loss = 0.866238 (* 1 = 0.866238 loss)
I0506 04:39:55.634088 12834 sgd_solver.cpp:106] Iteration 65100, lr = 2.62144e-05
I0506 04:39:56.566345 12834 solver.cpp:242] Iteration 65200 (106.724 iter/s, 0.936995s/100 iter), loss = 1.78351
I0506 04:39:56.566385 12834 solver.cpp:261]     Train net output #0: loss = 1.78351 (* 1 = 1.78351 loss)
I0506 04:39:56.566395 12834 sgd_solver.cpp:106] Iteration 65200, lr = 2.62144e-05
I0506 04:39:56.571110 12834 solver.cpp:242] Iteration 65200 (106.722 iter/s, 0.937012s/100 iter), loss = 0.77844
I0506 04:39:56.571135 12834 solver.cpp:261]     Train net output #0: loss = 0.77844 (* 1 = 0.77844 loss)
I0506 04:39:56.571143 12834 sgd_solver.cpp:106] Iteration 65200, lr = 2.62144e-05
I0506 04:39:57.503690 12834 solver.cpp:242] Iteration 65300 (106.692 iter/s, 0.937275s/100 iter), loss = 5.03851
I0506 04:39:57.503731 12834 solver.cpp:261]     Train net output #0: loss = 5.03851 (* 1 = 5.03851 loss)
I0506 04:39:57.503739 12834 sgd_solver.cpp:106] Iteration 65300, lr = 2.62144e-05
I0506 04:39:57.508491 12834 solver.cpp:242] Iteration 65300 (106.685 iter/s, 0.937338s/100 iter), loss = 1.62027
I0506 04:39:57.508517 12834 solver.cpp:261]     Train net output #0: loss = 1.62027 (* 1 = 1.62027 loss)
I0506 04:39:57.508527 12834 sgd_solver.cpp:106] Iteration 65300, lr = 2.62144e-05
I0506 04:39:58.441009 12834 solver.cpp:242] Iteration 65400 (106.695 iter/s, 0.937255s/100 iter), loss = 0.556497
I0506 04:39:58.441043 12834 solver.cpp:261]     Train net output #0: loss = 0.556497 (* 1 = 0.556497 loss)
I0506 04:39:58.441052 12834 sgd_solver.cpp:106] Iteration 65400, lr = 2.62144e-05
I0506 04:39:58.445858 12834 solver.cpp:242] Iteration 65400 (106.688 iter/s, 0.937313s/100 iter), loss = 0.539435
I0506 04:39:58.445883 12834 solver.cpp:261]     Train net output #0: loss = 0.539435 (* 1 = 0.539435 loss)
I0506 04:39:58.445893 12834 sgd_solver.cpp:106] Iteration 65400, lr = 2.62144e-05
I0506 04:39:59.459168 12834 solver.cpp:362] Iteration 65500, Testing net (#0)
I0506 04:39:59.459197 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:59.592250 12834 solver.cpp:429]     Test net output #0: loss = 1.65553 (* 1 = 1.65553 loss)
I0506 04:39:59.594900 12834 solver.cpp:242] Iteration 65500 (86.6674 iter/s, 1.15384s/100 iter), loss = 2.81683
I0506 04:39:59.594925 12834 solver.cpp:261]     Train net output #0: loss = 2.81683 (* 1 = 2.81683 loss)
I0506 04:39:59.594936 12834 sgd_solver.cpp:106] Iteration 65500, lr = 2.62144e-05
I0506 04:39:59.597141 12834 solver.cpp:362] Iteration 65500, Testing net (#0)
I0506 04:39:59.597157 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:39:59.737979 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7355
I0506 04:39:59.738003 12834 solver.cpp:429]     Test net output #1: loss = 0.618314 (* 1 = 0.618314 loss)
I0506 04:39:59.740695 12834 solver.cpp:242] Iteration 65500 (77.2326 iter/s, 1.29479s/100 iter), loss = 0.585472
I0506 04:39:59.740721 12834 solver.cpp:261]     Train net output #0: loss = 0.585472 (* 1 = 0.585472 loss)
I0506 04:39:59.740732 12834 sgd_solver.cpp:106] Iteration 65500, lr = 2.62144e-05
I0506 04:40:00.736946 12834 solver.cpp:242] Iteration 65600 (87.5668 iter/s, 1.14199s/100 iter), loss = 1.42769
I0506 04:40:00.736986 12834 solver.cpp:261]     Train net output #0: loss = 1.42769 (* 1 = 1.42769 loss)
I0506 04:40:00.736995 12834 sgd_solver.cpp:106] Iteration 65600, lr = 2.62144e-05
I0506 04:40:00.741838 12834 solver.cpp:242] Iteration 65600 (99.8903 iter/s, 1.0011s/100 iter), loss = 0.465749
I0506 04:40:00.741874 12834 solver.cpp:261]     Train net output #0: loss = 0.465749 (* 1 = 0.465749 loss)
I0506 04:40:00.741884 12834 sgd_solver.cpp:106] Iteration 65600, lr = 2.62144e-05
I0506 04:40:01.689549 12834 solver.cpp:242] Iteration 65700 (104.983 iter/s, 0.952536s/100 iter), loss = 0.888477
I0506 04:40:01.689587 12834 solver.cpp:261]     Train net output #0: loss = 0.888477 (* 1 = 0.888477 loss)
I0506 04:40:01.689597 12834 sgd_solver.cpp:106] Iteration 65700, lr = 2.62144e-05
I0506 04:40:01.694310 12834 solver.cpp:242] Iteration 65700 (104.996 iter/s, 0.952417s/100 iter), loss = 0.517818
I0506 04:40:01.694336 12834 solver.cpp:261]     Train net output #0: loss = 0.517818 (* 1 = 0.517818 loss)
I0506 04:40:01.694345 12834 sgd_solver.cpp:106] Iteration 65700, lr = 2.62144e-05
I0506 04:40:02.633769 12834 solver.cpp:242] Iteration 65800 (105.916 iter/s, 0.944148s/100 iter), loss = 1.73127
I0506 04:40:02.633802 12834 solver.cpp:261]     Train net output #0: loss = 1.73127 (* 1 = 1.73127 loss)
I0506 04:40:02.633815 12834 sgd_solver.cpp:106] Iteration 65800, lr = 2.62144e-05
I0506 04:40:02.639009 12834 solver.cpp:242] Iteration 65800 (105.859 iter/s, 0.944653s/100 iter), loss = 0.693508
I0506 04:40:02.639036 12834 solver.cpp:261]     Train net output #0: loss = 0.693508 (* 1 = 0.693508 loss)
I0506 04:40:02.639047 12834 sgd_solver.cpp:106] Iteration 65800, lr = 2.62144e-05
I0506 04:40:03.580392 12834 solver.cpp:242] Iteration 65900 (105.645 iter/s, 0.946563s/100 iter), loss = 0.805625
I0506 04:40:03.580435 12834 solver.cpp:261]     Train net output #0: loss = 0.805625 (* 1 = 0.805625 loss)
I0506 04:40:03.580443 12834 sgd_solver.cpp:106] Iteration 65900, lr = 2.62144e-05
I0506 04:40:03.585162 12834 solver.cpp:242] Iteration 65900 (105.696 iter/s, 0.946107s/100 iter), loss = 0.7386
I0506 04:40:03.585187 12834 solver.cpp:261]     Train net output #0: loss = 0.7386 (* 1 = 0.7386 loss)
I0506 04:40:03.585196 12834 sgd_solver.cpp:106] Iteration 65900, lr = 2.62144e-05
I0506 04:40:04.537781 12834 solver.cpp:362] Iteration 66000, Testing net (#0)
I0506 04:40:04.537811 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:04.660401 12834 solver.cpp:429]     Test net output #0: loss = 1.67423 (* 1 = 1.67423 loss)
I0506 04:40:04.662925 12834 solver.cpp:242] Iteration 66000 (92.3813 iter/s, 1.08247s/100 iter), loss = 1.54295
I0506 04:40:04.662945 12834 solver.cpp:261]     Train net output #0: loss = 1.54295 (* 1 = 1.54295 loss)
I0506 04:40:04.662953 12834 sgd_solver.cpp:106] Iteration 66000, lr = 2.62144e-05
I0506 04:40:04.664778 12834 solver.cpp:362] Iteration 66000, Testing net (#0)
I0506 04:40:04.664793 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:04.793462 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7385
I0506 04:40:04.793480 12834 solver.cpp:429]     Test net output #1: loss = 0.620875 (* 1 = 0.620875 loss)
I0506 04:40:04.796037 12834 solver.cpp:242] Iteration 66000 (82.5881 iter/s, 1.21083s/100 iter), loss = 0.807743
I0506 04:40:04.796057 12834 solver.cpp:261]     Train net output #0: loss = 0.807743 (* 1 = 0.807743 loss)
I0506 04:40:04.796066 12834 sgd_solver.cpp:106] Iteration 66000, lr = 2.62144e-05
I0506 04:40:05.729064 12834 solver.cpp:242] Iteration 66100 (93.8006 iter/s, 1.06609s/100 iter), loss = 1.32105
I0506 04:40:05.729115 12834 solver.cpp:261]     Train net output #0: loss = 1.32105 (* 1 = 1.32105 loss)
I0506 04:40:05.729176 12834 sgd_solver.cpp:106] Iteration 66100, lr = 2.62144e-05
I0506 04:40:05.734004 12834 solver.cpp:242] Iteration 66100 (106.618 iter/s, 0.937928s/100 iter), loss = 0.64787
I0506 04:40:05.734028 12834 solver.cpp:261]     Train net output #0: loss = 0.64787 (* 1 = 0.64787 loss)
I0506 04:40:05.734037 12834 sgd_solver.cpp:106] Iteration 66100, lr = 2.62144e-05
I0506 04:40:06.666795 12834 solver.cpp:242] Iteration 66200 (106.649 iter/s, 0.937651s/100 iter), loss = 1.88268
I0506 04:40:06.666836 12834 solver.cpp:261]     Train net output #0: loss = 1.88268 (* 1 = 1.88268 loss)
I0506 04:40:06.666857 12834 sgd_solver.cpp:106] Iteration 66200, lr = 2.62144e-05
I0506 04:40:06.671577 12834 solver.cpp:242] Iteration 66200 (106.663 iter/s, 0.93753s/100 iter), loss = 0.634792
I0506 04:40:06.671603 12834 solver.cpp:261]     Train net output #0: loss = 0.634792 (* 1 = 0.634792 loss)
I0506 04:40:06.671612 12834 sgd_solver.cpp:106] Iteration 66200, lr = 2.62144e-05
I0506 04:40:07.604513 12834 solver.cpp:242] Iteration 66300 (106.649 iter/s, 0.937653s/100 iter), loss = 0.661574
I0506 04:40:07.604559 12834 solver.cpp:261]     Train net output #0: loss = 0.661574 (* 1 = 0.661574 loss)
I0506 04:40:07.604570 12834 sgd_solver.cpp:106] Iteration 66300, lr = 2.62144e-05
I0506 04:40:07.609369 12834 solver.cpp:242] Iteration 66300 (106.64 iter/s, 0.937737s/100 iter), loss = 0.528429
I0506 04:40:07.609395 12834 solver.cpp:261]     Train net output #0: loss = 0.528429 (* 1 = 0.528429 loss)
I0506 04:40:07.609405 12834 sgd_solver.cpp:106] Iteration 66300, lr = 2.62144e-05
I0506 04:40:08.542340 12834 solver.cpp:242] Iteration 66400 (106.638 iter/s, 0.937754s/100 iter), loss = 1.89151
I0506 04:40:08.542379 12834 solver.cpp:261]     Train net output #0: loss = 1.89151 (* 1 = 1.89151 loss)
I0506 04:40:08.542389 12834 sgd_solver.cpp:106] Iteration 66400, lr = 2.62144e-05
I0506 04:40:08.547185 12834 solver.cpp:242] Iteration 66400 (106.636 iter/s, 0.937772s/100 iter), loss = 0.885287
I0506 04:40:08.547214 12834 solver.cpp:261]     Train net output #0: loss = 0.885287 (* 1 = 0.885287 loss)
I0506 04:40:08.547222 12834 sgd_solver.cpp:106] Iteration 66400, lr = 2.62144e-05
I0506 04:40:09.477246 12834 solver.cpp:362] Iteration 66500, Testing net (#0)
I0506 04:40:09.477272 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:09.599911 12834 solver.cpp:429]     Test net output #0: loss = 1.64311 (* 1 = 1.64311 loss)
I0506 04:40:09.602422 12834 solver.cpp:242] Iteration 66500 (94.3375 iter/s, 1.06002s/100 iter), loss = 3.56007
I0506 04:40:09.602447 12834 solver.cpp:261]     Train net output #0: loss = 3.56007 (* 1 = 3.56007 loss)
I0506 04:40:09.602454 12834 sgd_solver.cpp:106] Iteration 66500, lr = 2.62144e-05
I0506 04:40:09.604267 12834 solver.cpp:362] Iteration 66500, Testing net (#0)
I0506 04:40:09.604280 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:09.733250 12834 solver.cpp:429]     Test net output #0: accuracy = 0.731
I0506 04:40:09.733270 12834 solver.cpp:429]     Test net output #1: loss = 0.622256 (* 1 = 0.622256 loss)
I0506 04:40:09.735815 12834 solver.cpp:242] Iteration 66500 (84.134 iter/s, 1.18858s/100 iter), loss = 0.965272
I0506 04:40:09.735836 12834 solver.cpp:261]     Train net output #0: loss = 0.965272 (* 1 = 0.965272 loss)
I0506 04:40:09.735843 12834 sgd_solver.cpp:106] Iteration 66500, lr = 2.62144e-05
I0506 04:40:10.667909 12834 solver.cpp:242] Iteration 66600 (93.8584 iter/s, 1.06544s/100 iter), loss = 0.916974
I0506 04:40:10.667948 12834 solver.cpp:261]     Train net output #0: loss = 0.916974 (* 1 = 0.916974 loss)
I0506 04:40:10.667958 12834 sgd_solver.cpp:106] Iteration 66600, lr = 2.62144e-05
I0506 04:40:10.672673 12834 solver.cpp:242] Iteration 66600 (106.744 iter/s, 0.93682s/100 iter), loss = 0.571908
I0506 04:40:10.672698 12834 solver.cpp:261]     Train net output #0: loss = 0.571908 (* 1 = 0.571908 loss)
I0506 04:40:10.672706 12834 sgd_solver.cpp:106] Iteration 66600, lr = 2.62144e-05
I0506 04:40:11.604804 12834 solver.cpp:242] Iteration 66700 (106.744 iter/s, 0.936823s/100 iter), loss = 1.40766
I0506 04:40:11.604845 12834 solver.cpp:261]     Train net output #0: loss = 1.40766 (* 1 = 1.40766 loss)
I0506 04:40:11.604853 12834 sgd_solver.cpp:106] Iteration 66700, lr = 2.62144e-05
I0506 04:40:11.609566 12834 solver.cpp:242] Iteration 66700 (106.741 iter/s, 0.93685s/100 iter), loss = 0.825611
I0506 04:40:11.609591 12834 solver.cpp:261]     Train net output #0: loss = 0.825611 (* 1 = 0.825611 loss)
I0506 04:40:11.609599 12834 sgd_solver.cpp:106] Iteration 66700, lr = 2.62144e-05
I0506 04:40:12.542532 12834 solver.cpp:242] Iteration 66800 (106.648 iter/s, 0.937662s/100 iter), loss = 1.2514
I0506 04:40:12.542582 12834 solver.cpp:261]     Train net output #0: loss = 1.2514 (* 1 = 1.2514 loss)
I0506 04:40:12.542593 12834 sgd_solver.cpp:106] Iteration 66800, lr = 2.62144e-05
I0506 04:40:12.547315 12834 solver.cpp:242] Iteration 66800 (106.643 iter/s, 0.937705s/100 iter), loss = 0.791606
I0506 04:40:12.547341 12834 solver.cpp:261]     Train net output #0: loss = 0.791606 (* 1 = 0.791606 loss)
I0506 04:40:12.547349 12834 sgd_solver.cpp:106] Iteration 66800, lr = 2.62144e-05
I0506 04:40:13.480542 12834 solver.cpp:242] Iteration 66900 (106.618 iter/s, 0.937928s/100 iter), loss = 0.643969
I0506 04:40:13.480583 12834 solver.cpp:261]     Train net output #0: loss = 0.643969 (* 1 = 0.643969 loss)
I0506 04:40:13.480593 12834 sgd_solver.cpp:106] Iteration 66900, lr = 2.62144e-05
I0506 04:40:13.485337 12834 solver.cpp:242] Iteration 66900 (106.612 iter/s, 0.937978s/100 iter), loss = 0.960553
I0506 04:40:13.485361 12834 solver.cpp:261]     Train net output #0: loss = 0.960553 (* 1 = 0.960553 loss)
I0506 04:40:13.485370 12834 sgd_solver.cpp:106] Iteration 66900, lr = 2.62144e-05
I0506 04:40:14.426081 12834 solver.cpp:362] Iteration 67000, Testing net (#0)
I0506 04:40:14.426110 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:14.548802 12834 solver.cpp:429]     Test net output #0: loss = 1.74751 (* 1 = 1.74751 loss)
I0506 04:40:14.551309 12834 solver.cpp:242] Iteration 67000 (93.3962 iter/s, 1.07071s/100 iter), loss = 2.12099
I0506 04:40:14.551329 12834 solver.cpp:261]     Train net output #0: loss = 2.12099 (* 1 = 2.12099 loss)
I0506 04:40:14.551338 12834 sgd_solver.cpp:106] Iteration 67000, lr = 2.62144e-05
I0506 04:40:14.553164 12834 solver.cpp:362] Iteration 67000, Testing net (#0)
I0506 04:40:14.553177 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:14.692270 12834 solver.cpp:429]     Test net output #0: accuracy = 0.709
I0506 04:40:14.692296 12834 solver.cpp:429]     Test net output #1: loss = 0.65557 (* 1 = 0.65557 loss)
I0506 04:40:14.694991 12834 solver.cpp:242] Iteration 67000 (82.6714 iter/s, 1.20961s/100 iter), loss = 0.522558
I0506 04:40:14.695017 12834 solver.cpp:261]     Train net output #0: loss = 0.522558 (* 1 = 0.522558 loss)
I0506 04:40:14.695029 12834 sgd_solver.cpp:106] Iteration 67000, lr = 2.62144e-05
I0506 04:40:15.630882 12834 solver.cpp:242] Iteration 67100 (92.6338 iter/s, 1.07952s/100 iter), loss = 1.471
I0506 04:40:15.630916 12834 solver.cpp:261]     Train net output #0: loss = 1.471 (* 1 = 1.471 loss)
I0506 04:40:15.630926 12834 sgd_solver.cpp:106] Iteration 67100, lr = 2.62144e-05
I0506 04:40:15.635687 12834 solver.cpp:242] Iteration 67100 (106.309 iter/s, 0.940653s/100 iter), loss = 0.780139
I0506 04:40:15.635712 12834 solver.cpp:261]     Train net output #0: loss = 0.780139 (* 1 = 0.780139 loss)
I0506 04:40:15.635722 12834 sgd_solver.cpp:106] Iteration 67100, lr = 2.62144e-05
I0506 04:40:16.568595 12834 solver.cpp:242] Iteration 67200 (106.649 iter/s, 0.937654s/100 iter), loss = 2.30789
I0506 04:40:16.568630 12834 solver.cpp:261]     Train net output #0: loss = 2.30789 (* 1 = 2.30789 loss)
I0506 04:40:16.568640 12834 sgd_solver.cpp:106] Iteration 67200, lr = 2.62144e-05
I0506 04:40:16.573442 12834 solver.cpp:242] Iteration 67200 (106.644 iter/s, 0.937702s/100 iter), loss = 0.471183
I0506 04:40:16.573467 12834 solver.cpp:261]     Train net output #0: loss = 0.471183 (* 1 = 0.471183 loss)
I0506 04:40:16.573477 12834 sgd_solver.cpp:106] Iteration 67200, lr = 2.62144e-05
I0506 04:40:17.505537 12834 solver.cpp:242] Iteration 67300 (106.737 iter/s, 0.936878s/100 iter), loss = 1.08463
I0506 04:40:17.505578 12834 solver.cpp:261]     Train net output #0: loss = 1.08463 (* 1 = 1.08463 loss)
I0506 04:40:17.505589 12834 sgd_solver.cpp:106] Iteration 67300, lr = 2.62144e-05
I0506 04:40:17.510289 12834 solver.cpp:242] Iteration 67300 (106.746 iter/s, 0.936804s/100 iter), loss = 0.426027
I0506 04:40:17.510316 12834 solver.cpp:261]     Train net output #0: loss = 0.426027 (* 1 = 0.426027 loss)
I0506 04:40:17.510326 12834 sgd_solver.cpp:106] Iteration 67300, lr = 2.62144e-05
I0506 04:40:18.442813 12834 solver.cpp:242] Iteration 67400 (106.699 iter/s, 0.937212s/100 iter), loss = 3.00656
I0506 04:40:18.442854 12834 solver.cpp:261]     Train net output #0: loss = 3.00656 (* 1 = 3.00656 loss)
I0506 04:40:18.442864 12834 sgd_solver.cpp:106] Iteration 67400, lr = 2.62144e-05
I0506 04:40:18.447593 12834 solver.cpp:242] Iteration 67400 (106.695 iter/s, 0.937249s/100 iter), loss = 0.625814
I0506 04:40:18.447619 12834 solver.cpp:261]     Train net output #0: loss = 0.625814 (* 1 = 0.625814 loss)
I0506 04:40:18.447628 12834 sgd_solver.cpp:106] Iteration 67400, lr = 2.62144e-05
I0506 04:40:19.376886 12834 solver.cpp:362] Iteration 67500, Testing net (#0)
I0506 04:40:19.376912 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:19.499678 12834 solver.cpp:429]     Test net output #0: loss = 1.59199 (* 1 = 1.59199 loss)
I0506 04:40:19.502189 12834 solver.cpp:242] Iteration 67500 (94.4006 iter/s, 1.05932s/100 iter), loss = 0.862561
I0506 04:40:19.502212 12834 solver.cpp:261]     Train net output #0: loss = 0.862561 (* 1 = 0.862561 loss)
I0506 04:40:19.502221 12834 sgd_solver.cpp:106] Iteration 67500, lr = 2.62144e-05
I0506 04:40:19.504040 12834 solver.cpp:362] Iteration 67500, Testing net (#0)
I0506 04:40:19.504052 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:19.632733 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7365
I0506 04:40:19.632753 12834 solver.cpp:429]     Test net output #1: loss = 0.615803 (* 1 = 0.615803 loss)
I0506 04:40:19.635325 12834 solver.cpp:242] Iteration 67500 (84.1974 iter/s, 1.18768s/100 iter), loss = 0.596903
I0506 04:40:19.635346 12834 solver.cpp:261]     Train net output #0: loss = 0.596903 (* 1 = 0.596903 loss)
I0506 04:40:19.635355 12834 sgd_solver.cpp:106] Iteration 67500, lr = 2.62144e-05
I0506 04:40:20.567931 12834 solver.cpp:242] Iteration 67600 (93.8364 iter/s, 1.06568s/100 iter), loss = 0.366486
I0506 04:40:20.567970 12834 solver.cpp:261]     Train net output #0: loss = 0.366486 (* 1 = 0.366486 loss)
I0506 04:40:20.567981 12834 sgd_solver.cpp:106] Iteration 67600, lr = 2.62144e-05
I0506 04:40:20.572755 12834 solver.cpp:242] Iteration 67600 (106.679 iter/s, 0.937391s/100 iter), loss = 0.605906
I0506 04:40:20.572782 12834 solver.cpp:261]     Train net output #0: loss = 0.605906 (* 1 = 0.605906 loss)
I0506 04:40:20.572790 12834 sgd_solver.cpp:106] Iteration 67600, lr = 2.62144e-05
I0506 04:40:21.505111 12834 solver.cpp:242] Iteration 67700 (106.711 iter/s, 0.937115s/100 iter), loss = 0.184198
I0506 04:40:21.505156 12834 solver.cpp:261]     Train net output #0: loss = 0.184198 (* 1 = 0.184198 loss)
I0506 04:40:21.505383 12834 sgd_solver.cpp:106] Iteration 67700, lr = 2.62144e-05
I0506 04:40:21.510182 12834 solver.cpp:242] Iteration 67700 (106.68 iter/s, 0.937382s/100 iter), loss = 0.169431
I0506 04:40:21.510208 12834 solver.cpp:261]     Train net output #0: loss = 0.169431 (* 1 = 0.169431 loss)
I0506 04:40:21.510218 12834 sgd_solver.cpp:106] Iteration 67700, lr = 2.62144e-05
I0506 04:40:22.443023 12834 solver.cpp:242] Iteration 67800 (106.628 iter/s, 0.93784s/100 iter), loss = 0.921587
I0506 04:40:22.443063 12834 solver.cpp:261]     Train net output #0: loss = 0.921587 (* 1 = 0.921587 loss)
I0506 04:40:22.443073 12834 sgd_solver.cpp:106] Iteration 67800, lr = 2.62144e-05
I0506 04:40:22.447808 12834 solver.cpp:242] Iteration 67800 (106.658 iter/s, 0.937581s/100 iter), loss = 0.466128
I0506 04:40:22.447832 12834 solver.cpp:261]     Train net output #0: loss = 0.466128 (* 1 = 0.466128 loss)
I0506 04:40:22.447841 12834 sgd_solver.cpp:106] Iteration 67800, lr = 2.62144e-05
I0506 04:40:23.464426 12834 solver.cpp:242] Iteration 67900 (97.9109 iter/s, 1.02134s/100 iter), loss = 1.74566
I0506 04:40:23.464471 12834 solver.cpp:261]     Train net output #0: loss = 1.74566 (* 1 = 1.74566 loss)
I0506 04:40:23.464483 12834 sgd_solver.cpp:106] Iteration 67900, lr = 2.62144e-05
I0506 04:40:23.469693 12834 solver.cpp:242] Iteration 67900 (97.8627 iter/s, 1.02184s/100 iter), loss = 0.598349
I0506 04:40:23.469724 12834 solver.cpp:261]     Train net output #0: loss = 0.598349 (* 1 = 0.598349 loss)
I0506 04:40:23.469746 12834 sgd_solver.cpp:106] Iteration 67900, lr = 2.62144e-05
I0506 04:40:24.497062 12834 solver.cpp:362] Iteration 68000, Testing net (#0)
I0506 04:40:24.497090 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:24.630108 12834 solver.cpp:429]     Test net output #0: loss = 1.57843 (* 1 = 1.57843 loss)
I0506 04:40:24.632756 12834 solver.cpp:242] Iteration 68000 (85.5971 iter/s, 1.16826s/100 iter), loss = 1.62036
I0506 04:40:24.632786 12834 solver.cpp:261]     Train net output #0: loss = 1.62036 (* 1 = 1.62036 loss)
I0506 04:40:24.632797 12834 sgd_solver.cpp:106] Iteration 68000, lr = 2.62144e-05
I0506 04:40:24.634976 12834 solver.cpp:362] Iteration 68000, Testing net (#0)
I0506 04:40:24.634991 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:24.765396 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7165
I0506 04:40:24.765416 12834 solver.cpp:429]     Test net output #1: loss = 0.655316 (* 1 = 0.655316 loss)
I0506 04:40:24.767967 12834 solver.cpp:242] Iteration 68000 (77.0285 iter/s, 1.29822s/100 iter), loss = 0.812916
I0506 04:40:24.767987 12834 solver.cpp:261]     Train net output #0: loss = 0.812916 (* 1 = 0.812916 loss)
I0506 04:40:24.767997 12834 sgd_solver.cpp:106] Iteration 68000, lr = 2.62144e-05
I0506 04:40:25.711673 12834 solver.cpp:242] Iteration 68100 (92.6903 iter/s, 1.07886s/100 iter), loss = 1.59349
I0506 04:40:25.711710 12834 solver.cpp:261]     Train net output #0: loss = 1.59349 (* 1 = 1.59349 loss)
I0506 04:40:25.711719 12834 sgd_solver.cpp:106] Iteration 68100, lr = 2.62144e-05
I0506 04:40:25.716521 12834 solver.cpp:242] Iteration 68100 (105.429 iter/s, 0.948504s/100 iter), loss = 0.521264
I0506 04:40:25.716545 12834 solver.cpp:261]     Train net output #0: loss = 0.521264 (* 1 = 0.521264 loss)
I0506 04:40:25.716559 12834 sgd_solver.cpp:106] Iteration 68100, lr = 2.62144e-05
I0506 04:40:26.655966 12834 solver.cpp:242] Iteration 68200 (105.907 iter/s, 0.944226s/100 iter), loss = 0.846371
I0506 04:40:26.656015 12834 solver.cpp:261]     Train net output #0: loss = 0.846371 (* 1 = 0.846371 loss)
I0506 04:40:26.656095 12834 sgd_solver.cpp:106] Iteration 68200, lr = 2.62144e-05
I0506 04:40:26.660881 12834 solver.cpp:242] Iteration 68200 (105.897 iter/s, 0.944316s/100 iter), loss = 0.62303
I0506 04:40:26.660904 12834 solver.cpp:261]     Train net output #0: loss = 0.62303 (* 1 = 0.62303 loss)
I0506 04:40:26.660913 12834 sgd_solver.cpp:106] Iteration 68200, lr = 2.62144e-05
I0506 04:40:27.593369 12834 solver.cpp:242] Iteration 68300 (106.686 iter/s, 0.937333s/100 iter), loss = 0.589676
I0506 04:40:27.593407 12834 solver.cpp:261]     Train net output #0: loss = 0.589676 (* 1 = 0.589676 loss)
I0506 04:40:27.593416 12834 sgd_solver.cpp:106] Iteration 68300, lr = 2.62144e-05
I0506 04:40:27.598217 12834 solver.cpp:242] Iteration 68300 (106.691 iter/s, 0.937285s/100 iter), loss = 0.455077
I0506 04:40:27.598243 12834 solver.cpp:261]     Train net output #0: loss = 0.455077 (* 1 = 0.455077 loss)
I0506 04:40:27.598253 12834 sgd_solver.cpp:106] Iteration 68300, lr = 2.62144e-05
I0506 04:40:28.531268 12834 solver.cpp:242] Iteration 68400 (106.629 iter/s, 0.937833s/100 iter), loss = 1.45864
I0506 04:40:28.531306 12834 solver.cpp:261]     Train net output #0: loss = 1.45864 (* 1 = 1.45864 loss)
I0506 04:40:28.531316 12834 sgd_solver.cpp:106] Iteration 68400, lr = 2.62144e-05
I0506 04:40:28.536031 12834 solver.cpp:242] Iteration 68400 (106.636 iter/s, 0.937771s/100 iter), loss = 0.647223
I0506 04:40:28.536056 12834 solver.cpp:261]     Train net output #0: loss = 0.647223 (* 1 = 0.647223 loss)
I0506 04:40:28.536064 12834 sgd_solver.cpp:106] Iteration 68400, lr = 2.62144e-05
I0506 04:40:29.465541 12834 solver.cpp:362] Iteration 68500, Testing net (#0)
I0506 04:40:29.465559 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:29.588253 12834 solver.cpp:429]     Test net output #0: loss = 1.5467 (* 1 = 1.5467 loss)
I0506 04:40:29.590773 12834 solver.cpp:242] Iteration 68500 (94.3888 iter/s, 1.05945s/100 iter), loss = 2.20717
I0506 04:40:29.590802 12834 solver.cpp:261]     Train net output #0: loss = 2.20717 (* 1 = 2.20717 loss)
I0506 04:40:29.590812 12834 sgd_solver.cpp:106] Iteration 68500, lr = 2.62144e-05
I0506 04:40:29.592691 12834 solver.cpp:362] Iteration 68500, Testing net (#0)
I0506 04:40:29.592703 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:29.721954 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7575
I0506 04:40:29.721973 12834 solver.cpp:429]     Test net output #1: loss = 0.581913 (* 1 = 0.581913 loss)
I0506 04:40:29.724520 12834 solver.cpp:242] Iteration 68500 (84.1437 iter/s, 1.18844s/100 iter), loss = 0.694333
I0506 04:40:29.724540 12834 solver.cpp:261]     Train net output #0: loss = 0.694333 (* 1 = 0.694333 loss)
I0506 04:40:29.724548 12834 sgd_solver.cpp:106] Iteration 68500, lr = 2.62144e-05
I0506 04:40:30.665359 12834 solver.cpp:242] Iteration 68600 (93.0641 iter/s, 1.07453s/100 iter), loss = 0.911914
I0506 04:40:30.665397 12834 solver.cpp:261]     Train net output #0: loss = 0.911914 (* 1 = 0.911914 loss)
I0506 04:40:30.665408 12834 sgd_solver.cpp:106] Iteration 68600, lr = 2.62144e-05
I0506 04:40:30.670625 12834 solver.cpp:242] Iteration 68600 (105.701 iter/s, 0.946066s/100 iter), loss = 0.47282
I0506 04:40:30.670655 12834 solver.cpp:261]     Train net output #0: loss = 0.47282 (* 1 = 0.47282 loss)
I0506 04:40:30.670665 12834 sgd_solver.cpp:106] Iteration 68600, lr = 2.62144e-05
I0506 04:40:31.673802 12834 solver.cpp:242] Iteration 68700 (99.1696 iter/s, 1.00837s/100 iter), loss = 1.89506
I0506 04:40:31.673840 12834 solver.cpp:261]     Train net output #0: loss = 1.89506 (* 1 = 1.89506 loss)
I0506 04:40:31.674091 12834 sgd_solver.cpp:106] Iteration 68700, lr = 2.62144e-05
I0506 04:40:31.678875 12834 solver.cpp:242] Iteration 68700 (99.1864 iter/s, 1.0082s/100 iter), loss = 0.752902
I0506 04:40:31.678899 12834 solver.cpp:261]     Train net output #0: loss = 0.752902 (* 1 = 0.752902 loss)
I0506 04:40:31.678907 12834 sgd_solver.cpp:106] Iteration 68700, lr = 2.62144e-05
I0506 04:40:32.615028 12834 solver.cpp:242] Iteration 68800 (106.251 iter/s, 0.941164s/100 iter), loss = 1.5456
I0506 04:40:32.615079 12834 solver.cpp:261]     Train net output #0: loss = 1.5456 (* 1 = 1.5456 loss)
I0506 04:40:32.615090 12834 sgd_solver.cpp:106] Iteration 68800, lr = 2.62144e-05
I0506 04:40:32.620322 12834 solver.cpp:242] Iteration 68800 (106.224 iter/s, 0.941404s/100 iter), loss = 0.489736
I0506 04:40:32.620354 12834 solver.cpp:261]     Train net output #0: loss = 0.489736 (* 1 = 0.489736 loss)
I0506 04:40:32.620365 12834 sgd_solver.cpp:106] Iteration 68800, lr = 2.62144e-05
I0506 04:40:33.562562 12834 solver.cpp:242] Iteration 68900 (105.546 iter/s, 0.947454s/100 iter), loss = 2.07362
I0506 04:40:33.562604 12834 solver.cpp:261]     Train net output #0: loss = 2.07362 (* 1 = 2.07362 loss)
I0506 04:40:33.562613 12834 sgd_solver.cpp:106] Iteration 68900, lr = 2.62144e-05
I0506 04:40:33.567386 12834 solver.cpp:242] Iteration 68900 (105.595 iter/s, 0.947015s/100 iter), loss = 0.767456
I0506 04:40:33.567414 12834 solver.cpp:261]     Train net output #0: loss = 0.767456 (* 1 = 0.767456 loss)
I0506 04:40:33.567423 12834 sgd_solver.cpp:106] Iteration 68900, lr = 2.62144e-05
I0506 04:40:34.517468 12834 solver.cpp:362] Iteration 69000, Testing net (#0)
I0506 04:40:34.517500 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:34.645632 12834 solver.cpp:429]     Test net output #0: loss = 1.88983 (* 1 = 1.88983 loss)
I0506 04:40:34.648288 12834 solver.cpp:242] Iteration 69000 (92.1097 iter/s, 1.08566s/100 iter), loss = 0.988691
I0506 04:40:34.648319 12834 solver.cpp:261]     Train net output #0: loss = 0.988691 (* 1 = 0.988691 loss)
I0506 04:40:34.648329 12834 sgd_solver.cpp:106] Iteration 69000, lr = 2.62144e-05
I0506 04:40:34.650609 12834 solver.cpp:362] Iteration 69000, Testing net (#0)
I0506 04:40:34.650625 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:34.791386 12834 solver.cpp:429]     Test net output #0: accuracy = 0.699
I0506 04:40:34.791409 12834 solver.cpp:429]     Test net output #1: loss = 0.756489 (* 1 = 0.756489 loss)
I0506 04:40:34.794134 12834 solver.cpp:242] Iteration 69000 (81.5197 iter/s, 1.2267s/100 iter), loss = 0.58522
I0506 04:40:34.794160 12834 solver.cpp:261]     Train net output #0: loss = 0.58522 (* 1 = 0.58522 loss)
I0506 04:40:34.794172 12834 sgd_solver.cpp:106] Iteration 69000, lr = 2.62144e-05
I0506 04:40:35.824743 12834 solver.cpp:242] Iteration 69100 (85.0058 iter/s, 1.17639s/100 iter), loss = 1.44126
I0506 04:40:35.824791 12834 solver.cpp:261]     Train net output #0: loss = 1.44126 (* 1 = 1.44126 loss)
I0506 04:40:35.824802 12834 sgd_solver.cpp:106] Iteration 69100, lr = 2.62144e-05
I0506 04:40:35.830039 12834 solver.cpp:242] Iteration 69100 (96.5383 iter/s, 1.03586s/100 iter), loss = 0.589066
I0506 04:40:35.830072 12834 solver.cpp:261]     Train net output #0: loss = 0.589066 (* 1 = 0.589066 loss)
I0506 04:40:35.830083 12834 sgd_solver.cpp:106] Iteration 69100, lr = 2.62144e-05
I0506 04:40:36.859959 12834 solver.cpp:242] Iteration 69200 (96.605 iter/s, 1.03514s/100 iter), loss = 1.84956
I0506 04:40:36.860011 12834 solver.cpp:261]     Train net output #0: loss = 1.84956 (* 1 = 1.84956 loss)
I0506 04:40:36.860118 12834 sgd_solver.cpp:106] Iteration 69200, lr = 2.62144e-05
I0506 04:40:36.865007 12834 solver.cpp:242] Iteration 69200 (96.627 iter/s, 1.03491s/100 iter), loss = 0.803333
I0506 04:40:36.865036 12834 solver.cpp:261]     Train net output #0: loss = 0.803333 (* 1 = 0.803333 loss)
I0506 04:40:36.865044 12834 sgd_solver.cpp:106] Iteration 69200, lr = 2.62144e-05
I0506 04:40:37.797153 12834 solver.cpp:242] Iteration 69300 (106.71 iter/s, 0.937117s/100 iter), loss = 2.61582
I0506 04:40:37.797195 12834 solver.cpp:261]     Train net output #0: loss = 2.61582 (* 1 = 2.61582 loss)
I0506 04:40:37.797204 12834 sgd_solver.cpp:106] Iteration 69300, lr = 2.62144e-05
I0506 04:40:37.801923 12834 solver.cpp:242] Iteration 69300 (106.739 iter/s, 0.936868s/100 iter), loss = 0.754132
I0506 04:40:37.801951 12834 solver.cpp:261]     Train net output #0: loss = 0.754132 (* 1 = 0.754132 loss)
I0506 04:40:37.801960 12834 sgd_solver.cpp:106] Iteration 69300, lr = 2.62144e-05
I0506 04:40:38.734447 12834 solver.cpp:242] Iteration 69400 (106.699 iter/s, 0.93722s/100 iter), loss = 0.578807
I0506 04:40:38.734488 12834 solver.cpp:261]     Train net output #0: loss = 0.578807 (* 1 = 0.578807 loss)
I0506 04:40:38.734496 12834 sgd_solver.cpp:106] Iteration 69400, lr = 2.62144e-05
I0506 04:40:38.739244 12834 solver.cpp:242] Iteration 69400 (106.692 iter/s, 0.937274s/100 iter), loss = 0.676199
I0506 04:40:38.739270 12834 solver.cpp:261]     Train net output #0: loss = 0.676199 (* 1 = 0.676199 loss)
I0506 04:40:38.739279 12834 sgd_solver.cpp:106] Iteration 69400, lr = 2.62144e-05
I0506 04:40:39.668810 12834 solver.cpp:362] Iteration 69500, Testing net (#0)
I0506 04:40:39.668836 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:39.791419 12834 solver.cpp:429]     Test net output #0: loss = 1.43996 (* 1 = 1.43996 loss)
I0506 04:40:39.793944 12834 solver.cpp:242] Iteration 69500 (94.3896 iter/s, 1.05944s/100 iter), loss = 1.90766
I0506 04:40:39.793965 12834 solver.cpp:261]     Train net output #0: loss = 1.90766 (* 1 = 1.90766 loss)
I0506 04:40:39.793974 12834 sgd_solver.cpp:106] Iteration 69500, lr = 2.62144e-05
I0506 04:40:39.795789 12834 solver.cpp:362] Iteration 69500, Testing net (#0)
I0506 04:40:39.795802 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:39.924357 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7585
I0506 04:40:39.924376 12834 solver.cpp:429]     Test net output #1: loss = 0.560029 (* 1 = 0.560029 loss)
I0506 04:40:39.926920 12834 solver.cpp:242] Iteration 69500 (84.2013 iter/s, 1.18763s/100 iter), loss = 0.613774
I0506 04:40:39.926941 12834 solver.cpp:261]     Train net output #0: loss = 0.613774 (* 1 = 0.613774 loss)
I0506 04:40:39.926950 12834 sgd_solver.cpp:106] Iteration 69500, lr = 2.62144e-05
I0506 04:40:40.889031 12834 solver.cpp:242] Iteration 69600 (91.3219 iter/s, 1.09503s/100 iter), loss = 3.54426
I0506 04:40:40.889091 12834 solver.cpp:261]     Train net output #0: loss = 3.54426 (* 1 = 3.54426 loss)
I0506 04:40:40.889103 12834 sgd_solver.cpp:106] Iteration 69600, lr = 2.62144e-05
I0506 04:40:40.894314 12834 solver.cpp:242] Iteration 69600 (103.375 iter/s, 0.967351s/100 iter), loss = 0.755528
I0506 04:40:40.894345 12834 solver.cpp:261]     Train net output #0: loss = 0.755528 (* 1 = 0.755528 loss)
I0506 04:40:40.894356 12834 sgd_solver.cpp:106] Iteration 69600, lr = 2.62144e-05
I0506 04:40:41.903131 12834 solver.cpp:242] Iteration 69700 (98.6178 iter/s, 1.01402s/100 iter), loss = 2.78812
I0506 04:40:41.903177 12834 solver.cpp:261]     Train net output #0: loss = 2.78812 (* 1 = 2.78812 loss)
I0506 04:40:41.903244 12834 sgd_solver.cpp:106] Iteration 69700, lr = 2.62144e-05
I0506 04:40:41.908035 12834 solver.cpp:242] Iteration 69700 (98.6512 iter/s, 1.01367s/100 iter), loss = 0.65565
I0506 04:40:41.908059 12834 solver.cpp:261]     Train net output #0: loss = 0.65565 (* 1 = 0.65565 loss)
I0506 04:40:41.908068 12834 sgd_solver.cpp:106] Iteration 69700, lr = 2.62144e-05
I0506 04:40:42.867741 12834 solver.cpp:242] Iteration 69800 (103.677 iter/s, 0.964533s/100 iter), loss = 1.2727
I0506 04:40:42.867786 12834 solver.cpp:261]     Train net output #0: loss = 1.2727 (* 1 = 1.2727 loss)
I0506 04:40:42.867797 12834 sgd_solver.cpp:106] Iteration 69800, lr = 2.62144e-05
I0506 04:40:42.873034 12834 solver.cpp:242] Iteration 69800 (103.632 iter/s, 0.964955s/100 iter), loss = 0.605747
I0506 04:40:42.873064 12834 solver.cpp:261]     Train net output #0: loss = 0.605747 (* 1 = 0.605747 loss)
I0506 04:40:42.873075 12834 sgd_solver.cpp:106] Iteration 69800, lr = 2.62144e-05
I0506 04:40:43.902796 12834 solver.cpp:242] Iteration 69900 (96.6198 iter/s, 1.03498s/100 iter), loss = 0.674226
I0506 04:40:43.902839 12834 solver.cpp:261]     Train net output #0: loss = 0.674226 (* 1 = 0.674226 loss)
I0506 04:40:43.902850 12834 sgd_solver.cpp:106] Iteration 69900, lr = 2.62144e-05
I0506 04:40:43.908152 12834 solver.cpp:242] Iteration 69900 (96.6131 iter/s, 1.03506s/100 iter), loss = 0.722947
I0506 04:40:43.908184 12834 solver.cpp:261]     Train net output #0: loss = 0.722947 (* 1 = 0.722947 loss)
I0506 04:40:43.908193 12834 sgd_solver.cpp:106] Iteration 69900, lr = 2.62144e-05
I0506 04:40:44.914777 12834 solver.cpp:362] Iteration 70000, Testing net (#0)
I0506 04:40:44.914803 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:45.037292 12834 solver.cpp:429]     Test net output #0: loss = 1.48891 (* 1 = 1.48891 loss)
I0506 04:40:45.039814 12834 solver.cpp:242] Iteration 70000 (87.9541 iter/s, 1.13696s/100 iter), loss = 1.50401
I0506 04:40:45.039837 12834 solver.cpp:261]     Train net output #0: loss = 1.50401 (* 1 = 1.50401 loss)
I0506 04:40:45.039846 12834 sgd_solver.cpp:106] Iteration 70000, lr = 2.09715e-05
I0506 04:40:45.041667 12834 solver.cpp:362] Iteration 70000, Testing net (#0)
I0506 04:40:45.041682 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:45.170222 12834 solver.cpp:429]     Test net output #0: accuracy = 0.746
I0506 04:40:45.170241 12834 solver.cpp:429]     Test net output #1: loss = 0.594095 (* 1 = 0.594095 loss)
I0506 04:40:45.172793 12834 solver.cpp:242] Iteration 70000 (79.0771 iter/s, 1.26459s/100 iter), loss = 0.838828
I0506 04:40:45.172816 12834 solver.cpp:261]     Train net output #0: loss = 0.838828 (* 1 = 0.838828 loss)
I0506 04:40:45.172824 12834 sgd_solver.cpp:106] Iteration 70000, lr = 2.09715e-05
I0506 04:40:46.105651 12834 solver.cpp:242] Iteration 70100 (93.8273 iter/s, 1.06579s/100 iter), loss = 1.91205
I0506 04:40:46.105690 12834 solver.cpp:261]     Train net output #0: loss = 1.91205 (* 1 = 1.91205 loss)
I0506 04:40:46.105700 12834 sgd_solver.cpp:106] Iteration 70100, lr = 2.09715e-05
I0506 04:40:46.110499 12834 solver.cpp:242] Iteration 70100 (106.649 iter/s, 0.937656s/100 iter), loss = 0.396519
I0506 04:40:46.110525 12834 solver.cpp:261]     Train net output #0: loss = 0.396519 (* 1 = 0.396519 loss)
I0506 04:40:46.110534 12834 sgd_solver.cpp:106] Iteration 70100, lr = 2.09715e-05
I0506 04:40:47.091658 12834 solver.cpp:242] Iteration 70200 (101.426 iter/s, 0.98594s/100 iter), loss = 1.16725
I0506 04:40:47.091707 12834 solver.cpp:261]     Train net output #0: loss = 1.16725 (* 1 = 1.16725 loss)
I0506 04:40:47.091773 12834 sgd_solver.cpp:106] Iteration 70200, lr = 2.09715e-05
I0506 04:40:47.096585 12834 solver.cpp:242] Iteration 70200 (101.416 iter/s, 0.986041s/100 iter), loss = 0.393521
I0506 04:40:47.096611 12834 solver.cpp:261]     Train net output #0: loss = 0.393521 (* 1 = 0.393521 loss)
I0506 04:40:47.096621 12834 sgd_solver.cpp:106] Iteration 70200, lr = 2.09715e-05
I0506 04:40:48.029541 12834 solver.cpp:242] Iteration 70300 (106.632 iter/s, 0.937803s/100 iter), loss = 1.47069
I0506 04:40:48.029579 12834 solver.cpp:261]     Train net output #0: loss = 1.47069 (* 1 = 1.47069 loss)
I0506 04:40:48.029588 12834 sgd_solver.cpp:106] Iteration 70300, lr = 2.09715e-05
I0506 04:40:48.034297 12834 solver.cpp:242] Iteration 70300 (106.647 iter/s, 0.937669s/100 iter), loss = 0.545843
I0506 04:40:48.034324 12834 solver.cpp:261]     Train net output #0: loss = 0.545843 (* 1 = 0.545843 loss)
I0506 04:40:48.034333 12834 sgd_solver.cpp:106] Iteration 70300, lr = 2.09715e-05
I0506 04:40:48.966562 12834 solver.cpp:242] Iteration 70400 (106.728 iter/s, 0.936957s/100 iter), loss = 1.85615
I0506 04:40:48.966598 12834 solver.cpp:261]     Train net output #0: loss = 1.85615 (* 1 = 1.85615 loss)
I0506 04:40:48.966609 12834 sgd_solver.cpp:106] Iteration 70400, lr = 2.09715e-05
I0506 04:40:48.971318 12834 solver.cpp:242] Iteration 70400 (106.726 iter/s, 0.936976s/100 iter), loss = 0.666044
I0506 04:40:48.971343 12834 solver.cpp:261]     Train net output #0: loss = 0.666044 (* 1 = 0.666044 loss)
I0506 04:40:48.971351 12834 sgd_solver.cpp:106] Iteration 70400, lr = 2.09715e-05
I0506 04:40:49.912348 12834 solver.cpp:362] Iteration 70500, Testing net (#0)
I0506 04:40:49.912371 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:50.035001 12834 solver.cpp:429]     Test net output #0: loss = 1.51331 (* 1 = 1.51331 loss)
I0506 04:40:50.037513 12834 solver.cpp:242] Iteration 70500 (93.3797 iter/s, 1.0709s/100 iter), loss = 0.42264
I0506 04:40:50.037536 12834 solver.cpp:261]     Train net output #0: loss = 0.42264 (* 1 = 0.42264 loss)
I0506 04:40:50.037545 12834 sgd_solver.cpp:106] Iteration 70500, lr = 2.09715e-05
I0506 04:40:50.039358 12834 solver.cpp:362] Iteration 70500, Testing net (#0)
I0506 04:40:50.039371 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:50.168071 12834 solver.cpp:429]     Test net output #0: accuracy = 0.742
I0506 04:40:50.168089 12834 solver.cpp:429]     Test net output #1: loss = 0.621108 (* 1 = 0.621108 loss)
I0506 04:40:50.170644 12834 solver.cpp:242] Iteration 70500 (83.3834 iter/s, 1.19928s/100 iter), loss = 0.370967
I0506 04:40:50.170665 12834 solver.cpp:261]     Train net output #0: loss = 0.370967 (* 1 = 0.370967 loss)
I0506 04:40:50.170675 12834 sgd_solver.cpp:106] Iteration 70500, lr = 2.09715e-05
I0506 04:40:51.103137 12834 solver.cpp:242] Iteration 70600 (93.8462 iter/s, 1.06557s/100 iter), loss = 1.63874
I0506 04:40:51.103164 12834 solver.cpp:261]     Train net output #0: loss = 1.63874 (* 1 = 1.63874 loss)
I0506 04:40:51.103174 12834 sgd_solver.cpp:106] Iteration 70600, lr = 2.09715e-05
I0506 04:40:51.107903 12834 solver.cpp:242] Iteration 70600 (106.699 iter/s, 0.937219s/100 iter), loss = 0.62691
I0506 04:40:51.107928 12834 solver.cpp:261]     Train net output #0: loss = 0.62691 (* 1 = 0.62691 loss)
I0506 04:40:51.107936 12834 sgd_solver.cpp:106] Iteration 70600, lr = 2.09715e-05
I0506 04:40:52.040081 12834 solver.cpp:242] Iteration 70700 (106.737 iter/s, 0.936883s/100 iter), loss = 1.63893
I0506 04:40:52.040124 12834 solver.cpp:261]     Train net output #0: loss = 1.63893 (* 1 = 1.63893 loss)
I0506 04:40:52.040134 12834 sgd_solver.cpp:106] Iteration 70700, lr = 2.09715e-05
I0506 04:40:52.044842 12834 solver.cpp:242] Iteration 70700 (106.735 iter/s, 0.936897s/100 iter), loss = 0.530654
I0506 04:40:52.044867 12834 solver.cpp:261]     Train net output #0: loss = 0.530654 (* 1 = 0.530654 loss)
I0506 04:40:52.044885 12834 sgd_solver.cpp:106] Iteration 70700, lr = 2.09715e-05
I0506 04:40:52.977650 12834 solver.cpp:242] Iteration 70800 (106.666 iter/s, 0.937502s/100 iter), loss = 1.55856
I0506 04:40:52.977691 12834 solver.cpp:261]     Train net output #0: loss = 1.55856 (* 1 = 1.55856 loss)
I0506 04:40:52.977700 12834 sgd_solver.cpp:106] Iteration 70800, lr = 2.09715e-05
I0506 04:40:52.982492 12834 solver.cpp:242] Iteration 70800 (106.656 iter/s, 0.937597s/100 iter), loss = 0.476318
I0506 04:40:52.982519 12834 solver.cpp:261]     Train net output #0: loss = 0.476318 (* 1 = 0.476318 loss)
I0506 04:40:52.982528 12834 sgd_solver.cpp:106] Iteration 70800, lr = 2.09715e-05
I0506 04:40:53.915227 12834 solver.cpp:242] Iteration 70900 (106.666 iter/s, 0.937509s/100 iter), loss = 1.11187
I0506 04:40:53.915267 12834 solver.cpp:261]     Train net output #0: loss = 1.11187 (* 1 = 1.11187 loss)
I0506 04:40:53.915277 12834 sgd_solver.cpp:106] Iteration 70900, lr = 2.09715e-05
I0506 04:40:53.919998 12834 solver.cpp:242] Iteration 70900 (106.671 iter/s, 0.93746s/100 iter), loss = 0.644459
I0506 04:40:53.920025 12834 solver.cpp:261]     Train net output #0: loss = 0.644459 (* 1 = 0.644459 loss)
I0506 04:40:53.920034 12834 sgd_solver.cpp:106] Iteration 70900, lr = 2.09715e-05
I0506 04:40:54.879226 12834 solver.cpp:362] Iteration 71000, Testing net (#0)
I0506 04:40:54.879259 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:55.012197 12834 solver.cpp:429]     Test net output #0: loss = 1.31232 (* 1 = 1.31232 loss)
I0506 04:40:55.014848 12834 solver.cpp:242] Iteration 71000 (90.9456 iter/s, 1.09956s/100 iter), loss = 0.777115
I0506 04:40:55.014881 12834 solver.cpp:261]     Train net output #0: loss = 0.777115 (* 1 = 0.777115 loss)
I0506 04:40:55.014892 12834 sgd_solver.cpp:106] Iteration 71000, lr = 2.09715e-05
I0506 04:40:55.017180 12834 solver.cpp:362] Iteration 71000, Testing net (#0)
I0506 04:40:55.017197 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:40:55.157778 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7415
I0506 04:40:55.157800 12834 solver.cpp:429]     Test net output #1: loss = 0.600026 (* 1 = 0.600026 loss)
I0506 04:40:55.160488 12834 solver.cpp:242] Iteration 71000 (80.6166 iter/s, 1.24044s/100 iter), loss = 0.759411
I0506 04:40:55.160512 12834 solver.cpp:261]     Train net output #0: loss = 0.759411 (* 1 = 0.759411 loss)
I0506 04:40:55.160522 12834 sgd_solver.cpp:106] Iteration 71000, lr = 2.09715e-05
I0506 04:40:56.190663 12834 solver.cpp:242] Iteration 71100 (85.052 iter/s, 1.17575s/100 iter), loss = 1.04719
I0506 04:40:56.190711 12834 solver.cpp:261]     Train net output #0: loss = 1.04719 (* 1 = 1.04719 loss)
I0506 04:40:56.190722 12834 sgd_solver.cpp:106] Iteration 71100, lr = 2.09715e-05
I0506 04:40:56.195945 12834 solver.cpp:242] Iteration 71100 (96.58 iter/s, 1.03541s/100 iter), loss = 0.520198
I0506 04:40:56.195976 12834 solver.cpp:261]     Train net output #0: loss = 0.520198 (* 1 = 0.520198 loss)
I0506 04:40:56.195988 12834 sgd_solver.cpp:106] Iteration 71100, lr = 2.09715e-05
I0506 04:40:57.178915 12834 solver.cpp:242] Iteration 71200 (101.197 iter/s, 0.988171s/100 iter), loss = 0.531774
I0506 04:40:57.178961 12834 solver.cpp:261]     Train net output #0: loss = 0.531774 (* 1 = 0.531774 loss)
I0506 04:40:57.179100 12834 sgd_solver.cpp:106] Iteration 71200, lr = 2.09715e-05
I0506 04:40:57.183899 12834 solver.cpp:242] Iteration 71200 (101.224 iter/s, 0.987905s/100 iter), loss = 0.510621
I0506 04:40:57.183924 12834 solver.cpp:261]     Train net output #0: loss = 0.510621 (* 1 = 0.510621 loss)
I0506 04:40:57.183933 12834 sgd_solver.cpp:106] Iteration 71200, lr = 2.09715e-05
I0506 04:40:58.116178 12834 solver.cpp:242] Iteration 71300 (106.702 iter/s, 0.937191s/100 iter), loss = 0.97775
I0506 04:40:58.116219 12834 solver.cpp:261]     Train net output #0: loss = 0.97775 (* 1 = 0.97775 loss)
I0506 04:40:58.116227 12834 sgd_solver.cpp:106] Iteration 71300, lr = 2.09715e-05
I0506 04:40:58.120929 12834 solver.cpp:242] Iteration 71300 (106.725 iter/s, 0.936987s/100 iter), loss = 0.583774
I0506 04:40:58.120965 12834 solver.cpp:261]     Train net output #0: loss = 0.583774 (* 1 = 0.583774 loss)
I0506 04:40:58.120975 12834 sgd_solver.cpp:106] Iteration 71300, lr = 2.09715e-05
I0506 04:40:59.054044 12834 solver.cpp:242] Iteration 71400 (106.633 iter/s, 0.937795s/100 iter), loss = 1.90119
I0506 04:40:59.054082 12834 solver.cpp:261]     Train net output #0: loss = 1.90119 (* 1 = 1.90119 loss)
I0506 04:40:59.054091 12834 sgd_solver.cpp:106] Iteration 71400, lr = 2.09715e-05
I0506 04:40:59.058807 12834 solver.cpp:242] Iteration 71400 (106.63 iter/s, 0.937825s/100 iter), loss = 0.437618
I0506 04:40:59.058832 12834 solver.cpp:261]     Train net output #0: loss = 0.437618 (* 1 = 0.437618 loss)
I0506 04:40:59.058841 12834 sgd_solver.cpp:106] Iteration 71400, lr = 2.09715e-05
I0506 04:40:59.988976 12834 solver.cpp:362] Iteration 71500, Testing net (#0)
I0506 04:40:59.989001 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:00.111819 12834 solver.cpp:429]     Test net output #0: loss = 1.41049 (* 1 = 1.41049 loss)
I0506 04:41:00.114346 12834 solver.cpp:242] Iteration 71500 (94.318 iter/s, 1.06024s/100 iter), loss = 3.39052
I0506 04:41:00.114367 12834 solver.cpp:261]     Train net output #0: loss = 3.39052 (* 1 = 3.39052 loss)
I0506 04:41:00.114375 12834 sgd_solver.cpp:106] Iteration 71500, lr = 2.09715e-05
I0506 04:41:00.116214 12834 solver.cpp:362] Iteration 71500, Testing net (#0)
I0506 04:41:00.116226 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:00.246073 12834 solver.cpp:429]     Test net output #0: accuracy = 0.725
I0506 04:41:00.246116 12834 solver.cpp:429]     Test net output #1: loss = 0.643914 (* 1 = 0.643914 loss)
I0506 04:41:00.248704 12834 solver.cpp:242] Iteration 71500 (84.0441 iter/s, 1.18985s/100 iter), loss = 0.653144
I0506 04:41:00.248726 12834 solver.cpp:261]     Train net output #0: loss = 0.653144 (* 1 = 0.653144 loss)
I0506 04:41:00.248736 12834 sgd_solver.cpp:106] Iteration 71500, lr = 2.09715e-05
I0506 04:41:01.190421 12834 solver.cpp:242] Iteration 71600 (92.9352 iter/s, 1.07602s/100 iter), loss = 1.03059
I0506 04:41:01.190462 12834 solver.cpp:261]     Train net output #0: loss = 1.03059 (* 1 = 1.03059 loss)
I0506 04:41:01.190472 12834 sgd_solver.cpp:106] Iteration 71600, lr = 2.09715e-05
I0506 04:41:01.195246 12834 solver.cpp:242] Iteration 71600 (105.652 iter/s, 0.946501s/100 iter), loss = 0.44565
I0506 04:41:01.195273 12834 solver.cpp:261]     Train net output #0: loss = 0.44565 (* 1 = 0.44565 loss)
I0506 04:41:01.195283 12834 sgd_solver.cpp:106] Iteration 71600, lr = 2.09715e-05
I0506 04:41:02.132490 12834 solver.cpp:242] Iteration 71700 (106.157 iter/s, 0.942005s/100 iter), loss = 1.06027
I0506 04:41:02.132529 12834 solver.cpp:261]     Train net output #0: loss = 1.06027 (* 1 = 1.06027 loss)
I0506 04:41:02.132537 12834 sgd_solver.cpp:106] Iteration 71700, lr = 2.09715e-05
I0506 04:41:02.137362 12834 solver.cpp:242] Iteration 71700 (106.15 iter/s, 0.94206s/100 iter), loss = 0.570094
I0506 04:41:02.137388 12834 solver.cpp:261]     Train net output #0: loss = 0.570094 (* 1 = 0.570094 loss)
I0506 04:41:02.137398 12834 sgd_solver.cpp:106] Iteration 71700, lr = 2.09715e-05
I0506 04:41:03.071339 12834 solver.cpp:242] Iteration 71800 (106.521 iter/s, 0.938784s/100 iter), loss = 1.62027
I0506 04:41:03.071377 12834 solver.cpp:261]     Train net output #0: loss = 1.62027 (* 1 = 1.62027 loss)
I0506 04:41:03.071388 12834 sgd_solver.cpp:106] Iteration 71800, lr = 2.09715e-05
I0506 04:41:03.076139 12834 solver.cpp:242] Iteration 71800 (106.527 iter/s, 0.938733s/100 iter), loss = 0.771972
I0506 04:41:03.076164 12834 solver.cpp:261]     Train net output #0: loss = 0.771972 (* 1 = 0.771972 loss)
I0506 04:41:03.076172 12834 sgd_solver.cpp:106] Iteration 71800, lr = 2.09715e-05
I0506 04:41:04.008812 12834 solver.cpp:242] Iteration 71900 (106.676 iter/s, 0.937414s/100 iter), loss = 2.2875
I0506 04:41:04.008843 12834 solver.cpp:261]     Train net output #0: loss = 2.2875 (* 1 = 2.2875 loss)
I0506 04:41:04.008853 12834 sgd_solver.cpp:106] Iteration 71900, lr = 2.09715e-05
I0506 04:41:04.013666 12834 solver.cpp:242] Iteration 71900 (106.669 iter/s, 0.937475s/100 iter), loss = 0.948658
I0506 04:41:04.013690 12834 solver.cpp:261]     Train net output #0: loss = 0.948658 (* 1 = 0.948658 loss)
I0506 04:41:04.013700 12834 sgd_solver.cpp:106] Iteration 71900, lr = 2.09715e-05
I0506 04:41:04.943612 12834 solver.cpp:362] Iteration 72000, Testing net (#0)
I0506 04:41:04.943641 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:05.066320 12834 solver.cpp:429]     Test net output #0: loss = 1.41956 (* 1 = 1.41956 loss)
I0506 04:41:05.068864 12834 solver.cpp:242] Iteration 72000 (94.3395 iter/s, 1.06s/100 iter), loss = 0.526301
I0506 04:41:05.068895 12834 solver.cpp:261]     Train net output #0: loss = 0.526301 (* 1 = 0.526301 loss)
I0506 04:41:05.068904 12834 sgd_solver.cpp:106] Iteration 72000, lr = 2.09715e-05
I0506 04:41:05.070718 12834 solver.cpp:362] Iteration 72000, Testing net (#0)
I0506 04:41:05.070731 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:05.199316 12834 solver.cpp:429]     Test net output #0: accuracy = 0.759
I0506 04:41:05.199335 12834 solver.cpp:429]     Test net output #1: loss = 0.564967 (* 1 = 0.564967 loss)
I0506 04:41:05.201897 12834 solver.cpp:242] Iteration 72000 (84.1619 iter/s, 1.18819s/100 iter), loss = 0.320395
I0506 04:41:05.201918 12834 solver.cpp:261]     Train net output #0: loss = 0.320395 (* 1 = 0.320395 loss)
I0506 04:41:05.201926 12834 sgd_solver.cpp:106] Iteration 72000, lr = 2.09715e-05
I0506 04:41:06.134526 12834 solver.cpp:242] Iteration 72100 (93.844 iter/s, 1.0656s/100 iter), loss = 1.81811
I0506 04:41:06.134560 12834 solver.cpp:261]     Train net output #0: loss = 1.81811 (* 1 = 1.81811 loss)
I0506 04:41:06.134569 12834 sgd_solver.cpp:106] Iteration 72100, lr = 2.09715e-05
I0506 04:41:06.139288 12834 solver.cpp:242] Iteration 72100 (106.683 iter/s, 0.937352s/100 iter), loss = 0.325041
I0506 04:41:06.139312 12834 solver.cpp:261]     Train net output #0: loss = 0.325041 (* 1 = 0.325041 loss)
I0506 04:41:06.139322 12834 sgd_solver.cpp:106] Iteration 72100, lr = 2.09715e-05
I0506 04:41:07.123478 12834 solver.cpp:242] Iteration 72200 (101.123 iter/s, 0.988891s/100 iter), loss = 1.78499
I0506 04:41:07.123520 12834 solver.cpp:261]     Train net output #0: loss = 1.78499 (* 1 = 1.78499 loss)
I0506 04:41:07.123531 12834 sgd_solver.cpp:106] Iteration 72200, lr = 2.09715e-05
I0506 04:41:07.128768 12834 solver.cpp:242] Iteration 72200 (101.068 iter/s, 0.989436s/100 iter), loss = 0.742241
I0506 04:41:07.128798 12834 solver.cpp:261]     Train net output #0: loss = 0.742241 (* 1 = 0.742241 loss)
I0506 04:41:07.128808 12834 sgd_solver.cpp:106] Iteration 72200, lr = 2.09715e-05
I0506 04:41:08.084339 12834 solver.cpp:242] Iteration 72300 (104.081 iter/s, 0.960787s/100 iter), loss = 2.91013
I0506 04:41:08.084388 12834 solver.cpp:261]     Train net output #0: loss = 2.91013 (* 1 = 2.91013 loss)
I0506 04:41:08.084447 12834 sgd_solver.cpp:106] Iteration 72300, lr = 2.09715e-05
I0506 04:41:08.089241 12834 solver.cpp:242] Iteration 72300 (104.121 iter/s, 0.960424s/100 iter), loss = 0.869277
I0506 04:41:08.089267 12834 solver.cpp:261]     Train net output #0: loss = 0.869277 (* 1 = 0.869277 loss)
I0506 04:41:08.089275 12834 sgd_solver.cpp:106] Iteration 72300, lr = 2.09715e-05
I0506 04:41:09.022191 12834 solver.cpp:242] Iteration 72400 (106.635 iter/s, 0.93778s/100 iter), loss = 0.679016
I0506 04:41:09.022231 12834 solver.cpp:261]     Train net output #0: loss = 0.679016 (* 1 = 0.679016 loss)
I0506 04:41:09.022240 12834 sgd_solver.cpp:106] Iteration 72400, lr = 2.09715e-05
I0506 04:41:09.026964 12834 solver.cpp:242] Iteration 72400 (106.646 iter/s, 0.93768s/100 iter), loss = 0.691495
I0506 04:41:09.026989 12834 solver.cpp:261]     Train net output #0: loss = 0.691495 (* 1 = 0.691495 loss)
I0506 04:41:09.026998 12834 sgd_solver.cpp:106] Iteration 72400, lr = 2.09715e-05
I0506 04:41:09.956679 12834 solver.cpp:362] Iteration 72500, Testing net (#0)
I0506 04:41:09.956707 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:10.079514 12834 solver.cpp:429]     Test net output #0: loss = 1.61581 (* 1 = 1.61581 loss)
I0506 04:41:10.082034 12834 solver.cpp:242] Iteration 72500 (94.3588 iter/s, 1.05978s/100 iter), loss = 0.664708
I0506 04:41:10.082057 12834 solver.cpp:261]     Train net output #0: loss = 0.664708 (* 1 = 0.664708 loss)
I0506 04:41:10.082067 12834 sgd_solver.cpp:106] Iteration 72500, lr = 2.09715e-05
I0506 04:41:10.083883 12834 solver.cpp:362] Iteration 72500, Testing net (#0)
I0506 04:41:10.083895 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:10.212394 12834 solver.cpp:429]     Test net output #0: accuracy = 0.746
I0506 04:41:10.212414 12834 solver.cpp:429]     Test net output #1: loss = 0.602598 (* 1 = 0.602598 loss)
I0506 04:41:10.214982 12834 solver.cpp:242] Iteration 72500 (84.1771 iter/s, 1.18797s/100 iter), loss = 0.492904
I0506 04:41:10.215003 12834 solver.cpp:261]     Train net output #0: loss = 0.492904 (* 1 = 0.492904 loss)
I0506 04:41:10.215011 12834 sgd_solver.cpp:106] Iteration 72500, lr = 2.09715e-05
I0506 04:41:11.207231 12834 solver.cpp:242] Iteration 72600 (88.8775 iter/s, 1.12514s/100 iter), loss = 2.1452
I0506 04:41:11.207279 12834 solver.cpp:261]     Train net output #0: loss = 2.1452 (* 1 = 2.1452 loss)
I0506 04:41:11.207290 12834 sgd_solver.cpp:106] Iteration 72600, lr = 2.09715e-05
I0506 04:41:11.212601 12834 solver.cpp:242] Iteration 72600 (100.244 iter/s, 0.997566s/100 iter), loss = 0.478513
I0506 04:41:11.212631 12834 solver.cpp:261]     Train net output #0: loss = 0.478513 (* 1 = 0.478513 loss)
I0506 04:41:11.212642 12834 sgd_solver.cpp:106] Iteration 72600, lr = 2.09715e-05
I0506 04:41:12.243257 12834 solver.cpp:242] Iteration 72700 (96.5299 iter/s, 1.03595s/100 iter), loss = 6.06264
I0506 04:41:12.243304 12834 solver.cpp:261]     Train net output #0: loss = 6.06264 (* 1 = 6.06264 loss)
I0506 04:41:12.243315 12834 sgd_solver.cpp:106] Iteration 72700, lr = 2.09715e-05
I0506 04:41:12.248589 12834 solver.cpp:242] Iteration 72700 (96.531 iter/s, 1.03594s/100 iter), loss = 0.790735
I0506 04:41:12.248617 12834 solver.cpp:261]     Train net output #0: loss = 0.790735 (* 1 = 0.790735 loss)
I0506 04:41:12.248630 12834 sgd_solver.cpp:106] Iteration 72700, lr = 2.09715e-05
I0506 04:41:13.278650 12834 solver.cpp:242] Iteration 72800 (96.5884 iter/s, 1.03532s/100 iter), loss = 1.74857
I0506 04:41:13.278700 12834 solver.cpp:261]     Train net output #0: loss = 1.74857 (* 1 = 1.74857 loss)
I0506 04:41:13.279036 12834 sgd_solver.cpp:106] Iteration 72800, lr = 2.09715e-05
I0506 04:41:13.283931 12834 solver.cpp:242] Iteration 72800 (96.5918 iter/s, 1.03528s/100 iter), loss = 0.546525
I0506 04:41:13.283957 12834 solver.cpp:261]     Train net output #0: loss = 0.546525 (* 1 = 0.546525 loss)
I0506 04:41:13.283967 12834 sgd_solver.cpp:106] Iteration 72800, lr = 2.09715e-05
I0506 04:41:14.216539 12834 solver.cpp:242] Iteration 72900 (106.631 iter/s, 0.937815s/100 iter), loss = 1.67881
I0506 04:41:14.216581 12834 solver.cpp:261]     Train net output #0: loss = 1.67881 (* 1 = 1.67881 loss)
I0506 04:41:14.216591 12834 sgd_solver.cpp:106] Iteration 72900, lr = 2.09715e-05
I0506 04:41:14.221331 12834 solver.cpp:242] Iteration 72900 (106.683 iter/s, 0.937356s/100 iter), loss = 0.55112
I0506 04:41:14.221357 12834 solver.cpp:261]     Train net output #0: loss = 0.55112 (* 1 = 0.55112 loss)
I0506 04:41:14.221366 12834 sgd_solver.cpp:106] Iteration 72900, lr = 2.09715e-05
I0506 04:41:15.151420 12834 solver.cpp:362] Iteration 73000, Testing net (#0)
I0506 04:41:15.151446 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:15.274055 12834 solver.cpp:429]     Test net output #0: loss = 1.5309 (* 1 = 1.5309 loss)
I0506 04:41:15.276579 12834 solver.cpp:242] Iteration 73000 (94.3416 iter/s, 1.05998s/100 iter), loss = 0.406929
I0506 04:41:15.276603 12834 solver.cpp:261]     Train net output #0: loss = 0.406929 (* 1 = 0.406929 loss)
I0506 04:41:15.276612 12834 sgd_solver.cpp:106] Iteration 73000, lr = 2.09715e-05
I0506 04:41:15.278424 12834 solver.cpp:362] Iteration 73000, Testing net (#0)
I0506 04:41:15.278447 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:15.407011 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7465
I0506 04:41:15.407030 12834 solver.cpp:429]     Test net output #1: loss = 0.595979 (* 1 = 0.595979 loss)
I0506 04:41:15.409586 12834 solver.cpp:242] Iteration 73000 (84.1604 iter/s, 1.18821s/100 iter), loss = 0.360767
I0506 04:41:15.409607 12834 solver.cpp:261]     Train net output #0: loss = 0.360767 (* 1 = 0.360767 loss)
I0506 04:41:15.409615 12834 sgd_solver.cpp:106] Iteration 73000, lr = 2.09715e-05
I0506 04:41:16.342162 12834 solver.cpp:242] Iteration 73100 (93.8501 iter/s, 1.06553s/100 iter), loss = 0.609546
I0506 04:41:16.342202 12834 solver.cpp:261]     Train net output #0: loss = 0.609546 (* 1 = 0.609546 loss)
I0506 04:41:16.342211 12834 sgd_solver.cpp:106] Iteration 73100, lr = 2.09715e-05
I0506 04:41:16.346931 12834 solver.cpp:242] Iteration 73100 (106.689 iter/s, 0.937306s/100 iter), loss = 0.505718
I0506 04:41:16.346957 12834 solver.cpp:261]     Train net output #0: loss = 0.505718 (* 1 = 0.505718 loss)
I0506 04:41:16.346966 12834 sgd_solver.cpp:106] Iteration 73100, lr = 2.09715e-05
I0506 04:41:17.352776 12834 solver.cpp:242] Iteration 73200 (98.9573 iter/s, 1.01054s/100 iter), loss = 1.654
I0506 04:41:17.352821 12834 solver.cpp:261]     Train net output #0: loss = 1.654 (* 1 = 1.654 loss)
I0506 04:41:17.352833 12834 sgd_solver.cpp:106] Iteration 73200, lr = 2.09715e-05
I0506 04:41:17.358077 12834 solver.cpp:242] Iteration 73200 (98.9023 iter/s, 1.0111s/100 iter), loss = 0.703257
I0506 04:41:17.358105 12834 solver.cpp:261]     Train net output #0: loss = 0.703257 (* 1 = 0.703257 loss)
I0506 04:41:17.358116 12834 sgd_solver.cpp:106] Iteration 73200, lr = 2.09715e-05
I0506 04:41:18.322999 12834 solver.cpp:242] Iteration 73300 (103.077 iter/s, 0.970152s/100 iter), loss = 1.033
I0506 04:41:18.323045 12834 solver.cpp:261]     Train net output #0: loss = 1.033 (* 1 = 1.033 loss)
I0506 04:41:18.323217 12834 sgd_solver.cpp:106] Iteration 73300, lr = 2.09715e-05
I0506 04:41:18.328028 12834 solver.cpp:242] Iteration 73300 (103.103 iter/s, 0.969905s/100 iter), loss = 0.502005
I0506 04:41:18.328052 12834 solver.cpp:261]     Train net output #0: loss = 0.502005 (* 1 = 0.502005 loss)
I0506 04:41:18.328061 12834 sgd_solver.cpp:106] Iteration 73300, lr = 2.09715e-05
I0506 04:41:19.261330 12834 solver.cpp:242] Iteration 73400 (106.581 iter/s, 0.938258s/100 iter), loss = 0.972078
I0506 04:41:19.261368 12834 solver.cpp:261]     Train net output #0: loss = 0.972078 (* 1 = 0.972078 loss)
I0506 04:41:19.261376 12834 sgd_solver.cpp:106] Iteration 73400, lr = 2.09715e-05
I0506 04:41:19.266111 12834 solver.cpp:242] Iteration 73400 (106.605 iter/s, 0.93804s/100 iter), loss = 0.424593
I0506 04:41:19.266136 12834 solver.cpp:261]     Train net output #0: loss = 0.424593 (* 1 = 0.424593 loss)
I0506 04:41:19.266145 12834 sgd_solver.cpp:106] Iteration 73400, lr = 2.09715e-05
I0506 04:41:20.196148 12834 solver.cpp:362] Iteration 73500, Testing net (#0)
I0506 04:41:20.196169 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:20.318698 12834 solver.cpp:429]     Test net output #0: loss = 1.58923 (* 1 = 1.58923 loss)
I0506 04:41:20.321210 12834 solver.cpp:242] Iteration 73500 (94.3552 iter/s, 1.05982s/100 iter), loss = 1.20431
I0506 04:41:20.321230 12834 solver.cpp:261]     Train net output #0: loss = 1.20431 (* 1 = 1.20431 loss)
I0506 04:41:20.321238 12834 sgd_solver.cpp:106] Iteration 73500, lr = 2.09715e-05
I0506 04:41:20.323046 12834 solver.cpp:362] Iteration 73500, Testing net (#0)
I0506 04:41:20.323060 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:20.451967 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7475
I0506 04:41:20.451987 12834 solver.cpp:429]     Test net output #1: loss = 0.579087 (* 1 = 0.579087 loss)
I0506 04:41:20.454537 12834 solver.cpp:242] Iteration 73500 (84.1482 iter/s, 1.18838s/100 iter), loss = 0.699181
I0506 04:41:20.454557 12834 solver.cpp:261]     Train net output #0: loss = 0.699181 (* 1 = 0.699181 loss)
I0506 04:41:20.454576 12834 sgd_solver.cpp:106] Iteration 73500, lr = 2.09715e-05
I0506 04:41:21.387177 12834 solver.cpp:242] Iteration 73600 (93.8163 iter/s, 1.06591s/100 iter), loss = 1.29577
I0506 04:41:21.387213 12834 solver.cpp:261]     Train net output #0: loss = 1.29577 (* 1 = 1.29577 loss)
I0506 04:41:21.387223 12834 sgd_solver.cpp:106] Iteration 73600, lr = 2.09715e-05
I0506 04:41:21.391970 12834 solver.cpp:242] Iteration 73600 (106.679 iter/s, 0.937395s/100 iter), loss = 0.978195
I0506 04:41:21.391996 12834 solver.cpp:261]     Train net output #0: loss = 0.978195 (* 1 = 0.978195 loss)
I0506 04:41:21.392005 12834 sgd_solver.cpp:106] Iteration 73600, lr = 2.09715e-05
I0506 04:41:22.324399 12834 solver.cpp:242] Iteration 73700 (106.705 iter/s, 0.937163s/100 iter), loss = 0.913159
I0506 04:41:22.324434 12834 solver.cpp:261]     Train net output #0: loss = 0.913159 (* 1 = 0.913159 loss)
I0506 04:41:22.324442 12834 sgd_solver.cpp:106] Iteration 73700, lr = 2.09715e-05
I0506 04:41:22.329217 12834 solver.cpp:242] Iteration 73700 (106.702 iter/s, 0.937192s/100 iter), loss = 0.702475
I0506 04:41:22.329241 12834 solver.cpp:261]     Train net output #0: loss = 0.702475 (* 1 = 0.702475 loss)
I0506 04:41:22.329251 12834 sgd_solver.cpp:106] Iteration 73700, lr = 2.09715e-05
I0506 04:41:23.333721 12834 solver.cpp:242] Iteration 73800 (99.0824 iter/s, 1.00926s/100 iter), loss = 1.26596
I0506 04:41:23.333761 12834 solver.cpp:261]     Train net output #0: loss = 1.26596 (* 1 = 1.26596 loss)
I0506 04:41:23.333827 12834 sgd_solver.cpp:106] Iteration 73800, lr = 2.09715e-05
I0506 04:41:23.338631 12834 solver.cpp:242] Iteration 73800 (99.0716 iter/s, 1.00937s/100 iter), loss = 0.610548
I0506 04:41:23.338654 12834 solver.cpp:261]     Train net output #0: loss = 0.610548 (* 1 = 0.610548 loss)
I0506 04:41:23.338665 12834 sgd_solver.cpp:106] Iteration 73800, lr = 2.09715e-05
I0506 04:41:24.271723 12834 solver.cpp:242] Iteration 73900 (106.618 iter/s, 0.937929s/100 iter), loss = 0.82184
I0506 04:41:24.271764 12834 solver.cpp:261]     Train net output #0: loss = 0.82184 (* 1 = 0.82184 loss)
I0506 04:41:24.271775 12834 sgd_solver.cpp:106] Iteration 73900, lr = 2.09715e-05
I0506 04:41:24.276502 12834 solver.cpp:242] Iteration 73900 (106.629 iter/s, 0.93783s/100 iter), loss = 0.608973
I0506 04:41:24.276527 12834 solver.cpp:261]     Train net output #0: loss = 0.608973 (* 1 = 0.608973 loss)
I0506 04:41:24.276536 12834 sgd_solver.cpp:106] Iteration 73900, lr = 2.09715e-05
I0506 04:41:25.218092 12834 solver.cpp:362] Iteration 74000, Testing net (#0)
I0506 04:41:25.218122 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:25.340692 12834 solver.cpp:429]     Test net output #0: loss = 1.48848 (* 1 = 1.48848 loss)
I0506 04:41:25.343219 12834 solver.cpp:242] Iteration 74000 (93.3328 iter/s, 1.07143s/100 iter), loss = 0.473873
I0506 04:41:25.343238 12834 solver.cpp:261]     Train net output #0: loss = 0.473873 (* 1 = 0.473873 loss)
I0506 04:41:25.343247 12834 sgd_solver.cpp:106] Iteration 74000, lr = 2.09715e-05
I0506 04:41:25.345073 12834 solver.cpp:362] Iteration 74000, Testing net (#0)
I0506 04:41:25.345088 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:25.473716 12834 solver.cpp:429]     Test net output #0: accuracy = 0.738
I0506 04:41:25.473737 12834 solver.cpp:429]     Test net output #1: loss = 0.609873 (* 1 = 0.609873 loss)
I0506 04:41:25.476294 12834 solver.cpp:242] Iteration 74000 (83.3511 iter/s, 1.19974s/100 iter), loss = 0.491692
I0506 04:41:25.476315 12834 solver.cpp:261]     Train net output #0: loss = 0.491692 (* 1 = 0.491692 loss)
I0506 04:41:25.476322 12834 sgd_solver.cpp:106] Iteration 74000, lr = 2.09715e-05
I0506 04:41:26.409440 12834 solver.cpp:242] Iteration 74100 (93.7941 iter/s, 1.06617s/100 iter), loss = 1.45733
I0506 04:41:26.409481 12834 solver.cpp:261]     Train net output #0: loss = 1.45733 (* 1 = 1.45733 loss)
I0506 04:41:26.409490 12834 sgd_solver.cpp:106] Iteration 74100, lr = 2.09715e-05
I0506 04:41:26.414211 12834 solver.cpp:242] Iteration 74100 (106.624 iter/s, 0.937879s/100 iter), loss = 0.53933
I0506 04:41:26.414247 12834 solver.cpp:261]     Train net output #0: loss = 0.53933 (* 1 = 0.53933 loss)
I0506 04:41:26.414258 12834 sgd_solver.cpp:106] Iteration 74100, lr = 2.09715e-05
I0506 04:41:27.360982 12834 solver.cpp:242] Iteration 74200 (105.1 iter/s, 0.951474s/100 iter), loss = 2.14033
I0506 04:41:27.361027 12834 solver.cpp:261]     Train net output #0: loss = 2.14033 (* 1 = 2.14033 loss)
I0506 04:41:27.361037 12834 sgd_solver.cpp:106] Iteration 74200, lr = 2.09715e-05
I0506 04:41:27.365769 12834 solver.cpp:242] Iteration 74200 (105.097 iter/s, 0.951503s/100 iter), loss = 0.540641
I0506 04:41:27.365797 12834 solver.cpp:261]     Train net output #0: loss = 0.540641 (* 1 = 0.540641 loss)
I0506 04:41:27.365806 12834 sgd_solver.cpp:106] Iteration 74200, lr = 2.09715e-05
I0506 04:41:28.297981 12834 solver.cpp:242] Iteration 74300 (106.732 iter/s, 0.936922s/100 iter), loss = 2.37412
I0506 04:41:28.298020 12834 solver.cpp:261]     Train net output #0: loss = 2.37412 (* 1 = 2.37412 loss)
I0506 04:41:28.298029 12834 sgd_solver.cpp:106] Iteration 74300, lr = 2.09715e-05
I0506 04:41:28.302772 12834 solver.cpp:242] Iteration 74300 (106.729 iter/s, 0.936957s/100 iter), loss = 0.402729
I0506 04:41:28.302796 12834 solver.cpp:261]     Train net output #0: loss = 0.402729 (* 1 = 0.402729 loss)
I0506 04:41:28.302805 12834 sgd_solver.cpp:106] Iteration 74300, lr = 2.09715e-05
I0506 04:41:29.235517 12834 solver.cpp:242] Iteration 74400 (106.67 iter/s, 0.937471s/100 iter), loss = 1.69583
I0506 04:41:29.235556 12834 solver.cpp:261]     Train net output #0: loss = 1.69583 (* 1 = 1.69583 loss)
I0506 04:41:29.235565 12834 sgd_solver.cpp:106] Iteration 74400, lr = 2.09715e-05
I0506 04:41:29.240291 12834 solver.cpp:242] Iteration 74400 (106.67 iter/s, 0.937475s/100 iter), loss = 0.545878
I0506 04:41:29.240315 12834 solver.cpp:261]     Train net output #0: loss = 0.545878 (* 1 = 0.545878 loss)
I0506 04:41:29.240324 12834 sgd_solver.cpp:106] Iteration 74400, lr = 2.09715e-05
I0506 04:41:30.170300 12834 solver.cpp:362] Iteration 74500, Testing net (#0)
I0506 04:41:30.170323 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:30.292896 12834 solver.cpp:429]     Test net output #0: loss = 1.48925 (* 1 = 1.48925 loss)
I0506 04:41:30.295411 12834 solver.cpp:242] Iteration 74500 (94.3541 iter/s, 1.05984s/100 iter), loss = 2.66733
I0506 04:41:30.295431 12834 solver.cpp:261]     Train net output #0: loss = 2.66733 (* 1 = 2.66733 loss)
I0506 04:41:30.295439 12834 sgd_solver.cpp:106] Iteration 74500, lr = 2.09715e-05
I0506 04:41:30.297271 12834 solver.cpp:362] Iteration 74500, Testing net (#0)
I0506 04:41:30.297284 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:30.426367 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7385
I0506 04:41:30.426386 12834 solver.cpp:429]     Test net output #1: loss = 0.59964 (* 1 = 0.59964 loss)
I0506 04:41:30.428939 12834 solver.cpp:242] Iteration 74500 (84.1324 iter/s, 1.1886s/100 iter), loss = 0.58714
I0506 04:41:30.428961 12834 solver.cpp:261]     Train net output #0: loss = 0.58714 (* 1 = 0.58714 loss)
I0506 04:41:30.428968 12834 sgd_solver.cpp:106] Iteration 74500, lr = 2.09715e-05
I0506 04:41:31.361449 12834 solver.cpp:242] Iteration 74600 (93.8094 iter/s, 1.06599s/100 iter), loss = 4.11161
I0506 04:41:31.361488 12834 solver.cpp:261]     Train net output #0: loss = 4.11161 (* 1 = 4.11161 loss)
I0506 04:41:31.361497 12834 sgd_solver.cpp:106] Iteration 74600, lr = 2.09715e-05
I0506 04:41:31.366297 12834 solver.cpp:242] Iteration 74600 (106.688 iter/s, 0.937308s/100 iter), loss = 0.817326
I0506 04:41:31.366322 12834 solver.cpp:261]     Train net output #0: loss = 0.817326 (* 1 = 0.817326 loss)
I0506 04:41:31.366331 12834 sgd_solver.cpp:106] Iteration 74600, lr = 2.09715e-05
I0506 04:41:32.298924 12834 solver.cpp:242] Iteration 74700 (106.677 iter/s, 0.937409s/100 iter), loss = 0.678422
I0506 04:41:32.298962 12834 solver.cpp:261]     Train net output #0: loss = 0.678422 (* 1 = 0.678422 loss)
I0506 04:41:32.298971 12834 sgd_solver.cpp:106] Iteration 74700, lr = 2.09715e-05
I0506 04:41:32.303706 12834 solver.cpp:242] Iteration 74700 (106.682 iter/s, 0.937368s/100 iter), loss = 0.695887
I0506 04:41:32.303732 12834 solver.cpp:261]     Train net output #0: loss = 0.695887 (* 1 = 0.695887 loss)
I0506 04:41:32.303741 12834 sgd_solver.cpp:106] Iteration 74700, lr = 2.09715e-05
I0506 04:41:33.236740 12834 solver.cpp:242] Iteration 74800 (106.639 iter/s, 0.937745s/100 iter), loss = 1.19502
I0506 04:41:33.236778 12834 solver.cpp:261]     Train net output #0: loss = 1.19502 (* 1 = 1.19502 loss)
I0506 04:41:33.236786 12834 sgd_solver.cpp:106] Iteration 74800, lr = 2.09715e-05
I0506 04:41:33.241511 12834 solver.cpp:242] Iteration 74800 (106.637 iter/s, 0.937761s/100 iter), loss = 0.797163
I0506 04:41:33.241535 12834 solver.cpp:261]     Train net output #0: loss = 0.797163 (* 1 = 0.797163 loss)
I0506 04:41:33.241544 12834 sgd_solver.cpp:106] Iteration 74800, lr = 2.09715e-05
I0506 04:41:34.174405 12834 solver.cpp:242] Iteration 74900 (106.655 iter/s, 0.937604s/100 iter), loss = 0.772573
I0506 04:41:34.174437 12834 solver.cpp:261]     Train net output #0: loss = 0.772573 (* 1 = 0.772573 loss)
I0506 04:41:34.174446 12834 sgd_solver.cpp:106] Iteration 74900, lr = 2.09715e-05
I0506 04:41:34.179195 12834 solver.cpp:242] Iteration 74900 (106.651 iter/s, 0.937642s/100 iter), loss = 0.502481
I0506 04:41:34.179219 12834 solver.cpp:261]     Train net output #0: loss = 0.502481 (* 1 = 0.502481 loss)
I0506 04:41:34.179227 12834 sgd_solver.cpp:106] Iteration 74900, lr = 2.09715e-05
I0506 04:41:35.109068 12834 solver.cpp:362] Iteration 75000, Testing net (#0)
I0506 04:41:35.109097 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:35.231678 12834 solver.cpp:429]     Test net output #0: loss = 1.33001 (* 1 = 1.33001 loss)
I0506 04:41:35.234205 12834 solver.cpp:242] Iteration 75000 (94.362 iter/s, 1.05975s/100 iter), loss = 4.15921
I0506 04:41:35.234228 12834 solver.cpp:261]     Train net output #0: loss = 4.15921 (* 1 = 4.15921 loss)
I0506 04:41:35.234236 12834 sgd_solver.cpp:106] Iteration 75000, lr = 2.09715e-05
I0506 04:41:35.236043 12834 solver.cpp:362] Iteration 75000, Testing net (#0)
I0506 04:41:35.236055 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:35.364830 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7535
I0506 04:41:35.364850 12834 solver.cpp:429]     Test net output #1: loss = 0.581989 (* 1 = 0.581989 loss)
I0506 04:41:35.367442 12834 solver.cpp:242] Iteration 75000 (84.1607 iter/s, 1.1882s/100 iter), loss = 0.829038
I0506 04:41:35.367463 12834 solver.cpp:261]     Train net output #0: loss = 0.829038 (* 1 = 0.829038 loss)
I0506 04:41:35.367471 12834 sgd_solver.cpp:106] Iteration 75000, lr = 2.09715e-05
I0506 04:41:36.301038 12834 solver.cpp:242] Iteration 75100 (93.7399 iter/s, 1.06678s/100 iter), loss = 1.30361
I0506 04:41:36.301069 12834 solver.cpp:261]     Train net output #0: loss = 1.30361 (* 1 = 1.30361 loss)
I0506 04:41:36.301077 12834 sgd_solver.cpp:106] Iteration 75100, lr = 2.09715e-05
I0506 04:41:36.305768 12834 solver.cpp:242] Iteration 75100 (106.577 iter/s, 0.938286s/100 iter), loss = 0.749467
I0506 04:41:36.305791 12834 solver.cpp:261]     Train net output #0: loss = 0.749467 (* 1 = 0.749467 loss)
I0506 04:41:36.305801 12834 sgd_solver.cpp:106] Iteration 75100, lr = 2.09715e-05
I0506 04:41:37.237825 12834 solver.cpp:242] Iteration 75200 (106.755 iter/s, 0.936724s/100 iter), loss = 0.887957
I0506 04:41:37.237866 12834 solver.cpp:261]     Train net output #0: loss = 0.887957 (* 1 = 0.887957 loss)
I0506 04:41:37.237876 12834 sgd_solver.cpp:106] Iteration 75200, lr = 2.09715e-05
I0506 04:41:37.242607 12834 solver.cpp:242] Iteration 75200 (106.747 iter/s, 0.936798s/100 iter), loss = 0.465656
I0506 04:41:37.242631 12834 solver.cpp:261]     Train net output #0: loss = 0.465656 (* 1 = 0.465656 loss)
I0506 04:41:37.242640 12834 sgd_solver.cpp:106] Iteration 75200, lr = 2.09715e-05
I0506 04:41:38.175313 12834 solver.cpp:242] Iteration 75300 (106.675 iter/s, 0.937423s/100 iter), loss = 2.38167
I0506 04:41:38.175355 12834 solver.cpp:261]     Train net output #0: loss = 2.38167 (* 1 = 2.38167 loss)
I0506 04:41:38.175374 12834 sgd_solver.cpp:106] Iteration 75300, lr = 2.09715e-05
I0506 04:41:38.180099 12834 solver.cpp:242] Iteration 75300 (106.673 iter/s, 0.937448s/100 iter), loss = 0.776684
I0506 04:41:38.180124 12834 solver.cpp:261]     Train net output #0: loss = 0.776684 (* 1 = 0.776684 loss)
I0506 04:41:38.180132 12834 sgd_solver.cpp:106] Iteration 75300, lr = 2.09715e-05
I0506 04:41:39.126521 12834 solver.cpp:242] Iteration 75400 (105.138 iter/s, 0.951134s/100 iter), loss = 1.31813
I0506 04:41:39.126569 12834 solver.cpp:261]     Train net output #0: loss = 1.31813 (* 1 = 1.31813 loss)
I0506 04:41:39.126698 12834 sgd_solver.cpp:106] Iteration 75400, lr = 2.09715e-05
I0506 04:41:39.131498 12834 solver.cpp:242] Iteration 75400 (105.113 iter/s, 0.951356s/100 iter), loss = 0.427923
I0506 04:41:39.131522 12834 solver.cpp:261]     Train net output #0: loss = 0.427923 (* 1 = 0.427923 loss)
I0506 04:41:39.131531 12834 sgd_solver.cpp:106] Iteration 75400, lr = 2.09715e-05
I0506 04:41:40.061413 12834 solver.cpp:362] Iteration 75500, Testing net (#0)
I0506 04:41:40.061439 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:40.184085 12834 solver.cpp:429]     Test net output #0: loss = 1.55371 (* 1 = 1.55371 loss)
I0506 04:41:40.186602 12834 solver.cpp:242] Iteration 75500 (94.3381 iter/s, 1.06002s/100 iter), loss = 0.704703
I0506 04:41:40.186626 12834 solver.cpp:261]     Train net output #0: loss = 0.704703 (* 1 = 0.704703 loss)
I0506 04:41:40.186635 12834 sgd_solver.cpp:106] Iteration 75500, lr = 2.09715e-05
I0506 04:41:40.188522 12834 solver.cpp:362] Iteration 75500, Testing net (#0)
I0506 04:41:40.188534 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:40.317256 12834 solver.cpp:429]     Test net output #0: accuracy = 0.759
I0506 04:41:40.317276 12834 solver.cpp:429]     Test net output #1: loss = 0.574398 (* 1 = 0.574398 loss)
I0506 04:41:40.319823 12834 solver.cpp:242] Iteration 75500 (84.1553 iter/s, 1.18828s/100 iter), loss = 0.770544
I0506 04:41:40.319844 12834 solver.cpp:261]     Train net output #0: loss = 0.770544 (* 1 = 0.770544 loss)
I0506 04:41:40.319852 12834 sgd_solver.cpp:106] Iteration 75500, lr = 2.09715e-05
I0506 04:41:41.323158 12834 solver.cpp:242] Iteration 75600 (87.9895 iter/s, 1.1365s/100 iter), loss = 3.64499
I0506 04:41:41.323205 12834 solver.cpp:261]     Train net output #0: loss = 3.64499 (* 1 = 3.64499 loss)
I0506 04:41:41.323216 12834 sgd_solver.cpp:106] Iteration 75600, lr = 2.09715e-05
I0506 04:41:41.328472 12834 solver.cpp:242] Iteration 75600 (99.1466 iter/s, 1.00861s/100 iter), loss = 0.620148
I0506 04:41:41.328502 12834 solver.cpp:261]     Train net output #0: loss = 0.620148 (* 1 = 0.620148 loss)
I0506 04:41:41.328513 12834 sgd_solver.cpp:106] Iteration 75600, lr = 2.09715e-05
I0506 04:41:42.295941 12834 solver.cpp:242] Iteration 75700 (102.805 iter/s, 0.972713s/100 iter), loss = 1.48535
I0506 04:41:42.295981 12834 solver.cpp:261]     Train net output #0: loss = 1.48535 (* 1 = 1.48535 loss)
I0506 04:41:42.295990 12834 sgd_solver.cpp:106] Iteration 75700, lr = 2.09715e-05
I0506 04:41:42.300710 12834 solver.cpp:242] Iteration 75700 (102.861 iter/s, 0.972182s/100 iter), loss = 0.619073
I0506 04:41:42.300737 12834 solver.cpp:261]     Train net output #0: loss = 0.619073 (* 1 = 0.619073 loss)
I0506 04:41:42.300746 12834 sgd_solver.cpp:106] Iteration 75700, lr = 2.09715e-05
I0506 04:41:43.301936 12834 solver.cpp:242] Iteration 75800 (99.4108 iter/s, 1.00593s/100 iter), loss = 0.449715
I0506 04:41:43.301983 12834 solver.cpp:261]     Train net output #0: loss = 0.449715 (* 1 = 0.449715 loss)
I0506 04:41:43.301995 12834 sgd_solver.cpp:106] Iteration 75800, lr = 2.09715e-05
I0506 04:41:43.307205 12834 solver.cpp:242] Iteration 75800 (99.3594 iter/s, 1.00645s/100 iter), loss = 0.569433
I0506 04:41:43.307236 12834 solver.cpp:261]     Train net output #0: loss = 0.569433 (* 1 = 0.569433 loss)
I0506 04:41:43.307247 12834 sgd_solver.cpp:106] Iteration 75800, lr = 2.09715e-05
I0506 04:41:44.257513 12834 solver.cpp:242] Iteration 75900 (104.657 iter/s, 0.9555s/100 iter), loss = 1.31372
I0506 04:41:44.257643 12834 solver.cpp:261]     Train net output #0: loss = 1.31372 (* 1 = 1.31372 loss)
I0506 04:41:44.257660 12834 sgd_solver.cpp:106] Iteration 75900, lr = 2.09715e-05
I0506 04:41:44.262437 12834 solver.cpp:242] Iteration 75900 (104.692 iter/s, 0.955184s/100 iter), loss = 0.569559
I0506 04:41:44.262465 12834 solver.cpp:261]     Train net output #0: loss = 0.569559 (* 1 = 0.569559 loss)
I0506 04:41:44.262472 12834 sgd_solver.cpp:106] Iteration 75900, lr = 2.09715e-05
I0506 04:41:45.191958 12834 solver.cpp:362] Iteration 76000, Testing net (#0)
I0506 04:41:45.191982 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:45.314508 12834 solver.cpp:429]     Test net output #0: loss = 1.57841 (* 1 = 1.57841 loss)
I0506 04:41:45.317035 12834 solver.cpp:242] Iteration 76000 (94.394 iter/s, 1.05939s/100 iter), loss = 0.905294
I0506 04:41:45.317055 12834 solver.cpp:261]     Train net output #0: loss = 0.905294 (* 1 = 0.905294 loss)
I0506 04:41:45.317065 12834 sgd_solver.cpp:106] Iteration 76000, lr = 2.09715e-05
I0506 04:41:45.318898 12834 solver.cpp:362] Iteration 76000, Testing net (#0)
I0506 04:41:45.318912 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:45.447425 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7485
I0506 04:41:45.447445 12834 solver.cpp:429]     Test net output #1: loss = 0.61432 (* 1 = 0.61432 loss)
I0506 04:41:45.449987 12834 solver.cpp:242] Iteration 76000 (84.2104 iter/s, 1.1875s/100 iter), loss = 0.343371
I0506 04:41:45.450007 12834 solver.cpp:261]     Train net output #0: loss = 0.343371 (* 1 = 0.343371 loss)
I0506 04:41:45.450017 12834 sgd_solver.cpp:106] Iteration 76000, lr = 2.09715e-05
I0506 04:41:46.382923 12834 solver.cpp:242] Iteration 76100 (93.8234 iter/s, 1.06583s/100 iter), loss = 1.72038
I0506 04:41:46.382959 12834 solver.cpp:261]     Train net output #0: loss = 1.72038 (* 1 = 1.72038 loss)
I0506 04:41:46.382969 12834 sgd_solver.cpp:106] Iteration 76100, lr = 2.09715e-05
I0506 04:41:46.387727 12834 solver.cpp:242] Iteration 76100 (106.644 iter/s, 0.937701s/100 iter), loss = 0.668101
I0506 04:41:46.387751 12834 solver.cpp:261]     Train net output #0: loss = 0.668101 (* 1 = 0.668101 loss)
I0506 04:41:46.387760 12834 sgd_solver.cpp:106] Iteration 76100, lr = 2.09715e-05
I0506 04:41:47.321287 12834 solver.cpp:242] Iteration 76200 (106.575 iter/s, 0.938303s/100 iter), loss = 4.83741
I0506 04:41:47.321323 12834 solver.cpp:261]     Train net output #0: loss = 4.83741 (* 1 = 4.83741 loss)
I0506 04:41:47.321332 12834 sgd_solver.cpp:106] Iteration 76200, lr = 2.09715e-05
I0506 04:41:47.326058 12834 solver.cpp:242] Iteration 76200 (106.577 iter/s, 0.938288s/100 iter), loss = 0.924739
I0506 04:41:47.326083 12834 solver.cpp:261]     Train net output #0: loss = 0.924739 (* 1 = 0.924739 loss)
I0506 04:41:47.326092 12834 sgd_solver.cpp:106] Iteration 76200, lr = 2.09715e-05
I0506 04:41:48.258803 12834 solver.cpp:242] Iteration 76300 (106.672 iter/s, 0.937451s/100 iter), loss = 6.15554
I0506 04:41:48.258837 12834 solver.cpp:261]     Train net output #0: loss = 6.15554 (* 1 = 6.15554 loss)
I0506 04:41:48.258847 12834 sgd_solver.cpp:106] Iteration 76300, lr = 2.09715e-05
I0506 04:41:48.263567 12834 solver.cpp:242] Iteration 76300 (106.67 iter/s, 0.937467s/100 iter), loss = 0.765041
I0506 04:41:48.263592 12834 solver.cpp:261]     Train net output #0: loss = 0.765041 (* 1 = 0.765041 loss)
I0506 04:41:48.263600 12834 sgd_solver.cpp:106] Iteration 76300, lr = 2.09715e-05
I0506 04:41:49.195960 12834 solver.cpp:242] Iteration 76400 (106.712 iter/s, 0.937098s/100 iter), loss = 1.35284
I0506 04:41:49.195991 12834 solver.cpp:261]     Train net output #0: loss = 1.35284 (* 1 = 1.35284 loss)
I0506 04:41:49.196002 12834 sgd_solver.cpp:106] Iteration 76400, lr = 2.09715e-05
I0506 04:41:49.200814 12834 solver.cpp:242] Iteration 76400 (106.701 iter/s, 0.937195s/100 iter), loss = 0.590668
I0506 04:41:49.200837 12834 solver.cpp:261]     Train net output #0: loss = 0.590668 (* 1 = 0.590668 loss)
I0506 04:41:49.200846 12834 sgd_solver.cpp:106] Iteration 76400, lr = 2.09715e-05
I0506 04:41:50.130707 12834 solver.cpp:362] Iteration 76500, Testing net (#0)
I0506 04:41:50.130726 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:50.253267 12834 solver.cpp:429]     Test net output #0: loss = 1.58415 (* 1 = 1.58415 loss)
I0506 04:41:50.255777 12834 solver.cpp:242] Iteration 76500 (94.3603 iter/s, 1.05977s/100 iter), loss = 1.07233
I0506 04:41:50.255796 12834 solver.cpp:261]     Train net output #0: loss = 1.07233 (* 1 = 1.07233 loss)
I0506 04:41:50.255805 12834 sgd_solver.cpp:106] Iteration 76500, lr = 2.09715e-05
I0506 04:41:50.257617 12834 solver.cpp:362] Iteration 76500, Testing net (#0)
I0506 04:41:50.257630 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:50.386545 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7515
I0506 04:41:50.386564 12834 solver.cpp:429]     Test net output #1: loss = 0.57689 (* 1 = 0.57689 loss)
I0506 04:41:50.389107 12834 solver.cpp:242] Iteration 76500 (84.1574 iter/s, 1.18825s/100 iter), loss = 0.464313
I0506 04:41:50.389128 12834 solver.cpp:261]     Train net output #0: loss = 0.464313 (* 1 = 0.464313 loss)
I0506 04:41:50.389137 12834 sgd_solver.cpp:106] Iteration 76500, lr = 2.09715e-05
I0506 04:41:51.322427 12834 solver.cpp:242] Iteration 76600 (93.7555 iter/s, 1.0666s/100 iter), loss = 1.72263
I0506 04:41:51.322468 12834 solver.cpp:261]     Train net output #0: loss = 1.72263 (* 1 = 1.72263 loss)
I0506 04:41:51.322476 12834 sgd_solver.cpp:106] Iteration 76600, lr = 2.09715e-05
I0506 04:41:51.327265 12834 solver.cpp:242] Iteration 76600 (106.597 iter/s, 0.938109s/100 iter), loss = 0.499372
I0506 04:41:51.327289 12834 solver.cpp:261]     Train net output #0: loss = 0.499372 (* 1 = 0.499372 loss)
I0506 04:41:51.327299 12834 sgd_solver.cpp:106] Iteration 76600, lr = 2.09715e-05
I0506 04:41:52.259601 12834 solver.cpp:242] Iteration 76700 (106.711 iter/s, 0.937106s/100 iter), loss = 1.32195
I0506 04:41:52.259642 12834 solver.cpp:261]     Train net output #0: loss = 1.32195 (* 1 = 1.32195 loss)
I0506 04:41:52.259652 12834 sgd_solver.cpp:106] Iteration 76700, lr = 2.09715e-05
I0506 04:41:52.264405 12834 solver.cpp:242] Iteration 76700 (106.712 iter/s, 0.937098s/100 iter), loss = 0.465548
I0506 04:41:52.264430 12834 solver.cpp:261]     Train net output #0: loss = 0.465548 (* 1 = 0.465548 loss)
I0506 04:41:52.264438 12834 sgd_solver.cpp:106] Iteration 76700, lr = 2.09715e-05
I0506 04:41:53.196389 12834 solver.cpp:242] Iteration 76800 (106.756 iter/s, 0.936715s/100 iter), loss = 2.67341
I0506 04:41:53.196430 12834 solver.cpp:261]     Train net output #0: loss = 2.67341 (* 1 = 2.67341 loss)
I0506 04:41:53.196439 12834 sgd_solver.cpp:106] Iteration 76800, lr = 2.09715e-05
I0506 04:41:53.201158 12834 solver.cpp:242] Iteration 76800 (106.757 iter/s, 0.936709s/100 iter), loss = 0.743446
I0506 04:41:53.201182 12834 solver.cpp:261]     Train net output #0: loss = 0.743446 (* 1 = 0.743446 loss)
I0506 04:41:53.201191 12834 sgd_solver.cpp:106] Iteration 76800, lr = 2.09715e-05
I0506 04:41:54.134487 12834 solver.cpp:242] Iteration 76900 (106.606 iter/s, 0.938031s/100 iter), loss = 1.56013
I0506 04:41:54.134526 12834 solver.cpp:261]     Train net output #0: loss = 1.56013 (* 1 = 1.56013 loss)
I0506 04:41:54.134536 12834 sgd_solver.cpp:106] Iteration 76900, lr = 2.09715e-05
I0506 04:41:54.139261 12834 solver.cpp:242] Iteration 76900 (106.603 iter/s, 0.93806s/100 iter), loss = 0.963832
I0506 04:41:54.139287 12834 solver.cpp:261]     Train net output #0: loss = 0.963832 (* 1 = 0.963832 loss)
I0506 04:41:54.139297 12834 sgd_solver.cpp:106] Iteration 76900, lr = 2.09715e-05
I0506 04:41:55.120263 12834 solver.cpp:362] Iteration 77000, Testing net (#0)
I0506 04:41:55.120298 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:55.243039 12834 solver.cpp:429]     Test net output #0: loss = 1.34624 (* 1 = 1.34624 loss)
I0506 04:41:55.245574 12834 solver.cpp:242] Iteration 77000 (90.0067 iter/s, 1.11103s/100 iter), loss = 1.66553
I0506 04:41:55.245597 12834 solver.cpp:261]     Train net output #0: loss = 1.66553 (* 1 = 1.66553 loss)
I0506 04:41:55.245613 12834 sgd_solver.cpp:106] Iteration 77000, lr = 2.09715e-05
I0506 04:41:55.247437 12834 solver.cpp:362] Iteration 77000, Testing net (#0)
I0506 04:41:55.247450 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:41:55.376314 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7665
I0506 04:41:55.376333 12834 solver.cpp:429]     Test net output #1: loss = 0.544635 (* 1 = 0.544635 loss)
I0506 04:41:55.378882 12834 solver.cpp:242] Iteration 77000 (80.6728 iter/s, 1.23957s/100 iter), loss = 0.561738
I0506 04:41:55.378903 12834 solver.cpp:261]     Train net output #0: loss = 0.561738 (* 1 = 0.561738 loss)
I0506 04:41:55.378912 12834 sgd_solver.cpp:106] Iteration 77000, lr = 2.09715e-05
I0506 04:41:56.311208 12834 solver.cpp:242] Iteration 77100 (93.8455 iter/s, 1.06558s/100 iter), loss = 2.66224
I0506 04:41:56.311247 12834 solver.cpp:261]     Train net output #0: loss = 2.66224 (* 1 = 2.66224 loss)
I0506 04:41:56.311256 12834 sgd_solver.cpp:106] Iteration 77100, lr = 2.09715e-05
I0506 04:41:56.315976 12834 solver.cpp:242] Iteration 77100 (106.717 iter/s, 0.937054s/100 iter), loss = 0.897014
I0506 04:41:56.316000 12834 solver.cpp:261]     Train net output #0: loss = 0.897014 (* 1 = 0.897014 loss)
I0506 04:41:56.316009 12834 sgd_solver.cpp:106] Iteration 77100, lr = 2.09715e-05
I0506 04:41:57.249311 12834 solver.cpp:242] Iteration 77200 (106.606 iter/s, 0.938034s/100 iter), loss = 3.15552
I0506 04:41:57.249351 12834 solver.cpp:261]     Train net output #0: loss = 3.15552 (* 1 = 3.15552 loss)
I0506 04:41:57.249359 12834 sgd_solver.cpp:106] Iteration 77200, lr = 2.09715e-05
I0506 04:41:57.254076 12834 solver.cpp:242] Iteration 77200 (106.603 iter/s, 0.938057s/100 iter), loss = 0.74195
I0506 04:41:57.254101 12834 solver.cpp:261]     Train net output #0: loss = 0.74195 (* 1 = 0.74195 loss)
I0506 04:41:57.254108 12834 sgd_solver.cpp:106] Iteration 77200, lr = 2.09715e-05
I0506 04:41:58.186666 12834 solver.cpp:242] Iteration 77300 (106.69 iter/s, 0.937293s/100 iter), loss = 0.696597
I0506 04:41:58.186707 12834 solver.cpp:261]     Train net output #0: loss = 0.696597 (* 1 = 0.696597 loss)
I0506 04:41:58.186717 12834 sgd_solver.cpp:106] Iteration 77300, lr = 2.09715e-05
I0506 04:41:58.191505 12834 solver.cpp:242] Iteration 77300 (106.682 iter/s, 0.937367s/100 iter), loss = 0.29727
I0506 04:41:58.191529 12834 solver.cpp:261]     Train net output #0: loss = 0.29727 (* 1 = 0.29727 loss)
I0506 04:41:58.191540 12834 sgd_solver.cpp:106] Iteration 77300, lr = 2.09715e-05
I0506 04:41:59.180726 12834 solver.cpp:242] Iteration 77400 (100.605 iter/s, 0.993991s/100 iter), loss = 1.73342
I0506 04:41:59.180768 12834 solver.cpp:261]     Train net output #0: loss = 1.73342 (* 1 = 1.73342 loss)
I0506 04:41:59.180779 12834 sgd_solver.cpp:106] Iteration 77400, lr = 2.09715e-05
I0506 04:41:59.185998 12834 solver.cpp:242] Iteration 77400 (100.558 iter/s, 0.994448s/100 iter), loss = 0.604451
I0506 04:41:59.186027 12834 solver.cpp:261]     Train net output #0: loss = 0.604451 (* 1 = 0.604451 loss)
I0506 04:41:59.186038 12834 sgd_solver.cpp:106] Iteration 77400, lr = 2.09715e-05
I0506 04:42:00.241600 12834 solver.cpp:362] Iteration 77500, Testing net (#0)
I0506 04:42:00.241657 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:00.365495 12834 solver.cpp:429]     Test net output #0: loss = 1.52116 (* 1 = 1.52116 loss)
I0506 04:42:00.368059 12834 solver.cpp:242] Iteration 77500 (84.2269 iter/s, 1.18727s/100 iter), loss = 1.40389
I0506 04:42:00.368088 12834 solver.cpp:261]     Train net output #0: loss = 1.40389 (* 1 = 1.40389 loss)
I0506 04:42:00.368096 12834 sgd_solver.cpp:106] Iteration 77500, lr = 2.09715e-05
I0506 04:42:00.370178 12834 solver.cpp:362] Iteration 77500, Testing net (#0)
I0506 04:42:00.370193 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:00.500835 12834 solver.cpp:429]     Test net output #0: accuracy = 0.75
I0506 04:42:00.500855 12834 solver.cpp:429]     Test net output #1: loss = 0.584768 (* 1 = 0.584768 loss)
I0506 04:42:00.503456 12834 solver.cpp:242] Iteration 77500 (75.9066 iter/s, 1.31741s/100 iter), loss = 0.642103
I0506 04:42:00.503486 12834 solver.cpp:261]     Train net output #0: loss = 0.642103 (* 1 = 0.642103 loss)
I0506 04:42:00.503497 12834 sgd_solver.cpp:106] Iteration 77500, lr = 2.09715e-05
I0506 04:42:01.448576 12834 solver.cpp:242] Iteration 77600 (92.5532 iter/s, 1.08046s/100 iter), loss = 0.642038
I0506 04:42:01.448613 12834 solver.cpp:261]     Train net output #0: loss = 0.642038 (* 1 = 0.642038 loss)
I0506 04:42:01.448622 12834 sgd_solver.cpp:106] Iteration 77600, lr = 2.09715e-05
I0506 04:42:01.453459 12834 solver.cpp:242] Iteration 77600 (105.268 iter/s, 0.949954s/100 iter), loss = 0.244984
I0506 04:42:01.453485 12834 solver.cpp:261]     Train net output #0: loss = 0.244984 (* 1 = 0.244984 loss)
I0506 04:42:01.453495 12834 sgd_solver.cpp:106] Iteration 77600, lr = 2.09715e-05
I0506 04:42:02.392854 12834 solver.cpp:242] Iteration 77700 (105.909 iter/s, 0.944209s/100 iter), loss = 1.69311
I0506 04:42:02.392890 12834 solver.cpp:261]     Train net output #0: loss = 1.69311 (* 1 = 1.69311 loss)
I0506 04:42:02.392900 12834 sgd_solver.cpp:106] Iteration 77700, lr = 2.09715e-05
I0506 04:42:02.397665 12834 solver.cpp:242] Iteration 77700 (105.914 iter/s, 0.944162s/100 iter), loss = 0.584026
I0506 04:42:02.397689 12834 solver.cpp:261]     Train net output #0: loss = 0.584026 (* 1 = 0.584026 loss)
I0506 04:42:02.397698 12834 sgd_solver.cpp:106] Iteration 77700, lr = 2.09715e-05
I0506 04:42:03.351167 12834 solver.cpp:242] Iteration 77800 (104.357 iter/s, 0.958251s/100 iter), loss = 2.20687
I0506 04:42:03.351202 12834 solver.cpp:261]     Train net output #0: loss = 2.20687 (* 1 = 2.20687 loss)
I0506 04:42:03.351212 12834 sgd_solver.cpp:106] Iteration 77800, lr = 2.09715e-05
I0506 04:42:03.355962 12834 solver.cpp:242] Iteration 77800 (104.357 iter/s, 0.958253s/100 iter), loss = 0.659095
I0506 04:42:03.355986 12834 solver.cpp:261]     Train net output #0: loss = 0.659095 (* 1 = 0.659095 loss)
I0506 04:42:03.355995 12834 sgd_solver.cpp:106] Iteration 77800, lr = 2.09715e-05
I0506 04:42:04.295558 12834 solver.cpp:242] Iteration 77900 (105.896 iter/s, 0.944327s/100 iter), loss = 1.12665
I0506 04:42:04.295590 12834 solver.cpp:261]     Train net output #0: loss = 1.12665 (* 1 = 1.12665 loss)
I0506 04:42:04.295600 12834 sgd_solver.cpp:106] Iteration 77900, lr = 2.09715e-05
I0506 04:42:04.300343 12834 solver.cpp:242] Iteration 77900 (105.894 iter/s, 0.944338s/100 iter), loss = 0.760271
I0506 04:42:04.300366 12834 solver.cpp:261]     Train net output #0: loss = 0.760271 (* 1 = 0.760271 loss)
I0506 04:42:04.300375 12834 sgd_solver.cpp:106] Iteration 77900, lr = 2.09715e-05
I0506 04:42:05.230474 12834 solver.cpp:362] Iteration 78000, Testing net (#0)
I0506 04:42:05.230502 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:05.353137 12834 solver.cpp:429]     Test net output #0: loss = 1.47213 (* 1 = 1.47213 loss)
I0506 04:42:05.355648 12834 solver.cpp:242] Iteration 78000 (94.3362 iter/s, 1.06004s/100 iter), loss = 1.08382
I0506 04:42:05.355667 12834 solver.cpp:261]     Train net output #0: loss = 1.08382 (* 1 = 1.08382 loss)
I0506 04:42:05.355676 12834 sgd_solver.cpp:106] Iteration 78000, lr = 2.09715e-05
I0506 04:42:05.357532 12834 solver.cpp:362] Iteration 78000, Testing net (#0)
I0506 04:42:05.357544 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:05.486587 12834 solver.cpp:429]     Test net output #0: accuracy = 0.751
I0506 04:42:05.486606 12834 solver.cpp:429]     Test net output #1: loss = 0.587407 (* 1 = 0.587407 loss)
I0506 04:42:05.489163 12834 solver.cpp:242] Iteration 78000 (84.1201 iter/s, 1.18878s/100 iter), loss = 0.62093
I0506 04:42:05.489184 12834 solver.cpp:261]     Train net output #0: loss = 0.62093 (* 1 = 0.62093 loss)
I0506 04:42:05.489193 12834 sgd_solver.cpp:106] Iteration 78000, lr = 2.09715e-05
I0506 04:42:06.421988 12834 solver.cpp:242] Iteration 78100 (93.7832 iter/s, 1.06629s/100 iter), loss = 0.739293
I0506 04:42:06.422015 12834 solver.cpp:261]     Train net output #0: loss = 0.739293 (* 1 = 0.739293 loss)
I0506 04:42:06.422034 12834 sgd_solver.cpp:106] Iteration 78100, lr = 2.09715e-05
I0506 04:42:06.426772 12834 solver.cpp:242] Iteration 78100 (106.659 iter/s, 0.93757s/100 iter), loss = 0.403035
I0506 04:42:06.426797 12834 solver.cpp:261]     Train net output #0: loss = 0.403035 (* 1 = 0.403035 loss)
I0506 04:42:06.426806 12834 sgd_solver.cpp:106] Iteration 78100, lr = 2.09715e-05
I0506 04:42:07.359338 12834 solver.cpp:242] Iteration 78200 (106.69 iter/s, 0.937298s/100 iter), loss = 1.72967
I0506 04:42:07.359380 12834 solver.cpp:261]     Train net output #0: loss = 1.72967 (* 1 = 1.72967 loss)
I0506 04:42:07.359390 12834 sgd_solver.cpp:106] Iteration 78200, lr = 2.09715e-05
I0506 04:42:07.364197 12834 solver.cpp:242] Iteration 78200 (106.681 iter/s, 0.937372s/100 iter), loss = 0.483573
I0506 04:42:07.364223 12834 solver.cpp:261]     Train net output #0: loss = 0.483573 (* 1 = 0.483573 loss)
I0506 04:42:07.364233 12834 sgd_solver.cpp:106] Iteration 78200, lr = 2.09715e-05
I0506 04:42:08.297250 12834 solver.cpp:242] Iteration 78300 (106.628 iter/s, 0.937842s/100 iter), loss = 1.59081
I0506 04:42:08.297289 12834 solver.cpp:261]     Train net output #0: loss = 1.59081 (* 1 = 1.59081 loss)
I0506 04:42:08.297298 12834 sgd_solver.cpp:106] Iteration 78300, lr = 2.09715e-05
I0506 04:42:08.302017 12834 solver.cpp:242] Iteration 78300 (106.635 iter/s, 0.937775s/100 iter), loss = 0.495628
I0506 04:42:08.302044 12834 solver.cpp:261]     Train net output #0: loss = 0.495628 (* 1 = 0.495628 loss)
I0506 04:42:08.302053 12834 sgd_solver.cpp:106] Iteration 78300, lr = 2.09715e-05
I0506 04:42:09.234690 12834 solver.cpp:242] Iteration 78400 (106.681 iter/s, 0.937378s/100 iter), loss = 0.890569
I0506 04:42:09.234730 12834 solver.cpp:261]     Train net output #0: loss = 0.890569 (* 1 = 0.890569 loss)
I0506 04:42:09.234740 12834 sgd_solver.cpp:106] Iteration 78400, lr = 2.09715e-05
I0506 04:42:09.239542 12834 solver.cpp:242] Iteration 78400 (106.67 iter/s, 0.93747s/100 iter), loss = 0.469144
I0506 04:42:09.239565 12834 solver.cpp:261]     Train net output #0: loss = 0.469144 (* 1 = 0.469144 loss)
I0506 04:42:09.239574 12834 sgd_solver.cpp:106] Iteration 78400, lr = 2.09715e-05
I0506 04:42:10.170112 12834 solver.cpp:362] Iteration 78500, Testing net (#0)
I0506 04:42:10.170138 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:10.292588 12834 solver.cpp:429]     Test net output #0: loss = 1.49817 (* 1 = 1.49817 loss)
I0506 04:42:10.295169 12834 solver.cpp:242] Iteration 78500 (94.3022 iter/s, 1.06042s/100 iter), loss = 3.10543
I0506 04:42:10.295192 12834 solver.cpp:261]     Train net output #0: loss = 3.10543 (* 1 = 3.10543 loss)
I0506 04:42:10.295200 12834 sgd_solver.cpp:106] Iteration 78500, lr = 2.09715e-05
I0506 04:42:10.297045 12834 solver.cpp:362] Iteration 78500, Testing net (#0)
I0506 04:42:10.297060 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:10.425904 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7425
I0506 04:42:10.425923 12834 solver.cpp:429]     Test net output #1: loss = 0.607279 (* 1 = 0.607279 loss)
I0506 04:42:10.428630 12834 solver.cpp:242] Iteration 78500 (84.1012 iter/s, 1.18904s/100 iter), loss = 0.766191
I0506 04:42:10.428652 12834 solver.cpp:261]     Train net output #0: loss = 0.766191 (* 1 = 0.766191 loss)
I0506 04:42:10.428660 12834 sgd_solver.cpp:106] Iteration 78500, lr = 2.09715e-05
I0506 04:42:11.361984 12834 solver.cpp:242] Iteration 78600 (93.742 iter/s, 1.06676s/100 iter), loss = 3.70783
I0506 04:42:11.362023 12834 solver.cpp:261]     Train net output #0: loss = 3.70783 (* 1 = 3.70783 loss)
I0506 04:42:11.362032 12834 sgd_solver.cpp:106] Iteration 78600, lr = 2.09715e-05
I0506 04:42:11.366765 12834 solver.cpp:242] Iteration 78600 (106.599 iter/s, 0.938096s/100 iter), loss = 0.960749
I0506 04:42:11.366791 12834 solver.cpp:261]     Train net output #0: loss = 0.960749 (* 1 = 0.960749 loss)
I0506 04:42:11.366799 12834 sgd_solver.cpp:106] Iteration 78600, lr = 2.09715e-05
I0506 04:42:12.300369 12834 solver.cpp:242] Iteration 78700 (106.573 iter/s, 0.938322s/100 iter), loss = 0.7404
I0506 04:42:12.300417 12834 solver.cpp:261]     Train net output #0: loss = 0.7404 (* 1 = 0.7404 loss)
I0506 04:42:12.300427 12834 sgd_solver.cpp:106] Iteration 78700, lr = 2.09715e-05
I0506 04:42:12.305143 12834 solver.cpp:242] Iteration 78700 (106.572 iter/s, 0.938335s/100 iter), loss = 0.646556
I0506 04:42:12.305167 12834 solver.cpp:261]     Train net output #0: loss = 0.646556 (* 1 = 0.646556 loss)
I0506 04:42:12.305176 12834 sgd_solver.cpp:106] Iteration 78700, lr = 2.09715e-05
I0506 04:42:13.237238 12834 solver.cpp:242] Iteration 78800 (106.747 iter/s, 0.936791s/100 iter), loss = 0.94168
I0506 04:42:13.237277 12834 solver.cpp:261]     Train net output #0: loss = 0.94168 (* 1 = 0.94168 loss)
I0506 04:42:13.237287 12834 sgd_solver.cpp:106] Iteration 78800, lr = 2.09715e-05
I0506 04:42:13.242010 12834 solver.cpp:242] Iteration 78800 (106.744 iter/s, 0.936825s/100 iter), loss = 0.54813
I0506 04:42:13.242033 12834 solver.cpp:261]     Train net output #0: loss = 0.54813 (* 1 = 0.54813 loss)
I0506 04:42:13.242043 12834 sgd_solver.cpp:106] Iteration 78800, lr = 2.09715e-05
I0506 04:42:14.174121 12834 solver.cpp:242] Iteration 78900 (106.744 iter/s, 0.93682s/100 iter), loss = 0.926539
I0506 04:42:14.174157 12834 solver.cpp:261]     Train net output #0: loss = 0.926539 (* 1 = 0.926539 loss)
I0506 04:42:14.174167 12834 sgd_solver.cpp:106] Iteration 78900, lr = 2.09715e-05
I0506 04:42:14.178905 12834 solver.cpp:242] Iteration 78900 (106.74 iter/s, 0.936853s/100 iter), loss = 0.794394
I0506 04:42:14.178930 12834 solver.cpp:261]     Train net output #0: loss = 0.794394 (* 1 = 0.794394 loss)
I0506 04:42:14.178938 12834 sgd_solver.cpp:106] Iteration 78900, lr = 2.09715e-05
I0506 04:42:15.122381 12834 solver.cpp:362] Iteration 79000, Testing net (#0)
I0506 04:42:15.122402 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:15.244992 12834 solver.cpp:429]     Test net output #0: loss = 1.55964 (* 1 = 1.55964 loss)
I0506 04:42:15.247516 12834 solver.cpp:242] Iteration 79000 (93.1671 iter/s, 1.07334s/100 iter), loss = 1.54048
I0506 04:42:15.247535 12834 solver.cpp:261]     Train net output #0: loss = 1.54048 (* 1 = 1.54048 loss)
I0506 04:42:15.247545 12834 sgd_solver.cpp:106] Iteration 79000, lr = 2.09715e-05
I0506 04:42:15.249383 12834 solver.cpp:362] Iteration 79000, Testing net (#0)
I0506 04:42:15.249397 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:15.378394 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7745
I0506 04:42:15.378417 12834 solver.cpp:429]     Test net output #1: loss = 0.571827 (* 1 = 0.571827 loss)
I0506 04:42:15.381037 12834 solver.cpp:242] Iteration 79000 (83.1887 iter/s, 1.20209s/100 iter), loss = 0.530905
I0506 04:42:15.381058 12834 solver.cpp:261]     Train net output #0: loss = 0.530905 (* 1 = 0.530905 loss)
I0506 04:42:15.381067 12834 sgd_solver.cpp:106] Iteration 79000, lr = 2.09715e-05
I0506 04:42:16.313508 12834 solver.cpp:242] Iteration 79100 (93.8134 iter/s, 1.06595s/100 iter), loss = 0.995417
I0506 04:42:16.313544 12834 solver.cpp:261]     Train net output #0: loss = 0.995417 (* 1 = 0.995417 loss)
I0506 04:42:16.313555 12834 sgd_solver.cpp:106] Iteration 79100, lr = 2.09715e-05
I0506 04:42:16.318369 12834 solver.cpp:242] Iteration 79100 (106.691 iter/s, 0.937283s/100 iter), loss = 0.813017
I0506 04:42:16.318393 12834 solver.cpp:261]     Train net output #0: loss = 0.813017 (* 1 = 0.813017 loss)
I0506 04:42:16.318403 12834 sgd_solver.cpp:106] Iteration 79100, lr = 2.09715e-05
I0506 04:42:17.250790 12834 solver.cpp:242] Iteration 79200 (106.699 iter/s, 0.93722s/100 iter), loss = 1.6298
I0506 04:42:17.250818 12834 solver.cpp:261]     Train net output #0: loss = 1.6298 (* 1 = 1.6298 loss)
I0506 04:42:17.250828 12834 sgd_solver.cpp:106] Iteration 79200, lr = 2.09715e-05
I0506 04:42:17.255537 12834 solver.cpp:242] Iteration 79200 (106.709 iter/s, 0.937126s/100 iter), loss = 0.627707
I0506 04:42:17.255560 12834 solver.cpp:261]     Train net output #0: loss = 0.627707 (* 1 = 0.627707 loss)
I0506 04:42:17.255569 12834 sgd_solver.cpp:106] Iteration 79200, lr = 2.09715e-05
I0506 04:42:18.187737 12834 solver.cpp:242] Iteration 79300 (106.736 iter/s, 0.936894s/100 iter), loss = 0.554487
I0506 04:42:18.187780 12834 solver.cpp:261]     Train net output #0: loss = 0.554487 (* 1 = 0.554487 loss)
I0506 04:42:18.187789 12834 sgd_solver.cpp:106] Iteration 79300, lr = 2.09715e-05
I0506 04:42:18.192617 12834 solver.cpp:242] Iteration 79300 (106.72 iter/s, 0.93703s/100 iter), loss = 0.724882
I0506 04:42:18.192641 12834 solver.cpp:261]     Train net output #0: loss = 0.724882 (* 1 = 0.724882 loss)
I0506 04:42:18.192651 12834 sgd_solver.cpp:106] Iteration 79300, lr = 2.09715e-05
I0506 04:42:19.181867 12834 solver.cpp:242] Iteration 79400 (100.598 iter/s, 0.994058s/100 iter), loss = 4.71322
I0506 04:42:19.181917 12834 solver.cpp:261]     Train net output #0: loss = 4.71322 (* 1 = 4.71322 loss)
I0506 04:42:19.181928 12834 sgd_solver.cpp:106] Iteration 79400, lr = 2.09715e-05
I0506 04:42:19.187129 12834 solver.cpp:242] Iteration 79400 (100.556 iter/s, 0.994468s/100 iter), loss = 0.83526
I0506 04:42:19.187160 12834 solver.cpp:261]     Train net output #0: loss = 0.83526 (* 1 = 0.83526 loss)
I0506 04:42:19.187170 12834 sgd_solver.cpp:106] Iteration 79400, lr = 2.09715e-05
I0506 04:42:20.131382 12834 solver.cpp:362] Iteration 79500, Testing net (#0)
I0506 04:42:20.131410 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:20.253939 12834 solver.cpp:429]     Test net output #0: loss = 1.43552 (* 1 = 1.43552 loss)
I0506 04:42:20.256454 12834 solver.cpp:242] Iteration 79500 (93.0649 iter/s, 1.07452s/100 iter), loss = 1.28265
I0506 04:42:20.256474 12834 solver.cpp:261]     Train net output #0: loss = 1.28265 (* 1 = 1.28265 loss)
I0506 04:42:20.256482 12834 sgd_solver.cpp:106] Iteration 79500, lr = 2.09715e-05
I0506 04:42:20.258307 12834 solver.cpp:362] Iteration 79500, Testing net (#0)
I0506 04:42:20.258322 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:20.387022 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7475
I0506 04:42:20.387048 12834 solver.cpp:429]     Test net output #1: loss = 0.599736 (* 1 = 0.599736 loss)
I0506 04:42:20.390023 12834 solver.cpp:242] Iteration 79500 (83.1363 iter/s, 1.20284s/100 iter), loss = 0.426871
I0506 04:42:20.390044 12834 solver.cpp:261]     Train net output #0: loss = 0.426871 (* 1 = 0.426871 loss)
I0506 04:42:20.390053 12834 sgd_solver.cpp:106] Iteration 79500, lr = 2.09715e-05
I0506 04:42:21.322538 12834 solver.cpp:242] Iteration 79600 (93.8055 iter/s, 1.06604s/100 iter), loss = 1.79404
I0506 04:42:21.322580 12834 solver.cpp:261]     Train net output #0: loss = 1.79404 (* 1 = 1.79404 loss)
I0506 04:42:21.322589 12834 sgd_solver.cpp:106] Iteration 79600, lr = 2.09715e-05
I0506 04:42:21.327319 12834 solver.cpp:242] Iteration 79600 (106.694 iter/s, 0.937257s/100 iter), loss = 0.679308
I0506 04:42:21.327344 12834 solver.cpp:261]     Train net output #0: loss = 0.679308 (* 1 = 0.679308 loss)
I0506 04:42:21.327353 12834 sgd_solver.cpp:106] Iteration 79600, lr = 2.09715e-05
I0506 04:42:22.260573 12834 solver.cpp:242] Iteration 79700 (106.615 iter/s, 0.937958s/100 iter), loss = 1.6198
I0506 04:42:22.260614 12834 solver.cpp:261]     Train net output #0: loss = 1.6198 (* 1 = 1.6198 loss)
I0506 04:42:22.260624 12834 sgd_solver.cpp:106] Iteration 79700, lr = 2.09715e-05
I0506 04:42:22.265344 12834 solver.cpp:242] Iteration 79700 (106.612 iter/s, 0.937983s/100 iter), loss = 0.770202
I0506 04:42:22.265369 12834 solver.cpp:261]     Train net output #0: loss = 0.770202 (* 1 = 0.770202 loss)
I0506 04:42:22.265378 12834 sgd_solver.cpp:106] Iteration 79700, lr = 2.09715e-05
I0506 04:42:23.262727 12834 solver.cpp:242] Iteration 79800 (99.7921 iter/s, 1.00208s/100 iter), loss = 1.45348
I0506 04:42:23.262773 12834 solver.cpp:261]     Train net output #0: loss = 1.45348 (* 1 = 1.45348 loss)
I0506 04:42:23.262785 12834 sgd_solver.cpp:106] Iteration 79800, lr = 2.09715e-05
I0506 04:42:23.268003 12834 solver.cpp:242] Iteration 79800 (99.7393 iter/s, 1.00261s/100 iter), loss = 0.454645
I0506 04:42:23.268033 12834 solver.cpp:261]     Train net output #0: loss = 0.454645 (* 1 = 0.454645 loss)
I0506 04:42:23.268054 12834 sgd_solver.cpp:106] Iteration 79800, lr = 2.09715e-05
I0506 04:42:24.298121 12834 solver.cpp:242] Iteration 79900 (96.5889 iter/s, 1.03532s/100 iter), loss = 1.07527
I0506 04:42:24.298167 12834 solver.cpp:261]     Train net output #0: loss = 1.07527 (* 1 = 1.07527 loss)
I0506 04:42:24.298179 12834 sgd_solver.cpp:106] Iteration 79900, lr = 2.09715e-05
I0506 04:42:24.303400 12834 solver.cpp:242] Iteration 79900 (96.586 iter/s, 1.03535s/100 iter), loss = 0.591221
I0506 04:42:24.303428 12834 solver.cpp:261]     Train net output #0: loss = 0.591221 (* 1 = 0.591221 loss)
I0506 04:42:24.303439 12834 sgd_solver.cpp:106] Iteration 79900, lr = 2.09715e-05
I0506 04:42:25.331110 12834 solver.cpp:362] Iteration 80000, Testing net (#0)
I0506 04:42:25.331140 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:25.454591 12834 solver.cpp:429]     Test net output #0: loss = 1.34868 (* 1 = 1.34868 loss)
I0506 04:42:25.457162 12834 solver.cpp:242] Iteration 80000 (86.2832 iter/s, 1.15897s/100 iter), loss = 0.786014
I0506 04:42:25.457190 12834 solver.cpp:261]     Train net output #0: loss = 0.786014 (* 1 = 0.786014 loss)
I0506 04:42:25.457200 12834 sgd_solver.cpp:106] Iteration 80000, lr = 1.67772e-05
I0506 04:42:25.459108 12834 solver.cpp:362] Iteration 80000, Testing net (#0)
I0506 04:42:25.459122 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:25.587776 12834 solver.cpp:429]     Test net output #0: accuracy = 0.744
I0506 04:42:25.587796 12834 solver.cpp:429]     Test net output #1: loss = 0.576766 (* 1 = 0.576766 loss)
I0506 04:42:25.590353 12834 solver.cpp:242] Iteration 80000 (77.7059 iter/s, 1.2869s/100 iter), loss = 0.681973
I0506 04:42:25.590373 12834 solver.cpp:261]     Train net output #0: loss = 0.681973 (* 1 = 0.681973 loss)
I0506 04:42:25.590382 12834 sgd_solver.cpp:106] Iteration 80000, lr = 1.67772e-05
I0506 04:42:26.523071 12834 solver.cpp:242] Iteration 80100 (93.8217 iter/s, 1.06585s/100 iter), loss = 4.29945
I0506 04:42:26.523110 12834 solver.cpp:261]     Train net output #0: loss = 4.29945 (* 1 = 4.29945 loss)
I0506 04:42:26.523120 12834 sgd_solver.cpp:106] Iteration 80100, lr = 1.67772e-05
I0506 04:42:26.527845 12834 solver.cpp:242] Iteration 80100 (106.672 iter/s, 0.937452s/100 iter), loss = 0.623031
I0506 04:42:26.527873 12834 solver.cpp:261]     Train net output #0: loss = 0.623031 (* 1 = 0.623031 loss)
I0506 04:42:26.527881 12834 sgd_solver.cpp:106] Iteration 80100, lr = 1.67772e-05
I0506 04:42:27.460238 12834 solver.cpp:242] Iteration 80200 (106.712 iter/s, 0.937105s/100 iter), loss = 1.52007
I0506 04:42:27.460278 12834 solver.cpp:261]     Train net output #0: loss = 1.52007 (* 1 = 1.52007 loss)
I0506 04:42:27.460288 12834 sgd_solver.cpp:106] Iteration 80200, lr = 1.67772e-05
I0506 04:42:27.465087 12834 solver.cpp:242] Iteration 80200 (106.702 iter/s, 0.937186s/100 iter), loss = 0.773523
I0506 04:42:27.465113 12834 solver.cpp:261]     Train net output #0: loss = 0.773523 (* 1 = 0.773523 loss)
I0506 04:42:27.465122 12834 sgd_solver.cpp:106] Iteration 80200, lr = 1.67772e-05
I0506 04:42:28.397310 12834 solver.cpp:242] Iteration 80300 (106.723 iter/s, 0.937004s/100 iter), loss = 0.572342
I0506 04:42:28.397348 12834 solver.cpp:261]     Train net output #0: loss = 0.572342 (* 1 = 0.572342 loss)
I0506 04:42:28.397358 12834 sgd_solver.cpp:106] Iteration 80300, lr = 1.67772e-05
I0506 04:42:28.402068 12834 solver.cpp:242] Iteration 80300 (106.731 iter/s, 0.936936s/100 iter), loss = 0.545049
I0506 04:42:28.402094 12834 solver.cpp:261]     Train net output #0: loss = 0.545049 (* 1 = 0.545049 loss)
I0506 04:42:28.402103 12834 sgd_solver.cpp:106] Iteration 80300, lr = 1.67772e-05
I0506 04:42:29.334676 12834 solver.cpp:242] Iteration 80400 (106.69 iter/s, 0.937296s/100 iter), loss = 3.00042
I0506 04:42:29.334713 12834 solver.cpp:261]     Train net output #0: loss = 3.00042 (* 1 = 3.00042 loss)
I0506 04:42:29.334723 12834 sgd_solver.cpp:106] Iteration 80400, lr = 1.67772e-05
I0506 04:42:29.339447 12834 solver.cpp:242] Iteration 80400 (106.685 iter/s, 0.937335s/100 iter), loss = 0.502936
I0506 04:42:29.339483 12834 solver.cpp:261]     Train net output #0: loss = 0.502936 (* 1 = 0.502936 loss)
I0506 04:42:29.339493 12834 sgd_solver.cpp:106] Iteration 80400, lr = 1.67772e-05
I0506 04:42:30.279968 12834 solver.cpp:362] Iteration 80500, Testing net (#0)
I0506 04:42:30.279991 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:30.402684 12834 solver.cpp:429]     Test net output #0: loss = 1.32427 (* 1 = 1.32427 loss)
I0506 04:42:30.405208 12834 solver.cpp:242] Iteration 80500 (93.4164 iter/s, 1.07048s/100 iter), loss = 2.35287
I0506 04:42:30.405230 12834 solver.cpp:261]     Train net output #0: loss = 2.35287 (* 1 = 2.35287 loss)
I0506 04:42:30.405239 12834 sgd_solver.cpp:106] Iteration 80500, lr = 1.67772e-05
I0506 04:42:30.407057 12834 solver.cpp:362] Iteration 80500, Testing net (#0)
I0506 04:42:30.407068 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:30.535977 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7385
I0506 04:42:30.536000 12834 solver.cpp:429]     Test net output #1: loss = 0.598388 (* 1 = 0.598388 loss)
I0506 04:42:30.538884 12834 solver.cpp:242] Iteration 80500 (83.3764 iter/s, 1.19938s/100 iter), loss = 0.679333
I0506 04:42:30.538905 12834 solver.cpp:261]     Train net output #0: loss = 0.679333 (* 1 = 0.679333 loss)
I0506 04:42:30.538914 12834 sgd_solver.cpp:106] Iteration 80500, lr = 1.67772e-05
I0506 04:42:31.471297 12834 solver.cpp:242] Iteration 80600 (93.8058 iter/s, 1.06603s/100 iter), loss = 1.30821
I0506 04:42:31.471334 12834 solver.cpp:261]     Train net output #0: loss = 1.30821 (* 1 = 1.30821 loss)
I0506 04:42:31.471343 12834 sgd_solver.cpp:106] Iteration 80600, lr = 1.67772e-05
I0506 04:42:31.476068 12834 solver.cpp:242] Iteration 80600 (106.707 iter/s, 0.937144s/100 iter), loss = 0.774007
I0506 04:42:31.476091 12834 solver.cpp:261]     Train net output #0: loss = 0.774007 (* 1 = 0.774007 loss)
I0506 04:42:31.476100 12834 sgd_solver.cpp:106] Iteration 80600, lr = 1.67772e-05
I0506 04:42:32.408421 12834 solver.cpp:242] Iteration 80700 (106.716 iter/s, 0.937062s/100 iter), loss = 1.53149
I0506 04:42:32.408457 12834 solver.cpp:261]     Train net output #0: loss = 1.53149 (* 1 = 1.53149 loss)
I0506 04:42:32.408466 12834 sgd_solver.cpp:106] Iteration 80700, lr = 1.67772e-05
I0506 04:42:32.413177 12834 solver.cpp:242] Iteration 80700 (106.716 iter/s, 0.937066s/100 iter), loss = 0.407513
I0506 04:42:32.413202 12834 solver.cpp:261]     Train net output #0: loss = 0.407513 (* 1 = 0.407513 loss)
I0506 04:42:32.413210 12834 sgd_solver.cpp:106] Iteration 80700, lr = 1.67772e-05
I0506 04:42:33.345877 12834 solver.cpp:242] Iteration 80800 (106.679 iter/s, 0.937391s/100 iter), loss = 1.44942
I0506 04:42:33.345907 12834 solver.cpp:261]     Train net output #0: loss = 1.44942 (* 1 = 1.44942 loss)
I0506 04:42:33.345916 12834 sgd_solver.cpp:106] Iteration 80800, lr = 1.67772e-05
I0506 04:42:33.350633 12834 solver.cpp:242] Iteration 80800 (106.677 iter/s, 0.937413s/100 iter), loss = 0.592753
I0506 04:42:33.350656 12834 solver.cpp:261]     Train net output #0: loss = 0.592753 (* 1 = 0.592753 loss)
I0506 04:42:33.350664 12834 sgd_solver.cpp:106] Iteration 80800, lr = 1.67772e-05
I0506 04:42:34.283236 12834 solver.cpp:242] Iteration 80900 (106.689 iter/s, 0.937301s/100 iter), loss = 2.07262
I0506 04:42:34.283277 12834 solver.cpp:261]     Train net output #0: loss = 2.07262 (* 1 = 2.07262 loss)
I0506 04:42:34.283288 12834 sgd_solver.cpp:106] Iteration 80900, lr = 1.67772e-05
I0506 04:42:34.288094 12834 solver.cpp:242] Iteration 80900 (106.677 iter/s, 0.93741s/100 iter), loss = 0.878218
I0506 04:42:34.288121 12834 solver.cpp:261]     Train net output #0: loss = 0.878218 (* 1 = 0.878218 loss)
I0506 04:42:34.288130 12834 sgd_solver.cpp:106] Iteration 80900, lr = 1.67772e-05
I0506 04:42:35.284601 12834 solver.cpp:362] Iteration 81000, Testing net (#0)
I0506 04:42:35.284633 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:35.417803 12834 solver.cpp:429]     Test net output #0: loss = 1.43316 (* 1 = 1.43316 loss)
I0506 04:42:35.420465 12834 solver.cpp:242] Iteration 81000 (87.9378 iter/s, 1.13717s/100 iter), loss = 1.46979
I0506 04:42:35.420492 12834 solver.cpp:261]     Train net output #0: loss = 1.46979 (* 1 = 1.46979 loss)
I0506 04:42:35.420503 12834 sgd_solver.cpp:106] Iteration 81000, lr = 1.67772e-05
I0506 04:42:35.422693 12834 solver.cpp:362] Iteration 81000, Testing net (#0)
I0506 04:42:35.422708 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:35.563634 12834 solver.cpp:429]     Test net output #0: accuracy = 0.751
I0506 04:42:35.563658 12834 solver.cpp:429]     Test net output #1: loss = 0.571503 (* 1 = 0.571503 loss)
I0506 04:42:35.566332 12834 solver.cpp:242] Iteration 81000 (78.2357 iter/s, 1.27819s/100 iter), loss = 0.385792
I0506 04:42:35.566354 12834 solver.cpp:261]     Train net output #0: loss = 0.385792 (* 1 = 0.385792 loss)
I0506 04:42:35.566362 12834 sgd_solver.cpp:106] Iteration 81000, lr = 1.67772e-05
I0506 04:42:36.498913 12834 solver.cpp:242] Iteration 81100 (92.7306 iter/s, 1.07839s/100 iter), loss = 0.643989
I0506 04:42:36.498955 12834 solver.cpp:261]     Train net output #0: loss = 0.643989 (* 1 = 0.643989 loss)
I0506 04:42:36.498963 12834 sgd_solver.cpp:106] Iteration 81100, lr = 1.67772e-05
I0506 04:42:36.503756 12834 solver.cpp:242] Iteration 81100 (106.681 iter/s, 0.937375s/100 iter), loss = 0.5889
I0506 04:42:36.503782 12834 solver.cpp:261]     Train net output #0: loss = 0.5889 (* 1 = 0.5889 loss)
I0506 04:42:36.503790 12834 sgd_solver.cpp:106] Iteration 81100, lr = 1.67772e-05
I0506 04:42:37.436269 12834 solver.cpp:242] Iteration 81200 (106.691 iter/s, 0.937287s/100 iter), loss = 2.19029
I0506 04:42:37.436311 12834 solver.cpp:261]     Train net output #0: loss = 2.19029 (* 1 = 2.19029 loss)
I0506 04:42:37.436319 12834 sgd_solver.cpp:106] Iteration 81200, lr = 1.67772e-05
I0506 04:42:37.441031 12834 solver.cpp:242] Iteration 81200 (106.697 iter/s, 0.937232s/100 iter), loss = 1.27486
I0506 04:42:37.441056 12834 solver.cpp:261]     Train net output #0: loss = 1.27486 (* 1 = 1.27486 loss)
I0506 04:42:37.441064 12834 sgd_solver.cpp:106] Iteration 81200, lr = 1.67772e-05
I0506 04:42:38.381323 12834 solver.cpp:242] Iteration 81300 (105.823 iter/s, 0.944977s/100 iter), loss = 2.07796
I0506 04:42:38.381373 12834 solver.cpp:261]     Train net output #0: loss = 2.07796 (* 1 = 2.07796 loss)
I0506 04:42:38.381386 12834 sgd_solver.cpp:106] Iteration 81300, lr = 1.67772e-05
I0506 04:42:38.386600 12834 solver.cpp:242] Iteration 81300 (105.761 iter/s, 0.945524s/100 iter), loss = 0.712574
I0506 04:42:38.386627 12834 solver.cpp:261]     Train net output #0: loss = 0.712574 (* 1 = 0.712574 loss)
I0506 04:42:38.386638 12834 sgd_solver.cpp:106] Iteration 81300, lr = 1.67772e-05
I0506 04:42:39.350903 12834 solver.cpp:242] Iteration 81400 (103.146 iter/s, 0.969502s/100 iter), loss = 1.18848
I0506 04:42:39.350942 12834 solver.cpp:261]     Train net output #0: loss = 1.18848 (* 1 = 1.18848 loss)
I0506 04:42:39.350951 12834 sgd_solver.cpp:106] Iteration 81400, lr = 1.67772e-05
I0506 04:42:39.355690 12834 solver.cpp:242] Iteration 81400 (103.194 iter/s, 0.969045s/100 iter), loss = 0.47297
I0506 04:42:39.355715 12834 solver.cpp:261]     Train net output #0: loss = 0.47297 (* 1 = 0.47297 loss)
I0506 04:42:39.355725 12834 sgd_solver.cpp:106] Iteration 81400, lr = 1.67772e-05
I0506 04:42:40.285775 12834 solver.cpp:362] Iteration 81500, Testing net (#0)
I0506 04:42:40.285799 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:40.408457 12834 solver.cpp:429]     Test net output #0: loss = 1.39371 (* 1 = 1.39371 loss)
I0506 04:42:40.410974 12834 solver.cpp:242] Iteration 81500 (94.3385 iter/s, 1.06001s/100 iter), loss = 1.19694
I0506 04:42:40.410993 12834 solver.cpp:261]     Train net output #0: loss = 1.19694 (* 1 = 1.19694 loss)
I0506 04:42:40.411002 12834 sgd_solver.cpp:106] Iteration 81500, lr = 1.67772e-05
I0506 04:42:40.412833 12834 solver.cpp:362] Iteration 81500, Testing net (#0)
I0506 04:42:40.412847 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:40.541679 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7495
I0506 04:42:40.541708 12834 solver.cpp:429]     Test net output #1: loss = 0.585547 (* 1 = 0.585547 loss)
I0506 04:42:40.544261 12834 solver.cpp:242] Iteration 81500 (84.1378 iter/s, 1.18853s/100 iter), loss = 0.889455
I0506 04:42:40.544281 12834 solver.cpp:261]     Train net output #0: loss = 0.889455 (* 1 = 0.889455 loss)
I0506 04:42:40.544289 12834 sgd_solver.cpp:106] Iteration 81500, lr = 1.67772e-05
I0506 04:42:41.476663 12834 solver.cpp:242] Iteration 81600 (93.8402 iter/s, 1.06564s/100 iter), loss = 0.77156
I0506 04:42:41.476703 12834 solver.cpp:261]     Train net output #0: loss = 0.77156 (* 1 = 0.77156 loss)
I0506 04:42:41.476713 12834 sgd_solver.cpp:106] Iteration 81600, lr = 1.67772e-05
I0506 04:42:41.481433 12834 solver.cpp:242] Iteration 81600 (106.708 iter/s, 0.937133s/100 iter), loss = 0.689837
I0506 04:42:41.481457 12834 solver.cpp:261]     Train net output #0: loss = 0.689837 (* 1 = 0.689837 loss)
I0506 04:42:41.481467 12834 sgd_solver.cpp:106] Iteration 81600, lr = 1.67772e-05
I0506 04:42:42.413934 12834 solver.cpp:242] Iteration 81700 (106.701 iter/s, 0.9372s/100 iter), loss = 0.546348
I0506 04:42:42.413974 12834 solver.cpp:261]     Train net output #0: loss = 0.546348 (* 1 = 0.546348 loss)
I0506 04:42:42.413982 12834 sgd_solver.cpp:106] Iteration 81700, lr = 1.67772e-05
I0506 04:42:42.418701 12834 solver.cpp:242] Iteration 81700 (106.698 iter/s, 0.937225s/100 iter), loss = 0.557285
I0506 04:42:42.418726 12834 solver.cpp:261]     Train net output #0: loss = 0.557285 (* 1 = 0.557285 loss)
I0506 04:42:42.418736 12834 sgd_solver.cpp:106] Iteration 81700, lr = 1.67772e-05
I0506 04:42:43.350915 12834 solver.cpp:242] Iteration 81800 (106.733 iter/s, 0.936918s/100 iter), loss = 2.60039
I0506 04:42:43.350955 12834 solver.cpp:261]     Train net output #0: loss = 2.60039 (* 1 = 2.60039 loss)
I0506 04:42:43.350963 12834 sgd_solver.cpp:106] Iteration 81800, lr = 1.67772e-05
I0506 04:42:43.355696 12834 solver.cpp:242] Iteration 81800 (106.729 iter/s, 0.936952s/100 iter), loss = 0.558532
I0506 04:42:43.355721 12834 solver.cpp:261]     Train net output #0: loss = 0.558532 (* 1 = 0.558532 loss)
I0506 04:42:43.355731 12834 sgd_solver.cpp:106] Iteration 81800, lr = 1.67772e-05
I0506 04:42:44.289072 12834 solver.cpp:242] Iteration 81900 (106.6 iter/s, 0.938087s/100 iter), loss = 1.31937
I0506 04:42:44.289103 12834 solver.cpp:261]     Train net output #0: loss = 1.31937 (* 1 = 1.31937 loss)
I0506 04:42:44.289113 12834 sgd_solver.cpp:106] Iteration 81900, lr = 1.67772e-05
I0506 04:42:44.293845 12834 solver.cpp:242] Iteration 81900 (106.598 iter/s, 0.938105s/100 iter), loss = 0.887282
I0506 04:42:44.293870 12834 solver.cpp:261]     Train net output #0: loss = 0.887282 (* 1 = 0.887282 loss)
I0506 04:42:44.293879 12834 sgd_solver.cpp:106] Iteration 81900, lr = 1.67772e-05
I0506 04:42:45.236340 12834 solver.cpp:362] Iteration 82000, Testing net (#0)
I0506 04:42:45.236367 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:45.359001 12834 solver.cpp:429]     Test net output #0: loss = 1.26569 (* 1 = 1.26569 loss)
I0506 04:42:45.361519 12834 solver.cpp:242] Iteration 82000 (93.2492 iter/s, 1.0724s/100 iter), loss = 1.52675
I0506 04:42:45.361539 12834 solver.cpp:261]     Train net output #0: loss = 1.52675 (* 1 = 1.52675 loss)
I0506 04:42:45.361548 12834 sgd_solver.cpp:106] Iteration 82000, lr = 1.67772e-05
I0506 04:42:45.363457 12834 solver.cpp:362] Iteration 82000, Testing net (#0)
I0506 04:42:45.363471 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:45.492476 12834 solver.cpp:429]     Test net output #0: accuracy = 0.768
I0506 04:42:45.492497 12834 solver.cpp:429]     Test net output #1: loss = 0.548517 (* 1 = 0.548517 loss)
I0506 04:42:45.495071 12834 solver.cpp:242] Iteration 82000 (83.2515 iter/s, 1.20118s/100 iter), loss = 0.520544
I0506 04:42:45.495092 12834 solver.cpp:261]     Train net output #0: loss = 0.520544 (* 1 = 0.520544 loss)
I0506 04:42:45.495101 12834 sgd_solver.cpp:106] Iteration 82000, lr = 1.67772e-05
I0506 04:42:46.428038 12834 solver.cpp:242] Iteration 82100 (93.7674 iter/s, 1.06647s/100 iter), loss = 1.67302
I0506 04:42:46.428076 12834 solver.cpp:261]     Train net output #0: loss = 1.67302 (* 1 = 1.67302 loss)
I0506 04:42:46.428086 12834 sgd_solver.cpp:106] Iteration 82100, lr = 1.67772e-05
I0506 04:42:46.432924 12834 solver.cpp:242] Iteration 82100 (106.631 iter/s, 0.937812s/100 iter), loss = 0.552879
I0506 04:42:46.432947 12834 solver.cpp:261]     Train net output #0: loss = 0.552879 (* 1 = 0.552879 loss)
I0506 04:42:46.432956 12834 sgd_solver.cpp:106] Iteration 82100, lr = 1.67772e-05
I0506 04:42:47.366055 12834 solver.cpp:242] Iteration 82200 (106.616 iter/s, 0.937948s/100 iter), loss = 0.86298
I0506 04:42:47.366086 12834 solver.cpp:261]     Train net output #0: loss = 0.86298 (* 1 = 0.86298 loss)
I0506 04:42:47.366096 12834 sgd_solver.cpp:106] Iteration 82200, lr = 1.67772e-05
I0506 04:42:47.370808 12834 solver.cpp:242] Iteration 82200 (106.628 iter/s, 0.937842s/100 iter), loss = 0.485585
I0506 04:42:47.370832 12834 solver.cpp:261]     Train net output #0: loss = 0.485585 (* 1 = 0.485585 loss)
I0506 04:42:47.370841 12834 sgd_solver.cpp:106] Iteration 82200, lr = 1.67772e-05
I0506 04:42:48.303148 12834 solver.cpp:242] Iteration 82300 (106.72 iter/s, 0.937034s/100 iter), loss = 3.74031
I0506 04:42:48.303189 12834 solver.cpp:261]     Train net output #0: loss = 3.74031 (* 1 = 3.74031 loss)
I0506 04:42:48.303198 12834 sgd_solver.cpp:106] Iteration 82300, lr = 1.67772e-05
I0506 04:42:48.307926 12834 solver.cpp:242] Iteration 82300 (106.715 iter/s, 0.937076s/100 iter), loss = 0.458099
I0506 04:42:48.307952 12834 solver.cpp:261]     Train net output #0: loss = 0.458099 (* 1 = 0.458099 loss)
I0506 04:42:48.307961 12834 sgd_solver.cpp:106] Iteration 82300, lr = 1.67772e-05
I0506 04:42:49.240836 12834 solver.cpp:242] Iteration 82400 (106.654 iter/s, 0.937613s/100 iter), loss = 1.29852
I0506 04:42:49.240878 12834 solver.cpp:261]     Train net output #0: loss = 1.29852 (* 1 = 1.29852 loss)
I0506 04:42:49.240887 12834 sgd_solver.cpp:106] Iteration 82400, lr = 1.67772e-05
I0506 04:42:49.245627 12834 solver.cpp:242] Iteration 82400 (106.649 iter/s, 0.937656s/100 iter), loss = 0.536634
I0506 04:42:49.245651 12834 solver.cpp:261]     Train net output #0: loss = 0.536634 (* 1 = 0.536634 loss)
I0506 04:42:49.245661 12834 sgd_solver.cpp:106] Iteration 82400, lr = 1.67772e-05
I0506 04:42:50.186434 12834 solver.cpp:362] Iteration 82500, Testing net (#0)
I0506 04:42:50.186461 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:50.308979 12834 solver.cpp:429]     Test net output #0: loss = 1.35873 (* 1 = 1.35873 loss)
I0506 04:42:50.311496 12834 solver.cpp:242] Iteration 82500 (93.4057 iter/s, 1.0706s/100 iter), loss = 1.99823
I0506 04:42:50.311518 12834 solver.cpp:261]     Train net output #0: loss = 1.99823 (* 1 = 1.99823 loss)
I0506 04:42:50.311527 12834 sgd_solver.cpp:106] Iteration 82500, lr = 1.67772e-05
I0506 04:42:50.313344 12834 solver.cpp:362] Iteration 82500, Testing net (#0)
I0506 04:42:50.313357 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:50.442083 12834 solver.cpp:429]     Test net output #0: accuracy = 0.755
I0506 04:42:50.442102 12834 solver.cpp:429]     Test net output #1: loss = 0.571797 (* 1 = 0.571797 loss)
I0506 04:42:50.444651 12834 solver.cpp:242] Iteration 82500 (83.4042 iter/s, 1.19898s/100 iter), loss = 0.540456
I0506 04:42:50.444672 12834 solver.cpp:261]     Train net output #0: loss = 0.540456 (* 1 = 0.540456 loss)
I0506 04:42:50.444681 12834 sgd_solver.cpp:106] Iteration 82500, lr = 1.67772e-05
I0506 04:42:51.378412 12834 solver.cpp:242] Iteration 82600 (93.7331 iter/s, 1.06686s/100 iter), loss = 0.693569
I0506 04:42:51.378455 12834 solver.cpp:261]     Train net output #0: loss = 0.693569 (* 1 = 0.693569 loss)
I0506 04:42:51.378465 12834 sgd_solver.cpp:106] Iteration 82600, lr = 1.67772e-05
I0506 04:42:51.383219 12834 solver.cpp:242] Iteration 82600 (106.55 iter/s, 0.938529s/100 iter), loss = 0.657485
I0506 04:42:51.383244 12834 solver.cpp:261]     Train net output #0: loss = 0.657485 (* 1 = 0.657485 loss)
I0506 04:42:51.383261 12834 sgd_solver.cpp:106] Iteration 82600, lr = 1.67772e-05
I0506 04:42:52.315508 12834 solver.cpp:242] Iteration 82700 (106.72 iter/s, 0.93703s/100 iter), loss = 2.83294
I0506 04:42:52.315547 12834 solver.cpp:261]     Train net output #0: loss = 2.83294 (* 1 = 2.83294 loss)
I0506 04:42:52.315557 12834 sgd_solver.cpp:106] Iteration 82700, lr = 1.67772e-05
I0506 04:42:52.320286 12834 solver.cpp:242] Iteration 82700 (106.721 iter/s, 0.937024s/100 iter), loss = 0.952761
I0506 04:42:52.320309 12834 solver.cpp:261]     Train net output #0: loss = 0.952761 (* 1 = 0.952761 loss)
I0506 04:42:52.320318 12834 sgd_solver.cpp:106] Iteration 82700, lr = 1.67772e-05
I0506 04:42:53.323635 12834 solver.cpp:242] Iteration 82800 (99.2011 iter/s, 1.00805s/100 iter), loss = 1.10449
I0506 04:42:53.323681 12834 solver.cpp:261]     Train net output #0: loss = 1.10449 (* 1 = 1.10449 loss)
I0506 04:42:53.323693 12834 sgd_solver.cpp:106] Iteration 82800, lr = 1.67772e-05
I0506 04:42:53.328908 12834 solver.cpp:242] Iteration 82800 (99.1494 iter/s, 1.00858s/100 iter), loss = 0.664305
I0506 04:42:53.328938 12834 solver.cpp:261]     Train net output #0: loss = 0.664305 (* 1 = 0.664305 loss)
I0506 04:42:53.328949 12834 sgd_solver.cpp:106] Iteration 82800, lr = 1.67772e-05
I0506 04:42:54.296149 12834 solver.cpp:242] Iteration 82900 (102.834 iter/s, 0.972444s/100 iter), loss = 0.719165
I0506 04:42:54.296187 12834 solver.cpp:261]     Train net output #0: loss = 0.719165 (* 1 = 0.719165 loss)
I0506 04:42:54.296196 12834 sgd_solver.cpp:106] Iteration 82900, lr = 1.67772e-05
I0506 04:42:54.300988 12834 solver.cpp:242] Iteration 82900 (102.878 iter/s, 0.972023s/100 iter), loss = 0.595949
I0506 04:42:54.301012 12834 solver.cpp:261]     Train net output #0: loss = 0.595949 (* 1 = 0.595949 loss)
I0506 04:42:54.301021 12834 sgd_solver.cpp:106] Iteration 82900, lr = 1.67772e-05
I0506 04:42:55.230671 12834 solver.cpp:362] Iteration 83000, Testing net (#0)
I0506 04:42:55.230695 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:55.353313 12834 solver.cpp:429]     Test net output #0: loss = 1.59036 (* 1 = 1.59036 loss)
I0506 04:42:55.355828 12834 solver.cpp:242] Iteration 83000 (94.3734 iter/s, 1.05962s/100 iter), loss = 1.88227
I0506 04:42:55.355849 12834 solver.cpp:261]     Train net output #0: loss = 1.88227 (* 1 = 1.88227 loss)
I0506 04:42:55.355857 12834 sgd_solver.cpp:106] Iteration 83000, lr = 1.67772e-05
I0506 04:42:55.357692 12834 solver.cpp:362] Iteration 83000, Testing net (#0)
I0506 04:42:55.357704 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:42:55.486896 12834 solver.cpp:429]     Test net output #0: accuracy = 0.74
I0506 04:42:55.486914 12834 solver.cpp:429]     Test net output #1: loss = 0.608695 (* 1 = 0.608695 loss)
I0506 04:42:55.489476 12834 solver.cpp:242] Iteration 83000 (84.1438 iter/s, 1.18844s/100 iter), loss = 0.969634
I0506 04:42:55.489498 12834 solver.cpp:261]     Train net output #0: loss = 0.969634 (* 1 = 0.969634 loss)
I0506 04:42:55.489507 12834 sgd_solver.cpp:106] Iteration 83000, lr = 1.67772e-05
I0506 04:42:56.510913 12834 solver.cpp:242] Iteration 83100 (86.5781 iter/s, 1.15503s/100 iter), loss = 1.30869
I0506 04:42:56.510962 12834 solver.cpp:261]     Train net output #0: loss = 1.30869 (* 1 = 1.30869 loss)
I0506 04:42:56.511118 12834 sgd_solver.cpp:106] Iteration 83100, lr = 1.67772e-05
I0506 04:42:56.515913 12834 solver.cpp:242] Iteration 83100 (97.4283 iter/s, 1.0264s/100 iter), loss = 0.729234
I0506 04:42:56.515939 12834 solver.cpp:261]     Train net output #0: loss = 0.729234 (* 1 = 0.729234 loss)
I0506 04:42:56.515949 12834 sgd_solver.cpp:106] Iteration 83100, lr = 1.67772e-05
I0506 04:42:57.448457 12834 solver.cpp:242] Iteration 83200 (106.67 iter/s, 0.937471s/100 iter), loss = 1.40945
I0506 04:42:57.448494 12834 solver.cpp:261]     Train net output #0: loss = 1.40945 (* 1 = 1.40945 loss)
I0506 04:42:57.448504 12834 sgd_solver.cpp:106] Iteration 83200, lr = 1.67772e-05
I0506 04:42:57.453253 12834 solver.cpp:242] Iteration 83200 (106.69 iter/s, 0.937295s/100 iter), loss = 0.985333
I0506 04:42:57.453289 12834 solver.cpp:261]     Train net output #0: loss = 0.985333 (* 1 = 0.985333 loss)
I0506 04:42:57.453299 12834 sgd_solver.cpp:106] Iteration 83200, lr = 1.67772e-05
I0506 04:42:58.385677 12834 solver.cpp:242] Iteration 83300 (106.706 iter/s, 0.93715s/100 iter), loss = 1.44351
I0506 04:42:58.385715 12834 solver.cpp:261]     Train net output #0: loss = 1.44351 (* 1 = 1.44351 loss)
I0506 04:42:58.385725 12834 sgd_solver.cpp:106] Iteration 83300, lr = 1.67772e-05
I0506 04:42:58.390455 12834 solver.cpp:242] Iteration 83300 (106.707 iter/s, 0.937148s/100 iter), loss = 0.603897
I0506 04:42:58.390478 12834 solver.cpp:261]     Train net output #0: loss = 0.603897 (* 1 = 0.603897 loss)
I0506 04:42:58.390487 12834 sgd_solver.cpp:106] Iteration 83300, lr = 1.67772e-05
I0506 04:42:59.400768 12834 solver.cpp:242] Iteration 83400 (98.5198 iter/s, 1.01502s/100 iter), loss = 1.66203
I0506 04:42:59.400810 12834 solver.cpp:261]     Train net output #0: loss = 1.66203 (* 1 = 1.66203 loss)
I0506 04:42:59.400821 12834 sgd_solver.cpp:106] Iteration 83400, lr = 1.67772e-05
I0506 04:42:59.406085 12834 solver.cpp:242] Iteration 83400 (98.4652 iter/s, 1.01559s/100 iter), loss = 0.482865
I0506 04:42:59.406114 12834 solver.cpp:261]     Train net output #0: loss = 0.482865 (* 1 = 0.482865 loss)
I0506 04:42:59.406126 12834 sgd_solver.cpp:106] Iteration 83400, lr = 1.67772e-05
I0506 04:43:00.439810 12834 solver.cpp:362] Iteration 83500, Testing net (#0)
I0506 04:43:00.439836 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:00.574129 12834 solver.cpp:429]     Test net output #0: loss = 1.36019 (* 1 = 1.36019 loss)
I0506 04:43:00.576797 12834 solver.cpp:242] Iteration 83500 (85.0365 iter/s, 1.17597s/100 iter), loss = 0.756142
I0506 04:43:00.576824 12834 solver.cpp:261]     Train net output #0: loss = 0.756142 (* 1 = 0.756142 loss)
I0506 04:43:00.576835 12834 sgd_solver.cpp:106] Iteration 83500, lr = 1.67772e-05
I0506 04:43:00.579053 12834 solver.cpp:362] Iteration 83500, Testing net (#0)
I0506 04:43:00.579067 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:00.720923 12834 solver.cpp:429]     Test net output #0: accuracy = 0.766
I0506 04:43:00.720947 12834 solver.cpp:429]     Test net output #1: loss = 0.570853 (* 1 = 0.570853 loss)
I0506 04:43:00.723662 12834 solver.cpp:242] Iteration 83500 (75.8999 iter/s, 1.31752s/100 iter), loss = 0.402165
I0506 04:43:00.723687 12834 solver.cpp:261]     Train net output #0: loss = 0.402165 (* 1 = 0.402165 loss)
I0506 04:43:00.723697 12834 sgd_solver.cpp:106] Iteration 83500, lr = 1.67772e-05
I0506 04:43:01.753206 12834 solver.cpp:242] Iteration 83600 (85.0084 iter/s, 1.17635s/100 iter), loss = 0.393795
I0506 04:43:01.753248 12834 solver.cpp:261]     Train net output #0: loss = 0.393795 (* 1 = 0.393795 loss)
I0506 04:43:01.753602 12834 sgd_solver.cpp:106] Iteration 83600, lr = 1.67772e-05
I0506 04:43:01.758421 12834 solver.cpp:242] Iteration 83600 (96.645 iter/s, 1.03472s/100 iter), loss = 0.621629
I0506 04:43:01.758446 12834 solver.cpp:261]     Train net output #0: loss = 0.621629 (* 1 = 0.621629 loss)
I0506 04:43:01.758455 12834 sgd_solver.cpp:106] Iteration 83600, lr = 1.67772e-05
I0506 04:43:02.691898 12834 solver.cpp:242] Iteration 83700 (106.539 iter/s, 0.938622s/100 iter), loss = 1.31451
I0506 04:43:02.691936 12834 solver.cpp:261]     Train net output #0: loss = 1.31451 (* 1 = 1.31451 loss)
I0506 04:43:02.691944 12834 sgd_solver.cpp:106] Iteration 83700, lr = 1.67772e-05
I0506 04:43:02.696663 12834 solver.cpp:242] Iteration 83700 (106.587 iter/s, 0.938198s/100 iter), loss = 0.771963
I0506 04:43:02.696688 12834 solver.cpp:261]     Train net output #0: loss = 0.771963 (* 1 = 0.771963 loss)
I0506 04:43:02.696697 12834 sgd_solver.cpp:106] Iteration 83700, lr = 1.67772e-05
I0506 04:43:03.629297 12834 solver.cpp:242] Iteration 83800 (106.685 iter/s, 0.937337s/100 iter), loss = 3.81193
I0506 04:43:03.629330 12834 solver.cpp:261]     Train net output #0: loss = 3.81193 (* 1 = 3.81193 loss)
I0506 04:43:03.629340 12834 sgd_solver.cpp:106] Iteration 83800, lr = 1.67772e-05
I0506 04:43:03.634142 12834 solver.cpp:242] Iteration 83800 (106.675 iter/s, 0.937426s/100 iter), loss = 0.764789
I0506 04:43:03.634166 12834 solver.cpp:261]     Train net output #0: loss = 0.764789 (* 1 = 0.764789 loss)
I0506 04:43:03.634176 12834 sgd_solver.cpp:106] Iteration 83800, lr = 1.67772e-05
I0506 04:43:04.566463 12834 solver.cpp:242] Iteration 83900 (106.711 iter/s, 0.937106s/100 iter), loss = 1.83942
I0506 04:43:04.566493 12834 solver.cpp:261]     Train net output #0: loss = 1.83942 (* 1 = 1.83942 loss)
I0506 04:43:04.566503 12834 sgd_solver.cpp:106] Iteration 83900, lr = 1.67772e-05
I0506 04:43:04.571225 12834 solver.cpp:242] Iteration 83900 (106.719 iter/s, 0.937041s/100 iter), loss = 0.739902
I0506 04:43:04.571249 12834 solver.cpp:261]     Train net output #0: loss = 0.739902 (* 1 = 0.739902 loss)
I0506 04:43:04.571259 12834 sgd_solver.cpp:106] Iteration 83900, lr = 1.67772e-05
I0506 04:43:05.500761 12834 solver.cpp:362] Iteration 84000, Testing net (#0)
I0506 04:43:05.500789 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:05.623412 12834 solver.cpp:429]     Test net output #0: loss = 1.40677 (* 1 = 1.40677 loss)
I0506 04:43:05.625931 12834 solver.cpp:242] Iteration 84000 (94.3914 iter/s, 1.05942s/100 iter), loss = 0.821905
I0506 04:43:05.625952 12834 solver.cpp:261]     Train net output #0: loss = 0.821905 (* 1 = 0.821905 loss)
I0506 04:43:05.625962 12834 sgd_solver.cpp:106] Iteration 84000, lr = 1.67772e-05
I0506 04:43:05.627779 12834 solver.cpp:362] Iteration 84000, Testing net (#0)
I0506 04:43:05.627790 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:05.756515 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7575
I0506 04:43:05.756532 12834 solver.cpp:429]     Test net output #1: loss = 0.573082 (* 1 = 0.573082 loss)
I0506 04:43:05.759086 12834 solver.cpp:242] Iteration 84000 (84.1881 iter/s, 1.18782s/100 iter), loss = 0.155628
I0506 04:43:05.759106 12834 solver.cpp:261]     Train net output #0: loss = 0.155628 (* 1 = 0.155628 loss)
I0506 04:43:05.759115 12834 sgd_solver.cpp:106] Iteration 84000, lr = 1.67772e-05
I0506 04:43:06.704356 12834 solver.cpp:242] Iteration 84100 (92.7324 iter/s, 1.07837s/100 iter), loss = 1.28083
I0506 04:43:06.704406 12834 solver.cpp:261]     Train net output #0: loss = 1.28083 (* 1 = 1.28083 loss)
I0506 04:43:06.704418 12834 sgd_solver.cpp:106] Iteration 84100, lr = 1.67772e-05
I0506 04:43:06.709641 12834 solver.cpp:242] Iteration 84100 (105.206 iter/s, 0.950514s/100 iter), loss = 0.545939
I0506 04:43:06.709671 12834 solver.cpp:261]     Train net output #0: loss = 0.545939 (* 1 = 0.545939 loss)
I0506 04:43:06.709682 12834 sgd_solver.cpp:106] Iteration 84100, lr = 1.67772e-05
I0506 04:43:07.663100 12834 solver.cpp:242] Iteration 84200 (104.313 iter/s, 0.958658s/100 iter), loss = 0.68313
I0506 04:43:07.663151 12834 solver.cpp:261]     Train net output #0: loss = 0.68313 (* 1 = 0.68313 loss)
I0506 04:43:07.663162 12834 sgd_solver.cpp:106] Iteration 84200, lr = 1.67772e-05
I0506 04:43:07.668406 12834 solver.cpp:242] Iteration 84200 (104.306 iter/s, 0.958717s/100 iter), loss = 0.376842
I0506 04:43:07.668437 12834 solver.cpp:261]     Train net output #0: loss = 0.376842 (* 1 = 0.376842 loss)
I0506 04:43:07.668448 12834 sgd_solver.cpp:106] Iteration 84200, lr = 1.67772e-05
I0506 04:43:08.672013 12834 solver.cpp:242] Iteration 84300 (99.124 iter/s, 1.00884s/100 iter), loss = 1.49499
I0506 04:43:08.672055 12834 solver.cpp:261]     Train net output #0: loss = 1.49499 (* 1 = 1.49499 loss)
I0506 04:43:08.672065 12834 sgd_solver.cpp:106] Iteration 84300, lr = 1.67772e-05
I0506 04:43:08.676782 12834 solver.cpp:242] Iteration 84300 (99.1742 iter/s, 1.00833s/100 iter), loss = 0.652743
I0506 04:43:08.676808 12834 solver.cpp:261]     Train net output #0: loss = 0.652743 (* 1 = 0.652743 loss)
I0506 04:43:08.676817 12834 sgd_solver.cpp:106] Iteration 84300, lr = 1.67772e-05
I0506 04:43:09.609246 12834 solver.cpp:242] Iteration 84400 (106.705 iter/s, 0.93716s/100 iter), loss = 0.617982
I0506 04:43:09.609287 12834 solver.cpp:261]     Train net output #0: loss = 0.617982 (* 1 = 0.617982 loss)
I0506 04:43:09.609305 12834 sgd_solver.cpp:106] Iteration 84400, lr = 1.67772e-05
I0506 04:43:09.614054 12834 solver.cpp:242] Iteration 84400 (106.697 iter/s, 0.937229s/100 iter), loss = 0.494904
I0506 04:43:09.614078 12834 solver.cpp:261]     Train net output #0: loss = 0.494904 (* 1 = 0.494904 loss)
I0506 04:43:09.614087 12834 sgd_solver.cpp:106] Iteration 84400, lr = 1.67772e-05
I0506 04:43:10.544159 12834 solver.cpp:362] Iteration 84500, Testing net (#0)
I0506 04:43:10.544186 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:10.674437 12834 solver.cpp:429]     Test net output #0: loss = 1.46481 (* 1 = 1.46481 loss)
I0506 04:43:10.677081 12834 solver.cpp:242] Iteration 84500 (93.6527 iter/s, 1.06778s/100 iter), loss = 1.41234
I0506 04:43:10.677106 12834 solver.cpp:261]     Train net output #0: loss = 1.41234 (* 1 = 1.41234 loss)
I0506 04:43:10.677117 12834 sgd_solver.cpp:106] Iteration 84500, lr = 1.67772e-05
I0506 04:43:10.679293 12834 solver.cpp:362] Iteration 84500, Testing net (#0)
I0506 04:43:10.679307 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:10.820019 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7545
I0506 04:43:10.820042 12834 solver.cpp:429]     Test net output #1: loss = 0.583254 (* 1 = 0.583254 loss)
I0506 04:43:10.822742 12834 solver.cpp:242] Iteration 84500 (82.7375 iter/s, 1.20864s/100 iter), loss = 0.733838
I0506 04:43:10.822767 12834 solver.cpp:261]     Train net output #0: loss = 0.733838 (* 1 = 0.733838 loss)
I0506 04:43:10.822777 12834 sgd_solver.cpp:106] Iteration 84500, lr = 1.67772e-05
I0506 04:43:11.852982 12834 solver.cpp:242] Iteration 84600 (85.0457 iter/s, 1.17584s/100 iter), loss = 1.66981
I0506 04:43:11.853034 12834 solver.cpp:261]     Train net output #0: loss = 1.66981 (* 1 = 1.66981 loss)
I0506 04:43:11.853346 12834 sgd_solver.cpp:106] Iteration 84600, lr = 1.67772e-05
I0506 04:43:11.858136 12834 solver.cpp:242] Iteration 84600 (96.5856 iter/s, 1.03535s/100 iter), loss = 0.841788
I0506 04:43:11.858161 12834 solver.cpp:261]     Train net output #0: loss = 0.841788 (* 1 = 0.841788 loss)
I0506 04:43:11.858170 12834 sgd_solver.cpp:106] Iteration 84600, lr = 1.67772e-05
I0506 04:43:12.791249 12834 solver.cpp:242] Iteration 84700 (106.588 iter/s, 0.938193s/100 iter), loss = 2.91357
I0506 04:43:12.791285 12834 solver.cpp:261]     Train net output #0: loss = 2.91357 (* 1 = 2.91357 loss)
I0506 04:43:12.791295 12834 sgd_solver.cpp:106] Iteration 84700, lr = 1.67772e-05
I0506 04:43:12.796109 12834 solver.cpp:242] Iteration 84700 (106.619 iter/s, 0.937919s/100 iter), loss = 0.710288
I0506 04:43:12.796135 12834 solver.cpp:261]     Train net output #0: loss = 0.710288 (* 1 = 0.710288 loss)
I0506 04:43:12.796144 12834 sgd_solver.cpp:106] Iteration 84700, lr = 1.67772e-05
I0506 04:43:13.728888 12834 solver.cpp:242] Iteration 84800 (106.658 iter/s, 0.937576s/100 iter), loss = 2.47493
I0506 04:43:13.728927 12834 solver.cpp:261]     Train net output #0: loss = 2.47493 (* 1 = 2.47493 loss)
I0506 04:43:13.728936 12834 sgd_solver.cpp:106] Iteration 84800, lr = 1.67772e-05
I0506 04:43:13.733680 12834 solver.cpp:242] Iteration 84800 (106.664 iter/s, 0.937525s/100 iter), loss = 0.885484
I0506 04:43:13.733702 12834 solver.cpp:261]     Train net output #0: loss = 0.885484 (* 1 = 0.885484 loss)
I0506 04:43:13.733712 12834 sgd_solver.cpp:106] Iteration 84800, lr = 1.67772e-05
I0506 04:43:14.666393 12834 solver.cpp:242] Iteration 84900 (106.673 iter/s, 0.937443s/100 iter), loss = 0.404605
I0506 04:43:14.666431 12834 solver.cpp:261]     Train net output #0: loss = 0.404605 (* 1 = 0.404605 loss)
I0506 04:43:14.666441 12834 sgd_solver.cpp:106] Iteration 84900, lr = 1.67772e-05
I0506 04:43:14.671252 12834 solver.cpp:242] Iteration 84900 (106.664 iter/s, 0.937521s/100 iter), loss = 0.705517
I0506 04:43:14.671277 12834 solver.cpp:261]     Train net output #0: loss = 0.705517 (* 1 = 0.705517 loss)
I0506 04:43:14.671286 12834 sgd_solver.cpp:106] Iteration 84900, lr = 1.67772e-05
I0506 04:43:15.601194 12834 solver.cpp:362] Iteration 85000, Testing net (#0)
I0506 04:43:15.601228 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:15.723827 12834 solver.cpp:429]     Test net output #0: loss = 1.38943 (* 1 = 1.38943 loss)
I0506 04:43:15.726352 12834 solver.cpp:242] Iteration 85000 (94.3484 iter/s, 1.0599s/100 iter), loss = 1.05721
I0506 04:43:15.726373 12834 solver.cpp:261]     Train net output #0: loss = 1.05721 (* 1 = 1.05721 loss)
I0506 04:43:15.726382 12834 sgd_solver.cpp:106] Iteration 85000, lr = 1.67772e-05
I0506 04:43:15.728199 12834 solver.cpp:362] Iteration 85000, Testing net (#0)
I0506 04:43:15.728211 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:15.856701 12834 solver.cpp:429]     Test net output #0: accuracy = 0.768
I0506 04:43:15.856721 12834 solver.cpp:429]     Test net output #1: loss = 0.548059 (* 1 = 0.548059 loss)
I0506 04:43:15.859264 12834 solver.cpp:242] Iteration 85000 (84.1774 iter/s, 1.18797s/100 iter), loss = 0.69347
I0506 04:43:15.859284 12834 solver.cpp:261]     Train net output #0: loss = 0.69347 (* 1 = 0.69347 loss)
I0506 04:43:15.859293 12834 sgd_solver.cpp:106] Iteration 85000, lr = 1.67772e-05
I0506 04:43:16.814908 12834 solver.cpp:242] Iteration 85100 (91.8698 iter/s, 1.0885s/100 iter), loss = 0.826283
I0506 04:43:16.814950 12834 solver.cpp:261]     Train net output #0: loss = 0.826283 (* 1 = 0.826283 loss)
I0506 04:43:16.814961 12834 sgd_solver.cpp:106] Iteration 85100, lr = 1.67772e-05
I0506 04:43:16.820188 12834 solver.cpp:242] Iteration 85100 (104.071 iter/s, 0.960883s/100 iter), loss = 0.51814
I0506 04:43:16.820217 12834 solver.cpp:261]     Train net output #0: loss = 0.51814 (* 1 = 0.51814 loss)
I0506 04:43:16.820228 12834 sgd_solver.cpp:106] Iteration 85100, lr = 1.67772e-05
I0506 04:43:17.806126 12834 solver.cpp:242] Iteration 85200 (100.893 iter/s, 0.991151s/100 iter), loss = 0.580785
I0506 04:43:17.806164 12834 solver.cpp:261]     Train net output #0: loss = 0.580785 (* 1 = 0.580785 loss)
I0506 04:43:17.806174 12834 sgd_solver.cpp:106] Iteration 85200, lr = 1.67772e-05
I0506 04:43:17.810923 12834 solver.cpp:242] Iteration 85200 (100.94 iter/s, 0.990687s/100 iter), loss = 0.204449
I0506 04:43:17.810948 12834 solver.cpp:261]     Train net output #0: loss = 0.204449 (* 1 = 0.204449 loss)
I0506 04:43:17.810957 12834 sgd_solver.cpp:106] Iteration 85200, lr = 1.67772e-05
I0506 04:43:18.743476 12834 solver.cpp:242] Iteration 85300 (106.692 iter/s, 0.937282s/100 iter), loss = 2.19991
I0506 04:43:18.743510 12834 solver.cpp:261]     Train net output #0: loss = 2.19991 (* 1 = 2.19991 loss)
I0506 04:43:18.743520 12834 sgd_solver.cpp:106] Iteration 85300, lr = 1.67772e-05
I0506 04:43:18.748255 12834 solver.cpp:242] Iteration 85300 (106.691 iter/s, 0.937289s/100 iter), loss = 0.693814
I0506 04:43:18.748278 12834 solver.cpp:261]     Train net output #0: loss = 0.693814 (* 1 = 0.693814 loss)
I0506 04:43:18.748287 12834 sgd_solver.cpp:106] Iteration 85300, lr = 1.67772e-05
I0506 04:43:19.680548 12834 solver.cpp:242] Iteration 85400 (106.722 iter/s, 0.937014s/100 iter), loss = 2.80885
I0506 04:43:19.680596 12834 solver.cpp:261]     Train net output #0: loss = 2.80885 (* 1 = 2.80885 loss)
I0506 04:43:19.680606 12834 sgd_solver.cpp:106] Iteration 85400, lr = 1.67772e-05
I0506 04:43:19.685364 12834 solver.cpp:242] Iteration 85400 (106.716 iter/s, 0.937067s/100 iter), loss = 0.650131
I0506 04:43:19.685387 12834 solver.cpp:261]     Train net output #0: loss = 0.650131 (* 1 = 0.650131 loss)
I0506 04:43:19.685396 12834 sgd_solver.cpp:106] Iteration 85400, lr = 1.67772e-05
I0506 04:43:20.615193 12834 solver.cpp:362] Iteration 85500, Testing net (#0)
I0506 04:43:20.615223 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:20.737903 12834 solver.cpp:429]     Test net output #0: loss = 1.38287 (* 1 = 1.38287 loss)
I0506 04:43:20.740419 12834 solver.cpp:242] Iteration 85500 (94.357 iter/s, 1.0598s/100 iter), loss = 0.757059
I0506 04:43:20.740440 12834 solver.cpp:261]     Train net output #0: loss = 0.757059 (* 1 = 0.757059 loss)
I0506 04:43:20.740449 12834 sgd_solver.cpp:106] Iteration 85500, lr = 1.67772e-05
I0506 04:43:20.742274 12834 solver.cpp:362] Iteration 85500, Testing net (#0)
I0506 04:43:20.742288 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:20.871146 12834 solver.cpp:429]     Test net output #0: accuracy = 0.743
I0506 04:43:20.871165 12834 solver.cpp:429]     Test net output #1: loss = 0.59375 (* 1 = 0.59375 loss)
I0506 04:43:20.873719 12834 solver.cpp:242] Iteration 85500 (84.1531 iter/s, 1.18831s/100 iter), loss = 0.920534
I0506 04:43:20.873740 12834 solver.cpp:261]     Train net output #0: loss = 0.920534 (* 1 = 0.920534 loss)
I0506 04:43:20.873749 12834 sgd_solver.cpp:106] Iteration 85500, lr = 1.67772e-05
I0506 04:43:21.806215 12834 solver.cpp:242] Iteration 85600 (93.8309 iter/s, 1.06575s/100 iter), loss = 1.75623
I0506 04:43:21.806249 12834 solver.cpp:261]     Train net output #0: loss = 1.75623 (* 1 = 1.75623 loss)
I0506 04:43:21.806258 12834 sgd_solver.cpp:106] Iteration 85600, lr = 1.67772e-05
I0506 04:43:21.811055 12834 solver.cpp:242] Iteration 85600 (106.691 iter/s, 0.937287s/100 iter), loss = 0.508266
I0506 04:43:21.811080 12834 solver.cpp:261]     Train net output #0: loss = 0.508266 (* 1 = 0.508266 loss)
I0506 04:43:21.811089 12834 sgd_solver.cpp:106] Iteration 85600, lr = 1.67772e-05
I0506 04:43:22.761118 12834 solver.cpp:242] Iteration 85700 (104.73 iter/s, 0.954838s/100 iter), loss = 1.16379
I0506 04:43:22.761173 12834 solver.cpp:261]     Train net output #0: loss = 1.16379 (* 1 = 1.16379 loss)
I0506 04:43:22.761449 12834 sgd_solver.cpp:106] Iteration 85700, lr = 1.67772e-05
I0506 04:43:22.766242 12834 solver.cpp:242] Iteration 85700 (104.696 iter/s, 0.955142s/100 iter), loss = 0.724834
I0506 04:43:22.766268 12834 solver.cpp:261]     Train net output #0: loss = 0.724834 (* 1 = 0.724834 loss)
I0506 04:43:22.766276 12834 sgd_solver.cpp:106] Iteration 85700, lr = 1.67772e-05
I0506 04:43:23.699018 12834 solver.cpp:242] Iteration 85800 (106.63 iter/s, 0.937825s/100 iter), loss = 0.704467
I0506 04:43:23.699060 12834 solver.cpp:261]     Train net output #0: loss = 0.704467 (* 1 = 0.704467 loss)
I0506 04:43:23.699070 12834 sgd_solver.cpp:106] Iteration 85800, lr = 1.67772e-05
I0506 04:43:23.703866 12834 solver.cpp:242] Iteration 85800 (106.659 iter/s, 0.937571s/100 iter), loss = 0.447732
I0506 04:43:23.703891 12834 solver.cpp:261]     Train net output #0: loss = 0.447732 (* 1 = 0.447732 loss)
I0506 04:43:23.703900 12834 sgd_solver.cpp:106] Iteration 85800, lr = 1.67772e-05
I0506 04:43:24.636826 12834 solver.cpp:242] Iteration 85900 (106.64 iter/s, 0.937738s/100 iter), loss = 1.69565
I0506 04:43:24.636863 12834 solver.cpp:261]     Train net output #0: loss = 1.69565 (* 1 = 1.69565 loss)
I0506 04:43:24.636873 12834 sgd_solver.cpp:106] Iteration 85900, lr = 1.67772e-05
I0506 04:43:24.641600 12834 solver.cpp:242] Iteration 85900 (106.645 iter/s, 0.93769s/100 iter), loss = 0.770148
I0506 04:43:24.641625 12834 solver.cpp:261]     Train net output #0: loss = 0.770148 (* 1 = 0.770148 loss)
I0506 04:43:24.641635 12834 sgd_solver.cpp:106] Iteration 85900, lr = 1.67772e-05
I0506 04:43:25.571511 12834 solver.cpp:362] Iteration 86000, Testing net (#0)
I0506 04:43:25.571537 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:25.694167 12834 solver.cpp:429]     Test net output #0: loss = 1.63864 (* 1 = 1.63864 loss)
I0506 04:43:25.696687 12834 solver.cpp:242] Iteration 86000 (94.3571 iter/s, 1.0598s/100 iter), loss = 1.8235
I0506 04:43:25.696708 12834 solver.cpp:261]     Train net output #0: loss = 1.8235 (* 1 = 1.8235 loss)
I0506 04:43:25.696717 12834 sgd_solver.cpp:106] Iteration 86000, lr = 1.67772e-05
I0506 04:43:25.698539 12834 solver.cpp:362] Iteration 86000, Testing net (#0)
I0506 04:43:25.698554 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:25.827359 12834 solver.cpp:429]     Test net output #0: accuracy = 0.723
I0506 04:43:25.827380 12834 solver.cpp:429]     Test net output #1: loss = 0.663521 (* 1 = 0.663521 loss)
I0506 04:43:25.829936 12834 solver.cpp:242] Iteration 86000 (84.1546 iter/s, 1.18829s/100 iter), loss = 0.442869
I0506 04:43:25.829964 12834 solver.cpp:261]     Train net output #0: loss = 0.442869 (* 1 = 0.442869 loss)
I0506 04:43:25.829974 12834 sgd_solver.cpp:106] Iteration 86000, lr = 1.67772e-05
I0506 04:43:26.775990 12834 solver.cpp:242] Iteration 86100 (92.6568 iter/s, 1.07925s/100 iter), loss = 2.81776
I0506 04:43:26.776031 12834 solver.cpp:261]     Train net output #0: loss = 2.81776 (* 1 = 2.81776 loss)
I0506 04:43:26.776039 12834 sgd_solver.cpp:106] Iteration 86100, lr = 1.67772e-05
I0506 04:43:26.780747 12834 solver.cpp:242] Iteration 86100 (105.179 iter/s, 0.950765s/100 iter), loss = 0.537851
I0506 04:43:26.780772 12834 solver.cpp:261]     Train net output #0: loss = 0.537851 (* 1 = 0.537851 loss)
I0506 04:43:26.780781 12834 sgd_solver.cpp:106] Iteration 86100, lr = 1.67772e-05
I0506 04:43:27.734242 12834 solver.cpp:242] Iteration 86200 (104.365 iter/s, 0.958179s/100 iter), loss = 1.54587
I0506 04:43:27.734285 12834 solver.cpp:261]     Train net output #0: loss = 1.54587 (* 1 = 1.54587 loss)
I0506 04:43:27.734294 12834 sgd_solver.cpp:106] Iteration 86200, lr = 1.67772e-05
I0506 04:43:27.739049 12834 solver.cpp:242] Iteration 86200 (104.356 iter/s, 0.958258s/100 iter), loss = 0.458764
I0506 04:43:27.739075 12834 solver.cpp:261]     Train net output #0: loss = 0.458764 (* 1 = 0.458764 loss)
I0506 04:43:27.739095 12834 sgd_solver.cpp:106] Iteration 86200, lr = 1.67772e-05
I0506 04:43:28.672027 12834 solver.cpp:242] Iteration 86300 (106.642 iter/s, 0.937716s/100 iter), loss = 1.26202
I0506 04:43:28.672066 12834 solver.cpp:261]     Train net output #0: loss = 1.26202 (* 1 = 1.26202 loss)
I0506 04:43:28.672076 12834 sgd_solver.cpp:106] Iteration 86300, lr = 1.67772e-05
I0506 04:43:28.676831 12834 solver.cpp:242] Iteration 86300 (106.64 iter/s, 0.937737s/100 iter), loss = 0.920423
I0506 04:43:28.676856 12834 solver.cpp:261]     Train net output #0: loss = 0.920423 (* 1 = 0.920423 loss)
I0506 04:43:28.676864 12834 sgd_solver.cpp:106] Iteration 86300, lr = 1.67772e-05
I0506 04:43:29.609292 12834 solver.cpp:242] Iteration 86400 (106.701 iter/s, 0.937195s/100 iter), loss = 1.27443
I0506 04:43:29.609328 12834 solver.cpp:261]     Train net output #0: loss = 1.27443 (* 1 = 1.27443 loss)
I0506 04:43:29.609338 12834 sgd_solver.cpp:106] Iteration 86400, lr = 1.67772e-05
I0506 04:43:29.614050 12834 solver.cpp:242] Iteration 86400 (106.704 iter/s, 0.937176s/100 iter), loss = 0.517408
I0506 04:43:29.614073 12834 solver.cpp:261]     Train net output #0: loss = 0.517408 (* 1 = 0.517408 loss)
I0506 04:43:29.614082 12834 sgd_solver.cpp:106] Iteration 86400, lr = 1.67772e-05
I0506 04:43:30.544298 12834 solver.cpp:362] Iteration 86500, Testing net (#0)
I0506 04:43:30.544322 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:30.667063 12834 solver.cpp:429]     Test net output #0: loss = 1.82283 (* 1 = 1.82283 loss)
I0506 04:43:30.669589 12834 solver.cpp:242] Iteration 86500 (94.3181 iter/s, 1.06024s/100 iter), loss = 4.42698
I0506 04:43:30.669610 12834 solver.cpp:261]     Train net output #0: loss = 4.42698 (* 1 = 4.42698 loss)
I0506 04:43:30.669618 12834 sgd_solver.cpp:106] Iteration 86500, lr = 1.67772e-05
I0506 04:43:30.671555 12834 solver.cpp:362] Iteration 86500, Testing net (#0)
I0506 04:43:30.671569 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:30.800117 12834 solver.cpp:429]     Test net output #0: accuracy = 0.73
I0506 04:43:30.800137 12834 solver.cpp:429]     Test net output #1: loss = 0.672569 (* 1 = 0.672569 loss)
I0506 04:43:30.802685 12834 solver.cpp:242] Iteration 86500 (84.1333 iter/s, 1.18859s/100 iter), loss = 1.33284
I0506 04:43:30.802705 12834 solver.cpp:261]     Train net output #0: loss = 1.33284 (* 1 = 1.33284 loss)
I0506 04:43:30.802712 12834 sgd_solver.cpp:106] Iteration 86500, lr = 1.67772e-05
I0506 04:43:31.734930 12834 solver.cpp:242] Iteration 86600 (93.8711 iter/s, 1.06529s/100 iter), loss = 0.56916
I0506 04:43:31.734966 12834 solver.cpp:261]     Train net output #0: loss = 0.56916 (* 1 = 0.56916 loss)
I0506 04:43:31.734975 12834 sgd_solver.cpp:106] Iteration 86600, lr = 1.67772e-05
I0506 04:43:31.739750 12834 solver.cpp:242] Iteration 86600 (106.721 iter/s, 0.937027s/100 iter), loss = 0.454735
I0506 04:43:31.739775 12834 solver.cpp:261]     Train net output #0: loss = 0.454735 (* 1 = 0.454735 loss)
I0506 04:43:31.739784 12834 sgd_solver.cpp:106] Iteration 86600, lr = 1.67772e-05
I0506 04:43:32.682468 12834 solver.cpp:242] Iteration 86700 (105.543 iter/s, 0.947479s/100 iter), loss = 1.98887
I0506 04:43:32.682504 12834 solver.cpp:261]     Train net output #0: loss = 1.98887 (* 1 = 1.98887 loss)
I0506 04:43:32.682515 12834 sgd_solver.cpp:106] Iteration 86700, lr = 1.67772e-05
I0506 04:43:32.687840 12834 solver.cpp:242] Iteration 86700 (105.481 iter/s, 0.948035s/100 iter), loss = 0.511847
I0506 04:43:32.687868 12834 solver.cpp:261]     Train net output #0: loss = 0.511847 (* 1 = 0.511847 loss)
I0506 04:43:32.687880 12834 sgd_solver.cpp:106] Iteration 86700, lr = 1.67772e-05
I0506 04:43:33.624392 12834 solver.cpp:242] Iteration 86800 (106.173 iter/s, 0.941862s/100 iter), loss = 1.26955
I0506 04:43:33.624435 12834 solver.cpp:261]     Train net output #0: loss = 1.26955 (* 1 = 1.26955 loss)
I0506 04:43:33.624444 12834 sgd_solver.cpp:106] Iteration 86800, lr = 1.67772e-05
I0506 04:43:33.629165 12834 solver.cpp:242] Iteration 86800 (106.238 iter/s, 0.941279s/100 iter), loss = 0.370154
I0506 04:43:33.629189 12834 solver.cpp:261]     Train net output #0: loss = 0.370154 (* 1 = 0.370154 loss)
I0506 04:43:33.629199 12834 sgd_solver.cpp:106] Iteration 86800, lr = 1.67772e-05
I0506 04:43:34.561966 12834 solver.cpp:242] Iteration 86900 (106.667 iter/s, 0.937497s/100 iter), loss = 0.892741
I0506 04:43:34.562008 12834 solver.cpp:261]     Train net output #0: loss = 0.892741 (* 1 = 0.892741 loss)
I0506 04:43:34.562018 12834 sgd_solver.cpp:106] Iteration 86900, lr = 1.67772e-05
I0506 04:43:34.566750 12834 solver.cpp:242] Iteration 86900 (106.662 iter/s, 0.937542s/100 iter), loss = 0.446117
I0506 04:43:34.566776 12834 solver.cpp:261]     Train net output #0: loss = 0.446117 (* 1 = 0.446117 loss)
I0506 04:43:34.566786 12834 sgd_solver.cpp:106] Iteration 86900, lr = 1.67772e-05
I0506 04:43:35.497320 12834 solver.cpp:362] Iteration 87000, Testing net (#0)
I0506 04:43:35.497349 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:35.619938 12834 solver.cpp:429]     Test net output #0: loss = 1.46345 (* 1 = 1.46345 loss)
I0506 04:43:35.622457 12834 solver.cpp:242] Iteration 87000 (94.3016 iter/s, 1.06043s/100 iter), loss = 1.28021
I0506 04:43:35.622476 12834 solver.cpp:261]     Train net output #0: loss = 1.28021 (* 1 = 1.28021 loss)
I0506 04:43:35.622485 12834 sgd_solver.cpp:106] Iteration 87000, lr = 1.67772e-05
I0506 04:43:35.624313 12834 solver.cpp:362] Iteration 87000, Testing net (#0)
I0506 04:43:35.624328 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:35.752854 12834 solver.cpp:429]     Test net output #0: accuracy = 0.758
I0506 04:43:35.752876 12834 solver.cpp:429]     Test net output #1: loss = 0.563882 (* 1 = 0.563882 loss)
I0506 04:43:35.755434 12834 solver.cpp:242] Iteration 87000 (84.13 iter/s, 1.18864s/100 iter), loss = 0.486389
I0506 04:43:35.755453 12834 solver.cpp:261]     Train net output #0: loss = 0.486389 (* 1 = 0.486389 loss)
I0506 04:43:35.755462 12834 sgd_solver.cpp:106] Iteration 87000, lr = 1.67772e-05
I0506 04:43:36.688393 12834 solver.cpp:242] Iteration 87100 (93.819 iter/s, 1.06588s/100 iter), loss = 0.880803
I0506 04:43:36.688434 12834 solver.cpp:261]     Train net output #0: loss = 0.880803 (* 1 = 0.880803 loss)
I0506 04:43:36.688444 12834 sgd_solver.cpp:106] Iteration 87100, lr = 1.67772e-05
I0506 04:43:36.693164 12834 solver.cpp:242] Iteration 87100 (106.645 iter/s, 0.937692s/100 iter), loss = 0.69504
I0506 04:43:36.693191 12834 solver.cpp:261]     Train net output #0: loss = 0.69504 (* 1 = 0.69504 loss)
I0506 04:43:36.693198 12834 sgd_solver.cpp:106] Iteration 87100, lr = 1.67772e-05
I0506 04:43:37.625689 12834 solver.cpp:242] Iteration 87200 (106.697 iter/s, 0.937231s/100 iter), loss = 0.908121
I0506 04:43:37.625730 12834 solver.cpp:261]     Train net output #0: loss = 0.908121 (* 1 = 0.908121 loss)
I0506 04:43:37.625754 12834 sgd_solver.cpp:106] Iteration 87200, lr = 1.67772e-05
I0506 04:43:37.630456 12834 solver.cpp:242] Iteration 87200 (106.695 iter/s, 0.937249s/100 iter), loss = 0.736468
I0506 04:43:37.630481 12834 solver.cpp:261]     Train net output #0: loss = 0.736468 (* 1 = 0.736468 loss)
I0506 04:43:37.630491 12834 sgd_solver.cpp:106] Iteration 87200, lr = 1.67772e-05
I0506 04:43:38.563515 12834 solver.cpp:242] Iteration 87300 (106.638 iter/s, 0.937755s/100 iter), loss = 1.11947
I0506 04:43:38.563555 12834 solver.cpp:261]     Train net output #0: loss = 1.11947 (* 1 = 1.11947 loss)
I0506 04:43:38.563563 12834 sgd_solver.cpp:106] Iteration 87300, lr = 1.67772e-05
I0506 04:43:38.568294 12834 solver.cpp:242] Iteration 87300 (106.633 iter/s, 0.937795s/100 iter), loss = 0.543866
I0506 04:43:38.568320 12834 solver.cpp:261]     Train net output #0: loss = 0.543866 (* 1 = 0.543866 loss)
I0506 04:43:38.568328 12834 sgd_solver.cpp:106] Iteration 87300, lr = 1.67772e-05
I0506 04:43:39.514600 12834 solver.cpp:242] Iteration 87400 (105.15 iter/s, 0.951023s/100 iter), loss = 1.79002
I0506 04:43:39.514639 12834 solver.cpp:261]     Train net output #0: loss = 1.79002 (* 1 = 1.79002 loss)
I0506 04:43:39.514648 12834 sgd_solver.cpp:106] Iteration 87400, lr = 1.67772e-05
I0506 04:43:39.519438 12834 solver.cpp:242] Iteration 87400 (105.143 iter/s, 0.95109s/100 iter), loss = 0.653646
I0506 04:43:39.519464 12834 solver.cpp:261]     Train net output #0: loss = 0.653646 (* 1 = 0.653646 loss)
I0506 04:43:39.519472 12834 sgd_solver.cpp:106] Iteration 87400, lr = 1.67772e-05
I0506 04:43:40.449159 12834 solver.cpp:362] Iteration 87500, Testing net (#0)
I0506 04:43:40.449184 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:40.571873 12834 solver.cpp:429]     Test net output #0: loss = 1.2589 (* 1 = 1.2589 loss)
I0506 04:43:40.574391 12834 solver.cpp:242] Iteration 87500 (94.3634 iter/s, 1.05973s/100 iter), loss = 0.495123
I0506 04:43:40.574414 12834 solver.cpp:261]     Train net output #0: loss = 0.495123 (* 1 = 0.495123 loss)
I0506 04:43:40.574422 12834 sgd_solver.cpp:106] Iteration 87500, lr = 1.67772e-05
I0506 04:43:40.576244 12834 solver.cpp:362] Iteration 87500, Testing net (#0)
I0506 04:43:40.576256 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:40.717263 12834 solver.cpp:429]     Test net output #0: accuracy = 0.753
I0506 04:43:40.717286 12834 solver.cpp:429]     Test net output #1: loss = 0.558115 (* 1 = 0.558115 loss)
I0506 04:43:40.719982 12834 solver.cpp:242] Iteration 87500 (83.2988 iter/s, 1.2005s/100 iter), loss = 0.526634
I0506 04:43:40.720006 12834 solver.cpp:261]     Train net output #0: loss = 0.526634 (* 1 = 0.526634 loss)
I0506 04:43:40.720017 12834 sgd_solver.cpp:106] Iteration 87500, lr = 1.67772e-05
I0506 04:43:41.744663 12834 solver.cpp:242] Iteration 87600 (85.4539 iter/s, 1.17022s/100 iter), loss = 1.53298
I0506 04:43:41.744702 12834 solver.cpp:261]     Train net output #0: loss = 1.53298 (* 1 = 1.53298 loss)
I0506 04:43:41.744711 12834 sgd_solver.cpp:106] Iteration 87600, lr = 1.67772e-05
I0506 04:43:41.749511 12834 solver.cpp:242] Iteration 87600 (97.1369 iter/s, 1.02948s/100 iter), loss = 0.852623
I0506 04:43:41.749537 12834 solver.cpp:261]     Train net output #0: loss = 0.852623 (* 1 = 0.852623 loss)
I0506 04:43:41.749547 12834 sgd_solver.cpp:106] Iteration 87600, lr = 1.67772e-05
I0506 04:43:42.693222 12834 solver.cpp:242] Iteration 87700 (105.431 iter/s, 0.948491s/100 iter), loss = 3.46603
I0506 04:43:42.693267 12834 solver.cpp:261]     Train net output #0: loss = 3.46603 (* 1 = 3.46603 loss)
I0506 04:43:42.693279 12834 sgd_solver.cpp:106] Iteration 87700, lr = 1.67772e-05
I0506 04:43:42.698513 12834 solver.cpp:242] Iteration 87700 (105.379 iter/s, 0.948956s/100 iter), loss = 0.89326
I0506 04:43:42.698542 12834 solver.cpp:261]     Train net output #0: loss = 0.89326 (* 1 = 0.89326 loss)
I0506 04:43:42.698554 12834 sgd_solver.cpp:106] Iteration 87700, lr = 1.67772e-05
I0506 04:43:43.729470 12834 solver.cpp:242] Iteration 87800 (96.5096 iter/s, 1.03617s/100 iter), loss = 0.834779
I0506 04:43:43.729523 12834 solver.cpp:261]     Train net output #0: loss = 0.834779 (* 1 = 0.834779 loss)
I0506 04:43:43.729535 12834 sgd_solver.cpp:106] Iteration 87800, lr = 1.67772e-05
I0506 04:43:43.734781 12834 solver.cpp:242] Iteration 87800 (96.5047 iter/s, 1.03622s/100 iter), loss = 0.704765
I0506 04:43:43.734812 12834 solver.cpp:261]     Train net output #0: loss = 0.704765 (* 1 = 0.704765 loss)
I0506 04:43:43.734822 12834 sgd_solver.cpp:106] Iteration 87800, lr = 1.67772e-05
I0506 04:43:44.725101 12834 solver.cpp:242] Iteration 87900 (100.447 iter/s, 0.995554s/100 iter), loss = 1.75185
I0506 04:43:44.725138 12834 solver.cpp:261]     Train net output #0: loss = 1.75185 (* 1 = 1.75185 loss)
I0506 04:43:44.725148 12834 sgd_solver.cpp:106] Iteration 87900, lr = 1.67772e-05
I0506 04:43:44.729876 12834 solver.cpp:242] Iteration 87900 (100.498 iter/s, 0.995047s/100 iter), loss = 0.902887
I0506 04:43:44.729900 12834 solver.cpp:261]     Train net output #0: loss = 0.902887 (* 1 = 0.902887 loss)
I0506 04:43:44.729909 12834 sgd_solver.cpp:106] Iteration 87900, lr = 1.67772e-05
I0506 04:43:45.659896 12834 solver.cpp:362] Iteration 88000, Testing net (#0)
I0506 04:43:45.659919 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:45.782691 12834 solver.cpp:429]     Test net output #0: loss = 1.49763 (* 1 = 1.49763 loss)
I0506 04:43:45.785208 12834 solver.cpp:242] Iteration 88000 (94.335 iter/s, 1.06005s/100 iter), loss = 1.115
I0506 04:43:45.785228 12834 solver.cpp:261]     Train net output #0: loss = 1.115 (* 1 = 1.115 loss)
I0506 04:43:45.785238 12834 sgd_solver.cpp:106] Iteration 88000, lr = 1.67772e-05
I0506 04:43:45.787063 12834 solver.cpp:362] Iteration 88000, Testing net (#0)
I0506 04:43:45.787077 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:45.915774 12834 solver.cpp:429]     Test net output #0: accuracy = 0.758
I0506 04:43:45.915794 12834 solver.cpp:429]     Test net output #1: loss = 0.569387 (* 1 = 0.569387 loss)
I0506 04:43:45.918354 12834 solver.cpp:242] Iteration 88000 (84.1444 iter/s, 1.18843s/100 iter), loss = 0.682634
I0506 04:43:45.918375 12834 solver.cpp:261]     Train net output #0: loss = 0.682634 (* 1 = 0.682634 loss)
I0506 04:43:45.918383 12834 sgd_solver.cpp:106] Iteration 88000, lr = 1.67772e-05
I0506 04:43:46.851866 12834 solver.cpp:242] Iteration 88100 (93.755 iter/s, 1.06661s/100 iter), loss = 0.583637
I0506 04:43:46.851903 12834 solver.cpp:261]     Train net output #0: loss = 0.583637 (* 1 = 0.583637 loss)
I0506 04:43:46.851913 12834 sgd_solver.cpp:106] Iteration 88100, lr = 1.67772e-05
I0506 04:43:46.856685 12834 solver.cpp:242] Iteration 88100 (106.577 iter/s, 0.938291s/100 iter), loss = 0.773516
I0506 04:43:46.856710 12834 solver.cpp:261]     Train net output #0: loss = 0.773516 (* 1 = 0.773516 loss)
I0506 04:43:46.856719 12834 sgd_solver.cpp:106] Iteration 88100, lr = 1.67772e-05
I0506 04:43:47.788805 12834 solver.cpp:242] Iteration 88200 (106.738 iter/s, 0.93687s/100 iter), loss = 1.79282
I0506 04:43:47.788839 12834 solver.cpp:261]     Train net output #0: loss = 1.79282 (* 1 = 1.79282 loss)
I0506 04:43:47.788848 12834 sgd_solver.cpp:106] Iteration 88200, lr = 1.67772e-05
I0506 04:43:47.793576 12834 solver.cpp:242] Iteration 88200 (106.741 iter/s, 0.936846s/100 iter), loss = 0.418534
I0506 04:43:47.793598 12834 solver.cpp:261]     Train net output #0: loss = 0.418534 (* 1 = 0.418534 loss)
I0506 04:43:47.793607 12834 sgd_solver.cpp:106] Iteration 88200, lr = 1.67772e-05
I0506 04:43:48.726433 12834 solver.cpp:242] Iteration 88300 (106.659 iter/s, 0.937571s/100 iter), loss = 1.63782
I0506 04:43:48.726469 12834 solver.cpp:261]     Train net output #0: loss = 1.63782 (* 1 = 1.63782 loss)
I0506 04:43:48.726477 12834 sgd_solver.cpp:106] Iteration 88300, lr = 1.67772e-05
I0506 04:43:48.731282 12834 solver.cpp:242] Iteration 88300 (106.649 iter/s, 0.937655s/100 iter), loss = 0.73231
I0506 04:43:48.731308 12834 solver.cpp:261]     Train net output #0: loss = 0.73231 (* 1 = 0.73231 loss)
I0506 04:43:48.731317 12834 sgd_solver.cpp:106] Iteration 88300, lr = 1.67772e-05
I0506 04:43:49.672849 12834 solver.cpp:242] Iteration 88400 (105.669 iter/s, 0.946351s/100 iter), loss = 1.49593
I0506 04:43:49.672905 12834 solver.cpp:261]     Train net output #0: loss = 1.49593 (* 1 = 1.49593 loss)
I0506 04:43:49.673264 12834 sgd_solver.cpp:106] Iteration 88400, lr = 1.67772e-05
I0506 04:43:49.678081 12834 solver.cpp:242] Iteration 88400 (105.624 iter/s, 0.946754s/100 iter), loss = 0.459947
I0506 04:43:49.678105 12834 solver.cpp:261]     Train net output #0: loss = 0.459947 (* 1 = 0.459947 loss)
I0506 04:43:49.678114 12834 sgd_solver.cpp:106] Iteration 88400, lr = 1.67772e-05
I0506 04:43:50.611070 12834 solver.cpp:362] Iteration 88500, Testing net (#0)
I0506 04:43:50.611102 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:50.742336 12834 solver.cpp:429]     Test net output #0: loss = 1.52082 (* 1 = 1.52082 loss)
I0506 04:43:50.744849 12834 solver.cpp:242] Iteration 88500 (93.2899 iter/s, 1.07193s/100 iter), loss = 0.682073
I0506 04:43:50.744871 12834 solver.cpp:261]     Train net output #0: loss = 0.682073 (* 1 = 0.682073 loss)
I0506 04:43:50.744879 12834 sgd_solver.cpp:106] Iteration 88500, lr = 1.67772e-05
I0506 04:43:50.746764 12834 solver.cpp:362] Iteration 88500, Testing net (#0)
I0506 04:43:50.746778 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:50.875442 12834 solver.cpp:429]     Test net output #0: accuracy = 0.761
I0506 04:43:50.875461 12834 solver.cpp:429]     Test net output #1: loss = 0.575388 (* 1 = 0.575388 loss)
I0506 04:43:50.878020 12834 solver.cpp:242] Iteration 88500 (83.3407 iter/s, 1.19989s/100 iter), loss = 0.348103
I0506 04:43:50.878041 12834 solver.cpp:261]     Train net output #0: loss = 0.348103 (* 1 = 0.348103 loss)
I0506 04:43:50.878049 12834 sgd_solver.cpp:106] Iteration 88500, lr = 1.67772e-05
I0506 04:43:51.810220 12834 solver.cpp:242] Iteration 88600 (93.8687 iter/s, 1.06532s/100 iter), loss = 2.97238
I0506 04:43:51.810258 12834 solver.cpp:261]     Train net output #0: loss = 2.97238 (* 1 = 2.97238 loss)
I0506 04:43:51.810268 12834 sgd_solver.cpp:106] Iteration 88600, lr = 1.67772e-05
I0506 04:43:51.814983 12834 solver.cpp:242] Iteration 88600 (106.732 iter/s, 0.936923s/100 iter), loss = 0.66054
I0506 04:43:51.815011 12834 solver.cpp:261]     Train net output #0: loss = 0.66054 (* 1 = 0.66054 loss)
I0506 04:43:51.815019 12834 sgd_solver.cpp:106] Iteration 88600, lr = 1.67772e-05
I0506 04:43:52.747243 12834 solver.cpp:242] Iteration 88700 (106.729 iter/s, 0.936952s/100 iter), loss = 0.618184
I0506 04:43:52.747283 12834 solver.cpp:261]     Train net output #0: loss = 0.618184 (* 1 = 0.618184 loss)
I0506 04:43:52.747292 12834 sgd_solver.cpp:106] Iteration 88700, lr = 1.67772e-05
I0506 04:43:52.752019 12834 solver.cpp:242] Iteration 88700 (106.725 iter/s, 0.936991s/100 iter), loss = 0.554895
I0506 04:43:52.752046 12834 solver.cpp:261]     Train net output #0: loss = 0.554895 (* 1 = 0.554895 loss)
I0506 04:43:52.752055 12834 sgd_solver.cpp:106] Iteration 88700, lr = 1.67772e-05
I0506 04:43:53.684572 12834 solver.cpp:242] Iteration 88800 (106.695 iter/s, 0.937249s/100 iter), loss = 0.39439
I0506 04:43:53.684612 12834 solver.cpp:261]     Train net output #0: loss = 0.39439 (* 1 = 0.39439 loss)
I0506 04:43:53.684623 12834 sgd_solver.cpp:106] Iteration 88800, lr = 1.67772e-05
I0506 04:43:53.689359 12834 solver.cpp:242] Iteration 88800 (106.69 iter/s, 0.937295s/100 iter), loss = 0.518232
I0506 04:43:53.689383 12834 solver.cpp:261]     Train net output #0: loss = 0.518232 (* 1 = 0.518232 loss)
I0506 04:43:53.689393 12834 sgd_solver.cpp:106] Iteration 88800, lr = 1.67772e-05
I0506 04:43:54.626796 12834 solver.cpp:242] Iteration 88900 (106.14 iter/s, 0.942149s/100 iter), loss = 0.221633
I0506 04:43:54.626840 12834 solver.cpp:261]     Train net output #0: loss = 0.221633 (* 1 = 0.221633 loss)
I0506 04:43:54.626852 12834 sgd_solver.cpp:106] Iteration 88900, lr = 1.67772e-05
I0506 04:43:54.632061 12834 solver.cpp:242] Iteration 88900 (106.083 iter/s, 0.942657s/100 iter), loss = 0.159695
I0506 04:43:54.632091 12834 solver.cpp:261]     Train net output #0: loss = 0.159695 (* 1 = 0.159695 loss)
I0506 04:43:54.632112 12834 sgd_solver.cpp:106] Iteration 88900, lr = 1.67772e-05
I0506 04:43:55.623916 12834 solver.cpp:362] Iteration 89000, Testing net (#0)
I0506 04:43:55.623942 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:55.746417 12834 solver.cpp:429]     Test net output #0: loss = 1.36683 (* 1 = 1.36683 loss)
I0506 04:43:55.748920 12834 solver.cpp:242] Iteration 89000 (89.1216 iter/s, 1.12206s/100 iter), loss = 0.739143
I0506 04:43:55.748941 12834 solver.cpp:261]     Train net output #0: loss = 0.739143 (* 1 = 0.739143 loss)
I0506 04:43:55.748950 12834 sgd_solver.cpp:106] Iteration 89000, lr = 1.67772e-05
I0506 04:43:55.750763 12834 solver.cpp:362] Iteration 89000, Testing net (#0)
I0506 04:43:55.750777 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:43:55.879256 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7535
I0506 04:43:55.879277 12834 solver.cpp:429]     Test net output #1: loss = 0.567919 (* 1 = 0.567919 loss)
I0506 04:43:55.881850 12834 solver.cpp:242] Iteration 89000 (80.0167 iter/s, 1.24974s/100 iter), loss = 0.433966
I0506 04:43:55.881871 12834 solver.cpp:261]     Train net output #0: loss = 0.433966 (* 1 = 0.433966 loss)
I0506 04:43:55.881880 12834 sgd_solver.cpp:106] Iteration 89000, lr = 1.67772e-05
I0506 04:43:56.814844 12834 solver.cpp:242] Iteration 89100 (93.8202 iter/s, 1.06587s/100 iter), loss = 1.61501
I0506 04:43:56.814882 12834 solver.cpp:261]     Train net output #0: loss = 1.61501 (* 1 = 1.61501 loss)
I0506 04:43:56.814893 12834 sgd_solver.cpp:106] Iteration 89100, lr = 1.67772e-05
I0506 04:43:56.819602 12834 solver.cpp:242] Iteration 89100 (106.643 iter/s, 0.937712s/100 iter), loss = 0.562523
I0506 04:43:56.819627 12834 solver.cpp:261]     Train net output #0: loss = 0.562523 (* 1 = 0.562523 loss)
I0506 04:43:56.819635 12834 sgd_solver.cpp:106] Iteration 89100, lr = 1.67772e-05
I0506 04:43:57.752099 12834 solver.cpp:242] Iteration 89200 (106.702 iter/s, 0.937192s/100 iter), loss = 1.50082
I0506 04:43:57.752136 12834 solver.cpp:261]     Train net output #0: loss = 1.50082 (* 1 = 1.50082 loss)
I0506 04:43:57.752146 12834 sgd_solver.cpp:106] Iteration 89200, lr = 1.67772e-05
I0506 04:43:57.756953 12834 solver.cpp:242] Iteration 89200 (106.69 iter/s, 0.937298s/100 iter), loss = 0.685377
I0506 04:43:57.756978 12834 solver.cpp:261]     Train net output #0: loss = 0.685377 (* 1 = 0.685377 loss)
I0506 04:43:57.756989 12834 sgd_solver.cpp:106] Iteration 89200, lr = 1.67772e-05
I0506 04:43:58.689127 12834 solver.cpp:242] Iteration 89300 (106.728 iter/s, 0.936963s/100 iter), loss = 1.03235
I0506 04:43:58.689177 12834 solver.cpp:261]     Train net output #0: loss = 1.03235 (* 1 = 1.03235 loss)
I0506 04:43:58.689187 12834 sgd_solver.cpp:106] Iteration 89300, lr = 1.67772e-05
I0506 04:43:58.693919 12834 solver.cpp:242] Iteration 89300 (106.732 iter/s, 0.936922s/100 iter), loss = 0.52688
I0506 04:43:58.693943 12834 solver.cpp:261]     Train net output #0: loss = 0.52688 (* 1 = 0.52688 loss)
I0506 04:43:58.693953 12834 sgd_solver.cpp:106] Iteration 89300, lr = 1.67772e-05
I0506 04:43:59.626718 12834 solver.cpp:242] Iteration 89400 (106.663 iter/s, 0.937529s/100 iter), loss = 0.728386
I0506 04:43:59.626746 12834 solver.cpp:261]     Train net output #0: loss = 0.728386 (* 1 = 0.728386 loss)
I0506 04:43:59.626755 12834 sgd_solver.cpp:106] Iteration 89400, lr = 1.67772e-05
I0506 04:43:59.631536 12834 solver.cpp:242] Iteration 89400 (106.659 iter/s, 0.937566s/100 iter), loss = 0.5678
I0506 04:43:59.631561 12834 solver.cpp:261]     Train net output #0: loss = 0.5678 (* 1 = 0.5678 loss)
I0506 04:43:59.631569 12834 sgd_solver.cpp:106] Iteration 89400, lr = 1.67772e-05
I0506 04:44:00.567414 12834 solver.cpp:362] Iteration 89500, Testing net (#0)
I0506 04:44:00.567448 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:00.690184 12834 solver.cpp:429]     Test net output #0: loss = 1.41009 (* 1 = 1.41009 loss)
I0506 04:44:00.692714 12834 solver.cpp:242] Iteration 89500 (93.813 iter/s, 1.06595s/100 iter), loss = 0.466907
I0506 04:44:00.692747 12834 solver.cpp:261]     Train net output #0: loss = 0.466907 (* 1 = 0.466907 loss)
I0506 04:44:00.692757 12834 sgd_solver.cpp:106] Iteration 89500, lr = 1.67772e-05
I0506 04:44:00.694607 12834 solver.cpp:362] Iteration 89500, Testing net (#0)
I0506 04:44:00.694619 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:00.823402 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7535
I0506 04:44:00.823421 12834 solver.cpp:429]     Test net output #1: loss = 0.601575 (* 1 = 0.601575 loss)
I0506 04:44:00.825973 12834 solver.cpp:242] Iteration 89500 (83.7247 iter/s, 1.19439s/100 iter), loss = 0.420993
I0506 04:44:00.825992 12834 solver.cpp:261]     Train net output #0: loss = 0.420993 (* 1 = 0.420993 loss)
I0506 04:44:00.826001 12834 sgd_solver.cpp:106] Iteration 89500, lr = 1.67772e-05
I0506 04:44:01.760900 12834 solver.cpp:242] Iteration 89600 (93.6225 iter/s, 1.06812s/100 iter), loss = 1.11002
I0506 04:44:01.760931 12834 solver.cpp:261]     Train net output #0: loss = 1.11002 (* 1 = 1.11002 loss)
I0506 04:44:01.760941 12834 sgd_solver.cpp:106] Iteration 89600, lr = 1.67772e-05
I0506 04:44:01.765664 12834 solver.cpp:242] Iteration 89600 (106.422 iter/s, 0.939652s/100 iter), loss = 0.553505
I0506 04:44:01.765687 12834 solver.cpp:261]     Train net output #0: loss = 0.553505 (* 1 = 0.553505 loss)
I0506 04:44:01.765697 12834 sgd_solver.cpp:106] Iteration 89600, lr = 1.67772e-05
I0506 04:44:02.711016 12834 solver.cpp:242] Iteration 89700 (105.257 iter/s, 0.950055s/100 iter), loss = 1.98362
I0506 04:44:02.711066 12834 solver.cpp:261]     Train net output #0: loss = 1.98362 (* 1 = 1.98362 loss)
I0506 04:44:02.711078 12834 sgd_solver.cpp:106] Iteration 89700, lr = 1.67772e-05
I0506 04:44:02.716338 12834 solver.cpp:242] Iteration 89700 (105.193 iter/s, 0.95063s/100 iter), loss = 0.63512
I0506 04:44:02.716370 12834 solver.cpp:261]     Train net output #0: loss = 0.63512 (* 1 = 0.63512 loss)
I0506 04:44:02.716382 12834 sgd_solver.cpp:106] Iteration 89700, lr = 1.67772e-05
I0506 04:44:03.649405 12834 solver.cpp:242] Iteration 89800 (106.575 iter/s, 0.938307s/100 iter), loss = 0.627416
I0506 04:44:03.649446 12834 solver.cpp:261]     Train net output #0: loss = 0.627416 (* 1 = 0.627416 loss)
I0506 04:44:03.649456 12834 sgd_solver.cpp:106] Iteration 89800, lr = 1.67772e-05
I0506 04:44:03.654189 12834 solver.cpp:242] Iteration 89800 (106.632 iter/s, 0.937802s/100 iter), loss = 0.435054
I0506 04:44:03.654214 12834 solver.cpp:261]     Train net output #0: loss = 0.435054 (* 1 = 0.435054 loss)
I0506 04:44:03.654222 12834 sgd_solver.cpp:106] Iteration 89800, lr = 1.67772e-05
I0506 04:44:04.588003 12834 solver.cpp:242] Iteration 89900 (106.55 iter/s, 0.938531s/100 iter), loss = 1.78084
I0506 04:44:04.588053 12834 solver.cpp:261]     Train net output #0: loss = 1.78084 (* 1 = 1.78084 loss)
I0506 04:44:04.588064 12834 sgd_solver.cpp:106] Iteration 89900, lr = 1.67772e-05
I0506 04:44:04.593296 12834 solver.cpp:242] Iteration 89900 (106.489 iter/s, 0.939061s/100 iter), loss = 0.719898
I0506 04:44:04.593327 12834 solver.cpp:261]     Train net output #0: loss = 0.719898 (* 1 = 0.719898 loss)
I0506 04:44:04.593338 12834 sgd_solver.cpp:106] Iteration 89900, lr = 1.67772e-05
I0506 04:44:05.621172 12834 solver.cpp:362] Iteration 90000, Testing net (#0)
I0506 04:44:05.621207 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:05.744413 12834 solver.cpp:429]     Test net output #0: loss = 1.55981 (* 1 = 1.55981 loss)
I0506 04:44:05.746940 12834 solver.cpp:242] Iteration 90000 (86.2911 iter/s, 1.15887s/100 iter), loss = 1.61652
I0506 04:44:05.746964 12834 solver.cpp:261]     Train net output #0: loss = 1.61652 (* 1 = 1.61652 loss)
I0506 04:44:05.746973 12834 sgd_solver.cpp:106] Iteration 90000, lr = 1.34218e-05
I0506 04:44:05.748797 12834 solver.cpp:362] Iteration 90000, Testing net (#0)
I0506 04:44:05.748811 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:05.877529 12834 solver.cpp:429]     Test net output #0: accuracy = 0.751
I0506 04:44:05.877557 12834 solver.cpp:429]     Test net output #1: loss = 0.601724 (* 1 = 0.601724 loss)
I0506 04:44:05.880103 12834 solver.cpp:242] Iteration 90000 (77.7149 iter/s, 1.28675s/100 iter), loss = 0.420594
I0506 04:44:05.880123 12834 solver.cpp:261]     Train net output #0: loss = 0.420594 (* 1 = 0.420594 loss)
I0506 04:44:05.880132 12834 sgd_solver.cpp:106] Iteration 90000, lr = 1.34218e-05
I0506 04:44:06.812796 12834 solver.cpp:242] Iteration 90100 (93.8259 iter/s, 1.0658s/100 iter), loss = 1.94272
I0506 04:44:06.812836 12834 solver.cpp:261]     Train net output #0: loss = 1.94272 (* 1 = 1.94272 loss)
I0506 04:44:06.812846 12834 sgd_solver.cpp:106] Iteration 90100, lr = 1.34218e-05
I0506 04:44:06.817596 12834 solver.cpp:242] Iteration 90100 (106.672 iter/s, 0.937455s/100 iter), loss = 0.709653
I0506 04:44:06.817621 12834 solver.cpp:261]     Train net output #0: loss = 0.709653 (* 1 = 0.709653 loss)
I0506 04:44:06.817631 12834 sgd_solver.cpp:106] Iteration 90100, lr = 1.34218e-05
I0506 04:44:07.750339 12834 solver.cpp:242] Iteration 90200 (106.67 iter/s, 0.937472s/100 iter), loss = 0.706606
I0506 04:44:07.750378 12834 solver.cpp:261]     Train net output #0: loss = 0.706606 (* 1 = 0.706606 loss)
I0506 04:44:07.750387 12834 sgd_solver.cpp:106] Iteration 90200, lr = 1.34218e-05
I0506 04:44:07.755115 12834 solver.cpp:242] Iteration 90200 (106.67 iter/s, 0.937475s/100 iter), loss = 0.568502
I0506 04:44:07.755141 12834 solver.cpp:261]     Train net output #0: loss = 0.568502 (* 1 = 0.568502 loss)
I0506 04:44:07.755151 12834 sgd_solver.cpp:106] Iteration 90200, lr = 1.34218e-05
I0506 04:44:08.688539 12834 solver.cpp:242] Iteration 90300 (106.594 iter/s, 0.938136s/100 iter), loss = 1.39988
I0506 04:44:08.688585 12834 solver.cpp:261]     Train net output #0: loss = 1.39988 (* 1 = 1.39988 loss)
I0506 04:44:08.688596 12834 sgd_solver.cpp:106] Iteration 90300, lr = 1.34218e-05
I0506 04:44:08.693401 12834 solver.cpp:242] Iteration 90300 (106.584 iter/s, 0.938231s/100 iter), loss = 0.539118
I0506 04:44:08.693428 12834 solver.cpp:261]     Train net output #0: loss = 0.539118 (* 1 = 0.539118 loss)
I0506 04:44:08.693436 12834 sgd_solver.cpp:106] Iteration 90300, lr = 1.34218e-05
I0506 04:44:09.626549 12834 solver.cpp:242] Iteration 90400 (106.617 iter/s, 0.937937s/100 iter), loss = 1.38719
I0506 04:44:09.626587 12834 solver.cpp:261]     Train net output #0: loss = 1.38719 (* 1 = 1.38719 loss)
I0506 04:44:09.626596 12834 sgd_solver.cpp:106] Iteration 90400, lr = 1.34218e-05
I0506 04:44:09.631319 12834 solver.cpp:242] Iteration 90400 (106.624 iter/s, 0.937873s/100 iter), loss = 0.769505
I0506 04:44:09.631342 12834 solver.cpp:261]     Train net output #0: loss = 0.769505 (* 1 = 0.769505 loss)
I0506 04:44:09.631351 12834 sgd_solver.cpp:106] Iteration 90400, lr = 1.34218e-05
I0506 04:44:10.561378 12834 solver.cpp:362] Iteration 90500, Testing net (#0)
I0506 04:44:10.561400 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:10.693145 12834 solver.cpp:429]     Test net output #0: loss = 1.36605 (* 1 = 1.36605 loss)
I0506 04:44:10.695725 12834 solver.cpp:242] Iteration 90500 (93.535 iter/s, 1.06912s/100 iter), loss = 2.96767
I0506 04:44:10.695749 12834 solver.cpp:261]     Train net output #0: loss = 2.96767 (* 1 = 2.96767 loss)
I0506 04:44:10.695757 12834 sgd_solver.cpp:106] Iteration 90500, lr = 1.34218e-05
I0506 04:44:10.697597 12834 solver.cpp:362] Iteration 90500, Testing net (#0)
I0506 04:44:10.697608 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:10.826683 12834 solver.cpp:429]     Test net output #0: accuracy = 0.762
I0506 04:44:10.826702 12834 solver.cpp:429]     Test net output #1: loss = 0.558747 (* 1 = 0.558747 loss)
I0506 04:44:10.829254 12834 solver.cpp:242] Iteration 90500 (83.4801 iter/s, 1.19789s/100 iter), loss = 0.780827
I0506 04:44:10.829275 12834 solver.cpp:261]     Train net output #0: loss = 0.780827 (* 1 = 0.780827 loss)
I0506 04:44:10.829284 12834 sgd_solver.cpp:106] Iteration 90500, lr = 1.34218e-05
I0506 04:44:11.762033 12834 solver.cpp:242] Iteration 90600 (93.7861 iter/s, 1.06626s/100 iter), loss = 0.662924
I0506 04:44:11.762080 12834 solver.cpp:261]     Train net output #0: loss = 0.662924 (* 1 = 0.662924 loss)
I0506 04:44:11.762090 12834 sgd_solver.cpp:106] Iteration 90600, lr = 1.34218e-05
I0506 04:44:11.766806 12834 solver.cpp:242] Iteration 90600 (106.665 iter/s, 0.937512s/100 iter), loss = 0.61583
I0506 04:44:11.766832 12834 solver.cpp:261]     Train net output #0: loss = 0.61583 (* 1 = 0.61583 loss)
I0506 04:44:11.766840 12834 sgd_solver.cpp:106] Iteration 90600, lr = 1.34218e-05
I0506 04:44:12.699447 12834 solver.cpp:242] Iteration 90700 (106.685 iter/s, 0.937336s/100 iter), loss = 1.79863
I0506 04:44:12.699483 12834 solver.cpp:261]     Train net output #0: loss = 1.79863 (* 1 = 1.79863 loss)
I0506 04:44:12.699492 12834 sgd_solver.cpp:106] Iteration 90700, lr = 1.34218e-05
I0506 04:44:12.704223 12834 solver.cpp:242] Iteration 90700 (106.681 iter/s, 0.937374s/100 iter), loss = 0.512897
I0506 04:44:12.704246 12834 solver.cpp:261]     Train net output #0: loss = 0.512897 (* 1 = 0.512897 loss)
I0506 04:44:12.704255 12834 sgd_solver.cpp:106] Iteration 90700, lr = 1.34218e-05
I0506 04:44:13.637832 12834 solver.cpp:242] Iteration 90800 (106.573 iter/s, 0.938323s/100 iter), loss = 3.83658
I0506 04:44:13.637867 12834 solver.cpp:261]     Train net output #0: loss = 3.83658 (* 1 = 3.83658 loss)
I0506 04:44:13.637876 12834 sgd_solver.cpp:106] Iteration 90800, lr = 1.34218e-05
I0506 04:44:13.642608 12834 solver.cpp:242] Iteration 90800 (106.571 iter/s, 0.938343s/100 iter), loss = 0.740134
I0506 04:44:13.642632 12834 solver.cpp:261]     Train net output #0: loss = 0.740134 (* 1 = 0.740134 loss)
I0506 04:44:13.642642 12834 sgd_solver.cpp:106] Iteration 90800, lr = 1.34218e-05
I0506 04:44:14.575327 12834 solver.cpp:242] Iteration 90900 (106.675 iter/s, 0.937429s/100 iter), loss = 2.36262
I0506 04:44:14.575358 12834 solver.cpp:261]     Train net output #0: loss = 2.36262 (* 1 = 2.36262 loss)
I0506 04:44:14.575367 12834 sgd_solver.cpp:106] Iteration 90900, lr = 1.34218e-05
I0506 04:44:14.580409 12834 solver.cpp:242] Iteration 90900 (106.637 iter/s, 0.937757s/100 iter), loss = 0.605582
I0506 04:44:14.580437 12834 solver.cpp:261]     Train net output #0: loss = 0.605582 (* 1 = 0.605582 loss)
I0506 04:44:14.580448 12834 sgd_solver.cpp:106] Iteration 90900, lr = 1.34218e-05
I0506 04:44:15.523809 12834 solver.cpp:362] Iteration 91000, Testing net (#0)
I0506 04:44:15.523838 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:15.646592 12834 solver.cpp:429]     Test net output #0: loss = 1.52211 (* 1 = 1.52211 loss)
I0506 04:44:15.649111 12834 solver.cpp:242] Iteration 91000 (93.133 iter/s, 1.07373s/100 iter), loss = 1.43792
I0506 04:44:15.649132 12834 solver.cpp:261]     Train net output #0: loss = 1.43792 (* 1 = 1.43792 loss)
I0506 04:44:15.649140 12834 sgd_solver.cpp:106] Iteration 91000, lr = 1.34218e-05
I0506 04:44:15.650964 12834 solver.cpp:362] Iteration 91000, Testing net (#0)
I0506 04:44:15.650976 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:15.779811 12834 solver.cpp:429]     Test net output #0: accuracy = 0.757
I0506 04:44:15.779830 12834 solver.cpp:429]     Test net output #1: loss = 0.567808 (* 1 = 0.567808 loss)
I0506 04:44:15.782395 12834 solver.cpp:242] Iteration 91000 (83.199 iter/s, 1.20194s/100 iter), loss = 0.47346
I0506 04:44:15.782415 12834 solver.cpp:261]     Train net output #0: loss = 0.47346 (* 1 = 0.47346 loss)
I0506 04:44:15.782424 12834 sgd_solver.cpp:106] Iteration 91000, lr = 1.34218e-05
I0506 04:44:16.729606 12834 solver.cpp:242] Iteration 91100 (92.555 iter/s, 1.08044s/100 iter), loss = 0.617585
I0506 04:44:16.729657 12834 solver.cpp:261]     Train net output #0: loss = 0.617585 (* 1 = 0.617585 loss)
I0506 04:44:16.729668 12834 sgd_solver.cpp:106] Iteration 91100, lr = 1.34218e-05
I0506 04:44:16.734895 12834 solver.cpp:242] Iteration 91100 (104.991 iter/s, 0.952459s/100 iter), loss = 0.750789
I0506 04:44:16.734925 12834 solver.cpp:261]     Train net output #0: loss = 0.750789 (* 1 = 0.750789 loss)
I0506 04:44:16.734935 12834 sgd_solver.cpp:106] Iteration 91100, lr = 1.34218e-05
I0506 04:44:17.758435 12834 solver.cpp:242] Iteration 91200 (97.2051 iter/s, 1.02875s/100 iter), loss = 1.30576
I0506 04:44:17.758476 12834 solver.cpp:261]     Train net output #0: loss = 1.30576 (* 1 = 1.30576 loss)
I0506 04:44:17.758484 12834 sgd_solver.cpp:106] Iteration 91200, lr = 1.34218e-05
I0506 04:44:17.763285 12834 solver.cpp:242] Iteration 91200 (97.2448 iter/s, 1.02833s/100 iter), loss = 0.737256
I0506 04:44:17.763309 12834 solver.cpp:261]     Train net output #0: loss = 0.737256 (* 1 = 0.737256 loss)
I0506 04:44:17.763319 12834 sgd_solver.cpp:106] Iteration 91200, lr = 1.34218e-05
I0506 04:44:18.696240 12834 solver.cpp:242] Iteration 91300 (106.639 iter/s, 0.937739s/100 iter), loss = 3.27725
I0506 04:44:18.696283 12834 solver.cpp:261]     Train net output #0: loss = 3.27725 (* 1 = 3.27725 loss)
I0506 04:44:18.696293 12834 sgd_solver.cpp:106] Iteration 91300, lr = 1.34218e-05
I0506 04:44:18.701023 12834 solver.cpp:242] Iteration 91300 (106.644 iter/s, 0.937695s/100 iter), loss = 0.377655
I0506 04:44:18.701050 12834 solver.cpp:261]     Train net output #0: loss = 0.377655 (* 1 = 0.377655 loss)
I0506 04:44:18.701059 12834 sgd_solver.cpp:106] Iteration 91300, lr = 1.34218e-05
I0506 04:44:19.634307 12834 solver.cpp:242] Iteration 91400 (106.611 iter/s, 0.937991s/100 iter), loss = 0.842573
I0506 04:44:19.634349 12834 solver.cpp:261]     Train net output #0: loss = 0.842573 (* 1 = 0.842573 loss)
I0506 04:44:19.634358 12834 sgd_solver.cpp:106] Iteration 91400, lr = 1.34218e-05
I0506 04:44:19.639081 12834 solver.cpp:242] Iteration 91400 (106.608 iter/s, 0.938013s/100 iter), loss = 0.402695
I0506 04:44:19.639106 12834 solver.cpp:261]     Train net output #0: loss = 0.402695 (* 1 = 0.402695 loss)
I0506 04:44:19.639114 12834 sgd_solver.cpp:106] Iteration 91400, lr = 1.34218e-05
I0506 04:44:20.568532 12834 solver.cpp:362] Iteration 91500, Testing net (#0)
I0506 04:44:20.568563 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:20.691233 12834 solver.cpp:429]     Test net output #0: loss = 1.31913 (* 1 = 1.31913 loss)
I0506 04:44:20.693766 12834 solver.cpp:242] Iteration 91500 (94.3933 iter/s, 1.0594s/100 iter), loss = 1.39874
I0506 04:44:20.693794 12834 solver.cpp:261]     Train net output #0: loss = 1.39874 (* 1 = 1.39874 loss)
I0506 04:44:20.694044 12834 sgd_solver.cpp:106] Iteration 91500, lr = 1.34218e-05
I0506 04:44:20.695921 12834 solver.cpp:362] Iteration 91500, Testing net (#0)
I0506 04:44:20.695936 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:20.824434 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7655
I0506 04:44:20.824453 12834 solver.cpp:429]     Test net output #1: loss = 0.546634 (* 1 = 0.546634 loss)
I0506 04:44:20.827028 12834 solver.cpp:242] Iteration 91500 (84.1822 iter/s, 1.1879s/100 iter), loss = 0.530063
I0506 04:44:20.827049 12834 solver.cpp:261]     Train net output #0: loss = 0.530063 (* 1 = 0.530063 loss)
I0506 04:44:20.827057 12834 sgd_solver.cpp:106] Iteration 91500, lr = 1.34218e-05
I0506 04:44:21.760210 12834 solver.cpp:242] Iteration 91600 (93.7749 iter/s, 1.06638s/100 iter), loss = 1.97217
I0506 04:44:21.760251 12834 solver.cpp:261]     Train net output #0: loss = 1.97217 (* 1 = 1.97217 loss)
I0506 04:44:21.760260 12834 sgd_solver.cpp:106] Iteration 91600, lr = 1.34218e-05
I0506 04:44:21.764981 12834 solver.cpp:242] Iteration 91600 (106.62 iter/s, 0.937914s/100 iter), loss = 0.63581
I0506 04:44:21.765008 12834 solver.cpp:261]     Train net output #0: loss = 0.63581 (* 1 = 0.63581 loss)
I0506 04:44:21.765017 12834 sgd_solver.cpp:106] Iteration 91600, lr = 1.34218e-05
I0506 04:44:22.697245 12834 solver.cpp:242] Iteration 91700 (106.727 iter/s, 0.936967s/100 iter), loss = 0.466715
I0506 04:44:22.697285 12834 solver.cpp:261]     Train net output #0: loss = 0.466715 (* 1 = 0.466715 loss)
I0506 04:44:22.697295 12834 sgd_solver.cpp:106] Iteration 91700, lr = 1.34218e-05
I0506 04:44:22.702013 12834 solver.cpp:242] Iteration 91700 (106.725 iter/s, 0.936987s/100 iter), loss = 0.354005
I0506 04:44:22.702038 12834 solver.cpp:261]     Train net output #0: loss = 0.354005 (* 1 = 0.354005 loss)
I0506 04:44:22.702056 12834 sgd_solver.cpp:106] Iteration 91700, lr = 1.34218e-05
I0506 04:44:23.634963 12834 solver.cpp:242] Iteration 91800 (106.65 iter/s, 0.937647s/100 iter), loss = 2.21388
I0506 04:44:23.634999 12834 solver.cpp:261]     Train net output #0: loss = 2.21388 (* 1 = 2.21388 loss)
I0506 04:44:23.635010 12834 sgd_solver.cpp:106] Iteration 91800, lr = 1.34218e-05
I0506 04:44:23.639761 12834 solver.cpp:242] Iteration 91800 (106.643 iter/s, 0.937705s/100 iter), loss = 0.688867
I0506 04:44:23.639786 12834 solver.cpp:261]     Train net output #0: loss = 0.688867 (* 1 = 0.688867 loss)
I0506 04:44:23.639794 12834 sgd_solver.cpp:106] Iteration 91800, lr = 1.34218e-05
I0506 04:44:24.572412 12834 solver.cpp:242] Iteration 91900 (106.68 iter/s, 0.937386s/100 iter), loss = 1.31045
I0506 04:44:24.572448 12834 solver.cpp:261]     Train net output #0: loss = 1.31045 (* 1 = 1.31045 loss)
I0506 04:44:24.572458 12834 sgd_solver.cpp:106] Iteration 91900, lr = 1.34218e-05
I0506 04:44:24.577179 12834 solver.cpp:242] Iteration 91900 (106.681 iter/s, 0.937376s/100 iter), loss = 0.478994
I0506 04:44:24.577205 12834 solver.cpp:261]     Train net output #0: loss = 0.478994 (* 1 = 0.478994 loss)
I0506 04:44:24.577214 12834 sgd_solver.cpp:106] Iteration 91900, lr = 1.34218e-05
I0506 04:44:25.506686 12834 solver.cpp:362] Iteration 92000, Testing net (#0)
I0506 04:44:25.506709 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:25.629480 12834 solver.cpp:429]     Test net output #0: loss = 1.43474 (* 1 = 1.43474 loss)
I0506 04:44:25.631994 12834 solver.cpp:242] Iteration 92000 (94.3815 iter/s, 1.05953s/100 iter), loss = 1.60342
I0506 04:44:25.632014 12834 solver.cpp:261]     Train net output #0: loss = 1.60342 (* 1 = 1.60342 loss)
I0506 04:44:25.632022 12834 sgd_solver.cpp:106] Iteration 92000, lr = 1.34218e-05
I0506 04:44:25.633839 12834 solver.cpp:362] Iteration 92000, Testing net (#0)
I0506 04:44:25.633854 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:25.762850 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7565
I0506 04:44:25.762876 12834 solver.cpp:429]     Test net output #1: loss = 0.556167 (* 1 = 0.556167 loss)
I0506 04:44:25.765492 12834 solver.cpp:242] Iteration 92000 (84.1562 iter/s, 1.18827s/100 iter), loss = 0.478119
I0506 04:44:25.765513 12834 solver.cpp:261]     Train net output #0: loss = 0.478119 (* 1 = 0.478119 loss)
I0506 04:44:25.765522 12834 sgd_solver.cpp:106] Iteration 92000, lr = 1.34218e-05
I0506 04:44:26.698133 12834 solver.cpp:242] Iteration 92100 (93.8004 iter/s, 1.06609s/100 iter), loss = 1.19672
I0506 04:44:26.698168 12834 solver.cpp:261]     Train net output #0: loss = 1.19672 (* 1 = 1.19672 loss)
I0506 04:44:26.698176 12834 sgd_solver.cpp:106] Iteration 92100, lr = 1.34218e-05
I0506 04:44:26.702963 12834 solver.cpp:242] Iteration 92100 (106.676 iter/s, 0.937422s/100 iter), loss = 0.522144
I0506 04:44:26.702987 12834 solver.cpp:261]     Train net output #0: loss = 0.522144 (* 1 = 0.522144 loss)
I0506 04:44:26.702996 12834 sgd_solver.cpp:106] Iteration 92100, lr = 1.34218e-05
I0506 04:44:27.635247 12834 solver.cpp:242] Iteration 92200 (106.717 iter/s, 0.937054s/100 iter), loss = 0.936255
I0506 04:44:27.635277 12834 solver.cpp:261]     Train net output #0: loss = 0.936255 (* 1 = 0.936255 loss)
I0506 04:44:27.635287 12834 sgd_solver.cpp:106] Iteration 92200, lr = 1.34218e-05
I0506 04:44:27.640022 12834 solver.cpp:242] Iteration 92200 (106.722 iter/s, 0.937016s/100 iter), loss = 0.685015
I0506 04:44:27.640045 12834 solver.cpp:261]     Train net output #0: loss = 0.685015 (* 1 = 0.685015 loss)
I0506 04:44:27.640054 12834 sgd_solver.cpp:106] Iteration 92200, lr = 1.34218e-05
I0506 04:44:28.572528 12834 solver.cpp:242] Iteration 92300 (106.698 iter/s, 0.937226s/100 iter), loss = 0.963713
I0506 04:44:28.572585 12834 solver.cpp:261]     Train net output #0: loss = 0.963713 (* 1 = 0.963713 loss)
I0506 04:44:28.572595 12834 sgd_solver.cpp:106] Iteration 92300, lr = 1.34218e-05
I0506 04:44:28.577330 12834 solver.cpp:242] Iteration 92300 (106.694 iter/s, 0.937257s/100 iter), loss = 0.470582
I0506 04:44:28.577370 12834 solver.cpp:261]     Train net output #0: loss = 0.470582 (* 1 = 0.470582 loss)
I0506 04:44:28.577383 12834 sgd_solver.cpp:106] Iteration 92300, lr = 1.34218e-05
I0506 04:44:29.607580 12834 solver.cpp:242] Iteration 92400 (96.6214 iter/s, 1.03497s/100 iter), loss = 0.469589
I0506 04:44:29.607630 12834 solver.cpp:261]     Train net output #0: loss = 0.469589 (* 1 = 0.469589 loss)
I0506 04:44:29.607640 12834 sgd_solver.cpp:106] Iteration 92400, lr = 1.34218e-05
I0506 04:44:29.612877 12834 solver.cpp:242] Iteration 92400 (96.5729 iter/s, 1.03549s/100 iter), loss = 0.446568
I0506 04:44:29.612907 12834 solver.cpp:261]     Train net output #0: loss = 0.446568 (* 1 = 0.446568 loss)
I0506 04:44:29.612918 12834 sgd_solver.cpp:106] Iteration 92400, lr = 1.34218e-05
I0506 04:44:30.550443 12834 solver.cpp:362] Iteration 92500, Testing net (#0)
I0506 04:44:30.550472 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:30.681437 12834 solver.cpp:429]     Test net output #0: loss = 1.50677 (* 1 = 1.50677 loss)
I0506 04:44:30.684095 12834 solver.cpp:242] Iteration 92500 (92.8982 iter/s, 1.07645s/100 iter), loss = 0.740526
I0506 04:44:30.684119 12834 solver.cpp:261]     Train net output #0: loss = 0.740526 (* 1 = 0.740526 loss)
I0506 04:44:30.684130 12834 sgd_solver.cpp:106] Iteration 92500, lr = 1.34218e-05
I0506 04:44:30.686342 12834 solver.cpp:362] Iteration 92500, Testing net (#0)
I0506 04:44:30.686360 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:30.826961 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7395
I0506 04:44:30.826987 12834 solver.cpp:429]     Test net output #1: loss = 0.58217 (* 1 = 0.58217 loss)
I0506 04:44:30.829799 12834 solver.cpp:242] Iteration 92500 (82.1779 iter/s, 1.21687s/100 iter), loss = 0.542491
I0506 04:44:30.829821 12834 solver.cpp:261]     Train net output #0: loss = 0.542491 (* 1 = 0.542491 loss)
I0506 04:44:30.829830 12834 sgd_solver.cpp:106] Iteration 92500, lr = 1.34218e-05
I0506 04:44:31.762900 12834 solver.cpp:242] Iteration 92600 (92.6996 iter/s, 1.07875s/100 iter), loss = 1.8197
I0506 04:44:31.762936 12834 solver.cpp:261]     Train net output #0: loss = 1.8197 (* 1 = 1.8197 loss)
I0506 04:44:31.762945 12834 sgd_solver.cpp:106] Iteration 92600, lr = 1.34218e-05
I0506 04:44:31.767701 12834 solver.cpp:242] Iteration 92600 (106.626 iter/s, 0.93786s/100 iter), loss = 0.381636
I0506 04:44:31.767726 12834 solver.cpp:261]     Train net output #0: loss = 0.381636 (* 1 = 0.381636 loss)
I0506 04:44:31.767735 12834 sgd_solver.cpp:106] Iteration 92600, lr = 1.34218e-05
I0506 04:44:32.700449 12834 solver.cpp:242] Iteration 92700 (106.669 iter/s, 0.937481s/100 iter), loss = 3.21371
I0506 04:44:32.700490 12834 solver.cpp:261]     Train net output #0: loss = 3.21371 (* 1 = 3.21371 loss)
I0506 04:44:32.700500 12834 sgd_solver.cpp:106] Iteration 92700, lr = 1.34218e-05
I0506 04:44:32.705238 12834 solver.cpp:242] Iteration 92700 (106.667 iter/s, 0.937495s/100 iter), loss = 0.59046
I0506 04:44:32.705263 12834 solver.cpp:261]     Train net output #0: loss = 0.59046 (* 1 = 0.59046 loss)
I0506 04:44:32.705273 12834 sgd_solver.cpp:106] Iteration 92700, lr = 1.34218e-05
I0506 04:44:33.637652 12834 solver.cpp:242] Iteration 92800 (106.708 iter/s, 0.937137s/100 iter), loss = 0.888282
I0506 04:44:33.637693 12834 solver.cpp:261]     Train net output #0: loss = 0.888282 (* 1 = 0.888282 loss)
I0506 04:44:33.637702 12834 sgd_solver.cpp:106] Iteration 92800, lr = 1.34218e-05
I0506 04:44:33.642429 12834 solver.cpp:242] Iteration 92800 (106.707 iter/s, 0.937148s/100 iter), loss = 0.435332
I0506 04:44:33.642454 12834 solver.cpp:261]     Train net output #0: loss = 0.435332 (* 1 = 0.435332 loss)
I0506 04:44:33.642463 12834 sgd_solver.cpp:106] Iteration 92800, lr = 1.34218e-05
I0506 04:44:34.575146 12834 solver.cpp:242] Iteration 92900 (106.675 iter/s, 0.937423s/100 iter), loss = 0.944084
I0506 04:44:34.575186 12834 solver.cpp:261]     Train net output #0: loss = 0.944084 (* 1 = 0.944084 loss)
I0506 04:44:34.575204 12834 sgd_solver.cpp:106] Iteration 92900, lr = 1.34218e-05
I0506 04:44:34.580191 12834 solver.cpp:242] Iteration 92900 (106.642 iter/s, 0.937718s/100 iter), loss = 0.566321
I0506 04:44:34.580221 12834 solver.cpp:261]     Train net output #0: loss = 0.566321 (* 1 = 0.566321 loss)
I0506 04:44:34.580232 12834 sgd_solver.cpp:106] Iteration 92900, lr = 1.34218e-05
I0506 04:44:35.607488 12834 solver.cpp:362] Iteration 93000, Testing net (#0)
I0506 04:44:35.607518 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:35.740672 12834 solver.cpp:429]     Test net output #0: loss = 1.67711 (* 1 = 1.67711 loss)
I0506 04:44:35.743330 12834 solver.cpp:242] Iteration 93000 (85.6074 iter/s, 1.16812s/100 iter), loss = 1.2565
I0506 04:44:35.743358 12834 solver.cpp:261]     Train net output #0: loss = 1.2565 (* 1 = 1.2565 loss)
I0506 04:44:35.743368 12834 sgd_solver.cpp:106] Iteration 93000, lr = 1.34218e-05
I0506 04:44:35.745676 12834 solver.cpp:362] Iteration 93000, Testing net (#0)
I0506 04:44:35.745692 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:35.886440 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7345
I0506 04:44:35.886466 12834 solver.cpp:429]     Test net output #1: loss = 0.602509 (* 1 = 0.602509 loss)
I0506 04:44:35.889276 12834 solver.cpp:242] Iteration 93000 (76.3923 iter/s, 1.30903s/100 iter), loss = 0.582317
I0506 04:44:35.889297 12834 solver.cpp:261]     Train net output #0: loss = 0.582317 (* 1 = 0.582317 loss)
I0506 04:44:35.889305 12834 sgd_solver.cpp:106] Iteration 93000, lr = 1.34218e-05
I0506 04:44:36.847059 12834 solver.cpp:242] Iteration 93100 (90.6069 iter/s, 1.10367s/100 iter), loss = 2.19965
I0506 04:44:36.847105 12834 solver.cpp:261]     Train net output #0: loss = 2.19965 (* 1 = 2.19965 loss)
I0506 04:44:36.847116 12834 sgd_solver.cpp:106] Iteration 93100, lr = 1.34218e-05
I0506 04:44:36.852360 12834 solver.cpp:242] Iteration 93100 (103.838 iter/s, 0.963043s/100 iter), loss = 0.878226
I0506 04:44:36.852392 12834 solver.cpp:261]     Train net output #0: loss = 0.878226 (* 1 = 0.878226 loss)
I0506 04:44:36.852402 12834 sgd_solver.cpp:106] Iteration 93100, lr = 1.34218e-05
I0506 04:44:37.864751 12834 solver.cpp:242] Iteration 93200 (98.2683 iter/s, 1.01762s/100 iter), loss = 0.592176
I0506 04:44:37.864792 12834 solver.cpp:261]     Train net output #0: loss = 0.592176 (* 1 = 0.592176 loss)
I0506 04:44:37.864801 12834 sgd_solver.cpp:106] Iteration 93200, lr = 1.34218e-05
I0506 04:44:37.869637 12834 solver.cpp:242] Iteration 93200 (98.3072 iter/s, 1.01722s/100 iter), loss = 0.276019
I0506 04:44:37.869663 12834 solver.cpp:261]     Train net output #0: loss = 0.276019 (* 1 = 0.276019 loss)
I0506 04:44:37.869673 12834 sgd_solver.cpp:106] Iteration 93200, lr = 1.34218e-05
I0506 04:44:38.816004 12834 solver.cpp:242] Iteration 93300 (105.132 iter/s, 0.951183s/100 iter), loss = 1.34381
I0506 04:44:38.816043 12834 solver.cpp:261]     Train net output #0: loss = 1.34381 (* 1 = 1.34381 loss)
I0506 04:44:38.816052 12834 sgd_solver.cpp:106] Iteration 93300, lr = 1.34218e-05
I0506 04:44:38.820773 12834 solver.cpp:242] Iteration 93300 (105.142 iter/s, 0.951092s/100 iter), loss = 0.287015
I0506 04:44:38.820798 12834 solver.cpp:261]     Train net output #0: loss = 0.287015 (* 1 = 0.287015 loss)
I0506 04:44:38.820807 12834 sgd_solver.cpp:106] Iteration 93300, lr = 1.34218e-05
I0506 04:44:39.753527 12834 solver.cpp:242] Iteration 93400 (106.672 iter/s, 0.937454s/100 iter), loss = 1.62131
I0506 04:44:39.753566 12834 solver.cpp:261]     Train net output #0: loss = 1.62131 (* 1 = 1.62131 loss)
I0506 04:44:39.753574 12834 sgd_solver.cpp:106] Iteration 93400, lr = 1.34218e-05
I0506 04:44:39.758301 12834 solver.cpp:242] Iteration 93400 (106.669 iter/s, 0.937483s/100 iter), loss = 0.676237
I0506 04:44:39.758323 12834 solver.cpp:261]     Train net output #0: loss = 0.676237 (* 1 = 0.676237 loss)
I0506 04:44:39.758332 12834 sgd_solver.cpp:106] Iteration 93400, lr = 1.34218e-05
I0506 04:44:40.688094 12834 solver.cpp:362] Iteration 93500, Testing net (#0)
I0506 04:44:40.688118 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:40.810835 12834 solver.cpp:429]     Test net output #0: loss = 1.48209 (* 1 = 1.48209 loss)
I0506 04:44:40.813346 12834 solver.cpp:242] Iteration 93500 (94.3608 iter/s, 1.05976s/100 iter), loss = 3.00078
I0506 04:44:40.813367 12834 solver.cpp:261]     Train net output #0: loss = 3.00078 (* 1 = 3.00078 loss)
I0506 04:44:40.813376 12834 sgd_solver.cpp:106] Iteration 93500, lr = 1.34218e-05
I0506 04:44:40.815196 12834 solver.cpp:362] Iteration 93500, Testing net (#0)
I0506 04:44:40.815208 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:40.943699 12834 solver.cpp:429]     Test net output #0: accuracy = 0.757
I0506 04:44:40.943722 12834 solver.cpp:429]     Test net output #1: loss = 0.565319 (* 1 = 0.565319 loss)
I0506 04:44:40.946384 12834 solver.cpp:242] Iteration 93500 (84.1723 iter/s, 1.18804s/100 iter), loss = 0.829905
I0506 04:44:40.946406 12834 solver.cpp:261]     Train net output #0: loss = 0.829905 (* 1 = 0.829905 loss)
I0506 04:44:40.946415 12834 sgd_solver.cpp:106] Iteration 93500, lr = 1.34218e-05
I0506 04:44:41.879447 12834 solver.cpp:242] Iteration 93600 (93.8046 iter/s, 1.06605s/100 iter), loss = 0.542587
I0506 04:44:41.879485 12834 solver.cpp:261]     Train net output #0: loss = 0.542587 (* 1 = 0.542587 loss)
I0506 04:44:41.879495 12834 sgd_solver.cpp:106] Iteration 93600, lr = 1.34218e-05
I0506 04:44:41.884230 12834 solver.cpp:242] Iteration 93600 (106.632 iter/s, 0.937806s/100 iter), loss = 0.625166
I0506 04:44:41.884254 12834 solver.cpp:261]     Train net output #0: loss = 0.625166 (* 1 = 0.625166 loss)
I0506 04:44:41.884263 12834 sgd_solver.cpp:106] Iteration 93600, lr = 1.34218e-05
I0506 04:44:42.816608 12834 solver.cpp:242] Iteration 93700 (106.712 iter/s, 0.937098s/100 iter), loss = 0.589249
I0506 04:44:42.816642 12834 solver.cpp:261]     Train net output #0: loss = 0.589249 (* 1 = 0.589249 loss)
I0506 04:44:42.816651 12834 sgd_solver.cpp:106] Iteration 93700, lr = 1.34218e-05
I0506 04:44:42.821379 12834 solver.cpp:242] Iteration 93700 (106.711 iter/s, 0.937106s/100 iter), loss = 0.436144
I0506 04:44:42.821403 12834 solver.cpp:261]     Train net output #0: loss = 0.436144 (* 1 = 0.436144 loss)
I0506 04:44:42.821411 12834 sgd_solver.cpp:106] Iteration 93700, lr = 1.34218e-05
I0506 04:44:43.754582 12834 solver.cpp:242] Iteration 93800 (106.62 iter/s, 0.937908s/100 iter), loss = 2.0797
I0506 04:44:43.754623 12834 solver.cpp:261]     Train net output #0: loss = 2.0797 (* 1 = 2.0797 loss)
I0506 04:44:43.754633 12834 sgd_solver.cpp:106] Iteration 93800, lr = 1.34218e-05
I0506 04:44:43.759382 12834 solver.cpp:242] Iteration 93800 (106.614 iter/s, 0.937961s/100 iter), loss = 0.56595
I0506 04:44:43.759407 12834 solver.cpp:261]     Train net output #0: loss = 0.56595 (* 1 = 0.56595 loss)
I0506 04:44:43.759416 12834 sgd_solver.cpp:106] Iteration 93800, lr = 1.34218e-05
I0506 04:44:44.704176 12834 solver.cpp:242] Iteration 93900 (105.316 iter/s, 0.949527s/100 iter), loss = 5.95999
I0506 04:44:44.704226 12834 solver.cpp:261]     Train net output #0: loss = 5.95999 (* 1 = 5.95999 loss)
I0506 04:44:44.704238 12834 sgd_solver.cpp:106] Iteration 93900, lr = 1.34218e-05
I0506 04:44:44.709569 12834 solver.cpp:242] Iteration 93900 (105.249 iter/s, 0.95013s/100 iter), loss = 0.706316
I0506 04:44:44.709601 12834 solver.cpp:261]     Train net output #0: loss = 0.706316 (* 1 = 0.706316 loss)
I0506 04:44:44.709612 12834 sgd_solver.cpp:106] Iteration 93900, lr = 1.34218e-05
I0506 04:44:45.640393 12834 solver.cpp:362] Iteration 94000, Testing net (#0)
I0506 04:44:45.640421 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:45.763169 12834 solver.cpp:429]     Test net output #0: loss = 1.55622 (* 1 = 1.55622 loss)
I0506 04:44:45.765702 12834 solver.cpp:242] Iteration 94000 (94.21 iter/s, 1.06146s/100 iter), loss = 1.74848
I0506 04:44:45.765724 12834 solver.cpp:261]     Train net output #0: loss = 1.74848 (* 1 = 1.74848 loss)
I0506 04:44:45.765733 12834 sgd_solver.cpp:106] Iteration 94000, lr = 1.34218e-05
I0506 04:44:45.767545 12834 solver.cpp:362] Iteration 94000, Testing net (#0)
I0506 04:44:45.767568 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:45.896127 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7315
I0506 04:44:45.896145 12834 solver.cpp:429]     Test net output #1: loss = 0.63198 (* 1 = 0.63198 loss)
I0506 04:44:45.898690 12834 solver.cpp:242] Iteration 94000 (84.0994 iter/s, 1.18907s/100 iter), loss = 0.582922
I0506 04:44:45.898710 12834 solver.cpp:261]     Train net output #0: loss = 0.582922 (* 1 = 0.582922 loss)
I0506 04:44:45.898720 12834 sgd_solver.cpp:106] Iteration 94000, lr = 1.34218e-05
I0506 04:44:46.831221 12834 solver.cpp:242] Iteration 94100 (93.8553 iter/s, 1.06547s/100 iter), loss = 1.1
I0506 04:44:46.831265 12834 solver.cpp:261]     Train net output #0: loss = 1.1 (* 1 = 1.1 loss)
I0506 04:44:46.831274 12834 sgd_solver.cpp:106] Iteration 94100, lr = 1.34218e-05
I0506 04:44:46.836119 12834 solver.cpp:242] Iteration 94100 (106.68 iter/s, 0.937382s/100 iter), loss = 0.527492
I0506 04:44:46.836145 12834 solver.cpp:261]     Train net output #0: loss = 0.527492 (* 1 = 0.527492 loss)
I0506 04:44:46.836154 12834 sgd_solver.cpp:106] Iteration 94100, lr = 1.34218e-05
I0506 04:44:47.768699 12834 solver.cpp:242] Iteration 94200 (106.677 iter/s, 0.937407s/100 iter), loss = 0.447605
I0506 04:44:47.768739 12834 solver.cpp:261]     Train net output #0: loss = 0.447605 (* 1 = 0.447605 loss)
I0506 04:44:47.768748 12834 sgd_solver.cpp:106] Iteration 94200, lr = 1.34218e-05
I0506 04:44:47.773475 12834 solver.cpp:242] Iteration 94200 (106.688 iter/s, 0.937311s/100 iter), loss = 0.32076
I0506 04:44:47.773501 12834 solver.cpp:261]     Train net output #0: loss = 0.32076 (* 1 = 0.32076 loss)
I0506 04:44:47.773510 12834 sgd_solver.cpp:106] Iteration 94200, lr = 1.34218e-05
I0506 04:44:48.707074 12834 solver.cpp:242] Iteration 94300 (106.575 iter/s, 0.938303s/100 iter), loss = 0.56712
I0506 04:44:48.707115 12834 solver.cpp:261]     Train net output #0: loss = 0.56712 (* 1 = 0.56712 loss)
I0506 04:44:48.707125 12834 sgd_solver.cpp:106] Iteration 94300, lr = 1.34218e-05
I0506 04:44:48.711875 12834 solver.cpp:242] Iteration 94300 (106.569 iter/s, 0.938356s/100 iter), loss = 0.512841
I0506 04:44:48.711900 12834 solver.cpp:261]     Train net output #0: loss = 0.512841 (* 1 = 0.512841 loss)
I0506 04:44:48.711910 12834 sgd_solver.cpp:106] Iteration 94300, lr = 1.34218e-05
I0506 04:44:49.644675 12834 solver.cpp:242] Iteration 94400 (106.663 iter/s, 0.937533s/100 iter), loss = 1.46154
I0506 04:44:49.644713 12834 solver.cpp:261]     Train net output #0: loss = 1.46154 (* 1 = 1.46154 loss)
I0506 04:44:49.644723 12834 sgd_solver.cpp:106] Iteration 94400, lr = 1.34218e-05
I0506 04:44:49.649446 12834 solver.cpp:242] Iteration 94400 (106.664 iter/s, 0.937526s/100 iter), loss = 0.675885
I0506 04:44:49.649468 12834 solver.cpp:261]     Train net output #0: loss = 0.675885 (* 1 = 0.675885 loss)
I0506 04:44:49.649477 12834 sgd_solver.cpp:106] Iteration 94400, lr = 1.34218e-05
I0506 04:44:50.580196 12834 solver.cpp:362] Iteration 94500, Testing net (#0)
I0506 04:44:50.580226 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:50.713407 12834 solver.cpp:429]     Test net output #0: loss = 1.39971 (* 1 = 1.39971 loss)
I0506 04:44:50.716056 12834 solver.cpp:242] Iteration 94500 (93.3425 iter/s, 1.07132s/100 iter), loss = 0.912058
I0506 04:44:50.716080 12834 solver.cpp:261]     Train net output #0: loss = 0.912058 (* 1 = 0.912058 loss)
I0506 04:44:50.716091 12834 sgd_solver.cpp:106] Iteration 94500, lr = 1.34218e-05
I0506 04:44:50.718282 12834 solver.cpp:362] Iteration 94500, Testing net (#0)
I0506 04:44:50.718299 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:50.847278 12834 solver.cpp:429]     Test net output #0: accuracy = 0.699
I0506 04:44:50.847298 12834 solver.cpp:429]     Test net output #1: loss = 0.665395 (* 1 = 0.665395 loss)
I0506 04:44:50.849867 12834 solver.cpp:242] Iteration 94500 (83.3071 iter/s, 1.20038s/100 iter), loss = 0.541929
I0506 04:44:50.849887 12834 solver.cpp:261]     Train net output #0: loss = 0.541929 (* 1 = 0.541929 loss)
I0506 04:44:50.849905 12834 sgd_solver.cpp:106] Iteration 94500, lr = 1.34218e-05
I0506 04:44:51.782660 12834 solver.cpp:242] Iteration 94600 (93.76 iter/s, 1.06655s/100 iter), loss = 0.871926
I0506 04:44:51.782699 12834 solver.cpp:261]     Train net output #0: loss = 0.871926 (* 1 = 0.871926 loss)
I0506 04:44:51.782708 12834 sgd_solver.cpp:106] Iteration 94600, lr = 1.34218e-05
I0506 04:44:51.787442 12834 solver.cpp:242] Iteration 94600 (106.663 iter/s, 0.937535s/100 iter), loss = 0.439152
I0506 04:44:51.787467 12834 solver.cpp:261]     Train net output #0: loss = 0.439152 (* 1 = 0.439152 loss)
I0506 04:44:51.787475 12834 sgd_solver.cpp:106] Iteration 94600, lr = 1.34218e-05
I0506 04:44:52.740229 12834 solver.cpp:242] Iteration 94700 (104.439 iter/s, 0.957496s/100 iter), loss = 1.26796
I0506 04:44:52.740276 12834 solver.cpp:261]     Train net output #0: loss = 1.26796 (* 1 = 1.26796 loss)
I0506 04:44:52.740286 12834 sgd_solver.cpp:106] Iteration 94700, lr = 1.34218e-05
I0506 04:44:52.745009 12834 solver.cpp:242] Iteration 94700 (104.436 iter/s, 0.957523s/100 iter), loss = 0.671953
I0506 04:44:52.745038 12834 solver.cpp:261]     Train net output #0: loss = 0.671953 (* 1 = 0.671953 loss)
I0506 04:44:52.745046 12834 sgd_solver.cpp:106] Iteration 94700, lr = 1.34218e-05
I0506 04:44:53.677822 12834 solver.cpp:242] Iteration 94800 (106.664 iter/s, 0.937522s/100 iter), loss = 1.20536
I0506 04:44:53.677858 12834 solver.cpp:261]     Train net output #0: loss = 1.20536 (* 1 = 1.20536 loss)
I0506 04:44:53.677868 12834 sgd_solver.cpp:106] Iteration 94800, lr = 1.34218e-05
I0506 04:44:53.682684 12834 solver.cpp:242] Iteration 94800 (106.653 iter/s, 0.937619s/100 iter), loss = 0.953946
I0506 04:44:53.682708 12834 solver.cpp:261]     Train net output #0: loss = 0.953946 (* 1 = 0.953946 loss)
I0506 04:44:53.682718 12834 sgd_solver.cpp:106] Iteration 94800, lr = 1.34218e-05
I0506 04:44:54.639967 12834 solver.cpp:242] Iteration 94900 (103.941 iter/s, 0.962081s/100 iter), loss = 0.823769
I0506 04:44:54.640002 12834 solver.cpp:261]     Train net output #0: loss = 0.823769 (* 1 = 0.823769 loss)
I0506 04:44:54.640012 12834 sgd_solver.cpp:106] Iteration 94900, lr = 1.34218e-05
I0506 04:44:54.644733 12834 solver.cpp:242] Iteration 94900 (103.949 iter/s, 0.962006s/100 iter), loss = 0.663455
I0506 04:44:54.644758 12834 solver.cpp:261]     Train net output #0: loss = 0.663455 (* 1 = 0.663455 loss)
I0506 04:44:54.644768 12834 sgd_solver.cpp:106] Iteration 94900, lr = 1.34218e-05
I0506 04:44:55.574724 12834 solver.cpp:362] Iteration 95000, Testing net (#0)
I0506 04:44:55.574753 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:55.697433 12834 solver.cpp:429]     Test net output #0: loss = 1.29469 (* 1 = 1.29469 loss)
I0506 04:44:55.699954 12834 solver.cpp:242] Iteration 95000 (94.3455 iter/s, 1.05993s/100 iter), loss = 0.43029
I0506 04:44:55.699986 12834 solver.cpp:261]     Train net output #0: loss = 0.43029 (* 1 = 0.43029 loss)
I0506 04:44:55.699995 12834 sgd_solver.cpp:106] Iteration 95000, lr = 1.34218e-05
I0506 04:44:55.701885 12834 solver.cpp:362] Iteration 95000, Testing net (#0)
I0506 04:44:55.701900 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:44:55.830366 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7545
I0506 04:44:55.830386 12834 solver.cpp:429]     Test net output #1: loss = 0.57889 (* 1 = 0.57889 loss)
I0506 04:44:55.832936 12834 solver.cpp:242] Iteration 95000 (84.1641 iter/s, 1.18816s/100 iter), loss = 0.525629
I0506 04:44:55.832957 12834 solver.cpp:261]     Train net output #0: loss = 0.525629 (* 1 = 0.525629 loss)
I0506 04:44:55.832965 12834 sgd_solver.cpp:106] Iteration 95000, lr = 1.34218e-05
I0506 04:44:56.765417 12834 solver.cpp:242] Iteration 95100 (93.8613 iter/s, 1.0654s/100 iter), loss = 0.580816
I0506 04:44:56.765451 12834 solver.cpp:261]     Train net output #0: loss = 0.580816 (* 1 = 0.580816 loss)
I0506 04:44:56.765461 12834 sgd_solver.cpp:106] Iteration 95100, lr = 1.34218e-05
I0506 04:44:56.770181 12834 solver.cpp:242] Iteration 95100 (106.7 iter/s, 0.937206s/100 iter), loss = 0.617757
I0506 04:44:56.770221 12834 solver.cpp:261]     Train net output #0: loss = 0.617757 (* 1 = 0.617757 loss)
I0506 04:44:56.770231 12834 sgd_solver.cpp:106] Iteration 95100, lr = 1.34218e-05
I0506 04:44:57.703094 12834 solver.cpp:242] Iteration 95200 (106.654 iter/s, 0.937611s/100 iter), loss = 0.393194
I0506 04:44:57.703128 12834 solver.cpp:261]     Train net output #0: loss = 0.393194 (* 1 = 0.393194 loss)
I0506 04:44:57.703137 12834 sgd_solver.cpp:106] Iteration 95200, lr = 1.34218e-05
I0506 04:44:57.707880 12834 solver.cpp:242] Iteration 95200 (106.651 iter/s, 0.93764s/100 iter), loss = 0.369566
I0506 04:44:57.707906 12834 solver.cpp:261]     Train net output #0: loss = 0.369566 (* 1 = 0.369566 loss)
I0506 04:44:57.707914 12834 sgd_solver.cpp:106] Iteration 95200, lr = 1.34218e-05
I0506 04:44:58.640631 12834 solver.cpp:242] Iteration 95300 (106.669 iter/s, 0.937477s/100 iter), loss = 1.13802
I0506 04:44:58.640672 12834 solver.cpp:261]     Train net output #0: loss = 1.13802 (* 1 = 1.13802 loss)
I0506 04:44:58.640681 12834 sgd_solver.cpp:106] Iteration 95300, lr = 1.34218e-05
I0506 04:44:58.645416 12834 solver.cpp:242] Iteration 95300 (106.668 iter/s, 0.937492s/100 iter), loss = 0.466251
I0506 04:44:58.645442 12834 solver.cpp:261]     Train net output #0: loss = 0.466251 (* 1 = 0.466251 loss)
I0506 04:44:58.645450 12834 sgd_solver.cpp:106] Iteration 95300, lr = 1.34218e-05
I0506 04:44:59.578061 12834 solver.cpp:242] Iteration 95400 (106.683 iter/s, 0.937358s/100 iter), loss = 1.69377
I0506 04:44:59.578101 12834 solver.cpp:261]     Train net output #0: loss = 1.69377 (* 1 = 1.69377 loss)
I0506 04:44:59.578111 12834 sgd_solver.cpp:106] Iteration 95400, lr = 1.34218e-05
I0506 04:44:59.582862 12834 solver.cpp:242] Iteration 95400 (106.678 iter/s, 0.937402s/100 iter), loss = 0.543724
I0506 04:44:59.582890 12834 solver.cpp:261]     Train net output #0: loss = 0.543724 (* 1 = 0.543724 loss)
I0506 04:44:59.582898 12834 sgd_solver.cpp:106] Iteration 95400, lr = 1.34218e-05
I0506 04:45:00.518558 12834 solver.cpp:362] Iteration 95500, Testing net (#0)
I0506 04:45:00.518587 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:00.641196 12834 solver.cpp:429]     Test net output #0: loss = 1.32104 (* 1 = 1.32104 loss)
I0506 04:45:00.643715 12834 solver.cpp:242] Iteration 95500 (93.8444 iter/s, 1.06559s/100 iter), loss = 2.5176
I0506 04:45:00.643734 12834 solver.cpp:261]     Train net output #0: loss = 2.5176 (* 1 = 2.5176 loss)
I0506 04:45:00.643743 12834 sgd_solver.cpp:106] Iteration 95500, lr = 1.34218e-05
I0506 04:45:00.645592 12834 solver.cpp:362] Iteration 95500, Testing net (#0)
I0506 04:45:00.645611 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:00.774155 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7605
I0506 04:45:00.774178 12834 solver.cpp:429]     Test net output #1: loss = 0.558555 (* 1 = 0.558555 loss)
I0506 04:45:00.776724 12834 solver.cpp:242] Iteration 95500 (83.7652 iter/s, 1.19381s/100 iter), loss = 0.452053
I0506 04:45:00.776744 12834 solver.cpp:261]     Train net output #0: loss = 0.452053 (* 1 = 0.452053 loss)
I0506 04:45:00.776753 12834 sgd_solver.cpp:106] Iteration 95500, lr = 1.34218e-05
I0506 04:45:01.720350 12834 solver.cpp:242] Iteration 95600 (92.8867 iter/s, 1.07658s/100 iter), loss = 1.41779
I0506 04:45:01.720388 12834 solver.cpp:261]     Train net output #0: loss = 1.41779 (* 1 = 1.41779 loss)
I0506 04:45:01.720397 12834 sgd_solver.cpp:106] Iteration 95600, lr = 1.34218e-05
I0506 04:45:01.725136 12834 solver.cpp:242] Iteration 95600 (105.444 iter/s, 0.948372s/100 iter), loss = 0.440463
I0506 04:45:01.725162 12834 solver.cpp:261]     Train net output #0: loss = 0.440463 (* 1 = 0.440463 loss)
I0506 04:45:01.725170 12834 sgd_solver.cpp:106] Iteration 95600, lr = 1.34218e-05
I0506 04:45:02.657914 12834 solver.cpp:242] Iteration 95700 (106.666 iter/s, 0.937502s/100 iter), loss = 2.34763
I0506 04:45:02.657960 12834 solver.cpp:261]     Train net output #0: loss = 2.34763 (* 1 = 2.34763 loss)
I0506 04:45:02.658028 12834 sgd_solver.cpp:106] Iteration 95700, lr = 1.34218e-05
I0506 04:45:02.662917 12834 solver.cpp:242] Iteration 95700 (106.641 iter/s, 0.937727s/100 iter), loss = 0.558679
I0506 04:45:02.662941 12834 solver.cpp:261]     Train net output #0: loss = 0.558679 (* 1 = 0.558679 loss)
I0506 04:45:02.662950 12834 sgd_solver.cpp:106] Iteration 95700, lr = 1.34218e-05
I0506 04:45:03.595798 12834 solver.cpp:242] Iteration 95800 (106.631 iter/s, 0.937811s/100 iter), loss = 4.28357
I0506 04:45:03.595836 12834 solver.cpp:261]     Train net output #0: loss = 4.28357 (* 1 = 4.28357 loss)
I0506 04:45:03.595845 12834 sgd_solver.cpp:106] Iteration 95800, lr = 1.34218e-05
I0506 04:45:03.600574 12834 solver.cpp:242] Iteration 95800 (106.654 iter/s, 0.937613s/100 iter), loss = 0.77928
I0506 04:45:03.600597 12834 solver.cpp:261]     Train net output #0: loss = 0.77928 (* 1 = 0.77928 loss)
I0506 04:45:03.600606 12834 sgd_solver.cpp:106] Iteration 95800, lr = 1.34218e-05
I0506 04:45:04.533433 12834 solver.cpp:242] Iteration 95900 (106.658 iter/s, 0.937573s/100 iter), loss = 0.625043
I0506 04:45:04.533471 12834 solver.cpp:261]     Train net output #0: loss = 0.625043 (* 1 = 0.625043 loss)
I0506 04:45:04.533480 12834 sgd_solver.cpp:106] Iteration 95900, lr = 1.34218e-05
I0506 04:45:04.538295 12834 solver.cpp:242] Iteration 95900 (106.647 iter/s, 0.937671s/100 iter), loss = 0.652921
I0506 04:45:04.538319 12834 solver.cpp:261]     Train net output #0: loss = 0.652921 (* 1 = 0.652921 loss)
I0506 04:45:04.538328 12834 sgd_solver.cpp:106] Iteration 95900, lr = 1.34218e-05
I0506 04:45:05.467742 12834 solver.cpp:362] Iteration 96000, Testing net (#0)
I0506 04:45:05.467766 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:05.590502 12834 solver.cpp:429]     Test net output #0: loss = 1.50244 (* 1 = 1.50244 loss)
I0506 04:45:05.593022 12834 solver.cpp:242] Iteration 96000 (94.3812 iter/s, 1.05953s/100 iter), loss = 0.98665
I0506 04:45:05.593042 12834 solver.cpp:261]     Train net output #0: loss = 0.98665 (* 1 = 0.98665 loss)
I0506 04:45:05.593051 12834 sgd_solver.cpp:106] Iteration 96000, lr = 1.34218e-05
I0506 04:45:05.594872 12834 solver.cpp:362] Iteration 96000, Testing net (#0)
I0506 04:45:05.594884 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:05.723454 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7695
I0506 04:45:05.723474 12834 solver.cpp:429]     Test net output #1: loss = 0.537075 (* 1 = 0.537075 loss)
I0506 04:45:05.726024 12834 solver.cpp:242] Iteration 96000 (84.1975 iter/s, 1.18768s/100 iter), loss = 0.734362
I0506 04:45:05.726045 12834 solver.cpp:261]     Train net output #0: loss = 0.734362 (* 1 = 0.734362 loss)
I0506 04:45:05.726053 12834 sgd_solver.cpp:106] Iteration 96000, lr = 1.34218e-05
I0506 04:45:06.667229 12834 solver.cpp:242] Iteration 96100 (93.097 iter/s, 1.07415s/100 iter), loss = 1.07344
I0506 04:45:06.667273 12834 solver.cpp:261]     Train net output #0: loss = 1.07344 (* 1 = 1.07344 loss)
I0506 04:45:06.667284 12834 sgd_solver.cpp:106] Iteration 96100, lr = 1.34218e-05
I0506 04:45:06.672493 12834 solver.cpp:242] Iteration 96100 (105.66 iter/s, 0.946428s/100 iter), loss = 0.365111
I0506 04:45:06.672523 12834 solver.cpp:261]     Train net output #0: loss = 0.365111 (* 1 = 0.365111 loss)
I0506 04:45:06.672535 12834 sgd_solver.cpp:106] Iteration 96100, lr = 1.34218e-05
I0506 04:45:07.670699 12834 solver.cpp:242] Iteration 96200 (99.661 iter/s, 1.0034s/100 iter), loss = 3.60416
I0506 04:45:07.670742 12834 solver.cpp:261]     Train net output #0: loss = 3.60416 (* 1 = 3.60416 loss)
I0506 04:45:07.670919 12834 sgd_solver.cpp:106] Iteration 96200, lr = 1.34218e-05
I0506 04:45:07.675714 12834 solver.cpp:242] Iteration 96200 (99.6837 iter/s, 1.00317s/100 iter), loss = 0.746413
I0506 04:45:07.675740 12834 solver.cpp:261]     Train net output #0: loss = 0.746413 (* 1 = 0.746413 loss)
I0506 04:45:07.675748 12834 sgd_solver.cpp:106] Iteration 96200, lr = 1.34218e-05
I0506 04:45:08.608209 12834 solver.cpp:242] Iteration 96300 (106.674 iter/s, 0.937436s/100 iter), loss = 1.29063
I0506 04:45:08.608245 12834 solver.cpp:261]     Train net output #0: loss = 1.29063 (* 1 = 1.29063 loss)
I0506 04:45:08.608264 12834 sgd_solver.cpp:106] Iteration 96300, lr = 1.34218e-05
I0506 04:45:08.613001 12834 solver.cpp:242] Iteration 96300 (106.696 iter/s, 0.937244s/100 iter), loss = 0.720716
I0506 04:45:08.613025 12834 solver.cpp:261]     Train net output #0: loss = 0.720716 (* 1 = 0.720716 loss)
I0506 04:45:08.613034 12834 sgd_solver.cpp:106] Iteration 96300, lr = 1.34218e-05
I0506 04:45:09.545122 12834 solver.cpp:242] Iteration 96400 (106.74 iter/s, 0.936854s/100 iter), loss = 0.646506
I0506 04:45:09.545156 12834 solver.cpp:261]     Train net output #0: loss = 0.646506 (* 1 = 0.646506 loss)
I0506 04:45:09.545166 12834 sgd_solver.cpp:106] Iteration 96400, lr = 1.34218e-05
I0506 04:45:09.549892 12834 solver.cpp:242] Iteration 96400 (106.741 iter/s, 0.936848s/100 iter), loss = 0.393209
I0506 04:45:09.549916 12834 solver.cpp:261]     Train net output #0: loss = 0.393209 (* 1 = 0.393209 loss)
I0506 04:45:09.549926 12834 sgd_solver.cpp:106] Iteration 96400, lr = 1.34218e-05
I0506 04:45:10.479951 12834 solver.cpp:362] Iteration 96500, Testing net (#0)
I0506 04:45:10.479981 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:10.604862 12834 solver.cpp:429]     Test net output #0: loss = 1.56919 (* 1 = 1.56919 loss)
I0506 04:45:10.607502 12834 solver.cpp:242] Iteration 96500 (94.1329 iter/s, 1.06233s/100 iter), loss = 2.72601
I0506 04:45:10.607527 12834 solver.cpp:261]     Train net output #0: loss = 2.72601 (* 1 = 2.72601 loss)
I0506 04:45:10.607537 12834 sgd_solver.cpp:106] Iteration 96500, lr = 1.34218e-05
I0506 04:45:10.609767 12834 solver.cpp:362] Iteration 96500, Testing net (#0)
I0506 04:45:10.609783 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:10.750422 12834 solver.cpp:429]     Test net output #0: accuracy = 0.73
I0506 04:45:10.750444 12834 solver.cpp:429]     Test net output #1: loss = 0.606565 (* 1 = 0.606565 loss)
I0506 04:45:10.753132 12834 solver.cpp:242] Iteration 96500 (83.1121 iter/s, 1.20319s/100 iter), loss = 0.84633
I0506 04:45:10.753156 12834 solver.cpp:261]     Train net output #0: loss = 0.84633 (* 1 = 0.84633 loss)
I0506 04:45:10.753167 12834 sgd_solver.cpp:106] Iteration 96500, lr = 1.34218e-05
I0506 04:45:11.782840 12834 solver.cpp:242] Iteration 96600 (85.0858 iter/s, 1.17528s/100 iter), loss = 1.43106
I0506 04:45:11.782876 12834 solver.cpp:261]     Train net output #0: loss = 1.43106 (* 1 = 1.43106 loss)
I0506 04:45:11.782887 12834 sgd_solver.cpp:106] Iteration 96600, lr = 1.34218e-05
I0506 04:45:11.788200 12834 solver.cpp:242] Iteration 96600 (96.6172 iter/s, 1.03501s/100 iter), loss = 0.383407
I0506 04:45:11.788228 12834 solver.cpp:261]     Train net output #0: loss = 0.383407 (* 1 = 0.383407 loss)
I0506 04:45:11.788239 12834 sgd_solver.cpp:106] Iteration 96600, lr = 1.34218e-05
I0506 04:45:12.814492 12834 solver.cpp:242] Iteration 96700 (96.9378 iter/s, 1.03159s/100 iter), loss = 0.524289
I0506 04:45:12.814524 12834 solver.cpp:261]     Train net output #0: loss = 0.524289 (* 1 = 0.524289 loss)
I0506 04:45:12.814533 12834 sgd_solver.cpp:106] Iteration 96700, lr = 1.34218e-05
I0506 04:45:12.819267 12834 solver.cpp:242] Iteration 96700 (96.9914 iter/s, 1.03102s/100 iter), loss = 0.721013
I0506 04:45:12.819291 12834 solver.cpp:261]     Train net output #0: loss = 0.721013 (* 1 = 0.721013 loss)
I0506 04:45:12.819300 12834 sgd_solver.cpp:106] Iteration 96700, lr = 1.34218e-05
I0506 04:45:13.762455 12834 solver.cpp:242] Iteration 96800 (105.496 iter/s, 0.947906s/100 iter), loss = 4.08525
I0506 04:45:13.762497 12834 solver.cpp:261]     Train net output #0: loss = 4.08525 (* 1 = 4.08525 loss)
I0506 04:45:13.762506 12834 sgd_solver.cpp:106] Iteration 96800, lr = 1.34218e-05
I0506 04:45:13.767290 12834 solver.cpp:242] Iteration 96800 (105.488 iter/s, 0.947971s/100 iter), loss = 0.670567
I0506 04:45:13.767315 12834 solver.cpp:261]     Train net output #0: loss = 0.670567 (* 1 = 0.670567 loss)
I0506 04:45:13.767325 12834 sgd_solver.cpp:106] Iteration 96800, lr = 1.34218e-05
I0506 04:45:14.699303 12834 solver.cpp:242] Iteration 96900 (106.749 iter/s, 0.936779s/100 iter), loss = 1.19281
I0506 04:45:14.699357 12834 solver.cpp:261]     Train net output #0: loss = 1.19281 (* 1 = 1.19281 loss)
I0506 04:45:14.699368 12834 sgd_solver.cpp:106] Iteration 96900, lr = 1.34218e-05
I0506 04:45:14.704075 12834 solver.cpp:242] Iteration 96900 (106.753 iter/s, 0.936741s/100 iter), loss = 0.590478
I0506 04:45:14.704099 12834 solver.cpp:261]     Train net output #0: loss = 0.590478 (* 1 = 0.590478 loss)
I0506 04:45:14.704107 12834 sgd_solver.cpp:106] Iteration 96900, lr = 1.34218e-05
I0506 04:45:15.634024 12834 solver.cpp:362] Iteration 97000, Testing net (#0)
I0506 04:45:15.634052 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:15.756649 12834 solver.cpp:429]     Test net output #0: loss = 1.4711 (* 1 = 1.4711 loss)
I0506 04:45:15.759155 12834 solver.cpp:242] Iteration 97000 (94.3591 iter/s, 1.05978s/100 iter), loss = 0.234732
I0506 04:45:15.759176 12834 solver.cpp:261]     Train net output #0: loss = 0.234732 (* 1 = 0.234732 loss)
I0506 04:45:15.759186 12834 sgd_solver.cpp:106] Iteration 97000, lr = 1.34218e-05
I0506 04:45:15.760993 12834 solver.cpp:362] Iteration 97000, Testing net (#0)
I0506 04:45:15.761005 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:15.889652 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7495
I0506 04:45:15.889672 12834 solver.cpp:429]     Test net output #1: loss = 0.577509 (* 1 = 0.577509 loss)
I0506 04:45:15.892217 12834 solver.cpp:242] Iteration 97000 (84.1682 iter/s, 1.1881s/100 iter), loss = 0.52121
I0506 04:45:15.892237 12834 solver.cpp:261]     Train net output #0: loss = 0.52121 (* 1 = 0.52121 loss)
I0506 04:45:15.892246 12834 sgd_solver.cpp:106] Iteration 97000, lr = 1.34218e-05
I0506 04:45:16.825032 12834 solver.cpp:242] Iteration 97100 (93.8237 iter/s, 1.06583s/100 iter), loss = 0.842072
I0506 04:45:16.825072 12834 solver.cpp:261]     Train net output #0: loss = 0.842072 (* 1 = 0.842072 loss)
I0506 04:45:16.825081 12834 sgd_solver.cpp:106] Iteration 97100, lr = 1.34218e-05
I0506 04:45:16.829794 12834 solver.cpp:242] Iteration 97100 (106.662 iter/s, 0.937539s/100 iter), loss = 0.501317
I0506 04:45:16.829819 12834 solver.cpp:261]     Train net output #0: loss = 0.501317 (* 1 = 0.501317 loss)
I0506 04:45:16.829828 12834 sgd_solver.cpp:106] Iteration 97100, lr = 1.34218e-05
I0506 04:45:17.762503 12834 solver.cpp:242] Iteration 97200 (106.678 iter/s, 0.937399s/100 iter), loss = 0.618942
I0506 04:45:17.762543 12834 solver.cpp:261]     Train net output #0: loss = 0.618942 (* 1 = 0.618942 loss)
I0506 04:45:17.762552 12834 sgd_solver.cpp:106] Iteration 97200, lr = 1.34218e-05
I0506 04:45:17.767297 12834 solver.cpp:242] Iteration 97200 (106.671 iter/s, 0.937459s/100 iter), loss = 0.319516
I0506 04:45:17.767323 12834 solver.cpp:261]     Train net output #0: loss = 0.319516 (* 1 = 0.319516 loss)
I0506 04:45:17.767331 12834 sgd_solver.cpp:106] Iteration 97200, lr = 1.34218e-05
I0506 04:45:18.699864 12834 solver.cpp:242] Iteration 97300 (106.69 iter/s, 0.937297s/100 iter), loss = 1.41762
I0506 04:45:18.699905 12834 solver.cpp:261]     Train net output #0: loss = 1.41762 (* 1 = 1.41762 loss)
I0506 04:45:18.699915 12834 sgd_solver.cpp:106] Iteration 97300, lr = 1.34218e-05
I0506 04:45:18.704639 12834 solver.cpp:242] Iteration 97300 (106.69 iter/s, 0.937299s/100 iter), loss = 0.552789
I0506 04:45:18.704664 12834 solver.cpp:261]     Train net output #0: loss = 0.552789 (* 1 = 0.552789 loss)
I0506 04:45:18.704672 12834 sgd_solver.cpp:106] Iteration 97300, lr = 1.34218e-05
I0506 04:45:19.637154 12834 solver.cpp:242] Iteration 97400 (106.699 iter/s, 0.937218s/100 iter), loss = 5.28746
I0506 04:45:19.637192 12834 solver.cpp:261]     Train net output #0: loss = 5.28746 (* 1 = 5.28746 loss)
I0506 04:45:19.637202 12834 sgd_solver.cpp:106] Iteration 97400, lr = 1.34218e-05
I0506 04:45:19.641911 12834 solver.cpp:242] Iteration 97400 (106.697 iter/s, 0.937229s/100 iter), loss = 0.916783
I0506 04:45:19.641935 12834 solver.cpp:261]     Train net output #0: loss = 0.916783 (* 1 = 0.916783 loss)
I0506 04:45:19.641954 12834 sgd_solver.cpp:106] Iteration 97400, lr = 1.34218e-05
I0506 04:45:20.571949 12834 solver.cpp:362] Iteration 97500, Testing net (#0)
I0506 04:45:20.571972 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:20.694514 12834 solver.cpp:429]     Test net output #0: loss = 1.23698 (* 1 = 1.23698 loss)
I0506 04:45:20.697055 12834 solver.cpp:242] Iteration 97500 (94.3536 iter/s, 1.05984s/100 iter), loss = 5.66555
I0506 04:45:20.697078 12834 solver.cpp:261]     Train net output #0: loss = 5.66555 (* 1 = 5.66555 loss)
I0506 04:45:20.697087 12834 sgd_solver.cpp:106] Iteration 97500, lr = 1.34218e-05
I0506 04:45:20.698978 12834 solver.cpp:362] Iteration 97500, Testing net (#0)
I0506 04:45:20.698990 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:20.827677 12834 solver.cpp:429]     Test net output #0: accuracy = 0.752
I0506 04:45:20.827695 12834 solver.cpp:429]     Test net output #1: loss = 0.589259 (* 1 = 0.589259 loss)
I0506 04:45:20.830247 12834 solver.cpp:242] Iteration 97500 (84.1545 iter/s, 1.18829s/100 iter), loss = 0.947631
I0506 04:45:20.830268 12834 solver.cpp:261]     Train net output #0: loss = 0.947631 (* 1 = 0.947631 loss)
I0506 04:45:20.830277 12834 sgd_solver.cpp:106] Iteration 97500, lr = 1.34218e-05
I0506 04:45:21.762842 12834 solver.cpp:242] Iteration 97600 (93.832 iter/s, 1.06573s/100 iter), loss = 1.39641
I0506 04:45:21.762877 12834 solver.cpp:261]     Train net output #0: loss = 1.39641 (* 1 = 1.39641 loss)
I0506 04:45:21.762887 12834 sgd_solver.cpp:106] Iteration 97600, lr = 1.34218e-05
I0506 04:45:21.767633 12834 solver.cpp:242] Iteration 97600 (106.684 iter/s, 0.937347s/100 iter), loss = 0.481069
I0506 04:45:21.767658 12834 solver.cpp:261]     Train net output #0: loss = 0.481069 (* 1 = 0.481069 loss)
I0506 04:45:21.767668 12834 sgd_solver.cpp:106] Iteration 97600, lr = 1.34218e-05
I0506 04:45:22.712810 12834 solver.cpp:242] Iteration 97700 (105.274 iter/s, 0.949906s/100 iter), loss = 0.910981
I0506 04:45:22.712851 12834 solver.cpp:261]     Train net output #0: loss = 0.910981 (* 1 = 0.910981 loss)
I0506 04:45:22.712862 12834 sgd_solver.cpp:106] Iteration 97700, lr = 1.34218e-05
I0506 04:45:22.718197 12834 solver.cpp:242] Iteration 97700 (105.207 iter/s, 0.950509s/100 iter), loss = 0.409037
I0506 04:45:22.718227 12834 solver.cpp:261]     Train net output #0: loss = 0.409037 (* 1 = 0.409037 loss)
I0506 04:45:22.718238 12834 sgd_solver.cpp:106] Iteration 97700, lr = 1.34218e-05
I0506 04:45:23.709087 12834 solver.cpp:242] Iteration 97800 (100.38 iter/s, 0.99621s/100 iter), loss = 1.74305
I0506 04:45:23.709123 12834 solver.cpp:261]     Train net output #0: loss = 1.74305 (* 1 = 1.74305 loss)
I0506 04:45:23.709132 12834 sgd_solver.cpp:106] Iteration 97800, lr = 1.34218e-05
I0506 04:45:23.713862 12834 solver.cpp:242] Iteration 97800 (100.44 iter/s, 0.995617s/100 iter), loss = 0.496397
I0506 04:45:23.713886 12834 solver.cpp:261]     Train net output #0: loss = 0.496397 (* 1 = 0.496397 loss)
I0506 04:45:23.713896 12834 sgd_solver.cpp:106] Iteration 97800, lr = 1.34218e-05
I0506 04:45:24.647053 12834 solver.cpp:242] Iteration 97900 (106.621 iter/s, 0.937898s/100 iter), loss = 1.35392
I0506 04:45:24.647086 12834 solver.cpp:261]     Train net output #0: loss = 1.35392 (* 1 = 1.35392 loss)
I0506 04:45:24.647095 12834 sgd_solver.cpp:106] Iteration 97900, lr = 1.34218e-05
I0506 04:45:24.651825 12834 solver.cpp:242] Iteration 97900 (106.619 iter/s, 0.93792s/100 iter), loss = 0.495439
I0506 04:45:24.651849 12834 solver.cpp:261]     Train net output #0: loss = 0.495439 (* 1 = 0.495439 loss)
I0506 04:45:24.651859 12834 sgd_solver.cpp:106] Iteration 97900, lr = 1.34218e-05
I0506 04:45:25.581468 12834 solver.cpp:362] Iteration 98000, Testing net (#0)
I0506 04:45:25.581496 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:25.704291 12834 solver.cpp:429]     Test net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I0506 04:45:25.706807 12834 solver.cpp:242] Iteration 98000 (94.3661 iter/s, 1.0597s/100 iter), loss = 2.09543
I0506 04:45:25.706828 12834 solver.cpp:261]     Train net output #0: loss = 2.09543 (* 1 = 2.09543 loss)
I0506 04:45:25.706846 12834 sgd_solver.cpp:106] Iteration 98000, lr = 1.34218e-05
I0506 04:45:25.708676 12834 solver.cpp:362] Iteration 98000, Testing net (#0)
I0506 04:45:25.708689 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:25.837230 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7525
I0506 04:45:25.837249 12834 solver.cpp:429]     Test net output #1: loss = 0.594721 (* 1 = 0.594721 loss)
I0506 04:45:25.839807 12834 solver.cpp:242] Iteration 98000 (84.1795 iter/s, 1.18794s/100 iter), loss = 0.607814
I0506 04:45:25.839826 12834 solver.cpp:261]     Train net output #0: loss = 0.607814 (* 1 = 0.607814 loss)
I0506 04:45:25.839835 12834 sgd_solver.cpp:106] Iteration 98000, lr = 1.34218e-05
I0506 04:45:26.785954 12834 solver.cpp:242] Iteration 98100 (92.6707 iter/s, 1.07909s/100 iter), loss = 1.40631
I0506 04:45:26.785995 12834 solver.cpp:261]     Train net output #0: loss = 1.40631 (* 1 = 1.40631 loss)
I0506 04:45:26.786003 12834 sgd_solver.cpp:106] Iteration 98100, lr = 1.34218e-05
I0506 04:45:26.790729 12834 solver.cpp:242] Iteration 98100 (105.165 iter/s, 0.950882s/100 iter), loss = 0.910725
I0506 04:45:26.790755 12834 solver.cpp:261]     Train net output #0: loss = 0.910725 (* 1 = 0.910725 loss)
I0506 04:45:26.790763 12834 sgd_solver.cpp:106] Iteration 98100, lr = 1.34218e-05
I0506 04:45:27.722661 12834 solver.cpp:242] Iteration 98200 (106.764 iter/s, 0.936641s/100 iter), loss = 1.56846
I0506 04:45:27.722702 12834 solver.cpp:261]     Train net output #0: loss = 1.56846 (* 1 = 1.56846 loss)
I0506 04:45:27.722712 12834 sgd_solver.cpp:106] Iteration 98200, lr = 1.34218e-05
I0506 04:45:27.727450 12834 solver.cpp:242] Iteration 98200 (106.76 iter/s, 0.936678s/100 iter), loss = 0.507065
I0506 04:45:27.727474 12834 solver.cpp:261]     Train net output #0: loss = 0.507065 (* 1 = 0.507065 loss)
I0506 04:45:27.727483 12834 sgd_solver.cpp:106] Iteration 98200, lr = 1.34218e-05
I0506 04:45:28.660106 12834 solver.cpp:242] Iteration 98300 (106.681 iter/s, 0.937372s/100 iter), loss = 2.4731
I0506 04:45:28.660157 12834 solver.cpp:261]     Train net output #0: loss = 2.4731 (* 1 = 2.4731 loss)
I0506 04:45:28.660226 12834 sgd_solver.cpp:106] Iteration 98300, lr = 1.34218e-05
I0506 04:45:28.665002 12834 solver.cpp:242] Iteration 98300 (106.666 iter/s, 0.93751s/100 iter), loss = 0.800456
I0506 04:45:28.665027 12834 solver.cpp:261]     Train net output #0: loss = 0.800456 (* 1 = 0.800456 loss)
I0506 04:45:28.665036 12834 sgd_solver.cpp:106] Iteration 98300, lr = 1.34218e-05
I0506 04:45:29.597904 12834 solver.cpp:242] Iteration 98400 (106.641 iter/s, 0.937725s/100 iter), loss = 3.03598
I0506 04:45:29.597944 12834 solver.cpp:261]     Train net output #0: loss = 3.03598 (* 1 = 3.03598 loss)
I0506 04:45:29.597954 12834 sgd_solver.cpp:106] Iteration 98400, lr = 1.34218e-05
I0506 04:45:29.602669 12834 solver.cpp:242] Iteration 98400 (106.653 iter/s, 0.937623s/100 iter), loss = 0.629654
I0506 04:45:29.602695 12834 solver.cpp:261]     Train net output #0: loss = 0.629654 (* 1 = 0.629654 loss)
I0506 04:45:29.602705 12834 sgd_solver.cpp:106] Iteration 98400, lr = 1.34218e-05
I0506 04:45:30.532130 12834 solver.cpp:362] Iteration 98500, Testing net (#0)
I0506 04:45:30.532157 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:30.654798 12834 solver.cpp:429]     Test net output #0: loss = 1.43148 (* 1 = 1.43148 loss)
I0506 04:45:30.657315 12834 solver.cpp:242] Iteration 98500 (94.3973 iter/s, 1.05935s/100 iter), loss = 0.433131
I0506 04:45:30.657338 12834 solver.cpp:261]     Train net output #0: loss = 0.433131 (* 1 = 0.433131 loss)
I0506 04:45:30.657348 12834 sgd_solver.cpp:106] Iteration 98500, lr = 1.34218e-05
I0506 04:45:30.659162 12834 solver.cpp:362] Iteration 98500, Testing net (#0)
I0506 04:45:30.659174 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:30.787958 12834 solver.cpp:429]     Test net output #0: accuracy = 0.766
I0506 04:45:30.787977 12834 solver.cpp:429]     Test net output #1: loss = 0.555543 (* 1 = 0.555543 loss)
I0506 04:45:30.790561 12834 solver.cpp:242] Iteration 98500 (84.1861 iter/s, 1.18785s/100 iter), loss = 0.194013
I0506 04:45:30.790583 12834 solver.cpp:261]     Train net output #0: loss = 0.194013 (* 1 = 0.194013 loss)
I0506 04:45:30.790592 12834 sgd_solver.cpp:106] Iteration 98500, lr = 1.34218e-05
I0506 04:45:31.724102 12834 solver.cpp:242] Iteration 98600 (93.7438 iter/s, 1.06674s/100 iter), loss = 1.54264
I0506 04:45:31.724141 12834 solver.cpp:261]     Train net output #0: loss = 1.54264 (* 1 = 1.54264 loss)
I0506 04:45:31.724150 12834 sgd_solver.cpp:106] Iteration 98600, lr = 1.34218e-05
I0506 04:45:31.728960 12834 solver.cpp:242] Iteration 98600 (106.57 iter/s, 0.938349s/100 iter), loss = 0.58763
I0506 04:45:31.728986 12834 solver.cpp:261]     Train net output #0: loss = 0.58763 (* 1 = 0.58763 loss)
I0506 04:45:31.728996 12834 sgd_solver.cpp:106] Iteration 98600, lr = 1.34218e-05
I0506 04:45:32.670967 12834 solver.cpp:242] Iteration 98700 (105.619 iter/s, 0.946798s/100 iter), loss = 1.25927
I0506 04:45:32.671013 12834 solver.cpp:261]     Train net output #0: loss = 1.25927 (* 1 = 1.25927 loss)
I0506 04:45:32.671025 12834 sgd_solver.cpp:106] Iteration 98700, lr = 1.34218e-05
I0506 04:45:32.676260 12834 solver.cpp:242] Iteration 98700 (105.568 iter/s, 0.947254s/100 iter), loss = 0.64487
I0506 04:45:32.676290 12834 solver.cpp:261]     Train net output #0: loss = 0.64487 (* 1 = 0.64487 loss)
I0506 04:45:32.676301 12834 sgd_solver.cpp:106] Iteration 98700, lr = 1.34218e-05
I0506 04:45:33.613816 12834 solver.cpp:242] Iteration 98800 (106.07 iter/s, 0.942772s/100 iter), loss = 0.625184
I0506 04:45:33.613857 12834 solver.cpp:261]     Train net output #0: loss = 0.625184 (* 1 = 0.625184 loss)
I0506 04:45:33.613865 12834 sgd_solver.cpp:106] Iteration 98800, lr = 1.34218e-05
I0506 04:45:33.618608 12834 solver.cpp:242] Iteration 98800 (106.123 iter/s, 0.9423s/100 iter), loss = 0.255809
I0506 04:45:33.618633 12834 solver.cpp:261]     Train net output #0: loss = 0.255809 (* 1 = 0.255809 loss)
I0506 04:45:33.618641 12834 sgd_solver.cpp:106] Iteration 98800, lr = 1.34218e-05
I0506 04:45:34.552090 12834 solver.cpp:242] Iteration 98900 (106.586 iter/s, 0.938208s/100 iter), loss = 1.32425
I0506 04:45:34.552127 12834 solver.cpp:261]     Train net output #0: loss = 1.32425 (* 1 = 1.32425 loss)
I0506 04:45:34.552136 12834 sgd_solver.cpp:106] Iteration 98900, lr = 1.34218e-05
I0506 04:45:34.556869 12834 solver.cpp:242] Iteration 98900 (106.585 iter/s, 0.938217s/100 iter), loss = 0.472876
I0506 04:45:34.556903 12834 solver.cpp:261]     Train net output #0: loss = 0.472876 (* 1 = 0.472876 loss)
I0506 04:45:34.556912 12834 sgd_solver.cpp:106] Iteration 98900, lr = 1.34218e-05
I0506 04:45:35.487099 12834 solver.cpp:362] Iteration 99000, Testing net (#0)
I0506 04:45:35.487123 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:35.609841 12834 solver.cpp:429]     Test net output #0: loss = 1.41557 (* 1 = 1.41557 loss)
I0506 04:45:35.612359 12834 solver.cpp:242] Iteration 99000 (94.3207 iter/s, 1.06021s/100 iter), loss = 1.56362
I0506 04:45:35.612378 12834 solver.cpp:261]     Train net output #0: loss = 1.56362 (* 1 = 1.56362 loss)
I0506 04:45:35.612386 12834 sgd_solver.cpp:106] Iteration 99000, lr = 1.34218e-05
I0506 04:45:35.614213 12834 solver.cpp:362] Iteration 99000, Testing net (#0)
I0506 04:45:35.614228 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:35.742952 12834 solver.cpp:429]     Test net output #0: accuracy = 0.748
I0506 04:45:35.742972 12834 solver.cpp:429]     Test net output #1: loss = 0.57309 (* 1 = 0.57309 loss)
I0506 04:45:35.745537 12834 solver.cpp:242] Iteration 99000 (84.1318 iter/s, 1.18861s/100 iter), loss = 0.612945
I0506 04:45:35.745556 12834 solver.cpp:261]     Train net output #0: loss = 0.612945 (* 1 = 0.612945 loss)
I0506 04:45:35.745565 12834 sgd_solver.cpp:106] Iteration 99000, lr = 1.34218e-05
I0506 04:45:36.689561 12834 solver.cpp:242] Iteration 99100 (92.8372 iter/s, 1.07715s/100 iter), loss = 0.805378
I0506 04:45:36.689599 12834 solver.cpp:261]     Train net output #0: loss = 0.805378 (* 1 = 0.805378 loss)
I0506 04:45:36.689621 12834 sgd_solver.cpp:106] Iteration 99100, lr = 1.34218e-05
I0506 04:45:36.694852 12834 solver.cpp:242] Iteration 99100 (105.343 iter/s, 0.949276s/100 iter), loss = 0.699079
I0506 04:45:36.694881 12834 solver.cpp:261]     Train net output #0: loss = 0.699079 (* 1 = 0.699079 loss)
I0506 04:45:36.694892 12834 sgd_solver.cpp:106] Iteration 99100, lr = 1.34218e-05
I0506 04:45:37.722434 12834 solver.cpp:242] Iteration 99200 (96.8239 iter/s, 1.0328s/100 iter), loss = 0.737671
I0506 04:45:37.722466 12834 solver.cpp:261]     Train net output #0: loss = 0.737671 (* 1 = 0.737671 loss)
I0506 04:45:37.722476 12834 sgd_solver.cpp:106] Iteration 99200, lr = 1.34218e-05
I0506 04:45:37.727190 12834 solver.cpp:242] Iteration 99200 (96.8721 iter/s, 1.03229s/100 iter), loss = 0.532678
I0506 04:45:37.727213 12834 solver.cpp:261]     Train net output #0: loss = 0.532678 (* 1 = 0.532678 loss)
I0506 04:45:37.727222 12834 sgd_solver.cpp:106] Iteration 99200, lr = 1.34218e-05
I0506 04:45:38.668732 12834 solver.cpp:242] Iteration 99300 (105.682 iter/s, 0.946239s/100 iter), loss = 0.714329
I0506 04:45:38.668779 12834 solver.cpp:261]     Train net output #0: loss = 0.714329 (* 1 = 0.714329 loss)
I0506 04:45:38.668792 12834 sgd_solver.cpp:106] Iteration 99300, lr = 1.34218e-05
I0506 04:45:38.674015 12834 solver.cpp:242] Iteration 99300 (105.621 iter/s, 0.946781s/100 iter), loss = 0.351616
I0506 04:45:38.674044 12834 solver.cpp:261]     Train net output #0: loss = 0.351616 (* 1 = 0.351616 loss)
I0506 04:45:38.674054 12834 sgd_solver.cpp:106] Iteration 99300, lr = 1.34218e-05
I0506 04:45:39.611227 12834 solver.cpp:242] Iteration 99400 (106.11 iter/s, 0.942417s/100 iter), loss = 1.30757
I0506 04:45:39.611269 12834 solver.cpp:261]     Train net output #0: loss = 1.30757 (* 1 = 1.30757 loss)
I0506 04:45:39.611279 12834 sgd_solver.cpp:106] Iteration 99400, lr = 1.34218e-05
I0506 04:45:39.616009 12834 solver.cpp:242] Iteration 99400 (106.163 iter/s, 0.941948s/100 iter), loss = 0.431426
I0506 04:45:39.616034 12834 solver.cpp:261]     Train net output #0: loss = 0.431426 (* 1 = 0.431426 loss)
I0506 04:45:39.616042 12834 sgd_solver.cpp:106] Iteration 99400, lr = 1.34218e-05
I0506 04:45:40.545753 12834 solver.cpp:362] Iteration 99500, Testing net (#0)
I0506 04:45:40.545779 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:40.668387 12834 solver.cpp:429]     Test net output #0: loss = 1.42422 (* 1 = 1.42422 loss)
I0506 04:45:40.670902 12834 solver.cpp:242] Iteration 99500 (94.374 iter/s, 1.05961s/100 iter), loss = 1.30638
I0506 04:45:40.670924 12834 solver.cpp:261]     Train net output #0: loss = 1.30638 (* 1 = 1.30638 loss)
I0506 04:45:40.670933 12834 sgd_solver.cpp:106] Iteration 99500, lr = 1.34218e-05
I0506 04:45:40.672833 12834 solver.cpp:362] Iteration 99500, Testing net (#0)
I0506 04:45:40.672845 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:40.801481 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7685
I0506 04:45:40.801499 12834 solver.cpp:429]     Test net output #1: loss = 0.536362 (* 1 = 0.536362 loss)
I0506 04:45:40.804049 12834 solver.cpp:242] Iteration 99500 (84.1755 iter/s, 1.18799s/100 iter), loss = 0.474791
I0506 04:45:40.804069 12834 solver.cpp:261]     Train net output #0: loss = 0.474791 (* 1 = 0.474791 loss)
I0506 04:45:40.804078 12834 sgd_solver.cpp:106] Iteration 99500, lr = 1.34218e-05
I0506 04:45:41.747861 12834 solver.cpp:242] Iteration 99600 (92.8584 iter/s, 1.07691s/100 iter), loss = 0.833721
I0506 04:45:41.747894 12834 solver.cpp:261]     Train net output #0: loss = 0.833721 (* 1 = 0.833721 loss)
I0506 04:45:41.747902 12834 sgd_solver.cpp:106] Iteration 99600, lr = 1.34218e-05
I0506 04:45:41.752626 12834 solver.cpp:242] Iteration 99600 (105.425 iter/s, 0.948538s/100 iter), loss = 0.423809
I0506 04:45:41.752650 12834 solver.cpp:261]     Train net output #0: loss = 0.423809 (* 1 = 0.423809 loss)
I0506 04:45:41.752658 12834 sgd_solver.cpp:106] Iteration 99600, lr = 1.34218e-05
I0506 04:45:42.685216 12834 solver.cpp:242] Iteration 99700 (106.691 iter/s, 0.93729s/100 iter), loss = 3.37988
I0506 04:45:42.685268 12834 solver.cpp:261]     Train net output #0: loss = 3.37988 (* 1 = 3.37988 loss)
I0506 04:45:42.685277 12834 sgd_solver.cpp:106] Iteration 99700, lr = 1.34218e-05
I0506 04:45:42.690001 12834 solver.cpp:242] Iteration 99700 (106.686 iter/s, 0.937333s/100 iter), loss = 0.699967
I0506 04:45:42.690026 12834 solver.cpp:261]     Train net output #0: loss = 0.699967 (* 1 = 0.699967 loss)
I0506 04:45:42.690034 12834 sgd_solver.cpp:106] Iteration 99700, lr = 1.34218e-05
I0506 04:45:43.622901 12834 solver.cpp:242] Iteration 99800 (106.654 iter/s, 0.937607s/100 iter), loss = 3.03181
I0506 04:45:43.622941 12834 solver.cpp:261]     Train net output #0: loss = 3.03181 (* 1 = 3.03181 loss)
I0506 04:45:43.622951 12834 sgd_solver.cpp:106] Iteration 99800, lr = 1.34218e-05
I0506 04:45:43.627663 12834 solver.cpp:242] Iteration 99800 (106.653 iter/s, 0.937619s/100 iter), loss = 0.934542
I0506 04:45:43.627689 12834 solver.cpp:261]     Train net output #0: loss = 0.934542 (* 1 = 0.934542 loss)
I0506 04:45:43.627698 12834 sgd_solver.cpp:106] Iteration 99800, lr = 1.34218e-05
I0506 04:45:44.560261 12834 solver.cpp:242] Iteration 99900 (106.691 iter/s, 0.937287s/100 iter), loss = 0.731479
I0506 04:45:44.560298 12834 solver.cpp:261]     Train net output #0: loss = 0.731479 (* 1 = 0.731479 loss)
I0506 04:45:44.560308 12834 sgd_solver.cpp:106] Iteration 99900, lr = 1.34218e-05
I0506 04:45:44.565062 12834 solver.cpp:242] Iteration 99900 (106.683 iter/s, 0.937354s/100 iter), loss = 0.627859
I0506 04:45:44.565085 12834 solver.cpp:261]     Train net output #0: loss = 0.627859 (* 1 = 0.627859 loss)
I0506 04:45:44.565094 12834 sgd_solver.cpp:106] Iteration 99900, lr = 1.34218e-05
I0506 04:45:45.488729 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_100000.caffemodel
I0506 04:45:45.505846 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_100000.solverstate
I0506 04:45:45.519201 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_100000.caffemodel
I0506 04:45:45.536777 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_100000.solverstate
I0506 04:45:45.547080 12834 solver.cpp:362] Iteration 100000, Testing net (#0)
I0506 04:45:45.547106 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:45.670027 12834 solver.cpp:429]     Test net output #0: loss = 1.48046 (* 1 = 1.48046 loss)
I0506 04:45:45.672569 12834 solver.cpp:242] Iteration 100000 (89.9077 iter/s, 1.11225s/100 iter), loss = 0.899687
I0506 04:45:45.672592 12834 solver.cpp:261]     Train net output #0: loss = 0.899687 (* 1 = 0.899687 loss)
I0506 04:45:45.672601 12834 sgd_solver.cpp:106] Iteration 100000, lr = 1.07374e-05
I0506 04:45:45.674476 12834 solver.cpp:362] Iteration 100000, Testing net (#0)
I0506 04:45:45.674489 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:45.803196 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7435
I0506 04:45:45.803215 12834 solver.cpp:429]     Test net output #1: loss = 0.56354 (* 1 = 0.56354 loss)
I0506 04:45:45.805778 12834 solver.cpp:242] Iteration 100000 (80.6015 iter/s, 1.24067s/100 iter), loss = 0.498125
I0506 04:45:45.805809 12834 solver.cpp:261]     Train net output #0: loss = 0.498125 (* 1 = 0.498125 loss)
I0506 04:45:45.805819 12834 sgd_solver.cpp:106] Iteration 100000, lr = 1.07374e-05
I0506 04:45:46.755627 12834 solver.cpp:242] Iteration 100100 (92.3364 iter/s, 1.083s/100 iter), loss = 0.702777
I0506 04:45:46.755676 12834 solver.cpp:261]     Train net output #0: loss = 0.702777 (* 1 = 0.702777 loss)
I0506 04:45:46.755687 12834 sgd_solver.cpp:106] Iteration 100100, lr = 1.07374e-05
I0506 04:45:46.760952 12834 solver.cpp:242] Iteration 100100 (104.698 iter/s, 0.955124s/100 iter), loss = 0.839481
I0506 04:45:46.760984 12834 solver.cpp:261]     Train net output #0: loss = 0.839481 (* 1 = 0.839481 loss)
I0506 04:45:46.760994 12834 sgd_solver.cpp:106] Iteration 100100, lr = 1.07374e-05
I0506 04:45:47.791465 12834 solver.cpp:242] Iteration 100200 (96.5474 iter/s, 1.03576s/100 iter), loss = 1.71434
I0506 04:45:47.791510 12834 solver.cpp:261]     Train net output #0: loss = 1.71434 (* 1 = 1.71434 loss)
I0506 04:45:47.791522 12834 sgd_solver.cpp:106] Iteration 100200, lr = 1.07374e-05
I0506 04:45:47.796738 12834 solver.cpp:242] Iteration 100200 (96.5498 iter/s, 1.03574s/100 iter), loss = 0.492513
I0506 04:45:47.796769 12834 solver.cpp:261]     Train net output #0: loss = 0.492513 (* 1 = 0.492513 loss)
I0506 04:45:47.796780 12834 sgd_solver.cpp:106] Iteration 100200, lr = 1.07374e-05
I0506 04:45:48.829740 12834 solver.cpp:242] Iteration 100300 (96.321 iter/s, 1.03819s/100 iter), loss = 0.998033
I0506 04:45:48.829787 12834 solver.cpp:261]     Train net output #0: loss = 0.998033 (* 1 = 0.998033 loss)
I0506 04:45:48.829798 12834 sgd_solver.cpp:106] Iteration 100300, lr = 1.07374e-05
I0506 04:45:48.835026 12834 solver.cpp:242] Iteration 100300 (96.3173 iter/s, 1.03824s/100 iter), loss = 0.834354
I0506 04:45:48.835057 12834 solver.cpp:261]     Train net output #0: loss = 0.834354 (* 1 = 0.834354 loss)
I0506 04:45:48.835067 12834 sgd_solver.cpp:106] Iteration 100300, lr = 1.07374e-05
I0506 04:45:49.849385 12834 solver.cpp:242] Iteration 100400 (98.08 iter/s, 1.01958s/100 iter), loss = 1.33468
I0506 04:45:49.849423 12834 solver.cpp:261]     Train net output #0: loss = 1.33468 (* 1 = 1.33468 loss)
I0506 04:45:49.849433 12834 sgd_solver.cpp:106] Iteration 100400, lr = 1.07374e-05
I0506 04:45:49.854220 12834 solver.cpp:242] Iteration 100400 (98.1223 iter/s, 1.01914s/100 iter), loss = 0.574307
I0506 04:45:49.854245 12834 solver.cpp:261]     Train net output #0: loss = 0.574307 (* 1 = 0.574307 loss)
I0506 04:45:49.854254 12834 sgd_solver.cpp:106] Iteration 100400, lr = 1.07374e-05
I0506 04:45:50.785066 12834 solver.cpp:362] Iteration 100500, Testing net (#0)
I0506 04:45:50.785094 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:50.907850 12834 solver.cpp:429]     Test net output #0: loss = 1.39708 (* 1 = 1.39708 loss)
I0506 04:45:50.910373 12834 solver.cpp:242] Iteration 100500 (94.2569 iter/s, 1.06093s/100 iter), loss = 0.306834
I0506 04:45:50.910394 12834 solver.cpp:261]     Train net output #0: loss = 0.306834 (* 1 = 0.306834 loss)
I0506 04:45:50.910403 12834 sgd_solver.cpp:106] Iteration 100500, lr = 1.07374e-05
I0506 04:45:50.912220 12834 solver.cpp:362] Iteration 100500, Testing net (#0)
I0506 04:45:50.912233 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:51.040922 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7605
I0506 04:45:51.040942 12834 solver.cpp:429]     Test net output #1: loss = 0.547534 (* 1 = 0.547534 loss)
I0506 04:45:51.043493 12834 solver.cpp:242] Iteration 100500 (84.0882 iter/s, 1.18923s/100 iter), loss = 0.643159
I0506 04:45:51.043514 12834 solver.cpp:261]     Train net output #0: loss = 0.643159 (* 1 = 0.643159 loss)
I0506 04:45:51.043522 12834 sgd_solver.cpp:106] Iteration 100500, lr = 1.07374e-05
I0506 04:45:51.976423 12834 solver.cpp:242] Iteration 100600 (93.8084 iter/s, 1.066s/100 iter), loss = 4.26027
I0506 04:45:51.976464 12834 solver.cpp:261]     Train net output #0: loss = 4.26027 (* 1 = 4.26027 loss)
I0506 04:45:51.976472 12834 sgd_solver.cpp:106] Iteration 100600, lr = 1.07374e-05
I0506 04:45:51.981220 12834 solver.cpp:242] Iteration 100600 (106.646 iter/s, 0.937678s/100 iter), loss = 0.750482
I0506 04:45:51.981243 12834 solver.cpp:261]     Train net output #0: loss = 0.750482 (* 1 = 0.750482 loss)
I0506 04:45:51.981252 12834 sgd_solver.cpp:106] Iteration 100600, lr = 1.07374e-05
I0506 04:45:52.914489 12834 solver.cpp:242] Iteration 100700 (106.61 iter/s, 0.938s/100 iter), loss = 1.21501
I0506 04:45:52.914525 12834 solver.cpp:261]     Train net output #0: loss = 1.21501 (* 1 = 1.21501 loss)
I0506 04:45:52.914533 12834 sgd_solver.cpp:106] Iteration 100700, lr = 1.07374e-05
I0506 04:45:52.919333 12834 solver.cpp:242] Iteration 100700 (106.602 iter/s, 0.938072s/100 iter), loss = 0.410381
I0506 04:45:52.919358 12834 solver.cpp:261]     Train net output #0: loss = 0.410381 (* 1 = 0.410381 loss)
I0506 04:45:52.919366 12834 sgd_solver.cpp:106] Iteration 100700, lr = 1.07374e-05
I0506 04:45:53.852849 12834 solver.cpp:242] Iteration 100800 (106.576 iter/s, 0.938294s/100 iter), loss = 1.62671
I0506 04:45:53.852880 12834 solver.cpp:261]     Train net output #0: loss = 1.62671 (* 1 = 1.62671 loss)
I0506 04:45:53.852890 12834 sgd_solver.cpp:106] Iteration 100800, lr = 1.07374e-05
I0506 04:45:53.857630 12834 solver.cpp:242] Iteration 100800 (106.581 iter/s, 0.938254s/100 iter), loss = 0.568153
I0506 04:45:53.857656 12834 solver.cpp:261]     Train net output #0: loss = 0.568153 (* 1 = 0.568153 loss)
I0506 04:45:53.857664 12834 sgd_solver.cpp:106] Iteration 100800, lr = 1.07374e-05
I0506 04:45:54.812909 12834 solver.cpp:242] Iteration 100900 (104.167 iter/s, 0.960001s/100 iter), loss = 1.36046
I0506 04:45:54.812958 12834 solver.cpp:261]     Train net output #0: loss = 1.36046 (* 1 = 1.36046 loss)
I0506 04:45:54.812970 12834 sgd_solver.cpp:106] Iteration 100900, lr = 1.07374e-05
I0506 04:45:54.818197 12834 solver.cpp:242] Iteration 100900 (104.11 iter/s, 0.960522s/100 iter), loss = 0.625313
I0506 04:45:54.818228 12834 solver.cpp:261]     Train net output #0: loss = 0.625313 (* 1 = 0.625313 loss)
I0506 04:45:54.818238 12834 sgd_solver.cpp:106] Iteration 100900, lr = 1.07374e-05
I0506 04:45:55.797894 12834 solver.cpp:362] Iteration 101000, Testing net (#0)
I0506 04:45:55.797925 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:55.920610 12834 solver.cpp:429]     Test net output #0: loss = 1.39241 (* 1 = 1.39241 loss)
I0506 04:45:55.923126 12834 solver.cpp:242] Iteration 101000 (90.078 iter/s, 1.11015s/100 iter), loss = 1.59588
I0506 04:45:55.923146 12834 solver.cpp:261]     Train net output #0: loss = 1.59588 (* 1 = 1.59588 loss)
I0506 04:45:55.923154 12834 sgd_solver.cpp:106] Iteration 101000, lr = 1.07374e-05
I0506 04:45:55.924973 12834 solver.cpp:362] Iteration 101000, Testing net (#0)
I0506 04:45:55.924985 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:45:56.053483 12834 solver.cpp:429]     Test net output #0: accuracy = 0.744
I0506 04:45:56.053503 12834 solver.cpp:429]     Test net output #1: loss = 0.577996 (* 1 = 0.577996 loss)
I0506 04:45:56.056048 12834 solver.cpp:242] Iteration 101000 (80.7884 iter/s, 1.2378s/100 iter), loss = 0.386147
I0506 04:45:56.056068 12834 solver.cpp:261]     Train net output #0: loss = 0.386147 (* 1 = 0.386147 loss)
I0506 04:45:56.056077 12834 sgd_solver.cpp:106] Iteration 101000, lr = 1.07374e-05
I0506 04:45:56.988651 12834 solver.cpp:242] Iteration 101100 (93.8547 iter/s, 1.06548s/100 iter), loss = 0.708412
I0506 04:45:56.988682 12834 solver.cpp:261]     Train net output #0: loss = 0.708412 (* 1 = 0.708412 loss)
I0506 04:45:56.988692 12834 sgd_solver.cpp:106] Iteration 101100, lr = 1.07374e-05
I0506 04:45:56.993412 12834 solver.cpp:242] Iteration 101100 (106.687 iter/s, 0.937326s/100 iter), loss = 0.515218
I0506 04:45:56.993436 12834 solver.cpp:261]     Train net output #0: loss = 0.515218 (* 1 = 0.515218 loss)
I0506 04:45:56.993445 12834 sgd_solver.cpp:106] Iteration 101100, lr = 1.07374e-05
I0506 04:45:57.926275 12834 solver.cpp:242] Iteration 101200 (106.659 iter/s, 0.937563s/100 iter), loss = 0.725124
I0506 04:45:57.926321 12834 solver.cpp:261]     Train net output #0: loss = 0.725124 (* 1 = 0.725124 loss)
I0506 04:45:57.926331 12834 sgd_solver.cpp:106] Iteration 101200, lr = 1.07374e-05
I0506 04:45:57.931041 12834 solver.cpp:242] Iteration 101200 (106.657 iter/s, 0.937587s/100 iter), loss = 0.660962
I0506 04:45:57.931066 12834 solver.cpp:261]     Train net output #0: loss = 0.660962 (* 1 = 0.660962 loss)
I0506 04:45:57.931074 12834 sgd_solver.cpp:106] Iteration 101200, lr = 1.07374e-05
I0506 04:45:58.894744 12834 solver.cpp:242] Iteration 101300 (103.263 iter/s, 0.968397s/100 iter), loss = 3.36559
I0506 04:45:58.894793 12834 solver.cpp:261]     Train net output #0: loss = 3.36559 (* 1 = 3.36559 loss)
I0506 04:45:58.894804 12834 sgd_solver.cpp:106] Iteration 101300, lr = 1.07374e-05
I0506 04:45:58.900126 12834 solver.cpp:242] Iteration 101300 (103.196 iter/s, 0.96903s/100 iter), loss = 0.549332
I0506 04:45:58.900157 12834 solver.cpp:261]     Train net output #0: loss = 0.549332 (* 1 = 0.549332 loss)
I0506 04:45:58.900168 12834 sgd_solver.cpp:106] Iteration 101300, lr = 1.07374e-05
I0506 04:45:59.930797 12834 solver.cpp:242] Iteration 101400 (96.5274 iter/s, 1.03598s/100 iter), loss = 1.48832
I0506 04:45:59.930846 12834 solver.cpp:261]     Train net output #0: loss = 1.48832 (* 1 = 1.48832 loss)
I0506 04:45:59.930857 12834 sgd_solver.cpp:106] Iteration 101400, lr = 1.07374e-05
I0506 04:45:59.936110 12834 solver.cpp:242] Iteration 101400 (96.5315 iter/s, 1.03593s/100 iter), loss = 0.731271
I0506 04:45:59.936137 12834 solver.cpp:261]     Train net output #0: loss = 0.731271 (* 1 = 0.731271 loss)
I0506 04:45:59.936148 12834 sgd_solver.cpp:106] Iteration 101400, lr = 1.07374e-05
I0506 04:46:00.973171 12834 solver.cpp:362] Iteration 101500, Testing net (#0)
I0506 04:46:00.973215 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:01.095994 12834 solver.cpp:429]     Test net output #0: loss = 1.23763 (* 1 = 1.23763 loss)
I0506 04:46:01.098520 12834 solver.cpp:242] Iteration 101500 (85.6418 iter/s, 1.16765s/100 iter), loss = 0.396214
I0506 04:46:01.098546 12834 solver.cpp:261]     Train net output #0: loss = 0.396214 (* 1 = 0.396214 loss)
I0506 04:46:01.098554 12834 sgd_solver.cpp:106] Iteration 101500, lr = 1.07374e-05
I0506 04:46:01.100479 12834 solver.cpp:362] Iteration 101500, Testing net (#0)
I0506 04:46:01.100492 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:01.230887 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:46:01.230908 12834 solver.cpp:429]     Test net output #1: loss = 0.529215 (* 1 = 0.529215 loss)
I0506 04:46:01.233464 12834 solver.cpp:242] Iteration 101500 (77.0829 iter/s, 1.2973s/100 iter), loss = 0.502655
I0506 04:46:01.233485 12834 solver.cpp:261]     Train net output #0: loss = 0.502655 (* 1 = 0.502655 loss)
I0506 04:46:01.233494 12834 sgd_solver.cpp:106] Iteration 101500, lr = 1.07374e-05
I0506 04:46:02.168522 12834 solver.cpp:242] Iteration 101600 (93.4626 iter/s, 1.06995s/100 iter), loss = 3.16495
I0506 04:46:02.168566 12834 solver.cpp:261]     Train net output #0: loss = 3.16495 (* 1 = 3.16495 loss)
I0506 04:46:02.168577 12834 sgd_solver.cpp:106] Iteration 101600, lr = 1.07374e-05
I0506 04:46:02.173310 12834 solver.cpp:242] Iteration 101600 (106.405 iter/s, 0.939806s/100 iter), loss = 0.468785
I0506 04:46:02.173333 12834 solver.cpp:261]     Train net output #0: loss = 0.468785 (* 1 = 0.468785 loss)
I0506 04:46:02.173342 12834 sgd_solver.cpp:106] Iteration 101600, lr = 1.07374e-05
I0506 04:46:03.106868 12834 solver.cpp:242] Iteration 101700 (106.579 iter/s, 0.938268s/100 iter), loss = 1.70383
I0506 04:46:03.106909 12834 solver.cpp:261]     Train net output #0: loss = 1.70383 (* 1 = 1.70383 loss)
I0506 04:46:03.106919 12834 sgd_solver.cpp:106] Iteration 101700, lr = 1.07374e-05
I0506 04:46:03.111623 12834 solver.cpp:242] Iteration 101700 (106.579 iter/s, 0.938271s/100 iter), loss = 0.65707
I0506 04:46:03.111649 12834 solver.cpp:261]     Train net output #0: loss = 0.65707 (* 1 = 0.65707 loss)
I0506 04:46:03.111657 12834 sgd_solver.cpp:106] Iteration 101700, lr = 1.07374e-05
I0506 04:46:04.044625 12834 solver.cpp:242] Iteration 101800 (106.645 iter/s, 0.93769s/100 iter), loss = 2.34005
I0506 04:46:04.044663 12834 solver.cpp:261]     Train net output #0: loss = 2.34005 (* 1 = 2.34005 loss)
I0506 04:46:04.044672 12834 sgd_solver.cpp:106] Iteration 101800, lr = 1.07374e-05
I0506 04:46:04.049387 12834 solver.cpp:242] Iteration 101800 (106.642 iter/s, 0.937721s/100 iter), loss = 0.75361
I0506 04:46:04.049413 12834 solver.cpp:261]     Train net output #0: loss = 0.75361 (* 1 = 0.75361 loss)
I0506 04:46:04.049422 12834 sgd_solver.cpp:106] Iteration 101800, lr = 1.07374e-05
I0506 04:46:04.983769 12834 solver.cpp:242] Iteration 101900 (106.488 iter/s, 0.939071s/100 iter), loss = 1.27603
I0506 04:46:04.983816 12834 solver.cpp:261]     Train net output #0: loss = 1.27603 (* 1 = 1.27603 loss)
I0506 04:46:04.983825 12834 sgd_solver.cpp:106] Iteration 101900, lr = 1.07374e-05
I0506 04:46:04.988570 12834 solver.cpp:242] Iteration 101900 (106.482 iter/s, 0.939126s/100 iter), loss = 0.397887
I0506 04:46:04.988597 12834 solver.cpp:261]     Train net output #0: loss = 0.397887 (* 1 = 0.397887 loss)
I0506 04:46:04.988606 12834 sgd_solver.cpp:106] Iteration 101900, lr = 1.07374e-05
I0506 04:46:05.918781 12834 solver.cpp:362] Iteration 102000, Testing net (#0)
I0506 04:46:05.918805 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:06.041384 12834 solver.cpp:429]     Test net output #0: loss = 1.42882 (* 1 = 1.42882 loss)
I0506 04:46:06.043943 12834 solver.cpp:242] Iteration 102000 (94.33 iter/s, 1.06011s/100 iter), loss = 1.37047
I0506 04:46:06.043965 12834 solver.cpp:261]     Train net output #0: loss = 1.37047 (* 1 = 1.37047 loss)
I0506 04:46:06.043974 12834 sgd_solver.cpp:106] Iteration 102000, lr = 1.07374e-05
I0506 04:46:06.045843 12834 solver.cpp:362] Iteration 102000, Testing net (#0)
I0506 04:46:06.045857 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:06.174597 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7815
I0506 04:46:06.174615 12834 solver.cpp:429]     Test net output #1: loss = 0.53807 (* 1 = 0.53807 loss)
I0506 04:46:06.177165 12834 solver.cpp:242] Iteration 102000 (84.1363 iter/s, 1.18855s/100 iter), loss = 0.558565
I0506 04:46:06.177186 12834 solver.cpp:261]     Train net output #0: loss = 0.558565 (* 1 = 0.558565 loss)
I0506 04:46:06.177194 12834 sgd_solver.cpp:106] Iteration 102000, lr = 1.07374e-05
I0506 04:46:07.110512 12834 solver.cpp:242] Iteration 102100 (93.7635 iter/s, 1.06651s/100 iter), loss = 1.80853
I0506 04:46:07.110550 12834 solver.cpp:261]     Train net output #0: loss = 1.80853 (* 1 = 1.80853 loss)
I0506 04:46:07.110559 12834 sgd_solver.cpp:106] Iteration 102100, lr = 1.07374e-05
I0506 04:46:07.115283 12834 solver.cpp:242] Iteration 102100 (106.601 iter/s, 0.938079s/100 iter), loss = 0.836733
I0506 04:46:07.115309 12834 solver.cpp:261]     Train net output #0: loss = 0.836733 (* 1 = 0.836733 loss)
I0506 04:46:07.115317 12834 sgd_solver.cpp:106] Iteration 102100, lr = 1.07374e-05
I0506 04:46:08.048218 12834 solver.cpp:242] Iteration 102200 (106.65 iter/s, 0.937644s/100 iter), loss = 1.29705
I0506 04:46:08.048256 12834 solver.cpp:261]     Train net output #0: loss = 1.29705 (* 1 = 1.29705 loss)
I0506 04:46:08.048266 12834 sgd_solver.cpp:106] Iteration 102200, lr = 1.07374e-05
I0506 04:46:08.053061 12834 solver.cpp:242] Iteration 102200 (106.641 iter/s, 0.937722s/100 iter), loss = 0.350152
I0506 04:46:08.053086 12834 solver.cpp:261]     Train net output #0: loss = 0.350152 (* 1 = 0.350152 loss)
I0506 04:46:08.053097 12834 sgd_solver.cpp:106] Iteration 102200, lr = 1.07374e-05
I0506 04:46:08.985985 12834 solver.cpp:242] Iteration 102300 (106.644 iter/s, 0.937703s/100 iter), loss = 0.524293
I0506 04:46:08.986014 12834 solver.cpp:261]     Train net output #0: loss = 0.524293 (* 1 = 0.524293 loss)
I0506 04:46:08.986024 12834 sgd_solver.cpp:106] Iteration 102300, lr = 1.07374e-05
I0506 04:46:08.990777 12834 solver.cpp:242] Iteration 102300 (106.647 iter/s, 0.937671s/100 iter), loss = 0.529445
I0506 04:46:08.990800 12834 solver.cpp:261]     Train net output #0: loss = 0.529445 (* 1 = 0.529445 loss)
I0506 04:46:08.990820 12834 sgd_solver.cpp:106] Iteration 102300, lr = 1.07374e-05
I0506 04:46:09.924120 12834 solver.cpp:242] Iteration 102400 (106.601 iter/s, 0.938081s/100 iter), loss = 1.79032
I0506 04:46:09.924162 12834 solver.cpp:261]     Train net output #0: loss = 1.79032 (* 1 = 1.79032 loss)
I0506 04:46:09.924171 12834 sgd_solver.cpp:106] Iteration 102400, lr = 1.07374e-05
I0506 04:46:09.928993 12834 solver.cpp:242] Iteration 102400 (106.591 iter/s, 0.938166s/100 iter), loss = 1.19501
I0506 04:46:09.929019 12834 solver.cpp:261]     Train net output #0: loss = 1.19501 (* 1 = 1.19501 loss)
I0506 04:46:09.929028 12834 sgd_solver.cpp:106] Iteration 102400, lr = 1.07374e-05
I0506 04:46:10.888813 12834 solver.cpp:362] Iteration 102500, Testing net (#0)
I0506 04:46:10.888844 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:11.021976 12834 solver.cpp:429]     Test net output #0: loss = 1.55867 (* 1 = 1.55867 loss)
I0506 04:46:11.024629 12834 solver.cpp:242] Iteration 102500 (90.8721 iter/s, 1.10045s/100 iter), loss = 1.72071
I0506 04:46:11.024654 12834 solver.cpp:261]     Train net output #0: loss = 1.72071 (* 1 = 1.72071 loss)
I0506 04:46:11.024665 12834 sgd_solver.cpp:106] Iteration 102500, lr = 1.07374e-05
I0506 04:46:11.026875 12834 solver.cpp:362] Iteration 102500, Testing net (#0)
I0506 04:46:11.026892 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:11.168047 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7555
I0506 04:46:11.168073 12834 solver.cpp:429]     Test net output #1: loss = 0.570203 (* 1 = 0.570203 loss)
I0506 04:46:11.170718 12834 solver.cpp:242] Iteration 102500 (80.5363 iter/s, 1.24168s/100 iter), loss = 0.630296
I0506 04:46:11.170740 12834 solver.cpp:261]     Train net output #0: loss = 0.630296 (* 1 = 0.630296 loss)
I0506 04:46:11.170750 12834 sgd_solver.cpp:106] Iteration 102500, lr = 1.07374e-05
I0506 04:46:12.103626 12834 solver.cpp:242] Iteration 102600 (92.6838 iter/s, 1.07894s/100 iter), loss = 1.15881
I0506 04:46:12.103657 12834 solver.cpp:261]     Train net output #0: loss = 1.15881 (* 1 = 1.15881 loss)
I0506 04:46:12.103667 12834 sgd_solver.cpp:106] Iteration 102600, lr = 1.07374e-05
I0506 04:46:12.108397 12834 solver.cpp:242] Iteration 102600 (106.651 iter/s, 0.937638s/100 iter), loss = 0.461833
I0506 04:46:12.108422 12834 solver.cpp:261]     Train net output #0: loss = 0.461833 (* 1 = 0.461833 loss)
I0506 04:46:12.108430 12834 sgd_solver.cpp:106] Iteration 102600, lr = 1.07374e-05
I0506 04:46:13.040834 12834 solver.cpp:242] Iteration 102700 (106.706 iter/s, 0.93715s/100 iter), loss = 1.05703
I0506 04:46:13.040876 12834 solver.cpp:261]     Train net output #0: loss = 1.05703 (* 1 = 1.05703 loss)
I0506 04:46:13.040885 12834 sgd_solver.cpp:106] Iteration 102700, lr = 1.07374e-05
I0506 04:46:13.045641 12834 solver.cpp:242] Iteration 102700 (106.701 iter/s, 0.937201s/100 iter), loss = 0.845036
I0506 04:46:13.045665 12834 solver.cpp:261]     Train net output #0: loss = 0.845036 (* 1 = 0.845036 loss)
I0506 04:46:13.045675 12834 sgd_solver.cpp:106] Iteration 102700, lr = 1.07374e-05
I0506 04:46:13.978230 12834 solver.cpp:242] Iteration 102800 (106.687 iter/s, 0.937323s/100 iter), loss = 0.493784
I0506 04:46:13.978272 12834 solver.cpp:261]     Train net output #0: loss = 0.493784 (* 1 = 0.493784 loss)
I0506 04:46:13.978281 12834 sgd_solver.cpp:106] Iteration 102800, lr = 1.07374e-05
I0506 04:46:13.983031 12834 solver.cpp:242] Iteration 102800 (106.684 iter/s, 0.937348s/100 iter), loss = 0.654543
I0506 04:46:13.983057 12834 solver.cpp:261]     Train net output #0: loss = 0.654543 (* 1 = 0.654543 loss)
I0506 04:46:13.983067 12834 sgd_solver.cpp:106] Iteration 102800, lr = 1.07374e-05
I0506 04:46:14.929687 12834 solver.cpp:242] Iteration 102900 (105.11 iter/s, 0.951388s/100 iter), loss = 0.458412
I0506 04:46:14.929726 12834 solver.cpp:261]     Train net output #0: loss = 0.458412 (* 1 = 0.458412 loss)
I0506 04:46:14.929735 12834 sgd_solver.cpp:106] Iteration 102900, lr = 1.07374e-05
I0506 04:46:14.934490 12834 solver.cpp:242] Iteration 102900 (105.107 iter/s, 0.951416s/100 iter), loss = 0.514243
I0506 04:46:14.934517 12834 solver.cpp:261]     Train net output #0: loss = 0.514243 (* 1 = 0.514243 loss)
I0506 04:46:14.934526 12834 sgd_solver.cpp:106] Iteration 102900, lr = 1.07374e-05
I0506 04:46:15.864202 12834 solver.cpp:362] Iteration 103000, Testing net (#0)
I0506 04:46:15.864228 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:15.986862 12834 solver.cpp:429]     Test net output #0: loss = 1.24953 (* 1 = 1.24953 loss)
I0506 04:46:15.989384 12834 solver.cpp:242] Iteration 103000 (94.3716 iter/s, 1.05964s/100 iter), loss = 2.09804
I0506 04:46:15.989408 12834 solver.cpp:261]     Train net output #0: loss = 2.09804 (* 1 = 2.09804 loss)
I0506 04:46:15.989415 12834 sgd_solver.cpp:106] Iteration 103000, lr = 1.07374e-05
I0506 04:46:15.991220 12834 solver.cpp:362] Iteration 103000, Testing net (#0)
I0506 04:46:15.991232 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:16.120131 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7675
I0506 04:46:16.120151 12834 solver.cpp:429]     Test net output #1: loss = 0.536475 (* 1 = 0.536475 loss)
I0506 04:46:16.122723 12834 solver.cpp:242] Iteration 103000 (84.162 iter/s, 1.18819s/100 iter), loss = 0.519332
I0506 04:46:16.122745 12834 solver.cpp:261]     Train net output #0: loss = 0.519332 (* 1 = 0.519332 loss)
I0506 04:46:16.122753 12834 sgd_solver.cpp:106] Iteration 103000, lr = 1.07374e-05
I0506 04:46:17.055387 12834 solver.cpp:242] Iteration 103100 (93.8127 iter/s, 1.06595s/100 iter), loss = 1.49527
I0506 04:46:17.055428 12834 solver.cpp:261]     Train net output #0: loss = 1.49527 (* 1 = 1.49527 loss)
I0506 04:46:17.055438 12834 sgd_solver.cpp:106] Iteration 103100, lr = 1.07374e-05
I0506 04:46:17.060281 12834 solver.cpp:242] Iteration 103100 (106.666 iter/s, 0.937509s/100 iter), loss = 0.894286
I0506 04:46:17.060307 12834 solver.cpp:261]     Train net output #0: loss = 0.894286 (* 1 = 0.894286 loss)
I0506 04:46:17.060317 12834 sgd_solver.cpp:106] Iteration 103100, lr = 1.07374e-05
I0506 04:46:17.992699 12834 solver.cpp:242] Iteration 103200 (106.696 iter/s, 0.937244s/100 iter), loss = 1.58899
I0506 04:46:17.992739 12834 solver.cpp:261]     Train net output #0: loss = 1.58899 (* 1 = 1.58899 loss)
I0506 04:46:17.992749 12834 sgd_solver.cpp:106] Iteration 103200, lr = 1.07374e-05
I0506 04:46:17.997483 12834 solver.cpp:242] Iteration 103200 (106.706 iter/s, 0.937157s/100 iter), loss = 0.526728
I0506 04:46:17.997506 12834 solver.cpp:261]     Train net output #0: loss = 0.526728 (* 1 = 0.526728 loss)
I0506 04:46:17.997515 12834 sgd_solver.cpp:106] Iteration 103200, lr = 1.07374e-05
I0506 04:46:18.966949 12834 solver.cpp:242] Iteration 103300 (102.65 iter/s, 0.974184s/100 iter), loss = 1.06436
I0506 04:46:18.966995 12834 solver.cpp:261]     Train net output #0: loss = 1.06436 (* 1 = 1.06436 loss)
I0506 04:46:18.967006 12834 sgd_solver.cpp:106] Iteration 103300, lr = 1.07374e-05
I0506 04:46:18.972316 12834 solver.cpp:242] Iteration 103300 (102.587 iter/s, 0.974778s/100 iter), loss = 0.51839
I0506 04:46:18.972343 12834 solver.cpp:261]     Train net output #0: loss = 0.51839 (* 1 = 0.51839 loss)
I0506 04:46:18.972354 12834 sgd_solver.cpp:106] Iteration 103300, lr = 1.07374e-05
I0506 04:46:20.028298 12834 solver.cpp:242] Iteration 103400 (94.2266 iter/s, 1.06127s/100 iter), loss = 0.811037
I0506 04:46:20.028347 12834 solver.cpp:261]     Train net output #0: loss = 0.811037 (* 1 = 0.811037 loss)
I0506 04:46:20.028358 12834 sgd_solver.cpp:106] Iteration 103400, lr = 1.07374e-05
I0506 04:46:20.033582 12834 solver.cpp:242] Iteration 103400 (94.2314 iter/s, 1.06122s/100 iter), loss = 0.485138
I0506 04:46:20.033613 12834 solver.cpp:261]     Train net output #0: loss = 0.485138 (* 1 = 0.485138 loss)
I0506 04:46:20.033624 12834 sgd_solver.cpp:106] Iteration 103400, lr = 1.07374e-05
I0506 04:46:21.028558 12834 solver.cpp:362] Iteration 103500, Testing net (#0)
I0506 04:46:21.028583 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:21.151259 12834 solver.cpp:429]     Test net output #0: loss = 1.39217 (* 1 = 1.39217 loss)
I0506 04:46:21.153765 12834 solver.cpp:242] Iteration 103500 (88.8573 iter/s, 1.1254s/100 iter), loss = 4.11944
I0506 04:46:21.153786 12834 solver.cpp:261]     Train net output #0: loss = 4.11944 (* 1 = 4.11944 loss)
I0506 04:46:21.153795 12834 sgd_solver.cpp:106] Iteration 103500, lr = 1.07374e-05
I0506 04:46:21.155616 12834 solver.cpp:362] Iteration 103500, Testing net (#0)
I0506 04:46:21.155628 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:21.284198 12834 solver.cpp:429]     Test net output #0: accuracy = 0.778
I0506 04:46:21.284217 12834 solver.cpp:429]     Test net output #1: loss = 0.523631 (* 1 = 0.523631 loss)
I0506 04:46:21.286777 12834 solver.cpp:242] Iteration 103500 (79.7993 iter/s, 1.25314s/100 iter), loss = 0.396545
I0506 04:46:21.286798 12834 solver.cpp:261]     Train net output #0: loss = 0.396545 (* 1 = 0.396545 loss)
I0506 04:46:21.286808 12834 sgd_solver.cpp:106] Iteration 103500, lr = 1.07374e-05
I0506 04:46:22.219750 12834 solver.cpp:242] Iteration 103600 (93.8143 iter/s, 1.06594s/100 iter), loss = 1.28264
I0506 04:46:22.219790 12834 solver.cpp:261]     Train net output #0: loss = 1.28264 (* 1 = 1.28264 loss)
I0506 04:46:22.219799 12834 sgd_solver.cpp:106] Iteration 103600, lr = 1.07374e-05
I0506 04:46:22.224586 12834 solver.cpp:242] Iteration 103600 (106.636 iter/s, 0.937769s/100 iter), loss = 0.559993
I0506 04:46:22.224612 12834 solver.cpp:261]     Train net output #0: loss = 0.559993 (* 1 = 0.559993 loss)
I0506 04:46:22.224622 12834 sgd_solver.cpp:106] Iteration 103600, lr = 1.07374e-05
I0506 04:46:23.158195 12834 solver.cpp:242] Iteration 103700 (106.568 iter/s, 0.938372s/100 iter), loss = 1.854
I0506 04:46:23.158233 12834 solver.cpp:261]     Train net output #0: loss = 1.854 (* 1 = 1.854 loss)
I0506 04:46:23.158242 12834 sgd_solver.cpp:106] Iteration 103700, lr = 1.07374e-05
I0506 04:46:23.163033 12834 solver.cpp:242] Iteration 103700 (106.564 iter/s, 0.938402s/100 iter), loss = 0.504169
I0506 04:46:23.163058 12834 solver.cpp:261]     Train net output #0: loss = 0.504169 (* 1 = 0.504169 loss)
I0506 04:46:23.163066 12834 sgd_solver.cpp:106] Iteration 103700, lr = 1.07374e-05
I0506 04:46:24.095692 12834 solver.cpp:242] Iteration 103800 (106.674 iter/s, 0.937435s/100 iter), loss = 0.38789
I0506 04:46:24.095729 12834 solver.cpp:261]     Train net output #0: loss = 0.38789 (* 1 = 0.38789 loss)
I0506 04:46:24.095739 12834 sgd_solver.cpp:106] Iteration 103800, lr = 1.07374e-05
I0506 04:46:24.100471 12834 solver.cpp:242] Iteration 103800 (106.679 iter/s, 0.937395s/100 iter), loss = 0.631031
I0506 04:46:24.100494 12834 solver.cpp:261]     Train net output #0: loss = 0.631031 (* 1 = 0.631031 loss)
I0506 04:46:24.100503 12834 sgd_solver.cpp:106] Iteration 103800, lr = 1.07374e-05
I0506 04:46:25.080835 12834 solver.cpp:242] Iteration 103900 (101.515 iter/s, 0.985075s/100 iter), loss = 2.04111
I0506 04:46:25.080871 12834 solver.cpp:261]     Train net output #0: loss = 2.04111 (* 1 = 2.04111 loss)
I0506 04:46:25.080883 12834 sgd_solver.cpp:106] Iteration 103900, lr = 1.07374e-05
I0506 04:46:25.086097 12834 solver.cpp:242] Iteration 103900 (101.463 iter/s, 0.985582s/100 iter), loss = 0.764358
I0506 04:46:25.086123 12834 solver.cpp:261]     Train net output #0: loss = 0.764358 (* 1 = 0.764358 loss)
I0506 04:46:25.086134 12834 sgd_solver.cpp:106] Iteration 103900, lr = 1.07374e-05
I0506 04:46:26.073554 12834 solver.cpp:362] Iteration 104000, Testing net (#0)
I0506 04:46:26.073581 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:26.196234 12834 solver.cpp:429]     Test net output #0: loss = 1.35308 (* 1 = 1.35308 loss)
I0506 04:46:26.198767 12834 solver.cpp:242] Iteration 104000 (89.4553 iter/s, 1.11788s/100 iter), loss = 0.855196
I0506 04:46:26.198791 12834 solver.cpp:261]     Train net output #0: loss = 0.855196 (* 1 = 0.855196 loss)
I0506 04:46:26.198799 12834 sgd_solver.cpp:106] Iteration 104000, lr = 1.07374e-05
I0506 04:46:26.200696 12834 solver.cpp:362] Iteration 104000, Testing net (#0)
I0506 04:46:26.200719 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:26.329277 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7585
I0506 04:46:26.329296 12834 solver.cpp:429]     Test net output #1: loss = 0.558903 (* 1 = 0.558903 loss)
I0506 04:46:26.331847 12834 solver.cpp:242] Iteration 104000 (80.2759 iter/s, 1.2457s/100 iter), loss = 0.61449
I0506 04:46:26.331868 12834 solver.cpp:261]     Train net output #0: loss = 0.61449 (* 1 = 0.61449 loss)
I0506 04:46:26.331877 12834 sgd_solver.cpp:106] Iteration 104000, lr = 1.07374e-05
I0506 04:46:27.278780 12834 solver.cpp:242] Iteration 104100 (92.5961 iter/s, 1.07996s/100 iter), loss = 0.766935
I0506 04:46:27.278815 12834 solver.cpp:261]     Train net output #0: loss = 0.766935 (* 1 = 0.766935 loss)
I0506 04:46:27.278825 12834 sgd_solver.cpp:106] Iteration 104100, lr = 1.07374e-05
I0506 04:46:27.283551 12834 solver.cpp:242] Iteration 104100 (105.079 iter/s, 0.951664s/100 iter), loss = 0.568013
I0506 04:46:27.283576 12834 solver.cpp:261]     Train net output #0: loss = 0.568013 (* 1 = 0.568013 loss)
I0506 04:46:27.283586 12834 sgd_solver.cpp:106] Iteration 104100, lr = 1.07374e-05
I0506 04:46:28.216501 12834 solver.cpp:242] Iteration 104200 (106.648 iter/s, 0.937664s/100 iter), loss = 1.60818
I0506 04:46:28.216532 12834 solver.cpp:261]     Train net output #0: loss = 1.60818 (* 1 = 1.60818 loss)
I0506 04:46:28.216542 12834 sgd_solver.cpp:106] Iteration 104200, lr = 1.07374e-05
I0506 04:46:28.221344 12834 solver.cpp:242] Iteration 104200 (106.639 iter/s, 0.937741s/100 iter), loss = 0.928321
I0506 04:46:28.221369 12834 solver.cpp:261]     Train net output #0: loss = 0.928321 (* 1 = 0.928321 loss)
I0506 04:46:28.221377 12834 sgd_solver.cpp:106] Iteration 104200, lr = 1.07374e-05
I0506 04:46:29.153836 12834 solver.cpp:242] Iteration 104300 (106.692 iter/s, 0.937275s/100 iter), loss = 1.17003
I0506 04:46:29.153877 12834 solver.cpp:261]     Train net output #0: loss = 1.17003 (* 1 = 1.17003 loss)
I0506 04:46:29.153887 12834 sgd_solver.cpp:106] Iteration 104300, lr = 1.07374e-05
I0506 04:46:29.158632 12834 solver.cpp:242] Iteration 104300 (106.696 iter/s, 0.937246s/100 iter), loss = 0.68789
I0506 04:46:29.158658 12834 solver.cpp:261]     Train net output #0: loss = 0.68789 (* 1 = 0.68789 loss)
I0506 04:46:29.158668 12834 sgd_solver.cpp:106] Iteration 104300, lr = 1.07374e-05
I0506 04:46:30.092082 12834 solver.cpp:242] Iteration 104400 (106.59 iter/s, 0.938172s/100 iter), loss = 1.35498
I0506 04:46:30.092123 12834 solver.cpp:261]     Train net output #0: loss = 1.35498 (* 1 = 1.35498 loss)
I0506 04:46:30.092133 12834 sgd_solver.cpp:106] Iteration 104400, lr = 1.07374e-05
I0506 04:46:30.096853 12834 solver.cpp:242] Iteration 104400 (106.59 iter/s, 0.938175s/100 iter), loss = 0.957423
I0506 04:46:30.096876 12834 solver.cpp:261]     Train net output #0: loss = 0.957423 (* 1 = 0.957423 loss)
I0506 04:46:30.096885 12834 sgd_solver.cpp:106] Iteration 104400, lr = 1.07374e-05
I0506 04:46:31.074911 12834 solver.cpp:362] Iteration 104500, Testing net (#0)
I0506 04:46:31.074941 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:31.208048 12834 solver.cpp:429]     Test net output #0: loss = 1.26119 (* 1 = 1.26119 loss)
I0506 04:46:31.210696 12834 solver.cpp:242] Iteration 104500 (89.4012 iter/s, 1.11855s/100 iter), loss = 1.10724
I0506 04:46:31.210723 12834 solver.cpp:261]     Train net output #0: loss = 1.10724 (* 1 = 1.10724 loss)
I0506 04:46:31.210734 12834 sgd_solver.cpp:106] Iteration 104500, lr = 1.07374e-05
I0506 04:46:31.212934 12834 solver.cpp:362] Iteration 104500, Testing net (#0)
I0506 04:46:31.212950 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:31.345612 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7675
I0506 04:46:31.345631 12834 solver.cpp:429]     Test net output #1: loss = 0.534043 (* 1 = 0.534043 loss)
I0506 04:46:31.348191 12834 solver.cpp:242] Iteration 104500 (79.9174 iter/s, 1.25129s/100 iter), loss = 0.60772
I0506 04:46:31.348209 12834 solver.cpp:261]     Train net output #0: loss = 0.60772 (* 1 = 0.60772 loss)
I0506 04:46:31.348228 12834 sgd_solver.cpp:106] Iteration 104500, lr = 1.07374e-05
I0506 04:46:32.281451 12834 solver.cpp:242] Iteration 104600 (93.3973 iter/s, 1.07069s/100 iter), loss = 1.36379
I0506 04:46:32.281499 12834 solver.cpp:261]     Train net output #0: loss = 1.36379 (* 1 = 1.36379 loss)
I0506 04:46:32.281718 12834 sgd_solver.cpp:106] Iteration 104600, lr = 1.07374e-05
I0506 04:46:32.286530 12834 solver.cpp:242] Iteration 104600 (106.576 iter/s, 0.938301s/100 iter), loss = 0.447188
I0506 04:46:32.286556 12834 solver.cpp:261]     Train net output #0: loss = 0.447188 (* 1 = 0.447188 loss)
I0506 04:46:32.286564 12834 sgd_solver.cpp:106] Iteration 104600, lr = 1.07374e-05
I0506 04:46:33.219003 12834 solver.cpp:242] Iteration 104700 (106.669 iter/s, 0.937481s/100 iter), loss = 0.69875
I0506 04:46:33.219044 12834 solver.cpp:261]     Train net output #0: loss = 0.69875 (* 1 = 0.69875 loss)
I0506 04:46:33.219053 12834 sgd_solver.cpp:106] Iteration 104700, lr = 1.07374e-05
I0506 04:46:33.223816 12834 solver.cpp:242] Iteration 104700 (106.696 iter/s, 0.937243s/100 iter), loss = 0.403774
I0506 04:46:33.223841 12834 solver.cpp:261]     Train net output #0: loss = 0.403774 (* 1 = 0.403774 loss)
I0506 04:46:33.223850 12834 sgd_solver.cpp:106] Iteration 104700, lr = 1.07374e-05
I0506 04:46:34.156960 12834 solver.cpp:242] Iteration 104800 (106.623 iter/s, 0.937884s/100 iter), loss = 0.314982
I0506 04:46:34.157001 12834 solver.cpp:261]     Train net output #0: loss = 0.314982 (* 1 = 0.314982 loss)
I0506 04:46:34.157009 12834 sgd_solver.cpp:106] Iteration 104800, lr = 1.07374e-05
I0506 04:46:34.161711 12834 solver.cpp:242] Iteration 104800 (106.627 iter/s, 0.937852s/100 iter), loss = 0.567402
I0506 04:46:34.161738 12834 solver.cpp:261]     Train net output #0: loss = 0.567402 (* 1 = 0.567402 loss)
I0506 04:46:34.161758 12834 sgd_solver.cpp:106] Iteration 104800, lr = 1.07374e-05
I0506 04:46:35.148510 12834 solver.cpp:242] Iteration 104900 (100.859 iter/s, 0.991484s/100 iter), loss = 1.08014
I0506 04:46:35.148558 12834 solver.cpp:261]     Train net output #0: loss = 1.08014 (* 1 = 1.08014 loss)
I0506 04:46:35.148571 12834 sgd_solver.cpp:106] Iteration 104900, lr = 1.07374e-05
I0506 04:46:35.153878 12834 solver.cpp:242] Iteration 104900 (100.795 iter/s, 0.992109s/100 iter), loss = 0.789113
I0506 04:46:35.153908 12834 solver.cpp:261]     Train net output #0: loss = 0.789113 (* 1 = 0.789113 loss)
I0506 04:46:35.153920 12834 sgd_solver.cpp:106] Iteration 104900, lr = 1.07374e-05
I0506 04:46:36.181818 12834 solver.cpp:362] Iteration 105000, Testing net (#0)
I0506 04:46:36.181845 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:36.314906 12834 solver.cpp:429]     Test net output #0: loss = 1.47051 (* 1 = 1.47051 loss)
I0506 04:46:36.317555 12834 solver.cpp:242] Iteration 105000 (85.5446 iter/s, 1.16898s/100 iter), loss = 3.55564
I0506 04:46:36.317579 12834 solver.cpp:261]     Train net output #0: loss = 3.55564 (* 1 = 3.55564 loss)
I0506 04:46:36.317590 12834 sgd_solver.cpp:106] Iteration 105000, lr = 1.07374e-05
I0506 04:46:36.319773 12834 solver.cpp:362] Iteration 105000, Testing net (#0)
I0506 04:46:36.319789 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:36.460714 12834 solver.cpp:429]     Test net output #0: accuracy = 0.743
I0506 04:46:36.460738 12834 solver.cpp:429]     Test net output #1: loss = 0.597633 (* 1 = 0.597633 loss)
I0506 04:46:36.463413 12834 solver.cpp:242] Iteration 105000 (76.3661 iter/s, 1.30948s/100 iter), loss = 0.761331
I0506 04:46:36.463438 12834 solver.cpp:261]     Train net output #0: loss = 0.761331 (* 1 = 0.761331 loss)
I0506 04:46:36.463449 12834 sgd_solver.cpp:106] Iteration 105000, lr = 1.07374e-05
I0506 04:46:37.477629 12834 solver.cpp:242] Iteration 105100 (86.2052 iter/s, 1.16002s/100 iter), loss = 2.07843
I0506 04:46:37.477669 12834 solver.cpp:261]     Train net output #0: loss = 2.07843 (* 1 = 2.07843 loss)
I0506 04:46:37.477679 12834 sgd_solver.cpp:106] Iteration 105100, lr = 1.07374e-05
I0506 04:46:37.482491 12834 solver.cpp:242] Iteration 105100 (98.133 iter/s, 1.01903s/100 iter), loss = 0.713164
I0506 04:46:37.482523 12834 solver.cpp:261]     Train net output #0: loss = 0.713164 (* 1 = 0.713164 loss)
I0506 04:46:37.482533 12834 sgd_solver.cpp:106] Iteration 105100, lr = 1.07374e-05
I0506 04:46:38.416198 12834 solver.cpp:242] Iteration 105200 (106.553 iter/s, 0.938501s/100 iter), loss = 0.876472
I0506 04:46:38.416234 12834 solver.cpp:261]     Train net output #0: loss = 0.876472 (* 1 = 0.876472 loss)
I0506 04:46:38.416244 12834 sgd_solver.cpp:106] Iteration 105200, lr = 1.07374e-05
I0506 04:46:38.420967 12834 solver.cpp:242] Iteration 105200 (106.561 iter/s, 0.938425s/100 iter), loss = 0.124638
I0506 04:46:38.420994 12834 solver.cpp:261]     Train net output #0: loss = 0.124638 (* 1 = 0.124638 loss)
I0506 04:46:38.421002 12834 sgd_solver.cpp:106] Iteration 105200, lr = 1.07374e-05
I0506 04:46:39.353770 12834 solver.cpp:242] Iteration 105300 (106.666 iter/s, 0.937503s/100 iter), loss = 1.09939
I0506 04:46:39.353809 12834 solver.cpp:261]     Train net output #0: loss = 1.09939 (* 1 = 1.09939 loss)
I0506 04:46:39.353818 12834 sgd_solver.cpp:106] Iteration 105300, lr = 1.07374e-05
I0506 04:46:39.358598 12834 solver.cpp:242] Iteration 105300 (106.657 iter/s, 0.937586s/100 iter), loss = 0.558423
I0506 04:46:39.358623 12834 solver.cpp:261]     Train net output #0: loss = 0.558423 (* 1 = 0.558423 loss)
I0506 04:46:39.358631 12834 sgd_solver.cpp:106] Iteration 105300, lr = 1.07374e-05
I0506 04:46:40.291345 12834 solver.cpp:242] Iteration 105400 (106.665 iter/s, 0.937512s/100 iter), loss = 0.645643
I0506 04:46:40.291383 12834 solver.cpp:261]     Train net output #0: loss = 0.645643 (* 1 = 0.645643 loss)
I0506 04:46:40.291393 12834 sgd_solver.cpp:106] Iteration 105400, lr = 1.07374e-05
I0506 04:46:40.296116 12834 solver.cpp:242] Iteration 105400 (106.67 iter/s, 0.937475s/100 iter), loss = 0.342028
I0506 04:46:40.296142 12834 solver.cpp:261]     Train net output #0: loss = 0.342028 (* 1 = 0.342028 loss)
I0506 04:46:40.296151 12834 sgd_solver.cpp:106] Iteration 105400, lr = 1.07374e-05
I0506 04:46:41.226182 12834 solver.cpp:362] Iteration 105500, Testing net (#0)
I0506 04:46:41.226200 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:41.348814 12834 solver.cpp:429]     Test net output #0: loss = 1.326 (* 1 = 1.326 loss)
I0506 04:46:41.351336 12834 solver.cpp:242] Iteration 105500 (94.3454 iter/s, 1.05994s/100 iter), loss = 1.34858
I0506 04:46:41.351356 12834 solver.cpp:261]     Train net output #0: loss = 1.34858 (* 1 = 1.34858 loss)
I0506 04:46:41.351364 12834 sgd_solver.cpp:106] Iteration 105500, lr = 1.07374e-05
I0506 04:46:41.353212 12834 solver.cpp:362] Iteration 105500, Testing net (#0)
I0506 04:46:41.353226 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:41.482342 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7685
I0506 04:46:41.482362 12834 solver.cpp:429]     Test net output #1: loss = 0.547025 (* 1 = 0.547025 loss)
I0506 04:46:41.484916 12834 solver.cpp:242] Iteration 105500 (84.1217 iter/s, 1.18875s/100 iter), loss = 0.598748
I0506 04:46:41.484937 12834 solver.cpp:261]     Train net output #0: loss = 0.598748 (* 1 = 0.598748 loss)
I0506 04:46:41.484946 12834 sgd_solver.cpp:106] Iteration 105500, lr = 1.07374e-05
I0506 04:46:42.417708 12834 solver.cpp:242] Iteration 105600 (93.7801 iter/s, 1.06632s/100 iter), loss = 0.549512
I0506 04:46:42.417743 12834 solver.cpp:261]     Train net output #0: loss = 0.549512 (* 1 = 0.549512 loss)
I0506 04:46:42.417753 12834 sgd_solver.cpp:106] Iteration 105600, lr = 1.07374e-05
I0506 04:46:42.422472 12834 solver.cpp:242] Iteration 105600 (106.665 iter/s, 0.937516s/100 iter), loss = 0.471245
I0506 04:46:42.422497 12834 solver.cpp:261]     Train net output #0: loss = 0.471245 (* 1 = 0.471245 loss)
I0506 04:46:42.422504 12834 sgd_solver.cpp:106] Iteration 105600, lr = 1.07374e-05
I0506 04:46:43.425930 12834 solver.cpp:242] Iteration 105700 (99.1912 iter/s, 1.00815s/100 iter), loss = 1.4638
I0506 04:46:43.425964 12834 solver.cpp:261]     Train net output #0: loss = 1.4638 (* 1 = 1.4638 loss)
I0506 04:46:43.425982 12834 sgd_solver.cpp:106] Iteration 105700, lr = 1.07374e-05
I0506 04:46:43.430712 12834 solver.cpp:242] Iteration 105700 (99.187 iter/s, 1.0082s/100 iter), loss = 0.678418
I0506 04:46:43.430737 12834 solver.cpp:261]     Train net output #0: loss = 0.678418 (* 1 = 0.678418 loss)
I0506 04:46:43.430745 12834 sgd_solver.cpp:106] Iteration 105700, lr = 1.07374e-05
I0506 04:46:44.363987 12834 solver.cpp:242] Iteration 105800 (106.61 iter/s, 0.938s/100 iter), loss = 1.59868
I0506 04:46:44.364017 12834 solver.cpp:261]     Train net output #0: loss = 1.59868 (* 1 = 1.59868 loss)
I0506 04:46:44.364025 12834 sgd_solver.cpp:106] Iteration 105800, lr = 1.07374e-05
I0506 04:46:44.368862 12834 solver.cpp:242] Iteration 105800 (106.599 iter/s, 0.938097s/100 iter), loss = 0.856683
I0506 04:46:44.368886 12834 solver.cpp:261]     Train net output #0: loss = 0.856683 (* 1 = 0.856683 loss)
I0506 04:46:44.368896 12834 sgd_solver.cpp:106] Iteration 105800, lr = 1.07374e-05
I0506 04:46:45.301558 12834 solver.cpp:242] Iteration 105900 (106.665 iter/s, 0.937514s/100 iter), loss = 2.68133
I0506 04:46:45.301599 12834 solver.cpp:261]     Train net output #0: loss = 2.68133 (* 1 = 2.68133 loss)
I0506 04:46:45.301607 12834 sgd_solver.cpp:106] Iteration 105900, lr = 1.07374e-05
I0506 04:46:45.306330 12834 solver.cpp:242] Iteration 105900 (106.675 iter/s, 0.937426s/100 iter), loss = 0.671788
I0506 04:46:45.306356 12834 solver.cpp:261]     Train net output #0: loss = 0.671788 (* 1 = 0.671788 loss)
I0506 04:46:45.306365 12834 sgd_solver.cpp:106] Iteration 105900, lr = 1.07374e-05
I0506 04:46:46.236307 12834 solver.cpp:362] Iteration 106000, Testing net (#0)
I0506 04:46:46.236336 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:46.359042 12834 solver.cpp:429]     Test net output #0: loss = 1.3208 (* 1 = 1.3208 loss)
I0506 04:46:46.361562 12834 solver.cpp:242] Iteration 106000 (94.3446 iter/s, 1.05994s/100 iter), loss = 2.24337
I0506 04:46:46.361582 12834 solver.cpp:261]     Train net output #0: loss = 2.24337 (* 1 = 2.24337 loss)
I0506 04:46:46.361590 12834 sgd_solver.cpp:106] Iteration 106000, lr = 1.07374e-05
I0506 04:46:46.363481 12834 solver.cpp:362] Iteration 106000, Testing net (#0)
I0506 04:46:46.363493 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:46.492612 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7635
I0506 04:46:46.492630 12834 solver.cpp:429]     Test net output #1: loss = 0.5613 (* 1 = 0.5613 loss)
I0506 04:46:46.495178 12834 solver.cpp:242] Iteration 106000 (84.1183 iter/s, 1.1888s/100 iter), loss = 0.848205
I0506 04:46:46.495198 12834 solver.cpp:261]     Train net output #0: loss = 0.848205 (* 1 = 0.848205 loss)
I0506 04:46:46.495208 12834 sgd_solver.cpp:106] Iteration 106000, lr = 1.07374e-05
I0506 04:46:47.516891 12834 solver.cpp:242] Iteration 106100 (86.5595 iter/s, 1.15527s/100 iter), loss = 0.25451
I0506 04:46:47.516938 12834 solver.cpp:261]     Train net output #0: loss = 0.25451 (* 1 = 0.25451 loss)
I0506 04:46:47.516949 12834 sgd_solver.cpp:106] Iteration 106100, lr = 1.07374e-05
I0506 04:46:47.522189 12834 solver.cpp:242] Iteration 106100 (97.3739 iter/s, 1.02697s/100 iter), loss = 0.615613
I0506 04:46:47.522218 12834 solver.cpp:261]     Train net output #0: loss = 0.615613 (* 1 = 0.615613 loss)
I0506 04:46:47.522229 12834 sgd_solver.cpp:106] Iteration 106100, lr = 1.07374e-05
I0506 04:46:48.532742 12834 solver.cpp:242] Iteration 106200 (98.4474 iter/s, 1.01577s/100 iter), loss = 1.07079
I0506 04:46:48.532783 12834 solver.cpp:261]     Train net output #0: loss = 1.07079 (* 1 = 1.07079 loss)
I0506 04:46:48.532793 12834 sgd_solver.cpp:106] Iteration 106200, lr = 1.07374e-05
I0506 04:46:48.537508 12834 solver.cpp:242] Iteration 106200 (98.4958 iter/s, 1.01527s/100 iter), loss = 0.687028
I0506 04:46:48.537533 12834 solver.cpp:261]     Train net output #0: loss = 0.687028 (* 1 = 0.687028 loss)
I0506 04:46:48.537541 12834 sgd_solver.cpp:106] Iteration 106200, lr = 1.07374e-05
I0506 04:46:49.469840 12834 solver.cpp:242] Iteration 106300 (106.72 iter/s, 0.937029s/100 iter), loss = 0.564806
I0506 04:46:49.469889 12834 solver.cpp:261]     Train net output #0: loss = 0.564806 (* 1 = 0.564806 loss)
I0506 04:46:49.469899 12834 sgd_solver.cpp:106] Iteration 106300, lr = 1.07374e-05
I0506 04:46:49.474613 12834 solver.cpp:242] Iteration 106300 (106.716 iter/s, 0.937063s/100 iter), loss = 0.472295
I0506 04:46:49.474637 12834 solver.cpp:261]     Train net output #0: loss = 0.472295 (* 1 = 0.472295 loss)
I0506 04:46:49.474647 12834 sgd_solver.cpp:106] Iteration 106300, lr = 1.07374e-05
I0506 04:46:50.407236 12834 solver.cpp:242] Iteration 106400 (106.688 iter/s, 0.937314s/100 iter), loss = 0.512943
I0506 04:46:50.407275 12834 solver.cpp:261]     Train net output #0: loss = 0.512943 (* 1 = 0.512943 loss)
I0506 04:46:50.407284 12834 sgd_solver.cpp:106] Iteration 106400, lr = 1.07374e-05
I0506 04:46:50.412008 12834 solver.cpp:242] Iteration 106400 (106.684 iter/s, 0.93735s/100 iter), loss = 0.200344
I0506 04:46:50.412034 12834 solver.cpp:261]     Train net output #0: loss = 0.200344 (* 1 = 0.200344 loss)
I0506 04:46:50.412044 12834 sgd_solver.cpp:106] Iteration 106400, lr = 1.07374e-05
I0506 04:46:51.341706 12834 solver.cpp:362] Iteration 106500, Testing net (#0)
I0506 04:46:51.341732 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:51.464521 12834 solver.cpp:429]     Test net output #0: loss = 1.18237 (* 1 = 1.18237 loss)
I0506 04:46:51.467041 12834 solver.cpp:242] Iteration 106500 (94.3621 iter/s, 1.05975s/100 iter), loss = 2.38857
I0506 04:46:51.467067 12834 solver.cpp:261]     Train net output #0: loss = 2.38857 (* 1 = 2.38857 loss)
I0506 04:46:51.467075 12834 sgd_solver.cpp:106] Iteration 106500, lr = 1.07374e-05
I0506 04:46:51.468893 12834 solver.cpp:362] Iteration 106500, Testing net (#0)
I0506 04:46:51.468905 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:51.597640 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7655
I0506 04:46:51.597661 12834 solver.cpp:429]     Test net output #1: loss = 0.531129 (* 1 = 0.531129 loss)
I0506 04:46:51.600204 12834 solver.cpp:242] Iteration 106500 (84.1645 iter/s, 1.18815s/100 iter), loss = 0.691301
I0506 04:46:51.600225 12834 solver.cpp:261]     Train net output #0: loss = 0.691301 (* 1 = 0.691301 loss)
I0506 04:46:51.600234 12834 sgd_solver.cpp:106] Iteration 106500, lr = 1.07374e-05
I0506 04:46:52.533008 12834 solver.cpp:242] Iteration 106600 (93.8167 iter/s, 1.06591s/100 iter), loss = 1.87917
I0506 04:46:52.533046 12834 solver.cpp:261]     Train net output #0: loss = 1.87917 (* 1 = 1.87917 loss)
I0506 04:46:52.533056 12834 sgd_solver.cpp:106] Iteration 106600, lr = 1.07374e-05
I0506 04:46:52.537770 12834 solver.cpp:242] Iteration 106600 (106.664 iter/s, 0.937527s/100 iter), loss = 0.55548
I0506 04:46:52.537793 12834 solver.cpp:261]     Train net output #0: loss = 0.55548 (* 1 = 0.55548 loss)
I0506 04:46:52.537802 12834 sgd_solver.cpp:106] Iteration 106600, lr = 1.07374e-05
I0506 04:46:53.478469 12834 solver.cpp:242] Iteration 106700 (105.776 iter/s, 0.945398s/100 iter), loss = 0.795443
I0506 04:46:53.478508 12834 solver.cpp:261]     Train net output #0: loss = 0.795443 (* 1 = 0.795443 loss)
I0506 04:46:53.478518 12834 sgd_solver.cpp:106] Iteration 106700, lr = 1.07374e-05
I0506 04:46:53.483237 12834 solver.cpp:242] Iteration 106700 (105.773 iter/s, 0.945424s/100 iter), loss = 0.831646
I0506 04:46:53.483261 12834 solver.cpp:261]     Train net output #0: loss = 0.831646 (* 1 = 0.831646 loss)
I0506 04:46:53.483270 12834 sgd_solver.cpp:106] Iteration 106700, lr = 1.07374e-05
I0506 04:46:54.415993 12834 solver.cpp:242] Iteration 106800 (106.672 iter/s, 0.937455s/100 iter), loss = 1.77933
I0506 04:46:54.416033 12834 solver.cpp:261]     Train net output #0: loss = 1.77933 (* 1 = 1.77933 loss)
I0506 04:46:54.416043 12834 sgd_solver.cpp:106] Iteration 106800, lr = 1.07374e-05
I0506 04:46:54.420784 12834 solver.cpp:242] Iteration 106800 (106.666 iter/s, 0.937505s/100 iter), loss = 0.456163
I0506 04:46:54.420809 12834 solver.cpp:261]     Train net output #0: loss = 0.456163 (* 1 = 0.456163 loss)
I0506 04:46:54.420826 12834 sgd_solver.cpp:106] Iteration 106800, lr = 1.07374e-05
I0506 04:46:55.354100 12834 solver.cpp:242] Iteration 106900 (106.605 iter/s, 0.938045s/100 iter), loss = 1.25574
I0506 04:46:55.354137 12834 solver.cpp:261]     Train net output #0: loss = 1.25574 (* 1 = 1.25574 loss)
I0506 04:46:55.354146 12834 sgd_solver.cpp:106] Iteration 106900, lr = 1.07374e-05
I0506 04:46:55.358950 12834 solver.cpp:242] Iteration 106900 (106.597 iter/s, 0.938114s/100 iter), loss = 0.665888
I0506 04:46:55.358974 12834 solver.cpp:261]     Train net output #0: loss = 0.665888 (* 1 = 0.665888 loss)
I0506 04:46:55.358983 12834 sgd_solver.cpp:106] Iteration 106900, lr = 1.07374e-05
I0506 04:46:56.289196 12834 solver.cpp:362] Iteration 107000, Testing net (#0)
I0506 04:46:56.289216 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:56.411892 12834 solver.cpp:429]     Test net output #0: loss = 1.18783 (* 1 = 1.18783 loss)
I0506 04:46:56.414404 12834 solver.cpp:242] Iteration 107000 (94.3174 iter/s, 1.06025s/100 iter), loss = 0.66455
I0506 04:46:56.414425 12834 solver.cpp:261]     Train net output #0: loss = 0.66455 (* 1 = 0.66455 loss)
I0506 04:46:56.414434 12834 sgd_solver.cpp:106] Iteration 107000, lr = 1.07374e-05
I0506 04:46:56.416255 12834 solver.cpp:362] Iteration 107000, Testing net (#0)
I0506 04:46:56.416268 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:46:56.544922 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7575
I0506 04:46:56.544941 12834 solver.cpp:429]     Test net output #1: loss = 0.552086 (* 1 = 0.552086 loss)
I0506 04:46:56.547492 12834 solver.cpp:242] Iteration 107000 (84.14 iter/s, 1.1885s/100 iter), loss = 0.435333
I0506 04:46:56.547510 12834 solver.cpp:261]     Train net output #0: loss = 0.435333 (* 1 = 0.435333 loss)
I0506 04:46:56.547519 12834 sgd_solver.cpp:106] Iteration 107000, lr = 1.07374e-05
I0506 04:46:57.480677 12834 solver.cpp:242] Iteration 107100 (93.7894 iter/s, 1.06622s/100 iter), loss = 1.62322
I0506 04:46:57.480711 12834 solver.cpp:261]     Train net output #0: loss = 1.62322 (* 1 = 1.62322 loss)
I0506 04:46:57.480720 12834 sgd_solver.cpp:106] Iteration 107100, lr = 1.07374e-05
I0506 04:46:57.485451 12834 solver.cpp:242] Iteration 107100 (106.619 iter/s, 0.937922s/100 iter), loss = 0.689866
I0506 04:46:57.485476 12834 solver.cpp:261]     Train net output #0: loss = 0.689866 (* 1 = 0.689866 loss)
I0506 04:46:57.485486 12834 sgd_solver.cpp:106] Iteration 107100, lr = 1.07374e-05
I0506 04:46:58.418701 12834 solver.cpp:242] Iteration 107200 (106.614 iter/s, 0.937963s/100 iter), loss = 1.44199
I0506 04:46:58.418743 12834 solver.cpp:261]     Train net output #0: loss = 1.44199 (* 1 = 1.44199 loss)
I0506 04:46:58.418752 12834 sgd_solver.cpp:106] Iteration 107200, lr = 1.07374e-05
I0506 04:46:58.423470 12834 solver.cpp:242] Iteration 107200 (106.613 iter/s, 0.937975s/100 iter), loss = 0.379172
I0506 04:46:58.423494 12834 solver.cpp:261]     Train net output #0: loss = 0.379172 (* 1 = 0.379172 loss)
I0506 04:46:58.423503 12834 sgd_solver.cpp:106] Iteration 107200, lr = 1.07374e-05
I0506 04:46:59.428056 12834 solver.cpp:242] Iteration 107300 (99.0806 iter/s, 1.00928s/100 iter), loss = 2.71244
I0506 04:46:59.428100 12834 solver.cpp:261]     Train net output #0: loss = 2.71244 (* 1 = 2.71244 loss)
I0506 04:46:59.428110 12834 sgd_solver.cpp:106] Iteration 107300, lr = 1.07374e-05
I0506 04:46:59.432847 12834 solver.cpp:242] Iteration 107300 (99.0753 iter/s, 1.00933s/100 iter), loss = 0.532141
I0506 04:46:59.432873 12834 solver.cpp:261]     Train net output #0: loss = 0.532141 (* 1 = 0.532141 loss)
I0506 04:46:59.432883 12834 sgd_solver.cpp:106] Iteration 107300, lr = 1.07374e-05
I0506 04:47:00.370800 12834 solver.cpp:242] Iteration 107400 (106.081 iter/s, 0.942672s/100 iter), loss = 1.24975
I0506 04:47:00.370847 12834 solver.cpp:261]     Train net output #0: loss = 1.24975 (* 1 = 1.24975 loss)
I0506 04:47:00.370857 12834 sgd_solver.cpp:106] Iteration 107400, lr = 1.07374e-05
I0506 04:47:00.375607 12834 solver.cpp:242] Iteration 107400 (106.077 iter/s, 0.942715s/100 iter), loss = 0.402735
I0506 04:47:00.375643 12834 solver.cpp:261]     Train net output #0: loss = 0.402735 (* 1 = 0.402735 loss)
I0506 04:47:00.375653 12834 sgd_solver.cpp:106] Iteration 107400, lr = 1.07374e-05
I0506 04:47:01.310134 12834 solver.cpp:362] Iteration 107500, Testing net (#0)
I0506 04:47:01.310160 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:01.432880 12834 solver.cpp:429]     Test net output #0: loss = 1.5207 (* 1 = 1.5207 loss)
I0506 04:47:01.435400 12834 solver.cpp:242] Iteration 107500 (93.9379 iter/s, 1.06453s/100 iter), loss = 1.34495
I0506 04:47:01.435421 12834 solver.cpp:261]     Train net output #0: loss = 1.34495 (* 1 = 1.34495 loss)
I0506 04:47:01.435430 12834 sgd_solver.cpp:106] Iteration 107500, lr = 1.07374e-05
I0506 04:47:01.437288 12834 solver.cpp:362] Iteration 107500, Testing net (#0)
I0506 04:47:01.437302 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:01.567086 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7715
I0506 04:47:01.567106 12834 solver.cpp:429]     Test net output #1: loss = 0.545125 (* 1 = 0.545125 loss)
I0506 04:47:01.569653 12834 solver.cpp:242] Iteration 107500 (83.7529 iter/s, 1.19399s/100 iter), loss = 0.824637
I0506 04:47:01.569674 12834 solver.cpp:261]     Train net output #0: loss = 0.824637 (* 1 = 0.824637 loss)
I0506 04:47:01.569682 12834 sgd_solver.cpp:106] Iteration 107500, lr = 1.07374e-05
I0506 04:47:02.502738 12834 solver.cpp:242] Iteration 107600 (93.6953 iter/s, 1.06729s/100 iter), loss = 1.03329
I0506 04:47:02.502779 12834 solver.cpp:261]     Train net output #0: loss = 1.03329 (* 1 = 1.03329 loss)
I0506 04:47:02.502789 12834 sgd_solver.cpp:106] Iteration 107600, lr = 1.07374e-05
I0506 04:47:02.507524 12834 solver.cpp:242] Iteration 107600 (106.629 iter/s, 0.93783s/100 iter), loss = 0.455922
I0506 04:47:02.507549 12834 solver.cpp:261]     Train net output #0: loss = 0.455922 (* 1 = 0.455922 loss)
I0506 04:47:02.507557 12834 sgd_solver.cpp:106] Iteration 107600, lr = 1.07374e-05
I0506 04:47:03.454447 12834 solver.cpp:242] Iteration 107700 (105.082 iter/s, 0.951635s/100 iter), loss = 4.14456
I0506 04:47:03.454486 12834 solver.cpp:261]     Train net output #0: loss = 4.14456 (* 1 = 4.14456 loss)
I0506 04:47:03.454496 12834 sgd_solver.cpp:106] Iteration 107700, lr = 1.07374e-05
I0506 04:47:03.459270 12834 solver.cpp:242] Iteration 107700 (105.075 iter/s, 0.951704s/100 iter), loss = 0.855495
I0506 04:47:03.459297 12834 solver.cpp:261]     Train net output #0: loss = 0.855495 (* 1 = 0.855495 loss)
I0506 04:47:03.459307 12834 sgd_solver.cpp:106] Iteration 107700, lr = 1.07374e-05
I0506 04:47:04.392536 12834 solver.cpp:242] Iteration 107800 (106.607 iter/s, 0.938026s/100 iter), loss = 0.629133
I0506 04:47:04.392580 12834 solver.cpp:261]     Train net output #0: loss = 0.629133 (* 1 = 0.629133 loss)
I0506 04:47:04.392590 12834 sgd_solver.cpp:106] Iteration 107800, lr = 1.07374e-05
I0506 04:47:04.397380 12834 solver.cpp:242] Iteration 107800 (106.604 iter/s, 0.938055s/100 iter), loss = 0.449812
I0506 04:47:04.397404 12834 solver.cpp:261]     Train net output #0: loss = 0.449812 (* 1 = 0.449812 loss)
I0506 04:47:04.397413 12834 sgd_solver.cpp:106] Iteration 107800, lr = 1.07374e-05
I0506 04:47:05.330349 12834 solver.cpp:242] Iteration 107900 (106.639 iter/s, 0.937743s/100 iter), loss = 1.5523
I0506 04:47:05.330390 12834 solver.cpp:261]     Train net output #0: loss = 1.5523 (* 1 = 1.5523 loss)
I0506 04:47:05.330399 12834 sgd_solver.cpp:106] Iteration 107900, lr = 1.07374e-05
I0506 04:47:05.335129 12834 solver.cpp:242] Iteration 107900 (106.643 iter/s, 0.937706s/100 iter), loss = 0.472976
I0506 04:47:05.335152 12834 solver.cpp:261]     Train net output #0: loss = 0.472976 (* 1 = 0.472976 loss)
I0506 04:47:05.335161 12834 sgd_solver.cpp:106] Iteration 107900, lr = 1.07374e-05
I0506 04:47:06.276165 12834 solver.cpp:362] Iteration 108000, Testing net (#0)
I0506 04:47:06.276190 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:06.398962 12834 solver.cpp:429]     Test net output #0: loss = 1.21296 (* 1 = 1.21296 loss)
I0506 04:47:06.401491 12834 solver.cpp:242] Iteration 108000 (93.3635 iter/s, 1.07108s/100 iter), loss = 1.15234
I0506 04:47:06.401515 12834 solver.cpp:261]     Train net output #0: loss = 1.15234 (* 1 = 1.15234 loss)
I0506 04:47:06.401523 12834 sgd_solver.cpp:106] Iteration 108000, lr = 1.07374e-05
I0506 04:47:06.403342 12834 solver.cpp:362] Iteration 108000, Testing net (#0)
I0506 04:47:06.403355 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:06.532105 12834 solver.cpp:429]     Test net output #0: accuracy = 0.765
I0506 04:47:06.532125 12834 solver.cpp:429]     Test net output #1: loss = 0.533849 (* 1 = 0.533849 loss)
I0506 04:47:06.534672 12834 solver.cpp:242] Iteration 108000 (83.3682 iter/s, 1.1995s/100 iter), loss = 0.333539
I0506 04:47:06.534693 12834 solver.cpp:261]     Train net output #0: loss = 0.333539 (* 1 = 0.333539 loss)
I0506 04:47:06.534700 12834 sgd_solver.cpp:106] Iteration 108000, lr = 1.07374e-05
I0506 04:47:07.467795 12834 solver.cpp:242] Iteration 108100 (93.7863 iter/s, 1.06625s/100 iter), loss = 0.719752
I0506 04:47:07.467833 12834 solver.cpp:261]     Train net output #0: loss = 0.719752 (* 1 = 0.719752 loss)
I0506 04:47:07.467842 12834 sgd_solver.cpp:106] Iteration 108100, lr = 1.07374e-05
I0506 04:47:07.472596 12834 solver.cpp:242] Iteration 108100 (106.623 iter/s, 0.937886s/100 iter), loss = 0.392231
I0506 04:47:07.472622 12834 solver.cpp:261]     Train net output #0: loss = 0.392231 (* 1 = 0.392231 loss)
I0506 04:47:07.472631 12834 sgd_solver.cpp:106] Iteration 108100, lr = 1.07374e-05
I0506 04:47:08.492305 12834 solver.cpp:242] Iteration 108200 (97.6148 iter/s, 1.02444s/100 iter), loss = 1.13929
I0506 04:47:08.492349 12834 solver.cpp:261]     Train net output #0: loss = 1.13929 (* 1 = 1.13929 loss)
I0506 04:47:08.492360 12834 sgd_solver.cpp:106] Iteration 108200, lr = 1.07374e-05
I0506 04:47:08.497586 12834 solver.cpp:242] Iteration 108200 (97.5665 iter/s, 1.02494s/100 iter), loss = 0.44612
I0506 04:47:08.497614 12834 solver.cpp:261]     Train net output #0: loss = 0.44612 (* 1 = 0.44612 loss)
I0506 04:47:08.497625 12834 sgd_solver.cpp:106] Iteration 108200, lr = 1.07374e-05
I0506 04:47:09.451494 12834 solver.cpp:242] Iteration 108300 (104.262 iter/s, 0.959121s/100 iter), loss = 0.92716
I0506 04:47:09.451530 12834 solver.cpp:261]     Train net output #0: loss = 0.92716 (* 1 = 0.92716 loss)
I0506 04:47:09.451540 12834 sgd_solver.cpp:106] Iteration 108300, lr = 1.07374e-05
I0506 04:47:09.456375 12834 solver.cpp:242] Iteration 108300 (104.303 iter/s, 0.958744s/100 iter), loss = 0.688389
I0506 04:47:09.456400 12834 solver.cpp:261]     Train net output #0: loss = 0.688389 (* 1 = 0.688389 loss)
I0506 04:47:09.456408 12834 sgd_solver.cpp:106] Iteration 108300, lr = 1.07374e-05
I0506 04:47:10.389370 12834 solver.cpp:242] Iteration 108400 (106.632 iter/s, 0.937809s/100 iter), loss = 0.681811
I0506 04:47:10.389405 12834 solver.cpp:261]     Train net output #0: loss = 0.681811 (* 1 = 0.681811 loss)
I0506 04:47:10.389415 12834 sgd_solver.cpp:106] Iteration 108400, lr = 1.07374e-05
I0506 04:47:10.394140 12834 solver.cpp:242] Iteration 108400 (106.641 iter/s, 0.937722s/100 iter), loss = 0.633528
I0506 04:47:10.394165 12834 solver.cpp:261]     Train net output #0: loss = 0.633528 (* 1 = 0.633528 loss)
I0506 04:47:10.394173 12834 sgd_solver.cpp:106] Iteration 108400, lr = 1.07374e-05
I0506 04:47:11.323762 12834 solver.cpp:362] Iteration 108500, Testing net (#0)
I0506 04:47:11.323783 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:11.446471 12834 solver.cpp:429]     Test net output #0: loss = 1.22192 (* 1 = 1.22192 loss)
I0506 04:47:11.448982 12834 solver.cpp:242] Iteration 108500 (94.3789 iter/s, 1.05956s/100 iter), loss = 1.09866
I0506 04:47:11.449004 12834 solver.cpp:261]     Train net output #0: loss = 1.09866 (* 1 = 1.09866 loss)
I0506 04:47:11.449013 12834 sgd_solver.cpp:106] Iteration 108500, lr = 1.07374e-05
I0506 04:47:11.450834 12834 solver.cpp:362] Iteration 108500, Testing net (#0)
I0506 04:47:11.450846 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:11.579619 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7715
I0506 04:47:11.579638 12834 solver.cpp:429]     Test net output #1: loss = 0.556642 (* 1 = 0.556642 loss)
I0506 04:47:11.582200 12834 solver.cpp:242] Iteration 108500 (84.1741 iter/s, 1.18801s/100 iter), loss = 0.566005
I0506 04:47:11.582221 12834 solver.cpp:261]     Train net output #0: loss = 0.566005 (* 1 = 0.566005 loss)
I0506 04:47:11.582229 12834 sgd_solver.cpp:106] Iteration 108500, lr = 1.07374e-05
I0506 04:47:12.515240 12834 solver.cpp:242] Iteration 108600 (93.7907 iter/s, 1.0662s/100 iter), loss = 1.25399
I0506 04:47:12.515276 12834 solver.cpp:261]     Train net output #0: loss = 1.25399 (* 1 = 1.25399 loss)
I0506 04:47:12.515285 12834 sgd_solver.cpp:106] Iteration 108600, lr = 1.07374e-05
I0506 04:47:12.520020 12834 solver.cpp:242] Iteration 108600 (106.635 iter/s, 0.937781s/100 iter), loss = 0.650695
I0506 04:47:12.520045 12834 solver.cpp:261]     Train net output #0: loss = 0.650695 (* 1 = 0.650695 loss)
I0506 04:47:12.520054 12834 sgd_solver.cpp:106] Iteration 108600, lr = 1.07374e-05
I0506 04:47:13.452966 12834 solver.cpp:242] Iteration 108700 (106.648 iter/s, 0.937667s/100 iter), loss = 0.383401
I0506 04:47:13.453001 12834 solver.cpp:261]     Train net output #0: loss = 0.383401 (* 1 = 0.383401 loss)
I0506 04:47:13.453011 12834 sgd_solver.cpp:106] Iteration 108700, lr = 1.07374e-05
I0506 04:47:13.457943 12834 solver.cpp:242] Iteration 108700 (106.625 iter/s, 0.937869s/100 iter), loss = 0.5413
I0506 04:47:13.457967 12834 solver.cpp:261]     Train net output #0: loss = 0.5413 (* 1 = 0.5413 loss)
I0506 04:47:13.457976 12834 sgd_solver.cpp:106] Iteration 108700, lr = 1.07374e-05
I0506 04:47:14.390439 12834 solver.cpp:242] Iteration 108800 (106.677 iter/s, 0.93741s/100 iter), loss = 1.42597
I0506 04:47:14.390480 12834 solver.cpp:261]     Train net output #0: loss = 1.42597 (* 1 = 1.42597 loss)
I0506 04:47:14.390489 12834 sgd_solver.cpp:106] Iteration 108800, lr = 1.07374e-05
I0506 04:47:14.395228 12834 solver.cpp:242] Iteration 108800 (106.696 iter/s, 0.937243s/100 iter), loss = 0.795093
I0506 04:47:14.395252 12834 solver.cpp:261]     Train net output #0: loss = 0.795093 (* 1 = 0.795093 loss)
I0506 04:47:14.395262 12834 sgd_solver.cpp:106] Iteration 108800, lr = 1.07374e-05
I0506 04:47:15.341820 12834 solver.cpp:242] Iteration 108900 (105.117 iter/s, 0.951316s/100 iter), loss = 3.56034
I0506 04:47:15.341861 12834 solver.cpp:261]     Train net output #0: loss = 3.56034 (* 1 = 3.56034 loss)
I0506 04:47:15.341871 12834 sgd_solver.cpp:106] Iteration 108900, lr = 1.07374e-05
I0506 04:47:15.346634 12834 solver.cpp:242] Iteration 108900 (105.113 iter/s, 0.951355s/100 iter), loss = 0.860327
I0506 04:47:15.346662 12834 solver.cpp:261]     Train net output #0: loss = 0.860327 (* 1 = 0.860327 loss)
I0506 04:47:15.346670 12834 sgd_solver.cpp:106] Iteration 108900, lr = 1.07374e-05
I0506 04:47:16.276811 12834 solver.cpp:362] Iteration 109000, Testing net (#0)
I0506 04:47:16.276839 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:16.399500 12834 solver.cpp:429]     Test net output #0: loss = 1.40341 (* 1 = 1.40341 loss)
I0506 04:47:16.402024 12834 solver.cpp:242] Iteration 109000 (94.3267 iter/s, 1.06015s/100 iter), loss = 0.712448
I0506 04:47:16.402048 12834 solver.cpp:261]     Train net output #0: loss = 0.712448 (* 1 = 0.712448 loss)
I0506 04:47:16.402057 12834 sgd_solver.cpp:106] Iteration 109000, lr = 1.07374e-05
I0506 04:47:16.403873 12834 solver.cpp:362] Iteration 109000, Testing net (#0)
I0506 04:47:16.403885 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:16.532663 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7505
I0506 04:47:16.532683 12834 solver.cpp:429]     Test net output #1: loss = 0.57307 (* 1 = 0.57307 loss)
I0506 04:47:16.535239 12834 solver.cpp:242] Iteration 109000 (84.1357 iter/s, 1.18856s/100 iter), loss = 0.585836
I0506 04:47:16.535259 12834 solver.cpp:261]     Train net output #0: loss = 0.585836 (* 1 = 0.585836 loss)
I0506 04:47:16.535269 12834 sgd_solver.cpp:106] Iteration 109000, lr = 1.07374e-05
I0506 04:47:17.561709 12834 solver.cpp:242] Iteration 109100 (86.235 iter/s, 1.15962s/100 iter), loss = 1.56652
I0506 04:47:17.561756 12834 solver.cpp:261]     Train net output #0: loss = 1.56652 (* 1 = 1.56652 loss)
I0506 04:47:17.561769 12834 sgd_solver.cpp:106] Iteration 109100, lr = 1.07374e-05
I0506 04:47:17.566972 12834 solver.cpp:242] Iteration 109100 (96.9281 iter/s, 1.03169s/100 iter), loss = 0.890403
I0506 04:47:17.567003 12834 solver.cpp:261]     Train net output #0: loss = 0.890403 (* 1 = 0.890403 loss)
I0506 04:47:17.567013 12834 sgd_solver.cpp:106] Iteration 109100, lr = 1.07374e-05
I0506 04:47:18.511960 12834 solver.cpp:242] Iteration 109200 (105.243 iter/s, 0.950178s/100 iter), loss = 1.14651
I0506 04:47:18.512001 12834 solver.cpp:261]     Train net output #0: loss = 1.14651 (* 1 = 1.14651 loss)
I0506 04:47:18.512011 12834 sgd_solver.cpp:106] Iteration 109200, lr = 1.07374e-05
I0506 04:47:18.516739 12834 solver.cpp:242] Iteration 109200 (105.294 iter/s, 0.949719s/100 iter), loss = 0.638909
I0506 04:47:18.516767 12834 solver.cpp:261]     Train net output #0: loss = 0.638909 (* 1 = 0.638909 loss)
I0506 04:47:18.516775 12834 sgd_solver.cpp:106] Iteration 109200, lr = 1.07374e-05
I0506 04:47:19.540963 12834 solver.cpp:242] Iteration 109300 (97.1887 iter/s, 1.02893s/100 iter), loss = 0.388419
I0506 04:47:19.541010 12834 solver.cpp:261]     Train net output #0: loss = 0.388419 (* 1 = 0.388419 loss)
I0506 04:47:19.541023 12834 sgd_solver.cpp:106] Iteration 109300, lr = 1.07374e-05
I0506 04:47:19.546273 12834 solver.cpp:242] Iteration 109300 (97.1357 iter/s, 1.02949s/100 iter), loss = 0.808396
I0506 04:47:19.546303 12834 solver.cpp:261]     Train net output #0: loss = 0.808396 (* 1 = 0.808396 loss)
I0506 04:47:19.546314 12834 sgd_solver.cpp:106] Iteration 109300, lr = 1.07374e-05
I0506 04:47:20.559006 12834 solver.cpp:242] Iteration 109400 (98.2348 iter/s, 1.01797s/100 iter), loss = 1.34045
I0506 04:47:20.559046 12834 solver.cpp:261]     Train net output #0: loss = 1.34045 (* 1 = 1.34045 loss)
I0506 04:47:20.559056 12834 sgd_solver.cpp:106] Iteration 109400, lr = 1.07374e-05
I0506 04:47:20.563822 12834 solver.cpp:242] Iteration 109400 (98.2802 iter/s, 1.0175s/100 iter), loss = 0.36339
I0506 04:47:20.563846 12834 solver.cpp:261]     Train net output #0: loss = 0.36339 (* 1 = 0.36339 loss)
I0506 04:47:20.563855 12834 sgd_solver.cpp:106] Iteration 109400, lr = 1.07374e-05
I0506 04:47:21.493682 12834 solver.cpp:362] Iteration 109500, Testing net (#0)
I0506 04:47:21.493710 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:21.616464 12834 solver.cpp:429]     Test net output #0: loss = 1.42579 (* 1 = 1.42579 loss)
I0506 04:47:21.618993 12834 solver.cpp:242] Iteration 109500 (94.3461 iter/s, 1.05993s/100 iter), loss = 1.81363
I0506 04:47:21.619014 12834 solver.cpp:261]     Train net output #0: loss = 1.81363 (* 1 = 1.81363 loss)
I0506 04:47:21.619024 12834 sgd_solver.cpp:106] Iteration 109500, lr = 1.07374e-05
I0506 04:47:21.620849 12834 solver.cpp:362] Iteration 109500, Testing net (#0)
I0506 04:47:21.620862 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:21.749733 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7475
I0506 04:47:21.749752 12834 solver.cpp:429]     Test net output #1: loss = 0.59616 (* 1 = 0.59616 loss)
I0506 04:47:21.752303 12834 solver.cpp:242] Iteration 109500 (84.1442 iter/s, 1.18844s/100 iter), loss = 0.856202
I0506 04:47:21.752323 12834 solver.cpp:261]     Train net output #0: loss = 0.856202 (* 1 = 0.856202 loss)
I0506 04:47:21.752332 12834 sgd_solver.cpp:106] Iteration 109500, lr = 1.07374e-05
I0506 04:47:22.696578 12834 solver.cpp:242] Iteration 109600 (92.8044 iter/s, 1.07753s/100 iter), loss = 2.27009
I0506 04:47:22.696626 12834 solver.cpp:261]     Train net output #0: loss = 2.27009 (* 1 = 2.27009 loss)
I0506 04:47:22.696640 12834 sgd_solver.cpp:106] Iteration 109600, lr = 1.07374e-05
I0506 04:47:22.701944 12834 solver.cpp:242] Iteration 109600 (105.309 iter/s, 0.949589s/100 iter), loss = 0.38641
I0506 04:47:22.701974 12834 solver.cpp:261]     Train net output #0: loss = 0.38641 (* 1 = 0.38641 loss)
I0506 04:47:22.701997 12834 sgd_solver.cpp:106] Iteration 109600, lr = 1.07374e-05
I0506 04:47:23.732410 12834 solver.cpp:242] Iteration 109700 (96.5479 iter/s, 1.03576s/100 iter), loss = 0.576521
I0506 04:47:23.732458 12834 solver.cpp:261]     Train net output #0: loss = 0.576521 (* 1 = 0.576521 loss)
I0506 04:47:23.732470 12834 sgd_solver.cpp:106] Iteration 109700, lr = 1.07374e-05
I0506 04:47:23.737721 12834 solver.cpp:242] Iteration 109700 (96.5506 iter/s, 1.03573s/100 iter), loss = 0.319633
I0506 04:47:23.737751 12834 solver.cpp:261]     Train net output #0: loss = 0.319633 (* 1 = 0.319633 loss)
I0506 04:47:23.737762 12834 sgd_solver.cpp:106] Iteration 109700, lr = 1.07374e-05
I0506 04:47:24.767683 12834 solver.cpp:242] Iteration 109800 (96.5996 iter/s, 1.0352s/100 iter), loss = 2.57806
I0506 04:47:24.767727 12834 solver.cpp:261]     Train net output #0: loss = 2.57806 (* 1 = 2.57806 loss)
I0506 04:47:24.767738 12834 sgd_solver.cpp:106] Iteration 109800, lr = 1.07374e-05
I0506 04:47:24.773054 12834 solver.cpp:242] Iteration 109800 (96.5928 iter/s, 1.03527s/100 iter), loss = 0.543567
I0506 04:47:24.773084 12834 solver.cpp:261]     Train net output #0: loss = 0.543567 (* 1 = 0.543567 loss)
I0506 04:47:24.773095 12834 sgd_solver.cpp:106] Iteration 109800, lr = 1.07374e-05
I0506 04:47:25.794004 12834 solver.cpp:242] Iteration 109900 (97.4422 iter/s, 1.02625s/100 iter), loss = 0.51454
I0506 04:47:25.794049 12834 solver.cpp:261]     Train net output #0: loss = 0.51454 (* 1 = 0.51454 loss)
I0506 04:47:25.794292 12834 sgd_solver.cpp:106] Iteration 109900, lr = 1.07374e-05
I0506 04:47:25.799103 12834 solver.cpp:242] Iteration 109900 (97.4659 iter/s, 1.026s/100 iter), loss = 0.525896
I0506 04:47:25.799127 12834 solver.cpp:261]     Train net output #0: loss = 0.525896 (* 1 = 0.525896 loss)
I0506 04:47:25.799136 12834 sgd_solver.cpp:106] Iteration 109900, lr = 1.07374e-05
I0506 04:47:26.729221 12834 solver.cpp:362] Iteration 110000, Testing net (#0)
I0506 04:47:26.729248 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:26.852008 12834 solver.cpp:429]     Test net output #0: loss = 1.38316 (* 1 = 1.38316 loss)
I0506 04:47:26.854522 12834 solver.cpp:242] Iteration 110000 (94.299 iter/s, 1.06046s/100 iter), loss = 0.376551
I0506 04:47:26.854545 12834 solver.cpp:261]     Train net output #0: loss = 0.376551 (* 1 = 0.376551 loss)
I0506 04:47:26.854554 12834 sgd_solver.cpp:106] Iteration 110000, lr = 8.58994e-06
I0506 04:47:26.856398 12834 solver.cpp:362] Iteration 110000, Testing net (#0)
I0506 04:47:26.856410 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:26.985142 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7685
I0506 04:47:26.985160 12834 solver.cpp:429]     Test net output #1: loss = 0.605205 (* 1 = 0.605205 loss)
I0506 04:47:26.987707 12834 solver.cpp:242] Iteration 110000 (84.1354 iter/s, 1.18856s/100 iter), loss = 0.440891
I0506 04:47:26.987727 12834 solver.cpp:261]     Train net output #0: loss = 0.440891 (* 1 = 0.440891 loss)
I0506 04:47:26.987736 12834 sgd_solver.cpp:106] Iteration 110000, lr = 8.58994e-06
I0506 04:47:27.921064 12834 solver.cpp:242] Iteration 110100 (93.7654 iter/s, 1.06649s/100 iter), loss = 0.153071
I0506 04:47:27.921103 12834 solver.cpp:261]     Train net output #0: loss = 0.153071 (* 1 = 0.153071 loss)
I0506 04:47:27.921111 12834 sgd_solver.cpp:106] Iteration 110100, lr = 8.58994e-06
I0506 04:47:27.925833 12834 solver.cpp:242] Iteration 110100 (106.6 iter/s, 0.938086s/100 iter), loss = 0.153227
I0506 04:47:27.925858 12834 solver.cpp:261]     Train net output #0: loss = 0.153227 (* 1 = 0.153227 loss)
I0506 04:47:27.925868 12834 sgd_solver.cpp:106] Iteration 110100, lr = 8.58994e-06
I0506 04:47:28.859236 12834 solver.cpp:242] Iteration 110200 (106.598 iter/s, 0.938101s/100 iter), loss = 0.578894
I0506 04:47:28.859273 12834 solver.cpp:261]     Train net output #0: loss = 0.578894 (* 1 = 0.578894 loss)
I0506 04:47:28.859282 12834 sgd_solver.cpp:106] Iteration 110200, lr = 8.58994e-06
I0506 04:47:28.864011 12834 solver.cpp:242] Iteration 110200 (106.595 iter/s, 0.938133s/100 iter), loss = 0.423606
I0506 04:47:28.864034 12834 solver.cpp:261]     Train net output #0: loss = 0.423606 (* 1 = 0.423606 loss)
I0506 04:47:28.864043 12834 sgd_solver.cpp:106] Iteration 110200, lr = 8.58994e-06
I0506 04:47:29.796893 12834 solver.cpp:242] Iteration 110300 (106.656 iter/s, 0.937595s/100 iter), loss = 1.8211
I0506 04:47:29.796926 12834 solver.cpp:261]     Train net output #0: loss = 1.8211 (* 1 = 1.8211 loss)
I0506 04:47:29.796934 12834 sgd_solver.cpp:106] Iteration 110300, lr = 8.58994e-06
I0506 04:47:29.801652 12834 solver.cpp:242] Iteration 110300 (106.655 iter/s, 0.937599s/100 iter), loss = 0.554394
I0506 04:47:29.801676 12834 solver.cpp:261]     Train net output #0: loss = 0.554394 (* 1 = 0.554394 loss)
I0506 04:47:29.801686 12834 sgd_solver.cpp:106] Iteration 110300, lr = 8.58994e-06
I0506 04:47:30.751123 12834 solver.cpp:242] Iteration 110400 (104.804 iter/s, 0.954163s/100 iter), loss = 1.68519
I0506 04:47:30.751176 12834 solver.cpp:261]     Train net output #0: loss = 1.68519 (* 1 = 1.68519 loss)
I0506 04:47:30.751188 12834 sgd_solver.cpp:106] Iteration 110400, lr = 8.58994e-06
I0506 04:47:30.756425 12834 solver.cpp:242] Iteration 110400 (104.742 iter/s, 0.954729s/100 iter), loss = 0.629038
I0506 04:47:30.756455 12834 solver.cpp:261]     Train net output #0: loss = 0.629038 (* 1 = 0.629038 loss)
I0506 04:47:30.756466 12834 sgd_solver.cpp:106] Iteration 110400, lr = 8.58994e-06
I0506 04:47:31.746898 12834 solver.cpp:362] Iteration 110500, Testing net (#0)
I0506 04:47:31.746928 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:31.869480 12834 solver.cpp:429]     Test net output #0: loss = 1.32537 (* 1 = 1.32537 loss)
I0506 04:47:31.871987 12834 solver.cpp:242] Iteration 110500 (89.2225 iter/s, 1.12079s/100 iter), loss = 1.28156
I0506 04:47:31.872009 12834 solver.cpp:261]     Train net output #0: loss = 1.28156 (* 1 = 1.28156 loss)
I0506 04:47:31.872016 12834 sgd_solver.cpp:106] Iteration 110500, lr = 8.58994e-06
I0506 04:47:31.873916 12834 solver.cpp:362] Iteration 110500, Testing net (#0)
I0506 04:47:31.873929 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:32.002566 12834 solver.cpp:429]     Test net output #0: accuracy = 0.757
I0506 04:47:32.002585 12834 solver.cpp:429]     Test net output #1: loss = 0.555761 (* 1 = 0.555761 loss)
I0506 04:47:32.005129 12834 solver.cpp:242] Iteration 110500 (80.0863 iter/s, 1.24865s/100 iter), loss = 0.50746
I0506 04:47:32.005151 12834 solver.cpp:261]     Train net output #0: loss = 0.50746 (* 1 = 0.50746 loss)
I0506 04:47:32.005158 12834 sgd_solver.cpp:106] Iteration 110500, lr = 8.58994e-06
I0506 04:47:32.938158 12834 solver.cpp:242] Iteration 110600 (93.7981 iter/s, 1.06612s/100 iter), loss = 0.610151
I0506 04:47:32.938192 12834 solver.cpp:261]     Train net output #0: loss = 0.610151 (* 1 = 0.610151 loss)
I0506 04:47:32.938201 12834 sgd_solver.cpp:106] Iteration 110600, lr = 8.58994e-06
I0506 04:47:32.942925 12834 solver.cpp:242] Iteration 110600 (106.637 iter/s, 0.937757s/100 iter), loss = 0.554796
I0506 04:47:32.942948 12834 solver.cpp:261]     Train net output #0: loss = 0.554796 (* 1 = 0.554796 loss)
I0506 04:47:32.942957 12834 sgd_solver.cpp:106] Iteration 110600, lr = 8.58994e-06
I0506 04:47:33.876103 12834 solver.cpp:242] Iteration 110700 (106.623 iter/s, 0.937888s/100 iter), loss = 0.390094
I0506 04:47:33.876135 12834 solver.cpp:261]     Train net output #0: loss = 0.390094 (* 1 = 0.390094 loss)
I0506 04:47:33.876144 12834 sgd_solver.cpp:106] Iteration 110700, lr = 8.58994e-06
I0506 04:47:33.880951 12834 solver.cpp:242] Iteration 110700 (106.613 iter/s, 0.937976s/100 iter), loss = 0.424593
I0506 04:47:33.880976 12834 solver.cpp:261]     Train net output #0: loss = 0.424593 (* 1 = 0.424593 loss)
I0506 04:47:33.880985 12834 sgd_solver.cpp:106] Iteration 110700, lr = 8.58994e-06
I0506 04:47:34.813807 12834 solver.cpp:242] Iteration 110800 (106.65 iter/s, 0.937644s/100 iter), loss = 0.788271
I0506 04:47:34.813848 12834 solver.cpp:261]     Train net output #0: loss = 0.788271 (* 1 = 0.788271 loss)
I0506 04:47:34.813868 12834 sgd_solver.cpp:106] Iteration 110800, lr = 8.58994e-06
I0506 04:47:34.818599 12834 solver.cpp:242] Iteration 110800 (106.655 iter/s, 0.937605s/100 iter), loss = 0.414804
I0506 04:47:34.818626 12834 solver.cpp:261]     Train net output #0: loss = 0.414804 (* 1 = 0.414804 loss)
I0506 04:47:34.818634 12834 sgd_solver.cpp:106] Iteration 110800, lr = 8.58994e-06
I0506 04:47:35.751587 12834 solver.cpp:242] Iteration 110900 (106.643 iter/s, 0.937706s/100 iter), loss = 1.74235
I0506 04:47:35.751629 12834 solver.cpp:261]     Train net output #0: loss = 1.74235 (* 1 = 1.74235 loss)
I0506 04:47:35.751638 12834 sgd_solver.cpp:106] Iteration 110900, lr = 8.58994e-06
I0506 04:47:35.756364 12834 solver.cpp:242] Iteration 110900 (106.642 iter/s, 0.93772s/100 iter), loss = 0.617291
I0506 04:47:35.756391 12834 solver.cpp:261]     Train net output #0: loss = 0.617291 (* 1 = 0.617291 loss)
I0506 04:47:35.756400 12834 sgd_solver.cpp:106] Iteration 110900, lr = 8.58994e-06
I0506 04:47:36.686724 12834 solver.cpp:362] Iteration 111000, Testing net (#0)
I0506 04:47:36.686753 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:36.809476 12834 solver.cpp:429]     Test net output #0: loss = 1.21822 (* 1 = 1.21822 loss)
I0506 04:47:36.812052 12834 solver.cpp:242] Iteration 111000 (94.3037 iter/s, 1.0604s/100 iter), loss = 0.618681
I0506 04:47:36.812079 12834 solver.cpp:261]     Train net output #0: loss = 0.618681 (* 1 = 0.618681 loss)
I0506 04:47:36.812088 12834 sgd_solver.cpp:106] Iteration 111000, lr = 8.58994e-06
I0506 04:47:36.813926 12834 solver.cpp:362] Iteration 111000, Testing net (#0)
I0506 04:47:36.813940 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:36.942565 12834 solver.cpp:429]     Test net output #0: accuracy = 0.783
I0506 04:47:36.942584 12834 solver.cpp:429]     Test net output #1: loss = 0.511004 (* 1 = 0.511004 loss)
I0506 04:47:36.945137 12834 solver.cpp:242] Iteration 111000 (84.1238 iter/s, 1.18872s/100 iter), loss = 0.399682
I0506 04:47:36.945158 12834 solver.cpp:261]     Train net output #0: loss = 0.399682 (* 1 = 0.399682 loss)
I0506 04:47:36.945166 12834 sgd_solver.cpp:106] Iteration 111000, lr = 8.58994e-06
I0506 04:47:37.878954 12834 solver.cpp:242] Iteration 111100 (93.7348 iter/s, 1.06684s/100 iter), loss = 1.5959
I0506 04:47:37.878995 12834 solver.cpp:261]     Train net output #0: loss = 1.5959 (* 1 = 1.5959 loss)
I0506 04:47:37.879004 12834 sgd_solver.cpp:106] Iteration 111100, lr = 8.58994e-06
I0506 04:47:37.883724 12834 solver.cpp:242] Iteration 111100 (106.547 iter/s, 0.938549s/100 iter), loss = 0.663207
I0506 04:47:37.883749 12834 solver.cpp:261]     Train net output #0: loss = 0.663207 (* 1 = 0.663207 loss)
I0506 04:47:37.883759 12834 sgd_solver.cpp:106] Iteration 111100, lr = 8.58994e-06
I0506 04:47:38.816627 12834 solver.cpp:242] Iteration 111200 (106.655 iter/s, 0.937606s/100 iter), loss = 1.33174
I0506 04:47:38.816668 12834 solver.cpp:261]     Train net output #0: loss = 1.33174 (* 1 = 1.33174 loss)
I0506 04:47:38.816678 12834 sgd_solver.cpp:106] Iteration 111200, lr = 8.58994e-06
I0506 04:47:38.821404 12834 solver.cpp:242] Iteration 111200 (106.651 iter/s, 0.937636s/100 iter), loss = 0.470553
I0506 04:47:38.821429 12834 solver.cpp:261]     Train net output #0: loss = 0.470553 (* 1 = 0.470553 loss)
I0506 04:47:38.821439 12834 sgd_solver.cpp:106] Iteration 111200, lr = 8.58994e-06
I0506 04:47:39.754885 12834 solver.cpp:242] Iteration 111300 (106.589 iter/s, 0.938187s/100 iter), loss = 1.73563
I0506 04:47:39.754923 12834 solver.cpp:261]     Train net output #0: loss = 1.73563 (* 1 = 1.73563 loss)
I0506 04:47:39.754933 12834 sgd_solver.cpp:106] Iteration 111300, lr = 8.58994e-06
I0506 04:47:39.759656 12834 solver.cpp:242] Iteration 111300 (106.586 iter/s, 0.938209s/100 iter), loss = 0.69219
I0506 04:47:39.759681 12834 solver.cpp:261]     Train net output #0: loss = 0.69219 (* 1 = 0.69219 loss)
I0506 04:47:39.759690 12834 sgd_solver.cpp:106] Iteration 111300, lr = 8.58994e-06
I0506 04:47:40.692912 12834 solver.cpp:242] Iteration 111400 (106.614 iter/s, 0.937965s/100 iter), loss = 0.609639
I0506 04:47:40.692958 12834 solver.cpp:261]     Train net output #0: loss = 0.609639 (* 1 = 0.609639 loss)
I0506 04:47:40.692968 12834 sgd_solver.cpp:106] Iteration 111400, lr = 8.58994e-06
I0506 04:47:40.697778 12834 solver.cpp:242] Iteration 111400 (106.602 iter/s, 0.938069s/100 iter), loss = 0.512164
I0506 04:47:40.697804 12834 solver.cpp:261]     Train net output #0: loss = 0.512164 (* 1 = 0.512164 loss)
I0506 04:47:40.697813 12834 sgd_solver.cpp:106] Iteration 111400, lr = 8.58994e-06
I0506 04:47:41.627845 12834 solver.cpp:362] Iteration 111500, Testing net (#0)
I0506 04:47:41.627866 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:41.750594 12834 solver.cpp:429]     Test net output #0: loss = 1.2782 (* 1 = 1.2782 loss)
I0506 04:47:41.753105 12834 solver.cpp:242] Iteration 111500 (94.3281 iter/s, 1.06013s/100 iter), loss = 1.48333
I0506 04:47:41.753126 12834 solver.cpp:261]     Train net output #0: loss = 1.48333 (* 1 = 1.48333 loss)
I0506 04:47:41.753134 12834 sgd_solver.cpp:106] Iteration 111500, lr = 8.58994e-06
I0506 04:47:41.754950 12834 solver.cpp:362] Iteration 111500, Testing net (#0)
I0506 04:47:41.754962 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:41.883481 12834 solver.cpp:429]     Test net output #0: accuracy = 0.768
I0506 04:47:41.883504 12834 solver.cpp:429]     Test net output #1: loss = 0.54055 (* 1 = 0.54055 loss)
I0506 04:47:41.886147 12834 solver.cpp:242] Iteration 111500 (84.1522 iter/s, 1.18832s/100 iter), loss = 0.548547
I0506 04:47:41.886169 12834 solver.cpp:261]     Train net output #0: loss = 0.548547 (* 1 = 0.548547 loss)
I0506 04:47:41.886178 12834 sgd_solver.cpp:106] Iteration 111500, lr = 8.58994e-06
I0506 04:47:42.819259 12834 solver.cpp:242] Iteration 111600 (93.7991 iter/s, 1.06611s/100 iter), loss = 1.48939
I0506 04:47:42.819295 12834 solver.cpp:261]     Train net output #0: loss = 1.48939 (* 1 = 1.48939 loss)
I0506 04:47:42.819304 12834 sgd_solver.cpp:106] Iteration 111600, lr = 8.58994e-06
I0506 04:47:42.824090 12834 solver.cpp:242] Iteration 111600 (106.622 iter/s, 0.937893s/100 iter), loss = 0.756949
I0506 04:47:42.824113 12834 solver.cpp:261]     Train net output #0: loss = 0.756949 (* 1 = 0.756949 loss)
I0506 04:47:42.824122 12834 sgd_solver.cpp:106] Iteration 111600, lr = 8.58994e-06
I0506 04:47:43.757339 12834 solver.cpp:242] Iteration 111700 (106.608 iter/s, 0.938016s/100 iter), loss = 3.27583
I0506 04:47:43.757374 12834 solver.cpp:261]     Train net output #0: loss = 3.27583 (* 1 = 3.27583 loss)
I0506 04:47:43.757382 12834 sgd_solver.cpp:106] Iteration 111700, lr = 8.58994e-06
I0506 04:47:43.762104 12834 solver.cpp:242] Iteration 111700 (106.613 iter/s, 0.937971s/100 iter), loss = 0.752872
I0506 04:47:43.762127 12834 solver.cpp:261]     Train net output #0: loss = 0.752872 (* 1 = 0.752872 loss)
I0506 04:47:43.762136 12834 sgd_solver.cpp:106] Iteration 111700, lr = 8.58994e-06
I0506 04:47:44.694905 12834 solver.cpp:242] Iteration 111800 (106.667 iter/s, 0.937501s/100 iter), loss = 0.678165
I0506 04:47:44.694936 12834 solver.cpp:261]     Train net output #0: loss = 0.678165 (* 1 = 0.678165 loss)
I0506 04:47:44.694946 12834 sgd_solver.cpp:106] Iteration 111800, lr = 8.58994e-06
I0506 04:47:44.699651 12834 solver.cpp:242] Iteration 111800 (106.666 iter/s, 0.937507s/100 iter), loss = 0.626414
I0506 04:47:44.699674 12834 solver.cpp:261]     Train net output #0: loss = 0.626414 (* 1 = 0.626414 loss)
I0506 04:47:44.699683 12834 sgd_solver.cpp:106] Iteration 111800, lr = 8.58994e-06
I0506 04:47:45.651991 12834 solver.cpp:242] Iteration 111900 (104.49 iter/s, 0.957027s/100 iter), loss = 1.70166
I0506 04:47:45.652037 12834 solver.cpp:261]     Train net output #0: loss = 1.70166 (* 1 = 1.70166 loss)
I0506 04:47:45.652046 12834 sgd_solver.cpp:106] Iteration 111900, lr = 8.58994e-06
I0506 04:47:45.656757 12834 solver.cpp:242] Iteration 111900 (104.486 iter/s, 0.957064s/100 iter), loss = 0.516364
I0506 04:47:45.656785 12834 solver.cpp:261]     Train net output #0: loss = 0.516364 (* 1 = 0.516364 loss)
I0506 04:47:45.656805 12834 sgd_solver.cpp:106] Iteration 111900, lr = 8.58994e-06
I0506 04:47:46.588124 12834 solver.cpp:362] Iteration 112000, Testing net (#0)
I0506 04:47:46.588156 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:46.721293 12834 solver.cpp:429]     Test net output #0: loss = 1.15515 (* 1 = 1.15515 loss)
I0506 04:47:46.723942 12834 solver.cpp:242] Iteration 112000 (93.2937 iter/s, 1.07188s/100 iter), loss = 4.10951
I0506 04:47:46.723968 12834 solver.cpp:261]     Train net output #0: loss = 4.10951 (* 1 = 4.10951 loss)
I0506 04:47:46.723978 12834 sgd_solver.cpp:106] Iteration 112000, lr = 8.58994e-06
I0506 04:47:46.726166 12834 solver.cpp:362] Iteration 112000, Testing net (#0)
I0506 04:47:46.726182 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:46.866829 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7715
I0506 04:47:46.866852 12834 solver.cpp:429]     Test net output #1: loss = 0.525308 (* 1 = 0.525308 loss)
I0506 04:47:46.869566 12834 solver.cpp:242] Iteration 112000 (82.4566 iter/s, 1.21276s/100 iter), loss = 0.830896
I0506 04:47:46.869591 12834 solver.cpp:261]     Train net output #0: loss = 0.830896 (* 1 = 0.830896 loss)
I0506 04:47:46.869601 12834 sgd_solver.cpp:106] Iteration 112000, lr = 8.58994e-06
I0506 04:47:47.809978 12834 solver.cpp:242] Iteration 112100 (92.0826 iter/s, 1.08598s/100 iter), loss = 2.26648
I0506 04:47:47.810019 12834 solver.cpp:261]     Train net output #0: loss = 2.26648 (* 1 = 2.26648 loss)
I0506 04:47:47.810029 12834 sgd_solver.cpp:106] Iteration 112100, lr = 8.58994e-06
I0506 04:47:47.814788 12834 solver.cpp:242] Iteration 112100 (105.8 iter/s, 0.94518s/100 iter), loss = 0.62413
I0506 04:47:47.814813 12834 solver.cpp:261]     Train net output #0: loss = 0.62413 (* 1 = 0.62413 loss)
I0506 04:47:47.814822 12834 sgd_solver.cpp:106] Iteration 112100, lr = 8.58994e-06
I0506 04:47:48.748165 12834 solver.cpp:242] Iteration 112200 (106.597 iter/s, 0.938114s/100 iter), loss = 1.16252
I0506 04:47:48.748205 12834 solver.cpp:261]     Train net output #0: loss = 1.16252 (* 1 = 1.16252 loss)
I0506 04:47:48.748214 12834 sgd_solver.cpp:106] Iteration 112200, lr = 8.58994e-06
I0506 04:47:48.752929 12834 solver.cpp:242] Iteration 112200 (106.599 iter/s, 0.938098s/100 iter), loss = 0.431434
I0506 04:47:48.752954 12834 solver.cpp:261]     Train net output #0: loss = 0.431434 (* 1 = 0.431434 loss)
I0506 04:47:48.752964 12834 sgd_solver.cpp:106] Iteration 112200, lr = 8.58994e-06
I0506 04:47:49.696707 12834 solver.cpp:242] Iteration 112300 (105.432 iter/s, 0.948477s/100 iter), loss = 0.591636
I0506 04:47:49.696746 12834 solver.cpp:261]     Train net output #0: loss = 0.591636 (* 1 = 0.591636 loss)
I0506 04:47:49.696756 12834 sgd_solver.cpp:106] Iteration 112300, lr = 8.58994e-06
I0506 04:47:49.701545 12834 solver.cpp:242] Iteration 112300 (105.423 iter/s, 0.94856s/100 iter), loss = 0.733363
I0506 04:47:49.701570 12834 solver.cpp:261]     Train net output #0: loss = 0.733363 (* 1 = 0.733363 loss)
I0506 04:47:49.701578 12834 sgd_solver.cpp:106] Iteration 112300, lr = 8.58994e-06
I0506 04:47:50.640542 12834 solver.cpp:242] Iteration 112400 (105.958 iter/s, 0.943767s/100 iter), loss = 1.16547
I0506 04:47:50.640594 12834 solver.cpp:261]     Train net output #0: loss = 1.16547 (* 1 = 1.16547 loss)
I0506 04:47:50.640606 12834 sgd_solver.cpp:106] Iteration 112400, lr = 8.58994e-06
I0506 04:47:50.645843 12834 solver.cpp:242] Iteration 112400 (105.904 iter/s, 0.944253s/100 iter), loss = 0.686865
I0506 04:47:50.645870 12834 solver.cpp:261]     Train net output #0: loss = 0.686865 (* 1 = 0.686865 loss)
I0506 04:47:50.645881 12834 sgd_solver.cpp:106] Iteration 112400, lr = 8.58994e-06
I0506 04:47:51.583257 12834 solver.cpp:362] Iteration 112500, Testing net (#0)
I0506 04:47:51.583286 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:51.706053 12834 solver.cpp:429]     Test net output #0: loss = 1.45918 (* 1 = 1.45918 loss)
I0506 04:47:51.708581 12834 solver.cpp:242] Iteration 112500 (93.6358 iter/s, 1.06797s/100 iter), loss = 3.52046
I0506 04:47:51.708611 12834 solver.cpp:261]     Train net output #0: loss = 3.52046 (* 1 = 3.52046 loss)
I0506 04:47:51.708621 12834 sgd_solver.cpp:106] Iteration 112500, lr = 8.58994e-06
I0506 04:47:51.710517 12834 solver.cpp:362] Iteration 112500, Testing net (#0)
I0506 04:47:51.710530 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:51.839040 12834 solver.cpp:429]     Test net output #0: accuracy = 0.777
I0506 04:47:51.839059 12834 solver.cpp:429]     Test net output #1: loss = 0.522828 (* 1 = 0.522828 loss)
I0506 04:47:51.841630 12834 solver.cpp:242] Iteration 112500 (83.6302 iter/s, 1.19574s/100 iter), loss = 0.334109
I0506 04:47:51.841651 12834 solver.cpp:261]     Train net output #0: loss = 0.334109 (* 1 = 0.334109 loss)
I0506 04:47:51.841660 12834 sgd_solver.cpp:106] Iteration 112500, lr = 8.58994e-06
I0506 04:47:52.775228 12834 solver.cpp:242] Iteration 112600 (93.757 iter/s, 1.06659s/100 iter), loss = 0.824534
I0506 04:47:52.775269 12834 solver.cpp:261]     Train net output #0: loss = 0.824534 (* 1 = 0.824534 loss)
I0506 04:47:52.775279 12834 sgd_solver.cpp:106] Iteration 112600, lr = 8.58994e-06
I0506 04:47:52.779991 12834 solver.cpp:242] Iteration 112600 (106.573 iter/s, 0.938322s/100 iter), loss = 0.384336
I0506 04:47:52.780017 12834 solver.cpp:261]     Train net output #0: loss = 0.384336 (* 1 = 0.384336 loss)
I0506 04:47:52.780026 12834 sgd_solver.cpp:106] Iteration 112600, lr = 8.58994e-06
I0506 04:47:53.713462 12834 solver.cpp:242] Iteration 112700 (106.591 iter/s, 0.938162s/100 iter), loss = 1.31919
I0506 04:47:53.713500 12834 solver.cpp:261]     Train net output #0: loss = 1.31919 (* 1 = 1.31919 loss)
I0506 04:47:53.713510 12834 sgd_solver.cpp:106] Iteration 112700, lr = 8.58994e-06
I0506 04:47:53.718237 12834 solver.cpp:242] Iteration 112700 (106.587 iter/s, 0.938202s/100 iter), loss = 0.522845
I0506 04:47:53.718263 12834 solver.cpp:261]     Train net output #0: loss = 0.522845 (* 1 = 0.522845 loss)
I0506 04:47:53.718272 12834 sgd_solver.cpp:106] Iteration 112700, lr = 8.58994e-06
I0506 04:47:54.659353 12834 solver.cpp:242] Iteration 112800 (105.728 iter/s, 0.945825s/100 iter), loss = 2.03828
I0506 04:47:54.659396 12834 solver.cpp:261]     Train net output #0: loss = 2.03828 (* 1 = 2.03828 loss)
I0506 04:47:54.659409 12834 sgd_solver.cpp:106] Iteration 112800, lr = 8.58994e-06
I0506 04:47:54.664628 12834 solver.cpp:242] Iteration 112800 (105.67 iter/s, 0.946346s/100 iter), loss = 0.596824
I0506 04:47:54.664656 12834 solver.cpp:261]     Train net output #0: loss = 0.596824 (* 1 = 0.596824 loss)
I0506 04:47:54.664667 12834 sgd_solver.cpp:106] Iteration 112800, lr = 8.58994e-06
I0506 04:47:55.667253 12834 solver.cpp:242] Iteration 112900 (99.2235 iter/s, 1.00783s/100 iter), loss = 0.449491
I0506 04:47:55.667289 12834 solver.cpp:261]     Train net output #0: loss = 0.449491 (* 1 = 0.449491 loss)
I0506 04:47:55.667299 12834 sgd_solver.cpp:106] Iteration 112900, lr = 8.58994e-06
I0506 04:47:55.672036 12834 solver.cpp:242] Iteration 112900 (99.2693 iter/s, 1.00736s/100 iter), loss = 0.347006
I0506 04:47:55.672061 12834 solver.cpp:261]     Train net output #0: loss = 0.347006 (* 1 = 0.347006 loss)
I0506 04:47:55.672070 12834 sgd_solver.cpp:106] Iteration 112900, lr = 8.58994e-06
I0506 04:47:56.602607 12834 solver.cpp:362] Iteration 113000, Testing net (#0)
I0506 04:47:56.602625 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:56.725252 12834 solver.cpp:429]     Test net output #0: loss = 1.51501 (* 1 = 1.51501 loss)
I0506 04:47:56.727766 12834 solver.cpp:242] Iteration 113000 (94.2989 iter/s, 1.06046s/100 iter), loss = 1.5261
I0506 04:47:56.727785 12834 solver.cpp:261]     Train net output #0: loss = 1.5261 (* 1 = 1.5261 loss)
I0506 04:47:56.727794 12834 sgd_solver.cpp:106] Iteration 113000, lr = 8.58994e-06
I0506 04:47:56.729609 12834 solver.cpp:362] Iteration 113000, Testing net (#0)
I0506 04:47:56.729622 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:47:56.858312 12834 solver.cpp:429]     Test net output #0: accuracy = 0.757
I0506 04:47:56.858340 12834 solver.cpp:429]     Test net output #1: loss = 0.576751 (* 1 = 0.576751 loss)
I0506 04:47:56.860894 12834 solver.cpp:242] Iteration 113000 (84.1175 iter/s, 1.18881s/100 iter), loss = 0.69632
I0506 04:47:56.860915 12834 solver.cpp:261]     Train net output #0: loss = 0.69632 (* 1 = 0.69632 loss)
I0506 04:47:56.860924 12834 sgd_solver.cpp:106] Iteration 113000, lr = 8.58994e-06
I0506 04:47:57.794067 12834 solver.cpp:242] Iteration 113100 (93.7868 iter/s, 1.06625s/100 iter), loss = 0.879297
I0506 04:47:57.794103 12834 solver.cpp:261]     Train net output #0: loss = 0.879297 (* 1 = 0.879297 loss)
I0506 04:47:57.794113 12834 sgd_solver.cpp:106] Iteration 113100, lr = 8.58994e-06
I0506 04:47:57.798913 12834 solver.cpp:242] Iteration 113100 (106.612 iter/s, 0.937979s/100 iter), loss = 0.476562
I0506 04:47:57.798935 12834 solver.cpp:261]     Train net output #0: loss = 0.476562 (* 1 = 0.476562 loss)
I0506 04:47:57.798944 12834 sgd_solver.cpp:106] Iteration 113100, lr = 8.58994e-06
I0506 04:47:58.747879 12834 solver.cpp:242] Iteration 113200 (104.849 iter/s, 0.953752s/100 iter), loss = 1.62778
I0506 04:47:58.747912 12834 solver.cpp:261]     Train net output #0: loss = 1.62778 (* 1 = 1.62778 loss)
I0506 04:47:58.747925 12834 sgd_solver.cpp:106] Iteration 113200, lr = 8.58994e-06
I0506 04:47:58.753247 12834 solver.cpp:242] Iteration 113200 (104.791 iter/s, 0.95428s/100 iter), loss = 0.474181
I0506 04:47:58.753274 12834 solver.cpp:261]     Train net output #0: loss = 0.474181 (* 1 = 0.474181 loss)
I0506 04:47:58.753285 12834 sgd_solver.cpp:106] Iteration 113200, lr = 8.58994e-06
I0506 04:47:59.783761 12834 solver.cpp:242] Iteration 113300 (96.5421 iter/s, 1.03582s/100 iter), loss = 1.18255
I0506 04:47:59.783797 12834 solver.cpp:261]     Train net output #0: loss = 1.18255 (* 1 = 1.18255 loss)
I0506 04:47:59.783808 12834 sgd_solver.cpp:106] Iteration 113300, lr = 8.58994e-06
I0506 04:47:59.789050 12834 solver.cpp:242] Iteration 113300 (96.5478 iter/s, 1.03576s/100 iter), loss = 0.474143
I0506 04:47:59.789078 12834 solver.cpp:261]     Train net output #0: loss = 0.474143 (* 1 = 0.474143 loss)
I0506 04:47:59.789089 12834 sgd_solver.cpp:106] Iteration 113300, lr = 8.58994e-06
I0506 04:48:00.828873 12834 solver.cpp:242] Iteration 113400 (95.6893 iter/s, 1.04505s/100 iter), loss = 0.675594
I0506 04:48:00.828913 12834 solver.cpp:261]     Train net output #0: loss = 0.675594 (* 1 = 0.675594 loss)
I0506 04:48:00.828924 12834 sgd_solver.cpp:106] Iteration 113400, lr = 8.58994e-06
I0506 04:48:00.834286 12834 solver.cpp:242] Iteration 113400 (95.6777 iter/s, 1.04518s/100 iter), loss = 0.675325
I0506 04:48:00.834316 12834 solver.cpp:261]     Train net output #0: loss = 0.675325 (* 1 = 0.675325 loss)
I0506 04:48:00.834327 12834 sgd_solver.cpp:106] Iteration 113400, lr = 8.58994e-06
I0506 04:48:01.852505 12834 solver.cpp:362] Iteration 113500, Testing net (#0)
I0506 04:48:01.852524 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:01.976011 12834 solver.cpp:429]     Test net output #0: loss = 1.31568 (* 1 = 1.31568 loss)
I0506 04:48:01.978533 12834 solver.cpp:242] Iteration 113500 (86.9869 iter/s, 1.1496s/100 iter), loss = 0.992443
I0506 04:48:01.978554 12834 solver.cpp:261]     Train net output #0: loss = 0.992443 (* 1 = 0.992443 loss)
I0506 04:48:01.978562 12834 sgd_solver.cpp:106] Iteration 113500, lr = 8.58994e-06
I0506 04:48:01.980413 12834 solver.cpp:362] Iteration 113500, Testing net (#0)
I0506 04:48:01.980425 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:02.110997 12834 solver.cpp:429]     Test net output #0: accuracy = 0.789
I0506 04:48:02.111016 12834 solver.cpp:429]     Test net output #1: loss = 0.506022 (* 1 = 0.506022 loss)
I0506 04:48:02.113585 12834 solver.cpp:242] Iteration 113500 (78.171 iter/s, 1.27925s/100 iter), loss = 0.415638
I0506 04:48:02.113606 12834 solver.cpp:261]     Train net output #0: loss = 0.415638 (* 1 = 0.415638 loss)
I0506 04:48:02.113615 12834 sgd_solver.cpp:106] Iteration 113500, lr = 8.58994e-06
I0506 04:48:03.057315 12834 solver.cpp:242] Iteration 113600 (92.7019 iter/s, 1.07873s/100 iter), loss = 0.479165
I0506 04:48:03.057431 12834 solver.cpp:261]     Train net output #0: loss = 0.479165 (* 1 = 0.479165 loss)
I0506 04:48:03.057449 12834 sgd_solver.cpp:106] Iteration 113600, lr = 8.58994e-06
I0506 04:48:03.062248 12834 solver.cpp:242] Iteration 113600 (105.416 iter/s, 0.948622s/100 iter), loss = 0.413822
I0506 04:48:03.062274 12834 solver.cpp:261]     Train net output #0: loss = 0.413822 (* 1 = 0.413822 loss)
I0506 04:48:03.062284 12834 sgd_solver.cpp:106] Iteration 113600, lr = 8.58994e-06
I0506 04:48:03.995357 12834 solver.cpp:242] Iteration 113700 (106.621 iter/s, 0.937903s/100 iter), loss = 0.692133
I0506 04:48:03.995398 12834 solver.cpp:261]     Train net output #0: loss = 0.692133 (* 1 = 0.692133 loss)
I0506 04:48:03.995407 12834 sgd_solver.cpp:106] Iteration 113700, lr = 8.58994e-06
I0506 04:48:04.000130 12834 solver.cpp:242] Iteration 113700 (106.628 iter/s, 0.937837s/100 iter), loss = 0.491627
I0506 04:48:04.000154 12834 solver.cpp:261]     Train net output #0: loss = 0.491627 (* 1 = 0.491627 loss)
I0506 04:48:04.000164 12834 sgd_solver.cpp:106] Iteration 113700, lr = 8.58994e-06
I0506 04:48:04.933094 12834 solver.cpp:242] Iteration 113800 (106.648 iter/s, 0.937665s/100 iter), loss = 1.52074
I0506 04:48:04.933135 12834 solver.cpp:261]     Train net output #0: loss = 1.52074 (* 1 = 1.52074 loss)
I0506 04:48:04.933145 12834 sgd_solver.cpp:106] Iteration 113800, lr = 8.58994e-06
I0506 04:48:04.937876 12834 solver.cpp:242] Iteration 113800 (106.644 iter/s, 0.937702s/100 iter), loss = 0.396093
I0506 04:48:04.937901 12834 solver.cpp:261]     Train net output #0: loss = 0.396093 (* 1 = 0.396093 loss)
I0506 04:48:04.937911 12834 sgd_solver.cpp:106] Iteration 113800, lr = 8.58994e-06
I0506 04:48:05.881974 12834 solver.cpp:242] Iteration 113900 (105.395 iter/s, 0.948815s/100 iter), loss = 3.13198
I0506 04:48:05.882014 12834 solver.cpp:261]     Train net output #0: loss = 3.13198 (* 1 = 3.13198 loss)
I0506 04:48:05.882025 12834 sgd_solver.cpp:106] Iteration 113900, lr = 8.58994e-06
I0506 04:48:05.886735 12834 solver.cpp:242] Iteration 113900 (105.395 iter/s, 0.948815s/100 iter), loss = 0.553955
I0506 04:48:05.886759 12834 solver.cpp:261]     Train net output #0: loss = 0.553955 (* 1 = 0.553955 loss)
I0506 04:48:05.886768 12834 sgd_solver.cpp:106] Iteration 113900, lr = 8.58994e-06
I0506 04:48:06.841514 12834 solver.cpp:362] Iteration 114000, Testing net (#0)
I0506 04:48:06.841547 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:06.974627 12834 solver.cpp:429]     Test net output #0: loss = 1.04849 (* 1 = 1.04849 loss)
I0506 04:48:06.977277 12834 solver.cpp:242] Iteration 114000 (91.304 iter/s, 1.09524s/100 iter), loss = 0.824207
I0506 04:48:06.977303 12834 solver.cpp:261]     Train net output #0: loss = 0.824207 (* 1 = 0.824207 loss)
I0506 04:48:06.977313 12834 sgd_solver.cpp:106] Iteration 114000, lr = 8.58994e-06
I0506 04:48:06.979506 12834 solver.cpp:362] Iteration 114000, Testing net (#0)
I0506 04:48:06.979523 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:07.120370 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7765
I0506 04:48:07.120395 12834 solver.cpp:429]     Test net output #1: loss = 0.522762 (* 1 = 0.522762 loss)
I0506 04:48:07.123088 12834 solver.cpp:242] Iteration 114000 (80.8861 iter/s, 1.23631s/100 iter), loss = 0.435388
I0506 04:48:07.123116 12834 solver.cpp:261]     Train net output #0: loss = 0.435388 (* 1 = 0.435388 loss)
I0506 04:48:07.123127 12834 sgd_solver.cpp:106] Iteration 114000, lr = 8.58994e-06
I0506 04:48:08.153440 12834 solver.cpp:242] Iteration 114100 (85.0262 iter/s, 1.17611s/100 iter), loss = 0.844604
I0506 04:48:08.153493 12834 solver.cpp:261]     Train net output #0: loss = 0.844604 (* 1 = 0.844604 loss)
I0506 04:48:08.153558 12834 sgd_solver.cpp:106] Iteration 114100, lr = 8.58994e-06
I0506 04:48:08.158427 12834 solver.cpp:242] Iteration 114100 (96.592 iter/s, 1.03528s/100 iter), loss = 0.552261
I0506 04:48:08.158454 12834 solver.cpp:261]     Train net output #0: loss = 0.552261 (* 1 = 0.552261 loss)
I0506 04:48:08.158473 12834 sgd_solver.cpp:106] Iteration 114100, lr = 8.58994e-06
I0506 04:48:09.091464 12834 solver.cpp:242] Iteration 114200 (106.616 iter/s, 0.937945s/100 iter), loss = 1.10412
I0506 04:48:09.091506 12834 solver.cpp:261]     Train net output #0: loss = 1.10412 (* 1 = 1.10412 loss)
I0506 04:48:09.091514 12834 sgd_solver.cpp:106] Iteration 114200, lr = 8.58994e-06
I0506 04:48:09.096225 12834 solver.cpp:242] Iteration 114200 (106.638 iter/s, 0.937753s/100 iter), loss = 0.508635
I0506 04:48:09.096251 12834 solver.cpp:261]     Train net output #0: loss = 0.508635 (* 1 = 0.508635 loss)
I0506 04:48:09.096259 12834 sgd_solver.cpp:106] Iteration 114200, lr = 8.58994e-06
I0506 04:48:10.029664 12834 solver.cpp:242] Iteration 114300 (106.594 iter/s, 0.938136s/100 iter), loss = 2.47602
I0506 04:48:10.029705 12834 solver.cpp:261]     Train net output #0: loss = 2.47602 (* 1 = 2.47602 loss)
I0506 04:48:10.029714 12834 sgd_solver.cpp:106] Iteration 114300, lr = 8.58994e-06
I0506 04:48:10.034518 12834 solver.cpp:242] Iteration 114300 (106.583 iter/s, 0.938239s/100 iter), loss = 0.877988
I0506 04:48:10.034543 12834 solver.cpp:261]     Train net output #0: loss = 0.877988 (* 1 = 0.877988 loss)
I0506 04:48:10.034553 12834 sgd_solver.cpp:106] Iteration 114300, lr = 8.58994e-06
I0506 04:48:11.007952 12834 solver.cpp:242] Iteration 114400 (102.227 iter/s, 0.978219s/100 iter), loss = 0.44249
I0506 04:48:11.007997 12834 solver.cpp:261]     Train net output #0: loss = 0.44249 (* 1 = 0.44249 loss)
I0506 04:48:11.008010 12834 sgd_solver.cpp:106] Iteration 114400, lr = 8.58994e-06
I0506 04:48:11.013253 12834 solver.cpp:242] Iteration 114400 (102.178 iter/s, 0.978689s/100 iter), loss = 0.250325
I0506 04:48:11.013284 12834 solver.cpp:261]     Train net output #0: loss = 0.250325 (* 1 = 0.250325 loss)
I0506 04:48:11.013296 12834 sgd_solver.cpp:106] Iteration 114400, lr = 8.58994e-06
I0506 04:48:12.040731 12834 solver.cpp:362] Iteration 114500, Testing net (#0)
I0506 04:48:12.040761 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:12.173835 12834 solver.cpp:429]     Test net output #0: loss = 1.25755 (* 1 = 1.25755 loss)
I0506 04:48:12.176482 12834 solver.cpp:242] Iteration 114500 (85.5824 iter/s, 1.16847s/100 iter), loss = 1.3044
I0506 04:48:12.176517 12834 solver.cpp:261]     Train net output #0: loss = 1.3044 (* 1 = 1.3044 loss)
I0506 04:48:12.176528 12834 sgd_solver.cpp:106] Iteration 114500, lr = 8.58994e-06
I0506 04:48:12.178731 12834 solver.cpp:362] Iteration 114500, Testing net (#0)
I0506 04:48:12.178750 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:12.319358 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7775
I0506 04:48:12.319383 12834 solver.cpp:429]     Test net output #1: loss = 0.499868 (* 1 = 0.499868 loss)
I0506 04:48:12.322089 12834 solver.cpp:242] Iteration 114500 (76.4069 iter/s, 1.30878s/100 iter), loss = 0.272556
I0506 04:48:12.322114 12834 solver.cpp:261]     Train net output #0: loss = 0.272556 (* 1 = 0.272556 loss)
I0506 04:48:12.322125 12834 sgd_solver.cpp:106] Iteration 114500, lr = 8.58994e-06
I0506 04:48:13.352591 12834 solver.cpp:242] Iteration 114600 (85.0311 iter/s, 1.17604s/100 iter), loss = 1.55519
I0506 04:48:13.352643 12834 solver.cpp:261]     Train net output #0: loss = 1.55519 (* 1 = 1.55519 loss)
I0506 04:48:13.353008 12834 sgd_solver.cpp:106] Iteration 114600, lr = 8.58994e-06
I0506 04:48:13.357830 12834 solver.cpp:242] Iteration 114600 (96.5534 iter/s, 1.0357s/100 iter), loss = 0.628606
I0506 04:48:13.357856 12834 solver.cpp:261]     Train net output #0: loss = 0.628606 (* 1 = 0.628606 loss)
I0506 04:48:13.357866 12834 sgd_solver.cpp:106] Iteration 114600, lr = 8.58994e-06
I0506 04:48:14.291043 12834 solver.cpp:242] Iteration 114700 (106.568 iter/s, 0.93837s/100 iter), loss = 2.85023
I0506 04:48:14.291080 12834 solver.cpp:261]     Train net output #0: loss = 2.85023 (* 1 = 2.85023 loss)
I0506 04:48:14.291090 12834 sgd_solver.cpp:106] Iteration 114700, lr = 8.58994e-06
I0506 04:48:14.295859 12834 solver.cpp:242] Iteration 114700 (106.611 iter/s, 0.937985s/100 iter), loss = 0.783927
I0506 04:48:14.295892 12834 solver.cpp:261]     Train net output #0: loss = 0.783927 (* 1 = 0.783927 loss)
I0506 04:48:14.295902 12834 sgd_solver.cpp:106] Iteration 114700, lr = 8.58994e-06
I0506 04:48:15.228828 12834 solver.cpp:242] Iteration 114800 (106.641 iter/s, 0.937722s/100 iter), loss = 0.59154
I0506 04:48:15.228865 12834 solver.cpp:261]     Train net output #0: loss = 0.59154 (* 1 = 0.59154 loss)
I0506 04:48:15.228874 12834 sgd_solver.cpp:106] Iteration 114800, lr = 8.58994e-06
I0506 04:48:15.233598 12834 solver.cpp:242] Iteration 114800 (106.645 iter/s, 0.937688s/100 iter), loss = 0.586849
I0506 04:48:15.233624 12834 solver.cpp:261]     Train net output #0: loss = 0.586849 (* 1 = 0.586849 loss)
I0506 04:48:15.233633 12834 sgd_solver.cpp:106] Iteration 114800, lr = 8.58994e-06
I0506 04:48:16.167214 12834 solver.cpp:242] Iteration 114900 (106.573 iter/s, 0.93832s/100 iter), loss = 0.597265
I0506 04:48:16.167253 12834 solver.cpp:261]     Train net output #0: loss = 0.597265 (* 1 = 0.597265 loss)
I0506 04:48:16.167263 12834 sgd_solver.cpp:106] Iteration 114900, lr = 8.58994e-06
I0506 04:48:16.171993 12834 solver.cpp:242] Iteration 114900 (106.57 iter/s, 0.93835s/100 iter), loss = 0.46154
I0506 04:48:16.172016 12834 solver.cpp:261]     Train net output #0: loss = 0.46154 (* 1 = 0.46154 loss)
I0506 04:48:16.172025 12834 sgd_solver.cpp:106] Iteration 114900, lr = 8.58994e-06
I0506 04:48:17.101917 12834 solver.cpp:362] Iteration 115000, Testing net (#0)
I0506 04:48:17.101939 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:17.224478 12834 solver.cpp:429]     Test net output #0: loss = 1.49136 (* 1 = 1.49136 loss)
I0506 04:48:17.226984 12834 solver.cpp:242] Iteration 115000 (94.3652 iter/s, 1.05971s/100 iter), loss = 1.96721
I0506 04:48:17.227005 12834 solver.cpp:261]     Train net output #0: loss = 1.96721 (* 1 = 1.96721 loss)
I0506 04:48:17.227012 12834 sgd_solver.cpp:106] Iteration 115000, lr = 8.58994e-06
I0506 04:48:17.228857 12834 solver.cpp:362] Iteration 115000, Testing net (#0)
I0506 04:48:17.228870 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:17.357349 12834 solver.cpp:429]     Test net output #0: accuracy = 0.767
I0506 04:48:17.357367 12834 solver.cpp:429]     Test net output #1: loss = 0.562729 (* 1 = 0.562729 loss)
I0506 04:48:17.359915 12834 solver.cpp:242] Iteration 115000 (84.1837 iter/s, 1.18788s/100 iter), loss = 0.572228
I0506 04:48:17.359935 12834 solver.cpp:261]     Train net output #0: loss = 0.572228 (* 1 = 0.572228 loss)
I0506 04:48:17.359943 12834 sgd_solver.cpp:106] Iteration 115000, lr = 8.58994e-06
I0506 04:48:18.293728 12834 solver.cpp:242] Iteration 115100 (93.7479 iter/s, 1.06669s/100 iter), loss = 6.19697
I0506 04:48:18.293761 12834 solver.cpp:261]     Train net output #0: loss = 6.19697 (* 1 = 6.19697 loss)
I0506 04:48:18.293771 12834 sgd_solver.cpp:106] Iteration 115100, lr = 8.58994e-06
I0506 04:48:18.298527 12834 solver.cpp:242] Iteration 115100 (106.545 iter/s, 0.938574s/100 iter), loss = 0.709157
I0506 04:48:18.298552 12834 solver.cpp:261]     Train net output #0: loss = 0.709157 (* 1 = 0.709157 loss)
I0506 04:48:18.298560 12834 sgd_solver.cpp:106] Iteration 115100, lr = 8.58994e-06
I0506 04:48:19.231684 12834 solver.cpp:242] Iteration 115200 (106.621 iter/s, 0.937899s/100 iter), loss = 1.4748
I0506 04:48:19.231729 12834 solver.cpp:261]     Train net output #0: loss = 1.4748 (* 1 = 1.4748 loss)
I0506 04:48:19.231739 12834 sgd_solver.cpp:106] Iteration 115200, lr = 8.58994e-06
I0506 04:48:19.236546 12834 solver.cpp:242] Iteration 115200 (106.614 iter/s, 0.937967s/100 iter), loss = 0.509539
I0506 04:48:19.236577 12834 solver.cpp:261]     Train net output #0: loss = 0.509539 (* 1 = 0.509539 loss)
I0506 04:48:19.236585 12834 sgd_solver.cpp:106] Iteration 115200, lr = 8.58994e-06
I0506 04:48:20.169607 12834 solver.cpp:242] Iteration 115300 (106.627 iter/s, 0.937852s/100 iter), loss = 0.797919
I0506 04:48:20.169647 12834 solver.cpp:261]     Train net output #0: loss = 0.797919 (* 1 = 0.797919 loss)
I0506 04:48:20.169656 12834 sgd_solver.cpp:106] Iteration 115300, lr = 8.58994e-06
I0506 04:48:20.174497 12834 solver.cpp:242] Iteration 115300 (106.621 iter/s, 0.937903s/100 iter), loss = 0.397625
I0506 04:48:20.174523 12834 solver.cpp:261]     Train net output #0: loss = 0.397625 (* 1 = 0.397625 loss)
I0506 04:48:20.174533 12834 sgd_solver.cpp:106] Iteration 115300, lr = 8.58994e-06
I0506 04:48:21.107611 12834 solver.cpp:242] Iteration 115400 (106.618 iter/s, 0.937931s/100 iter), loss = 0.528728
I0506 04:48:21.107653 12834 solver.cpp:261]     Train net output #0: loss = 0.528728 (* 1 = 0.528728 loss)
I0506 04:48:21.107662 12834 sgd_solver.cpp:106] Iteration 115400, lr = 8.58994e-06
I0506 04:48:21.112381 12834 solver.cpp:242] Iteration 115400 (106.628 iter/s, 0.937839s/100 iter), loss = 0.292427
I0506 04:48:21.112407 12834 solver.cpp:261]     Train net output #0: loss = 0.292427 (* 1 = 0.292427 loss)
I0506 04:48:21.112416 12834 sgd_solver.cpp:106] Iteration 115400, lr = 8.58994e-06
I0506 04:48:22.042701 12834 solver.cpp:362] Iteration 115500, Testing net (#0)
I0506 04:48:22.042732 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:22.165375 12834 solver.cpp:429]     Test net output #0: loss = 1.24347 (* 1 = 1.24347 loss)
I0506 04:48:22.167887 12834 solver.cpp:242] Iteration 115500 (94.3204 iter/s, 1.06022s/100 iter), loss = 0.553051
I0506 04:48:22.167909 12834 solver.cpp:261]     Train net output #0: loss = 0.553051 (* 1 = 0.553051 loss)
I0506 04:48:22.167918 12834 sgd_solver.cpp:106] Iteration 115500, lr = 8.58994e-06
I0506 04:48:22.169750 12834 solver.cpp:362] Iteration 115500, Testing net (#0)
I0506 04:48:22.169764 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:22.298332 12834 solver.cpp:429]     Test net output #0: accuracy = 0.769
I0506 04:48:22.298352 12834 solver.cpp:429]     Test net output #1: loss = 0.532786 (* 1 = 0.532786 loss)
I0506 04:48:22.300906 12834 solver.cpp:242] Iteration 115500 (84.1412 iter/s, 1.18848s/100 iter), loss = 0.470181
I0506 04:48:22.300928 12834 solver.cpp:261]     Train net output #0: loss = 0.470181 (* 1 = 0.470181 loss)
I0506 04:48:22.300936 12834 sgd_solver.cpp:106] Iteration 115500, lr = 8.58994e-06
I0506 04:48:23.302309 12834 solver.cpp:242] Iteration 115600 (88.1554 iter/s, 1.13436s/100 iter), loss = 1.34117
I0506 04:48:23.302359 12834 solver.cpp:261]     Train net output #0: loss = 1.34117 (* 1 = 1.34117 loss)
I0506 04:48:23.302371 12834 sgd_solver.cpp:106] Iteration 115600, lr = 8.58994e-06
I0506 04:48:23.307595 12834 solver.cpp:242] Iteration 115600 (99.3397 iter/s, 1.00665s/100 iter), loss = 0.709624
I0506 04:48:23.307626 12834 solver.cpp:261]     Train net output #0: loss = 0.709624 (* 1 = 0.709624 loss)
I0506 04:48:23.307637 12834 sgd_solver.cpp:106] Iteration 115600, lr = 8.58994e-06
I0506 04:48:24.258914 12834 solver.cpp:242] Iteration 115700 (104.545 iter/s, 0.95653s/100 iter), loss = 1.00004
I0506 04:48:24.258961 12834 solver.cpp:261]     Train net output #0: loss = 1.00004 (* 1 = 1.00004 loss)
I0506 04:48:24.259024 12834 sgd_solver.cpp:106] Iteration 115700, lr = 8.58994e-06
I0506 04:48:24.263844 12834 solver.cpp:242] Iteration 115700 (104.581 iter/s, 0.9562s/100 iter), loss = 0.477999
I0506 04:48:24.263867 12834 solver.cpp:261]     Train net output #0: loss = 0.477999 (* 1 = 0.477999 loss)
I0506 04:48:24.263876 12834 sgd_solver.cpp:106] Iteration 115700, lr = 8.58994e-06
I0506 04:48:25.196491 12834 solver.cpp:242] Iteration 115800 (106.667 iter/s, 0.937501s/100 iter), loss = 0.827499
I0506 04:48:25.196530 12834 solver.cpp:261]     Train net output #0: loss = 0.827499 (* 1 = 0.827499 loss)
I0506 04:48:25.196540 12834 sgd_solver.cpp:106] Iteration 115800, lr = 8.58994e-06
I0506 04:48:25.201267 12834 solver.cpp:242] Iteration 115800 (106.68 iter/s, 0.937381s/100 iter), loss = 0.443016
I0506 04:48:25.201290 12834 solver.cpp:261]     Train net output #0: loss = 0.443016 (* 1 = 0.443016 loss)
I0506 04:48:25.201299 12834 sgd_solver.cpp:106] Iteration 115800, lr = 8.58994e-06
I0506 04:48:26.133802 12834 solver.cpp:242] Iteration 115900 (106.695 iter/s, 0.937247s/100 iter), loss = 1.42324
I0506 04:48:26.133853 12834 solver.cpp:261]     Train net output #0: loss = 1.42324 (* 1 = 1.42324 loss)
I0506 04:48:26.133864 12834 sgd_solver.cpp:106] Iteration 115900, lr = 8.58994e-06
I0506 04:48:26.138587 12834 solver.cpp:242] Iteration 115900 (106.692 iter/s, 0.937279s/100 iter), loss = 0.659225
I0506 04:48:26.138610 12834 solver.cpp:261]     Train net output #0: loss = 0.659225 (* 1 = 0.659225 loss)
I0506 04:48:26.138619 12834 sgd_solver.cpp:106] Iteration 115900, lr = 8.58994e-06
I0506 04:48:27.081681 12834 solver.cpp:362] Iteration 116000, Testing net (#0)
I0506 04:48:27.081704 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:27.204309 12834 solver.cpp:429]     Test net output #0: loss = 1.38893 (* 1 = 1.38893 loss)
I0506 04:48:27.206822 12834 solver.cpp:242] Iteration 116000 (93.2009 iter/s, 1.07295s/100 iter), loss = 1.04905
I0506 04:48:27.206845 12834 solver.cpp:261]     Train net output #0: loss = 1.04905 (* 1 = 1.04905 loss)
I0506 04:48:27.206852 12834 sgd_solver.cpp:106] Iteration 116000, lr = 8.58994e-06
I0506 04:48:27.208694 12834 solver.cpp:362] Iteration 116000, Testing net (#0)
I0506 04:48:27.208708 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:27.337486 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7545
I0506 04:48:27.337504 12834 solver.cpp:429]     Test net output #1: loss = 0.579296 (* 1 = 0.579296 loss)
I0506 04:48:27.340060 12834 solver.cpp:242] Iteration 116000 (83.2342 iter/s, 1.20143s/100 iter), loss = 0.902596
I0506 04:48:27.340080 12834 solver.cpp:261]     Train net output #0: loss = 0.902596 (* 1 = 0.902596 loss)
I0506 04:48:27.340090 12834 sgd_solver.cpp:106] Iteration 116000, lr = 8.58994e-06
I0506 04:48:28.273010 12834 solver.cpp:242] Iteration 116100 (93.7963 iter/s, 1.06614s/100 iter), loss = 0.792739
I0506 04:48:28.273048 12834 solver.cpp:261]     Train net output #0: loss = 0.792739 (* 1 = 0.792739 loss)
I0506 04:48:28.273058 12834 sgd_solver.cpp:106] Iteration 116100, lr = 8.58994e-06
I0506 04:48:28.277838 12834 solver.cpp:242] Iteration 116100 (106.641 iter/s, 0.93773s/100 iter), loss = 0.672934
I0506 04:48:28.277864 12834 solver.cpp:261]     Train net output #0: loss = 0.672934 (* 1 = 0.672934 loss)
I0506 04:48:28.277873 12834 sgd_solver.cpp:106] Iteration 116100, lr = 8.58994e-06
I0506 04:48:29.276446 12834 solver.cpp:242] Iteration 116200 (99.6643 iter/s, 1.00337s/100 iter), loss = 0.376437
I0506 04:48:29.276491 12834 solver.cpp:261]     Train net output #0: loss = 0.376437 (* 1 = 0.376437 loss)
I0506 04:48:29.276576 12834 sgd_solver.cpp:106] Iteration 116200, lr = 8.58994e-06
I0506 04:48:29.281383 12834 solver.cpp:242] Iteration 116200 (99.6513 iter/s, 1.0035s/100 iter), loss = 0.532121
I0506 04:48:29.281409 12834 solver.cpp:261]     Train net output #0: loss = 0.532121 (* 1 = 0.532121 loss)
I0506 04:48:29.281417 12834 sgd_solver.cpp:106] Iteration 116200, lr = 8.58994e-06
I0506 04:48:30.214442 12834 solver.cpp:242] Iteration 116300 (106.619 iter/s, 0.937919s/100 iter), loss = 0.688899
I0506 04:48:30.214476 12834 solver.cpp:261]     Train net output #0: loss = 0.688899 (* 1 = 0.688899 loss)
I0506 04:48:30.214485 12834 sgd_solver.cpp:106] Iteration 116300, lr = 8.58994e-06
I0506 04:48:30.219192 12834 solver.cpp:242] Iteration 116300 (106.636 iter/s, 0.937767s/100 iter), loss = 0.603787
I0506 04:48:30.219215 12834 solver.cpp:261]     Train net output #0: loss = 0.603787 (* 1 = 0.603787 loss)
I0506 04:48:30.219224 12834 sgd_solver.cpp:106] Iteration 116300, lr = 8.58994e-06
I0506 04:48:31.152245 12834 solver.cpp:242] Iteration 116400 (106.639 iter/s, 0.937743s/100 iter), loss = 0.418742
I0506 04:48:31.152278 12834 solver.cpp:261]     Train net output #0: loss = 0.418742 (* 1 = 0.418742 loss)
I0506 04:48:31.152287 12834 sgd_solver.cpp:106] Iteration 116400, lr = 8.58994e-06
I0506 04:48:31.157042 12834 solver.cpp:242] Iteration 116400 (106.632 iter/s, 0.937808s/100 iter), loss = 0.351153
I0506 04:48:31.157065 12834 solver.cpp:261]     Train net output #0: loss = 0.351153 (* 1 = 0.351153 loss)
I0506 04:48:31.157074 12834 sgd_solver.cpp:106] Iteration 116400, lr = 8.58994e-06
I0506 04:48:32.086792 12834 solver.cpp:362] Iteration 116500, Testing net (#0)
I0506 04:48:32.086822 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:32.209410 12834 solver.cpp:429]     Test net output #0: loss = 1.34136 (* 1 = 1.34136 loss)
I0506 04:48:32.211920 12834 solver.cpp:242] Iteration 116500 (94.3731 iter/s, 1.05962s/100 iter), loss = 1.04128
I0506 04:48:32.211941 12834 solver.cpp:261]     Train net output #0: loss = 1.04128 (* 1 = 1.04128 loss)
I0506 04:48:32.211948 12834 sgd_solver.cpp:106] Iteration 116500, lr = 8.58994e-06
I0506 04:48:32.213768 12834 solver.cpp:362] Iteration 116500, Testing net (#0)
I0506 04:48:32.213780 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:32.342396 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7685
I0506 04:48:32.342414 12834 solver.cpp:429]     Test net output #1: loss = 0.552409 (* 1 = 0.552409 loss)
I0506 04:48:32.344969 12834 solver.cpp:242] Iteration 116500 (84.1834 iter/s, 1.18788s/100 iter), loss = 0.41301
I0506 04:48:32.344990 12834 solver.cpp:261]     Train net output #0: loss = 0.41301 (* 1 = 0.41301 loss)
I0506 04:48:32.344997 12834 sgd_solver.cpp:106] Iteration 116500, lr = 8.58994e-06
I0506 04:48:33.278688 12834 solver.cpp:242] Iteration 116600 (93.7454 iter/s, 1.06672s/100 iter), loss = 1.72982
I0506 04:48:33.278724 12834 solver.cpp:261]     Train net output #0: loss = 1.72982 (* 1 = 1.72982 loss)
I0506 04:48:33.278733 12834 sgd_solver.cpp:106] Iteration 116600, lr = 8.58994e-06
I0506 04:48:33.283457 12834 solver.cpp:242] Iteration 116600 (106.559 iter/s, 0.938449s/100 iter), loss = 0.527816
I0506 04:48:33.283481 12834 solver.cpp:261]     Train net output #0: loss = 0.527816 (* 1 = 0.527816 loss)
I0506 04:48:33.283490 12834 sgd_solver.cpp:106] Iteration 116600, lr = 8.58994e-06
I0506 04:48:34.219166 12834 solver.cpp:242] Iteration 116700 (106.337 iter/s, 0.940409s/100 iter), loss = 2.39512
I0506 04:48:34.219202 12834 solver.cpp:261]     Train net output #0: loss = 2.39512 (* 1 = 2.39512 loss)
I0506 04:48:34.219211 12834 sgd_solver.cpp:106] Iteration 116700, lr = 8.58994e-06
I0506 04:48:34.223987 12834 solver.cpp:242] Iteration 116700 (106.328 iter/s, 0.940488s/100 iter), loss = 0.432324
I0506 04:48:34.224012 12834 solver.cpp:261]     Train net output #0: loss = 0.432324 (* 1 = 0.432324 loss)
I0506 04:48:34.224021 12834 sgd_solver.cpp:106] Iteration 116700, lr = 8.58994e-06
I0506 04:48:35.157255 12834 solver.cpp:242] Iteration 116800 (106.607 iter/s, 0.938028s/100 iter), loss = 1.18606
I0506 04:48:35.157296 12834 solver.cpp:261]     Train net output #0: loss = 1.18606 (* 1 = 1.18606 loss)
I0506 04:48:35.157305 12834 sgd_solver.cpp:106] Iteration 116800, lr = 8.58994e-06
I0506 04:48:35.162057 12834 solver.cpp:242] Iteration 116800 (106.607 iter/s, 0.938027s/100 iter), loss = 0.421991
I0506 04:48:35.162083 12834 solver.cpp:261]     Train net output #0: loss = 0.421991 (* 1 = 0.421991 loss)
I0506 04:48:35.162092 12834 sgd_solver.cpp:106] Iteration 116800, lr = 8.58994e-06
I0506 04:48:36.095388 12834 solver.cpp:242] Iteration 116900 (106.603 iter/s, 0.938062s/100 iter), loss = 2.32704
I0506 04:48:36.095428 12834 solver.cpp:261]     Train net output #0: loss = 2.32704 (* 1 = 2.32704 loss)
I0506 04:48:36.095438 12834 sgd_solver.cpp:106] Iteration 116900, lr = 8.58994e-06
I0506 04:48:36.100169 12834 solver.cpp:242] Iteration 116900 (106.602 iter/s, 0.938068s/100 iter), loss = 0.542691
I0506 04:48:36.100194 12834 solver.cpp:261]     Train net output #0: loss = 0.542691 (* 1 = 0.542691 loss)
I0506 04:48:36.100203 12834 sgd_solver.cpp:106] Iteration 116900, lr = 8.58994e-06
I0506 04:48:37.029953 12834 solver.cpp:362] Iteration 117000, Testing net (#0)
I0506 04:48:37.029978 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:37.152765 12834 solver.cpp:429]     Test net output #0: loss = 1.31381 (* 1 = 1.31381 loss)
I0506 04:48:37.155282 12834 solver.cpp:242] Iteration 117000 (94.3543 iter/s, 1.05983s/100 iter), loss = 3.92597
I0506 04:48:37.155303 12834 solver.cpp:261]     Train net output #0: loss = 3.92597 (* 1 = 3.92597 loss)
I0506 04:48:37.155320 12834 sgd_solver.cpp:106] Iteration 117000, lr = 8.58994e-06
I0506 04:48:37.157239 12834 solver.cpp:362] Iteration 117000, Testing net (#0)
I0506 04:48:37.157254 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:37.285755 12834 solver.cpp:429]     Test net output #0: accuracy = 0.765
I0506 04:48:37.285774 12834 solver.cpp:429]     Test net output #1: loss = 0.543046 (* 1 = 0.543046 loss)
I0506 04:48:37.288323 12834 solver.cpp:242] Iteration 117000 (84.1675 iter/s, 1.18811s/100 iter), loss = 0.738072
I0506 04:48:37.288342 12834 solver.cpp:261]     Train net output #0: loss = 0.738072 (* 1 = 0.738072 loss)
I0506 04:48:37.288352 12834 sgd_solver.cpp:106] Iteration 117000, lr = 8.58994e-06
I0506 04:48:38.221215 12834 solver.cpp:242] Iteration 117100 (93.8191 iter/s, 1.06588s/100 iter), loss = 0.324097
I0506 04:48:38.221254 12834 solver.cpp:261]     Train net output #0: loss = 0.324097 (* 1 = 0.324097 loss)
I0506 04:48:38.221263 12834 sgd_solver.cpp:106] Iteration 117100, lr = 8.58994e-06
I0506 04:48:38.226001 12834 solver.cpp:242] Iteration 117100 (106.651 iter/s, 0.93764s/100 iter), loss = 0.631395
I0506 04:48:38.226027 12834 solver.cpp:261]     Train net output #0: loss = 0.631395 (* 1 = 0.631395 loss)
I0506 04:48:38.226034 12834 sgd_solver.cpp:106] Iteration 117100, lr = 8.58994e-06
I0506 04:48:39.173511 12834 solver.cpp:242] Iteration 117200 (105.016 iter/s, 0.952233s/100 iter), loss = 0.685982
I0506 04:48:39.173557 12834 solver.cpp:261]     Train net output #0: loss = 0.685982 (* 1 = 0.685982 loss)
I0506 04:48:39.173565 12834 sgd_solver.cpp:106] Iteration 117200, lr = 8.58994e-06
I0506 04:48:39.178279 12834 solver.cpp:242] Iteration 117200 (105.017 iter/s, 0.952225s/100 iter), loss = 0.740618
I0506 04:48:39.178306 12834 solver.cpp:261]     Train net output #0: loss = 0.740618 (* 1 = 0.740618 loss)
I0506 04:48:39.178315 12834 sgd_solver.cpp:106] Iteration 117200, lr = 8.58994e-06
I0506 04:48:40.111912 12834 solver.cpp:242] Iteration 117300 (106.572 iter/s, 0.93833s/100 iter), loss = 0.999894
I0506 04:48:40.111951 12834 solver.cpp:261]     Train net output #0: loss = 0.999894 (* 1 = 0.999894 loss)
I0506 04:48:40.111961 12834 sgd_solver.cpp:106] Iteration 117300, lr = 8.58994e-06
I0506 04:48:40.116705 12834 solver.cpp:242] Iteration 117300 (106.567 iter/s, 0.93838s/100 iter), loss = 0.338471
I0506 04:48:40.116731 12834 solver.cpp:261]     Train net output #0: loss = 0.338471 (* 1 = 0.338471 loss)
I0506 04:48:40.116740 12834 sgd_solver.cpp:106] Iteration 117300, lr = 8.58994e-06
I0506 04:48:41.051614 12834 solver.cpp:242] Iteration 117400 (106.425 iter/s, 0.939632s/100 iter), loss = 3.21108
I0506 04:48:41.051651 12834 solver.cpp:261]     Train net output #0: loss = 3.21108 (* 1 = 3.21108 loss)
I0506 04:48:41.051659 12834 sgd_solver.cpp:106] Iteration 117400, lr = 8.58994e-06
I0506 04:48:41.056390 12834 solver.cpp:242] Iteration 117400 (106.424 iter/s, 0.939639s/100 iter), loss = 0.694362
I0506 04:48:41.056414 12834 solver.cpp:261]     Train net output #0: loss = 0.694362 (* 1 = 0.694362 loss)
I0506 04:48:41.056424 12834 sgd_solver.cpp:106] Iteration 117400, lr = 8.58994e-06
I0506 04:48:41.986475 12834 solver.cpp:362] Iteration 117500, Testing net (#0)
I0506 04:48:41.986498 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:42.109140 12834 solver.cpp:429]     Test net output #0: loss = 1.30316 (* 1 = 1.30316 loss)
I0506 04:48:42.111665 12834 solver.cpp:242] Iteration 117500 (94.34 iter/s, 1.06s/100 iter), loss = 1.24319
I0506 04:48:42.111685 12834 solver.cpp:261]     Train net output #0: loss = 1.24319 (* 1 = 1.24319 loss)
I0506 04:48:42.111695 12834 sgd_solver.cpp:106] Iteration 117500, lr = 8.58994e-06
I0506 04:48:42.113512 12834 solver.cpp:362] Iteration 117500, Testing net (#0)
I0506 04:48:42.113524 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:42.242188 12834 solver.cpp:429]     Test net output #0: accuracy = 0.782
I0506 04:48:42.242208 12834 solver.cpp:429]     Test net output #1: loss = 0.519692 (* 1 = 0.519692 loss)
I0506 04:48:42.244793 12834 solver.cpp:242] Iteration 117500 (84.1499 iter/s, 1.18836s/100 iter), loss = 0.718033
I0506 04:48:42.244815 12834 solver.cpp:261]     Train net output #0: loss = 0.718033 (* 1 = 0.718033 loss)
I0506 04:48:42.244824 12834 sgd_solver.cpp:106] Iteration 117500, lr = 8.58994e-06
I0506 04:48:43.240813 12834 solver.cpp:242] Iteration 117600 (88.5669 iter/s, 1.12909s/100 iter), loss = 0.525946
I0506 04:48:43.240856 12834 solver.cpp:261]     Train net output #0: loss = 0.525946 (* 1 = 0.525946 loss)
I0506 04:48:43.240869 12834 sgd_solver.cpp:106] Iteration 117600, lr = 8.58994e-06
I0506 04:48:43.246099 12834 solver.cpp:242] Iteration 117600 (99.8737 iter/s, 1.00126s/100 iter), loss = 0.353282
I0506 04:48:43.246129 12834 solver.cpp:261]     Train net output #0: loss = 0.353282 (* 1 = 0.353282 loss)
I0506 04:48:43.246140 12834 sgd_solver.cpp:106] Iteration 117600, lr = 8.58994e-06
I0506 04:48:44.276899 12834 solver.cpp:242] Iteration 117700 (96.5236 iter/s, 1.03602s/100 iter), loss = 1.99583
I0506 04:48:44.276942 12834 solver.cpp:261]     Train net output #0: loss = 1.99583 (* 1 = 1.99583 loss)
I0506 04:48:44.276953 12834 sgd_solver.cpp:106] Iteration 117700, lr = 8.58994e-06
I0506 04:48:44.282192 12834 solver.cpp:242] Iteration 117700 (96.521 iter/s, 1.03604s/100 iter), loss = 0.746059
I0506 04:48:44.282222 12834 solver.cpp:261]     Train net output #0: loss = 0.746059 (* 1 = 0.746059 loss)
I0506 04:48:44.282232 12834 sgd_solver.cpp:106] Iteration 117700, lr = 8.58994e-06
I0506 04:48:45.257537 12834 solver.cpp:242] Iteration 117800 (101.982 iter/s, 0.980567s/100 iter), loss = 1.13738
I0506 04:48:45.257570 12834 solver.cpp:261]     Train net output #0: loss = 1.13738 (* 1 = 1.13738 loss)
I0506 04:48:45.257580 12834 sgd_solver.cpp:106] Iteration 117800, lr = 8.58994e-06
I0506 04:48:45.262287 12834 solver.cpp:242] Iteration 117800 (102.036 iter/s, 0.980048s/100 iter), loss = 0.364958
I0506 04:48:45.262311 12834 solver.cpp:261]     Train net output #0: loss = 0.364958 (* 1 = 0.364958 loss)
I0506 04:48:45.262320 12834 sgd_solver.cpp:106] Iteration 117800, lr = 8.58994e-06
I0506 04:48:46.195847 12834 solver.cpp:242] Iteration 117900 (106.581 iter/s, 0.938252s/100 iter), loss = 0.516741
I0506 04:48:46.195888 12834 solver.cpp:261]     Train net output #0: loss = 0.516741 (* 1 = 0.516741 loss)
I0506 04:48:46.195899 12834 sgd_solver.cpp:106] Iteration 117900, lr = 8.58994e-06
I0506 04:48:46.200721 12834 solver.cpp:242] Iteration 117900 (106.567 iter/s, 0.93838s/100 iter), loss = 0.690844
I0506 04:48:46.200743 12834 solver.cpp:261]     Train net output #0: loss = 0.690844 (* 1 = 0.690844 loss)
I0506 04:48:46.200752 12834 sgd_solver.cpp:106] Iteration 117900, lr = 8.58994e-06
I0506 04:48:47.189119 12834 solver.cpp:362] Iteration 118000, Testing net (#0)
I0506 04:48:47.189153 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:47.322104 12834 solver.cpp:429]     Test net output #0: loss = 1.25699 (* 1 = 1.25699 loss)
I0506 04:48:47.324738 12834 solver.cpp:242] Iteration 118000 (88.5875 iter/s, 1.12883s/100 iter), loss = 4.30754
I0506 04:48:47.324762 12834 solver.cpp:261]     Train net output #0: loss = 4.30754 (* 1 = 4.30754 loss)
I0506 04:48:47.324772 12834 sgd_solver.cpp:106] Iteration 118000, lr = 8.58994e-06
I0506 04:48:47.326961 12834 solver.cpp:362] Iteration 118000, Testing net (#0)
I0506 04:48:47.326974 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:47.467598 12834 solver.cpp:429]     Test net output #0: accuracy = 0.777
I0506 04:48:47.467622 12834 solver.cpp:429]     Test net output #1: loss = 0.52059 (* 1 = 0.52059 loss)
I0506 04:48:47.470322 12834 solver.cpp:242] Iteration 118000 (78.7677 iter/s, 1.26956s/100 iter), loss = 0.684881
I0506 04:48:47.470346 12834 solver.cpp:261]     Train net output #0: loss = 0.684881 (* 1 = 0.684881 loss)
I0506 04:48:47.470357 12834 sgd_solver.cpp:106] Iteration 118000, lr = 8.58994e-06
I0506 04:48:48.499907 12834 solver.cpp:242] Iteration 118100 (85.0979 iter/s, 1.17512s/100 iter), loss = 0.896188
I0506 04:48:48.499956 12834 solver.cpp:261]     Train net output #0: loss = 0.896188 (* 1 = 0.896188 loss)
I0506 04:48:48.499969 12834 sgd_solver.cpp:106] Iteration 118100, lr = 8.58994e-06
I0506 04:48:48.505293 12834 solver.cpp:242] Iteration 118100 (96.6261 iter/s, 1.03492s/100 iter), loss = 0.488578
I0506 04:48:48.505323 12834 solver.cpp:261]     Train net output #0: loss = 0.488578 (* 1 = 0.488578 loss)
I0506 04:48:48.505334 12834 sgd_solver.cpp:106] Iteration 118100, lr = 8.58994e-06
I0506 04:48:49.535270 12834 solver.cpp:242] Iteration 118200 (96.5917 iter/s, 1.03529s/100 iter), loss = 0.251281
I0506 04:48:49.535310 12834 solver.cpp:261]     Train net output #0: loss = 0.251281 (* 1 = 0.251281 loss)
I0506 04:48:49.535321 12834 sgd_solver.cpp:106] Iteration 118200, lr = 8.58994e-06
I0506 04:48:49.540539 12834 solver.cpp:242] Iteration 118200 (96.6001 iter/s, 1.0352s/100 iter), loss = 0.547916
I0506 04:48:49.540573 12834 solver.cpp:261]     Train net output #0: loss = 0.547916 (* 1 = 0.547916 loss)
I0506 04:48:49.540585 12834 sgd_solver.cpp:106] Iteration 118200, lr = 8.58994e-06
I0506 04:48:50.488083 12834 solver.cpp:242] Iteration 118300 (104.96 iter/s, 0.952744s/100 iter), loss = 0.775066
I0506 04:48:50.488112 12834 solver.cpp:261]     Train net output #0: loss = 0.775066 (* 1 = 0.775066 loss)
I0506 04:48:50.488122 12834 sgd_solver.cpp:106] Iteration 118300, lr = 8.58994e-06
I0506 04:48:50.492847 12834 solver.cpp:242] Iteration 118300 (105.014 iter/s, 0.952256s/100 iter), loss = 0.477618
I0506 04:48:50.492869 12834 solver.cpp:261]     Train net output #0: loss = 0.477618 (* 1 = 0.477618 loss)
I0506 04:48:50.492878 12834 sgd_solver.cpp:106] Iteration 118300, lr = 8.58994e-06
I0506 04:48:51.425504 12834 solver.cpp:242] Iteration 118400 (106.682 iter/s, 0.937364s/100 iter), loss = 0.477678
I0506 04:48:51.425545 12834 solver.cpp:261]     Train net output #0: loss = 0.477678 (* 1 = 0.477678 loss)
I0506 04:48:51.425554 12834 sgd_solver.cpp:106] Iteration 118400, lr = 8.58994e-06
I0506 04:48:51.430280 12834 solver.cpp:242] Iteration 118400 (106.679 iter/s, 0.937393s/100 iter), loss = 0.39331
I0506 04:48:51.430305 12834 solver.cpp:261]     Train net output #0: loss = 0.39331 (* 1 = 0.39331 loss)
I0506 04:48:51.430315 12834 sgd_solver.cpp:106] Iteration 118400, lr = 8.58994e-06
I0506 04:48:52.359612 12834 solver.cpp:362] Iteration 118500, Testing net (#0)
I0506 04:48:52.359639 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:52.482527 12834 solver.cpp:429]     Test net output #0: loss = 1.31402 (* 1 = 1.31402 loss)
I0506 04:48:52.485040 12834 solver.cpp:242] Iteration 118500 (94.3861 iter/s, 1.05948s/100 iter), loss = 1.22127
I0506 04:48:52.485060 12834 solver.cpp:261]     Train net output #0: loss = 1.22127 (* 1 = 1.22127 loss)
I0506 04:48:52.485069 12834 sgd_solver.cpp:106] Iteration 118500, lr = 8.58994e-06
I0506 04:48:52.486915 12834 solver.cpp:362] Iteration 118500, Testing net (#0)
I0506 04:48:52.486928 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:52.615842 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7775
I0506 04:48:52.615862 12834 solver.cpp:429]     Test net output #1: loss = 0.519722 (* 1 = 0.519722 loss)
I0506 04:48:52.618412 12834 solver.cpp:242] Iteration 118500 (84.1689 iter/s, 1.18809s/100 iter), loss = 0.526955
I0506 04:48:52.618432 12834 solver.cpp:261]     Train net output #0: loss = 0.526955 (* 1 = 0.526955 loss)
I0506 04:48:52.618440 12834 sgd_solver.cpp:106] Iteration 118500, lr = 8.58994e-06
I0506 04:48:53.552371 12834 solver.cpp:242] Iteration 118600 (93.696 iter/s, 1.06728s/100 iter), loss = 5.22233
I0506 04:48:53.552410 12834 solver.cpp:261]     Train net output #0: loss = 5.22233 (* 1 = 5.22233 loss)
I0506 04:48:53.552420 12834 sgd_solver.cpp:106] Iteration 118600, lr = 8.58994e-06
I0506 04:48:53.557143 12834 solver.cpp:242] Iteration 118600 (106.531 iter/s, 0.938693s/100 iter), loss = 0.817846
I0506 04:48:53.557168 12834 solver.cpp:261]     Train net output #0: loss = 0.817846 (* 1 = 0.817846 loss)
I0506 04:48:53.557176 12834 sgd_solver.cpp:106] Iteration 118600, lr = 8.58994e-06
I0506 04:48:54.490413 12834 solver.cpp:242] Iteration 118700 (106.613 iter/s, 0.937971s/100 iter), loss = 5.43343
I0506 04:48:54.490454 12834 solver.cpp:261]     Train net output #0: loss = 5.43343 (* 1 = 5.43343 loss)
I0506 04:48:54.490463 12834 sgd_solver.cpp:106] Iteration 118700, lr = 8.58994e-06
I0506 04:48:54.495188 12834 solver.cpp:242] Iteration 118700 (106.61 iter/s, 0.938001s/100 iter), loss = 0.787747
I0506 04:48:54.495214 12834 solver.cpp:261]     Train net output #0: loss = 0.787747 (* 1 = 0.787747 loss)
I0506 04:48:54.495223 12834 sgd_solver.cpp:106] Iteration 118700, lr = 8.58994e-06
I0506 04:48:55.516715 12834 solver.cpp:242] Iteration 118800 (97.4436 iter/s, 1.02623s/100 iter), loss = 1.40359
I0506 04:48:55.516764 12834 solver.cpp:261]     Train net output #0: loss = 1.40359 (* 1 = 1.40359 loss)
I0506 04:48:55.516841 12834 sgd_solver.cpp:106] Iteration 118800, lr = 8.58994e-06
I0506 04:48:55.521690 12834 solver.cpp:242] Iteration 118800 (97.4235 iter/s, 1.02645s/100 iter), loss = 0.410266
I0506 04:48:55.521714 12834 solver.cpp:261]     Train net output #0: loss = 0.410266 (* 1 = 0.410266 loss)
I0506 04:48:55.521723 12834 sgd_solver.cpp:106] Iteration 118800, lr = 8.58994e-06
I0506 04:48:56.455237 12834 solver.cpp:242] Iteration 118900 (106.559 iter/s, 0.938447s/100 iter), loss = 0.722703
I0506 04:48:56.455277 12834 solver.cpp:261]     Train net output #0: loss = 0.722703 (* 1 = 0.722703 loss)
I0506 04:48:56.455286 12834 sgd_solver.cpp:106] Iteration 118900, lr = 8.58994e-06
I0506 04:48:56.460031 12834 solver.cpp:242] Iteration 118900 (106.576 iter/s, 0.938298s/100 iter), loss = 0.34432
I0506 04:48:56.460055 12834 solver.cpp:261]     Train net output #0: loss = 0.34432 (* 1 = 0.34432 loss)
I0506 04:48:56.460064 12834 sgd_solver.cpp:106] Iteration 118900, lr = 8.58994e-06
I0506 04:48:57.389786 12834 solver.cpp:362] Iteration 119000, Testing net (#0)
I0506 04:48:57.389811 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:57.512403 12834 solver.cpp:429]     Test net output #0: loss = 1.43298 (* 1 = 1.43298 loss)
I0506 04:48:57.514921 12834 solver.cpp:242] Iteration 119000 (94.373 iter/s, 1.05963s/100 iter), loss = 1.60573
I0506 04:48:57.514942 12834 solver.cpp:261]     Train net output #0: loss = 1.60573 (* 1 = 1.60573 loss)
I0506 04:48:57.514951 12834 sgd_solver.cpp:106] Iteration 119000, lr = 8.58994e-06
I0506 04:48:57.516854 12834 solver.cpp:362] Iteration 119000, Testing net (#0)
I0506 04:48:57.516867 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:48:57.645555 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7655
I0506 04:48:57.645575 12834 solver.cpp:429]     Test net output #1: loss = 0.536618 (* 1 = 0.536618 loss)
I0506 04:48:57.648128 12834 solver.cpp:242] Iteration 119000 (84.1714 iter/s, 1.18805s/100 iter), loss = 0.384334
I0506 04:48:57.648149 12834 solver.cpp:261]     Train net output #0: loss = 0.384334 (* 1 = 0.384334 loss)
I0506 04:48:57.648156 12834 sgd_solver.cpp:106] Iteration 119000, lr = 8.58994e-06
I0506 04:48:58.581936 12834 solver.cpp:242] Iteration 119100 (93.724 iter/s, 1.06696s/100 iter), loss = 0.924234
I0506 04:48:58.581982 12834 solver.cpp:261]     Train net output #0: loss = 0.924234 (* 1 = 0.924234 loss)
I0506 04:48:58.581995 12834 sgd_solver.cpp:106] Iteration 119100, lr = 8.58994e-06
I0506 04:48:58.587206 12834 solver.cpp:242] Iteration 119100 (106.492 iter/s, 0.939039s/100 iter), loss = 0.374579
I0506 04:48:58.587235 12834 solver.cpp:261]     Train net output #0: loss = 0.374579 (* 1 = 0.374579 loss)
I0506 04:48:58.587246 12834 sgd_solver.cpp:106] Iteration 119100, lr = 8.58994e-06
I0506 04:48:59.596864 12834 solver.cpp:242] Iteration 119200 (98.5369 iter/s, 1.01485s/100 iter), loss = 2.04935
I0506 04:48:59.596904 12834 solver.cpp:261]     Train net output #0: loss = 2.04935 (* 1 = 2.04935 loss)
I0506 04:48:59.596912 12834 sgd_solver.cpp:106] Iteration 119200, lr = 8.58994e-06
I0506 04:48:59.601637 12834 solver.cpp:242] Iteration 119200 (98.5821 iter/s, 1.01438s/100 iter), loss = 0.565984
I0506 04:48:59.601661 12834 solver.cpp:261]     Train net output #0: loss = 0.565984 (* 1 = 0.565984 loss)
I0506 04:48:59.601680 12834 sgd_solver.cpp:106] Iteration 119200, lr = 8.58994e-06
I0506 04:49:00.539572 12834 solver.cpp:242] Iteration 119300 (106.085 iter/s, 0.94264s/100 iter), loss = 1.26488
I0506 04:49:00.539628 12834 solver.cpp:261]     Train net output #0: loss = 1.26488 (* 1 = 1.26488 loss)
I0506 04:49:00.539774 12834 sgd_solver.cpp:106] Iteration 119300, lr = 8.58994e-06
I0506 04:49:00.544582 12834 solver.cpp:242] Iteration 119300 (106.056 iter/s, 0.942902s/100 iter), loss = 0.876365
I0506 04:49:00.544607 12834 solver.cpp:261]     Train net output #0: loss = 0.876365 (* 1 = 0.876365 loss)
I0506 04:49:00.544616 12834 sgd_solver.cpp:106] Iteration 119300, lr = 8.58994e-06
I0506 04:49:01.481892 12834 solver.cpp:242] Iteration 119400 (106.131 iter/s, 0.942236s/100 iter), loss = 1.5521
I0506 04:49:01.481928 12834 solver.cpp:261]     Train net output #0: loss = 1.5521 (* 1 = 1.5521 loss)
I0506 04:49:01.481937 12834 sgd_solver.cpp:106] Iteration 119400, lr = 8.58994e-06
I0506 04:49:01.486697 12834 solver.cpp:242] Iteration 119400 (106.149 iter/s, 0.942071s/100 iter), loss = 0.459119
I0506 04:49:01.486723 12834 solver.cpp:261]     Train net output #0: loss = 0.459119 (* 1 = 0.459119 loss)
I0506 04:49:01.486732 12834 sgd_solver.cpp:106] Iteration 119400, lr = 8.58994e-06
I0506 04:49:02.417961 12834 solver.cpp:362] Iteration 119500, Testing net (#0)
I0506 04:49:02.417990 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:02.540643 12834 solver.cpp:429]     Test net output #0: loss = 1.3912 (* 1 = 1.3912 loss)
I0506 04:49:02.543166 12834 solver.cpp:242] Iteration 119500 (94.2312 iter/s, 1.06122s/100 iter), loss = 2.40916
I0506 04:49:02.543187 12834 solver.cpp:261]     Train net output #0: loss = 2.40916 (* 1 = 2.40916 loss)
I0506 04:49:02.543196 12834 sgd_solver.cpp:106] Iteration 119500, lr = 8.58994e-06
I0506 04:49:02.545016 12834 solver.cpp:362] Iteration 119500, Testing net (#0)
I0506 04:49:02.545029 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:02.673851 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7655
I0506 04:49:02.673871 12834 solver.cpp:429]     Test net output #1: loss = 0.531347 (* 1 = 0.531347 loss)
I0506 04:49:02.676426 12834 solver.cpp:242] Iteration 119500 (84.0561 iter/s, 1.18968s/100 iter), loss = 0.80926
I0506 04:49:02.676446 12834 solver.cpp:261]     Train net output #0: loss = 0.80926 (* 1 = 0.80926 loss)
I0506 04:49:02.676455 12834 sgd_solver.cpp:106] Iteration 119500, lr = 8.58994e-06
I0506 04:49:03.608886 12834 solver.cpp:242] Iteration 119600 (93.8381 iter/s, 1.06567s/100 iter), loss = 2.60092
I0506 04:49:03.608922 12834 solver.cpp:261]     Train net output #0: loss = 2.60092 (* 1 = 2.60092 loss)
I0506 04:49:03.608932 12834 sgd_solver.cpp:106] Iteration 119600, lr = 8.58994e-06
I0506 04:49:03.613713 12834 solver.cpp:242] Iteration 119600 (106.695 iter/s, 0.937247s/100 iter), loss = 0.604737
I0506 04:49:03.613737 12834 solver.cpp:261]     Train net output #0: loss = 0.604737 (* 1 = 0.604737 loss)
I0506 04:49:03.613746 12834 sgd_solver.cpp:106] Iteration 119600, lr = 8.58994e-06
I0506 04:49:04.545997 12834 solver.cpp:242] Iteration 119700 (106.718 iter/s, 0.937052s/100 iter), loss = 0.363517
I0506 04:49:04.546030 12834 solver.cpp:261]     Train net output #0: loss = 0.363517 (* 1 = 0.363517 loss)
I0506 04:49:04.546041 12834 sgd_solver.cpp:106] Iteration 119700, lr = 8.58994e-06
I0506 04:49:04.550834 12834 solver.cpp:242] Iteration 119700 (106.716 iter/s, 0.93707s/100 iter), loss = 0.182545
I0506 04:49:04.550858 12834 solver.cpp:261]     Train net output #0: loss = 0.182545 (* 1 = 0.182545 loss)
I0506 04:49:04.550868 12834 sgd_solver.cpp:106] Iteration 119700, lr = 8.58994e-06
I0506 04:49:05.483988 12834 solver.cpp:242] Iteration 119800 (106.618 iter/s, 0.937928s/100 iter), loss = 1.21537
I0506 04:49:05.484028 12834 solver.cpp:261]     Train net output #0: loss = 1.21537 (* 1 = 1.21537 loss)
I0506 04:49:05.484037 12834 sgd_solver.cpp:106] Iteration 119800, lr = 8.58994e-06
I0506 04:49:05.488778 12834 solver.cpp:242] Iteration 119800 (106.621 iter/s, 0.937901s/100 iter), loss = 0.579217
I0506 04:49:05.488806 12834 solver.cpp:261]     Train net output #0: loss = 0.579217 (* 1 = 0.579217 loss)
I0506 04:49:05.488814 12834 sgd_solver.cpp:106] Iteration 119800, lr = 8.58994e-06
I0506 04:49:06.422469 12834 solver.cpp:242] Iteration 119900 (106.562 iter/s, 0.938417s/100 iter), loss = 0.866609
I0506 04:49:06.422513 12834 solver.cpp:261]     Train net output #0: loss = 0.866609 (* 1 = 0.866609 loss)
I0506 04:49:06.422523 12834 sgd_solver.cpp:106] Iteration 119900, lr = 8.58994e-06
I0506 04:49:06.427323 12834 solver.cpp:242] Iteration 119900 (106.554 iter/s, 0.938491s/100 iter), loss = 0.557835
I0506 04:49:06.427348 12834 solver.cpp:261]     Train net output #0: loss = 0.557835 (* 1 = 0.557835 loss)
I0506 04:49:06.427357 12834 sgd_solver.cpp:106] Iteration 119900, lr = 8.58994e-06
I0506 04:49:07.357985 12834 solver.cpp:362] Iteration 120000, Testing net (#0)
I0506 04:49:07.358012 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:07.480751 12834 solver.cpp:429]     Test net output #0: loss = 1.35419 (* 1 = 1.35419 loss)
I0506 04:49:07.483273 12834 solver.cpp:242] Iteration 120000 (94.2736 iter/s, 1.06074s/100 iter), loss = 0.555792
I0506 04:49:07.483294 12834 solver.cpp:261]     Train net output #0: loss = 0.555792 (* 1 = 0.555792 loss)
I0506 04:49:07.483304 12834 sgd_solver.cpp:106] Iteration 120000, lr = 6.87195e-06
I0506 04:49:07.485141 12834 solver.cpp:362] Iteration 120000, Testing net (#0)
I0506 04:49:07.485154 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:07.613725 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7655
I0506 04:49:07.613746 12834 solver.cpp:429]     Test net output #1: loss = 0.53725 (* 1 = 0.53725 loss)
I0506 04:49:07.616297 12834 solver.cpp:242] Iteration 120000 (84.1094 iter/s, 1.18893s/100 iter), loss = 0.190926
I0506 04:49:07.616317 12834 solver.cpp:261]     Train net output #0: loss = 0.190926 (* 1 = 0.190926 loss)
I0506 04:49:07.616325 12834 sgd_solver.cpp:106] Iteration 120000, lr = 6.87195e-06
I0506 04:49:08.549356 12834 solver.cpp:242] Iteration 120100 (93.8063 iter/s, 1.06603s/100 iter), loss = 1.23393
I0506 04:49:08.549396 12834 solver.cpp:261]     Train net output #0: loss = 1.23393 (* 1 = 1.23393 loss)
I0506 04:49:08.549405 12834 sgd_solver.cpp:106] Iteration 120100, lr = 6.87195e-06
I0506 04:49:08.554138 12834 solver.cpp:242] Iteration 120100 (106.632 iter/s, 0.937803s/100 iter), loss = 0.476569
I0506 04:49:08.554163 12834 solver.cpp:261]     Train net output #0: loss = 0.476569 (* 1 = 0.476569 loss)
I0506 04:49:08.554172 12834 sgd_solver.cpp:106] Iteration 120100, lr = 6.87195e-06
I0506 04:49:09.500171 12834 solver.cpp:242] Iteration 120200 (105.18 iter/s, 0.950749s/100 iter), loss = 1.77792
I0506 04:49:09.500213 12834 solver.cpp:261]     Train net output #0: loss = 1.77792 (* 1 = 1.77792 loss)
I0506 04:49:09.500222 12834 sgd_solver.cpp:106] Iteration 120200, lr = 6.87195e-06
I0506 04:49:09.504942 12834 solver.cpp:242] Iteration 120200 (105.179 iter/s, 0.950761s/100 iter), loss = 0.626803
I0506 04:49:09.504967 12834 solver.cpp:261]     Train net output #0: loss = 0.626803 (* 1 = 0.626803 loss)
I0506 04:49:09.504976 12834 sgd_solver.cpp:106] Iteration 120200, lr = 6.87195e-06
I0506 04:49:10.438549 12834 solver.cpp:242] Iteration 120300 (106.575 iter/s, 0.938303s/100 iter), loss = 0.758904
I0506 04:49:10.438596 12834 solver.cpp:261]     Train net output #0: loss = 0.758904 (* 1 = 0.758904 loss)
I0506 04:49:10.438606 12834 sgd_solver.cpp:106] Iteration 120300, lr = 6.87195e-06
I0506 04:49:10.443326 12834 solver.cpp:242] Iteration 120300 (106.571 iter/s, 0.93834s/100 iter), loss = 0.649889
I0506 04:49:10.443354 12834 solver.cpp:261]     Train net output #0: loss = 0.649889 (* 1 = 0.649889 loss)
I0506 04:49:10.443363 12834 sgd_solver.cpp:106] Iteration 120300, lr = 6.87195e-06
I0506 04:49:11.459034 12834 solver.cpp:242] Iteration 120400 (97.9998 iter/s, 1.02041s/100 iter), loss = 0.614784
I0506 04:49:11.459084 12834 solver.cpp:261]     Train net output #0: loss = 0.614784 (* 1 = 0.614784 loss)
I0506 04:49:11.459203 12834 sgd_solver.cpp:106] Iteration 120400, lr = 6.87195e-06
I0506 04:49:11.463981 12834 solver.cpp:242] Iteration 120400 (97.9808 iter/s, 1.02061s/100 iter), loss = 0.425041
I0506 04:49:11.464007 12834 solver.cpp:261]     Train net output #0: loss = 0.425041 (* 1 = 0.425041 loss)
I0506 04:49:11.464015 12834 sgd_solver.cpp:106] Iteration 120400, lr = 6.87195e-06
I0506 04:49:12.415431 12834 solver.cpp:362] Iteration 120500, Testing net (#0)
I0506 04:49:12.415463 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:12.538220 12834 solver.cpp:429]     Test net output #0: loss = 1.3256 (* 1 = 1.3256 loss)
I0506 04:49:12.540745 12834 solver.cpp:242] Iteration 120500 (92.4519 iter/s, 1.08164s/100 iter), loss = 0.514584
I0506 04:49:12.540766 12834 solver.cpp:261]     Train net output #0: loss = 0.514584 (* 1 = 0.514584 loss)
I0506 04:49:12.540774 12834 sgd_solver.cpp:106] Iteration 120500, lr = 6.87195e-06
I0506 04:49:12.542590 12834 solver.cpp:362] Iteration 120500, Testing net (#0)
I0506 04:49:12.542606 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:12.671506 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7675
I0506 04:49:12.671528 12834 solver.cpp:429]     Test net output #1: loss = 0.534961 (* 1 = 0.534961 loss)
I0506 04:49:12.674087 12834 solver.cpp:242] Iteration 120500 (82.6406 iter/s, 1.21006s/100 iter), loss = 0.306404
I0506 04:49:12.674106 12834 solver.cpp:261]     Train net output #0: loss = 0.306404 (* 1 = 0.306404 loss)
I0506 04:49:12.674115 12834 sgd_solver.cpp:106] Iteration 120500, lr = 6.87195e-06
I0506 04:49:13.607367 12834 solver.cpp:242] Iteration 120600 (93.7581 iter/s, 1.06657s/100 iter), loss = 1.01697
I0506 04:49:13.607404 12834 solver.cpp:261]     Train net output #0: loss = 1.01697 (* 1 = 1.01697 loss)
I0506 04:49:13.607414 12834 sgd_solver.cpp:106] Iteration 120600, lr = 6.87195e-06
I0506 04:49:13.612233 12834 solver.cpp:242] Iteration 120600 (106.599 iter/s, 0.938098s/100 iter), loss = 0.429099
I0506 04:49:13.612259 12834 solver.cpp:261]     Train net output #0: loss = 0.429099 (* 1 = 0.429099 loss)
I0506 04:49:13.612268 12834 sgd_solver.cpp:106] Iteration 120600, lr = 6.87195e-06
I0506 04:49:14.545747 12834 solver.cpp:242] Iteration 120700 (106.574 iter/s, 0.938314s/100 iter), loss = 0.833727
I0506 04:49:14.545784 12834 solver.cpp:261]     Train net output #0: loss = 0.833727 (* 1 = 0.833727 loss)
I0506 04:49:14.545794 12834 sgd_solver.cpp:106] Iteration 120700, lr = 6.87195e-06
I0506 04:49:14.550549 12834 solver.cpp:242] Iteration 120700 (106.579 iter/s, 0.938272s/100 iter), loss = 0.436591
I0506 04:49:14.550573 12834 solver.cpp:261]     Train net output #0: loss = 0.436591 (* 1 = 0.436591 loss)
I0506 04:49:14.550582 12834 sgd_solver.cpp:106] Iteration 120700, lr = 6.87195e-06
I0506 04:49:15.496955 12834 solver.cpp:242] Iteration 120800 (105.136 iter/s, 0.951147s/100 iter), loss = 0.715495
I0506 04:49:15.496992 12834 solver.cpp:261]     Train net output #0: loss = 0.715495 (* 1 = 0.715495 loss)
I0506 04:49:15.497001 12834 sgd_solver.cpp:106] Iteration 120800, lr = 6.87195e-06
I0506 04:49:15.501775 12834 solver.cpp:242] Iteration 120800 (105.133 iter/s, 0.951174s/100 iter), loss = 0.355455
I0506 04:49:15.501801 12834 solver.cpp:261]     Train net output #0: loss = 0.355455 (* 1 = 0.355455 loss)
I0506 04:49:15.501809 12834 sgd_solver.cpp:106] Iteration 120800, lr = 6.87195e-06
I0506 04:49:16.434914 12834 solver.cpp:242] Iteration 120900 (106.622 iter/s, 0.937896s/100 iter), loss = 3.38203
I0506 04:49:16.434947 12834 solver.cpp:261]     Train net output #0: loss = 3.38203 (* 1 = 3.38203 loss)
I0506 04:49:16.434957 12834 sgd_solver.cpp:106] Iteration 120900, lr = 6.87195e-06
I0506 04:49:16.439702 12834 solver.cpp:242] Iteration 120900 (106.623 iter/s, 0.937884s/100 iter), loss = 0.700576
I0506 04:49:16.439726 12834 solver.cpp:261]     Train net output #0: loss = 0.700576 (* 1 = 0.700576 loss)
I0506 04:49:16.439734 12834 sgd_solver.cpp:106] Iteration 120900, lr = 6.87195e-06
I0506 04:49:17.439550 12834 solver.cpp:362] Iteration 121000, Testing net (#0)
I0506 04:49:17.439574 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:17.562070 12834 solver.cpp:429]     Test net output #0: loss = 1.19846 (* 1 = 1.19846 loss)
I0506 04:49:17.564587 12834 solver.cpp:242] Iteration 121000 (88.5254 iter/s, 1.12962s/100 iter), loss = 2.43096
I0506 04:49:17.564607 12834 solver.cpp:261]     Train net output #0: loss = 2.43096 (* 1 = 2.43096 loss)
I0506 04:49:17.564616 12834 sgd_solver.cpp:106] Iteration 121000, lr = 6.87195e-06
I0506 04:49:17.566431 12834 solver.cpp:362] Iteration 121000, Testing net (#0)
I0506 04:49:17.566442 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:17.695171 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7685
I0506 04:49:17.695190 12834 solver.cpp:429]     Test net output #1: loss = 0.52507 (* 1 = 0.52507 loss)
I0506 04:49:17.697764 12834 solver.cpp:242] Iteration 121000 (79.4903 iter/s, 1.25802s/100 iter), loss = 0.849452
I0506 04:49:17.697784 12834 solver.cpp:261]     Train net output #0: loss = 0.849452 (* 1 = 0.849452 loss)
I0506 04:49:17.697793 12834 sgd_solver.cpp:106] Iteration 121000, lr = 6.87195e-06
I0506 04:49:18.630759 12834 solver.cpp:242] Iteration 121100 (93.7977 iter/s, 1.06612s/100 iter), loss = 0.698685
I0506 04:49:18.630790 12834 solver.cpp:261]     Train net output #0: loss = 0.698685 (* 1 = 0.698685 loss)
I0506 04:49:18.630800 12834 sgd_solver.cpp:106] Iteration 121100, lr = 6.87195e-06
I0506 04:49:18.635512 12834 solver.cpp:242] Iteration 121100 (106.643 iter/s, 0.93771s/100 iter), loss = 0.652772
I0506 04:49:18.635535 12834 solver.cpp:261]     Train net output #0: loss = 0.652772 (* 1 = 0.652772 loss)
I0506 04:49:18.635545 12834 sgd_solver.cpp:106] Iteration 121100, lr = 6.87195e-06
I0506 04:49:19.567698 12834 solver.cpp:242] Iteration 121200 (106.738 iter/s, 0.936874s/100 iter), loss = 0.958125
I0506 04:49:19.567737 12834 solver.cpp:261]     Train net output #0: loss = 0.958125 (* 1 = 0.958125 loss)
I0506 04:49:19.567747 12834 sgd_solver.cpp:106] Iteration 121200, lr = 6.87195e-06
I0506 04:49:19.572461 12834 solver.cpp:242] Iteration 121200 (106.734 iter/s, 0.936907s/100 iter), loss = 0.456802
I0506 04:49:19.572486 12834 solver.cpp:261]     Train net output #0: loss = 0.456802 (* 1 = 0.456802 loss)
I0506 04:49:19.572494 12834 sgd_solver.cpp:106] Iteration 121200, lr = 6.87195e-06
I0506 04:49:20.505312 12834 solver.cpp:242] Iteration 121300 (106.661 iter/s, 0.937548s/100 iter), loss = 0.712458
I0506 04:49:20.505353 12834 solver.cpp:261]     Train net output #0: loss = 0.712458 (* 1 = 0.712458 loss)
I0506 04:49:20.505363 12834 sgd_solver.cpp:106] Iteration 121300, lr = 6.87195e-06
I0506 04:49:20.510099 12834 solver.cpp:242] Iteration 121300 (106.656 iter/s, 0.937595s/100 iter), loss = 0.846686
I0506 04:49:20.510124 12834 solver.cpp:261]     Train net output #0: loss = 0.846686 (* 1 = 0.846686 loss)
I0506 04:49:20.510134 12834 sgd_solver.cpp:106] Iteration 121300, lr = 6.87195e-06
I0506 04:49:21.442680 12834 solver.cpp:242] Iteration 121400 (106.69 iter/s, 0.937295s/100 iter), loss = 1.80935
I0506 04:49:21.442721 12834 solver.cpp:261]     Train net output #0: loss = 1.80935 (* 1 = 1.80935 loss)
I0506 04:49:21.442730 12834 sgd_solver.cpp:106] Iteration 121400, lr = 6.87195e-06
I0506 04:49:21.447458 12834 solver.cpp:242] Iteration 121400 (106.688 iter/s, 0.937314s/100 iter), loss = 0.513834
I0506 04:49:21.447482 12834 solver.cpp:261]     Train net output #0: loss = 0.513834 (* 1 = 0.513834 loss)
I0506 04:49:21.447491 12834 sgd_solver.cpp:106] Iteration 121400, lr = 6.87195e-06
I0506 04:49:22.377336 12834 solver.cpp:362] Iteration 121500, Testing net (#0)
I0506 04:49:22.377363 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:22.500185 12834 solver.cpp:429]     Test net output #0: loss = 1.2641 (* 1 = 1.2641 loss)
I0506 04:49:22.502701 12834 solver.cpp:242] Iteration 121500 (94.343 iter/s, 1.05996s/100 iter), loss = 0.987968
I0506 04:49:22.502727 12834 solver.cpp:261]     Train net output #0: loss = 0.987968 (* 1 = 0.987968 loss)
I0506 04:49:22.502743 12834 sgd_solver.cpp:106] Iteration 121500, lr = 6.87195e-06
I0506 04:49:22.504639 12834 solver.cpp:362] Iteration 121500, Testing net (#0)
I0506 04:49:22.504653 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:22.633278 12834 solver.cpp:429]     Test net output #0: accuracy = 0.766
I0506 04:49:22.633298 12834 solver.cpp:429]     Test net output #1: loss = 0.555276 (* 1 = 0.555276 loss)
I0506 04:49:22.635850 12834 solver.cpp:242] Iteration 121500 (84.1505 iter/s, 1.18835s/100 iter), loss = 0.861797
I0506 04:49:22.635870 12834 solver.cpp:261]     Train net output #0: loss = 0.861797 (* 1 = 0.861797 loss)
I0506 04:49:22.635879 12834 sgd_solver.cpp:106] Iteration 121500, lr = 6.87195e-06
I0506 04:49:23.569016 12834 solver.cpp:242] Iteration 121600 (93.7857 iter/s, 1.06626s/100 iter), loss = 1.25379
I0506 04:49:23.569057 12834 solver.cpp:261]     Train net output #0: loss = 1.25379 (* 1 = 1.25379 loss)
I0506 04:49:23.569067 12834 sgd_solver.cpp:106] Iteration 121600, lr = 6.87195e-06
I0506 04:49:23.573808 12834 solver.cpp:242] Iteration 121600 (106.619 iter/s, 0.937919s/100 iter), loss = 0.595968
I0506 04:49:23.573833 12834 solver.cpp:261]     Train net output #0: loss = 0.595968 (* 1 = 0.595968 loss)
I0506 04:49:23.573843 12834 sgd_solver.cpp:106] Iteration 121600, lr = 6.87195e-06
I0506 04:49:24.507063 12834 solver.cpp:242] Iteration 121700 (106.612 iter/s, 0.937982s/100 iter), loss = 0.213787
I0506 04:49:24.507102 12834 solver.cpp:261]     Train net output #0: loss = 0.213787 (* 1 = 0.213787 loss)
I0506 04:49:24.507112 12834 sgd_solver.cpp:106] Iteration 121700, lr = 6.87195e-06
I0506 04:49:24.511907 12834 solver.cpp:242] Iteration 121700 (106.605 iter/s, 0.938045s/100 iter), loss = 0.627951
I0506 04:49:24.511932 12834 solver.cpp:261]     Train net output #0: loss = 0.627951 (* 1 = 0.627951 loss)
I0506 04:49:24.511941 12834 sgd_solver.cpp:106] Iteration 121700, lr = 6.87195e-06
I0506 04:49:25.444589 12834 solver.cpp:242] Iteration 121800 (106.671 iter/s, 0.937459s/100 iter), loss = 4.38712
I0506 04:49:25.444628 12834 solver.cpp:261]     Train net output #0: loss = 4.38712 (* 1 = 4.38712 loss)
I0506 04:49:25.444638 12834 sgd_solver.cpp:106] Iteration 121800, lr = 6.87195e-06
I0506 04:49:25.449362 12834 solver.cpp:242] Iteration 121800 (106.677 iter/s, 0.937412s/100 iter), loss = 0.717976
I0506 04:49:25.449386 12834 solver.cpp:261]     Train net output #0: loss = 0.717976 (* 1 = 0.717976 loss)
I0506 04:49:25.449395 12834 sgd_solver.cpp:106] Iteration 121800, lr = 6.87195e-06
I0506 04:49:26.382315 12834 solver.cpp:242] Iteration 121900 (106.649 iter/s, 0.937654s/100 iter), loss = 0.919547
I0506 04:49:26.382354 12834 solver.cpp:261]     Train net output #0: loss = 0.919547 (* 1 = 0.919547 loss)
I0506 04:49:26.382362 12834 sgd_solver.cpp:106] Iteration 121900, lr = 6.87195e-06
I0506 04:49:26.387078 12834 solver.cpp:242] Iteration 121900 (106.647 iter/s, 0.937673s/100 iter), loss = 0.376223
I0506 04:49:26.387101 12834 solver.cpp:261]     Train net output #0: loss = 0.376223 (* 1 = 0.376223 loss)
I0506 04:49:26.387110 12834 sgd_solver.cpp:106] Iteration 121900, lr = 6.87195e-06
I0506 04:49:27.316581 12834 solver.cpp:362] Iteration 122000, Testing net (#0)
I0506 04:49:27.316606 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:27.439299 12834 solver.cpp:429]     Test net output #0: loss = 1.15743 (* 1 = 1.15743 loss)
I0506 04:49:27.441880 12834 solver.cpp:242] Iteration 122000 (94.3835 iter/s, 1.05951s/100 iter), loss = 1.54659
I0506 04:49:27.441905 12834 solver.cpp:261]     Train net output #0: loss = 1.54659 (* 1 = 1.54659 loss)
I0506 04:49:27.441913 12834 sgd_solver.cpp:106] Iteration 122000, lr = 6.87195e-06
I0506 04:49:27.443747 12834 solver.cpp:362] Iteration 122000, Testing net (#0)
I0506 04:49:27.443758 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:27.572363 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7785
I0506 04:49:27.572382 12834 solver.cpp:429]     Test net output #1: loss = 0.529114 (* 1 = 0.529114 loss)
I0506 04:49:27.574962 12834 solver.cpp:242] Iteration 122000 (84.1864 iter/s, 1.18784s/100 iter), loss = 0.535285
I0506 04:49:27.574985 12834 solver.cpp:261]     Train net output #0: loss = 0.535285 (* 1 = 0.535285 loss)
I0506 04:49:27.574993 12834 sgd_solver.cpp:106] Iteration 122000, lr = 6.87195e-06
I0506 04:49:28.507745 12834 solver.cpp:242] Iteration 122100 (93.8256 iter/s, 1.06581s/100 iter), loss = 1.01965
I0506 04:49:28.507781 12834 solver.cpp:261]     Train net output #0: loss = 1.01965 (* 1 = 1.01965 loss)
I0506 04:49:28.507791 12834 sgd_solver.cpp:106] Iteration 122100, lr = 6.87195e-06
I0506 04:49:28.512528 12834 solver.cpp:242] Iteration 122100 (106.664 iter/s, 0.937526s/100 iter), loss = 0.553511
I0506 04:49:28.512557 12834 solver.cpp:261]     Train net output #0: loss = 0.553511 (* 1 = 0.553511 loss)
I0506 04:49:28.512567 12834 sgd_solver.cpp:106] Iteration 122100, lr = 6.87195e-06
I0506 04:49:29.444798 12834 solver.cpp:242] Iteration 122200 (106.724 iter/s, 0.936993s/100 iter), loss = 1.49677
I0506 04:49:29.444833 12834 solver.cpp:261]     Train net output #0: loss = 1.49677 (* 1 = 1.49677 loss)
I0506 04:49:29.444842 12834 sgd_solver.cpp:106] Iteration 122200, lr = 6.87195e-06
I0506 04:49:29.449575 12834 solver.cpp:242] Iteration 122200 (106.723 iter/s, 0.937004s/100 iter), loss = 0.355095
I0506 04:49:29.449599 12834 solver.cpp:261]     Train net output #0: loss = 0.355095 (* 1 = 0.355095 loss)
I0506 04:49:29.449607 12834 sgd_solver.cpp:106] Iteration 122200, lr = 6.87195e-06
I0506 04:49:30.393647 12834 solver.cpp:242] Iteration 122300 (105.398 iter/s, 0.948782s/100 iter), loss = 0.77905
I0506 04:49:30.393690 12834 solver.cpp:261]     Train net output #0: loss = 0.77905 (* 1 = 0.77905 loss)
I0506 04:49:30.393699 12834 sgd_solver.cpp:106] Iteration 122300, lr = 6.87195e-06
I0506 04:49:30.398432 12834 solver.cpp:242] Iteration 122300 (105.394 iter/s, 0.948817s/100 iter), loss = 0.503574
I0506 04:49:30.398458 12834 solver.cpp:261]     Train net output #0: loss = 0.503574 (* 1 = 0.503574 loss)
I0506 04:49:30.398468 12834 sgd_solver.cpp:106] Iteration 122300, lr = 6.87195e-06
I0506 04:49:31.331037 12834 solver.cpp:242] Iteration 122400 (106.687 iter/s, 0.937322s/100 iter), loss = 0.645044
I0506 04:49:31.331079 12834 solver.cpp:261]     Train net output #0: loss = 0.645044 (* 1 = 0.645044 loss)
I0506 04:49:31.331089 12834 sgd_solver.cpp:106] Iteration 122400, lr = 6.87195e-06
I0506 04:49:31.335875 12834 solver.cpp:242] Iteration 122400 (106.68 iter/s, 0.937387s/100 iter), loss = 0.634555
I0506 04:49:31.335899 12834 solver.cpp:261]     Train net output #0: loss = 0.634555 (* 1 = 0.634555 loss)
I0506 04:49:31.335908 12834 sgd_solver.cpp:106] Iteration 122400, lr = 6.87195e-06
I0506 04:49:32.266036 12834 solver.cpp:362] Iteration 122500, Testing net (#0)
I0506 04:49:32.266063 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:32.388659 12834 solver.cpp:429]     Test net output #0: loss = 1.17883 (* 1 = 1.17883 loss)
I0506 04:49:32.391194 12834 solver.cpp:242] Iteration 122500 (94.331 iter/s, 1.0601s/100 iter), loss = 3.09982
I0506 04:49:32.391214 12834 solver.cpp:261]     Train net output #0: loss = 3.09982 (* 1 = 3.09982 loss)
I0506 04:49:32.391223 12834 sgd_solver.cpp:106] Iteration 122500, lr = 6.87195e-06
I0506 04:49:32.393064 12834 solver.cpp:362] Iteration 122500, Testing net (#0)
I0506 04:49:32.393079 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:32.521828 12834 solver.cpp:429]     Test net output #0: accuracy = 0.795
I0506 04:49:32.521848 12834 solver.cpp:429]     Test net output #1: loss = 0.472895 (* 1 = 0.472895 loss)
I0506 04:49:32.524389 12834 solver.cpp:242] Iteration 122500 (84.142 iter/s, 1.18847s/100 iter), loss = 0.573806
I0506 04:49:32.524410 12834 solver.cpp:261]     Train net output #0: loss = 0.573806 (* 1 = 0.573806 loss)
I0506 04:49:32.524417 12834 sgd_solver.cpp:106] Iteration 122500, lr = 6.87195e-06
I0506 04:49:33.457209 12834 solver.cpp:242] Iteration 122600 (93.8116 iter/s, 1.06597s/100 iter), loss = 1.45496
I0506 04:49:33.457252 12834 solver.cpp:261]     Train net output #0: loss = 1.45496 (* 1 = 1.45496 loss)
I0506 04:49:33.457270 12834 sgd_solver.cpp:106] Iteration 122600, lr = 6.87195e-06
I0506 04:49:33.462079 12834 solver.cpp:242] Iteration 122600 (106.651 iter/s, 0.937642s/100 iter), loss = 0.702195
I0506 04:49:33.462102 12834 solver.cpp:261]     Train net output #0: loss = 0.702195 (* 1 = 0.702195 loss)
I0506 04:49:33.462111 12834 sgd_solver.cpp:106] Iteration 122600, lr = 6.87195e-06
I0506 04:49:34.395402 12834 solver.cpp:242] Iteration 122700 (106.596 iter/s, 0.938123s/100 iter), loss = 0.397911
I0506 04:49:34.395440 12834 solver.cpp:261]     Train net output #0: loss = 0.397911 (* 1 = 0.397911 loss)
I0506 04:49:34.395450 12834 sgd_solver.cpp:106] Iteration 122700, lr = 6.87195e-06
I0506 04:49:34.400178 12834 solver.cpp:242] Iteration 122700 (106.603 iter/s, 0.938058s/100 iter), loss = 0.47438
I0506 04:49:34.400202 12834 solver.cpp:261]     Train net output #0: loss = 0.47438 (* 1 = 0.47438 loss)
I0506 04:49:34.400212 12834 sgd_solver.cpp:106] Iteration 122700, lr = 6.87195e-06
I0506 04:49:35.411139 12834 solver.cpp:242] Iteration 122800 (98.4582 iter/s, 1.01566s/100 iter), loss = 2.98685
I0506 04:49:35.411183 12834 solver.cpp:261]     Train net output #0: loss = 2.98685 (* 1 = 2.98685 loss)
I0506 04:49:35.411195 12834 sgd_solver.cpp:106] Iteration 122800, lr = 6.87195e-06
I0506 04:49:35.416445 12834 solver.cpp:242] Iteration 122800 (98.4037 iter/s, 1.01622s/100 iter), loss = 0.442945
I0506 04:49:35.416473 12834 solver.cpp:261]     Train net output #0: loss = 0.442945 (* 1 = 0.442945 loss)
I0506 04:49:35.416484 12834 sgd_solver.cpp:106] Iteration 122800, lr = 6.87195e-06
I0506 04:49:36.447329 12834 solver.cpp:242] Iteration 122900 (96.5142 iter/s, 1.03612s/100 iter), loss = 1.05818
I0506 04:49:36.447376 12834 solver.cpp:261]     Train net output #0: loss = 1.05818 (* 1 = 1.05818 loss)
I0506 04:49:36.447386 12834 sgd_solver.cpp:106] Iteration 122900, lr = 6.87195e-06
I0506 04:49:36.452627 12834 solver.cpp:242] Iteration 122900 (96.5127 iter/s, 1.03613s/100 iter), loss = 0.642282
I0506 04:49:36.452656 12834 solver.cpp:261]     Train net output #0: loss = 0.642282 (* 1 = 0.642282 loss)
I0506 04:49:36.452667 12834 sgd_solver.cpp:106] Iteration 122900, lr = 6.87195e-06
I0506 04:49:37.480525 12834 solver.cpp:362] Iteration 123000, Testing net (#0)
I0506 04:49:37.480583 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:37.603230 12834 solver.cpp:429]     Test net output #0: loss = 1.26241 (* 1 = 1.26241 loss)
I0506 04:49:37.605749 12834 solver.cpp:242] Iteration 123000 (86.3293 iter/s, 1.15836s/100 iter), loss = 2.22241
I0506 04:49:37.605769 12834 solver.cpp:261]     Train net output #0: loss = 2.22241 (* 1 = 2.22241 loss)
I0506 04:49:37.605778 12834 sgd_solver.cpp:106] Iteration 123000, lr = 6.87195e-06
I0506 04:49:37.607620 12834 solver.cpp:362] Iteration 123000, Testing net (#0)
I0506 04:49:37.607635 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:37.736405 12834 solver.cpp:429]     Test net output #0: accuracy = 0.764
I0506 04:49:37.736426 12834 solver.cpp:429]     Test net output #1: loss = 0.523061 (* 1 = 0.523061 loss)
I0506 04:49:37.738991 12834 solver.cpp:242] Iteration 123000 (77.7416 iter/s, 1.28631s/100 iter), loss = 0.748227
I0506 04:49:37.739011 12834 solver.cpp:261]     Train net output #0: loss = 0.748227 (* 1 = 0.748227 loss)
I0506 04:49:37.739019 12834 sgd_solver.cpp:106] Iteration 123000, lr = 6.87195e-06
I0506 04:49:38.671665 12834 solver.cpp:242] Iteration 123100 (93.8203 iter/s, 1.06587s/100 iter), loss = 1.16365
I0506 04:49:38.671707 12834 solver.cpp:261]     Train net output #0: loss = 1.16365 (* 1 = 1.16365 loss)
I0506 04:49:38.671716 12834 sgd_solver.cpp:106] Iteration 123100, lr = 6.87195e-06
I0506 04:49:38.676447 12834 solver.cpp:242] Iteration 123100 (106.676 iter/s, 0.937419s/100 iter), loss = 0.383075
I0506 04:49:38.676473 12834 solver.cpp:261]     Train net output #0: loss = 0.383075 (* 1 = 0.383075 loss)
I0506 04:49:38.676482 12834 sgd_solver.cpp:106] Iteration 123100, lr = 6.87195e-06
I0506 04:49:39.609311 12834 solver.cpp:242] Iteration 123200 (106.659 iter/s, 0.937572s/100 iter), loss = 1.1918
I0506 04:49:39.609364 12834 solver.cpp:261]     Train net output #0: loss = 1.1918 (* 1 = 1.1918 loss)
I0506 04:49:39.609375 12834 sgd_solver.cpp:106] Iteration 123200, lr = 6.87195e-06
I0506 04:49:39.614147 12834 solver.cpp:242] Iteration 123200 (106.649 iter/s, 0.937656s/100 iter), loss = 0.522218
I0506 04:49:39.614171 12834 solver.cpp:261]     Train net output #0: loss = 0.522218 (* 1 = 0.522218 loss)
I0506 04:49:39.614181 12834 sgd_solver.cpp:106] Iteration 123200, lr = 6.87195e-06
I0506 04:49:40.547721 12834 solver.cpp:242] Iteration 123300 (106.572 iter/s, 0.938332s/100 iter), loss = 1.49347
I0506 04:49:40.547760 12834 solver.cpp:261]     Train net output #0: loss = 1.49347 (* 1 = 1.49347 loss)
I0506 04:49:40.547768 12834 sgd_solver.cpp:106] Iteration 123300, lr = 6.87195e-06
I0506 04:49:40.552534 12834 solver.cpp:242] Iteration 123300 (106.571 iter/s, 0.938344s/100 iter), loss = 0.79635
I0506 04:49:40.552577 12834 solver.cpp:261]     Train net output #0: loss = 0.79635 (* 1 = 0.79635 loss)
I0506 04:49:40.552587 12834 sgd_solver.cpp:106] Iteration 123300, lr = 6.87195e-06
I0506 04:49:41.487555 12834 solver.cpp:242] Iteration 123400 (106.41 iter/s, 0.939765s/100 iter), loss = 1.14832
I0506 04:49:41.487591 12834 solver.cpp:261]     Train net output #0: loss = 1.14832 (* 1 = 1.14832 loss)
I0506 04:49:41.487601 12834 sgd_solver.cpp:106] Iteration 123400, lr = 6.87195e-06
I0506 04:49:41.492348 12834 solver.cpp:242] Iteration 123400 (106.411 iter/s, 0.939755s/100 iter), loss = 0.318298
I0506 04:49:41.492373 12834 solver.cpp:261]     Train net output #0: loss = 0.318298 (* 1 = 0.318298 loss)
I0506 04:49:41.492383 12834 sgd_solver.cpp:106] Iteration 123400, lr = 6.87195e-06
I0506 04:49:42.422439 12834 solver.cpp:362] Iteration 123500, Testing net (#0)
I0506 04:49:42.422463 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:42.545143 12834 solver.cpp:429]     Test net output #0: loss = 1.34912 (* 1 = 1.34912 loss)
I0506 04:49:42.547739 12834 solver.cpp:242] Iteration 123500 (94.3282 iter/s, 1.06013s/100 iter), loss = 0.372209
I0506 04:49:42.547765 12834 solver.cpp:261]     Train net output #0: loss = 0.372209 (* 1 = 0.372209 loss)
I0506 04:49:42.547773 12834 sgd_solver.cpp:106] Iteration 123500, lr = 6.87195e-06
I0506 04:49:42.549690 12834 solver.cpp:362] Iteration 123500, Testing net (#0)
I0506 04:49:42.549703 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:42.678295 12834 solver.cpp:429]     Test net output #0: accuracy = 0.763
I0506 04:49:42.678315 12834 solver.cpp:429]     Test net output #1: loss = 0.546138 (* 1 = 0.546138 loss)
I0506 04:49:42.680877 12834 solver.cpp:242] Iteration 123500 (84.1408 iter/s, 1.18848s/100 iter), loss = 0.494952
I0506 04:49:42.680898 12834 solver.cpp:261]     Train net output #0: loss = 0.494952 (* 1 = 0.494952 loss)
I0506 04:49:42.680907 12834 sgd_solver.cpp:106] Iteration 123500, lr = 6.87195e-06
I0506 04:49:43.614109 12834 solver.cpp:242] Iteration 123600 (93.7808 iter/s, 1.06632s/100 iter), loss = 1.46684
I0506 04:49:43.614147 12834 solver.cpp:261]     Train net output #0: loss = 1.46684 (* 1 = 1.46684 loss)
I0506 04:49:43.614156 12834 sgd_solver.cpp:106] Iteration 123600, lr = 6.87195e-06
I0506 04:49:43.618886 12834 solver.cpp:242] Iteration 123600 (106.613 iter/s, 0.937969s/100 iter), loss = 1.15639
I0506 04:49:43.618911 12834 solver.cpp:261]     Train net output #0: loss = 1.15639 (* 1 = 1.15639 loss)
I0506 04:49:43.618919 12834 sgd_solver.cpp:106] Iteration 123600, lr = 6.87195e-06
I0506 04:49:44.552594 12834 solver.cpp:242] Iteration 123700 (106.562 iter/s, 0.938417s/100 iter), loss = 1.63808
I0506 04:49:44.552630 12834 solver.cpp:261]     Train net output #0: loss = 1.63808 (* 1 = 1.63808 loss)
I0506 04:49:44.552640 12834 sgd_solver.cpp:106] Iteration 123700, lr = 6.87195e-06
I0506 04:49:44.557374 12834 solver.cpp:242] Iteration 123700 (106.559 iter/s, 0.938444s/100 iter), loss = 0.586487
I0506 04:49:44.557396 12834 solver.cpp:261]     Train net output #0: loss = 0.586487 (* 1 = 0.586487 loss)
I0506 04:49:44.557415 12834 sgd_solver.cpp:106] Iteration 123700, lr = 6.87195e-06
I0506 04:49:45.490015 12834 solver.cpp:242] Iteration 123800 (106.683 iter/s, 0.937358s/100 iter), loss = 1.09052
I0506 04:49:45.490056 12834 solver.cpp:261]     Train net output #0: loss = 1.09052 (* 1 = 1.09052 loss)
I0506 04:49:45.490066 12834 sgd_solver.cpp:106] Iteration 123800, lr = 6.87195e-06
I0506 04:49:45.494813 12834 solver.cpp:242] Iteration 123800 (106.678 iter/s, 0.937398s/100 iter), loss = 0.440435
I0506 04:49:45.494839 12834 solver.cpp:261]     Train net output #0: loss = 0.440435 (* 1 = 0.440435 loss)
I0506 04:49:45.494848 12834 sgd_solver.cpp:106] Iteration 123800, lr = 6.87195e-06
I0506 04:49:46.427425 12834 solver.cpp:242] Iteration 123900 (106.685 iter/s, 0.937336s/100 iter), loss = 0.844963
I0506 04:49:46.427467 12834 solver.cpp:261]     Train net output #0: loss = 0.844963 (* 1 = 0.844963 loss)
I0506 04:49:46.427487 12834 sgd_solver.cpp:106] Iteration 123900, lr = 6.87195e-06
I0506 04:49:46.432229 12834 solver.cpp:242] Iteration 123900 (106.681 iter/s, 0.937371s/100 iter), loss = 0.756147
I0506 04:49:46.432255 12834 solver.cpp:261]     Train net output #0: loss = 0.756147 (* 1 = 0.756147 loss)
I0506 04:49:46.432263 12834 sgd_solver.cpp:106] Iteration 123900, lr = 6.87195e-06
I0506 04:49:47.444531 12834 solver.cpp:362] Iteration 124000, Testing net (#0)
I0506 04:49:47.444567 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:47.577669 12834 solver.cpp:429]     Test net output #0: loss = 1.08554 (* 1 = 1.08554 loss)
I0506 04:49:47.580188 12834 solver.cpp:242] Iteration 124000 (86.7528 iter/s, 1.1527s/100 iter), loss = 0.535067
I0506 04:49:47.580210 12834 solver.cpp:261]     Train net output #0: loss = 0.535067 (* 1 = 0.535067 loss)
I0506 04:49:47.580219 12834 sgd_solver.cpp:106] Iteration 124000, lr = 6.87195e-06
I0506 04:49:47.582052 12834 solver.cpp:362] Iteration 124000, Testing net (#0)
I0506 04:49:47.582065 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:47.710654 12834 solver.cpp:429]     Test net output #0: accuracy = 0.774
I0506 04:49:47.710674 12834 solver.cpp:429]     Test net output #1: loss = 0.527676 (* 1 = 0.527676 loss)
I0506 04:49:47.713223 12834 solver.cpp:242] Iteration 124000 (78.0672 iter/s, 1.28095s/100 iter), loss = 0.62255
I0506 04:49:47.713245 12834 solver.cpp:261]     Train net output #0: loss = 0.62255 (* 1 = 0.62255 loss)
I0506 04:49:47.713254 12834 sgd_solver.cpp:106] Iteration 124000, lr = 6.87195e-06
I0506 04:49:48.646410 12834 solver.cpp:242] Iteration 124100 (93.7939 iter/s, 1.06617s/100 iter), loss = 0.507696
I0506 04:49:48.646441 12834 solver.cpp:261]     Train net output #0: loss = 0.507696 (* 1 = 0.507696 loss)
I0506 04:49:48.646451 12834 sgd_solver.cpp:106] Iteration 124100, lr = 6.87195e-06
I0506 04:49:48.651170 12834 solver.cpp:242] Iteration 124100 (106.621 iter/s, 0.937905s/100 iter), loss = 0.479112
I0506 04:49:48.651192 12834 solver.cpp:261]     Train net output #0: loss = 0.479112 (* 1 = 0.479112 loss)
I0506 04:49:48.651201 12834 sgd_solver.cpp:106] Iteration 124100, lr = 6.87195e-06
I0506 04:49:49.584326 12834 solver.cpp:242] Iteration 124200 (106.626 iter/s, 0.937859s/100 iter), loss = 2.24161
I0506 04:49:49.584367 12834 solver.cpp:261]     Train net output #0: loss = 2.24161 (* 1 = 2.24161 loss)
I0506 04:49:49.584375 12834 sgd_solver.cpp:106] Iteration 124200, lr = 6.87195e-06
I0506 04:49:49.589097 12834 solver.cpp:242] Iteration 124200 (106.623 iter/s, 0.937887s/100 iter), loss = 0.500252
I0506 04:49:49.589121 12834 solver.cpp:261]     Train net output #0: loss = 0.500252 (* 1 = 0.500252 loss)
I0506 04:49:49.589131 12834 sgd_solver.cpp:106] Iteration 124200, lr = 6.87195e-06
I0506 04:49:50.522047 12834 solver.cpp:242] Iteration 124300 (106.65 iter/s, 0.93765s/100 iter), loss = 1.22691
I0506 04:49:50.522088 12834 solver.cpp:261]     Train net output #0: loss = 1.22691 (* 1 = 1.22691 loss)
I0506 04:49:50.522096 12834 sgd_solver.cpp:106] Iteration 124300, lr = 6.87195e-06
I0506 04:49:50.526816 12834 solver.cpp:242] Iteration 124300 (106.647 iter/s, 0.937677s/100 iter), loss = 0.818426
I0506 04:49:50.526850 12834 solver.cpp:261]     Train net output #0: loss = 0.818426 (* 1 = 0.818426 loss)
I0506 04:49:50.526860 12834 sgd_solver.cpp:106] Iteration 124300, lr = 6.87195e-06
I0506 04:49:51.473340 12834 solver.cpp:242] Iteration 124400 (105.127 iter/s, 0.951229s/100 iter), loss = 1.39258
I0506 04:49:51.473378 12834 solver.cpp:261]     Train net output #0: loss = 1.39258 (* 1 = 1.39258 loss)
I0506 04:49:51.473387 12834 sgd_solver.cpp:106] Iteration 124400, lr = 6.87195e-06
I0506 04:49:51.478241 12834 solver.cpp:242] Iteration 124400 (105.112 iter/s, 0.951363s/100 iter), loss = 0.521649
I0506 04:49:51.478266 12834 solver.cpp:261]     Train net output #0: loss = 0.521649 (* 1 = 0.521649 loss)
I0506 04:49:51.478276 12834 sgd_solver.cpp:106] Iteration 124400, lr = 6.87195e-06
I0506 04:49:52.408319 12834 solver.cpp:362] Iteration 124500, Testing net (#0)
I0506 04:49:52.408345 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:52.531227 12834 solver.cpp:429]     Test net output #0: loss = 1.24347 (* 1 = 1.24347 loss)
I0506 04:49:52.533752 12834 solver.cpp:242] Iteration 124500 (94.308 iter/s, 1.06036s/100 iter), loss = 0.772924
I0506 04:49:52.533773 12834 solver.cpp:261]     Train net output #0: loss = 0.772924 (* 1 = 0.772924 loss)
I0506 04:49:52.533782 12834 sgd_solver.cpp:106] Iteration 124500, lr = 6.87195e-06
I0506 04:49:52.535601 12834 solver.cpp:362] Iteration 124500, Testing net (#0)
I0506 04:49:52.535614 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:52.664366 12834 solver.cpp:429]     Test net output #0: accuracy = 0.743
I0506 04:49:52.664391 12834 solver.cpp:429]     Test net output #1: loss = 0.576239 (* 1 = 0.576239 loss)
I0506 04:49:52.667011 12834 solver.cpp:242] Iteration 124500 (84.1238 iter/s, 1.18872s/100 iter), loss = 0.48142
I0506 04:49:52.667033 12834 solver.cpp:261]     Train net output #0: loss = 0.48142 (* 1 = 0.48142 loss)
I0506 04:49:52.667042 12834 sgd_solver.cpp:106] Iteration 124500, lr = 6.87195e-06
I0506 04:49:53.600293 12834 solver.cpp:242] Iteration 124600 (93.7661 iter/s, 1.06648s/100 iter), loss = 0.82764
I0506 04:49:53.600335 12834 solver.cpp:261]     Train net output #0: loss = 0.82764 (* 1 = 0.82764 loss)
I0506 04:49:53.600344 12834 sgd_solver.cpp:106] Iteration 124600, lr = 6.87195e-06
I0506 04:49:53.605093 12834 solver.cpp:242] Iteration 124600 (106.605 iter/s, 0.938041s/100 iter), loss = 0.473587
I0506 04:49:53.605118 12834 solver.cpp:261]     Train net output #0: loss = 0.473587 (* 1 = 0.473587 loss)
I0506 04:49:53.605128 12834 sgd_solver.cpp:106] Iteration 124600, lr = 6.87195e-06
I0506 04:49:54.537888 12834 solver.cpp:242] Iteration 124700 (106.664 iter/s, 0.937526s/100 iter), loss = 3.25402
I0506 04:49:54.537927 12834 solver.cpp:261]     Train net output #0: loss = 3.25402 (* 1 = 3.25402 loss)
I0506 04:49:54.537937 12834 sgd_solver.cpp:106] Iteration 124700, lr = 6.87195e-06
I0506 04:49:54.542656 12834 solver.cpp:242] Iteration 124700 (106.664 iter/s, 0.93752s/100 iter), loss = 0.346678
I0506 04:49:54.542681 12834 solver.cpp:261]     Train net output #0: loss = 0.346678 (* 1 = 0.346678 loss)
I0506 04:49:54.542690 12834 sgd_solver.cpp:106] Iteration 124700, lr = 6.87195e-06
I0506 04:49:55.475793 12834 solver.cpp:242] Iteration 124800 (106.629 iter/s, 0.937836s/100 iter), loss = 1.21523
I0506 04:49:55.475829 12834 solver.cpp:261]     Train net output #0: loss = 1.21523 (* 1 = 1.21523 loss)
I0506 04:49:55.475838 12834 sgd_solver.cpp:106] Iteration 124800, lr = 6.87195e-06
I0506 04:49:55.480587 12834 solver.cpp:242] Iteration 124800 (106.622 iter/s, 0.937889s/100 iter), loss = 0.570174
I0506 04:49:55.480612 12834 solver.cpp:261]     Train net output #0: loss = 0.570174 (* 1 = 0.570174 loss)
I0506 04:49:55.480620 12834 sgd_solver.cpp:106] Iteration 124800, lr = 6.87195e-06
I0506 04:49:56.413558 12834 solver.cpp:242] Iteration 124900 (106.643 iter/s, 0.937705s/100 iter), loss = 2.19884
I0506 04:49:56.413594 12834 solver.cpp:261]     Train net output #0: loss = 2.19884 (* 1 = 2.19884 loss)
I0506 04:49:56.413612 12834 sgd_solver.cpp:106] Iteration 124900, lr = 6.87195e-06
I0506 04:49:56.418331 12834 solver.cpp:242] Iteration 124900 (106.644 iter/s, 0.937701s/100 iter), loss = 0.492732
I0506 04:49:56.418356 12834 solver.cpp:261]     Train net output #0: loss = 0.492732 (* 1 = 0.492732 loss)
I0506 04:49:56.418365 12834 sgd_solver.cpp:106] Iteration 124900, lr = 6.87195e-06
I0506 04:49:57.348816 12834 solver.cpp:362] Iteration 125000, Testing net (#0)
I0506 04:49:57.348836 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:57.471601 12834 solver.cpp:429]     Test net output #0: loss = 1.29813 (* 1 = 1.29813 loss)
I0506 04:49:57.474128 12834 solver.cpp:242] Iteration 125000 (94.2937 iter/s, 1.06052s/100 iter), loss = 0.353247
I0506 04:49:57.474151 12834 solver.cpp:261]     Train net output #0: loss = 0.353247 (* 1 = 0.353247 loss)
I0506 04:49:57.474160 12834 sgd_solver.cpp:106] Iteration 125000, lr = 6.87195e-06
I0506 04:49:57.475968 12834 solver.cpp:362] Iteration 125000, Testing net (#0)
I0506 04:49:57.475980 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:49:57.604966 12834 solver.cpp:429]     Test net output #0: accuracy = 0.767
I0506 04:49:57.604990 12834 solver.cpp:429]     Test net output #1: loss = 0.533454 (* 1 = 0.533454 loss)
I0506 04:49:57.607554 12834 solver.cpp:242] Iteration 125000 (84.0919 iter/s, 1.18918s/100 iter), loss = 0.63519
I0506 04:49:57.607576 12834 solver.cpp:261]     Train net output #0: loss = 0.63519 (* 1 = 0.63519 loss)
I0506 04:49:57.607585 12834 sgd_solver.cpp:106] Iteration 125000, lr = 6.87195e-06
I0506 04:49:58.541090 12834 solver.cpp:242] Iteration 125100 (93.7285 iter/s, 1.06691s/100 iter), loss = 1.70573
I0506 04:49:58.541128 12834 solver.cpp:261]     Train net output #0: loss = 1.70573 (* 1 = 1.70573 loss)
I0506 04:49:58.541137 12834 sgd_solver.cpp:106] Iteration 125100, lr = 6.87195e-06
I0506 04:49:58.545851 12834 solver.cpp:242] Iteration 125100 (106.581 iter/s, 0.938255s/100 iter), loss = 0.677876
I0506 04:49:58.545876 12834 solver.cpp:261]     Train net output #0: loss = 0.677876 (* 1 = 0.677876 loss)
I0506 04:49:58.545884 12834 sgd_solver.cpp:106] Iteration 125100, lr = 6.87195e-06
I0506 04:49:59.478811 12834 solver.cpp:242] Iteration 125200 (106.649 iter/s, 0.937652s/100 iter), loss = 0.792424
I0506 04:49:59.478844 12834 solver.cpp:261]     Train net output #0: loss = 0.792424 (* 1 = 0.792424 loss)
I0506 04:49:59.478853 12834 sgd_solver.cpp:106] Iteration 125200, lr = 6.87195e-06
I0506 04:49:59.483592 12834 solver.cpp:242] Iteration 125200 (106.644 iter/s, 0.937699s/100 iter), loss = 0.60205
I0506 04:49:59.483615 12834 solver.cpp:261]     Train net output #0: loss = 0.60205 (* 1 = 0.60205 loss)
I0506 04:49:59.483624 12834 sgd_solver.cpp:106] Iteration 125200, lr = 6.87195e-06
I0506 04:50:00.421993 12834 solver.cpp:242] Iteration 125300 (106.031 iter/s, 0.943122s/100 iter), loss = 0.789687
I0506 04:50:00.422029 12834 solver.cpp:261]     Train net output #0: loss = 0.789687 (* 1 = 0.789687 loss)
I0506 04:50:00.422039 12834 sgd_solver.cpp:106] Iteration 125300, lr = 6.87195e-06
I0506 04:50:00.426869 12834 solver.cpp:242] Iteration 125300 (106.019 iter/s, 0.943224s/100 iter), loss = 0.584293
I0506 04:50:00.426895 12834 solver.cpp:261]     Train net output #0: loss = 0.584293 (* 1 = 0.584293 loss)
I0506 04:50:00.426904 12834 sgd_solver.cpp:106] Iteration 125300, lr = 6.87195e-06
I0506 04:50:01.366608 12834 solver.cpp:242] Iteration 125400 (105.87 iter/s, 0.944551s/100 iter), loss = 1.54679
I0506 04:50:01.366649 12834 solver.cpp:261]     Train net output #0: loss = 1.54679 (* 1 = 1.54679 loss)
I0506 04:50:01.366659 12834 sgd_solver.cpp:106] Iteration 125400, lr = 6.87195e-06
I0506 04:50:01.371429 12834 solver.cpp:242] Iteration 125400 (105.874 iter/s, 0.944516s/100 iter), loss = 0.933627
I0506 04:50:01.371454 12834 solver.cpp:261]     Train net output #0: loss = 0.933627 (* 1 = 0.933627 loss)
I0506 04:50:01.371464 12834 sgd_solver.cpp:106] Iteration 125400, lr = 6.87195e-06
I0506 04:50:02.304620 12834 solver.cpp:362] Iteration 125500, Testing net (#0)
I0506 04:50:02.304656 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:02.427448 12834 solver.cpp:429]     Test net output #0: loss = 1.26818 (* 1 = 1.26818 loss)
I0506 04:50:02.429972 12834 solver.cpp:242] Iteration 125500 (94.0465 iter/s, 1.0633s/100 iter), loss = 1.09934
I0506 04:50:02.429993 12834 solver.cpp:261]     Train net output #0: loss = 1.09934 (* 1 = 1.09934 loss)
I0506 04:50:02.430002 12834 sgd_solver.cpp:106] Iteration 125500, lr = 6.87195e-06
I0506 04:50:02.431826 12834 solver.cpp:362] Iteration 125500, Testing net (#0)
I0506 04:50:02.431841 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:02.560431 12834 solver.cpp:429]     Test net output #0: accuracy = 0.767
I0506 04:50:02.560452 12834 solver.cpp:429]     Test net output #1: loss = 0.53377 (* 1 = 0.53377 loss)
I0506 04:50:02.563016 12834 solver.cpp:242] Iteration 125500 (83.9249 iter/s, 1.19154s/100 iter), loss = 0.667087
I0506 04:50:02.563037 12834 solver.cpp:261]     Train net output #0: loss = 0.667087 (* 1 = 0.667087 loss)
I0506 04:50:02.563046 12834 sgd_solver.cpp:106] Iteration 125500, lr = 6.87195e-06
I0506 04:50:03.509776 12834 solver.cpp:242] Iteration 125600 (92.6137 iter/s, 1.07975s/100 iter), loss = 1.3098
I0506 04:50:03.509824 12834 solver.cpp:261]     Train net output #0: loss = 1.3098 (* 1 = 1.3098 loss)
I0506 04:50:03.509891 12834 sgd_solver.cpp:106] Iteration 125600, lr = 6.87195e-06
I0506 04:50:03.514700 12834 solver.cpp:242] Iteration 125600 (105.081 iter/s, 0.951645s/100 iter), loss = 0.964097
I0506 04:50:03.514724 12834 solver.cpp:261]     Train net output #0: loss = 0.964097 (* 1 = 0.964097 loss)
I0506 04:50:03.514734 12834 sgd_solver.cpp:106] Iteration 125600, lr = 6.87195e-06
I0506 04:50:04.447525 12834 solver.cpp:242] Iteration 125700 (106.647 iter/s, 0.937672s/100 iter), loss = 0.960389
I0506 04:50:04.447566 12834 solver.cpp:261]     Train net output #0: loss = 0.960389 (* 1 = 0.960389 loss)
I0506 04:50:04.447576 12834 sgd_solver.cpp:106] Iteration 125700, lr = 6.87195e-06
I0506 04:50:04.452330 12834 solver.cpp:242] Iteration 125700 (106.657 iter/s, 0.937588s/100 iter), loss = 0.600851
I0506 04:50:04.452355 12834 solver.cpp:261]     Train net output #0: loss = 0.600851 (* 1 = 0.600851 loss)
I0506 04:50:04.452364 12834 sgd_solver.cpp:106] Iteration 125700, lr = 6.87195e-06
I0506 04:50:05.385129 12834 solver.cpp:242] Iteration 125800 (106.663 iter/s, 0.937535s/100 iter), loss = 1.24748
I0506 04:50:05.385169 12834 solver.cpp:261]     Train net output #0: loss = 1.24748 (* 1 = 1.24748 loss)
I0506 04:50:05.385179 12834 sgd_solver.cpp:106] Iteration 125800, lr = 6.87195e-06
I0506 04:50:05.389910 12834 solver.cpp:242] Iteration 125800 (106.663 iter/s, 0.937537s/100 iter), loss = 0.533435
I0506 04:50:05.389935 12834 solver.cpp:261]     Train net output #0: loss = 0.533435 (* 1 = 0.533435 loss)
I0506 04:50:05.389945 12834 sgd_solver.cpp:106] Iteration 125800, lr = 6.87195e-06
I0506 04:50:06.323668 12834 solver.cpp:242] Iteration 125900 (106.557 iter/s, 0.938465s/100 iter), loss = 0.598662
I0506 04:50:06.323704 12834 solver.cpp:261]     Train net output #0: loss = 0.598662 (* 1 = 0.598662 loss)
I0506 04:50:06.323714 12834 sgd_solver.cpp:106] Iteration 125900, lr = 6.87195e-06
I0506 04:50:06.328438 12834 solver.cpp:242] Iteration 125900 (106.555 iter/s, 0.938484s/100 iter), loss = 0.377332
I0506 04:50:06.328462 12834 solver.cpp:261]     Train net output #0: loss = 0.377332 (* 1 = 0.377332 loss)
I0506 04:50:06.328471 12834 sgd_solver.cpp:106] Iteration 125900, lr = 6.87195e-06
I0506 04:50:07.330221 12834 solver.cpp:362] Iteration 126000, Testing net (#0)
I0506 04:50:07.330250 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:07.453769 12834 solver.cpp:429]     Test net output #0: loss = 1.26282 (* 1 = 1.26282 loss)
I0506 04:50:07.456281 12834 solver.cpp:242] Iteration 126000 (88.2957 iter/s, 1.13256s/100 iter), loss = 0.259707
I0506 04:50:07.456301 12834 solver.cpp:261]     Train net output #0: loss = 0.259707 (* 1 = 0.259707 loss)
I0506 04:50:07.456310 12834 sgd_solver.cpp:106] Iteration 126000, lr = 6.87195e-06
I0506 04:50:07.458148 12834 solver.cpp:362] Iteration 126000, Testing net (#0)
I0506 04:50:07.458163 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:07.586800 12834 solver.cpp:429]     Test net output #0: accuracy = 0.787
I0506 04:50:07.586820 12834 solver.cpp:429]     Test net output #1: loss = 0.498349 (* 1 = 0.498349 loss)
I0506 04:50:07.589375 12834 solver.cpp:242] Iteration 126000 (79.3091 iter/s, 1.26089s/100 iter), loss = 0.531009
I0506 04:50:07.589395 12834 solver.cpp:261]     Train net output #0: loss = 0.531009 (* 1 = 0.531009 loss)
I0506 04:50:07.589403 12834 sgd_solver.cpp:106] Iteration 126000, lr = 6.87195e-06
I0506 04:50:08.521893 12834 solver.cpp:242] Iteration 126100 (93.8476 iter/s, 1.06556s/100 iter), loss = 0.871223
I0506 04:50:08.521939 12834 solver.cpp:261]     Train net output #0: loss = 0.871223 (* 1 = 0.871223 loss)
I0506 04:50:08.522002 12834 sgd_solver.cpp:106] Iteration 126100, lr = 6.87195e-06
I0506 04:50:08.526784 12834 solver.cpp:242] Iteration 126100 (106.681 iter/s, 0.937371s/100 iter), loss = 0.828968
I0506 04:50:08.526809 12834 solver.cpp:261]     Train net output #0: loss = 0.828968 (* 1 = 0.828968 loss)
I0506 04:50:08.526818 12834 sgd_solver.cpp:106] Iteration 126100, lr = 6.87195e-06
I0506 04:50:09.458942 12834 solver.cpp:242] Iteration 126200 (106.726 iter/s, 0.936981s/100 iter), loss = 3.63728
I0506 04:50:09.458981 12834 solver.cpp:261]     Train net output #0: loss = 3.63728 (* 1 = 3.63728 loss)
I0506 04:50:09.458989 12834 sgd_solver.cpp:106] Iteration 126200, lr = 6.87195e-06
I0506 04:50:09.463789 12834 solver.cpp:242] Iteration 126200 (106.729 iter/s, 0.936953s/100 iter), loss = 0.787746
I0506 04:50:09.463814 12834 solver.cpp:261]     Train net output #0: loss = 0.787746 (* 1 = 0.787746 loss)
I0506 04:50:09.463824 12834 sgd_solver.cpp:106] Iteration 126200, lr = 6.87195e-06
I0506 04:50:10.396343 12834 solver.cpp:242] Iteration 126300 (106.685 iter/s, 0.937336s/100 iter), loss = 2.11117
I0506 04:50:10.396381 12834 solver.cpp:261]     Train net output #0: loss = 2.11117 (* 1 = 2.11117 loss)
I0506 04:50:10.396390 12834 sgd_solver.cpp:106] Iteration 126300, lr = 6.87195e-06
I0506 04:50:10.401108 12834 solver.cpp:242] Iteration 126300 (106.692 iter/s, 0.937276s/100 iter), loss = 0.695322
I0506 04:50:10.401131 12834 solver.cpp:261]     Train net output #0: loss = 0.695322 (* 1 = 0.695322 loss)
I0506 04:50:10.401140 12834 sgd_solver.cpp:106] Iteration 126300, lr = 6.87195e-06
I0506 04:50:11.333784 12834 solver.cpp:242] Iteration 126400 (106.68 iter/s, 0.937381s/100 iter), loss = 0.787913
I0506 04:50:11.333812 12834 solver.cpp:261]     Train net output #0: loss = 0.787913 (* 1 = 0.787913 loss)
I0506 04:50:11.333822 12834 sgd_solver.cpp:106] Iteration 126400, lr = 6.87195e-06
I0506 04:50:11.338608 12834 solver.cpp:242] Iteration 126400 (106.672 iter/s, 0.937451s/100 iter), loss = 0.122233
I0506 04:50:11.338630 12834 solver.cpp:261]     Train net output #0: loss = 0.122233 (* 1 = 0.122233 loss)
I0506 04:50:11.338640 12834 sgd_solver.cpp:106] Iteration 126400, lr = 6.87195e-06
I0506 04:50:12.268270 12834 solver.cpp:362] Iteration 126500, Testing net (#0)
I0506 04:50:12.268299 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:12.390910 12834 solver.cpp:429]     Test net output #0: loss = 1.33499 (* 1 = 1.33499 loss)
I0506 04:50:12.393422 12834 solver.cpp:242] Iteration 126500 (94.3761 iter/s, 1.05959s/100 iter), loss = 1.08072
I0506 04:50:12.393443 12834 solver.cpp:261]     Train net output #0: loss = 1.08072 (* 1 = 1.08072 loss)
I0506 04:50:12.393452 12834 sgd_solver.cpp:106] Iteration 126500, lr = 6.87195e-06
I0506 04:50:12.395272 12834 solver.cpp:362] Iteration 126500, Testing net (#0)
I0506 04:50:12.395287 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:12.523809 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7755
I0506 04:50:12.523828 12834 solver.cpp:429]     Test net output #1: loss = 0.525157 (* 1 = 0.525157 loss)
I0506 04:50:12.526388 12834 solver.cpp:242] Iteration 126500 (84.1937 iter/s, 1.18774s/100 iter), loss = 0.591621
I0506 04:50:12.526419 12834 solver.cpp:261]     Train net output #0: loss = 0.591621 (* 1 = 0.591621 loss)
I0506 04:50:12.526429 12834 sgd_solver.cpp:106] Iteration 126500, lr = 6.87195e-06
I0506 04:50:13.459221 12834 solver.cpp:242] Iteration 126600 (93.8313 iter/s, 1.06574s/100 iter), loss = 0.562237
I0506 04:50:13.459262 12834 solver.cpp:261]     Train net output #0: loss = 0.562237 (* 1 = 0.562237 loss)
I0506 04:50:13.459272 12834 sgd_solver.cpp:106] Iteration 126600, lr = 6.87195e-06
I0506 04:50:13.464017 12834 solver.cpp:242] Iteration 126600 (106.658 iter/s, 0.937581s/100 iter), loss = 0.33343
I0506 04:50:13.464042 12834 solver.cpp:261]     Train net output #0: loss = 0.33343 (* 1 = 0.33343 loss)
I0506 04:50:13.464051 12834 sgd_solver.cpp:106] Iteration 126600, lr = 6.87195e-06
I0506 04:50:14.397320 12834 solver.cpp:242] Iteration 126700 (106.606 iter/s, 0.938032s/100 iter), loss = 1.30119
I0506 04:50:14.397363 12834 solver.cpp:261]     Train net output #0: loss = 1.30119 (* 1 = 1.30119 loss)
I0506 04:50:14.397373 12834 sgd_solver.cpp:106] Iteration 126700, lr = 6.87195e-06
I0506 04:50:14.402086 12834 solver.cpp:242] Iteration 126700 (106.607 iter/s, 0.938026s/100 iter), loss = 0.535903
I0506 04:50:14.402110 12834 solver.cpp:261]     Train net output #0: loss = 0.535903 (* 1 = 0.535903 loss)
I0506 04:50:14.402119 12834 sgd_solver.cpp:106] Iteration 126700, lr = 6.87195e-06
I0506 04:50:15.334720 12834 solver.cpp:242] Iteration 126800 (106.686 iter/s, 0.937327s/100 iter), loss = 0.560977
I0506 04:50:15.334764 12834 solver.cpp:261]     Train net output #0: loss = 0.560977 (* 1 = 0.560977 loss)
I0506 04:50:15.334772 12834 sgd_solver.cpp:106] Iteration 126800, lr = 6.87195e-06
I0506 04:50:15.339509 12834 solver.cpp:242] Iteration 126800 (106.68 iter/s, 0.93738s/100 iter), loss = 0.437066
I0506 04:50:15.339534 12834 solver.cpp:261]     Train net output #0: loss = 0.437066 (* 1 = 0.437066 loss)
I0506 04:50:15.339542 12834 sgd_solver.cpp:106] Iteration 126800, lr = 6.87195e-06
I0506 04:50:16.272579 12834 solver.cpp:242] Iteration 126900 (106.633 iter/s, 0.937793s/100 iter), loss = 1.32632
I0506 04:50:16.272621 12834 solver.cpp:261]     Train net output #0: loss = 1.32632 (* 1 = 1.32632 loss)
I0506 04:50:16.272630 12834 sgd_solver.cpp:106] Iteration 126900, lr = 6.87195e-06
I0506 04:50:16.277360 12834 solver.cpp:242] Iteration 126900 (106.632 iter/s, 0.937809s/100 iter), loss = 0.656259
I0506 04:50:16.277384 12834 solver.cpp:261]     Train net output #0: loss = 0.656259 (* 1 = 0.656259 loss)
I0506 04:50:16.277392 12834 sgd_solver.cpp:106] Iteration 126900, lr = 6.87195e-06
I0506 04:50:17.207794 12834 solver.cpp:362] Iteration 127000, Testing net (#0)
I0506 04:50:17.207820 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:17.330529 12834 solver.cpp:429]     Test net output #0: loss = 1.29237 (* 1 = 1.29237 loss)
I0506 04:50:17.333045 12834 solver.cpp:242] Iteration 127000 (94.3035 iter/s, 1.06041s/100 iter), loss = 1.7057
I0506 04:50:17.333066 12834 solver.cpp:261]     Train net output #0: loss = 1.7057 (* 1 = 1.7057 loss)
I0506 04:50:17.333076 12834 sgd_solver.cpp:106] Iteration 127000, lr = 6.87195e-06
I0506 04:50:17.334885 12834 solver.cpp:362] Iteration 127000, Testing net (#0)
I0506 04:50:17.334899 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:17.463413 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:50:17.463433 12834 solver.cpp:429]     Test net output #1: loss = 0.513046 (* 1 = 0.513046 loss)
I0506 04:50:17.465992 12834 solver.cpp:242] Iteration 127000 (84.1335 iter/s, 1.18859s/100 iter), loss = 0.846006
I0506 04:50:17.466013 12834 solver.cpp:261]     Train net output #0: loss = 0.846006 (* 1 = 0.846006 loss)
I0506 04:50:17.466022 12834 sgd_solver.cpp:106] Iteration 127000, lr = 6.87195e-06
I0506 04:50:18.398902 12834 solver.cpp:242] Iteration 127100 (93.8254 iter/s, 1.06581s/100 iter), loss = 2.51759
I0506 04:50:18.398939 12834 solver.cpp:261]     Train net output #0: loss = 2.51759 (* 1 = 2.51759 loss)
I0506 04:50:18.398949 12834 sgd_solver.cpp:106] Iteration 127100, lr = 6.87195e-06
I0506 04:50:18.403779 12834 solver.cpp:242] Iteration 127100 (106.64 iter/s, 0.937738s/100 iter), loss = 0.655174
I0506 04:50:18.403805 12834 solver.cpp:261]     Train net output #0: loss = 0.655174 (* 1 = 0.655174 loss)
I0506 04:50:18.403815 12834 sgd_solver.cpp:106] Iteration 127100, lr = 6.87195e-06
I0506 04:50:19.409328 12834 solver.cpp:242] Iteration 127200 (98.9747 iter/s, 1.01036s/100 iter), loss = 2.07742
I0506 04:50:19.409375 12834 solver.cpp:261]     Train net output #0: loss = 2.07742 (* 1 = 2.07742 loss)
I0506 04:50:19.409703 12834 sgd_solver.cpp:106] Iteration 127200, lr = 6.87195e-06
I0506 04:50:19.414499 12834 solver.cpp:242] Iteration 127200 (98.9437 iter/s, 1.01068s/100 iter), loss = 0.794411
I0506 04:50:19.414523 12834 solver.cpp:261]     Train net output #0: loss = 0.794411 (* 1 = 0.794411 loss)
I0506 04:50:19.414532 12834 sgd_solver.cpp:106] Iteration 127200, lr = 6.87195e-06
I0506 04:50:20.346784 12834 solver.cpp:242] Iteration 127300 (106.679 iter/s, 0.937388s/100 iter), loss = 0.224357
I0506 04:50:20.346824 12834 solver.cpp:261]     Train net output #0: loss = 0.224357 (* 1 = 0.224357 loss)
I0506 04:50:20.346833 12834 sgd_solver.cpp:106] Iteration 127300, lr = 6.87195e-06
I0506 04:50:20.351613 12834 solver.cpp:242] Iteration 127300 (106.717 iter/s, 0.937061s/100 iter), loss = 0.608352
I0506 04:50:20.351639 12834 solver.cpp:261]     Train net output #0: loss = 0.608352 (* 1 = 0.608352 loss)
I0506 04:50:20.351647 12834 sgd_solver.cpp:106] Iteration 127300, lr = 6.87195e-06
I0506 04:50:21.284482 12834 solver.cpp:242] Iteration 127400 (106.652 iter/s, 0.93763s/100 iter), loss = 0.867778
I0506 04:50:21.284518 12834 solver.cpp:261]     Train net output #0: loss = 0.867778 (* 1 = 0.867778 loss)
I0506 04:50:21.284528 12834 sgd_solver.cpp:106] Iteration 127400, lr = 6.87195e-06
I0506 04:50:21.289264 12834 solver.cpp:242] Iteration 127400 (106.654 iter/s, 0.937607s/100 iter), loss = 0.667506
I0506 04:50:21.289289 12834 solver.cpp:261]     Train net output #0: loss = 0.667506 (* 1 = 0.667506 loss)
I0506 04:50:21.289299 12834 sgd_solver.cpp:106] Iteration 127400, lr = 6.87195e-06
I0506 04:50:22.219676 12834 solver.cpp:362] Iteration 127500, Testing net (#0)
I0506 04:50:22.219696 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:22.342392 12834 solver.cpp:429]     Test net output #0: loss = 1.24246 (* 1 = 1.24246 loss)
I0506 04:50:22.344903 12834 solver.cpp:242] Iteration 127500 (94.3069 iter/s, 1.06037s/100 iter), loss = 0.523966
I0506 04:50:22.344925 12834 solver.cpp:261]     Train net output #0: loss = 0.523966 (* 1 = 0.523966 loss)
I0506 04:50:22.344933 12834 sgd_solver.cpp:106] Iteration 127500, lr = 6.87195e-06
I0506 04:50:22.346755 12834 solver.cpp:362] Iteration 127500, Testing net (#0)
I0506 04:50:22.346766 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:22.475595 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:50:22.475615 12834 solver.cpp:429]     Test net output #1: loss = 0.531283 (* 1 = 0.531283 loss)
I0506 04:50:22.478188 12834 solver.cpp:242] Iteration 127500 (84.1129 iter/s, 1.18888s/100 iter), loss = 0.463786
I0506 04:50:22.478209 12834 solver.cpp:261]     Train net output #0: loss = 0.463786 (* 1 = 0.463786 loss)
I0506 04:50:22.478217 12834 sgd_solver.cpp:106] Iteration 127500, lr = 6.87195e-06
I0506 04:50:23.410435 12834 solver.cpp:242] Iteration 127600 (93.8542 iter/s, 1.06548s/100 iter), loss = 0.560701
I0506 04:50:23.410471 12834 solver.cpp:261]     Train net output #0: loss = 0.560701 (* 1 = 0.560701 loss)
I0506 04:50:23.410481 12834 sgd_solver.cpp:106] Iteration 127600, lr = 6.87195e-06
I0506 04:50:23.415202 12834 solver.cpp:242] Iteration 127600 (106.726 iter/s, 0.936975s/100 iter), loss = 0.197086
I0506 04:50:23.415227 12834 solver.cpp:261]     Train net output #0: loss = 0.197086 (* 1 = 0.197086 loss)
I0506 04:50:23.415236 12834 sgd_solver.cpp:106] Iteration 127600, lr = 6.87195e-06
I0506 04:50:24.428544 12834 solver.cpp:242] Iteration 127700 (98.2282 iter/s, 1.01804s/100 iter), loss = 2.44802
I0506 04:50:24.428669 12834 solver.cpp:261]     Train net output #0: loss = 2.44802 (* 1 = 2.44802 loss)
I0506 04:50:24.428686 12834 sgd_solver.cpp:106] Iteration 127700, lr = 6.87195e-06
I0506 04:50:24.433468 12834 solver.cpp:242] Iteration 127700 (98.2104 iter/s, 1.01822s/100 iter), loss = 0.651241
I0506 04:50:24.433492 12834 solver.cpp:261]     Train net output #0: loss = 0.651241 (* 1 = 0.651241 loss)
I0506 04:50:24.433501 12834 sgd_solver.cpp:106] Iteration 127700, lr = 6.87195e-06
I0506 04:50:25.366014 12834 solver.cpp:242] Iteration 127800 (106.685 iter/s, 0.937335s/100 iter), loss = 1.65806
I0506 04:50:25.366046 12834 solver.cpp:261]     Train net output #0: loss = 1.65806 (* 1 = 1.65806 loss)
I0506 04:50:25.366056 12834 sgd_solver.cpp:106] Iteration 127800, lr = 6.87195e-06
I0506 04:50:25.370770 12834 solver.cpp:242] Iteration 127800 (106.694 iter/s, 0.93726s/100 iter), loss = 0.549424
I0506 04:50:25.370793 12834 solver.cpp:261]     Train net output #0: loss = 0.549424 (* 1 = 0.549424 loss)
I0506 04:50:25.370802 12834 sgd_solver.cpp:106] Iteration 127800, lr = 6.87195e-06
I0506 04:50:26.303534 12834 solver.cpp:242] Iteration 127900 (106.672 iter/s, 0.937457s/100 iter), loss = 0.693537
I0506 04:50:26.303577 12834 solver.cpp:261]     Train net output #0: loss = 0.693537 (* 1 = 0.693537 loss)
I0506 04:50:26.303586 12834 sgd_solver.cpp:106] Iteration 127900, lr = 6.87195e-06
I0506 04:50:26.308357 12834 solver.cpp:242] Iteration 127900 (106.661 iter/s, 0.937546s/100 iter), loss = 0.797778
I0506 04:50:26.308382 12834 solver.cpp:261]     Train net output #0: loss = 0.797778 (* 1 = 0.797778 loss)
I0506 04:50:26.308392 12834 sgd_solver.cpp:106] Iteration 127900, lr = 6.87195e-06
I0506 04:50:27.238139 12834 solver.cpp:362] Iteration 128000, Testing net (#0)
I0506 04:50:27.238167 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:27.360843 12834 solver.cpp:429]     Test net output #0: loss = 1.32969 (* 1 = 1.32969 loss)
I0506 04:50:27.363363 12834 solver.cpp:242] Iteration 128000 (94.3604 iter/s, 1.05977s/100 iter), loss = 1.69166
I0506 04:50:27.363381 12834 solver.cpp:261]     Train net output #0: loss = 1.69166 (* 1 = 1.69166 loss)
I0506 04:50:27.363390 12834 sgd_solver.cpp:106] Iteration 128000, lr = 6.87195e-06
I0506 04:50:27.365293 12834 solver.cpp:362] Iteration 128000, Testing net (#0)
I0506 04:50:27.365306 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:27.493904 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:50:27.493922 12834 solver.cpp:429]     Test net output #1: loss = 0.514064 (* 1 = 0.514064 loss)
I0506 04:50:27.496469 12834 solver.cpp:242] Iteration 128000 (84.1705 iter/s, 1.18807s/100 iter), loss = 0.464928
I0506 04:50:27.496489 12834 solver.cpp:261]     Train net output #0: loss = 0.464928 (* 1 = 0.464928 loss)
I0506 04:50:27.496496 12834 sgd_solver.cpp:106] Iteration 128000, lr = 6.87195e-06
I0506 04:50:28.429342 12834 solver.cpp:242] Iteration 128100 (93.8148 iter/s, 1.06593s/100 iter), loss = 1.40711
I0506 04:50:28.429383 12834 solver.cpp:261]     Train net output #0: loss = 1.40711 (* 1 = 1.40711 loss)
I0506 04:50:28.429391 12834 sgd_solver.cpp:106] Iteration 128100, lr = 6.87195e-06
I0506 04:50:28.434150 12834 solver.cpp:242] Iteration 128100 (106.65 iter/s, 0.937644s/100 iter), loss = 0.662006
I0506 04:50:28.434176 12834 solver.cpp:261]     Train net output #0: loss = 0.662006 (* 1 = 0.662006 loss)
I0506 04:50:28.434185 12834 sgd_solver.cpp:106] Iteration 128100, lr = 6.87195e-06
I0506 04:50:29.366767 12834 solver.cpp:242] Iteration 128200 (106.682 iter/s, 0.937361s/100 iter), loss = 0.472164
I0506 04:50:29.366806 12834 solver.cpp:261]     Train net output #0: loss = 0.472164 (* 1 = 0.472164 loss)
I0506 04:50:29.366816 12834 sgd_solver.cpp:106] Iteration 128200, lr = 6.87195e-06
I0506 04:50:29.371631 12834 solver.cpp:242] Iteration 128200 (106.675 iter/s, 0.937428s/100 iter), loss = 0.398979
I0506 04:50:29.371655 12834 solver.cpp:261]     Train net output #0: loss = 0.398979 (* 1 = 0.398979 loss)
I0506 04:50:29.371665 12834 sgd_solver.cpp:106] Iteration 128200, lr = 6.87195e-06
I0506 04:50:30.304316 12834 solver.cpp:242] Iteration 128300 (106.669 iter/s, 0.937481s/100 iter), loss = 1.56911
I0506 04:50:30.304356 12834 solver.cpp:261]     Train net output #0: loss = 1.56911 (* 1 = 1.56911 loss)
I0506 04:50:30.304365 12834 sgd_solver.cpp:106] Iteration 128300, lr = 6.87195e-06
I0506 04:50:30.309092 12834 solver.cpp:242] Iteration 128300 (106.676 iter/s, 0.937419s/100 iter), loss = 0.665775
I0506 04:50:30.309118 12834 solver.cpp:261]     Train net output #0: loss = 0.665775 (* 1 = 0.665775 loss)
I0506 04:50:30.309128 12834 sgd_solver.cpp:106] Iteration 128300, lr = 6.87195e-06
I0506 04:50:31.242029 12834 solver.cpp:242] Iteration 128400 (106.651 iter/s, 0.937642s/100 iter), loss = 1.13962
I0506 04:50:31.242067 12834 solver.cpp:261]     Train net output #0: loss = 1.13962 (* 1 = 1.13962 loss)
I0506 04:50:31.242076 12834 sgd_solver.cpp:106] Iteration 128400, lr = 6.87195e-06
I0506 04:50:31.246800 12834 solver.cpp:242] Iteration 128400 (106.648 iter/s, 0.937662s/100 iter), loss = 0.367086
I0506 04:50:31.246825 12834 solver.cpp:261]     Train net output #0: loss = 0.367086 (* 1 = 0.367086 loss)
I0506 04:50:31.246834 12834 sgd_solver.cpp:106] Iteration 128400, lr = 6.87195e-06
I0506 04:50:32.176373 12834 solver.cpp:362] Iteration 128500, Testing net (#0)
I0506 04:50:32.176401 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:32.299058 12834 solver.cpp:429]     Test net output #0: loss = 1.30277 (* 1 = 1.30277 loss)
I0506 04:50:32.301604 12834 solver.cpp:242] Iteration 128500 (94.3826 iter/s, 1.05952s/100 iter), loss = 2.73065
I0506 04:50:32.301625 12834 solver.cpp:261]     Train net output #0: loss = 2.73065 (* 1 = 2.73065 loss)
I0506 04:50:32.301635 12834 sgd_solver.cpp:106] Iteration 128500, lr = 6.87195e-06
I0506 04:50:32.303450 12834 solver.cpp:362] Iteration 128500, Testing net (#0)
I0506 04:50:32.303462 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:32.431990 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7905
I0506 04:50:32.432010 12834 solver.cpp:429]     Test net output #1: loss = 0.503905 (* 1 = 0.503905 loss)
I0506 04:50:32.434547 12834 solver.cpp:242] Iteration 128500 (84.1963 iter/s, 1.1877s/100 iter), loss = 0.496572
I0506 04:50:32.434568 12834 solver.cpp:261]     Train net output #0: loss = 0.496572 (* 1 = 0.496572 loss)
I0506 04:50:32.434577 12834 sgd_solver.cpp:106] Iteration 128500, lr = 6.87195e-06
I0506 04:50:33.381342 12834 solver.cpp:242] Iteration 128600 (92.6198 iter/s, 1.07968s/100 iter), loss = 1.13003
I0506 04:50:33.381382 12834 solver.cpp:261]     Train net output #0: loss = 1.13003 (* 1 = 1.13003 loss)
I0506 04:50:33.381392 12834 sgd_solver.cpp:106] Iteration 128600, lr = 6.87195e-06
I0506 04:50:33.386111 12834 solver.cpp:242] Iteration 128600 (105.095 iter/s, 0.951523s/100 iter), loss = 0.36167
I0506 04:50:33.386135 12834 solver.cpp:261]     Train net output #0: loss = 0.36167 (* 1 = 0.36167 loss)
I0506 04:50:33.386144 12834 sgd_solver.cpp:106] Iteration 128600, lr = 6.87195e-06
I0506 04:50:34.319283 12834 solver.cpp:242] Iteration 128700 (106.624 iter/s, 0.937874s/100 iter), loss = 1.19063
I0506 04:50:34.319320 12834 solver.cpp:261]     Train net output #0: loss = 1.19063 (* 1 = 1.19063 loss)
I0506 04:50:34.319329 12834 sgd_solver.cpp:106] Iteration 128700, lr = 6.87195e-06
I0506 04:50:34.324056 12834 solver.cpp:242] Iteration 128700 (106.621 iter/s, 0.937902s/100 iter), loss = 0.769623
I0506 04:50:34.324080 12834 solver.cpp:261]     Train net output #0: loss = 0.769623 (* 1 = 0.769623 loss)
I0506 04:50:34.324090 12834 sgd_solver.cpp:106] Iteration 128700, lr = 6.87195e-06
I0506 04:50:35.299924 12834 solver.cpp:242] Iteration 128800 (101.981 iter/s, 0.980574s/100 iter), loss = 0.935599
I0506 04:50:35.299963 12834 solver.cpp:261]     Train net output #0: loss = 0.935599 (* 1 = 0.935599 loss)
I0506 04:50:35.299973 12834 sgd_solver.cpp:106] Iteration 128800, lr = 6.87195e-06
I0506 04:50:35.304689 12834 solver.cpp:242] Iteration 128800 (101.979 iter/s, 0.98059s/100 iter), loss = 0.429917
I0506 04:50:35.304725 12834 solver.cpp:261]     Train net output #0: loss = 0.429917 (* 1 = 0.429917 loss)
I0506 04:50:35.304735 12834 sgd_solver.cpp:106] Iteration 128800, lr = 6.87195e-06
I0506 04:50:36.237923 12834 solver.cpp:242] Iteration 128900 (106.617 iter/s, 0.937937s/100 iter), loss = 4.19497
I0506 04:50:36.237959 12834 solver.cpp:261]     Train net output #0: loss = 4.19497 (* 1 = 4.19497 loss)
I0506 04:50:36.237968 12834 sgd_solver.cpp:106] Iteration 128900, lr = 6.87195e-06
I0506 04:50:36.242760 12834 solver.cpp:242] Iteration 128900 (106.609 iter/s, 0.938007s/100 iter), loss = 0.733
I0506 04:50:36.242784 12834 solver.cpp:261]     Train net output #0: loss = 0.733 (* 1 = 0.733 loss)
I0506 04:50:36.242794 12834 sgd_solver.cpp:106] Iteration 128900, lr = 6.87195e-06
I0506 04:50:37.172729 12834 solver.cpp:362] Iteration 129000, Testing net (#0)
I0506 04:50:37.172749 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:37.295436 12834 solver.cpp:429]     Test net output #0: loss = 1.33944 (* 1 = 1.33944 loss)
I0506 04:50:37.297952 12834 solver.cpp:242] Iteration 129000 (94.3419 iter/s, 1.05997s/100 iter), loss = 0.536812
I0506 04:50:37.297972 12834 solver.cpp:261]     Train net output #0: loss = 0.536812 (* 1 = 0.536812 loss)
I0506 04:50:37.297981 12834 sgd_solver.cpp:106] Iteration 129000, lr = 6.87195e-06
I0506 04:50:37.299826 12834 solver.cpp:362] Iteration 129000, Testing net (#0)
I0506 04:50:37.299839 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:37.428385 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7695
I0506 04:50:37.428403 12834 solver.cpp:429]     Test net output #1: loss = 0.527852 (* 1 = 0.527852 loss)
I0506 04:50:37.430966 12834 solver.cpp:242] Iteration 129000 (84.1636 iter/s, 1.18816s/100 iter), loss = 0.422535
I0506 04:50:37.430987 12834 solver.cpp:261]     Train net output #0: loss = 0.422535 (* 1 = 0.422535 loss)
I0506 04:50:37.430996 12834 sgd_solver.cpp:106] Iteration 129000, lr = 6.87195e-06
I0506 04:50:38.384414 12834 solver.cpp:242] Iteration 129100 (92.0459 iter/s, 1.08641s/100 iter), loss = 1.31477
I0506 04:50:38.384448 12834 solver.cpp:261]     Train net output #0: loss = 1.31477 (* 1 = 1.31477 loss)
I0506 04:50:38.384456 12834 sgd_solver.cpp:106] Iteration 129100, lr = 6.87195e-06
I0506 04:50:38.389256 12834 solver.cpp:242] Iteration 129100 (104.358 iter/s, 0.95824s/100 iter), loss = 0.456157
I0506 04:50:38.389281 12834 solver.cpp:261]     Train net output #0: loss = 0.456157 (* 1 = 0.456157 loss)
I0506 04:50:38.389291 12834 sgd_solver.cpp:106] Iteration 129100, lr = 6.87195e-06
I0506 04:50:39.336028 12834 solver.cpp:242] Iteration 129200 (105.091 iter/s, 0.951552s/100 iter), loss = 1.16888
I0506 04:50:39.336069 12834 solver.cpp:261]     Train net output #0: loss = 1.16888 (* 1 = 1.16888 loss)
I0506 04:50:39.336078 12834 sgd_solver.cpp:106] Iteration 129200, lr = 6.87195e-06
I0506 04:50:39.340806 12834 solver.cpp:242] Iteration 129200 (105.097 iter/s, 0.951506s/100 iter), loss = 0.348313
I0506 04:50:39.340831 12834 solver.cpp:261]     Train net output #0: loss = 0.348313 (* 1 = 0.348313 loss)
I0506 04:50:39.340839 12834 sgd_solver.cpp:106] Iteration 129200, lr = 6.87195e-06
I0506 04:50:40.273964 12834 solver.cpp:242] Iteration 129300 (106.625 iter/s, 0.937862s/100 iter), loss = 0.556846
I0506 04:50:40.274011 12834 solver.cpp:261]     Train net output #0: loss = 0.556846 (* 1 = 0.556846 loss)
I0506 04:50:40.274212 12834 sgd_solver.cpp:106] Iteration 129300, lr = 6.87195e-06
I0506 04:50:40.279019 12834 solver.cpp:242] Iteration 129300 (106.59 iter/s, 0.938171s/100 iter), loss = 0.36396
I0506 04:50:40.279045 12834 solver.cpp:261]     Train net output #0: loss = 0.36396 (* 1 = 0.36396 loss)
I0506 04:50:40.279054 12834 sgd_solver.cpp:106] Iteration 129300, lr = 6.87195e-06
I0506 04:50:41.212265 12834 solver.cpp:242] Iteration 129400 (106.584 iter/s, 0.938229s/100 iter), loss = 1.07606
I0506 04:50:41.212306 12834 solver.cpp:261]     Train net output #0: loss = 1.07606 (* 1 = 1.07606 loss)
I0506 04:50:41.212314 12834 sgd_solver.cpp:106] Iteration 129400, lr = 6.87195e-06
I0506 04:50:41.217082 12834 solver.cpp:242] Iteration 129400 (106.608 iter/s, 0.938019s/100 iter), loss = 0.422098
I0506 04:50:41.217108 12834 solver.cpp:261]     Train net output #0: loss = 0.422098 (* 1 = 0.422098 loss)
I0506 04:50:41.217118 12834 sgd_solver.cpp:106] Iteration 129400, lr = 6.87195e-06
I0506 04:50:42.146951 12834 solver.cpp:362] Iteration 129500, Testing net (#0)
I0506 04:50:42.146981 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:42.269634 12834 solver.cpp:429]     Test net output #0: loss = 1.3038 (* 1 = 1.3038 loss)
I0506 04:50:42.272192 12834 solver.cpp:242] Iteration 129500 (94.3513 iter/s, 1.05987s/100 iter), loss = 0.844283
I0506 04:50:42.272212 12834 solver.cpp:261]     Train net output #0: loss = 0.844283 (* 1 = 0.844283 loss)
I0506 04:50:42.272222 12834 sgd_solver.cpp:106] Iteration 129500, lr = 6.87195e-06
I0506 04:50:42.274183 12834 solver.cpp:362] Iteration 129500, Testing net (#0)
I0506 04:50:42.274202 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:42.403162 12834 solver.cpp:429]     Test net output #0: accuracy = 0.772
I0506 04:50:42.403182 12834 solver.cpp:429]     Test net output #1: loss = 0.523456 (* 1 = 0.523456 loss)
I0506 04:50:42.405740 12834 solver.cpp:242] Iteration 129500 (84.1318 iter/s, 1.18861s/100 iter), loss = 0.677573
I0506 04:50:42.405761 12834 solver.cpp:261]     Train net output #0: loss = 0.677573 (* 1 = 0.677573 loss)
I0506 04:50:42.405771 12834 sgd_solver.cpp:106] Iteration 129500, lr = 6.87195e-06
I0506 04:50:43.411530 12834 solver.cpp:242] Iteration 129600 (87.7741 iter/s, 1.13929s/100 iter), loss = 0.620717
I0506 04:50:43.411572 12834 solver.cpp:261]     Train net output #0: loss = 0.620717 (* 1 = 0.620717 loss)
I0506 04:50:43.411581 12834 sgd_solver.cpp:106] Iteration 129600, lr = 6.87195e-06
I0506 04:50:43.416319 12834 solver.cpp:242] Iteration 129600 (98.957 iter/s, 1.01054s/100 iter), loss = 0.568488
I0506 04:50:43.416343 12834 solver.cpp:261]     Train net output #0: loss = 0.568488 (* 1 = 0.568488 loss)
I0506 04:50:43.416352 12834 sgd_solver.cpp:106] Iteration 129600, lr = 6.87195e-06
I0506 04:50:44.349733 12834 solver.cpp:242] Iteration 129700 (106.595 iter/s, 0.938129s/100 iter), loss = 1.15597
I0506 04:50:44.349772 12834 solver.cpp:261]     Train net output #0: loss = 1.15597 (* 1 = 1.15597 loss)
I0506 04:50:44.349781 12834 sgd_solver.cpp:106] Iteration 129700, lr = 6.87195e-06
I0506 04:50:44.354487 12834 solver.cpp:242] Iteration 129700 (106.596 iter/s, 0.938126s/100 iter), loss = 0.54736
I0506 04:50:44.354511 12834 solver.cpp:261]     Train net output #0: loss = 0.54736 (* 1 = 0.54736 loss)
I0506 04:50:44.354521 12834 sgd_solver.cpp:106] Iteration 129700, lr = 6.87195e-06
I0506 04:50:45.287108 12834 solver.cpp:242] Iteration 129800 (106.688 iter/s, 0.937311s/100 iter), loss = 1.21016
I0506 04:50:45.287153 12834 solver.cpp:261]     Train net output #0: loss = 1.21016 (* 1 = 1.21016 loss)
I0506 04:50:45.287375 12834 sgd_solver.cpp:106] Iteration 129800, lr = 6.87195e-06
I0506 04:50:45.292251 12834 solver.cpp:242] Iteration 129800 (106.643 iter/s, 0.937711s/100 iter), loss = 0.637518
I0506 04:50:45.292278 12834 solver.cpp:261]     Train net output #0: loss = 0.637518 (* 1 = 0.637518 loss)
I0506 04:50:45.292286 12834 sgd_solver.cpp:106] Iteration 129800, lr = 6.87195e-06
I0506 04:50:46.224489 12834 solver.cpp:242] Iteration 129900 (106.688 iter/s, 0.93731s/100 iter), loss = 0.455249
I0506 04:50:46.224529 12834 solver.cpp:261]     Train net output #0: loss = 0.455249 (* 1 = 0.455249 loss)
I0506 04:50:46.224537 12834 sgd_solver.cpp:106] Iteration 129900, lr = 6.87195e-06
I0506 04:50:46.229280 12834 solver.cpp:242] Iteration 129900 (106.725 iter/s, 0.936985s/100 iter), loss = 0.566157
I0506 04:50:46.229307 12834 solver.cpp:261]     Train net output #0: loss = 0.566157 (* 1 = 0.566157 loss)
I0506 04:50:46.229316 12834 sgd_solver.cpp:106] Iteration 129900, lr = 6.87195e-06
I0506 04:50:47.220173 12834 solver.cpp:362] Iteration 130000, Testing net (#0)
I0506 04:50:47.220201 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:47.353230 12834 solver.cpp:429]     Test net output #0: loss = 1.17203 (* 1 = 1.17203 loss)
I0506 04:50:47.355880 12834 solver.cpp:242] Iteration 130000 (88.3915 iter/s, 1.13133s/100 iter), loss = 1.22444
I0506 04:50:47.355906 12834 solver.cpp:261]     Train net output #0: loss = 1.22444 (* 1 = 1.22444 loss)
I0506 04:50:47.355917 12834 sgd_solver.cpp:106] Iteration 130000, lr = 5.49756e-06
I0506 04:50:47.358196 12834 solver.cpp:362] Iteration 130000, Testing net (#0)
I0506 04:50:47.358211 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:47.498826 12834 solver.cpp:429]     Test net output #0: accuracy = 0.787
I0506 04:50:47.498849 12834 solver.cpp:429]     Test net output #1: loss = 0.487776 (* 1 = 0.487776 loss)
I0506 04:50:47.501538 12834 solver.cpp:242] Iteration 130000 (78.6035 iter/s, 1.27221s/100 iter), loss = 0.764251
I0506 04:50:47.501562 12834 solver.cpp:261]     Train net output #0: loss = 0.764251 (* 1 = 0.764251 loss)
I0506 04:50:47.501574 12834 sgd_solver.cpp:106] Iteration 130000, lr = 5.49756e-06
I0506 04:50:48.531921 12834 solver.cpp:242] Iteration 130100 (85.0352 iter/s, 1.17598s/100 iter), loss = 3.41894
I0506 04:50:48.531970 12834 solver.cpp:261]     Train net output #0: loss = 3.41894 (* 1 = 3.41894 loss)
I0506 04:50:48.531980 12834 sgd_solver.cpp:106] Iteration 130100, lr = 5.49756e-06
I0506 04:50:48.537194 12834 solver.cpp:242] Iteration 130100 (96.5613 iter/s, 1.03561s/100 iter), loss = 0.748926
I0506 04:50:48.537225 12834 solver.cpp:261]     Train net output #0: loss = 0.748926 (* 1 = 0.748926 loss)
I0506 04:50:48.537236 12834 sgd_solver.cpp:106] Iteration 130100, lr = 5.49756e-06
I0506 04:50:49.567230 12834 solver.cpp:242] Iteration 130200 (96.5973 iter/s, 1.03523s/100 iter), loss = 0.560962
I0506 04:50:49.567278 12834 solver.cpp:261]     Train net output #0: loss = 0.560962 (* 1 = 0.560962 loss)
I0506 04:50:49.567289 12834 sgd_solver.cpp:106] Iteration 130200, lr = 5.49756e-06
I0506 04:50:49.572527 12834 solver.cpp:242] Iteration 130200 (96.592 iter/s, 1.03528s/100 iter), loss = 0.481076
I0506 04:50:49.572571 12834 solver.cpp:261]     Train net output #0: loss = 0.481076 (* 1 = 0.481076 loss)
I0506 04:50:49.572583 12834 sgd_solver.cpp:106] Iteration 130200, lr = 5.49756e-06
I0506 04:50:50.517015 12834 solver.cpp:242] Iteration 130300 (105.295 iter/s, 0.949713s/100 iter), loss = 1.29467
I0506 04:50:50.517055 12834 solver.cpp:261]     Train net output #0: loss = 1.29467 (* 1 = 1.29467 loss)
I0506 04:50:50.517065 12834 sgd_solver.cpp:106] Iteration 130300, lr = 5.49756e-06
I0506 04:50:50.521807 12834 solver.cpp:242] Iteration 130300 (105.348 iter/s, 0.94923s/100 iter), loss = 0.829017
I0506 04:50:50.521832 12834 solver.cpp:261]     Train net output #0: loss = 0.829017 (* 1 = 0.829017 loss)
I0506 04:50:50.521842 12834 sgd_solver.cpp:106] Iteration 130300, lr = 5.49756e-06
I0506 04:50:51.454931 12834 solver.cpp:242] Iteration 130400 (106.627 iter/s, 0.937845s/100 iter), loss = 1.34007
I0506 04:50:51.454968 12834 solver.cpp:261]     Train net output #0: loss = 1.34007 (* 1 = 1.34007 loss)
I0506 04:50:51.454977 12834 sgd_solver.cpp:106] Iteration 130400, lr = 5.49756e-06
I0506 04:50:51.459707 12834 solver.cpp:242] Iteration 130400 (106.626 iter/s, 0.937856s/100 iter), loss = 0.602013
I0506 04:50:51.459731 12834 solver.cpp:261]     Train net output #0: loss = 0.602013 (* 1 = 0.602013 loss)
I0506 04:50:51.459740 12834 sgd_solver.cpp:106] Iteration 130400, lr = 5.49756e-06
I0506 04:50:52.389379 12834 solver.cpp:362] Iteration 130500, Testing net (#0)
I0506 04:50:52.389402 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:52.512096 12834 solver.cpp:429]     Test net output #0: loss = 1.29769 (* 1 = 1.29769 loss)
I0506 04:50:52.514621 12834 solver.cpp:242] Iteration 130500 (94.3724 iter/s, 1.05963s/100 iter), loss = 0.3974
I0506 04:50:52.514642 12834 solver.cpp:261]     Train net output #0: loss = 0.3974 (* 1 = 0.3974 loss)
I0506 04:50:52.514650 12834 sgd_solver.cpp:106] Iteration 130500, lr = 5.49756e-06
I0506 04:50:52.516474 12834 solver.cpp:362] Iteration 130500, Testing net (#0)
I0506 04:50:52.516495 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:52.645097 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7695
I0506 04:50:52.645117 12834 solver.cpp:429]     Test net output #1: loss = 0.532615 (* 1 = 0.532615 loss)
I0506 04:50:52.647678 12834 solver.cpp:242] Iteration 130500 (84.1803 iter/s, 1.18793s/100 iter), loss = 0.539982
I0506 04:50:52.647698 12834 solver.cpp:261]     Train net output #0: loss = 0.539982 (* 1 = 0.539982 loss)
I0506 04:50:52.647706 12834 sgd_solver.cpp:106] Iteration 130500, lr = 5.49756e-06
I0506 04:50:53.580463 12834 solver.cpp:242] Iteration 130600 (93.8274 iter/s, 1.06579s/100 iter), loss = 1.04141
I0506 04:50:53.580502 12834 solver.cpp:261]     Train net output #0: loss = 1.04141 (* 1 = 1.04141 loss)
I0506 04:50:53.580510 12834 sgd_solver.cpp:106] Iteration 130600, lr = 5.49756e-06
I0506 04:50:53.585223 12834 solver.cpp:242] Iteration 130600 (106.666 iter/s, 0.937507s/100 iter), loss = 0.318457
I0506 04:50:53.585250 12834 solver.cpp:261]     Train net output #0: loss = 0.318457 (* 1 = 0.318457 loss)
I0506 04:50:53.585259 12834 sgd_solver.cpp:106] Iteration 130600, lr = 5.49756e-06
I0506 04:50:54.518838 12834 solver.cpp:242] Iteration 130700 (106.574 iter/s, 0.938315s/100 iter), loss = 1.58137
I0506 04:50:54.518869 12834 solver.cpp:261]     Train net output #0: loss = 1.58137 (* 1 = 1.58137 loss)
I0506 04:50:54.518878 12834 sgd_solver.cpp:106] Iteration 130700, lr = 5.49756e-06
I0506 04:50:54.523689 12834 solver.cpp:242] Iteration 130700 (106.563 iter/s, 0.938411s/100 iter), loss = 0.961788
I0506 04:50:54.523712 12834 solver.cpp:261]     Train net output #0: loss = 0.961788 (* 1 = 0.961788 loss)
I0506 04:50:54.523721 12834 sgd_solver.cpp:106] Iteration 130700, lr = 5.49756e-06
I0506 04:50:55.528892 12834 solver.cpp:242] Iteration 130800 (99.0106 iter/s, 1.00999s/100 iter), loss = 2.4281
I0506 04:50:55.528941 12834 solver.cpp:261]     Train net output #0: loss = 2.4281 (* 1 = 2.4281 loss)
I0506 04:50:55.529105 12834 sgd_solver.cpp:106] Iteration 130800, lr = 5.49756e-06
I0506 04:50:55.533915 12834 solver.cpp:242] Iteration 130800 (98.9919 iter/s, 1.01018s/100 iter), loss = 0.392147
I0506 04:50:55.533941 12834 solver.cpp:261]     Train net output #0: loss = 0.392147 (* 1 = 0.392147 loss)
I0506 04:50:55.533951 12834 sgd_solver.cpp:106] Iteration 130800, lr = 5.49756e-06
I0506 04:50:56.466634 12834 solver.cpp:242] Iteration 130900 (106.647 iter/s, 0.937673s/100 iter), loss = 0.679856
I0506 04:50:56.466675 12834 solver.cpp:261]     Train net output #0: loss = 0.679856 (* 1 = 0.679856 loss)
I0506 04:50:56.466686 12834 sgd_solver.cpp:106] Iteration 130900, lr = 5.49756e-06
I0506 04:50:56.471482 12834 solver.cpp:242] Iteration 130900 (106.665 iter/s, 0.937512s/100 iter), loss = 0.293016
I0506 04:50:56.471506 12834 solver.cpp:261]     Train net output #0: loss = 0.293016 (* 1 = 0.293016 loss)
I0506 04:50:56.471515 12834 sgd_solver.cpp:106] Iteration 130900, lr = 5.49756e-06
I0506 04:50:57.401947 12834 solver.cpp:362] Iteration 131000, Testing net (#0)
I0506 04:50:57.401975 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:57.524863 12834 solver.cpp:429]     Test net output #0: loss = 1.22572 (* 1 = 1.22572 loss)
I0506 04:50:57.527381 12834 solver.cpp:242] Iteration 131000 (94.2785 iter/s, 1.06069s/100 iter), loss = 2.08765
I0506 04:50:57.527403 12834 solver.cpp:261]     Train net output #0: loss = 2.08765 (* 1 = 2.08765 loss)
I0506 04:50:57.527411 12834 sgd_solver.cpp:106] Iteration 131000, lr = 5.49756e-06
I0506 04:50:57.529238 12834 solver.cpp:362] Iteration 131000, Testing net (#0)
I0506 04:50:57.529251 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:50:57.657910 12834 solver.cpp:429]     Test net output #0: accuracy = 0.765
I0506 04:50:57.657928 12834 solver.cpp:429]     Test net output #1: loss = 0.534746 (* 1 = 0.534746 loss)
I0506 04:50:57.660486 12834 solver.cpp:242] Iteration 131000 (84.1072 iter/s, 1.18896s/100 iter), loss = 0.462158
I0506 04:50:57.660506 12834 solver.cpp:261]     Train net output #0: loss = 0.462158 (* 1 = 0.462158 loss)
I0506 04:50:57.660526 12834 sgd_solver.cpp:106] Iteration 131000, lr = 5.49756e-06
I0506 04:50:58.596027 12834 solver.cpp:242] Iteration 131100 (93.5817 iter/s, 1.06858s/100 iter), loss = 0.257848
I0506 04:50:58.596077 12834 solver.cpp:261]     Train net output #0: loss = 0.257848 (* 1 = 0.257848 loss)
I0506 04:50:58.596088 12834 sgd_solver.cpp:106] Iteration 131100, lr = 5.49756e-06
I0506 04:50:58.601354 12834 solver.cpp:242] Iteration 131100 (106.289 iter/s, 0.940828s/100 iter), loss = 0.466878
I0506 04:50:58.601387 12834 solver.cpp:261]     Train net output #0: loss = 0.466878 (* 1 = 0.466878 loss)
I0506 04:50:58.601398 12834 sgd_solver.cpp:106] Iteration 131100, lr = 5.49756e-06
I0506 04:50:59.632578 12834 solver.cpp:242] Iteration 131200 (96.481 iter/s, 1.03647s/100 iter), loss = 0.221389
I0506 04:50:59.632627 12834 solver.cpp:261]     Train net output #0: loss = 0.221389 (* 1 = 0.221389 loss)
I0506 04:50:59.632638 12834 sgd_solver.cpp:106] Iteration 131200, lr = 5.49756e-06
I0506 04:50:59.637923 12834 solver.cpp:242] Iteration 131200 (96.4771 iter/s, 1.03652s/100 iter), loss = 0.35765
I0506 04:50:59.637954 12834 solver.cpp:261]     Train net output #0: loss = 0.35765 (* 1 = 0.35765 loss)
I0506 04:50:59.637965 12834 sgd_solver.cpp:106] Iteration 131200, lr = 5.49756e-06
I0506 04:51:00.676647 12834 solver.cpp:242] Iteration 131300 (95.7871 iter/s, 1.04398s/100 iter), loss = 0.160087
I0506 04:51:00.676712 12834 solver.cpp:261]     Train net output #0: loss = 0.160087 (* 1 = 0.160087 loss)
I0506 04:51:00.676777 12834 sgd_solver.cpp:106] Iteration 131300, lr = 5.49756e-06
I0506 04:51:00.681557 12834 solver.cpp:242] Iteration 131300 (95.8236 iter/s, 1.04358s/100 iter), loss = 0.151581
I0506 04:51:00.681583 12834 solver.cpp:261]     Train net output #0: loss = 0.151581 (* 1 = 0.151581 loss)
I0506 04:51:00.681592 12834 sgd_solver.cpp:106] Iteration 131300, lr = 5.49756e-06
I0506 04:51:01.614893 12834 solver.cpp:242] Iteration 131400 (106.592 iter/s, 0.938159s/100 iter), loss = 0.397644
I0506 04:51:01.614935 12834 solver.cpp:261]     Train net output #0: loss = 0.397644 (* 1 = 0.397644 loss)
I0506 04:51:01.614945 12834 sgd_solver.cpp:106] Iteration 131400, lr = 5.49756e-06
I0506 04:51:01.619669 12834 solver.cpp:242] Iteration 131400 (106.602 iter/s, 0.938067s/100 iter), loss = 0.410283
I0506 04:51:01.619695 12834 solver.cpp:261]     Train net output #0: loss = 0.410283 (* 1 = 0.410283 loss)
I0506 04:51:01.619704 12834 sgd_solver.cpp:106] Iteration 131400, lr = 5.49756e-06
I0506 04:51:02.549581 12834 solver.cpp:362] Iteration 131500, Testing net (#0)
I0506 04:51:02.549607 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:02.672235 12834 solver.cpp:429]     Test net output #0: loss = 1.29824 (* 1 = 1.29824 loss)
I0506 04:51:02.674764 12834 solver.cpp:242] Iteration 131500 (94.3564 iter/s, 1.05981s/100 iter), loss = 1.90003
I0506 04:51:02.674787 12834 solver.cpp:261]     Train net output #0: loss = 1.90003 (* 1 = 1.90003 loss)
I0506 04:51:02.674794 12834 sgd_solver.cpp:106] Iteration 131500, lr = 5.49756e-06
I0506 04:51:02.676618 12834 solver.cpp:362] Iteration 131500, Testing net (#0)
I0506 04:51:02.676631 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:02.805184 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7555
I0506 04:51:02.805204 12834 solver.cpp:429]     Test net output #1: loss = 0.544052 (* 1 = 0.544052 loss)
I0506 04:51:02.807770 12834 solver.cpp:242] Iteration 131500 (84.1713 iter/s, 1.18805s/100 iter), loss = 0.521019
I0506 04:51:02.807790 12834 solver.cpp:261]     Train net output #0: loss = 0.521019 (* 1 = 0.521019 loss)
I0506 04:51:02.807799 12834 sgd_solver.cpp:106] Iteration 131500, lr = 5.49756e-06
I0506 04:51:03.741875 12834 solver.cpp:242] Iteration 131600 (93.7153 iter/s, 1.06706s/100 iter), loss = 1.68521
I0506 04:51:03.741915 12834 solver.cpp:261]     Train net output #0: loss = 1.68521 (* 1 = 1.68521 loss)
I0506 04:51:03.741925 12834 sgd_solver.cpp:106] Iteration 131600, lr = 5.49756e-06
I0506 04:51:03.746652 12834 solver.cpp:242] Iteration 131600 (106.514 iter/s, 0.938843s/100 iter), loss = 0.595007
I0506 04:51:03.746678 12834 solver.cpp:261]     Train net output #0: loss = 0.595007 (* 1 = 0.595007 loss)
I0506 04:51:03.746687 12834 sgd_solver.cpp:106] Iteration 131600, lr = 5.49756e-06
I0506 04:51:04.678977 12834 solver.cpp:242] Iteration 131700 (106.72 iter/s, 0.937032s/100 iter), loss = 1.48437
I0506 04:51:04.679020 12834 solver.cpp:261]     Train net output #0: loss = 1.48437 (* 1 = 1.48437 loss)
I0506 04:51:04.679029 12834 sgd_solver.cpp:106] Iteration 131700, lr = 5.49756e-06
I0506 04:51:04.683753 12834 solver.cpp:242] Iteration 131700 (106.717 iter/s, 0.937057s/100 iter), loss = 0.527281
I0506 04:51:04.683778 12834 solver.cpp:261]     Train net output #0: loss = 0.527281 (* 1 = 0.527281 loss)
I0506 04:51:04.683786 12834 sgd_solver.cpp:106] Iteration 131700, lr = 5.49756e-06
I0506 04:51:05.616624 12834 solver.cpp:242] Iteration 131800 (106.657 iter/s, 0.937581s/100 iter), loss = 0.569731
I0506 04:51:05.616662 12834 solver.cpp:261]     Train net output #0: loss = 0.569731 (* 1 = 0.569731 loss)
I0506 04:51:05.616672 12834 sgd_solver.cpp:106] Iteration 131800, lr = 5.49756e-06
I0506 04:51:05.621461 12834 solver.cpp:242] Iteration 131800 (106.649 iter/s, 0.937656s/100 iter), loss = 0.539748
I0506 04:51:05.621487 12834 solver.cpp:261]     Train net output #0: loss = 0.539748 (* 1 = 0.539748 loss)
I0506 04:51:05.621496 12834 sgd_solver.cpp:106] Iteration 131800, lr = 5.49756e-06
I0506 04:51:06.554754 12834 solver.cpp:242] Iteration 131900 (106.603 iter/s, 0.938064s/100 iter), loss = 0.452274
I0506 04:51:06.554790 12834 solver.cpp:261]     Train net output #0: loss = 0.452274 (* 1 = 0.452274 loss)
I0506 04:51:06.554800 12834 sgd_solver.cpp:106] Iteration 131900, lr = 5.49756e-06
I0506 04:51:06.559577 12834 solver.cpp:242] Iteration 131900 (106.602 iter/s, 0.938071s/100 iter), loss = 0.424924
I0506 04:51:06.559602 12834 solver.cpp:261]     Train net output #0: loss = 0.424924 (* 1 = 0.424924 loss)
I0506 04:51:06.559610 12834 sgd_solver.cpp:106] Iteration 131900, lr = 5.49756e-06
I0506 04:51:07.490393 12834 solver.cpp:362] Iteration 132000, Testing net (#0)
I0506 04:51:07.490417 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:07.613220 12834 solver.cpp:429]     Test net output #0: loss = 1.14158 (* 1 = 1.14158 loss)
I0506 04:51:07.615742 12834 solver.cpp:242] Iteration 132000 (94.2565 iter/s, 1.06093s/100 iter), loss = 0.722022
I0506 04:51:07.615762 12834 solver.cpp:261]     Train net output #0: loss = 0.722022 (* 1 = 0.722022 loss)
I0506 04:51:07.615772 12834 sgd_solver.cpp:106] Iteration 132000, lr = 5.49756e-06
I0506 04:51:07.617590 12834 solver.cpp:362] Iteration 132000, Testing net (#0)
I0506 04:51:07.617604 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:07.746490 12834 solver.cpp:429]     Test net output #0: accuracy = 0.805
I0506 04:51:07.746510 12834 solver.cpp:429]     Test net output #1: loss = 0.482793 (* 1 = 0.482793 loss)
I0506 04:51:07.749058 12834 solver.cpp:242] Iteration 132000 (84.0734 iter/s, 1.18944s/100 iter), loss = 0.375028
I0506 04:51:07.749078 12834 solver.cpp:261]     Train net output #0: loss = 0.375028 (* 1 = 0.375028 loss)
I0506 04:51:07.749088 12834 sgd_solver.cpp:106] Iteration 132000, lr = 5.49756e-06
I0506 04:51:08.681469 12834 solver.cpp:242] Iteration 132100 (93.837 iter/s, 1.06568s/100 iter), loss = 1.48839
I0506 04:51:08.681506 12834 solver.cpp:261]     Train net output #0: loss = 1.48839 (* 1 = 1.48839 loss)
I0506 04:51:08.681515 12834 sgd_solver.cpp:106] Iteration 132100, lr = 5.49756e-06
I0506 04:51:08.686262 12834 solver.cpp:242] Iteration 132100 (106.705 iter/s, 0.937166s/100 iter), loss = 0.575869
I0506 04:51:08.686287 12834 solver.cpp:261]     Train net output #0: loss = 0.575869 (* 1 = 0.575869 loss)
I0506 04:51:08.686296 12834 sgd_solver.cpp:106] Iteration 132100, lr = 5.49756e-06
I0506 04:51:09.619412 12834 solver.cpp:242] Iteration 132200 (106.624 iter/s, 0.937873s/100 iter), loss = 0.787869
I0506 04:51:09.619451 12834 solver.cpp:261]     Train net output #0: loss = 0.787869 (* 1 = 0.787869 loss)
I0506 04:51:09.619469 12834 sgd_solver.cpp:106] Iteration 132200, lr = 5.49756e-06
I0506 04:51:09.624192 12834 solver.cpp:242] Iteration 132200 (106.623 iter/s, 0.937887s/100 iter), loss = 0.385238
I0506 04:51:09.624217 12834 solver.cpp:261]     Train net output #0: loss = 0.385238 (* 1 = 0.385238 loss)
I0506 04:51:09.624227 12834 sgd_solver.cpp:106] Iteration 132200, lr = 5.49756e-06
I0506 04:51:10.557637 12834 solver.cpp:242] Iteration 132300 (106.591 iter/s, 0.938162s/100 iter), loss = 1.50256
I0506 04:51:10.557672 12834 solver.cpp:261]     Train net output #0: loss = 1.50256 (* 1 = 1.50256 loss)
I0506 04:51:10.557680 12834 sgd_solver.cpp:106] Iteration 132300, lr = 5.49756e-06
I0506 04:51:10.562394 12834 solver.cpp:242] Iteration 132300 (106.592 iter/s, 0.938159s/100 iter), loss = 0.63291
I0506 04:51:10.562417 12834 solver.cpp:261]     Train net output #0: loss = 0.63291 (* 1 = 0.63291 loss)
I0506 04:51:10.562427 12834 sgd_solver.cpp:106] Iteration 132300, lr = 5.49756e-06
I0506 04:51:11.591435 12834 solver.cpp:242] Iteration 132400 (96.7372 iter/s, 1.03373s/100 iter), loss = 1.16936
I0506 04:51:11.591491 12834 solver.cpp:261]     Train net output #0: loss = 1.16936 (* 1 = 1.16936 loss)
I0506 04:51:11.591627 12834 sgd_solver.cpp:106] Iteration 132400, lr = 5.49756e-06
I0506 04:51:11.596459 12834 solver.cpp:242] Iteration 132400 (96.7097 iter/s, 1.03402s/100 iter), loss = 0.432404
I0506 04:51:11.596483 12834 solver.cpp:261]     Train net output #0: loss = 0.432404 (* 1 = 0.432404 loss)
I0506 04:51:11.596493 12834 sgd_solver.cpp:106] Iteration 132400, lr = 5.49756e-06
I0506 04:51:12.526571 12834 solver.cpp:362] Iteration 132500, Testing net (#0)
I0506 04:51:12.526597 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:12.649255 12834 solver.cpp:429]     Test net output #0: loss = 1.29815 (* 1 = 1.29815 loss)
I0506 04:51:12.651779 12834 solver.cpp:242] Iteration 132500 (94.3155 iter/s, 1.06027s/100 iter), loss = 1.66845
I0506 04:51:12.651800 12834 solver.cpp:261]     Train net output #0: loss = 1.66845 (* 1 = 1.66845 loss)
I0506 04:51:12.651808 12834 sgd_solver.cpp:106] Iteration 132500, lr = 5.49756e-06
I0506 04:51:12.653654 12834 solver.cpp:362] Iteration 132500, Testing net (#0)
I0506 04:51:12.653667 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:12.782304 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7625
I0506 04:51:12.782321 12834 solver.cpp:429]     Test net output #1: loss = 0.534443 (* 1 = 0.534443 loss)
I0506 04:51:12.784879 12834 solver.cpp:242] Iteration 132500 (84.1485 iter/s, 1.18837s/100 iter), loss = 0.660384
I0506 04:51:12.784899 12834 solver.cpp:261]     Train net output #0: loss = 0.660384 (* 1 = 0.660384 loss)
I0506 04:51:12.784909 12834 sgd_solver.cpp:106] Iteration 132500, lr = 5.49756e-06
I0506 04:51:13.718462 12834 solver.cpp:242] Iteration 132600 (93.7533 iter/s, 1.06663s/100 iter), loss = 0.596913
I0506 04:51:13.718502 12834 solver.cpp:261]     Train net output #0: loss = 0.596913 (* 1 = 0.596913 loss)
I0506 04:51:13.718511 12834 sgd_solver.cpp:106] Iteration 132600, lr = 5.49756e-06
I0506 04:51:13.723250 12834 solver.cpp:242] Iteration 132600 (106.572 iter/s, 0.938332s/100 iter), loss = 0.485367
I0506 04:51:13.723276 12834 solver.cpp:261]     Train net output #0: loss = 0.485367 (* 1 = 0.485367 loss)
I0506 04:51:13.723284 12834 sgd_solver.cpp:106] Iteration 132600, lr = 5.49756e-06
I0506 04:51:14.664152 12834 solver.cpp:242] Iteration 132700 (105.75 iter/s, 0.945624s/100 iter), loss = 1.40881
I0506 04:51:14.664201 12834 solver.cpp:261]     Train net output #0: loss = 1.40881 (* 1 = 1.40881 loss)
I0506 04:51:14.664212 12834 sgd_solver.cpp:106] Iteration 132700, lr = 5.49756e-06
I0506 04:51:14.669545 12834 solver.cpp:242] Iteration 132700 (105.682 iter/s, 0.946236s/100 iter), loss = 0.54926
I0506 04:51:14.669577 12834 solver.cpp:261]     Train net output #0: loss = 0.54926 (* 1 = 0.54926 loss)
I0506 04:51:14.669589 12834 sgd_solver.cpp:106] Iteration 132700, lr = 5.49756e-06
I0506 04:51:15.607810 12834 solver.cpp:242] Iteration 132800 (105.979 iter/s, 0.943582s/100 iter), loss = 1.5673
I0506 04:51:15.607858 12834 solver.cpp:261]     Train net output #0: loss = 1.5673 (* 1 = 1.5673 loss)
I0506 04:51:15.607868 12834 sgd_solver.cpp:106] Iteration 132800, lr = 5.49756e-06
I0506 04:51:15.612603 12834 solver.cpp:242] Iteration 132800 (106.044 iter/s, 0.943008s/100 iter), loss = 0.740353
I0506 04:51:15.612629 12834 solver.cpp:261]     Train net output #0: loss = 0.740353 (* 1 = 0.740353 loss)
I0506 04:51:15.612638 12834 sgd_solver.cpp:106] Iteration 132800, lr = 5.49756e-06
I0506 04:51:16.545550 12834 solver.cpp:242] Iteration 132900 (106.649 iter/s, 0.937659s/100 iter), loss = 3.31621
I0506 04:51:16.545590 12834 solver.cpp:261]     Train net output #0: loss = 3.31621 (* 1 = 3.31621 loss)
I0506 04:51:16.545599 12834 sgd_solver.cpp:106] Iteration 132900, lr = 5.49756e-06
I0506 04:51:16.550317 12834 solver.cpp:242] Iteration 132900 (106.647 iter/s, 0.93767s/100 iter), loss = 0.751775
I0506 04:51:16.550341 12834 solver.cpp:261]     Train net output #0: loss = 0.751775 (* 1 = 0.751775 loss)
I0506 04:51:16.550349 12834 sgd_solver.cpp:106] Iteration 132900, lr = 5.49756e-06
I0506 04:51:17.479779 12834 solver.cpp:362] Iteration 133000, Testing net (#0)
I0506 04:51:17.479805 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:17.602318 12834 solver.cpp:429]     Test net output #0: loss = 1.13828 (* 1 = 1.13828 loss)
I0506 04:51:17.604831 12834 solver.cpp:242] Iteration 133000 (94.4089 iter/s, 1.05922s/100 iter), loss = 0.680468
I0506 04:51:17.604853 12834 solver.cpp:261]     Train net output #0: loss = 0.680468 (* 1 = 0.680468 loss)
I0506 04:51:17.604862 12834 sgd_solver.cpp:106] Iteration 133000, lr = 5.49756e-06
I0506 04:51:17.606684 12834 solver.cpp:362] Iteration 133000, Testing net (#0)
I0506 04:51:17.606696 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:17.735404 12834 solver.cpp:429]     Test net output #0: accuracy = 0.783
I0506 04:51:17.735424 12834 solver.cpp:429]     Test net output #1: loss = 0.50742 (* 1 = 0.50742 loss)
I0506 04:51:17.737995 12834 solver.cpp:242] Iteration 133000 (84.2011 iter/s, 1.18763s/100 iter), loss = 0.618064
I0506 04:51:17.738016 12834 solver.cpp:261]     Train net output #0: loss = 0.618064 (* 1 = 0.618064 loss)
I0506 04:51:17.738025 12834 sgd_solver.cpp:106] Iteration 133000, lr = 5.49756e-06
I0506 04:51:18.680831 12834 solver.cpp:242] Iteration 133100 (92.942 iter/s, 1.07594s/100 iter), loss = 1.71142
I0506 04:51:18.680878 12834 solver.cpp:261]     Train net output #0: loss = 1.71142 (* 1 = 1.71142 loss)
I0506 04:51:18.680891 12834 sgd_solver.cpp:106] Iteration 133100, lr = 5.49756e-06
I0506 04:51:18.686100 12834 solver.cpp:242] Iteration 133100 (105.478 iter/s, 0.948064s/100 iter), loss = 0.520312
I0506 04:51:18.686131 12834 solver.cpp:261]     Train net output #0: loss = 0.520312 (* 1 = 0.520312 loss)
I0506 04:51:18.686142 12834 sgd_solver.cpp:106] Iteration 133100, lr = 5.49756e-06
I0506 04:51:19.681011 12834 solver.cpp:242] Iteration 133200 (99.9892 iter/s, 1.00011s/100 iter), loss = 3.93804
I0506 04:51:19.681051 12834 solver.cpp:261]     Train net output #0: loss = 3.93804 (* 1 = 3.93804 loss)
I0506 04:51:19.681061 12834 sgd_solver.cpp:106] Iteration 133200, lr = 5.49756e-06
I0506 04:51:19.685760 12834 solver.cpp:242] Iteration 133200 (100.039 iter/s, 0.999609s/100 iter), loss = 0.78128
I0506 04:51:19.685784 12834 solver.cpp:261]     Train net output #0: loss = 0.78128 (* 1 = 0.78128 loss)
I0506 04:51:19.685793 12834 sgd_solver.cpp:106] Iteration 133200, lr = 5.49756e-06
I0506 04:51:20.619029 12834 solver.cpp:242] Iteration 133300 (106.616 iter/s, 0.937948s/100 iter), loss = 2.12424
I0506 04:51:20.619065 12834 solver.cpp:261]     Train net output #0: loss = 2.12424 (* 1 = 2.12424 loss)
I0506 04:51:20.619074 12834 sgd_solver.cpp:106] Iteration 133300, lr = 5.49756e-06
I0506 04:51:20.623811 12834 solver.cpp:242] Iteration 133300 (106.609 iter/s, 0.938008s/100 iter), loss = 0.617286
I0506 04:51:20.623836 12834 solver.cpp:261]     Train net output #0: loss = 0.617286 (* 1 = 0.617286 loss)
I0506 04:51:20.623854 12834 sgd_solver.cpp:106] Iteration 133300, lr = 5.49756e-06
I0506 04:51:21.557288 12834 solver.cpp:242] Iteration 133400 (106.587 iter/s, 0.938198s/100 iter), loss = 0.933219
I0506 04:51:21.557322 12834 solver.cpp:261]     Train net output #0: loss = 0.933219 (* 1 = 0.933219 loss)
I0506 04:51:21.557332 12834 sgd_solver.cpp:106] Iteration 133400, lr = 5.49756e-06
I0506 04:51:21.562054 12834 solver.cpp:242] Iteration 133400 (106.587 iter/s, 0.9382s/100 iter), loss = 0.428261
I0506 04:51:21.562078 12834 solver.cpp:261]     Train net output #0: loss = 0.428261 (* 1 = 0.428261 loss)
I0506 04:51:21.562088 12834 sgd_solver.cpp:106] Iteration 133400, lr = 5.49756e-06
I0506 04:51:22.492087 12834 solver.cpp:362] Iteration 133500, Testing net (#0)
I0506 04:51:22.492105 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:22.614665 12834 solver.cpp:429]     Test net output #0: loss = 1.16259 (* 1 = 1.16259 loss)
I0506 04:51:22.617192 12834 solver.cpp:242] Iteration 133500 (94.3529 iter/s, 1.05985s/100 iter), loss = 0.590695
I0506 04:51:22.617213 12834 solver.cpp:261]     Train net output #0: loss = 0.590695 (* 1 = 0.590695 loss)
I0506 04:51:22.617221 12834 sgd_solver.cpp:106] Iteration 133500, lr = 5.49756e-06
I0506 04:51:22.619033 12834 solver.cpp:362] Iteration 133500, Testing net (#0)
I0506 04:51:22.619045 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:22.747897 12834 solver.cpp:429]     Test net output #0: accuracy = 0.766
I0506 04:51:22.747915 12834 solver.cpp:429]     Test net output #1: loss = 0.528614 (* 1 = 0.528614 loss)
I0506 04:51:22.750471 12834 solver.cpp:242] Iteration 133500 (84.1487 iter/s, 1.18837s/100 iter), loss = 0.699917
I0506 04:51:22.750493 12834 solver.cpp:261]     Train net output #0: loss = 0.699917 (* 1 = 0.699917 loss)
I0506 04:51:22.750501 12834 sgd_solver.cpp:106] Iteration 133500, lr = 5.49756e-06
I0506 04:51:23.683301 12834 solver.cpp:242] Iteration 133600 (93.8031 iter/s, 1.06606s/100 iter), loss = 1.12834
I0506 04:51:23.683334 12834 solver.cpp:261]     Train net output #0: loss = 1.12834 (* 1 = 1.12834 loss)
I0506 04:51:23.683343 12834 sgd_solver.cpp:106] Iteration 133600, lr = 5.49756e-06
I0506 04:51:23.688176 12834 solver.cpp:242] Iteration 133600 (106.649 iter/s, 0.937655s/100 iter), loss = 0.635396
I0506 04:51:23.688200 12834 solver.cpp:261]     Train net output #0: loss = 0.635396 (* 1 = 0.635396 loss)
I0506 04:51:23.688210 12834 sgd_solver.cpp:106] Iteration 133600, lr = 5.49756e-06
I0506 04:51:24.621137 12834 solver.cpp:242] Iteration 133700 (106.635 iter/s, 0.937777s/100 iter), loss = 3.61832
I0506 04:51:24.621170 12834 solver.cpp:261]     Train net output #0: loss = 3.61832 (* 1 = 3.61832 loss)
I0506 04:51:24.621181 12834 sgd_solver.cpp:106] Iteration 133700, lr = 5.49756e-06
I0506 04:51:24.625897 12834 solver.cpp:242] Iteration 133700 (106.646 iter/s, 0.937679s/100 iter), loss = 0.303163
I0506 04:51:24.625921 12834 solver.cpp:261]     Train net output #0: loss = 0.303163 (* 1 = 0.303163 loss)
I0506 04:51:24.625931 12834 sgd_solver.cpp:106] Iteration 133700, lr = 5.49756e-06
I0506 04:51:25.558970 12834 solver.cpp:242] Iteration 133800 (106.635 iter/s, 0.937775s/100 iter), loss = 0.760403
I0506 04:51:25.559010 12834 solver.cpp:261]     Train net output #0: loss = 0.760403 (* 1 = 0.760403 loss)
I0506 04:51:25.559020 12834 sgd_solver.cpp:106] Iteration 133800, lr = 5.49756e-06
I0506 04:51:25.563750 12834 solver.cpp:242] Iteration 133800 (106.632 iter/s, 0.937801s/100 iter), loss = 0.385657
I0506 04:51:25.563773 12834 solver.cpp:261]     Train net output #0: loss = 0.385657 (* 1 = 0.385657 loss)
I0506 04:51:25.563782 12834 sgd_solver.cpp:106] Iteration 133800, lr = 5.49756e-06
I0506 04:51:26.497208 12834 solver.cpp:242] Iteration 133900 (106.59 iter/s, 0.938171s/100 iter), loss = 1.28048
I0506 04:51:26.497249 12834 solver.cpp:261]     Train net output #0: loss = 1.28048 (* 1 = 1.28048 loss)
I0506 04:51:26.497258 12834 sgd_solver.cpp:106] Iteration 133900, lr = 5.49756e-06
I0506 04:51:26.502030 12834 solver.cpp:242] Iteration 133900 (106.583 iter/s, 0.938238s/100 iter), loss = 0.505574
I0506 04:51:26.502065 12834 solver.cpp:261]     Train net output #0: loss = 0.505574 (* 1 = 0.505574 loss)
I0506 04:51:26.502076 12834 sgd_solver.cpp:106] Iteration 133900, lr = 5.49756e-06
I0506 04:51:27.445981 12834 solver.cpp:362] Iteration 134000, Testing net (#0)
I0506 04:51:27.446007 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:27.568703 12834 solver.cpp:429]     Test net output #0: loss = 1.23972 (* 1 = 1.23972 loss)
I0506 04:51:27.571275 12834 solver.cpp:242] Iteration 134000 (93.1093 iter/s, 1.07401s/100 iter), loss = 2.18413
I0506 04:51:27.571298 12834 solver.cpp:261]     Train net output #0: loss = 2.18413 (* 1 = 2.18413 loss)
I0506 04:51:27.571307 12834 sgd_solver.cpp:106] Iteration 134000, lr = 5.49756e-06
I0506 04:51:27.573165 12834 solver.cpp:362] Iteration 134000, Testing net (#0)
I0506 04:51:27.573179 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:27.701874 12834 solver.cpp:429]     Test net output #0: accuracy = 0.781
I0506 04:51:27.701894 12834 solver.cpp:429]     Test net output #1: loss = 0.50464 (* 1 = 0.50464 loss)
I0506 04:51:27.704442 12834 solver.cpp:242] Iteration 134000 (83.17 iter/s, 1.20236s/100 iter), loss = 0.588065
I0506 04:51:27.704463 12834 solver.cpp:261]     Train net output #0: loss = 0.588065 (* 1 = 0.588065 loss)
I0506 04:51:27.704473 12834 sgd_solver.cpp:106] Iteration 134000, lr = 5.49756e-06
I0506 04:51:28.637197 12834 solver.cpp:242] Iteration 134100 (93.8201 iter/s, 1.06587s/100 iter), loss = 0.420932
I0506 04:51:28.637238 12834 solver.cpp:261]     Train net output #0: loss = 0.420932 (* 1 = 0.420932 loss)
I0506 04:51:28.637246 12834 sgd_solver.cpp:106] Iteration 134100, lr = 5.49756e-06
I0506 04:51:28.642015 12834 solver.cpp:242] Iteration 134100 (106.663 iter/s, 0.937533s/100 iter), loss = 0.337014
I0506 04:51:28.642040 12834 solver.cpp:261]     Train net output #0: loss = 0.337014 (* 1 = 0.337014 loss)
I0506 04:51:28.642050 12834 sgd_solver.cpp:106] Iteration 134100, lr = 5.49756e-06
I0506 04:51:29.574910 12834 solver.cpp:242] Iteration 134200 (106.651 iter/s, 0.937641s/100 iter), loss = 1.09131
I0506 04:51:29.574950 12834 solver.cpp:261]     Train net output #0: loss = 1.09131 (* 1 = 1.09131 loss)
I0506 04:51:29.574959 12834 sgd_solver.cpp:106] Iteration 134200, lr = 5.49756e-06
I0506 04:51:29.579702 12834 solver.cpp:242] Iteration 134200 (106.65 iter/s, 0.937645s/100 iter), loss = 0.692094
I0506 04:51:29.579727 12834 solver.cpp:261]     Train net output #0: loss = 0.692094 (* 1 = 0.692094 loss)
I0506 04:51:29.579736 12834 sgd_solver.cpp:106] Iteration 134200, lr = 5.49756e-06
I0506 04:51:30.512380 12834 solver.cpp:242] Iteration 134300 (106.677 iter/s, 0.937405s/100 iter), loss = 0.860896
I0506 04:51:30.512421 12834 solver.cpp:261]     Train net output #0: loss = 0.860896 (* 1 = 0.860896 loss)
I0506 04:51:30.512431 12834 sgd_solver.cpp:106] Iteration 134300, lr = 5.49756e-06
I0506 04:51:30.517158 12834 solver.cpp:242] Iteration 134300 (106.677 iter/s, 0.937411s/100 iter), loss = 0.440205
I0506 04:51:30.517181 12834 solver.cpp:261]     Train net output #0: loss = 0.440205 (* 1 = 0.440205 loss)
I0506 04:51:30.517190 12834 sgd_solver.cpp:106] Iteration 134300, lr = 5.49756e-06
I0506 04:51:31.522204 12834 solver.cpp:242] Iteration 134400 (99.0343 iter/s, 1.00975s/100 iter), loss = 1.54906
I0506 04:51:31.522241 12834 solver.cpp:261]     Train net output #0: loss = 1.54906 (* 1 = 1.54906 loss)
I0506 04:51:31.522251 12834 sgd_solver.cpp:106] Iteration 134400, lr = 5.49756e-06
I0506 04:51:31.526955 12834 solver.cpp:242] Iteration 134400 (99.034 iter/s, 1.00975s/100 iter), loss = 0.443844
I0506 04:51:31.526980 12834 solver.cpp:261]     Train net output #0: loss = 0.443844 (* 1 = 0.443844 loss)
I0506 04:51:31.526990 12834 sgd_solver.cpp:106] Iteration 134400, lr = 5.49756e-06
I0506 04:51:32.457142 12834 solver.cpp:362] Iteration 134500, Testing net (#0)
I0506 04:51:32.457167 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:32.579742 12834 solver.cpp:429]     Test net output #0: loss = 1.19249 (* 1 = 1.19249 loss)
I0506 04:51:32.582646 12834 solver.cpp:242] Iteration 134500 (94.3052 iter/s, 1.06039s/100 iter), loss = 1.13153
I0506 04:51:32.582667 12834 solver.cpp:261]     Train net output #0: loss = 1.13153 (* 1 = 1.13153 loss)
I0506 04:51:32.582676 12834 sgd_solver.cpp:106] Iteration 134500, lr = 5.49756e-06
I0506 04:51:32.584606 12834 solver.cpp:362] Iteration 134500, Testing net (#0)
I0506 04:51:32.584619 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:32.713299 12834 solver.cpp:429]     Test net output #0: accuracy = 0.764
I0506 04:51:32.713316 12834 solver.cpp:429]     Test net output #1: loss = 0.529056 (* 1 = 0.529056 loss)
I0506 04:51:32.715884 12834 solver.cpp:242] Iteration 134500 (84.1126 iter/s, 1.18888s/100 iter), loss = 0.469673
I0506 04:51:32.715904 12834 solver.cpp:261]     Train net output #0: loss = 0.469673 (* 1 = 0.469673 loss)
I0506 04:51:32.715912 12834 sgd_solver.cpp:106] Iteration 134500, lr = 5.49756e-06
I0506 04:51:33.648977 12834 solver.cpp:242] Iteration 134600 (93.784 iter/s, 1.06628s/100 iter), loss = 0.647981
I0506 04:51:33.649015 12834 solver.cpp:261]     Train net output #0: loss = 0.647981 (* 1 = 0.647981 loss)
I0506 04:51:33.649025 12834 sgd_solver.cpp:106] Iteration 134600, lr = 5.49756e-06
I0506 04:51:33.653726 12834 solver.cpp:242] Iteration 134600 (106.632 iter/s, 0.937804s/100 iter), loss = 0.633839
I0506 04:51:33.653750 12834 solver.cpp:261]     Train net output #0: loss = 0.633839 (* 1 = 0.633839 loss)
I0506 04:51:33.653759 12834 sgd_solver.cpp:106] Iteration 134600, lr = 5.49756e-06
I0506 04:51:34.586529 12834 solver.cpp:242] Iteration 134700 (106.668 iter/s, 0.93749s/100 iter), loss = 0.903634
I0506 04:51:34.586568 12834 solver.cpp:261]     Train net output #0: loss = 0.903634 (* 1 = 0.903634 loss)
I0506 04:51:34.586578 12834 sgd_solver.cpp:106] Iteration 134700, lr = 5.49756e-06
I0506 04:51:34.591398 12834 solver.cpp:242] Iteration 134700 (106.653 iter/s, 0.93762s/100 iter), loss = 0.404975
I0506 04:51:34.591423 12834 solver.cpp:261]     Train net output #0: loss = 0.404975 (* 1 = 0.404975 loss)
I0506 04:51:34.591433 12834 sgd_solver.cpp:106] Iteration 134700, lr = 5.49756e-06
I0506 04:51:35.523784 12834 solver.cpp:242] Iteration 134800 (106.702 iter/s, 0.937189s/100 iter), loss = 0.464423
I0506 04:51:35.523821 12834 solver.cpp:261]     Train net output #0: loss = 0.464423 (* 1 = 0.464423 loss)
I0506 04:51:35.523830 12834 sgd_solver.cpp:106] Iteration 134800, lr = 5.49756e-06
I0506 04:51:35.528580 12834 solver.cpp:242] Iteration 134800 (106.708 iter/s, 0.937139s/100 iter), loss = 0.389459
I0506 04:51:35.528605 12834 solver.cpp:261]     Train net output #0: loss = 0.389459 (* 1 = 0.389459 loss)
I0506 04:51:35.528614 12834 sgd_solver.cpp:106] Iteration 134800, lr = 5.49756e-06
I0506 04:51:36.461251 12834 solver.cpp:242] Iteration 134900 (106.678 iter/s, 0.9374s/100 iter), loss = 0.726611
I0506 04:51:36.461285 12834 solver.cpp:261]     Train net output #0: loss = 0.726611 (* 1 = 0.726611 loss)
I0506 04:51:36.461295 12834 sgd_solver.cpp:106] Iteration 134900, lr = 5.49756e-06
I0506 04:51:36.466022 12834 solver.cpp:242] Iteration 134900 (106.678 iter/s, 0.937398s/100 iter), loss = 0.455891
I0506 04:51:36.466055 12834 solver.cpp:261]     Train net output #0: loss = 0.455891 (* 1 = 0.455891 loss)
I0506 04:51:36.466065 12834 sgd_solver.cpp:106] Iteration 134900, lr = 5.49756e-06
I0506 04:51:37.395831 12834 solver.cpp:362] Iteration 135000, Testing net (#0)
I0506 04:51:37.395851 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:37.518581 12834 solver.cpp:429]     Test net output #0: loss = 1.19657 (* 1 = 1.19657 loss)
I0506 04:51:37.521096 12834 solver.cpp:242] Iteration 135000 (94.3581 iter/s, 1.05979s/100 iter), loss = 1.56558
I0506 04:51:37.521116 12834 solver.cpp:261]     Train net output #0: loss = 1.56558 (* 1 = 1.56558 loss)
I0506 04:51:37.521126 12834 sgd_solver.cpp:106] Iteration 135000, lr = 5.49756e-06
I0506 04:51:37.522944 12834 solver.cpp:362] Iteration 135000, Testing net (#0)
I0506 04:51:37.522964 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:37.651628 12834 solver.cpp:429]     Test net output #0: accuracy = 0.787
I0506 04:51:37.651648 12834 solver.cpp:429]     Test net output #1: loss = 0.516806 (* 1 = 0.516806 loss)
I0506 04:51:37.654223 12834 solver.cpp:242] Iteration 135000 (84.1647 iter/s, 1.18815s/100 iter), loss = 0.451233
I0506 04:51:37.654244 12834 solver.cpp:261]     Train net output #0: loss = 0.451233 (* 1 = 0.451233 loss)
I0506 04:51:37.654253 12834 sgd_solver.cpp:106] Iteration 135000, lr = 5.49756e-06
I0506 04:51:38.588086 12834 solver.cpp:242] Iteration 135100 (93.7264 iter/s, 1.06694s/100 iter), loss = 3.21547
I0506 04:51:38.588129 12834 solver.cpp:261]     Train net output #0: loss = 3.21547 (* 1 = 3.21547 loss)
I0506 04:51:38.588137 12834 sgd_solver.cpp:106] Iteration 135100, lr = 5.49756e-06
I0506 04:51:38.592869 12834 solver.cpp:242] Iteration 135100 (106.541 iter/s, 0.938607s/100 iter), loss = 0.510589
I0506 04:51:38.592895 12834 solver.cpp:261]     Train net output #0: loss = 0.510589 (* 1 = 0.510589 loss)
I0506 04:51:38.592903 12834 sgd_solver.cpp:106] Iteration 135100, lr = 5.49756e-06
I0506 04:51:39.525737 12834 solver.cpp:242] Iteration 135200 (106.657 iter/s, 0.937583s/100 iter), loss = 0.833774
I0506 04:51:39.525775 12834 solver.cpp:261]     Train net output #0: loss = 0.833774 (* 1 = 0.833774 loss)
I0506 04:51:39.525784 12834 sgd_solver.cpp:106] Iteration 135200, lr = 5.49756e-06
I0506 04:51:39.530506 12834 solver.cpp:242] Iteration 135200 (106.656 iter/s, 0.937594s/100 iter), loss = 0.432933
I0506 04:51:39.530530 12834 solver.cpp:261]     Train net output #0: loss = 0.432933 (* 1 = 0.432933 loss)
I0506 04:51:39.530539 12834 sgd_solver.cpp:106] Iteration 135200, lr = 5.49756e-06
I0506 04:51:40.463778 12834 solver.cpp:242] Iteration 135300 (106.613 iter/s, 0.93797s/100 iter), loss = 0.824147
I0506 04:51:40.463817 12834 solver.cpp:261]     Train net output #0: loss = 0.824147 (* 1 = 0.824147 loss)
I0506 04:51:40.463827 12834 sgd_solver.cpp:106] Iteration 135300, lr = 5.49756e-06
I0506 04:51:40.468574 12834 solver.cpp:242] Iteration 135300 (106.607 iter/s, 0.938024s/100 iter), loss = 0.538469
I0506 04:51:40.468600 12834 solver.cpp:261]     Train net output #0: loss = 0.538469 (* 1 = 0.538469 loss)
I0506 04:51:40.468607 12834 sgd_solver.cpp:106] Iteration 135300, lr = 5.49756e-06
I0506 04:51:41.401873 12834 solver.cpp:242] Iteration 135400 (106.606 iter/s, 0.938031s/100 iter), loss = 1.09574
I0506 04:51:41.401912 12834 solver.cpp:261]     Train net output #0: loss = 1.09574 (* 1 = 1.09574 loss)
I0506 04:51:41.401921 12834 sgd_solver.cpp:106] Iteration 135400, lr = 5.49756e-06
I0506 04:51:41.406723 12834 solver.cpp:242] Iteration 135400 (106.599 iter/s, 0.938094s/100 iter), loss = 0.513583
I0506 04:51:41.406747 12834 solver.cpp:261]     Train net output #0: loss = 0.513583 (* 1 = 0.513583 loss)
I0506 04:51:41.406756 12834 sgd_solver.cpp:106] Iteration 135400, lr = 5.49756e-06
I0506 04:51:42.336845 12834 solver.cpp:362] Iteration 135500, Testing net (#0)
I0506 04:51:42.336872 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:42.459506 12834 solver.cpp:429]     Test net output #0: loss = 1.2576 (* 1 = 1.2576 loss)
I0506 04:51:42.462029 12834 solver.cpp:242] Iteration 135500 (94.3309 iter/s, 1.0601s/100 iter), loss = 2.4529
I0506 04:51:42.462054 12834 solver.cpp:261]     Train net output #0: loss = 2.4529 (* 1 = 2.4529 loss)
I0506 04:51:42.462062 12834 sgd_solver.cpp:106] Iteration 135500, lr = 5.49756e-06
I0506 04:51:42.463877 12834 solver.cpp:362] Iteration 135500, Testing net (#0)
I0506 04:51:42.463889 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:42.594099 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7625
I0506 04:51:42.594122 12834 solver.cpp:429]     Test net output #1: loss = 0.516653 (* 1 = 0.516653 loss)
I0506 04:51:42.596808 12834 solver.cpp:242] Iteration 135500 (84.0308 iter/s, 1.19004s/100 iter), loss = 0.862159
I0506 04:51:42.596833 12834 solver.cpp:261]     Train net output #0: loss = 0.862159 (* 1 = 0.862159 loss)
I0506 04:51:42.596854 12834 sgd_solver.cpp:106] Iteration 135500, lr = 5.49756e-06
I0506 04:51:43.544190 12834 solver.cpp:242] Iteration 135600 (92.4121 iter/s, 1.08211s/100 iter), loss = 0.34159
I0506 04:51:43.544231 12834 solver.cpp:261]     Train net output #0: loss = 0.34159 (* 1 = 0.34159 loss)
I0506 04:51:43.544240 12834 sgd_solver.cpp:106] Iteration 135600, lr = 5.49756e-06
I0506 04:51:43.549082 12834 solver.cpp:242] Iteration 135600 (105.017 iter/s, 0.952223s/100 iter), loss = 0.230983
I0506 04:51:43.549108 12834 solver.cpp:261]     Train net output #0: loss = 0.230983 (* 1 = 0.230983 loss)
I0506 04:51:43.549116 12834 sgd_solver.cpp:106] Iteration 135600, lr = 5.49756e-06
I0506 04:51:44.482121 12834 solver.cpp:242] Iteration 135700 (106.625 iter/s, 0.937864s/100 iter), loss = 1.23375
I0506 04:51:44.482159 12834 solver.cpp:261]     Train net output #0: loss = 1.23375 (* 1 = 1.23375 loss)
I0506 04:51:44.482169 12834 sgd_solver.cpp:106] Iteration 135700, lr = 5.49756e-06
I0506 04:51:44.486901 12834 solver.cpp:242] Iteration 135700 (106.635 iter/s, 0.937775s/100 iter), loss = 0.253841
I0506 04:51:44.486925 12834 solver.cpp:261]     Train net output #0: loss = 0.253841 (* 1 = 0.253841 loss)
I0506 04:51:44.486934 12834 sgd_solver.cpp:106] Iteration 135700, lr = 5.49756e-06
I0506 04:51:45.431525 12834 solver.cpp:242] Iteration 135800 (105.337 iter/s, 0.949333s/100 iter), loss = 1.53545
I0506 04:51:45.431565 12834 solver.cpp:261]     Train net output #0: loss = 1.53545 (* 1 = 1.53545 loss)
I0506 04:51:45.431573 12834 sgd_solver.cpp:106] Iteration 135800, lr = 5.49756e-06
I0506 04:51:45.436313 12834 solver.cpp:242] Iteration 135800 (105.333 iter/s, 0.94937s/100 iter), loss = 0.614793
I0506 04:51:45.436339 12834 solver.cpp:261]     Train net output #0: loss = 0.614793 (* 1 = 0.614793 loss)
I0506 04:51:45.436348 12834 sgd_solver.cpp:106] Iteration 135800, lr = 5.49756e-06
I0506 04:51:46.369287 12834 solver.cpp:242] Iteration 135900 (106.644 iter/s, 0.937696s/100 iter), loss = 2.71163
I0506 04:51:46.369323 12834 solver.cpp:261]     Train net output #0: loss = 2.71163 (* 1 = 2.71163 loss)
I0506 04:51:46.369333 12834 sgd_solver.cpp:106] Iteration 135900, lr = 5.49756e-06
I0506 04:51:46.374058 12834 solver.cpp:242] Iteration 135900 (106.644 iter/s, 0.9377s/100 iter), loss = 0.790303
I0506 04:51:46.374083 12834 solver.cpp:261]     Train net output #0: loss = 0.790303 (* 1 = 0.790303 loss)
I0506 04:51:46.374092 12834 sgd_solver.cpp:106] Iteration 135900, lr = 5.49756e-06
I0506 04:51:47.304412 12834 solver.cpp:362] Iteration 136000, Testing net (#0)
I0506 04:51:47.304435 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:47.427134 12834 solver.cpp:429]     Test net output #0: loss = 1.3127 (* 1 = 1.3127 loss)
I0506 04:51:47.429649 12834 solver.cpp:242] Iteration 136000 (94.3123 iter/s, 1.06031s/100 iter), loss = 0.559113
I0506 04:51:47.429669 12834 solver.cpp:261]     Train net output #0: loss = 0.559113 (* 1 = 0.559113 loss)
I0506 04:51:47.429678 12834 sgd_solver.cpp:106] Iteration 136000, lr = 5.49756e-06
I0506 04:51:47.431493 12834 solver.cpp:362] Iteration 136000, Testing net (#0)
I0506 04:51:47.431506 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:47.560416 12834 solver.cpp:429]     Test net output #0: accuracy = 0.773
I0506 04:51:47.560437 12834 solver.cpp:429]     Test net output #1: loss = 0.530244 (* 1 = 0.530244 loss)
I0506 04:51:47.563010 12834 solver.cpp:242] Iteration 136000 (84.111 iter/s, 1.18891s/100 iter), loss = 0.567646
I0506 04:51:47.563030 12834 solver.cpp:261]     Train net output #0: loss = 0.567646 (* 1 = 0.567646 loss)
I0506 04:51:47.563040 12834 sgd_solver.cpp:106] Iteration 136000, lr = 5.49756e-06
I0506 04:51:48.496361 12834 solver.cpp:242] Iteration 136100 (93.7502 iter/s, 1.06666s/100 iter), loss = 0.578963
I0506 04:51:48.496397 12834 solver.cpp:261]     Train net output #0: loss = 0.578963 (* 1 = 0.578963 loss)
I0506 04:51:48.496407 12834 sgd_solver.cpp:106] Iteration 136100, lr = 5.49756e-06
I0506 04:51:48.501137 12834 solver.cpp:242] Iteration 136100 (106.6 iter/s, 0.938087s/100 iter), loss = 0.484919
I0506 04:51:48.501173 12834 solver.cpp:261]     Train net output #0: loss = 0.484919 (* 1 = 0.484919 loss)
I0506 04:51:48.501183 12834 sgd_solver.cpp:106] Iteration 136100, lr = 5.49756e-06
I0506 04:51:49.434231 12834 solver.cpp:242] Iteration 136200 (106.632 iter/s, 0.937803s/100 iter), loss = 1.81721
I0506 04:51:49.434260 12834 solver.cpp:261]     Train net output #0: loss = 1.81721 (* 1 = 1.81721 loss)
I0506 04:51:49.434269 12834 sgd_solver.cpp:106] Iteration 136200, lr = 5.49756e-06
I0506 04:51:49.438987 12834 solver.cpp:242] Iteration 136200 (106.633 iter/s, 0.937795s/100 iter), loss = 0.539282
I0506 04:51:49.439009 12834 solver.cpp:261]     Train net output #0: loss = 0.539282 (* 1 = 0.539282 loss)
I0506 04:51:49.439018 12834 sgd_solver.cpp:106] Iteration 136200, lr = 5.49756e-06
I0506 04:51:50.382524 12834 solver.cpp:242] Iteration 136300 (105.458 iter/s, 0.94824s/100 iter), loss = 6.22935
I0506 04:51:50.382563 12834 solver.cpp:261]     Train net output #0: loss = 6.22935 (* 1 = 6.22935 loss)
I0506 04:51:50.382572 12834 sgd_solver.cpp:106] Iteration 136300, lr = 5.49756e-06
I0506 04:51:50.387388 12834 solver.cpp:242] Iteration 136300 (105.446 iter/s, 0.94835s/100 iter), loss = 0.679458
I0506 04:51:50.387413 12834 solver.cpp:261]     Train net output #0: loss = 0.679458 (* 1 = 0.679458 loss)
I0506 04:51:50.387421 12834 sgd_solver.cpp:106] Iteration 136300, lr = 5.49756e-06
I0506 04:51:51.320057 12834 solver.cpp:242] Iteration 136400 (106.671 iter/s, 0.937466s/100 iter), loss = 1.12235
I0506 04:51:51.320097 12834 solver.cpp:261]     Train net output #0: loss = 1.12235 (* 1 = 1.12235 loss)
I0506 04:51:51.320107 12834 sgd_solver.cpp:106] Iteration 136400, lr = 5.49756e-06
I0506 04:51:51.324827 12834 solver.cpp:242] Iteration 136400 (106.678 iter/s, 0.937397s/100 iter), loss = 0.419042
I0506 04:51:51.324852 12834 solver.cpp:261]     Train net output #0: loss = 0.419042 (* 1 = 0.419042 loss)
I0506 04:51:51.324862 12834 sgd_solver.cpp:106] Iteration 136400, lr = 5.49756e-06
I0506 04:51:52.255110 12834 solver.cpp:362] Iteration 136500, Testing net (#0)
I0506 04:51:52.255137 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:52.377761 12834 solver.cpp:429]     Test net output #0: loss = 1.21831 (* 1 = 1.21831 loss)
I0506 04:51:52.380287 12834 solver.cpp:242] Iteration 136500 (94.3246 iter/s, 1.06017s/100 iter), loss = 0.742471
I0506 04:51:52.380311 12834 solver.cpp:261]     Train net output #0: loss = 0.742471 (* 1 = 0.742471 loss)
I0506 04:51:52.380321 12834 sgd_solver.cpp:106] Iteration 136500, lr = 5.49756e-06
I0506 04:51:52.382210 12834 solver.cpp:362] Iteration 136500, Testing net (#0)
I0506 04:51:52.382225 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:52.510849 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:51:52.510869 12834 solver.cpp:429]     Test net output #1: loss = 0.517014 (* 1 = 0.517014 loss)
I0506 04:51:52.513427 12834 solver.cpp:242] Iteration 136500 (84.1359 iter/s, 1.18855s/100 iter), loss = 0.407415
I0506 04:51:52.513447 12834 solver.cpp:261]     Train net output #0: loss = 0.407415 (* 1 = 0.407415 loss)
I0506 04:51:52.513456 12834 sgd_solver.cpp:106] Iteration 136500, lr = 5.49756e-06
I0506 04:51:53.446214 12834 solver.cpp:242] Iteration 136600 (93.8199 iter/s, 1.06587s/100 iter), loss = 0.53384
I0506 04:51:53.446259 12834 solver.cpp:261]     Train net output #0: loss = 0.53384 (* 1 = 0.53384 loss)
I0506 04:51:53.446269 12834 sgd_solver.cpp:106] Iteration 136600, lr = 5.49756e-06
I0506 04:51:53.450992 12834 solver.cpp:242] Iteration 136600 (106.664 iter/s, 0.937526s/100 iter), loss = 0.275924
I0506 04:51:53.451020 12834 solver.cpp:261]     Train net output #0: loss = 0.275924 (* 1 = 0.275924 loss)
I0506 04:51:53.451028 12834 sgd_solver.cpp:106] Iteration 136600, lr = 5.49756e-06
I0506 04:51:54.383896 12834 solver.cpp:242] Iteration 136700 (106.655 iter/s, 0.937605s/100 iter), loss = 0.637398
I0506 04:51:54.383936 12834 solver.cpp:261]     Train net output #0: loss = 0.637398 (* 1 = 0.637398 loss)
I0506 04:51:54.383955 12834 sgd_solver.cpp:106] Iteration 136700, lr = 5.49756e-06
I0506 04:51:54.388681 12834 solver.cpp:242] Iteration 136700 (106.65 iter/s, 0.937644s/100 iter), loss = 0.523723
I0506 04:51:54.388708 12834 solver.cpp:261]     Train net output #0: loss = 0.523723 (* 1 = 0.523723 loss)
I0506 04:51:54.388717 12834 sgd_solver.cpp:106] Iteration 136700, lr = 5.49756e-06
I0506 04:51:55.321682 12834 solver.cpp:242] Iteration 136800 (106.642 iter/s, 0.937721s/100 iter), loss = 1.238
I0506 04:51:55.321720 12834 solver.cpp:261]     Train net output #0: loss = 1.238 (* 1 = 1.238 loss)
I0506 04:51:55.321730 12834 sgd_solver.cpp:106] Iteration 136800, lr = 5.49756e-06
I0506 04:51:55.326463 12834 solver.cpp:242] Iteration 136800 (106.64 iter/s, 0.937737s/100 iter), loss = 0.685906
I0506 04:51:55.326488 12834 solver.cpp:261]     Train net output #0: loss = 0.685906 (* 1 = 0.685906 loss)
I0506 04:51:55.326498 12834 sgd_solver.cpp:106] Iteration 136800, lr = 5.49756e-06
I0506 04:51:56.259475 12834 solver.cpp:242] Iteration 136900 (106.641 iter/s, 0.937723s/100 iter), loss = 0.961161
I0506 04:51:56.259515 12834 solver.cpp:261]     Train net output #0: loss = 0.961161 (* 1 = 0.961161 loss)
I0506 04:51:56.259524 12834 sgd_solver.cpp:106] Iteration 136900, lr = 5.49756e-06
I0506 04:51:56.264258 12834 solver.cpp:242] Iteration 136900 (106.638 iter/s, 0.937753s/100 iter), loss = 0.471687
I0506 04:51:56.264282 12834 solver.cpp:261]     Train net output #0: loss = 0.471687 (* 1 = 0.471687 loss)
I0506 04:51:56.264292 12834 sgd_solver.cpp:106] Iteration 136900, lr = 5.49756e-06
I0506 04:51:57.194080 12834 solver.cpp:362] Iteration 137000, Testing net (#0)
I0506 04:51:57.194105 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:57.316804 12834 solver.cpp:429]     Test net output #0: loss = 1.28109 (* 1 = 1.28109 loss)
I0506 04:51:57.319315 12834 solver.cpp:242] Iteration 137000 (94.3591 iter/s, 1.05978s/100 iter), loss = 0.810528
I0506 04:51:57.319335 12834 solver.cpp:261]     Train net output #0: loss = 0.810528 (* 1 = 0.810528 loss)
I0506 04:51:57.319344 12834 sgd_solver.cpp:106] Iteration 137000, lr = 5.49756e-06
I0506 04:51:57.321172 12834 solver.cpp:362] Iteration 137000, Testing net (#0)
I0506 04:51:57.321187 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:51:57.449872 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7615
I0506 04:51:57.449892 12834 solver.cpp:429]     Test net output #1: loss = 0.539748 (* 1 = 0.539748 loss)
I0506 04:51:57.452436 12834 solver.cpp:242] Iteration 137000 (84.1656 iter/s, 1.18813s/100 iter), loss = 0.414824
I0506 04:51:57.452456 12834 solver.cpp:261]     Train net output #0: loss = 0.414824 (* 1 = 0.414824 loss)
I0506 04:51:57.452464 12834 sgd_solver.cpp:106] Iteration 137000, lr = 5.49756e-06
I0506 04:51:58.385270 12834 solver.cpp:242] Iteration 137100 (93.8173 iter/s, 1.0659s/100 iter), loss = 1.46351
I0506 04:51:58.385310 12834 solver.cpp:261]     Train net output #0: loss = 1.46351 (* 1 = 1.46351 loss)
I0506 04:51:58.385319 12834 sgd_solver.cpp:106] Iteration 137100, lr = 5.49756e-06
I0506 04:51:58.390094 12834 solver.cpp:242] Iteration 137100 (106.653 iter/s, 0.937618s/100 iter), loss = 0.627261
I0506 04:51:58.390120 12834 solver.cpp:261]     Train net output #0: loss = 0.627261 (* 1 = 0.627261 loss)
I0506 04:51:58.390127 12834 sgd_solver.cpp:106] Iteration 137100, lr = 5.49756e-06
I0506 04:51:59.353133 12834 solver.cpp:242] Iteration 137200 (103.327 iter/s, 0.967799s/100 iter), loss = 1.10768
I0506 04:51:59.353169 12834 solver.cpp:261]     Train net output #0: loss = 1.10768 (* 1 = 1.10768 loss)
I0506 04:51:59.353179 12834 sgd_solver.cpp:106] Iteration 137200, lr = 5.49756e-06
I0506 04:51:59.357975 12834 solver.cpp:242] Iteration 137200 (103.324 iter/s, 0.967826s/100 iter), loss = 0.942368
I0506 04:51:59.357997 12834 solver.cpp:261]     Train net output #0: loss = 0.942368 (* 1 = 0.942368 loss)
I0506 04:51:59.358007 12834 sgd_solver.cpp:106] Iteration 137200, lr = 5.49756e-06
I0506 04:52:00.371851 12834 solver.cpp:242] Iteration 137300 (98.1694 iter/s, 1.01865s/100 iter), loss = 0.854466
I0506 04:52:00.371924 12834 solver.cpp:261]     Train net output #0: loss = 0.854466 (* 1 = 0.854466 loss)
I0506 04:52:00.371937 12834 sgd_solver.cpp:106] Iteration 137300, lr = 5.49756e-06
I0506 04:52:00.377208 12834 solver.cpp:242] Iteration 137300 (98.1172 iter/s, 1.01919s/100 iter), loss = 0.666461
I0506 04:52:00.377243 12834 solver.cpp:261]     Train net output #0: loss = 0.666461 (* 1 = 0.666461 loss)
I0506 04:52:00.377254 12834 sgd_solver.cpp:106] Iteration 137300, lr = 5.49756e-06
I0506 04:52:01.415858 12834 solver.cpp:242] Iteration 137400 (95.7936 iter/s, 1.04391s/100 iter), loss = 0.370519
I0506 04:52:01.415900 12834 solver.cpp:261]     Train net output #0: loss = 0.370519 (* 1 = 0.370519 loss)
I0506 04:52:01.415911 12834 sgd_solver.cpp:106] Iteration 137400, lr = 5.49756e-06
I0506 04:52:01.421289 12834 solver.cpp:242] Iteration 137400 (95.784 iter/s, 1.04402s/100 iter), loss = 0.530211
I0506 04:52:01.421321 12834 solver.cpp:261]     Train net output #0: loss = 0.530211 (* 1 = 0.530211 loss)
I0506 04:52:01.421334 12834 sgd_solver.cpp:106] Iteration 137400, lr = 5.49756e-06
I0506 04:52:02.388262 12834 solver.cpp:362] Iteration 137500, Testing net (#0)
I0506 04:52:02.388284 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:02.512677 12834 solver.cpp:429]     Test net output #0: loss = 1.28319 (* 1 = 1.28319 loss)
I0506 04:52:02.515216 12834 solver.cpp:242] Iteration 137500 (90.9671 iter/s, 1.0993s/100 iter), loss = 0.598633
I0506 04:52:02.515238 12834 solver.cpp:261]     Train net output #0: loss = 0.598633 (* 1 = 0.598633 loss)
I0506 04:52:02.515246 12834 sgd_solver.cpp:106] Iteration 137500, lr = 5.49756e-06
I0506 04:52:02.517156 12834 solver.cpp:362] Iteration 137500, Testing net (#0)
I0506 04:52:02.517170 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:02.653780 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7745
I0506 04:52:02.653805 12834 solver.cpp:429]     Test net output #1: loss = 0.509111 (* 1 = 0.509111 loss)
I0506 04:52:02.656494 12834 solver.cpp:242] Iteration 137500 (80.9617 iter/s, 1.23515s/100 iter), loss = 0.56828
I0506 04:52:02.656518 12834 solver.cpp:261]     Train net output #0: loss = 0.56828 (* 1 = 0.56828 loss)
I0506 04:52:02.656529 12834 sgd_solver.cpp:106] Iteration 137500, lr = 5.49756e-06
I0506 04:52:03.602756 12834 solver.cpp:242] Iteration 137600 (91.9554 iter/s, 1.08748s/100 iter), loss = 0.465279
I0506 04:52:03.602792 12834 solver.cpp:261]     Train net output #0: loss = 0.465279 (* 1 = 0.465279 loss)
I0506 04:52:03.602802 12834 sgd_solver.cpp:106] Iteration 137600, lr = 5.49756e-06
I0506 04:52:03.607564 12834 solver.cpp:242] Iteration 137600 (105.149 iter/s, 0.951029s/100 iter), loss = 0.346333
I0506 04:52:03.607589 12834 solver.cpp:261]     Train net output #0: loss = 0.346333 (* 1 = 0.346333 loss)
I0506 04:52:03.607597 12834 sgd_solver.cpp:106] Iteration 137600, lr = 5.49756e-06
I0506 04:52:04.563201 12834 solver.cpp:242] Iteration 137700 (104.125 iter/s, 0.960384s/100 iter), loss = 0.950249
I0506 04:52:04.563232 12834 solver.cpp:261]     Train net output #0: loss = 0.950249 (* 1 = 0.950249 loss)
I0506 04:52:04.563241 12834 sgd_solver.cpp:106] Iteration 137700, lr = 5.49756e-06
I0506 04:52:04.567958 12834 solver.cpp:242] Iteration 137700 (104.129 iter/s, 0.960351s/100 iter), loss = 0.381548
I0506 04:52:04.567982 12834 solver.cpp:261]     Train net output #0: loss = 0.381548 (* 1 = 0.381548 loss)
I0506 04:52:04.567991 12834 sgd_solver.cpp:106] Iteration 137700, lr = 5.49756e-06
I0506 04:52:05.501364 12834 solver.cpp:242] Iteration 137800 (106.599 iter/s, 0.938099s/100 iter), loss = 1.67754
I0506 04:52:05.501407 12834 solver.cpp:261]     Train net output #0: loss = 1.67754 (* 1 = 1.67754 loss)
I0506 04:52:05.501417 12834 sgd_solver.cpp:106] Iteration 137800, lr = 5.49756e-06
I0506 04:52:05.506147 12834 solver.cpp:242] Iteration 137800 (106.593 iter/s, 0.938147s/100 iter), loss = 0.544293
I0506 04:52:05.506175 12834 solver.cpp:261]     Train net output #0: loss = 0.544293 (* 1 = 0.544293 loss)
I0506 04:52:05.506184 12834 sgd_solver.cpp:106] Iteration 137800, lr = 5.49756e-06
I0506 04:52:06.439631 12834 solver.cpp:242] Iteration 137900 (106.587 iter/s, 0.938198s/100 iter), loss = 2.40687
I0506 04:52:06.439672 12834 solver.cpp:261]     Train net output #0: loss = 2.40687 (* 1 = 2.40687 loss)
I0506 04:52:06.439682 12834 sgd_solver.cpp:106] Iteration 137900, lr = 5.49756e-06
I0506 04:52:06.444413 12834 solver.cpp:242] Iteration 137900 (106.585 iter/s, 0.938221s/100 iter), loss = 0.440339
I0506 04:52:06.444439 12834 solver.cpp:261]     Train net output #0: loss = 0.440339 (* 1 = 0.440339 loss)
I0506 04:52:06.444448 12834 sgd_solver.cpp:106] Iteration 137900, lr = 5.49756e-06
I0506 04:52:07.374248 12834 solver.cpp:362] Iteration 138000, Testing net (#0)
I0506 04:52:07.374275 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:07.497053 12834 solver.cpp:429]     Test net output #0: loss = 1.24769 (* 1 = 1.24769 loss)
I0506 04:52:07.499578 12834 solver.cpp:242] Iteration 138000 (94.3497 iter/s, 1.05989s/100 iter), loss = 1.31482
I0506 04:52:07.499600 12834 solver.cpp:261]     Train net output #0: loss = 1.31482 (* 1 = 1.31482 loss)
I0506 04:52:07.499609 12834 sgd_solver.cpp:106] Iteration 138000, lr = 5.49756e-06
I0506 04:52:07.501462 12834 solver.cpp:362] Iteration 138000, Testing net (#0)
I0506 04:52:07.501476 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:07.630276 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7705
I0506 04:52:07.630295 12834 solver.cpp:429]     Test net output #1: loss = 0.51422 (* 1 = 0.51422 loss)
I0506 04:52:07.632844 12834 solver.cpp:242] Iteration 138000 (84.1479 iter/s, 1.18838s/100 iter), loss = 0.444798
I0506 04:52:07.632865 12834 solver.cpp:261]     Train net output #0: loss = 0.444798 (* 1 = 0.444798 loss)
I0506 04:52:07.632874 12834 sgd_solver.cpp:106] Iteration 138000, lr = 5.49756e-06
I0506 04:52:08.565331 12834 solver.cpp:242] Iteration 138100 (93.8347 iter/s, 1.0657s/100 iter), loss = 2.37402
I0506 04:52:08.565372 12834 solver.cpp:261]     Train net output #0: loss = 2.37402 (* 1 = 2.37402 loss)
I0506 04:52:08.565382 12834 sgd_solver.cpp:106] Iteration 138100, lr = 5.49756e-06
I0506 04:52:08.570196 12834 solver.cpp:242] Iteration 138100 (106.689 iter/s, 0.937302s/100 iter), loss = 0.546106
I0506 04:52:08.570221 12834 solver.cpp:261]     Train net output #0: loss = 0.546106 (* 1 = 0.546106 loss)
I0506 04:52:08.570230 12834 sgd_solver.cpp:106] Iteration 138100, lr = 5.49756e-06
I0506 04:52:09.517267 12834 solver.cpp:242] Iteration 138200 (105.057 iter/s, 0.951866s/100 iter), loss = 3.52363
I0506 04:52:09.517312 12834 solver.cpp:261]     Train net output #0: loss = 3.52363 (* 1 = 3.52363 loss)
I0506 04:52:09.517320 12834 sgd_solver.cpp:106] Iteration 138200, lr = 5.49756e-06
I0506 04:52:09.522060 12834 solver.cpp:242] Iteration 138200 (105.062 iter/s, 0.95182s/100 iter), loss = 0.692312
I0506 04:52:09.522085 12834 solver.cpp:261]     Train net output #0: loss = 0.692312 (* 1 = 0.692312 loss)
I0506 04:52:09.522094 12834 sgd_solver.cpp:106] Iteration 138200, lr = 5.49756e-06
I0506 04:52:10.455196 12834 solver.cpp:242] Iteration 138300 (106.625 iter/s, 0.937862s/100 iter), loss = 0.262416
I0506 04:52:10.455235 12834 solver.cpp:261]     Train net output #0: loss = 0.262416 (* 1 = 0.262416 loss)
I0506 04:52:10.455245 12834 sgd_solver.cpp:106] Iteration 138300, lr = 5.49756e-06
I0506 04:52:10.460062 12834 solver.cpp:242] Iteration 138300 (106.616 iter/s, 0.937948s/100 iter), loss = 0.615482
I0506 04:52:10.460088 12834 solver.cpp:261]     Train net output #0: loss = 0.615482 (* 1 = 0.615482 loss)
I0506 04:52:10.460098 12834 sgd_solver.cpp:106] Iteration 138300, lr = 5.49756e-06
I0506 04:52:11.392688 12834 solver.cpp:242] Iteration 138400 (106.675 iter/s, 0.937425s/100 iter), loss = 0.656603
I0506 04:52:11.392724 12834 solver.cpp:261]     Train net output #0: loss = 0.656603 (* 1 = 0.656603 loss)
I0506 04:52:11.392735 12834 sgd_solver.cpp:106] Iteration 138400, lr = 5.49756e-06
I0506 04:52:11.397476 12834 solver.cpp:242] Iteration 138400 (106.682 iter/s, 0.93737s/100 iter), loss = 0.741156
I0506 04:52:11.397511 12834 solver.cpp:261]     Train net output #0: loss = 0.741156 (* 1 = 0.741156 loss)
I0506 04:52:11.397521 12834 sgd_solver.cpp:106] Iteration 138400, lr = 5.49756e-06
I0506 04:52:12.327630 12834 solver.cpp:362] Iteration 138500, Testing net (#0)
I0506 04:52:12.327656 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:12.450398 12834 solver.cpp:429]     Test net output #0: loss = 1.13217 (* 1 = 1.13217 loss)
I0506 04:52:12.452915 12834 solver.cpp:242] Iteration 138500 (94.3243 iter/s, 1.06017s/100 iter), loss = 0.915436
I0506 04:52:12.452937 12834 solver.cpp:261]     Train net output #0: loss = 0.915436 (* 1 = 0.915436 loss)
I0506 04:52:12.452945 12834 sgd_solver.cpp:106] Iteration 138500, lr = 5.49756e-06
I0506 04:52:12.454758 12834 solver.cpp:362] Iteration 138500, Testing net (#0)
I0506 04:52:12.454771 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:12.584059 12834 solver.cpp:429]     Test net output #0: accuracy = 0.775
I0506 04:52:12.584079 12834 solver.cpp:429]     Test net output #1: loss = 0.516993 (* 1 = 0.516993 loss)
I0506 04:52:12.586634 12834 solver.cpp:242] Iteration 138500 (84.097 iter/s, 1.1891s/100 iter), loss = 0.335626
I0506 04:52:12.586655 12834 solver.cpp:261]     Train net output #0: loss = 0.335626 (* 1 = 0.335626 loss)
I0506 04:52:12.586664 12834 sgd_solver.cpp:106] Iteration 138500, lr = 5.49756e-06
I0506 04:52:13.519481 12834 solver.cpp:242] Iteration 138600 (93.7635 iter/s, 1.06651s/100 iter), loss = 3.61357
I0506 04:52:13.519520 12834 solver.cpp:261]     Train net output #0: loss = 3.61357 (* 1 = 3.61357 loss)
I0506 04:52:13.519528 12834 sgd_solver.cpp:106] Iteration 138600, lr = 5.49756e-06
I0506 04:52:13.524236 12834 solver.cpp:242] Iteration 138600 (106.659 iter/s, 0.937563s/100 iter), loss = 0.732355
I0506 04:52:13.524261 12834 solver.cpp:261]     Train net output #0: loss = 0.732355 (* 1 = 0.732355 loss)
I0506 04:52:13.524271 12834 sgd_solver.cpp:106] Iteration 138600, lr = 5.49756e-06
I0506 04:52:14.457283 12834 solver.cpp:242] Iteration 138700 (106.64 iter/s, 0.937731s/100 iter), loss = 1.3245
I0506 04:52:14.457320 12834 solver.cpp:261]     Train net output #0: loss = 1.3245 (* 1 = 1.3245 loss)
I0506 04:52:14.457329 12834 sgd_solver.cpp:106] Iteration 138700, lr = 5.49756e-06
I0506 04:52:14.462069 12834 solver.cpp:242] Iteration 138700 (106.634 iter/s, 0.937789s/100 iter), loss = 0.750934
I0506 04:52:14.462093 12834 solver.cpp:261]     Train net output #0: loss = 0.750934 (* 1 = 0.750934 loss)
I0506 04:52:14.462103 12834 sgd_solver.cpp:106] Iteration 138700, lr = 5.49756e-06
I0506 04:52:15.410143 12834 solver.cpp:242] Iteration 138800 (104.954 iter/s, 0.952797s/100 iter), loss = 0.514665
I0506 04:52:15.410178 12834 solver.cpp:261]     Train net output #0: loss = 0.514665 (* 1 = 0.514665 loss)
I0506 04:52:15.410187 12834 sgd_solver.cpp:106] Iteration 138800, lr = 5.49756e-06
I0506 04:52:15.414899 12834 solver.cpp:242] Iteration 138800 (104.955 iter/s, 0.952787s/100 iter), loss = 0.345276
I0506 04:52:15.414922 12834 solver.cpp:261]     Train net output #0: loss = 0.345276 (* 1 = 0.345276 loss)
I0506 04:52:15.414932 12834 sgd_solver.cpp:106] Iteration 138800, lr = 5.49756e-06
I0506 04:52:16.347786 12834 solver.cpp:242] Iteration 138900 (106.658 iter/s, 0.937576s/100 iter), loss = 1.6403
I0506 04:52:16.347829 12834 solver.cpp:261]     Train net output #0: loss = 1.6403 (* 1 = 1.6403 loss)
I0506 04:52:16.347838 12834 sgd_solver.cpp:106] Iteration 138900, lr = 5.49756e-06
I0506 04:52:16.352578 12834 solver.cpp:242] Iteration 138900 (106.651 iter/s, 0.937637s/100 iter), loss = 0.72705
I0506 04:52:16.352603 12834 solver.cpp:261]     Train net output #0: loss = 0.72705 (* 1 = 0.72705 loss)
I0506 04:52:16.352612 12834 sgd_solver.cpp:106] Iteration 138900, lr = 5.49756e-06
I0506 04:52:17.282148 12834 solver.cpp:362] Iteration 139000, Testing net (#0)
I0506 04:52:17.282178 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:17.404892 12834 solver.cpp:429]     Test net output #0: loss = 1.42061 (* 1 = 1.42061 loss)
I0506 04:52:17.407419 12834 solver.cpp:242] Iteration 139000 (94.3778 iter/s, 1.05957s/100 iter), loss = 0.769747
I0506 04:52:17.407443 12834 solver.cpp:261]     Train net output #0: loss = 0.769747 (* 1 = 0.769747 loss)
I0506 04:52:17.407451 12834 sgd_solver.cpp:106] Iteration 139000, lr = 5.49756e-06
I0506 04:52:17.409343 12834 solver.cpp:362] Iteration 139000, Testing net (#0)
I0506 04:52:17.409356 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:17.538130 12834 solver.cpp:429]     Test net output #0: accuracy = 0.801
I0506 04:52:17.538149 12834 solver.cpp:429]     Test net output #1: loss = 0.487202 (* 1 = 0.487202 loss)
I0506 04:52:17.540699 12834 solver.cpp:242] Iteration 139000 (84.1697 iter/s, 1.18808s/100 iter), loss = 0.351188
I0506 04:52:17.540719 12834 solver.cpp:261]     Train net output #0: loss = 0.351188 (* 1 = 0.351188 loss)
I0506 04:52:17.540729 12834 sgd_solver.cpp:106] Iteration 139000, lr = 5.49756e-06
I0506 04:52:18.473966 12834 solver.cpp:242] Iteration 139100 (93.7651 iter/s, 1.0665s/100 iter), loss = 0.465521
I0506 04:52:18.473999 12834 solver.cpp:261]     Train net output #0: loss = 0.465521 (* 1 = 0.465521 loss)
I0506 04:52:18.474007 12834 sgd_solver.cpp:106] Iteration 139100, lr = 5.49756e-06
I0506 04:52:18.478726 12834 solver.cpp:242] Iteration 139100 (106.611 iter/s, 0.937987s/100 iter), loss = 0.688498
I0506 04:52:18.478750 12834 solver.cpp:261]     Train net output #0: loss = 0.688498 (* 1 = 0.688498 loss)
I0506 04:52:18.478760 12834 sgd_solver.cpp:106] Iteration 139100, lr = 5.49756e-06
I0506 04:52:19.499168 12834 solver.cpp:242] Iteration 139200 (97.5472 iter/s, 1.02514s/100 iter), loss = 3.94501
I0506 04:52:19.499204 12834 solver.cpp:261]     Train net output #0: loss = 3.94501 (* 1 = 3.94501 loss)
I0506 04:52:19.499217 12834 sgd_solver.cpp:106] Iteration 139200, lr = 5.49756e-06
I0506 04:52:19.504559 12834 solver.cpp:242] Iteration 139200 (97.4873 iter/s, 1.02577s/100 iter), loss = 0.64471
I0506 04:52:19.504587 12834 solver.cpp:261]     Train net output #0: loss = 0.64471 (* 1 = 0.64471 loss)
I0506 04:52:19.504598 12834 sgd_solver.cpp:106] Iteration 139200, lr = 5.49756e-06
I0506 04:52:20.515245 12834 solver.cpp:242] Iteration 139300 (98.4237 iter/s, 1.01602s/100 iter), loss = 0.89748
I0506 04:52:20.515280 12834 solver.cpp:261]     Train net output #0: loss = 0.89748 (* 1 = 0.89748 loss)
I0506 04:52:20.515290 12834 sgd_solver.cpp:106] Iteration 139300, lr = 5.49756e-06
I0506 04:52:20.520018 12834 solver.cpp:242] Iteration 139300 (98.4821 iter/s, 1.01541s/100 iter), loss = 0.498818
I0506 04:52:20.520042 12834 solver.cpp:261]     Train net output #0: loss = 0.498818 (* 1 = 0.498818 loss)
I0506 04:52:20.520051 12834 sgd_solver.cpp:106] Iteration 139300, lr = 5.49756e-06
I0506 04:52:21.453518 12834 solver.cpp:242] Iteration 139400 (106.586 iter/s, 0.938205s/100 iter), loss = 0.247227
I0506 04:52:21.453560 12834 solver.cpp:261]     Train net output #0: loss = 0.247227 (* 1 = 0.247227 loss)
I0506 04:52:21.453569 12834 sgd_solver.cpp:106] Iteration 139400, lr = 5.49756e-06
I0506 04:52:21.458297 12834 solver.cpp:242] Iteration 139400 (106.583 iter/s, 0.938236s/100 iter), loss = 0.534374
I0506 04:52:21.458322 12834 solver.cpp:261]     Train net output #0: loss = 0.534374 (* 1 = 0.534374 loss)
I0506 04:52:21.458330 12834 sgd_solver.cpp:106] Iteration 139400, lr = 5.49756e-06
I0506 04:52:22.388283 12834 solver.cpp:362] Iteration 139500, Testing net (#0)
I0506 04:52:22.388311 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:22.511092 12834 solver.cpp:429]     Test net output #0: loss = 1.43325 (* 1 = 1.43325 loss)
I0506 04:52:22.513617 12834 solver.cpp:242] Iteration 139500 (94.3363 iter/s, 1.06004s/100 iter), loss = 0.918899
I0506 04:52:22.513639 12834 solver.cpp:261]     Train net output #0: loss = 0.918899 (* 1 = 0.918899 loss)
I0506 04:52:22.513648 12834 sgd_solver.cpp:106] Iteration 139500, lr = 5.49756e-06
I0506 04:52:22.515462 12834 solver.cpp:362] Iteration 139500, Testing net (#0)
I0506 04:52:22.515475 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:22.644186 12834 solver.cpp:429]     Test net output #0: accuracy = 0.794
I0506 04:52:22.644204 12834 solver.cpp:429]     Test net output #1: loss = 0.502936 (* 1 = 0.502936 loss)
I0506 04:52:22.646761 12834 solver.cpp:242] Iteration 139500 (84.1454 iter/s, 1.18842s/100 iter), loss = 0.495852
I0506 04:52:22.646782 12834 solver.cpp:261]     Train net output #0: loss = 0.495852 (* 1 = 0.495852 loss)
I0506 04:52:22.646791 12834 sgd_solver.cpp:106] Iteration 139500, lr = 5.49756e-06
I0506 04:52:23.580193 12834 solver.cpp:242] Iteration 139600 (93.7629 iter/s, 1.06652s/100 iter), loss = 0.435707
I0506 04:52:23.580235 12834 solver.cpp:261]     Train net output #0: loss = 0.435707 (* 1 = 0.435707 loss)
I0506 04:52:23.580243 12834 sgd_solver.cpp:106] Iteration 139600, lr = 5.49756e-06
I0506 04:52:23.584975 12834 solver.cpp:242] Iteration 139600 (106.59 iter/s, 0.938173s/100 iter), loss = 0.452686
I0506 04:52:23.585000 12834 solver.cpp:261]     Train net output #0: loss = 0.452686 (* 1 = 0.452686 loss)
I0506 04:52:23.585009 12834 sgd_solver.cpp:106] Iteration 139600, lr = 5.49756e-06
I0506 04:52:24.517992 12834 solver.cpp:242] Iteration 139700 (106.64 iter/s, 0.937731s/100 iter), loss = 1.17889
I0506 04:52:24.518029 12834 solver.cpp:261]     Train net output #0: loss = 1.17889 (* 1 = 1.17889 loss)
I0506 04:52:24.518038 12834 sgd_solver.cpp:106] Iteration 139700, lr = 5.49756e-06
I0506 04:52:24.522774 12834 solver.cpp:242] Iteration 139700 (106.638 iter/s, 0.937755s/100 iter), loss = 0.497129
I0506 04:52:24.522799 12834 solver.cpp:261]     Train net output #0: loss = 0.497129 (* 1 = 0.497129 loss)
I0506 04:52:24.522809 12834 sgd_solver.cpp:106] Iteration 139700, lr = 5.49756e-06
I0506 04:52:25.455664 12834 solver.cpp:242] Iteration 139800 (106.655 iter/s, 0.937603s/100 iter), loss = 4.92249
I0506 04:52:25.455704 12834 solver.cpp:261]     Train net output #0: loss = 4.92249 (* 1 = 4.92249 loss)
I0506 04:52:25.455713 12834 sgd_solver.cpp:106] Iteration 139800, lr = 5.49756e-06
I0506 04:52:25.460525 12834 solver.cpp:242] Iteration 139800 (106.643 iter/s, 0.937706s/100 iter), loss = 0.783717
I0506 04:52:25.460548 12834 solver.cpp:261]     Train net output #0: loss = 0.783717 (* 1 = 0.783717 loss)
I0506 04:52:25.460564 12834 sgd_solver.cpp:106] Iteration 139800, lr = 5.49756e-06
I0506 04:52:26.393887 12834 solver.cpp:242] Iteration 139900 (106.592 iter/s, 0.938157s/100 iter), loss = 5.17951
I0506 04:52:26.393925 12834 solver.cpp:261]     Train net output #0: loss = 5.17951 (* 1 = 5.17951 loss)
I0506 04:52:26.393934 12834 sgd_solver.cpp:106] Iteration 139900, lr = 5.49756e-06
I0506 04:52:26.398669 12834 solver.cpp:242] Iteration 139900 (106.598 iter/s, 0.938103s/100 iter), loss = 0.800748
I0506 04:52:26.398694 12834 solver.cpp:261]     Train net output #0: loss = 0.800748 (* 1 = 0.800748 loss)
I0506 04:52:26.398702 12834 sgd_solver.cpp:106] Iteration 139900, lr = 5.49756e-06
I0506 04:52:27.341958 12834 solver.cpp:362] Iteration 140000, Testing net (#0)
I0506 04:52:27.341981 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:27.464769 12834 solver.cpp:429]     Test net output #0: loss = 1.37239 (* 1 = 1.37239 loss)
I0506 04:52:27.467280 12834 solver.cpp:242] Iteration 140000 (93.1675 iter/s, 1.07334s/100 iter), loss = 1.39903
I0506 04:52:27.467301 12834 solver.cpp:261]     Train net output #0: loss = 1.39903 (* 1 = 1.39903 loss)
I0506 04:52:27.467310 12834 sgd_solver.cpp:106] Iteration 140000, lr = 4.39805e-06
I0506 04:52:27.469156 12834 solver.cpp:362] Iteration 140000, Testing net (#0)
I0506 04:52:27.469168 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:27.598049 12834 solver.cpp:429]     Test net output #0: accuracy = 0.787
I0506 04:52:27.598069 12834 solver.cpp:429]     Test net output #1: loss = 0.509114 (* 1 = 0.509114 loss)
I0506 04:52:27.600625 12834 solver.cpp:242] Iteration 140000 (83.2009 iter/s, 1.20191s/100 iter), loss = 0.414451
I0506 04:52:27.600646 12834 solver.cpp:261]     Train net output #0: loss = 0.414451 (* 1 = 0.414451 loss)
I0506 04:52:27.600654 12834 sgd_solver.cpp:106] Iteration 140000, lr = 4.39805e-06
I0506 04:52:28.533293 12834 solver.cpp:242] Iteration 140100 (93.8117 iter/s, 1.06597s/100 iter), loss = 0.575615
I0506 04:52:28.533329 12834 solver.cpp:261]     Train net output #0: loss = 0.575615 (* 1 = 0.575615 loss)
I0506 04:52:28.533339 12834 sgd_solver.cpp:106] Iteration 140100, lr = 4.39805e-06
I0506 04:52:28.538125 12834 solver.cpp:242] Iteration 140100 (106.672 iter/s, 0.937451s/100 iter), loss = 0.318572
I0506 04:52:28.538151 12834 solver.cpp:261]     Train net output #0: loss = 0.318572 (* 1 = 0.318572 loss)
I0506 04:52:28.538161 12834 sgd_solver.cpp:106] Iteration 140100, lr = 4.39805e-06
I0506 04:52:29.470645 12834 solver.cpp:242] Iteration 140200 (106.691 iter/s, 0.93729s/100 iter), loss = 1.52128
I0506 04:52:29.470682 12834 solver.cpp:261]     Train net output #0: loss = 1.52128 (* 1 = 1.52128 loss)
I0506 04:52:29.470691 12834 sgd_solver.cpp:106] Iteration 140200, lr = 4.39805e-06
I0506 04:52:29.475401 12834 solver.cpp:242] Iteration 140200 (106.697 iter/s, 0.937231s/100 iter), loss = 0.356609
I0506 04:52:29.475426 12834 solver.cpp:261]     Train net output #0: loss = 0.356609 (* 1 = 0.356609 loss)
I0506 04:52:29.475435 12834 sgd_solver.cpp:106] Iteration 140200, lr = 4.39805e-06
I0506 04:52:30.418948 12834 solver.cpp:242] Iteration 140300 (105.459 iter/s, 0.948234s/100 iter), loss = 0.640696
I0506 04:52:30.418983 12834 solver.cpp:261]     Train net output #0: loss = 0.640696 (* 1 = 0.640696 loss)
I0506 04:52:30.418992 12834 sgd_solver.cpp:106] Iteration 140300, lr = 4.39805e-06
I0506 04:52:30.423740 12834 solver.cpp:242] Iteration 140300 (105.452 iter/s, 0.948296s/100 iter), loss = 0.347825
I0506 04:52:30.423764 12834 solver.cpp:261]     Train net output #0: loss = 0.347825 (* 1 = 0.347825 loss)
I0506 04:52:30.423774 12834 sgd_solver.cpp:106] Iteration 140300, lr = 4.39805e-06
I0506 04:52:31.421859 12834 solver.cpp:242] Iteration 140400 (99.7156 iter/s, 1.00285s/100 iter), loss = 1.90555
I0506 04:52:31.421888 12834 solver.cpp:261]     Train net output #0: loss = 1.90555 (* 1 = 1.90555 loss)
I0506 04:52:31.421898 12834 sgd_solver.cpp:106] Iteration 140400, lr = 4.39805e-06
I0506 04:52:31.426609 12834 solver.cpp:242] Iteration 140400 (99.7184 iter/s, 1.00282s/100 iter), loss = 0.519386
I0506 04:52:31.426631 12834 solver.cpp:261]     Train net output #0: loss = 0.519386 (* 1 = 0.519386 loss)
I0506 04:52:31.426640 12834 sgd_solver.cpp:106] Iteration 140400, lr = 4.39805e-06
I0506 04:52:32.356547 12834 solver.cpp:362] Iteration 140500, Testing net (#0)
I0506 04:52:32.356592 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:32.479336 12834 solver.cpp:429]     Test net output #0: loss = 1.03393 (* 1 = 1.03393 loss)
I0506 04:52:32.481861 12834 solver.cpp:242] Iteration 140500 (94.3438 iter/s, 1.05995s/100 iter), loss = 1.40287
I0506 04:52:32.481880 12834 solver.cpp:261]     Train net output #0: loss = 1.40287 (* 1 = 1.40287 loss)
I0506 04:52:32.481889 12834 sgd_solver.cpp:106] Iteration 140500, lr = 4.39805e-06
I0506 04:52:32.483855 12834 solver.cpp:362] Iteration 140500, Testing net (#0)
I0506 04:52:32.483870 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:32.616081 12834 solver.cpp:429]     Test net output #0: accuracy = 0.786
I0506 04:52:32.616103 12834 solver.cpp:429]     Test net output #1: loss = 0.504009 (* 1 = 0.504009 loss)
I0506 04:52:32.618795 12834 solver.cpp:242] Iteration 140500 (83.8826 iter/s, 1.19214s/100 iter), loss = 0.875804
I0506 04:52:32.618820 12834 solver.cpp:261]     Train net output #0: loss = 0.875804 (* 1 = 0.875804 loss)
I0506 04:52:32.618831 12834 sgd_solver.cpp:106] Iteration 140500, lr = 4.39805e-06
I0506 04:52:33.561362 12834 solver.cpp:242] Iteration 140600 (92.6395 iter/s, 1.07945s/100 iter), loss = 1.4472
I0506 04:52:33.561403 12834 solver.cpp:261]     Train net output #0: loss = 1.4472 (* 1 = 1.4472 loss)
I0506 04:52:33.561413 12834 sgd_solver.cpp:106] Iteration 140600, lr = 4.39805e-06
I0506 04:52:33.566156 12834 solver.cpp:242] Iteration 140600 (105.561 iter/s, 0.947319s/100 iter), loss = 0.438048
I0506 04:52:33.566180 12834 solver.cpp:261]     Train net output #0: loss = 0.438048 (* 1 = 0.438048 loss)
I0506 04:52:33.566198 12834 sgd_solver.cpp:106] Iteration 140600, lr = 4.39805e-06
I0506 04:52:34.499441 12834 solver.cpp:242] Iteration 140700 (106.609 iter/s, 0.938006s/100 iter), loss = 2.40443
I0506 04:52:34.499481 12834 solver.cpp:261]     Train net output #0: loss = 2.40443 (* 1 = 2.40443 loss)
I0506 04:52:34.499491 12834 sgd_solver.cpp:106] Iteration 140700, lr = 4.39805e-06
I0506 04:52:34.504235 12834 solver.cpp:242] Iteration 140700 (106.606 iter/s, 0.938036s/100 iter), loss = 0.807259
I0506 04:52:34.504259 12834 solver.cpp:261]     Train net output #0: loss = 0.807259 (* 1 = 0.807259 loss)
I0506 04:52:34.504268 12834 sgd_solver.cpp:106] Iteration 140700, lr = 4.39805e-06
I0506 04:52:35.437599 12834 solver.cpp:242] Iteration 140800 (106.599 iter/s, 0.938093s/100 iter), loss = 2.66701
I0506 04:52:35.437639 12834 solver.cpp:261]     Train net output #0: loss = 2.66701 (* 1 = 2.66701 loss)
I0506 04:52:35.437649 12834 sgd_solver.cpp:106] Iteration 140800, lr = 4.39805e-06
I0506 04:52:35.442410 12834 solver.cpp:242] Iteration 140800 (106.595 iter/s, 0.938133s/100 iter), loss = 0.595512
I0506 04:52:35.442436 12834 solver.cpp:261]     Train net output #0: loss = 0.595512 (* 1 = 0.595512 loss)
I0506 04:52:35.442445 12834 sgd_solver.cpp:106] Iteration 140800, lr = 4.39805e-06
I0506 04:52:36.375897 12834 solver.cpp:242] Iteration 140900 (106.584 iter/s, 0.938228s/100 iter), loss = 0.336263
I0506 04:52:36.375941 12834 solver.cpp:261]     Train net output #0: loss = 0.336263 (* 1 = 0.336263 loss)
I0506 04:52:36.375949 12834 sgd_solver.cpp:106] Iteration 140900, lr = 4.39805e-06
I0506 04:52:36.380684 12834 solver.cpp:242] Iteration 140900 (106.584 iter/s, 0.93823s/100 iter), loss = 0.165687
I0506 04:52:36.380709 12834 solver.cpp:261]     Train net output #0: loss = 0.165687 (* 1 = 0.165687 loss)
I0506 04:52:36.380717 12834 sgd_solver.cpp:106] Iteration 140900, lr = 4.39805e-06
I0506 04:52:37.310622 12834 solver.cpp:362] Iteration 141000, Testing net (#0)
I0506 04:52:37.310647 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:37.433261 12834 solver.cpp:429]     Test net output #0: loss = 1.20177 (* 1 = 1.20177 loss)
I0506 04:52:37.435786 12834 solver.cpp:242] Iteration 141000 (94.3551 iter/s, 1.05983s/100 iter), loss = 1.14574
I0506 04:52:37.435806 12834 solver.cpp:261]     Train net output #0: loss = 1.14574 (* 1 = 1.14574 loss)
I0506 04:52:37.435814 12834 sgd_solver.cpp:106] Iteration 141000, lr = 4.39805e-06
I0506 04:52:37.437716 12834 solver.cpp:362] Iteration 141000, Testing net (#0)
I0506 04:52:37.437731 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:37.566625 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7825
I0506 04:52:37.566645 12834 solver.cpp:429]     Test net output #1: loss = 0.490782 (* 1 = 0.490782 loss)
I0506 04:52:37.569202 12834 solver.cpp:242] Iteration 141000 (84.1416 iter/s, 1.18847s/100 iter), loss = 0.587781
I0506 04:52:37.569223 12834 solver.cpp:261]     Train net output #0: loss = 0.587781 (* 1 = 0.587781 loss)
I0506 04:52:37.569231 12834 sgd_solver.cpp:106] Iteration 141000, lr = 4.39805e-06
I0506 04:52:38.502034 12834 solver.cpp:242] Iteration 141100 (93.7913 iter/s, 1.0662s/100 iter), loss = 0.752263
I0506 04:52:38.502074 12834 solver.cpp:261]     Train net output #0: loss = 0.752263 (* 1 = 0.752263 loss)
I0506 04:52:38.502084 12834 sgd_solver.cpp:106] Iteration 141100, lr = 4.39805e-06
I0506 04:52:38.506814 12834 solver.cpp:242] Iteration 141100 (106.659 iter/s, 0.937571s/100 iter), loss = 0.512419
I0506 04:52:38.506839 12834 solver.cpp:261]     Train net output #0: loss = 0.512419 (* 1 = 0.512419 loss)
I0506 04:52:38.506849 12834 sgd_solver.cpp:106] Iteration 141100, lr = 4.39805e-06
I0506 04:52:39.439749 12834 solver.cpp:242] Iteration 141200 (106.65 iter/s, 0.937643s/100 iter), loss = 0.551945
I0506 04:52:39.439787 12834 solver.cpp:261]     Train net output #0: loss = 0.551945 (* 1 = 0.551945 loss)
I0506 04:52:39.439797 12834 sgd_solver.cpp:106] Iteration 141200, lr = 4.39805e-06
I0506 04:52:39.444533 12834 solver.cpp:242] Iteration 141200 (106.647 iter/s, 0.937677s/100 iter), loss = 0.183542
I0506 04:52:39.444563 12834 solver.cpp:261]     Train net output #0: loss = 0.183542 (* 1 = 0.183542 loss)
I0506 04:52:39.444573 12834 sgd_solver.cpp:106] Iteration 141200, lr = 4.39805e-06
I0506 04:52:40.377295 12834 solver.cpp:242] Iteration 141300 (106.669 iter/s, 0.937481s/100 iter), loss = 1.02276
I0506 04:52:40.377334 12834 solver.cpp:261]     Train net output #0: loss = 1.02276 (* 1 = 1.02276 loss)
I0506 04:52:40.377344 12834 sgd_solver.cpp:106] Iteration 141300, lr = 4.39805e-06
I0506 04:52:40.382083 12834 solver.cpp:242] Iteration 141300 (106.666 iter/s, 0.937503s/100 iter), loss = 0.448318
I0506 04:52:40.382108 12834 solver.cpp:261]     Train net output #0: loss = 0.448318 (* 1 = 0.448318 loss)
I0506 04:52:40.382118 12834 sgd_solver.cpp:106] Iteration 141300, lr = 4.39805e-06
I0506 04:52:41.314874 12834 solver.cpp:242] Iteration 141400 (106.666 iter/s, 0.937508s/100 iter), loss = 1.89198
I0506 04:52:41.314913 12834 solver.cpp:261]     Train net output #0: loss = 1.89198 (* 1 = 1.89198 loss)
I0506 04:52:41.314924 12834 sgd_solver.cpp:106] Iteration 141400, lr = 4.39805e-06
I0506 04:52:41.319690 12834 solver.cpp:242] Iteration 141400 (106.659 iter/s, 0.937563s/100 iter), loss = 0.629887
I0506 04:52:41.319715 12834 solver.cpp:261]     Train net output #0: loss = 0.629887 (* 1 = 0.629887 loss)
I0506 04:52:41.319723 12834 sgd_solver.cpp:106] Iteration 141400, lr = 4.39805e-06
I0506 04:52:42.249881 12834 solver.cpp:362] Iteration 141500, Testing net (#0)
I0506 04:52:42.249902 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:42.372803 12834 solver.cpp:429]     Test net output #0: loss = 1.2605 (* 1 = 1.2605 loss)
I0506 04:52:42.375325 12834 solver.cpp:242] Iteration 141500 (94.3047 iter/s, 1.06039s/100 iter), loss = 0.732285
I0506 04:52:42.375345 12834 solver.cpp:261]     Train net output #0: loss = 0.732285 (* 1 = 0.732285 loss)
I0506 04:52:42.375355 12834 sgd_solver.cpp:106] Iteration 141500, lr = 4.39805e-06
I0506 04:52:42.377193 12834 solver.cpp:362] Iteration 141500, Testing net (#0)
I0506 04:52:42.377207 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:42.505867 12834 solver.cpp:429]     Test net output #0: accuracy = 0.784
I0506 04:52:42.505887 12834 solver.cpp:429]     Test net output #1: loss = 0.506236 (* 1 = 0.506236 loss)
I0506 04:52:42.508436 12834 solver.cpp:242] Iteration 141500 (84.1254 iter/s, 1.1887s/100 iter), loss = 0.613552
I0506 04:52:42.508456 12834 solver.cpp:261]     Train net output #0: loss = 0.613552 (* 1 = 0.613552 loss)
I0506 04:52:42.508466 12834 sgd_solver.cpp:106] Iteration 141500, lr = 4.39805e-06
I0506 04:52:43.442847 12834 solver.cpp:242] Iteration 141600 (93.6796 iter/s, 1.06747s/100 iter), loss = 0.557379
I0506 04:52:43.442883 12834 solver.cpp:261]     Train net output #0: loss = 0.557379 (* 1 = 0.557379 loss)
I0506 04:52:43.442893 12834 sgd_solver.cpp:106] Iteration 141600, lr = 4.39805e-06
I0506 04:52:43.447597 12834 solver.cpp:242] Iteration 141600 (106.482 iter/s, 0.939123s/100 iter), loss = 0.374845
I0506 04:52:43.447623 12834 solver.cpp:261]     Train net output #0: loss = 0.374845 (* 1 = 0.374845 loss)
I0506 04:52:43.447631 12834 sgd_solver.cpp:106] Iteration 141600, lr = 4.39805e-06
I0506 04:52:44.380564 12834 solver.cpp:242] Iteration 141700 (106.649 iter/s, 0.937653s/100 iter), loss = 0.457778
I0506 04:52:44.380594 12834 solver.cpp:261]     Train net output #0: loss = 0.457778 (* 1 = 0.457778 loss)
I0506 04:52:44.380604 12834 sgd_solver.cpp:106] Iteration 141700, lr = 4.39805e-06
I0506 04:52:44.385325 12834 solver.cpp:242] Iteration 141700 (106.646 iter/s, 0.937685s/100 iter), loss = 0.288974
I0506 04:52:44.385349 12834 solver.cpp:261]     Train net output #0: loss = 0.288974 (* 1 = 0.288974 loss)
I0506 04:52:44.385359 12834 sgd_solver.cpp:106] Iteration 141700, lr = 4.39805e-06
I0506 04:52:45.318080 12834 solver.cpp:242] Iteration 141800 (106.672 iter/s, 0.937455s/100 iter), loss = 1.07577
I0506 04:52:45.318120 12834 solver.cpp:261]     Train net output #0: loss = 1.07577 (* 1 = 1.07577 loss)
I0506 04:52:45.318140 12834 sgd_solver.cpp:106] Iteration 141800, lr = 4.39805e-06
I0506 04:52:45.322868 12834 solver.cpp:242] Iteration 141800 (106.667 iter/s, 0.937501s/100 iter), loss = 0.42002
I0506 04:52:45.322893 12834 solver.cpp:261]     Train net output #0: loss = 0.42002 (* 1 = 0.42002 loss)
I0506 04:52:45.322902 12834 sgd_solver.cpp:106] Iteration 141800, lr = 4.39805e-06
I0506 04:52:46.255918 12834 solver.cpp:242] Iteration 141900 (106.636 iter/s, 0.937773s/100 iter), loss = 0.718665
I0506 04:52:46.255959 12834 solver.cpp:261]     Train net output #0: loss = 0.718665 (* 1 = 0.718665 loss)
I0506 04:52:46.255969 12834 sgd_solver.cpp:106] Iteration 141900, lr = 4.39805e-06
I0506 04:52:46.260764 12834 solver.cpp:242] Iteration 141900 (106.628 iter/s, 0.937842s/100 iter), loss = 0.419979
I0506 04:52:46.260789 12834 solver.cpp:261]     Train net output #0: loss = 0.419979 (* 1 = 0.419979 loss)
I0506 04:52:46.260798 12834 sgd_solver.cpp:106] Iteration 141900, lr = 4.39805e-06
I0506 04:52:47.190922 12834 solver.cpp:362] Iteration 142000, Testing net (#0)
I0506 04:52:47.190953 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:47.313858 12834 solver.cpp:429]     Test net output #0: loss = 1.16003 (* 1 = 1.16003 loss)
I0506 04:52:47.316377 12834 solver.cpp:242] Iteration 142000 (94.3041 iter/s, 1.0604s/100 iter), loss = 0.641133
I0506 04:52:47.316401 12834 solver.cpp:261]     Train net output #0: loss = 0.641133 (* 1 = 0.641133 loss)
I0506 04:52:47.316411 12834 sgd_solver.cpp:106] Iteration 142000, lr = 4.39805e-06
I0506 04:52:47.318239 12834 solver.cpp:362] Iteration 142000, Testing net (#0)
I0506 04:52:47.318253 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:47.446813 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7795
I0506 04:52:47.446831 12834 solver.cpp:429]     Test net output #1: loss = 0.507849 (* 1 = 0.507849 loss)
I0506 04:52:47.449398 12834 solver.cpp:242] Iteration 142000 (84.1334 iter/s, 1.18859s/100 iter), loss = 0.330675
I0506 04:52:47.449419 12834 solver.cpp:261]     Train net output #0: loss = 0.330675 (* 1 = 0.330675 loss)
I0506 04:52:47.449427 12834 sgd_solver.cpp:106] Iteration 142000, lr = 4.39805e-06
I0506 04:52:48.382540 12834 solver.cpp:242] Iteration 142100 (93.7986 iter/s, 1.06611s/100 iter), loss = 3.26663
I0506 04:52:48.382580 12834 solver.cpp:261]     Train net output #0: loss = 3.26663 (* 1 = 3.26663 loss)
I0506 04:52:48.382589 12834 sgd_solver.cpp:106] Iteration 142100, lr = 4.39805e-06
I0506 04:52:48.387310 12834 solver.cpp:242] Iteration 142100 (106.625 iter/s, 0.937863s/100 iter), loss = 0.683379
I0506 04:52:48.387333 12834 solver.cpp:261]     Train net output #0: loss = 0.683379 (* 1 = 0.683379 loss)
I0506 04:52:48.387342 12834 sgd_solver.cpp:106] Iteration 142100, lr = 4.39805e-06
I0506 04:52:49.320042 12834 solver.cpp:242] Iteration 142200 (106.674 iter/s, 0.937436s/100 iter), loss = 2.12548
I0506 04:52:49.320081 12834 solver.cpp:261]     Train net output #0: loss = 2.12548 (* 1 = 2.12548 loss)
I0506 04:52:49.320091 12834 sgd_solver.cpp:106] Iteration 142200, lr = 4.39805e-06
I0506 04:52:49.324815 12834 solver.cpp:242] Iteration 142200 (106.671 iter/s, 0.937462s/100 iter), loss = 0.848977
I0506 04:52:49.324839 12834 solver.cpp:261]     Train net output #0: loss = 0.848977 (* 1 = 0.848977 loss)
I0506 04:52:49.324848 12834 sgd_solver.cpp:106] Iteration 142200, lr = 4.39805e-06
I0506 04:52:50.257663 12834 solver.cpp:242] Iteration 142300 (106.661 iter/s, 0.937549s/100 iter), loss = 0.664189
I0506 04:52:50.257701 12834 solver.cpp:261]     Train net output #0: loss = 0.664189 (* 1 = 0.664189 loss)
I0506 04:52:50.257710 12834 sgd_solver.cpp:106] Iteration 142300, lr = 4.39805e-06
I0506 04:52:50.262432 12834 solver.cpp:242] Iteration 142300 (106.658 iter/s, 0.937574s/100 iter), loss = 0.669284
I0506 04:52:50.262457 12834 solver.cpp:261]     Train net output #0: loss = 0.669284 (* 1 = 0.669284 loss)
I0506 04:52:50.262465 12834 sgd_solver.cpp:106] Iteration 142300, lr = 4.39805e-06
I0506 04:52:51.209558 12834 solver.cpp:242] Iteration 142400 (105.061 iter/s, 0.951831s/100 iter), loss = 0.882107
I0506 04:52:51.209594 12834 solver.cpp:261]     Train net output #0: loss = 0.882107 (* 1 = 0.882107 loss)
I0506 04:52:51.209604 12834 sgd_solver.cpp:106] Iteration 142400, lr = 4.39805e-06
I0506 04:52:51.214318 12834 solver.cpp:242] Iteration 142400 (105.059 iter/s, 0.951842s/100 iter), loss = 0.42474
I0506 04:52:51.214341 12834 solver.cpp:261]     Train net output #0: loss = 0.42474 (* 1 = 0.42474 loss)
I0506 04:52:51.214350 12834 sgd_solver.cpp:106] Iteration 142400, lr = 4.39805e-06
I0506 04:52:52.144353 12834 solver.cpp:362] Iteration 142500, Testing net (#0)
I0506 04:52:52.144378 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:52.266985 12834 solver.cpp:429]     Test net output #0: loss = 1.22297 (* 1 = 1.22297 loss)
I0506 04:52:52.269551 12834 solver.cpp:242] Iteration 142500 (94.3452 iter/s, 1.05994s/100 iter), loss = 0.711168
I0506 04:52:52.269577 12834 solver.cpp:261]     Train net output #0: loss = 0.711168 (* 1 = 0.711168 loss)
I0506 04:52:52.269585 12834 sgd_solver.cpp:106] Iteration 142500, lr = 4.39805e-06
I0506 04:52:52.271409 12834 solver.cpp:362] Iteration 142500, Testing net (#0)
I0506 04:52:52.271420 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:52.400491 12834 solver.cpp:429]     Test net output #0: accuracy = 0.768
I0506 04:52:52.400511 12834 solver.cpp:429]     Test net output #1: loss = 0.544299 (* 1 = 0.544299 loss)
I0506 04:52:52.403061 12834 solver.cpp:242] Iteration 142500 (84.1256 iter/s, 1.1887s/100 iter), loss = 0.846116
I0506 04:52:52.403082 12834 solver.cpp:261]     Train net output #0: loss = 0.846116 (* 1 = 0.846116 loss)
I0506 04:52:52.403090 12834 sgd_solver.cpp:106] Iteration 142500, lr = 4.39805e-06
I0506 04:52:53.336390 12834 solver.cpp:242] Iteration 142600 (93.7396 iter/s, 1.06678s/100 iter), loss = 1.79101
I0506 04:52:53.336427 12834 solver.cpp:261]     Train net output #0: loss = 1.79101 (* 1 = 1.79101 loss)
I0506 04:52:53.336436 12834 sgd_solver.cpp:106] Iteration 142600, lr = 4.39805e-06
I0506 04:52:53.341150 12834 solver.cpp:242] Iteration 142600 (106.604 iter/s, 0.938049s/100 iter), loss = 0.519152
I0506 04:52:53.341173 12834 solver.cpp:261]     Train net output #0: loss = 0.519152 (* 1 = 0.519152 loss)
I0506 04:52:53.341182 12834 sgd_solver.cpp:106] Iteration 142600, lr = 4.39805e-06
I0506 04:52:54.273836 12834 solver.cpp:242] Iteration 142700 (106.68 iter/s, 0.93738s/100 iter), loss = 0.982295
I0506 04:52:54.273871 12834 solver.cpp:261]     Train net output #0: loss = 0.982295 (* 1 = 0.982295 loss)
I0506 04:52:54.273880 12834 sgd_solver.cpp:106] Iteration 142700, lr = 4.39805e-06
I0506 04:52:54.278625 12834 solver.cpp:242] Iteration 142700 (106.674 iter/s, 0.937432s/100 iter), loss = 0.845956
I0506 04:52:54.278648 12834 solver.cpp:261]     Train net output #0: loss = 0.845956 (* 1 = 0.845956 loss)
I0506 04:52:54.278656 12834 sgd_solver.cpp:106] Iteration 142700, lr = 4.39805e-06
I0506 04:52:55.278005 12834 solver.cpp:242] Iteration 142800 (99.5908 iter/s, 1.00411s/100 iter), loss = 1.20376
I0506 04:52:55.278046 12834 solver.cpp:261]     Train net output #0: loss = 1.20376 (* 1 = 1.20376 loss)
I0506 04:52:55.278057 12834 sgd_solver.cpp:106] Iteration 142800, lr = 4.39805e-06
I0506 04:52:55.283365 12834 solver.cpp:242] Iteration 142800 (99.5336 iter/s, 1.00469s/100 iter), loss = 0.594776
I0506 04:52:55.283394 12834 solver.cpp:261]     Train net output #0: loss = 0.594776 (* 1 = 0.594776 loss)
I0506 04:52:55.283406 12834 sgd_solver.cpp:106] Iteration 142800, lr = 4.39805e-06
I0506 04:52:56.221458 12834 solver.cpp:242] Iteration 142900 (106.001 iter/s, 0.943387s/100 iter), loss = 0.187875
I0506 04:52:56.221490 12834 solver.cpp:261]     Train net output #0: loss = 0.187875 (* 1 = 0.187875 loss)
I0506 04:52:56.221500 12834 sgd_solver.cpp:106] Iteration 142900, lr = 4.39805e-06
I0506 04:52:56.226217 12834 solver.cpp:242] Iteration 142900 (106.066 iter/s, 0.942805s/100 iter), loss = 0.60424
I0506 04:52:56.226240 12834 solver.cpp:261]     Train net output #0: loss = 0.60424 (* 1 = 0.60424 loss)
I0506 04:52:56.226261 12834 sgd_solver.cpp:106] Iteration 142900, lr = 4.39805e-06
I0506 04:52:57.155712 12834 solver.cpp:362] Iteration 143000, Testing net (#0)
I0506 04:52:57.155740 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:57.278352 12834 solver.cpp:429]     Test net output #0: loss = 1.35092 (* 1 = 1.35092 loss)
I0506 04:52:57.280889 12834 solver.cpp:242] Iteration 143000 (94.3949 iter/s, 1.05938s/100 iter), loss = 3.98276
I0506 04:52:57.280912 12834 solver.cpp:261]     Train net output #0: loss = 3.98276 (* 1 = 3.98276 loss)
I0506 04:52:57.280922 12834 sgd_solver.cpp:106] Iteration 143000, lr = 4.39805e-06
I0506 04:52:57.282829 12834 solver.cpp:362] Iteration 143000, Testing net (#0)
I0506 04:52:57.282841 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:52:57.411383 12834 solver.cpp:429]     Test net output #0: accuracy = 0.772
I0506 04:52:57.411402 12834 solver.cpp:429]     Test net output #1: loss = 0.547567 (* 1 = 0.547567 loss)
I0506 04:52:57.413960 12834 solver.cpp:242] Iteration 143000 (84.1964 iter/s, 1.1877s/100 iter), loss = 0.630811
I0506 04:52:57.413980 12834 solver.cpp:261]     Train net output #0: loss = 0.630811 (* 1 = 0.630811 loss)
I0506 04:52:57.413990 12834 sgd_solver.cpp:106] Iteration 143000, lr = 4.39805e-06
I0506 04:52:58.347375 12834 solver.cpp:242] Iteration 143100 (93.7703 iter/s, 1.06644s/100 iter), loss = 0.805419
I0506 04:52:58.347404 12834 solver.cpp:261]     Train net output #0: loss = 0.805419 (* 1 = 0.805419 loss)
I0506 04:52:58.347414 12834 sgd_solver.cpp:106] Iteration 143100, lr = 4.39805e-06
I0506 04:52:58.352140 12834 solver.cpp:242] Iteration 143100 (106.594 iter/s, 0.938141s/100 iter), loss = 0.372695
I0506 04:52:58.352164 12834 solver.cpp:261]     Train net output #0: loss = 0.372695 (* 1 = 0.372695 loss)
I0506 04:52:58.352172 12834 sgd_solver.cpp:106] Iteration 143100, lr = 4.39805e-06
I0506 04:52:59.285008 12834 solver.cpp:242] Iteration 143200 (106.659 iter/s, 0.93757s/100 iter), loss = 1.44319
I0506 04:52:59.285050 12834 solver.cpp:261]     Train net output #0: loss = 1.44319 (* 1 = 1.44319 loss)
I0506 04:52:59.285059 12834 sgd_solver.cpp:106] Iteration 143200, lr = 4.39805e-06
I0506 04:52:59.289770 12834 solver.cpp:242] Iteration 143200 (106.657 iter/s, 0.937589s/100 iter), loss = 0.505033
I0506 04:52:59.289795 12834 solver.cpp:261]     Train net output #0: loss = 0.505033 (* 1 = 0.505033 loss)
I0506 04:52:59.289804 12834 sgd_solver.cpp:106] Iteration 143200, lr = 4.39805e-06
I0506 04:53:00.223389 12834 solver.cpp:242] Iteration 143300 (106.575 iter/s, 0.938307s/100 iter), loss = 1.08307
I0506 04:53:00.223438 12834 solver.cpp:261]     Train net output #0: loss = 1.08307 (* 1 = 1.08307 loss)
I0506 04:53:00.223448 12834 sgd_solver.cpp:106] Iteration 143300, lr = 4.39805e-06
I0506 04:53:00.228365 12834 solver.cpp:242] Iteration 143300 (106.547 iter/s, 0.93855s/100 iter), loss = 0.50385
I0506 04:53:00.228397 12834 solver.cpp:261]     Train net output #0: loss = 0.50385 (* 1 = 0.50385 loss)
I0506 04:53:00.228407 12834 sgd_solver.cpp:106] Iteration 143300, lr = 4.39805e-06
I0506 04:53:01.170472 12834 solver.cpp:242] Iteration 143400 (105.596 iter/s, 0.947001s/100 iter), loss = 1.37702
I0506 04:53:01.170514 12834 solver.cpp:261]     Train net output #0: loss = 1.37702 (* 1 = 1.37702 loss)
I0506 04:53:01.170524 12834 sgd_solver.cpp:106] Iteration 143400, lr = 4.39805e-06
I0506 04:53:01.175318 12834 solver.cpp:242] Iteration 143400 (105.608 iter/s, 0.946902s/100 iter), loss = 0.361744
I0506 04:53:01.175343 12834 solver.cpp:261]     Train net output #0: loss = 0.361744 (* 1 = 0.361744 loss)
I0506 04:53:01.175353 12834 sgd_solver.cpp:106] Iteration 143400, lr = 4.39805e-06
I0506 04:53:02.108989 12834 solver.cpp:362] Iteration 143500, Testing net (#0)
I0506 04:53:02.109016 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:02.231675 12834 solver.cpp:429]     Test net output #0: loss = 1.29401 (* 1 = 1.29401 loss)
I0506 04:53:02.234197 12834 solver.cpp:242] Iteration 143500 (94.0147 iter/s, 1.06366s/100 iter), loss = 0.710571
I0506 04:53:02.234230 12834 solver.cpp:261]     Train net output #0: loss = 0.710571 (* 1 = 0.710571 loss)
I0506 04:53:02.234239 12834 sgd_solver.cpp:106] Iteration 143500, lr = 4.39805e-06
I0506 04:53:02.236070 12834 solver.cpp:362] Iteration 143500, Testing net (#0)
I0506 04:53:02.236083 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:02.364683 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7785
I0506 04:53:02.364708 12834 solver.cpp:429]     Test net output #1: loss = 0.526293 (* 1 = 0.526293 loss)
I0506 04:53:02.367353 12834 solver.cpp:242] Iteration 143500 (83.8934 iter/s, 1.19199s/100 iter), loss = 0.474094
I0506 04:53:02.367374 12834 solver.cpp:261]     Train net output #0: loss = 0.474094 (* 1 = 0.474094 loss)
I0506 04:53:02.367383 12834 sgd_solver.cpp:106] Iteration 143500, lr = 4.39805e-06
I0506 04:53:03.300348 12834 solver.cpp:242] Iteration 143600 (93.8011 iter/s, 1.06609s/100 iter), loss = 0.592525
I0506 04:53:03.300390 12834 solver.cpp:261]     Train net output #0: loss = 0.592525 (* 1 = 0.592525 loss)
I0506 04:53:03.300400 12834 sgd_solver.cpp:106] Iteration 143600, lr = 4.39805e-06
I0506 04:53:03.305197 12834 solver.cpp:242] Iteration 143600 (106.632 iter/s, 0.937804s/100 iter), loss = 0.624415
I0506 04:53:03.305222 12834 solver.cpp:261]     Train net output #0: loss = 0.624415 (* 1 = 0.624415 loss)
I0506 04:53:03.305232 12834 sgd_solver.cpp:106] Iteration 143600, lr = 4.39805e-06
I0506 04:53:04.238391 12834 solver.cpp:242] Iteration 143700 (106.612 iter/s, 0.937977s/100 iter), loss = 3.23846
I0506 04:53:04.238428 12834 solver.cpp:261]     Train net output #0: loss = 3.23846 (* 1 = 3.23846 loss)
I0506 04:53:04.238437 12834 sgd_solver.cpp:106] Iteration 143700, lr = 4.39805e-06
I0506 04:53:04.243247 12834 solver.cpp:242] Iteration 143700 (106.61 iter/s, 0.937996s/100 iter), loss = 0.58856
I0506 04:53:04.243270 12834 solver.cpp:261]     Train net output #0: loss = 0.58856 (* 1 = 0.58856 loss)
I0506 04:53:04.243279 12834 sgd_solver.cpp:106] Iteration 143700, lr = 4.39805e-06
I0506 04:53:05.175796 12834 solver.cpp:242] Iteration 143800 (106.685 iter/s, 0.937341s/100 iter), loss = 1.45798
I0506 04:53:05.175832 12834 solver.cpp:261]     Train net output #0: loss = 1.45798 (* 1 = 1.45798 loss)
I0506 04:53:05.175842 12834 sgd_solver.cpp:106] Iteration 143800, lr = 4.39805e-06
I0506 04:53:05.180568 12834 solver.cpp:242] Iteration 143800 (106.692 iter/s, 0.937279s/100 iter), loss = 0.674271
I0506 04:53:05.180593 12834 solver.cpp:261]     Train net output #0: loss = 0.674271 (* 1 = 0.674271 loss)
I0506 04:53:05.180603 12834 sgd_solver.cpp:106] Iteration 143800, lr = 4.39805e-06
I0506 04:53:06.113087 12834 solver.cpp:242] Iteration 143900 (106.697 iter/s, 0.937231s/100 iter), loss = 0.384691
I0506 04:53:06.113123 12834 solver.cpp:261]     Train net output #0: loss = 0.384691 (* 1 = 0.384691 loss)
I0506 04:53:06.113132 12834 sgd_solver.cpp:106] Iteration 143900, lr = 4.39805e-06
I0506 04:53:06.117920 12834 solver.cpp:242] Iteration 143900 (106.689 iter/s, 0.937301s/100 iter), loss = 0.445274
I0506 04:53:06.117945 12834 solver.cpp:261]     Train net output #0: loss = 0.445274 (* 1 = 0.445274 loss)
I0506 04:53:06.117954 12834 sgd_solver.cpp:106] Iteration 143900, lr = 4.39805e-06
I0506 04:53:07.097349 12834 solver.cpp:362] Iteration 144000, Testing net (#0)
I0506 04:53:07.097374 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:07.230420 12834 solver.cpp:429]     Test net output #0: loss = 1.23065 (* 1 = 1.23065 loss)
I0506 04:53:07.233053 12834 solver.cpp:242] Iteration 144000 (89.2929 iter/s, 1.11991s/100 iter), loss = 2.91394
I0506 04:53:07.233080 12834 solver.cpp:261]     Train net output #0: loss = 2.91394 (* 1 = 2.91394 loss)
I0506 04:53:07.233091 12834 sgd_solver.cpp:106] Iteration 144000, lr = 4.39805e-06
I0506 04:53:07.235276 12834 solver.cpp:362] Iteration 144000, Testing net (#0)
I0506 04:53:07.235291 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:07.375869 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7815
I0506 04:53:07.375986 12834 solver.cpp:429]     Test net output #1: loss = 0.511644 (* 1 = 0.511644 loss)
I0506 04:53:07.378597 12834 solver.cpp:242] Iteration 144000 (79.3254 iter/s, 1.26063s/100 iter), loss = 0.421021
I0506 04:53:07.378618 12834 solver.cpp:261]     Train net output #0: loss = 0.421021 (* 1 = 0.421021 loss)
I0506 04:53:07.378628 12834 sgd_solver.cpp:106] Iteration 144000, lr = 4.39805e-06
I0506 04:53:08.312101 12834 solver.cpp:242] Iteration 144100 (92.6795 iter/s, 1.07899s/100 iter), loss = 0.872388
I0506 04:53:08.312139 12834 solver.cpp:261]     Train net output #0: loss = 0.872388 (* 1 = 0.872388 loss)
I0506 04:53:08.312149 12834 sgd_solver.cpp:106] Iteration 144100, lr = 4.39805e-06
I0506 04:53:08.316912 12834 solver.cpp:242] Iteration 144100 (106.579 iter/s, 0.938275s/100 iter), loss = 0.640912
I0506 04:53:08.316936 12834 solver.cpp:261]     Train net output #0: loss = 0.640912 (* 1 = 0.640912 loss)
I0506 04:53:08.316946 12834 sgd_solver.cpp:106] Iteration 144100, lr = 4.39805e-06
I0506 04:53:09.249788 12834 solver.cpp:242] Iteration 144200 (106.653 iter/s, 0.937624s/100 iter), loss = 1.76517
I0506 04:53:09.249819 12834 solver.cpp:261]     Train net output #0: loss = 1.76517 (* 1 = 1.76517 loss)
I0506 04:53:09.249828 12834 sgd_solver.cpp:106] Iteration 144200, lr = 4.39805e-06
I0506 04:53:09.254547 12834 solver.cpp:242] Iteration 144200 (106.656 iter/s, 0.937594s/100 iter), loss = 0.741147
I0506 04:53:09.254570 12834 solver.cpp:261]     Train net output #0: loss = 0.741147 (* 1 = 0.741147 loss)
I0506 04:53:09.254580 12834 sgd_solver.cpp:106] Iteration 144200, lr = 4.39805e-06
I0506 04:53:10.187600 12834 solver.cpp:242] Iteration 144300 (106.638 iter/s, 0.93775s/100 iter), loss = 1.04509
I0506 04:53:10.187643 12834 solver.cpp:261]     Train net output #0: loss = 1.04509 (* 1 = 1.04509 loss)
I0506 04:53:10.187651 12834 sgd_solver.cpp:106] Iteration 144300, lr = 4.39805e-06
I0506 04:53:10.192370 12834 solver.cpp:242] Iteration 144300 (106.635 iter/s, 0.937782s/100 iter), loss = 0.384258
I0506 04:53:10.192396 12834 solver.cpp:261]     Train net output #0: loss = 0.384258 (* 1 = 0.384258 loss)
I0506 04:53:10.192405 12834 sgd_solver.cpp:106] Iteration 144300, lr = 4.39805e-06
I0506 04:53:11.182509 12834 solver.cpp:242] Iteration 144400 (100.519 iter/s, 0.994841s/100 iter), loss = 1.20066
I0506 04:53:11.182559 12834 solver.cpp:261]     Train net output #0: loss = 1.20066 (* 1 = 1.20066 loss)
I0506 04:53:11.182569 12834 sgd_solver.cpp:106] Iteration 144400, lr = 4.39805e-06
I0506 04:53:11.187803 12834 solver.cpp:242] Iteration 144400 (100.463 iter/s, 0.995387s/100 iter), loss = 0.525784
I0506 04:53:11.187834 12834 solver.cpp:261]     Train net output #0: loss = 0.525784 (* 1 = 0.525784 loss)
I0506 04:53:11.187845 12834 sgd_solver.cpp:106] Iteration 144400, lr = 4.39805e-06
I0506 04:53:12.215139 12834 solver.cpp:362] Iteration 144500, Testing net (#0)
I0506 04:53:12.215173 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:12.348258 12834 solver.cpp:429]     Test net output #0: loss = 1.18516 (* 1 = 1.18516 loss)
I0506 04:53:12.350900 12834 solver.cpp:242] Iteration 144500 (85.5928 iter/s, 1.16832s/100 iter), loss = 1.40975
I0506 04:53:12.350936 12834 solver.cpp:261]     Train net output #0: loss = 1.40975 (* 1 = 1.40975 loss)
I0506 04:53:12.350947 12834 sgd_solver.cpp:106] Iteration 144500, lr = 4.39805e-06
I0506 04:53:12.353137 12834 solver.cpp:362] Iteration 144500, Testing net (#0)
I0506 04:53:12.353153 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:12.485133 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7895
I0506 04:53:12.485155 12834 solver.cpp:429]     Test net output #1: loss = 0.493525 (* 1 = 0.493525 loss)
I0506 04:53:12.487733 12834 solver.cpp:242] Iteration 144500 (76.9303 iter/s, 1.29988s/100 iter), loss = 0.782546
I0506 04:53:12.487754 12834 solver.cpp:261]     Train net output #0: loss = 0.782546 (* 1 = 0.782546 loss)
I0506 04:53:12.487763 12834 sgd_solver.cpp:106] Iteration 144500, lr = 4.39805e-06
I0506 04:53:13.420459 12834 solver.cpp:242] Iteration 144600 (93.502 iter/s, 1.0695s/100 iter), loss = 1.0359
I0506 04:53:13.420501 12834 solver.cpp:261]     Train net output #0: loss = 1.0359 (* 1 = 1.0359 loss)
I0506 04:53:13.420511 12834 sgd_solver.cpp:106] Iteration 144600, lr = 4.39805e-06
I0506 04:53:13.425328 12834 solver.cpp:242] Iteration 144600 (106.662 iter/s, 0.937545s/100 iter), loss = 0.291398
I0506 04:53:13.425353 12834 solver.cpp:261]     Train net output #0: loss = 0.291398 (* 1 = 0.291398 loss)
I0506 04:53:13.425361 12834 sgd_solver.cpp:106] Iteration 144600, lr = 4.39805e-06
I0506 04:53:14.358433 12834 solver.cpp:242] Iteration 144700 (106.621 iter/s, 0.937905s/100 iter), loss = 0.311544
I0506 04:53:14.358466 12834 solver.cpp:261]     Train net output #0: loss = 0.311544 (* 1 = 0.311544 loss)
I0506 04:53:14.358475 12834 sgd_solver.cpp:106] Iteration 144700, lr = 4.39805e-06
I0506 04:53:14.363204 12834 solver.cpp:242] Iteration 144700 (106.629 iter/s, 0.937833s/100 iter), loss = 0.506111
I0506 04:53:14.363226 12834 solver.cpp:261]     Train net output #0: loss = 0.506111 (* 1 = 0.506111 loss)
I0506 04:53:14.363235 12834 sgd_solver.cpp:106] Iteration 144700, lr = 4.39805e-06
I0506 04:53:15.295795 12834 solver.cpp:242] Iteration 144800 (106.689 iter/s, 0.937305s/100 iter), loss = 1.25318
I0506 04:53:15.295837 12834 solver.cpp:261]     Train net output #0: loss = 1.25318 (* 1 = 1.25318 loss)
I0506 04:53:15.295847 12834 sgd_solver.cpp:106] Iteration 144800, lr = 4.39805e-06
I0506 04:53:15.300642 12834 solver.cpp:242] Iteration 144800 (106.679 iter/s, 0.937389s/100 iter), loss = 1.08622
I0506 04:53:15.300669 12834 solver.cpp:261]     Train net output #0: loss = 1.08622 (* 1 = 1.08622 loss)
I0506 04:53:15.300678 12834 sgd_solver.cpp:106] Iteration 144800, lr = 4.39805e-06
I0506 04:53:16.233485 12834 solver.cpp:242] Iteration 144900 (106.653 iter/s, 0.937622s/100 iter), loss = 1.57997
I0506 04:53:16.233525 12834 solver.cpp:261]     Train net output #0: loss = 1.57997 (* 1 = 1.57997 loss)
I0506 04:53:16.233535 12834 sgd_solver.cpp:106] Iteration 144900, lr = 4.39805e-06
I0506 04:53:16.238247 12834 solver.cpp:242] Iteration 144900 (106.66 iter/s, 0.93756s/100 iter), loss = 0.554064
I0506 04:53:16.238273 12834 solver.cpp:261]     Train net output #0: loss = 0.554064 (* 1 = 0.554064 loss)
I0506 04:53:16.238283 12834 sgd_solver.cpp:106] Iteration 144900, lr = 4.39805e-06
I0506 04:53:17.168121 12834 solver.cpp:362] Iteration 145000, Testing net (#0)
I0506 04:53:17.168148 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:17.290643 12834 solver.cpp:429]     Test net output #0: loss = 1.28724 (* 1 = 1.28724 loss)
I0506 04:53:17.293159 12834 solver.cpp:242] Iteration 145000 (94.374 iter/s, 1.05961s/100 iter), loss = 1.07303
I0506 04:53:17.293181 12834 solver.cpp:261]     Train net output #0: loss = 1.07303 (* 1 = 1.07303 loss)
I0506 04:53:17.293190 12834 sgd_solver.cpp:106] Iteration 145000, lr = 4.39805e-06
I0506 04:53:17.295018 12834 solver.cpp:362] Iteration 145000, Testing net (#0)
I0506 04:53:17.295032 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:17.423568 12834 solver.cpp:429]     Test net output #0: accuracy = 0.776
I0506 04:53:17.423586 12834 solver.cpp:429]     Test net output #1: loss = 0.516594 (* 1 = 0.516594 loss)
I0506 04:53:17.426148 12834 solver.cpp:242] Iteration 145000 (84.1855 iter/s, 1.18785s/100 iter), loss = 0.411241
I0506 04:53:17.426169 12834 solver.cpp:261]     Train net output #0: loss = 0.411241 (* 1 = 0.411241 loss)
I0506 04:53:17.426178 12834 sgd_solver.cpp:106] Iteration 145000, lr = 4.39805e-06
I0506 04:53:18.359186 12834 solver.cpp:242] Iteration 145100 (93.8108 iter/s, 1.06598s/100 iter), loss = 0.764646
I0506 04:53:18.359227 12834 solver.cpp:261]     Train net output #0: loss = 0.764646 (* 1 = 0.764646 loss)
I0506 04:53:18.359237 12834 sgd_solver.cpp:106] Iteration 145100, lr = 4.39805e-06
I0506 04:53:18.363991 12834 solver.cpp:242] Iteration 145100 (106.632 iter/s, 0.937803s/100 iter), loss = 0.735169
I0506 04:53:18.364017 12834 solver.cpp:261]     Train net output #0: loss = 0.735169 (* 1 = 0.735169 loss)
I0506 04:53:18.364035 12834 sgd_solver.cpp:106] Iteration 145100, lr = 4.39805e-06
I0506 04:53:19.296794 12834 solver.cpp:242] Iteration 145200 (106.663 iter/s, 0.937535s/100 iter), loss = 0.582157
I0506 04:53:19.296835 12834 solver.cpp:261]     Train net output #0: loss = 0.582157 (* 1 = 0.582157 loss)
I0506 04:53:19.296845 12834 sgd_solver.cpp:106] Iteration 145200, lr = 4.39805e-06
I0506 04:53:19.301594 12834 solver.cpp:242] Iteration 145200 (106.66 iter/s, 0.937561s/100 iter), loss = 0.605458
I0506 04:53:19.301620 12834 solver.cpp:261]     Train net output #0: loss = 0.605458 (* 1 = 0.605458 loss)
I0506 04:53:19.301627 12834 sgd_solver.cpp:106] Iteration 145200, lr = 4.39805e-06
I0506 04:53:20.234303 12834 solver.cpp:242] Iteration 145300 (106.673 iter/s, 0.937443s/100 iter), loss = 0.46762
I0506 04:53:20.234340 12834 solver.cpp:261]     Train net output #0: loss = 0.46762 (* 1 = 0.46762 loss)
I0506 04:53:20.234349 12834 sgd_solver.cpp:106] Iteration 145300, lr = 4.39805e-06
I0506 04:53:20.239087 12834 solver.cpp:242] Iteration 145300 (106.672 iter/s, 0.937449s/100 iter), loss = 0.46019
I0506 04:53:20.239111 12834 solver.cpp:261]     Train net output #0: loss = 0.46019 (* 1 = 0.46019 loss)
I0506 04:53:20.239120 12834 sgd_solver.cpp:106] Iteration 145300, lr = 4.39805e-06
I0506 04:53:21.172336 12834 solver.cpp:242] Iteration 145400 (106.614 iter/s, 0.937966s/100 iter), loss = 2.24227
I0506 04:53:21.172369 12834 solver.cpp:261]     Train net output #0: loss = 2.24227 (* 1 = 2.24227 loss)
I0506 04:53:21.172379 12834 sgd_solver.cpp:106] Iteration 145400, lr = 4.39805e-06
I0506 04:53:21.177100 12834 solver.cpp:242] Iteration 145400 (106.613 iter/s, 0.937971s/100 iter), loss = 0.485479
I0506 04:53:21.177124 12834 solver.cpp:261]     Train net output #0: loss = 0.485479 (* 1 = 0.485479 loss)
I0506 04:53:21.177134 12834 sgd_solver.cpp:106] Iteration 145400, lr = 4.39805e-06
I0506 04:53:22.107447 12834 solver.cpp:362] Iteration 145500, Testing net (#0)
I0506 04:53:22.107468 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:22.230213 12834 solver.cpp:429]     Test net output #0: loss = 1.29506 (* 1 = 1.29506 loss)
I0506 04:53:22.232727 12834 solver.cpp:242] Iteration 145500 (94.3096 iter/s, 1.06034s/100 iter), loss = 1.24459
I0506 04:53:22.232746 12834 solver.cpp:261]     Train net output #0: loss = 1.24459 (* 1 = 1.24459 loss)
I0506 04:53:22.232755 12834 sgd_solver.cpp:106] Iteration 145500, lr = 4.39805e-06
I0506 04:53:22.234679 12834 solver.cpp:362] Iteration 145500, Testing net (#0)
I0506 04:53:22.234693 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:22.363339 12834 solver.cpp:429]     Test net output #0: accuracy = 0.78
I0506 04:53:22.363359 12834 solver.cpp:429]     Test net output #1: loss = 0.510427 (* 1 = 0.510427 loss)
I0506 04:53:22.365936 12834 solver.cpp:242] Iteration 145500 (84.1191 iter/s, 1.18879s/100 iter), loss = 0.804142
I0506 04:53:22.365957 12834 solver.cpp:261]     Train net output #0: loss = 0.804142 (* 1 = 0.804142 loss)
I0506 04:53:22.365965 12834 sgd_solver.cpp:106] Iteration 145500, lr = 4.39805e-06
I0506 04:53:23.299543 12834 solver.cpp:242] Iteration 145600 (93.7411 iter/s, 1.06677s/100 iter), loss = 1.16537
I0506 04:53:23.299582 12834 solver.cpp:261]     Train net output #0: loss = 1.16537 (* 1 = 1.16537 loss)
I0506 04:53:23.299592 12834 sgd_solver.cpp:106] Iteration 145600, lr = 4.39805e-06
I0506 04:53:23.304330 12834 solver.cpp:242] Iteration 145600 (106.57 iter/s, 0.938355s/100 iter), loss = 0.499457
I0506 04:53:23.304355 12834 solver.cpp:261]     Train net output #0: loss = 0.499457 (* 1 = 0.499457 loss)
I0506 04:53:23.304364 12834 sgd_solver.cpp:106] Iteration 145600, lr = 4.39805e-06
I0506 04:53:24.237330 12834 solver.cpp:242] Iteration 145700 (106.641 iter/s, 0.937727s/100 iter), loss = 0.598137
I0506 04:53:24.237365 12834 solver.cpp:261]     Train net output #0: loss = 0.598137 (* 1 = 0.598137 loss)
I0506 04:53:24.237373 12834 sgd_solver.cpp:106] Iteration 145700, lr = 4.39805e-06
I0506 04:53:24.242161 12834 solver.cpp:242] Iteration 145700 (106.635 iter/s, 0.937778s/100 iter), loss = 0.452583
I0506 04:53:24.242195 12834 solver.cpp:261]     Train net output #0: loss = 0.452583 (* 1 = 0.452583 loss)
I0506 04:53:24.242204 12834 sgd_solver.cpp:106] Iteration 145700, lr = 4.39805e-06
I0506 04:53:25.237679 12834 solver.cpp:242] Iteration 145800 (99.9714 iter/s, 1.00029s/100 iter), loss = 0.878336
I0506 04:53:25.237721 12834 solver.cpp:261]     Train net output #0: loss = 0.878336 (* 1 = 0.878336 loss)
I0506 04:53:25.237732 12834 sgd_solver.cpp:106] Iteration 145800, lr = 4.39805e-06
I0506 04:53:25.242943 12834 solver.cpp:242] Iteration 145800 (99.9273 iter/s, 1.00073s/100 iter), loss = 0.503897
I0506 04:53:25.242970 12834 solver.cpp:261]     Train net output #0: loss = 0.503897 (* 1 = 0.503897 loss)
I0506 04:53:25.242981 12834 sgd_solver.cpp:106] Iteration 145800, lr = 4.39805e-06
I0506 04:53:26.218272 12834 solver.cpp:242] Iteration 145900 (101.987 iter/s, 0.98052s/100 iter), loss = 3.4605
I0506 04:53:26.218312 12834 solver.cpp:261]     Train net output #0: loss = 3.4605 (* 1 = 3.4605 loss)
I0506 04:53:26.218322 12834 sgd_solver.cpp:106] Iteration 145900, lr = 4.39805e-06
I0506 04:53:26.223029 12834 solver.cpp:242] Iteration 145900 (102.037 iter/s, 0.980041s/100 iter), loss = 0.33088
I0506 04:53:26.223055 12834 solver.cpp:261]     Train net output #0: loss = 0.33088 (* 1 = 0.33088 loss)
I0506 04:53:26.223064 12834 sgd_solver.cpp:106] Iteration 145900, lr = 4.39805e-06
I0506 04:53:27.166455 12834 solver.cpp:362] Iteration 146000, Testing net (#0)
I0506 04:53:27.166481 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:27.289180 12834 solver.cpp:429]     Test net output #0: loss = 1.35486 (* 1 = 1.35486 loss)
I0506 04:53:27.291688 12834 solver.cpp:242] Iteration 146000 (93.1657 iter/s, 1.07336s/100 iter), loss = 1.23853
I0506 04:53:27.291710 12834 solver.cpp:261]     Train net output #0: loss = 1.23853 (* 1 = 1.23853 loss)
I0506 04:53:27.291718 12834 sgd_solver.cpp:106] Iteration 146000, lr = 4.39805e-06
I0506 04:53:27.293550 12834 solver.cpp:362] Iteration 146000, Testing net (#0)
I0506 04:53:27.293562 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:27.422300 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7785
I0506 04:53:27.422319 12834 solver.cpp:429]     Test net output #1: loss = 0.511316 (* 1 = 0.511316 loss)
I0506 04:53:27.424876 12834 solver.cpp:242] Iteration 146000 (83.2085 iter/s, 1.2018s/100 iter), loss = 0.571121
I0506 04:53:27.424897 12834 solver.cpp:261]     Train net output #0: loss = 0.571121 (* 1 = 0.571121 loss)
I0506 04:53:27.424907 12834 sgd_solver.cpp:106] Iteration 146000, lr = 4.39805e-06
I0506 04:53:28.358042 12834 solver.cpp:242] Iteration 146100 (93.7826 iter/s, 1.0663s/100 iter), loss = 2.09296
I0506 04:53:28.358084 12834 solver.cpp:261]     Train net output #0: loss = 2.09296 (* 1 = 2.09296 loss)
I0506 04:53:28.358093 12834 sgd_solver.cpp:106] Iteration 146100, lr = 4.39805e-06
I0506 04:53:28.362800 12834 solver.cpp:242] Iteration 146100 (106.623 iter/s, 0.937884s/100 iter), loss = 0.489059
I0506 04:53:28.362826 12834 solver.cpp:261]     Train net output #0: loss = 0.489059 (* 1 = 0.489059 loss)
I0506 04:53:28.362835 12834 sgd_solver.cpp:106] Iteration 146100, lr = 4.39805e-06
I0506 04:53:29.295622 12834 solver.cpp:242] Iteration 146200 (106.665 iter/s, 0.937513s/100 iter), loss = 0.37493
I0506 04:53:29.295662 12834 solver.cpp:261]     Train net output #0: loss = 0.37493 (* 1 = 0.37493 loss)
I0506 04:53:29.295672 12834 sgd_solver.cpp:106] Iteration 146200, lr = 4.39805e-06
I0506 04:53:29.300400 12834 solver.cpp:242] Iteration 146200 (106.661 iter/s, 0.937554s/100 iter), loss = 0.617928
I0506 04:53:29.300426 12834 solver.cpp:261]     Train net output #0: loss = 0.617928 (* 1 = 0.617928 loss)
I0506 04:53:29.300434 12834 sgd_solver.cpp:106] Iteration 146200, lr = 4.39805e-06
I0506 04:53:30.253572 12834 solver.cpp:242] Iteration 146300 (104.398 iter/s, 0.957876s/100 iter), loss = 1.63586
I0506 04:53:30.253618 12834 solver.cpp:261]     Train net output #0: loss = 1.63586 (* 1 = 1.63586 loss)
I0506 04:53:30.253636 12834 sgd_solver.cpp:106] Iteration 146300, lr = 4.39805e-06
I0506 04:53:30.258373 12834 solver.cpp:242] Iteration 146300 (104.392 iter/s, 0.957928s/100 iter), loss = 0.599957
I0506 04:53:30.258399 12834 solver.cpp:261]     Train net output #0: loss = 0.599957 (* 1 = 0.599957 loss)
I0506 04:53:30.258407 12834 sgd_solver.cpp:106] Iteration 146300, lr = 4.39805e-06
I0506 04:53:31.192001 12834 solver.cpp:242] Iteration 146400 (106.569 iter/s, 0.938359s/100 iter), loss = 0.74261
I0506 04:53:31.192042 12834 solver.cpp:261]     Train net output #0: loss = 0.74261 (* 1 = 0.74261 loss)
I0506 04:53:31.192052 12834 sgd_solver.cpp:106] Iteration 146400, lr = 4.39805e-06
I0506 04:53:31.196851 12834 solver.cpp:242] Iteration 146400 (106.562 iter/s, 0.938423s/100 iter), loss = 0.57423
I0506 04:53:31.196877 12834 solver.cpp:261]     Train net output #0: loss = 0.57423 (* 1 = 0.57423 loss)
I0506 04:53:31.196885 12834 sgd_solver.cpp:106] Iteration 146400, lr = 4.39805e-06
I0506 04:53:32.127226 12834 solver.cpp:362] Iteration 146500, Testing net (#0)
I0506 04:53:32.127250 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:32.249779 12834 solver.cpp:429]     Test net output #0: loss = 1.3553 (* 1 = 1.3553 loss)
I0506 04:53:32.252287 12834 solver.cpp:242] Iteration 146500 (94.3196 iter/s, 1.06023s/100 iter), loss = 0.76625
I0506 04:53:32.252307 12834 solver.cpp:261]     Train net output #0: loss = 0.76625 (* 1 = 0.76625 loss)
I0506 04:53:32.252316 12834 sgd_solver.cpp:106] Iteration 146500, lr = 4.39805e-06
I0506 04:53:32.254144 12834 solver.cpp:362] Iteration 146500, Testing net (#0)
I0506 04:53:32.254158 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:32.382844 12834 solver.cpp:429]     Test net output #0: accuracy = 0.773
I0506 04:53:32.382865 12834 solver.cpp:429]     Test net output #1: loss = 0.526794 (* 1 = 0.526794 loss)
I0506 04:53:32.385424 12834 solver.cpp:242] Iteration 146500 (84.1377 iter/s, 1.18853s/100 iter), loss = 0.583117
I0506 04:53:32.385444 12834 solver.cpp:261]     Train net output #0: loss = 0.583117 (* 1 = 0.583117 loss)
I0506 04:53:32.385453 12834 sgd_solver.cpp:106] Iteration 146500, lr = 4.39805e-06
I0506 04:53:33.318513 12834 solver.cpp:242] Iteration 146600 (93.7929 iter/s, 1.06618s/100 iter), loss = 1.48836
I0506 04:53:33.318550 12834 solver.cpp:261]     Train net output #0: loss = 1.48836 (* 1 = 1.48836 loss)
I0506 04:53:33.318560 12834 sgd_solver.cpp:106] Iteration 146600, lr = 4.39805e-06
I0506 04:53:33.323374 12834 solver.cpp:242] Iteration 146600 (106.621 iter/s, 0.9379s/100 iter), loss = 0.914041
I0506 04:53:33.323398 12834 solver.cpp:261]     Train net output #0: loss = 0.914041 (* 1 = 0.914041 loss)
I0506 04:53:33.323407 12834 sgd_solver.cpp:106] Iteration 146600, lr = 4.39805e-06
I0506 04:53:34.256357 12834 solver.cpp:242] Iteration 146700 (106.635 iter/s, 0.937779s/100 iter), loss = 1.07067
I0506 04:53:34.256397 12834 solver.cpp:261]     Train net output #0: loss = 1.07067 (* 1 = 1.07067 loss)
I0506 04:53:34.256405 12834 sgd_solver.cpp:106] Iteration 146700, lr = 4.39805e-06
I0506 04:53:34.261124 12834 solver.cpp:242] Iteration 146700 (106.643 iter/s, 0.937706s/100 iter), loss = 0.644002
I0506 04:53:34.261149 12834 solver.cpp:261]     Train net output #0: loss = 0.644002 (* 1 = 0.644002 loss)
I0506 04:53:34.261158 12834 sgd_solver.cpp:106] Iteration 146700, lr = 4.39805e-06
I0506 04:53:35.259340 12834 solver.cpp:242] Iteration 146800 (99.7101 iter/s, 1.00291s/100 iter), loss = 1.19475
I0506 04:53:35.259384 12834 solver.cpp:261]     Train net output #0: loss = 1.19475 (* 1 = 1.19475 loss)
I0506 04:53:35.259395 12834 sgd_solver.cpp:106] Iteration 146800, lr = 4.39805e-06
I0506 04:53:35.264626 12834 solver.cpp:242] Iteration 146800 (99.6556 iter/s, 1.00346s/100 iter), loss = 0.92418
I0506 04:53:35.264657 12834 solver.cpp:261]     Train net output #0: loss = 0.92418 (* 1 = 0.92418 loss)
I0506 04:53:35.264668 12834 sgd_solver.cpp:106] Iteration 146800, lr = 4.39805e-06
I0506 04:53:36.295078 12834 solver.cpp:242] Iteration 146900 (96.5562 iter/s, 1.03567s/100 iter), loss = 0.882104
I0506 04:53:36.295128 12834 solver.cpp:261]     Train net output #0: loss = 0.882104 (* 1 = 0.882104 loss)
I0506 04:53:36.295140 12834 sgd_solver.cpp:106] Iteration 146900, lr = 4.39805e-06
I0506 04:53:36.300379 12834 solver.cpp:242] Iteration 146900 (96.5529 iter/s, 1.0357s/100 iter), loss = 0.619388
I0506 04:53:36.300406 12834 solver.cpp:261]     Train net output #0: loss = 0.619388 (* 1 = 0.619388 loss)
I0506 04:53:36.300417 12834 sgd_solver.cpp:106] Iteration 146900, lr = 4.39805e-06
I0506 04:53:37.242015 12834 solver.cpp:362] Iteration 147000, Testing net (#0)
I0506 04:53:37.242036 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:37.364594 12834 solver.cpp:429]     Test net output #0: loss = 1.24784 (* 1 = 1.24784 loss)
I0506 04:53:37.367125 12834 solver.cpp:242] Iteration 147000 (93.2854 iter/s, 1.07198s/100 iter), loss = 1.08943
I0506 04:53:37.367146 12834 solver.cpp:261]     Train net output #0: loss = 1.08943 (* 1 = 1.08943 loss)
I0506 04:53:37.367154 12834 sgd_solver.cpp:106] Iteration 147000, lr = 4.39805e-06
I0506 04:53:37.369004 12834 solver.cpp:362] Iteration 147000, Testing net (#0)
I0506 04:53:37.369016 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:37.497848 12834 solver.cpp:429]     Test net output #0: accuracy = 0.773
I0506 04:53:37.497869 12834 solver.cpp:429]     Test net output #1: loss = 0.534481 (* 1 = 0.534481 loss)
I0506 04:53:37.500417 12834 solver.cpp:242] Iteration 147000 (83.334 iter/s, 1.19999s/100 iter), loss = 0.452014
I0506 04:53:37.500437 12834 solver.cpp:261]     Train net output #0: loss = 0.452014 (* 1 = 0.452014 loss)
I0506 04:53:37.500445 12834 sgd_solver.cpp:106] Iteration 147000, lr = 4.39805e-06
I0506 04:53:38.433897 12834 solver.cpp:242] Iteration 147100 (93.745 iter/s, 1.06672s/100 iter), loss = 0.535284
I0506 04:53:38.433933 12834 solver.cpp:261]     Train net output #0: loss = 0.535284 (* 1 = 0.535284 loss)
I0506 04:53:38.433943 12834 sgd_solver.cpp:106] Iteration 147100, lr = 4.39805e-06
I0506 04:53:38.438669 12834 solver.cpp:242] Iteration 147100 (106.586 iter/s, 0.938213s/100 iter), loss = 0.363676
I0506 04:53:38.438694 12834 solver.cpp:261]     Train net output #0: loss = 0.363676 (* 1 = 0.363676 loss)
I0506 04:53:38.438702 12834 sgd_solver.cpp:106] Iteration 147100, lr = 4.39805e-06
I0506 04:53:39.384658 12834 solver.cpp:242] Iteration 147200 (105.186 iter/s, 0.950694s/100 iter), loss = 0.266081
I0506 04:53:39.384694 12834 solver.cpp:261]     Train net output #0: loss = 0.266081 (* 1 = 0.266081 loss)
I0506 04:53:39.384704 12834 sgd_solver.cpp:106] Iteration 147200, lr = 4.39805e-06
I0506 04:53:39.389425 12834 solver.cpp:242] Iteration 147200 (105.184 iter/s, 0.950712s/100 iter), loss = 0.519721
I0506 04:53:39.389449 12834 solver.cpp:261]     Train net output #0: loss = 0.519721 (* 1 = 0.519721 loss)
I0506 04:53:39.389457 12834 sgd_solver.cpp:106] Iteration 147200, lr = 4.39805e-06
I0506 04:53:40.322372 12834 solver.cpp:242] Iteration 147300 (106.649 iter/s, 0.937654s/100 iter), loss = 0.801594
I0506 04:53:40.322405 12834 solver.cpp:261]     Train net output #0: loss = 0.801594 (* 1 = 0.801594 loss)
I0506 04:53:40.322414 12834 sgd_solver.cpp:106] Iteration 147300, lr = 4.39805e-06
I0506 04:53:40.327221 12834 solver.cpp:242] Iteration 147300 (106.639 iter/s, 0.937745s/100 iter), loss = 0.809851
I0506 04:53:40.327245 12834 solver.cpp:261]     Train net output #0: loss = 0.809851 (* 1 = 0.809851 loss)
I0506 04:53:40.327255 12834 sgd_solver.cpp:106] Iteration 147300, lr = 4.39805e-06
I0506 04:53:41.260985 12834 solver.cpp:242] Iteration 147400 (106.547 iter/s, 0.938552s/100 iter), loss = 2.89543
I0506 04:53:41.261026 12834 solver.cpp:261]     Train net output #0: loss = 2.89543 (* 1 = 2.89543 loss)
I0506 04:53:41.261036 12834 sgd_solver.cpp:106] Iteration 147400, lr = 4.39805e-06
I0506 04:53:41.265825 12834 solver.cpp:242] Iteration 147400 (106.546 iter/s, 0.938561s/100 iter), loss = 0.686601
I0506 04:53:41.265852 12834 solver.cpp:261]     Train net output #0: loss = 0.686601 (* 1 = 0.686601 loss)
I0506 04:53:41.265872 12834 sgd_solver.cpp:106] Iteration 147400, lr = 4.39805e-06
I0506 04:53:42.196393 12834 solver.cpp:362] Iteration 147500, Testing net (#0)
I0506 04:53:42.196421 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:42.319021 12834 solver.cpp:429]     Test net output #0: loss = 1.12263 (* 1 = 1.12263 loss)
I0506 04:53:42.321535 12834 solver.cpp:242] Iteration 147500 (94.296 iter/s, 1.06049s/100 iter), loss = 2.12252
I0506 04:53:42.321557 12834 solver.cpp:261]     Train net output #0: loss = 2.12252 (* 1 = 2.12252 loss)
I0506 04:53:42.321565 12834 sgd_solver.cpp:106] Iteration 147500, lr = 4.39805e-06
I0506 04:53:42.323451 12834 solver.cpp:362] Iteration 147500, Testing net (#0)
I0506 04:53:42.323463 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:42.452016 12834 solver.cpp:429]     Test net output #0: accuracy = 0.774
I0506 04:53:42.452036 12834 solver.cpp:429]     Test net output #1: loss = 0.515348 (* 1 = 0.515348 loss)
I0506 04:53:42.454591 12834 solver.cpp:242] Iteration 147500 (84.1243 iter/s, 1.18872s/100 iter), loss = 0.668575
I0506 04:53:42.454612 12834 solver.cpp:261]     Train net output #0: loss = 0.668575 (* 1 = 0.668575 loss)
I0506 04:53:42.454620 12834 sgd_solver.cpp:106] Iteration 147500, lr = 4.39805e-06
I0506 04:53:43.472466 12834 solver.cpp:242] Iteration 147600 (86.8902 iter/s, 1.15088s/100 iter), loss = 0.747476
I0506 04:53:43.472517 12834 solver.cpp:261]     Train net output #0: loss = 0.747476 (* 1 = 0.747476 loss)
I0506 04:53:43.472528 12834 sgd_solver.cpp:106] Iteration 147600, lr = 4.39805e-06
I0506 04:53:43.477768 12834 solver.cpp:242] Iteration 147600 (97.7387 iter/s, 1.02314s/100 iter), loss = 0.122183
I0506 04:53:43.477799 12834 solver.cpp:261]     Train net output #0: loss = 0.122183 (* 1 = 0.122183 loss)
I0506 04:53:43.477810 12834 sgd_solver.cpp:106] Iteration 147600, lr = 4.39805e-06
I0506 04:53:44.451004 12834 solver.cpp:242] Iteration 147700 (102.202 iter/s, 0.978456s/100 iter), loss = 1.14014
I0506 04:53:44.451046 12834 solver.cpp:261]     Train net output #0: loss = 1.14014 (* 1 = 1.14014 loss)
I0506 04:53:44.451056 12834 sgd_solver.cpp:106] Iteration 147700, lr = 4.39805e-06
I0506 04:53:44.455770 12834 solver.cpp:242] Iteration 147700 (102.255 iter/s, 0.977952s/100 iter), loss = 0.64294
I0506 04:53:44.455795 12834 solver.cpp:261]     Train net output #0: loss = 0.64294 (* 1 = 0.64294 loss)
I0506 04:53:44.455802 12834 sgd_solver.cpp:106] Iteration 147700, lr = 4.39805e-06
I0506 04:53:45.388769 12834 solver.cpp:242] Iteration 147800 (106.644 iter/s, 0.937695s/100 iter), loss = 0.412021
I0506 04:53:45.388809 12834 solver.cpp:261]     Train net output #0: loss = 0.412021 (* 1 = 0.412021 loss)
I0506 04:53:45.388819 12834 sgd_solver.cpp:106] Iteration 147800, lr = 4.39805e-06
I0506 04:53:45.393537 12834 solver.cpp:242] Iteration 147800 (106.641 iter/s, 0.937723s/100 iter), loss = 0.29011
I0506 04:53:45.393563 12834 solver.cpp:261]     Train net output #0: loss = 0.29011 (* 1 = 0.29011 loss)
I0506 04:53:45.393573 12834 sgd_solver.cpp:106] Iteration 147800, lr = 4.39805e-06
I0506 04:53:46.326870 12834 solver.cpp:242] Iteration 147900 (106.607 iter/s, 0.938028s/100 iter), loss = 1.18649
I0506 04:53:46.326910 12834 solver.cpp:261]     Train net output #0: loss = 1.18649 (* 1 = 1.18649 loss)
I0506 04:53:46.326920 12834 sgd_solver.cpp:106] Iteration 147900, lr = 4.39805e-06
I0506 04:53:46.331662 12834 solver.cpp:242] Iteration 147900 (106.601 iter/s, 0.93808s/100 iter), loss = 0.516862
I0506 04:53:46.331687 12834 solver.cpp:261]     Train net output #0: loss = 0.516862 (* 1 = 0.516862 loss)
I0506 04:53:46.331696 12834 sgd_solver.cpp:106] Iteration 147900, lr = 4.39805e-06
I0506 04:53:47.262630 12834 solver.cpp:362] Iteration 148000, Testing net (#0)
I0506 04:53:47.262656 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:47.385252 12834 solver.cpp:429]     Test net output #0: loss = 1.23178 (* 1 = 1.23178 loss)
I0506 04:53:47.387768 12834 solver.cpp:242] Iteration 148000 (94.2651 iter/s, 1.06084s/100 iter), loss = 0.467921
I0506 04:53:47.387789 12834 solver.cpp:261]     Train net output #0: loss = 0.467921 (* 1 = 0.467921 loss)
I0506 04:53:47.387805 12834 sgd_solver.cpp:106] Iteration 148000, lr = 4.39805e-06
I0506 04:53:47.389658 12834 solver.cpp:362] Iteration 148000, Testing net (#0)
I0506 04:53:47.389672 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:47.518327 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7785
I0506 04:53:47.518370 12834 solver.cpp:429]     Test net output #1: loss = 0.519656 (* 1 = 0.519656 loss)
I0506 04:53:47.520943 12834 solver.cpp:242] Iteration 148000 (84.0877 iter/s, 1.18923s/100 iter), loss = 0.414137
I0506 04:53:47.520964 12834 solver.cpp:261]     Train net output #0: loss = 0.414137 (* 1 = 0.414137 loss)
I0506 04:53:47.520975 12834 sgd_solver.cpp:106] Iteration 148000, lr = 4.39805e-06
I0506 04:53:48.546164 12834 solver.cpp:242] Iteration 148100 (86.3305 iter/s, 1.15834s/100 iter), loss = 1.39614
I0506 04:53:48.546208 12834 solver.cpp:261]     Train net output #0: loss = 1.39614 (* 1 = 1.39614 loss)
I0506 04:53:48.546221 12834 sgd_solver.cpp:106] Iteration 148100, lr = 4.39805e-06
I0506 04:53:48.551442 12834 solver.cpp:242] Iteration 148100 (97.0443 iter/s, 1.03046s/100 iter), loss = 0.635571
I0506 04:53:48.551473 12834 solver.cpp:261]     Train net output #0: loss = 0.635571 (* 1 = 0.635571 loss)
I0506 04:53:48.551484 12834 sgd_solver.cpp:106] Iteration 148100, lr = 4.39805e-06
I0506 04:53:49.581625 12834 solver.cpp:242] Iteration 148200 (96.582 iter/s, 1.03539s/100 iter), loss = 1.76887
I0506 04:53:49.581676 12834 solver.cpp:261]     Train net output #0: loss = 1.76887 (* 1 = 1.76887 loss)
I0506 04:53:49.581795 12834 sgd_solver.cpp:106] Iteration 148200, lr = 4.39805e-06
I0506 04:53:49.586596 12834 solver.cpp:242] Iteration 148200 (96.6087 iter/s, 1.0351s/100 iter), loss = 0.85328
I0506 04:53:49.586622 12834 solver.cpp:261]     Train net output #0: loss = 0.85328 (* 1 = 0.85328 loss)
I0506 04:53:49.586632 12834 sgd_solver.cpp:106] Iteration 148200, lr = 4.39805e-06
I0506 04:53:50.519783 12834 solver.cpp:242] Iteration 148300 (106.601 iter/s, 0.938079s/100 iter), loss = 2.06726
I0506 04:53:50.519824 12834 solver.cpp:261]     Train net output #0: loss = 2.06726 (* 1 = 2.06726 loss)
I0506 04:53:50.519832 12834 sgd_solver.cpp:106] Iteration 148300, lr = 4.39805e-06
I0506 04:53:50.524564 12834 solver.cpp:242] Iteration 148300 (106.618 iter/s, 0.937924s/100 iter), loss = 0.607938
I0506 04:53:50.524590 12834 solver.cpp:261]     Train net output #0: loss = 0.607938 (* 1 = 0.607938 loss)
I0506 04:53:50.524600 12834 sgd_solver.cpp:106] Iteration 148300, lr = 4.39805e-06
I0506 04:53:51.471123 12834 solver.cpp:242] Iteration 148400 (105.122 iter/s, 0.951278s/100 iter), loss = 2.01816
I0506 04:53:51.471163 12834 solver.cpp:261]     Train net output #0: loss = 2.01816 (* 1 = 2.01816 loss)
I0506 04:53:51.471173 12834 sgd_solver.cpp:106] Iteration 148400, lr = 4.39805e-06
I0506 04:53:51.475970 12834 solver.cpp:242] Iteration 148400 (105.114 iter/s, 0.951352s/100 iter), loss = 0.759663
I0506 04:53:51.475997 12834 solver.cpp:261]     Train net output #0: loss = 0.759663 (* 1 = 0.759663 loss)
I0506 04:53:51.476006 12834 sgd_solver.cpp:106] Iteration 148400, lr = 4.39805e-06
I0506 04:53:52.406579 12834 solver.cpp:362] Iteration 148500, Testing net (#0)
I0506 04:53:52.406600 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:52.529430 12834 solver.cpp:429]     Test net output #0: loss = 1.1595 (* 1 = 1.1595 loss)
I0506 04:53:52.531949 12834 solver.cpp:242] Iteration 148500 (94.2714 iter/s, 1.06077s/100 iter), loss = 0.172495
I0506 04:53:52.531968 12834 solver.cpp:261]     Train net output #0: loss = 0.172495 (* 1 = 0.172495 loss)
I0506 04:53:52.531977 12834 sgd_solver.cpp:106] Iteration 148500, lr = 4.39805e-06
I0506 04:53:52.533802 12834 solver.cpp:362] Iteration 148500, Testing net (#0)
I0506 04:53:52.533814 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:52.662379 12834 solver.cpp:429]     Test net output #0: accuracy = 0.776
I0506 04:53:52.662398 12834 solver.cpp:429]     Test net output #1: loss = 0.521652 (* 1 = 0.521652 loss)
I0506 04:53:52.664958 12834 solver.cpp:242] Iteration 148500 (84.1085 iter/s, 1.18894s/100 iter), loss = 0.578834
I0506 04:53:52.664978 12834 solver.cpp:261]     Train net output #0: loss = 0.578834 (* 1 = 0.578834 loss)
I0506 04:53:52.664988 12834 sgd_solver.cpp:106] Iteration 148500, lr = 4.39805e-06
I0506 04:53:53.600040 12834 solver.cpp:242] Iteration 148600 (93.6299 iter/s, 1.06803s/100 iter), loss = 0.822372
I0506 04:53:53.600085 12834 solver.cpp:261]     Train net output #0: loss = 0.822372 (* 1 = 0.822372 loss)
I0506 04:53:53.600095 12834 sgd_solver.cpp:106] Iteration 148600, lr = 4.39805e-06
I0506 04:53:53.605331 12834 solver.cpp:242] Iteration 148600 (106.345 iter/s, 0.940333s/100 iter), loss = 0.649447
I0506 04:53:53.605360 12834 solver.cpp:261]     Train net output #0: loss = 0.649447 (* 1 = 0.649447 loss)
I0506 04:53:53.605371 12834 sgd_solver.cpp:106] Iteration 148600, lr = 4.39805e-06
I0506 04:53:54.546377 12834 solver.cpp:242] Iteration 148700 (105.678 iter/s, 0.946268s/100 iter), loss = 0.518732
I0506 04:53:54.546413 12834 solver.cpp:261]     Train net output #0: loss = 0.518732 (* 1 = 0.518732 loss)
I0506 04:53:54.546422 12834 sgd_solver.cpp:106] Iteration 148700, lr = 4.39805e-06
I0506 04:53:54.551126 12834 solver.cpp:242] Iteration 148700 (105.737 iter/s, 0.945747s/100 iter), loss = 0.4293
I0506 04:53:54.551151 12834 solver.cpp:261]     Train net output #0: loss = 0.4293 (* 1 = 0.4293 loss)
I0506 04:53:54.551159 12834 sgd_solver.cpp:106] Iteration 148700, lr = 4.39805e-06
I0506 04:53:55.483958 12834 solver.cpp:242] Iteration 148800 (106.665 iter/s, 0.937515s/100 iter), loss = 0.66434
I0506 04:53:55.483991 12834 solver.cpp:261]     Train net output #0: loss = 0.66434 (* 1 = 0.66434 loss)
I0506 04:53:55.484000 12834 sgd_solver.cpp:106] Iteration 148800, lr = 4.39805e-06
I0506 04:53:55.488724 12834 solver.cpp:242] Iteration 148800 (106.66 iter/s, 0.937557s/100 iter), loss = 0.210168
I0506 04:53:55.488749 12834 solver.cpp:261]     Train net output #0: loss = 0.210168 (* 1 = 0.210168 loss)
I0506 04:53:55.488759 12834 sgd_solver.cpp:106] Iteration 148800, lr = 4.39805e-06
I0506 04:53:56.421921 12834 solver.cpp:242] Iteration 148900 (106.621 iter/s, 0.937903s/100 iter), loss = 2.3722
I0506 04:53:56.421963 12834 solver.cpp:261]     Train net output #0: loss = 2.3722 (* 1 = 2.3722 loss)
I0506 04:53:56.421973 12834 sgd_solver.cpp:106] Iteration 148900, lr = 4.39805e-06
I0506 04:53:56.426689 12834 solver.cpp:242] Iteration 148900 (106.619 iter/s, 0.937922s/100 iter), loss = 0.630898
I0506 04:53:56.426715 12834 solver.cpp:261]     Train net output #0: loss = 0.630898 (* 1 = 0.630898 loss)
I0506 04:53:56.426724 12834 sgd_solver.cpp:106] Iteration 148900, lr = 4.39805e-06
I0506 04:53:57.356860 12834 solver.cpp:362] Iteration 149000, Testing net (#0)
I0506 04:53:57.356889 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:57.479434 12834 solver.cpp:429]     Test net output #0: loss = 1.18263 (* 1 = 1.18263 loss)
I0506 04:53:57.481957 12834 solver.cpp:242] Iteration 149000 (94.3418 iter/s, 1.05998s/100 iter), loss = 1.59169
I0506 04:53:57.481977 12834 solver.cpp:261]     Train net output #0: loss = 1.59169 (* 1 = 1.59169 loss)
I0506 04:53:57.481986 12834 sgd_solver.cpp:106] Iteration 149000, lr = 4.39805e-06
I0506 04:53:57.483795 12834 solver.cpp:362] Iteration 149000, Testing net (#0)
I0506 04:53:57.483808 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:53:57.612690 12834 solver.cpp:429]     Test net output #0: accuracy = 0.797
I0506 04:53:57.612709 12834 solver.cpp:429]     Test net output #1: loss = 0.470515 (* 1 = 0.470515 loss)
I0506 04:53:57.615259 12834 solver.cpp:242] Iteration 149000 (84.138 iter/s, 1.18852s/100 iter), loss = 0.536547
I0506 04:53:57.615279 12834 solver.cpp:261]     Train net output #0: loss = 0.536547 (* 1 = 0.536547 loss)
I0506 04:53:57.615288 12834 sgd_solver.cpp:106] Iteration 149000, lr = 4.39805e-06
I0506 04:53:58.548245 12834 solver.cpp:242] Iteration 149100 (93.7874 iter/s, 1.06624s/100 iter), loss = 0.638745
I0506 04:53:58.548296 12834 solver.cpp:261]     Train net output #0: loss = 0.638745 (* 1 = 0.638745 loss)
I0506 04:53:58.548306 12834 sgd_solver.cpp:106] Iteration 149100, lr = 4.39805e-06
I0506 04:53:58.553091 12834 solver.cpp:242] Iteration 149100 (106.633 iter/s, 0.937793s/100 iter), loss = 0.756485
I0506 04:53:58.553117 12834 solver.cpp:261]     Train net output #0: loss = 0.756485 (* 1 = 0.756485 loss)
I0506 04:53:58.553127 12834 sgd_solver.cpp:106] Iteration 149100, lr = 4.39805e-06
I0506 04:53:59.485968 12834 solver.cpp:242] Iteration 149200 (106.651 iter/s, 0.937642s/100 iter), loss = 1.64071
I0506 04:53:59.486011 12834 solver.cpp:261]     Train net output #0: loss = 1.64071 (* 1 = 1.64071 loss)
I0506 04:53:59.486021 12834 sgd_solver.cpp:106] Iteration 149200, lr = 4.39805e-06
I0506 04:53:59.490751 12834 solver.cpp:242] Iteration 149200 (106.653 iter/s, 0.937616s/100 iter), loss = 0.463636
I0506 04:53:59.490775 12834 solver.cpp:261]     Train net output #0: loss = 0.463636 (* 1 = 0.463636 loss)
I0506 04:53:59.490784 12834 sgd_solver.cpp:106] Iteration 149200, lr = 4.39805e-06
I0506 04:54:00.428984 12834 solver.cpp:242] Iteration 149300 (106.05 iter/s, 0.942947s/100 iter), loss = 1.34738
I0506 04:54:00.429044 12834 solver.cpp:261]     Train net output #0: loss = 1.34738 (* 1 = 1.34738 loss)
I0506 04:54:00.429270 12834 sgd_solver.cpp:106] Iteration 149300, lr = 4.39805e-06
I0506 04:54:00.434134 12834 solver.cpp:242] Iteration 149300 (106.007 iter/s, 0.94333s/100 iter), loss = 0.633148
I0506 04:54:00.434160 12834 solver.cpp:261]     Train net output #0: loss = 0.633148 (* 1 = 0.633148 loss)
I0506 04:54:00.434170 12834 sgd_solver.cpp:106] Iteration 149300, lr = 4.39805e-06
I0506 04:54:01.370054 12834 solver.cpp:242] Iteration 149400 (106.271 iter/s, 0.940988s/100 iter), loss = 0.321332
I0506 04:54:01.370095 12834 solver.cpp:261]     Train net output #0: loss = 0.321332 (* 1 = 0.321332 loss)
I0506 04:54:01.370105 12834 sgd_solver.cpp:106] Iteration 149400, lr = 4.39805e-06
I0506 04:54:01.374824 12834 solver.cpp:242] Iteration 149400 (106.31 iter/s, 0.940645s/100 iter), loss = 0.38073
I0506 04:54:01.374848 12834 solver.cpp:261]     Train net output #0: loss = 0.38073 (* 1 = 0.38073 loss)
I0506 04:54:01.374856 12834 sgd_solver.cpp:106] Iteration 149400, lr = 4.39805e-06
I0506 04:54:02.304980 12834 solver.cpp:362] Iteration 149500, Testing net (#0)
I0506 04:54:02.305006 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:02.427857 12834 solver.cpp:429]     Test net output #0: loss = 1.28717 (* 1 = 1.28717 loss)
I0506 04:54:02.430382 12834 solver.cpp:242] Iteration 149500 (94.3158 iter/s, 1.06027s/100 iter), loss = 1.43595
I0506 04:54:02.430402 12834 solver.cpp:261]     Train net output #0: loss = 1.43595 (* 1 = 1.43595 loss)
I0506 04:54:02.430409 12834 sgd_solver.cpp:106] Iteration 149500, lr = 4.39805e-06
I0506 04:54:02.432237 12834 solver.cpp:362] Iteration 149500, Testing net (#0)
I0506 04:54:02.432251 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:02.561053 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7695
I0506 04:54:02.561074 12834 solver.cpp:429]     Test net output #1: loss = 0.515874 (* 1 = 0.515874 loss)
I0506 04:54:02.563621 12834 solver.cpp:242] Iteration 149500 (84.1218 iter/s, 1.18875s/100 iter), loss = 0.610359
I0506 04:54:02.563640 12834 solver.cpp:261]     Train net output #0: loss = 0.610359 (* 1 = 0.610359 loss)
I0506 04:54:02.563648 12834 sgd_solver.cpp:106] Iteration 149500, lr = 4.39805e-06
I0506 04:54:03.496840 12834 solver.cpp:242] Iteration 149600 (93.7727 iter/s, 1.06641s/100 iter), loss = 0.924641
I0506 04:54:03.496879 12834 solver.cpp:261]     Train net output #0: loss = 0.924641 (* 1 = 0.924641 loss)
I0506 04:54:03.496889 12834 sgd_solver.cpp:106] Iteration 149600, lr = 4.39805e-06
I0506 04:54:03.501601 12834 solver.cpp:242] Iteration 149600 (106.616 iter/s, 0.937942s/100 iter), loss = 0.356986
I0506 04:54:03.501626 12834 solver.cpp:261]     Train net output #0: loss = 0.356986 (* 1 = 0.356986 loss)
I0506 04:54:03.501636 12834 sgd_solver.cpp:106] Iteration 149600, lr = 4.39805e-06
I0506 04:54:04.434685 12834 solver.cpp:242] Iteration 149700 (106.635 iter/s, 0.937775s/100 iter), loss = 2.8635
I0506 04:54:04.434725 12834 solver.cpp:261]     Train net output #0: loss = 2.8635 (* 1 = 2.8635 loss)
I0506 04:54:04.434734 12834 sgd_solver.cpp:106] Iteration 149700, lr = 4.39805e-06
I0506 04:54:04.439465 12834 solver.cpp:242] Iteration 149700 (106.63 iter/s, 0.937821s/100 iter), loss = 0.498848
I0506 04:54:04.439489 12834 solver.cpp:261]     Train net output #0: loss = 0.498848 (* 1 = 0.498848 loss)
I0506 04:54:04.439497 12834 sgd_solver.cpp:106] Iteration 149700, lr = 4.39805e-06
I0506 04:54:05.455898 12834 solver.cpp:242] Iteration 149800 (97.9295 iter/s, 1.02114s/100 iter), loss = 0.99886
I0506 04:54:05.455945 12834 solver.cpp:261]     Train net output #0: loss = 0.99886 (* 1 = 0.99886 loss)
I0506 04:54:05.456141 12834 sgd_solver.cpp:106] Iteration 149800, lr = 4.39805e-06
I0506 04:54:05.460935 12834 solver.cpp:242] Iteration 149800 (97.9023 iter/s, 1.02143s/100 iter), loss = 0.36099
I0506 04:54:05.460959 12834 solver.cpp:261]     Train net output #0: loss = 0.36099 (* 1 = 0.36099 loss)
I0506 04:54:05.460969 12834 sgd_solver.cpp:106] Iteration 149800, lr = 4.39805e-06
I0506 04:54:06.393770 12834 solver.cpp:242] Iteration 149900 (106.633 iter/s, 0.937796s/100 iter), loss = 1.11111
I0506 04:54:06.393807 12834 solver.cpp:261]     Train net output #0: loss = 1.11111 (* 1 = 1.11111 loss)
I0506 04:54:06.393816 12834 sgd_solver.cpp:106] Iteration 149900, lr = 4.39805e-06
I0506 04:54:06.398542 12834 solver.cpp:242] Iteration 149900 (106.659 iter/s, 0.937564s/100 iter), loss = 0.734087
I0506 04:54:06.398566 12834 solver.cpp:261]     Train net output #0: loss = 0.734087 (* 1 = 0.734087 loss)
I0506 04:54:06.398576 12834 sgd_solver.cpp:106] Iteration 149900, lr = 4.39805e-06
I0506 04:54:07.322867 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_150000.caffemodel
I0506 04:54:07.339864 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_150000.solverstate
I0506 04:54:07.353232 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_150000.caffemodel
I0506 04:54:07.370456 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_150000.solverstate
I0506 04:54:07.380789 12834 solver.cpp:362] Iteration 150000, Testing net (#0)
I0506 04:54:07.380815 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:07.503681 12834 solver.cpp:429]     Test net output #0: loss = 1.37002 (* 1 = 1.37002 loss)
I0506 04:54:07.506212 12834 solver.cpp:242] Iteration 150000 (89.8969 iter/s, 1.11239s/100 iter), loss = 0.917827
I0506 04:54:07.506233 12834 solver.cpp:261]     Train net output #0: loss = 0.917827 (* 1 = 0.917827 loss)
I0506 04:54:07.506242 12834 sgd_solver.cpp:106] Iteration 150000, lr = 3.51844e-06
I0506 04:54:07.508136 12834 solver.cpp:362] Iteration 150000, Testing net (#0)
I0506 04:54:07.508148 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:07.636950 12834 solver.cpp:429]     Test net output #0: accuracy = 0.775
I0506 04:54:07.636970 12834 solver.cpp:429]     Test net output #1: loss = 0.525289 (* 1 = 0.525289 loss)
I0506 04:54:07.639536 12834 solver.cpp:242] Iteration 150000 (80.5835 iter/s, 1.24095s/100 iter), loss = 0.422192
I0506 04:54:07.639564 12834 solver.cpp:261]     Train net output #0: loss = 0.422192 (* 1 = 0.422192 loss)
I0506 04:54:07.639574 12834 sgd_solver.cpp:106] Iteration 150000, lr = 3.51844e-06
I0506 04:54:08.572957 12834 solver.cpp:242] Iteration 150100 (93.7479 iter/s, 1.06669s/100 iter), loss = 4.19103
I0506 04:54:08.572989 12834 solver.cpp:261]     Train net output #0: loss = 4.19103 (* 1 = 4.19103 loss)
I0506 04:54:08.572999 12834 sgd_solver.cpp:106] Iteration 150100, lr = 3.51844e-06
I0506 04:54:08.577771 12834 solver.cpp:242] Iteration 150100 (106.589 iter/s, 0.938187s/100 iter), loss = 0.692877
I0506 04:54:08.577800 12834 solver.cpp:261]     Train net output #0: loss = 0.692877 (* 1 = 0.692877 loss)
I0506 04:54:08.577811 12834 sgd_solver.cpp:106] Iteration 150100, lr = 3.51844e-06
I0506 04:54:09.524788 12834 solver.cpp:242] Iteration 150200 (105.067 iter/s, 0.951775s/100 iter), loss = 0.495803
I0506 04:54:09.524816 12834 solver.cpp:261]     Train net output #0: loss = 0.495803 (* 1 = 0.495803 loss)
I0506 04:54:09.524826 12834 sgd_solver.cpp:106] Iteration 150200, lr = 3.51844e-06
I0506 04:54:09.529665 12834 solver.cpp:242] Iteration 150200 (105.06 iter/s, 0.951838s/100 iter), loss = 0.397591
I0506 04:54:09.529690 12834 solver.cpp:261]     Train net output #0: loss = 0.397591 (* 1 = 0.397591 loss)
I0506 04:54:09.529700 12834 sgd_solver.cpp:106] Iteration 150200, lr = 3.51844e-06
I0506 04:54:10.463048 12834 solver.cpp:242] Iteration 150300 (106.587 iter/s, 0.938204s/100 iter), loss = 1.03487
I0506 04:54:10.463104 12834 solver.cpp:261]     Train net output #0: loss = 1.03487 (* 1 = 1.03487 loss)
I0506 04:54:10.463176 12834 sgd_solver.cpp:106] Iteration 150300, lr = 3.51844e-06
I0506 04:54:10.467932 12834 solver.cpp:242] Iteration 150300 (106.584 iter/s, 0.938224s/100 iter), loss = 0.439483
I0506 04:54:10.467958 12834 solver.cpp:261]     Train net output #0: loss = 0.439483 (* 1 = 0.439483 loss)
I0506 04:54:10.467967 12834 sgd_solver.cpp:106] Iteration 150300, lr = 3.51844e-06
I0506 04:54:11.400903 12834 solver.cpp:242] Iteration 150400 (106.635 iter/s, 0.937779s/100 iter), loss = 1.0898
I0506 04:54:11.400945 12834 solver.cpp:261]     Train net output #0: loss = 1.0898 (* 1 = 1.0898 loss)
I0506 04:54:11.400955 12834 sgd_solver.cpp:106] Iteration 150400, lr = 3.51844e-06
I0506 04:54:11.405679 12834 solver.cpp:242] Iteration 150400 (106.645 iter/s, 0.937693s/100 iter), loss = 0.328759
I0506 04:54:11.405705 12834 solver.cpp:261]     Train net output #0: loss = 0.328759 (* 1 = 0.328759 loss)
I0506 04:54:11.405715 12834 sgd_solver.cpp:106] Iteration 150400, lr = 3.51844e-06
I0506 04:54:12.335675 12834 solver.cpp:362] Iteration 150500, Testing net (#0)
I0506 04:54:12.335703 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:12.458325 12834 solver.cpp:429]     Test net output #0: loss = 1.08111 (* 1 = 1.08111 loss)
I0506 04:54:12.460844 12834 solver.cpp:242] Iteration 150500 (94.3503 iter/s, 1.05988s/100 iter), loss = 0.45993
I0506 04:54:12.460865 12834 solver.cpp:261]     Train net output #0: loss = 0.45993 (* 1 = 0.45993 loss)
I0506 04:54:12.460873 12834 sgd_solver.cpp:106] Iteration 150500, lr = 3.51844e-06
I0506 04:54:12.462684 12834 solver.cpp:362] Iteration 150500, Testing net (#0)
I0506 04:54:12.462697 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:12.591486 12834 solver.cpp:429]     Test net output #0: accuracy = 0.783
I0506 04:54:12.591506 12834 solver.cpp:429]     Test net output #1: loss = 0.517468 (* 1 = 0.517468 loss)
I0506 04:54:12.594056 12834 solver.cpp:242] Iteration 150500 (84.1518 iter/s, 1.18833s/100 iter), loss = 0.366873
I0506 04:54:12.594076 12834 solver.cpp:261]     Train net output #0: loss = 0.366873 (* 1 = 0.366873 loss)
I0506 04:54:12.594085 12834 sgd_solver.cpp:106] Iteration 150500, lr = 3.51844e-06
I0506 04:54:13.527346 12834 solver.cpp:242] Iteration 150600 (93.7693 iter/s, 1.06645s/100 iter), loss = 1.08069
I0506 04:54:13.527387 12834 solver.cpp:261]     Train net output #0: loss = 1.08069 (* 1 = 1.08069 loss)
I0506 04:54:13.527405 12834 sgd_solver.cpp:106] Iteration 150600, lr = 3.51844e-06
I0506 04:54:13.532133 12834 solver.cpp:242] Iteration 150600 (106.605 iter/s, 0.938038s/100 iter), loss = 0.406468
I0506 04:54:13.532158 12834 solver.cpp:261]     Train net output #0: loss = 0.406468 (* 1 = 0.406468 loss)
I0506 04:54:13.532167 12834 sgd_solver.cpp:106] Iteration 150600, lr = 3.51844e-06
I0506 04:54:14.465211 12834 solver.cpp:242] Iteration 150700 (106.633 iter/s, 0.937798s/100 iter), loss = 0.724348
I0506 04:54:14.465252 12834 solver.cpp:261]     Train net output #0: loss = 0.724348 (* 1 = 0.724348 loss)
I0506 04:54:14.465261 12834 sgd_solver.cpp:106] Iteration 150700, lr = 3.51844e-06
I0506 04:54:14.469977 12834 solver.cpp:242] Iteration 150700 (106.632 iter/s, 0.937801s/100 iter), loss = 0.675314
I0506 04:54:14.470000 12834 solver.cpp:261]     Train net output #0: loss = 0.675314 (* 1 = 0.675314 loss)
I0506 04:54:14.470010 12834 sgd_solver.cpp:106] Iteration 150700, lr = 3.51844e-06
I0506 04:54:15.416488 12834 solver.cpp:242] Iteration 150800 (105.13 iter/s, 0.951206s/100 iter), loss = 0.61886
I0506 04:54:15.416527 12834 solver.cpp:261]     Train net output #0: loss = 0.61886 (* 1 = 0.61886 loss)
I0506 04:54:15.416538 12834 sgd_solver.cpp:106] Iteration 150800, lr = 3.51844e-06
I0506 04:54:15.421257 12834 solver.cpp:242] Iteration 150800 (105.126 iter/s, 0.951238s/100 iter), loss = 0.499297
I0506 04:54:15.421283 12834 solver.cpp:261]     Train net output #0: loss = 0.499297 (* 1 = 0.499297 loss)
I0506 04:54:15.421291 12834 sgd_solver.cpp:106] Iteration 150800, lr = 3.51844e-06
I0506 04:54:16.354071 12834 solver.cpp:242] Iteration 150900 (106.665 iter/s, 0.937517s/100 iter), loss = 1.11238
I0506 04:54:16.354110 12834 solver.cpp:261]     Train net output #0: loss = 1.11238 (* 1 = 1.11238 loss)
I0506 04:54:16.354120 12834 sgd_solver.cpp:106] Iteration 150900, lr = 3.51844e-06
I0506 04:54:16.358852 12834 solver.cpp:242] Iteration 150900 (106.661 iter/s, 0.937551s/100 iter), loss = 0.534239
I0506 04:54:16.358878 12834 solver.cpp:261]     Train net output #0: loss = 0.534239 (* 1 = 0.534239 loss)
I0506 04:54:16.358887 12834 sgd_solver.cpp:106] Iteration 150900, lr = 3.51844e-06
I0506 04:54:17.289263 12834 solver.cpp:362] Iteration 151000, Testing net (#0)
I0506 04:54:17.289288 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:17.412000 12834 solver.cpp:429]     Test net output #0: loss = 1.15333 (* 1 = 1.15333 loss)
I0506 04:54:17.414520 12834 solver.cpp:242] Iteration 151000 (94.3047 iter/s, 1.06039s/100 iter), loss = 1.19691
I0506 04:54:17.414541 12834 solver.cpp:261]     Train net output #0: loss = 1.19691 (* 1 = 1.19691 loss)
I0506 04:54:17.414549 12834 sgd_solver.cpp:106] Iteration 151000, lr = 3.51844e-06
I0506 04:54:17.416370 12834 solver.cpp:362] Iteration 151000, Testing net (#0)
I0506 04:54:17.416383 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:17.545074 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7735
I0506 04:54:17.545094 12834 solver.cpp:429]     Test net output #1: loss = 0.537973 (* 1 = 0.537973 loss)
I0506 04:54:17.547654 12834 solver.cpp:242] Iteration 151000 (84.1216 iter/s, 1.18876s/100 iter), loss = 0.601179
I0506 04:54:17.547673 12834 solver.cpp:261]     Train net output #0: loss = 0.601179 (* 1 = 0.601179 loss)
I0506 04:54:17.547683 12834 sgd_solver.cpp:106] Iteration 151000, lr = 3.51844e-06
I0506 04:54:18.480624 12834 solver.cpp:242] Iteration 151100 (93.8036 iter/s, 1.06606s/100 iter), loss = 0.722176
I0506 04:54:18.480662 12834 solver.cpp:261]     Train net output #0: loss = 0.722176 (* 1 = 0.722176 loss)
I0506 04:54:18.480672 12834 sgd_solver.cpp:106] Iteration 151100, lr = 3.51844e-06
I0506 04:54:18.485471 12834 solver.cpp:242] Iteration 151100 (106.636 iter/s, 0.93777s/100 iter), loss = 0.569988
I0506 04:54:18.485496 12834 solver.cpp:261]     Train net output #0: loss = 0.569988 (* 1 = 0.569988 loss)
I0506 04:54:18.485504 12834 sgd_solver.cpp:106] Iteration 151100, lr = 3.51844e-06
I0506 04:54:19.418700 12834 solver.cpp:242] Iteration 151200 (106.609 iter/s, 0.938011s/100 iter), loss = 1.11312
I0506 04:54:19.418746 12834 solver.cpp:261]     Train net output #0: loss = 1.11312 (* 1 = 1.11312 loss)
I0506 04:54:19.418756 12834 sgd_solver.cpp:106] Iteration 151200, lr = 3.51844e-06
I0506 04:54:19.423486 12834 solver.cpp:242] Iteration 151200 (106.613 iter/s, 0.937972s/100 iter), loss = 0.767313
I0506 04:54:19.423511 12834 solver.cpp:261]     Train net output #0: loss = 0.767313 (* 1 = 0.767313 loss)
I0506 04:54:19.423519 12834 sgd_solver.cpp:106] Iteration 151200, lr = 3.51844e-06
I0506 04:54:20.355840 12834 solver.cpp:242] Iteration 151300 (106.715 iter/s, 0.937072s/100 iter), loss = 3.21989
I0506 04:54:20.355871 12834 solver.cpp:261]     Train net output #0: loss = 3.21989 (* 1 = 3.21989 loss)
I0506 04:54:20.355880 12834 sgd_solver.cpp:106] Iteration 151300, lr = 3.51844e-06
I0506 04:54:20.360713 12834 solver.cpp:242] Iteration 151300 (106.704 iter/s, 0.937176s/100 iter), loss = 0.67688
I0506 04:54:20.360738 12834 solver.cpp:261]     Train net output #0: loss = 0.67688 (* 1 = 0.67688 loss)
I0506 04:54:20.360746 12834 sgd_solver.cpp:106] Iteration 151300, lr = 3.51844e-06
I0506 04:54:21.306987 12834 solver.cpp:242] Iteration 151400 (105.143 iter/s, 0.951087s/100 iter), loss = 0.519547
I0506 04:54:21.307036 12834 solver.cpp:261]     Train net output #0: loss = 0.519547 (* 1 = 0.519547 loss)
I0506 04:54:21.307282 12834 sgd_solver.cpp:106] Iteration 151400, lr = 3.51844e-06
I0506 04:54:21.312047 12834 solver.cpp:242] Iteration 151400 (105.12 iter/s, 0.951291s/100 iter), loss = 0.465098
I0506 04:54:21.312072 12834 solver.cpp:261]     Train net output #0: loss = 0.465098 (* 1 = 0.465098 loss)
I0506 04:54:21.312080 12834 sgd_solver.cpp:106] Iteration 151400, lr = 3.51844e-06
I0506 04:54:22.242591 12834 solver.cpp:362] Iteration 151500, Testing net (#0)
I0506 04:54:22.242620 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:22.365274 12834 solver.cpp:429]     Test net output #0: loss = 1.25534 (* 1 = 1.25534 loss)
I0506 04:54:22.367790 12834 solver.cpp:242] Iteration 151500 (94.274 iter/s, 1.06074s/100 iter), loss = 0.962942
I0506 04:54:22.367810 12834 solver.cpp:261]     Train net output #0: loss = 0.962942 (* 1 = 0.962942 loss)
I0506 04:54:22.367820 12834 sgd_solver.cpp:106] Iteration 151500, lr = 3.51844e-06
I0506 04:54:22.369649 12834 solver.cpp:362] Iteration 151500, Testing net (#0)
I0506 04:54:22.369663 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:22.498493 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7755
I0506 04:54:22.498512 12834 solver.cpp:429]     Test net output #1: loss = 0.508747 (* 1 = 0.508747 loss)
I0506 04:54:22.501065 12834 solver.cpp:242] Iteration 151500 (84.1062 iter/s, 1.18897s/100 iter), loss = 0.762037
I0506 04:54:22.501085 12834 solver.cpp:261]     Train net output #0: loss = 0.762037 (* 1 = 0.762037 loss)
I0506 04:54:22.501094 12834 sgd_solver.cpp:106] Iteration 151500, lr = 3.51844e-06
I0506 04:54:23.523844 12834 solver.cpp:242] Iteration 151600 (86.5051 iter/s, 1.156s/100 iter), loss = 1.38752
I0506 04:54:23.523885 12834 solver.cpp:261]     Train net output #0: loss = 1.38752 (* 1 = 1.38752 loss)
I0506 04:54:23.523895 12834 sgd_solver.cpp:106] Iteration 151600, lr = 3.51844e-06
I0506 04:54:23.529135 12834 solver.cpp:242] Iteration 151600 (97.2734 iter/s, 1.02803s/100 iter), loss = 0.582386
I0506 04:54:23.529163 12834 solver.cpp:261]     Train net output #0: loss = 0.582386 (* 1 = 0.582386 loss)
I0506 04:54:23.529175 12834 sgd_solver.cpp:106] Iteration 151600, lr = 3.51844e-06
I0506 04:54:24.559366 12834 solver.cpp:242] Iteration 151700 (96.5764 iter/s, 1.03545s/100 iter), loss = 0.410985
I0506 04:54:24.559401 12834 solver.cpp:261]     Train net output #0: loss = 0.410985 (* 1 = 0.410985 loss)
I0506 04:54:24.559412 12834 sgd_solver.cpp:106] Iteration 151700, lr = 3.51844e-06
I0506 04:54:24.564656 12834 solver.cpp:242] Iteration 151700 (96.5743 iter/s, 1.03547s/100 iter), loss = 0.522629
I0506 04:54:24.564684 12834 solver.cpp:261]     Train net output #0: loss = 0.522629 (* 1 = 0.522629 loss)
I0506 04:54:24.564705 12834 sgd_solver.cpp:106] Iteration 151700, lr = 3.51844e-06
I0506 04:54:25.594601 12834 solver.cpp:242] Iteration 151800 (96.6022 iter/s, 1.03517s/100 iter), loss = 1.0054
I0506 04:54:25.594650 12834 solver.cpp:261]     Train net output #0: loss = 1.0054 (* 1 = 1.0054 loss)
I0506 04:54:25.594660 12834 sgd_solver.cpp:106] Iteration 151800, lr = 3.51844e-06
I0506 04:54:25.599905 12834 solver.cpp:242] Iteration 151800 (96.5996 iter/s, 1.0352s/100 iter), loss = 0.319263
I0506 04:54:25.599934 12834 solver.cpp:261]     Train net output #0: loss = 0.319263 (* 1 = 0.319263 loss)
I0506 04:54:25.599946 12834 sgd_solver.cpp:106] Iteration 151800, lr = 3.51844e-06
I0506 04:54:26.541762 12834 solver.cpp:242] Iteration 151900 (105.587 iter/s, 0.947084s/100 iter), loss = 0.997075
I0506 04:54:26.541806 12834 solver.cpp:261]     Train net output #0: loss = 0.997075 (* 1 = 0.997075 loss)
I0506 04:54:26.541816 12834 sgd_solver.cpp:106] Iteration 151900, lr = 3.51844e-06
I0506 04:54:26.546516 12834 solver.cpp:242] Iteration 151900 (105.645 iter/s, 0.946564s/100 iter), loss = 0.80268
I0506 04:54:26.546541 12834 solver.cpp:261]     Train net output #0: loss = 0.80268 (* 1 = 0.80268 loss)
I0506 04:54:26.546550 12834 sgd_solver.cpp:106] Iteration 151900, lr = 3.51844e-06
I0506 04:54:27.476943 12834 solver.cpp:362] Iteration 152000, Testing net (#0)
I0506 04:54:27.476971 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:27.599699 12834 solver.cpp:429]     Test net output #0: loss = 1.24041 (* 1 = 1.24041 loss)
I0506 04:54:27.602222 12834 solver.cpp:242] Iteration 152000 (94.3043 iter/s, 1.0604s/100 iter), loss = 1.8899
I0506 04:54:27.602244 12834 solver.cpp:261]     Train net output #0: loss = 1.8899 (* 1 = 1.8899 loss)
I0506 04:54:27.602253 12834 sgd_solver.cpp:106] Iteration 152000, lr = 3.51844e-06
I0506 04:54:27.604177 12834 solver.cpp:362] Iteration 152000, Testing net (#0)
I0506 04:54:27.604190 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:27.732967 12834 solver.cpp:429]     Test net output #0: accuracy = 0.788
I0506 04:54:27.732985 12834 solver.cpp:429]     Test net output #1: loss = 0.508078 (* 1 = 0.508078 loss)
I0506 04:54:27.735549 12834 solver.cpp:242] Iteration 152000 (84.1052 iter/s, 1.18899s/100 iter), loss = 0.364771
I0506 04:54:27.735569 12834 solver.cpp:261]     Train net output #0: loss = 0.364771 (* 1 = 0.364771 loss)
I0506 04:54:27.735579 12834 sgd_solver.cpp:106] Iteration 152000, lr = 3.51844e-06
I0506 04:54:28.669011 12834 solver.cpp:242] Iteration 152100 (93.7439 iter/s, 1.06674s/100 iter), loss = 0.617286
I0506 04:54:28.669051 12834 solver.cpp:261]     Train net output #0: loss = 0.617286 (* 1 = 0.617286 loss)
I0506 04:54:28.669061 12834 sgd_solver.cpp:106] Iteration 152100, lr = 3.51844e-06
I0506 04:54:28.673792 12834 solver.cpp:242] Iteration 152100 (106.587 iter/s, 0.938204s/100 iter), loss = 0.296648
I0506 04:54:28.673817 12834 solver.cpp:261]     Train net output #0: loss = 0.296648 (* 1 = 0.296648 loss)
I0506 04:54:28.673826 12834 sgd_solver.cpp:106] Iteration 152100, lr = 3.51844e-06
I0506 04:54:29.606446 12834 solver.cpp:242] Iteration 152200 (106.682 iter/s, 0.93737s/100 iter), loss = 1.95505
I0506 04:54:29.606487 12834 solver.cpp:261]     Train net output #0: loss = 1.95505 (* 1 = 1.95505 loss)
I0506 04:54:29.606498 12834 sgd_solver.cpp:106] Iteration 152200, lr = 3.51844e-06
I0506 04:54:29.611297 12834 solver.cpp:242] Iteration 152200 (106.673 iter/s, 0.937442s/100 iter), loss = 0.437005
I0506 04:54:29.611322 12834 solver.cpp:261]     Train net output #0: loss = 0.437005 (* 1 = 0.437005 loss)
I0506 04:54:29.611332 12834 sgd_solver.cpp:106] Iteration 152200, lr = 3.51844e-06
I0506 04:54:30.544292 12834 solver.cpp:242] Iteration 152300 (106.635 iter/s, 0.937777s/100 iter), loss = 0.216338
I0506 04:54:30.544330 12834 solver.cpp:261]     Train net output #0: loss = 0.216338 (* 1 = 0.216338 loss)
I0506 04:54:30.544340 12834 sgd_solver.cpp:106] Iteration 152300, lr = 3.51844e-06
I0506 04:54:30.549065 12834 solver.cpp:242] Iteration 152300 (106.641 iter/s, 0.937724s/100 iter), loss = 0.454605
I0506 04:54:30.549099 12834 solver.cpp:261]     Train net output #0: loss = 0.454605 (* 1 = 0.454605 loss)
I0506 04:54:30.549109 12834 sgd_solver.cpp:106] Iteration 152300, lr = 3.51844e-06
I0506 04:54:31.576189 12834 solver.cpp:242] Iteration 152400 (96.9159 iter/s, 1.03182s/100 iter), loss = 0.207924
I0506 04:54:31.576238 12834 solver.cpp:261]     Train net output #0: loss = 0.207924 (* 1 = 0.207924 loss)
I0506 04:54:31.576331 12834 sgd_solver.cpp:106] Iteration 152400, lr = 3.51844e-06
I0506 04:54:31.581143 12834 solver.cpp:242] Iteration 152400 (96.897 iter/s, 1.03202s/100 iter), loss = 0.327837
I0506 04:54:31.581166 12834 solver.cpp:261]     Train net output #0: loss = 0.327837 (* 1 = 0.327837 loss)
I0506 04:54:31.581176 12834 sgd_solver.cpp:106] Iteration 152400, lr = 3.51844e-06
I0506 04:54:32.511282 12834 solver.cpp:362] Iteration 152500, Testing net (#0)
I0506 04:54:32.511309 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:32.634033 12834 solver.cpp:429]     Test net output #0: loss = 1.17429 (* 1 = 1.17429 loss)
I0506 04:54:32.636546 12834 solver.cpp:242] Iteration 152500 (94.3137 iter/s, 1.06029s/100 iter), loss = 0.162356
I0506 04:54:32.636574 12834 solver.cpp:261]     Train net output #0: loss = 0.162356 (* 1 = 0.162356 loss)
I0506 04:54:32.636582 12834 sgd_solver.cpp:106] Iteration 152500, lr = 3.51844e-06
I0506 04:54:32.638401 12834 solver.cpp:362] Iteration 152500, Testing net (#0)
I0506 04:54:32.638413 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:32.767246 12834 solver.cpp:429]     Test net output #0: accuracy = 0.788
I0506 04:54:32.767264 12834 solver.cpp:429]     Test net output #1: loss = 0.496056 (* 1 = 0.496056 loss)
I0506 04:54:32.769816 12834 solver.cpp:242] Iteration 152500 (84.1306 iter/s, 1.18863s/100 iter), loss = 0.152362
I0506 04:54:32.769837 12834 solver.cpp:261]     Train net output #0: loss = 0.152362 (* 1 = 0.152362 loss)
I0506 04:54:32.769846 12834 sgd_solver.cpp:106] Iteration 152500, lr = 3.51844e-06
I0506 04:54:33.703675 12834 solver.cpp:242] Iteration 152600 (93.7147 iter/s, 1.06707s/100 iter), loss = 0.469216
I0506 04:54:33.703714 12834 solver.cpp:261]     Train net output #0: loss = 0.469216 (* 1 = 0.469216 loss)
I0506 04:54:33.703723 12834 sgd_solver.cpp:106] Iteration 152600, lr = 3.51844e-06
I0506 04:54:33.708441 12834 solver.cpp:242] Iteration 152600 (106.543 iter/s, 0.938586s/100 iter), loss = 0.450362
I0506 04:54:33.708467 12834 solver.cpp:261]     Train net output #0: loss = 0.450362 (* 1 = 0.450362 loss)
I0506 04:54:33.708475 12834 sgd_solver.cpp:106] Iteration 152600, lr = 3.51844e-06
I0506 04:54:34.641434 12834 solver.cpp:242] Iteration 152700 (106.645 iter/s, 0.937694s/100 iter), loss = 1.94322
I0506 04:54:34.641475 12834 solver.cpp:261]     Train net output #0: loss = 1.94322 (* 1 = 1.94322 loss)
I0506 04:54:34.641485 12834 sgd_solver.cpp:106] Iteration 152700, lr = 3.51844e-06
I0506 04:54:34.646209 12834 solver.cpp:242] Iteration 152700 (106.641 iter/s, 0.937724s/100 iter), loss = 0.506894
I0506 04:54:34.646234 12834 solver.cpp:261]     Train net output #0: loss = 0.506894 (* 1 = 0.506894 loss)
I0506 04:54:34.646244 12834 sgd_solver.cpp:106] Iteration 152700, lr = 3.51844e-06
I0506 04:54:35.579188 12834 solver.cpp:242] Iteration 152800 (106.646 iter/s, 0.93768s/100 iter), loss = 1.35343
I0506 04:54:35.579232 12834 solver.cpp:261]     Train net output #0: loss = 1.35343 (* 1 = 1.35343 loss)
I0506 04:54:35.579243 12834 sgd_solver.cpp:106] Iteration 152800, lr = 3.51844e-06
I0506 04:54:35.584463 12834 solver.cpp:242] Iteration 152800 (106.586 iter/s, 0.938209s/100 iter), loss = 0.564092
I0506 04:54:35.584492 12834 solver.cpp:261]     Train net output #0: loss = 0.564092 (* 1 = 0.564092 loss)
I0506 04:54:35.584503 12834 sgd_solver.cpp:106] Iteration 152800, lr = 3.51844e-06
I0506 04:54:36.614261 12834 solver.cpp:242] Iteration 152900 (96.6181 iter/s, 1.035s/100 iter), loss = 1.09442
I0506 04:54:36.614306 12834 solver.cpp:261]     Train net output #0: loss = 1.09442 (* 1 = 1.09442 loss)
I0506 04:54:36.614395 12834 sgd_solver.cpp:106] Iteration 152900, lr = 3.51844e-06
I0506 04:54:36.619233 12834 solver.cpp:242] Iteration 152900 (96.6452 iter/s, 1.03471s/100 iter), loss = 0.529988
I0506 04:54:36.619257 12834 solver.cpp:261]     Train net output #0: loss = 0.529988 (* 1 = 0.529988 loss)
I0506 04:54:36.619266 12834 sgd_solver.cpp:106] Iteration 152900, lr = 3.51844e-06
I0506 04:54:37.550849 12834 solver.cpp:362] Iteration 153000, Testing net (#0)
I0506 04:54:37.550871 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:37.673635 12834 solver.cpp:429]     Test net output #0: loss = 1.28549 (* 1 = 1.28549 loss)
I0506 04:54:37.676154 12834 solver.cpp:242] Iteration 153000 (94.1771 iter/s, 1.06183s/100 iter), loss = 0.5374
I0506 04:54:37.676174 12834 solver.cpp:261]     Train net output #0: loss = 0.5374 (* 1 = 0.5374 loss)
I0506 04:54:37.676183 12834 sgd_solver.cpp:106] Iteration 153000, lr = 3.51844e-06
I0506 04:54:37.678030 12834 solver.cpp:362] Iteration 153000, Testing net (#0)
I0506 04:54:37.678043 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:37.806901 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7835
I0506 04:54:37.806921 12834 solver.cpp:429]     Test net output #1: loss = 0.509489 (* 1 = 0.509489 loss)
I0506 04:54:37.809468 12834 solver.cpp:242] Iteration 153000 (84.0201 iter/s, 1.19019s/100 iter), loss = 0.527422
I0506 04:54:37.809489 12834 solver.cpp:261]     Train net output #0: loss = 0.527422 (* 1 = 0.527422 loss)
I0506 04:54:37.809499 12834 sgd_solver.cpp:106] Iteration 153000, lr = 3.51844e-06
I0506 04:54:38.755966 12834 solver.cpp:242] Iteration 153100 (92.6126 iter/s, 1.07977s/100 iter), loss = 0.438197
I0506 04:54:38.756001 12834 solver.cpp:261]     Train net output #0: loss = 0.438197 (* 1 = 0.438197 loss)
I0506 04:54:38.756011 12834 sgd_solver.cpp:106] Iteration 153100, lr = 3.51844e-06
I0506 04:54:38.760794 12834 solver.cpp:242] Iteration 153100 (105.122 iter/s, 0.951278s/100 iter), loss = 0.430859
I0506 04:54:38.760819 12834 solver.cpp:261]     Train net output #0: loss = 0.430859 (* 1 = 0.430859 loss)
I0506 04:54:38.760828 12834 sgd_solver.cpp:106] Iteration 153100, lr = 3.51844e-06
I0506 04:54:39.693352 12834 solver.cpp:242] Iteration 153200 (106.687 iter/s, 0.937324s/100 iter), loss = 0.739128
I0506 04:54:39.693387 12834 solver.cpp:261]     Train net output #0: loss = 0.739128 (* 1 = 0.739128 loss)
I0506 04:54:39.693397 12834 sgd_solver.cpp:106] Iteration 153200, lr = 3.51844e-06
I0506 04:54:39.698128 12834 solver.cpp:242] Iteration 153200 (106.69 iter/s, 0.937291s/100 iter), loss = 0.375523
I0506 04:54:39.698153 12834 solver.cpp:261]     Train net output #0: loss = 0.375523 (* 1 = 0.375523 loss)
I0506 04:54:39.698161 12834 sgd_solver.cpp:106] Iteration 153200, lr = 3.51844e-06
I0506 04:54:40.631285 12834 solver.cpp:242] Iteration 153300 (106.625 iter/s, 0.937866s/100 iter), loss = 1.38485
I0506 04:54:40.631320 12834 solver.cpp:261]     Train net output #0: loss = 1.38485 (* 1 = 1.38485 loss)
I0506 04:54:40.631330 12834 sgd_solver.cpp:106] Iteration 153300, lr = 3.51844e-06
I0506 04:54:40.636070 12834 solver.cpp:242] Iteration 153300 (106.621 iter/s, 0.937899s/100 iter), loss = 0.553737
I0506 04:54:40.636093 12834 solver.cpp:261]     Train net output #0: loss = 0.553737 (* 1 = 0.553737 loss)
I0506 04:54:40.636102 12834 sgd_solver.cpp:106] Iteration 153300, lr = 3.51844e-06
I0506 04:54:41.568976 12834 solver.cpp:242] Iteration 153400 (106.652 iter/s, 0.937629s/100 iter), loss = 0.777729
I0506 04:54:41.569017 12834 solver.cpp:261]     Train net output #0: loss = 0.777729 (* 1 = 0.777729 loss)
I0506 04:54:41.569027 12834 sgd_solver.cpp:106] Iteration 153400, lr = 3.51844e-06
I0506 04:54:41.573753 12834 solver.cpp:242] Iteration 153400 (106.651 iter/s, 0.937642s/100 iter), loss = 0.381072
I0506 04:54:41.573779 12834 solver.cpp:261]     Train net output #0: loss = 0.381072 (* 1 = 0.381072 loss)
I0506 04:54:41.573788 12834 sgd_solver.cpp:106] Iteration 153400, lr = 3.51844e-06
I0506 04:54:42.503739 12834 solver.cpp:362] Iteration 153500, Testing net (#0)
I0506 04:54:42.503777 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:42.626461 12834 solver.cpp:429]     Test net output #0: loss = 1.25799 (* 1 = 1.25799 loss)
I0506 04:54:42.628994 12834 solver.cpp:242] Iteration 153500 (94.3434 iter/s, 1.05996s/100 iter), loss = 1.44394
I0506 04:54:42.629017 12834 solver.cpp:261]     Train net output #0: loss = 1.44394 (* 1 = 1.44394 loss)
I0506 04:54:42.629025 12834 sgd_solver.cpp:106] Iteration 153500, lr = 3.51844e-06
I0506 04:54:42.630841 12834 solver.cpp:362] Iteration 153500, Testing net (#0)
I0506 04:54:42.630854 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:42.759340 12834 solver.cpp:429]     Test net output #0: accuracy = 0.778
I0506 04:54:42.759359 12834 solver.cpp:429]     Test net output #1: loss = 0.50036 (* 1 = 0.50036 loss)
I0506 04:54:42.761905 12834 solver.cpp:242] Iteration 153500 (84.1676 iter/s, 1.18811s/100 iter), loss = 0.603866
I0506 04:54:42.761926 12834 solver.cpp:261]     Train net output #0: loss = 0.603866 (* 1 = 0.603866 loss)
I0506 04:54:42.761934 12834 sgd_solver.cpp:106] Iteration 153500, lr = 3.51844e-06
I0506 04:54:43.694943 12834 solver.cpp:242] Iteration 153600 (93.8176 iter/s, 1.0659s/100 iter), loss = 1.13812
I0506 04:54:43.694984 12834 solver.cpp:261]     Train net output #0: loss = 1.13812 (* 1 = 1.13812 loss)
I0506 04:54:43.694994 12834 sgd_solver.cpp:106] Iteration 153600, lr = 3.51844e-06
I0506 04:54:43.699748 12834 solver.cpp:242] Iteration 153600 (106.632 iter/s, 0.937802s/100 iter), loss = 0.422294
I0506 04:54:43.699774 12834 solver.cpp:261]     Train net output #0: loss = 0.422294 (* 1 = 0.422294 loss)
I0506 04:54:43.699782 12834 sgd_solver.cpp:106] Iteration 153600, lr = 3.51844e-06
I0506 04:54:44.638540 12834 solver.cpp:242] Iteration 153700 (105.986 iter/s, 0.943521s/100 iter), loss = 1.61528
I0506 04:54:44.638589 12834 solver.cpp:261]     Train net output #0: loss = 1.61528 (* 1 = 1.61528 loss)
I0506 04:54:44.638600 12834 sgd_solver.cpp:106] Iteration 153700, lr = 3.51844e-06
I0506 04:54:44.643813 12834 solver.cpp:242] Iteration 153700 (105.93 iter/s, 0.944021s/100 iter), loss = 0.660024
I0506 04:54:44.643843 12834 solver.cpp:261]     Train net output #0: loss = 0.660024 (* 1 = 0.660024 loss)
I0506 04:54:44.643854 12834 sgd_solver.cpp:106] Iteration 153700, lr = 3.51844e-06
I0506 04:54:45.583346 12834 solver.cpp:242] Iteration 153800 (105.85 iter/s, 0.944735s/100 iter), loss = 0.575567
I0506 04:54:45.583385 12834 solver.cpp:261]     Train net output #0: loss = 0.575567 (* 1 = 0.575567 loss)
I0506 04:54:45.583395 12834 sgd_solver.cpp:106] Iteration 153800, lr = 3.51844e-06
I0506 04:54:45.588186 12834 solver.cpp:242] Iteration 153800 (105.897 iter/s, 0.944315s/100 iter), loss = 0.488029
I0506 04:54:45.588209 12834 solver.cpp:261]     Train net output #0: loss = 0.488029 (* 1 = 0.488029 loss)
I0506 04:54:45.588218 12834 sgd_solver.cpp:106] Iteration 153800, lr = 3.51844e-06
I0506 04:54:46.521282 12834 solver.cpp:242] Iteration 153900 (106.625 iter/s, 0.937867s/100 iter), loss = 1.38351
I0506 04:54:46.521322 12834 solver.cpp:261]     Train net output #0: loss = 1.38351 (* 1 = 1.38351 loss)
I0506 04:54:46.521330 12834 sgd_solver.cpp:106] Iteration 153900, lr = 3.51844e-06
I0506 04:54:46.526053 12834 solver.cpp:242] Iteration 153900 (106.63 iter/s, 0.937826s/100 iter), loss = 0.55452
I0506 04:54:46.526078 12834 solver.cpp:261]     Train net output #0: loss = 0.55452 (* 1 = 0.55452 loss)
I0506 04:54:46.526087 12834 sgd_solver.cpp:106] Iteration 153900, lr = 3.51844e-06
I0506 04:54:47.516438 12834 solver.cpp:362] Iteration 154000, Testing net (#0)
I0506 04:54:47.516463 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:47.639250 12834 solver.cpp:429]     Test net output #0: loss = 1.20599 (* 1 = 1.20599 loss)
I0506 04:54:47.641763 12834 solver.cpp:242] Iteration 154000 (89.2521 iter/s, 1.12042s/100 iter), loss = 1.65267
I0506 04:54:47.641784 12834 solver.cpp:261]     Train net output #0: loss = 1.65267 (* 1 = 1.65267 loss)
I0506 04:54:47.641793 12834 sgd_solver.cpp:106] Iteration 154000, lr = 3.51844e-06
I0506 04:54:47.643703 12834 solver.cpp:362] Iteration 154000, Testing net (#0)
I0506 04:54:47.643717 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:47.772207 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7685
I0506 04:54:47.772228 12834 solver.cpp:429]     Test net output #1: loss = 0.522805 (* 1 = 0.522805 loss)
I0506 04:54:47.774775 12834 solver.cpp:242] Iteration 154000 (80.085 iter/s, 1.24867s/100 iter), loss = 0.736138
I0506 04:54:47.774794 12834 solver.cpp:261]     Train net output #0: loss = 0.736138 (* 1 = 0.736138 loss)
I0506 04:54:47.774802 12834 sgd_solver.cpp:106] Iteration 154000, lr = 3.51844e-06
I0506 04:54:48.707777 12834 solver.cpp:242] Iteration 154100 (93.8118 iter/s, 1.06596s/100 iter), loss = 3.17057
I0506 04:54:48.707816 12834 solver.cpp:261]     Train net output #0: loss = 3.17057 (* 1 = 3.17057 loss)
I0506 04:54:48.707825 12834 sgd_solver.cpp:106] Iteration 154100, lr = 3.51844e-06
I0506 04:54:48.712577 12834 solver.cpp:242] Iteration 154100 (106.637 iter/s, 0.937764s/100 iter), loss = 0.733687
I0506 04:54:48.712602 12834 solver.cpp:261]     Train net output #0: loss = 0.733687 (* 1 = 0.733687 loss)
I0506 04:54:48.712611 12834 sgd_solver.cpp:106] Iteration 154100, lr = 3.51844e-06
I0506 04:54:49.645112 12834 solver.cpp:242] Iteration 154200 (106.694 iter/s, 0.937263s/100 iter), loss = 0.665458
I0506 04:54:49.645151 12834 solver.cpp:261]     Train net output #0: loss = 0.665458 (* 1 = 0.665458 loss)
I0506 04:54:49.645161 12834 sgd_solver.cpp:106] Iteration 154200, lr = 3.51844e-06
I0506 04:54:49.649894 12834 solver.cpp:242] Iteration 154200 (106.692 iter/s, 0.937274s/100 iter), loss = 0.593387
I0506 04:54:49.649917 12834 solver.cpp:261]     Train net output #0: loss = 0.593387 (* 1 = 0.593387 loss)
I0506 04:54:49.649926 12834 sgd_solver.cpp:106] Iteration 154200, lr = 3.51844e-06
I0506 04:54:50.583423 12834 solver.cpp:242] Iteration 154300 (106.582 iter/s, 0.938244s/100 iter), loss = 1.59884
I0506 04:54:50.583467 12834 solver.cpp:261]     Train net output #0: loss = 1.59884 (* 1 = 1.59884 loss)
I0506 04:54:50.583478 12834 sgd_solver.cpp:106] Iteration 154300, lr = 3.51844e-06
I0506 04:54:50.588712 12834 solver.cpp:242] Iteration 154300 (106.522 iter/s, 0.938775s/100 iter), loss = 0.512144
I0506 04:54:50.588742 12834 solver.cpp:261]     Train net output #0: loss = 0.512144 (* 1 = 0.512144 loss)
I0506 04:54:50.588752 12834 sgd_solver.cpp:106] Iteration 154300, lr = 3.51844e-06
I0506 04:54:51.534711 12834 solver.cpp:242] Iteration 154400 (105.129 iter/s, 0.951216s/100 iter), loss = 3.88487
I0506 04:54:51.534741 12834 solver.cpp:261]     Train net output #0: loss = 3.88487 (* 1 = 3.88487 loss)
I0506 04:54:51.534750 12834 sgd_solver.cpp:106] Iteration 154400, lr = 3.51844e-06
I0506 04:54:51.539491 12834 solver.cpp:242] Iteration 154400 (105.182 iter/s, 0.950733s/100 iter), loss = 0.778636
I0506 04:54:51.539515 12834 solver.cpp:261]     Train net output #0: loss = 0.778636 (* 1 = 0.778636 loss)
I0506 04:54:51.539523 12834 sgd_solver.cpp:106] Iteration 154400, lr = 3.51844e-06
I0506 04:54:52.469597 12834 solver.cpp:362] Iteration 154500, Testing net (#0)
I0506 04:54:52.469627 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:52.592424 12834 solver.cpp:429]     Test net output #0: loss = 1.14755 (* 1 = 1.14755 loss)
I0506 04:54:52.594945 12834 solver.cpp:242] Iteration 154500 (94.3232 iter/s, 1.06019s/100 iter), loss = 2.06386
I0506 04:54:52.594966 12834 solver.cpp:261]     Train net output #0: loss = 2.06386 (* 1 = 2.06386 loss)
I0506 04:54:52.594975 12834 sgd_solver.cpp:106] Iteration 154500, lr = 3.51844e-06
I0506 04:54:52.596806 12834 solver.cpp:362] Iteration 154500, Testing net (#0)
I0506 04:54:52.596817 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:52.725658 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7795
I0506 04:54:52.725677 12834 solver.cpp:429]     Test net output #1: loss = 0.506137 (* 1 = 0.506137 loss)
I0506 04:54:52.728232 12834 solver.cpp:242] Iteration 154500 (84.1257 iter/s, 1.1887s/100 iter), loss = 0.620959
I0506 04:54:52.728262 12834 solver.cpp:261]     Train net output #0: loss = 0.620959 (* 1 = 0.620959 loss)
I0506 04:54:52.728271 12834 sgd_solver.cpp:106] Iteration 154500, lr = 3.51844e-06
I0506 04:54:53.661425 12834 solver.cpp:242] Iteration 154600 (93.7711 iter/s, 1.06643s/100 iter), loss = 0.947286
I0506 04:54:53.661458 12834 solver.cpp:261]     Train net output #0: loss = 0.947286 (* 1 = 0.947286 loss)
I0506 04:54:53.661468 12834 sgd_solver.cpp:106] Iteration 154600, lr = 3.51844e-06
I0506 04:54:53.666193 12834 solver.cpp:242] Iteration 154600 (106.62 iter/s, 0.937913s/100 iter), loss = 0.420525
I0506 04:54:53.666216 12834 solver.cpp:261]     Train net output #0: loss = 0.420525 (* 1 = 0.420525 loss)
I0506 04:54:53.666225 12834 sgd_solver.cpp:106] Iteration 154600, lr = 3.51844e-06
I0506 04:54:54.599019 12834 solver.cpp:242] Iteration 154700 (106.663 iter/s, 0.937535s/100 iter), loss = 0.581776
I0506 04:54:54.599061 12834 solver.cpp:261]     Train net output #0: loss = 0.581776 (* 1 = 0.581776 loss)
I0506 04:54:54.599071 12834 sgd_solver.cpp:106] Iteration 154700, lr = 3.51844e-06
I0506 04:54:54.603859 12834 solver.cpp:242] Iteration 154700 (106.654 iter/s, 0.937614s/100 iter), loss = 0.727004
I0506 04:54:54.603884 12834 solver.cpp:261]     Train net output #0: loss = 0.727004 (* 1 = 0.727004 loss)
I0506 04:54:54.603893 12834 sgd_solver.cpp:106] Iteration 154700, lr = 3.51844e-06
I0506 04:54:55.536752 12834 solver.cpp:242] Iteration 154800 (106.648 iter/s, 0.937665s/100 iter), loss = 0.932635
I0506 04:54:55.536792 12834 solver.cpp:261]     Train net output #0: loss = 0.932635 (* 1 = 0.932635 loss)
I0506 04:54:55.536803 12834 sgd_solver.cpp:106] Iteration 154800, lr = 3.51844e-06
I0506 04:54:55.541544 12834 solver.cpp:242] Iteration 154800 (106.651 iter/s, 0.937641s/100 iter), loss = 0.578085
I0506 04:54:55.541569 12834 solver.cpp:261]     Train net output #0: loss = 0.578085 (* 1 = 0.578085 loss)
I0506 04:54:55.541579 12834 sgd_solver.cpp:106] Iteration 154800, lr = 3.51844e-06
I0506 04:54:56.494398 12834 solver.cpp:242] Iteration 154900 (104.43 iter/s, 0.957578s/100 iter), loss = 3.77149
I0506 04:54:56.494446 12834 solver.cpp:261]     Train net output #0: loss = 3.77149 (* 1 = 3.77149 loss)
I0506 04:54:56.494455 12834 sgd_solver.cpp:106] Iteration 154900, lr = 3.51844e-06
I0506 04:54:56.499368 12834 solver.cpp:242] Iteration 154900 (104.409 iter/s, 0.95777s/100 iter), loss = 0.302605
I0506 04:54:56.499406 12834 solver.cpp:261]     Train net output #0: loss = 0.302605 (* 1 = 0.302605 loss)
I0506 04:54:56.499416 12834 sgd_solver.cpp:106] Iteration 154900, lr = 3.51844e-06
I0506 04:54:57.429213 12834 solver.cpp:362] Iteration 155000, Testing net (#0)
I0506 04:54:57.429239 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:57.551829 12834 solver.cpp:429]     Test net output #0: loss = 1.27901 (* 1 = 1.27901 loss)
I0506 04:54:57.554394 12834 solver.cpp:242] Iteration 155000 (94.3459 iter/s, 1.05993s/100 iter), loss = 0.78013
I0506 04:54:57.554416 12834 solver.cpp:261]     Train net output #0: loss = 0.78013 (* 1 = 0.78013 loss)
I0506 04:54:57.554426 12834 sgd_solver.cpp:106] Iteration 155000, lr = 3.51844e-06
I0506 04:54:57.556272 12834 solver.cpp:362] Iteration 155000, Testing net (#0)
I0506 04:54:57.556288 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:54:57.684809 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7885
I0506 04:54:57.684833 12834 solver.cpp:429]     Test net output #1: loss = 0.505354 (* 1 = 0.505354 loss)
I0506 04:54:57.687403 12834 solver.cpp:242] Iteration 155000 (84.176 iter/s, 1.18799s/100 iter), loss = 0.371137
I0506 04:54:57.687424 12834 solver.cpp:261]     Train net output #0: loss = 0.371137 (* 1 = 0.371137 loss)
I0506 04:54:57.687433 12834 sgd_solver.cpp:106] Iteration 155000, lr = 3.51844e-06
I0506 04:54:58.620728 12834 solver.cpp:242] Iteration 155100 (93.7845 iter/s, 1.06627s/100 iter), loss = 1.26041
I0506 04:54:58.620769 12834 solver.cpp:261]     Train net output #0: loss = 1.26041 (* 1 = 1.26041 loss)
I0506 04:54:58.620777 12834 sgd_solver.cpp:106] Iteration 155100, lr = 3.51844e-06
I0506 04:54:58.625517 12834 solver.cpp:242] Iteration 155100 (106.601 iter/s, 0.938074s/100 iter), loss = 0.496298
I0506 04:54:58.625543 12834 solver.cpp:261]     Train net output #0: loss = 0.496298 (* 1 = 0.496298 loss)
I0506 04:54:58.625552 12834 sgd_solver.cpp:106] Iteration 155100, lr = 3.51844e-06
I0506 04:54:59.558006 12834 solver.cpp:242] Iteration 155200 (106.7 iter/s, 0.93721s/100 iter), loss = 2.26506
I0506 04:54:59.558044 12834 solver.cpp:261]     Train net output #0: loss = 2.26506 (* 1 = 2.26506 loss)
I0506 04:54:59.558054 12834 sgd_solver.cpp:106] Iteration 155200, lr = 3.51844e-06
I0506 04:54:59.562808 12834 solver.cpp:242] Iteration 155200 (106.695 iter/s, 0.937247s/100 iter), loss = 0.594943
I0506 04:54:59.562834 12834 solver.cpp:261]     Train net output #0: loss = 0.594943 (* 1 = 0.594943 loss)
I0506 04:54:59.562844 12834 sgd_solver.cpp:106] Iteration 155200, lr = 3.51844e-06
I0506 04:55:00.501049 12834 solver.cpp:242] Iteration 155300 (106.048 iter/s, 0.942969s/100 iter), loss = 0.377557
I0506 04:55:00.501096 12834 solver.cpp:261]     Train net output #0: loss = 0.377557 (* 1 = 0.377557 loss)
I0506 04:55:00.501106 12834 sgd_solver.cpp:106] Iteration 155300, lr = 3.51844e-06
I0506 04:55:00.505846 12834 solver.cpp:242] Iteration 155300 (106.045 iter/s, 0.942993s/100 iter), loss = 0.325823
I0506 04:55:00.505874 12834 solver.cpp:261]     Train net output #0: loss = 0.325823 (* 1 = 0.325823 loss)
I0506 04:55:00.505883 12834 sgd_solver.cpp:106] Iteration 155300, lr = 3.51844e-06
I0506 04:55:01.439465 12834 solver.cpp:242] Iteration 155400 (106.571 iter/s, 0.938345s/100 iter), loss = 0.767676
I0506 04:55:01.439503 12834 solver.cpp:261]     Train net output #0: loss = 0.767676 (* 1 = 0.767676 loss)
I0506 04:55:01.439513 12834 sgd_solver.cpp:106] Iteration 155400, lr = 3.51844e-06
I0506 04:55:01.444233 12834 solver.cpp:242] Iteration 155400 (106.571 iter/s, 0.938341s/100 iter), loss = 0.66465
I0506 04:55:01.444258 12834 solver.cpp:261]     Train net output #0: loss = 0.66465 (* 1 = 0.66465 loss)
I0506 04:55:01.444268 12834 sgd_solver.cpp:106] Iteration 155400, lr = 3.51844e-06
I0506 04:55:02.376082 12834 solver.cpp:362] Iteration 155500, Testing net (#0)
I0506 04:55:02.376101 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:02.498776 12834 solver.cpp:429]     Test net output #0: loss = 1.36305 (* 1 = 1.36305 loss)
I0506 04:55:02.501302 12834 solver.cpp:242] Iteration 155500 (94.1816 iter/s, 1.06178s/100 iter), loss = 0.832505
I0506 04:55:02.501322 12834 solver.cpp:261]     Train net output #0: loss = 0.832505 (* 1 = 0.832505 loss)
I0506 04:55:02.501332 12834 sgd_solver.cpp:106] Iteration 155500, lr = 3.51844e-06
I0506 04:55:02.503142 12834 solver.cpp:362] Iteration 155500, Testing net (#0)
I0506 04:55:02.503155 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:02.637040 12834 solver.cpp:429]     Test net output #0: accuracy = 0.777
I0506 04:55:02.637065 12834 solver.cpp:429]     Test net output #1: loss = 0.51176 (* 1 = 0.51176 loss)
I0506 04:55:02.639711 12834 solver.cpp:242] Iteration 155500 (83.6518 iter/s, 1.19543s/100 iter), loss = 0.439963
I0506 04:55:02.639732 12834 solver.cpp:261]     Train net output #0: loss = 0.439963 (* 1 = 0.439963 loss)
I0506 04:55:02.639741 12834 sgd_solver.cpp:106] Iteration 155500, lr = 3.51844e-06
I0506 04:55:03.572868 12834 solver.cpp:242] Iteration 155600 (93.3263 iter/s, 1.07151s/100 iter), loss = 1.54941
I0506 04:55:03.572906 12834 solver.cpp:261]     Train net output #0: loss = 1.54941 (* 1 = 1.54941 loss)
I0506 04:55:03.572914 12834 sgd_solver.cpp:106] Iteration 155600, lr = 3.51844e-06
I0506 04:55:03.577714 12834 solver.cpp:242] Iteration 155600 (106.615 iter/s, 0.937952s/100 iter), loss = 0.442403
I0506 04:55:03.577739 12834 solver.cpp:261]     Train net output #0: loss = 0.442403 (* 1 = 0.442403 loss)
I0506 04:55:03.577747 12834 sgd_solver.cpp:106] Iteration 155600, lr = 3.51844e-06
I0506 04:55:04.511076 12834 solver.cpp:242] Iteration 155700 (106.593 iter/s, 0.938145s/100 iter), loss = 1.08138
I0506 04:55:04.511121 12834 solver.cpp:261]     Train net output #0: loss = 1.08138 (* 1 = 1.08138 loss)
I0506 04:55:04.511131 12834 sgd_solver.cpp:106] Iteration 155700, lr = 3.51844e-06
I0506 04:55:04.515872 12834 solver.cpp:242] Iteration 155700 (106.597 iter/s, 0.938115s/100 iter), loss = 0.456133
I0506 04:55:04.515897 12834 solver.cpp:261]     Train net output #0: loss = 0.456133 (* 1 = 0.456133 loss)
I0506 04:55:04.515907 12834 sgd_solver.cpp:106] Iteration 155700, lr = 3.51844e-06
I0506 04:55:05.448153 12834 solver.cpp:242] Iteration 155800 (106.722 iter/s, 0.93701s/100 iter), loss = 0.612812
I0506 04:55:05.448181 12834 solver.cpp:261]     Train net output #0: loss = 0.612812 (* 1 = 0.612812 loss)
I0506 04:55:05.448190 12834 sgd_solver.cpp:106] Iteration 155800, lr = 3.51844e-06
I0506 04:55:05.452980 12834 solver.cpp:242] Iteration 155800 (106.717 iter/s, 0.937055s/100 iter), loss = 0.605502
I0506 04:55:05.453002 12834 solver.cpp:261]     Train net output #0: loss = 0.605502 (* 1 = 0.605502 loss)
I0506 04:55:05.453011 12834 sgd_solver.cpp:106] Iteration 155800, lr = 3.51844e-06
I0506 04:55:06.396823 12834 solver.cpp:242] Iteration 155900 (105.417 iter/s, 0.948615s/100 iter), loss = 0.89749
I0506 04:55:06.396867 12834 solver.cpp:261]     Train net output #0: loss = 0.89749 (* 1 = 0.89749 loss)
I0506 04:55:06.396875 12834 sgd_solver.cpp:106] Iteration 155900, lr = 3.51844e-06
I0506 04:55:06.401593 12834 solver.cpp:242] Iteration 155900 (105.422 iter/s, 0.948572s/100 iter), loss = 0.405223
I0506 04:55:06.401618 12834 solver.cpp:261]     Train net output #0: loss = 0.405223 (* 1 = 0.405223 loss)
I0506 04:55:06.401626 12834 sgd_solver.cpp:106] Iteration 155900, lr = 3.51844e-06
I0506 04:55:07.410176 12834 solver.cpp:362] Iteration 156000, Testing net (#0)
I0506 04:55:07.410210 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:07.543462 12834 solver.cpp:429]     Test net output #0: loss = 1.25101 (* 1 = 1.25101 loss)
I0506 04:55:07.546108 12834 solver.cpp:242] Iteration 156000 (87.0155 iter/s, 1.14922s/100 iter), loss = 0.447337
I0506 04:55:07.546133 12834 solver.cpp:261]     Train net output #0: loss = 0.447337 (* 1 = 0.447337 loss)
I0506 04:55:07.546144 12834 sgd_solver.cpp:106] Iteration 156000, lr = 3.51844e-06
I0506 04:55:07.548323 12834 solver.cpp:362] Iteration 156000, Testing net (#0)
I0506 04:55:07.548339 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:07.689028 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7755
I0506 04:55:07.689054 12834 solver.cpp:429]     Test net output #1: loss = 0.508282 (* 1 = 0.508282 loss)
I0506 04:55:07.691699 12834 solver.cpp:242] Iteration 156000 (77.5159 iter/s, 1.29006s/100 iter), loss = 0.381641
I0506 04:55:07.691718 12834 solver.cpp:261]     Train net output #0: loss = 0.381641 (* 1 = 0.381641 loss)
I0506 04:55:07.691727 12834 sgd_solver.cpp:106] Iteration 156000, lr = 3.51844e-06
I0506 04:55:08.629344 12834 solver.cpp:242] Iteration 156100 (92.3206 iter/s, 1.08318s/100 iter), loss = 0.683016
I0506 04:55:08.629405 12834 solver.cpp:261]     Train net output #0: loss = 0.683016 (* 1 = 0.683016 loss)
I0506 04:55:08.629416 12834 sgd_solver.cpp:106] Iteration 156100, lr = 3.51844e-06
I0506 04:55:08.634631 12834 solver.cpp:242] Iteration 156100 (106.057 iter/s, 0.942893s/100 iter), loss = 0.428757
I0506 04:55:08.634662 12834 solver.cpp:261]     Train net output #0: loss = 0.428757 (* 1 = 0.428757 loss)
I0506 04:55:08.634673 12834 sgd_solver.cpp:106] Iteration 156100, lr = 3.51844e-06
I0506 04:55:09.576241 12834 solver.cpp:242] Iteration 156200 (105.618 iter/s, 0.946806s/100 iter), loss = 1.54152
I0506 04:55:09.576282 12834 solver.cpp:261]     Train net output #0: loss = 1.54152 (* 1 = 1.54152 loss)
I0506 04:55:09.576292 12834 sgd_solver.cpp:106] Iteration 156200, lr = 3.51844e-06
I0506 04:55:09.581037 12834 solver.cpp:242] Iteration 156200 (105.668 iter/s, 0.946358s/100 iter), loss = 0.465073
I0506 04:55:09.581063 12834 solver.cpp:261]     Train net output #0: loss = 0.465073 (* 1 = 0.465073 loss)
I0506 04:55:09.581073 12834 sgd_solver.cpp:106] Iteration 156200, lr = 3.51844e-06
I0506 04:55:10.513792 12834 solver.cpp:242] Iteration 156300 (106.668 iter/s, 0.937485s/100 iter), loss = 3.20376
I0506 04:55:10.513833 12834 solver.cpp:261]     Train net output #0: loss = 3.20376 (* 1 = 3.20376 loss)
I0506 04:55:10.513842 12834 sgd_solver.cpp:106] Iteration 156300, lr = 3.51844e-06
I0506 04:55:10.518563 12834 solver.cpp:242] Iteration 156300 (106.669 iter/s, 0.937482s/100 iter), loss = 0.472251
I0506 04:55:10.518589 12834 solver.cpp:261]     Train net output #0: loss = 0.472251 (* 1 = 0.472251 loss)
I0506 04:55:10.518597 12834 sgd_solver.cpp:106] Iteration 156300, lr = 3.51844e-06
I0506 04:55:11.451102 12834 solver.cpp:242] Iteration 156400 (106.696 iter/s, 0.937238s/100 iter), loss = 0.825494
I0506 04:55:11.451143 12834 solver.cpp:261]     Train net output #0: loss = 0.825494 (* 1 = 0.825494 loss)
I0506 04:55:11.451153 12834 sgd_solver.cpp:106] Iteration 156400, lr = 3.51844e-06
I0506 04:55:11.455866 12834 solver.cpp:242] Iteration 156400 (106.694 iter/s, 0.937259s/100 iter), loss = 0.429911
I0506 04:55:11.455890 12834 solver.cpp:261]     Train net output #0: loss = 0.429911 (* 1 = 0.429911 loss)
I0506 04:55:11.455899 12834 sgd_solver.cpp:106] Iteration 156400, lr = 3.51844e-06
I0506 04:55:12.385699 12834 solver.cpp:362] Iteration 156500, Testing net (#0)
I0506 04:55:12.385726 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:12.508404 12834 solver.cpp:429]     Test net output #0: loss = 1.0437 (* 1 = 1.0437 loss)
I0506 04:55:12.510922 12834 solver.cpp:242] Iteration 156500 (94.3609 iter/s, 1.05976s/100 iter), loss = 0.756775
I0506 04:55:12.510943 12834 solver.cpp:261]     Train net output #0: loss = 0.756775 (* 1 = 0.756775 loss)
I0506 04:55:12.510952 12834 sgd_solver.cpp:106] Iteration 156500, lr = 3.51844e-06
I0506 04:55:12.512786 12834 solver.cpp:362] Iteration 156500, Testing net (#0)
I0506 04:55:12.512800 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:12.641499 12834 solver.cpp:429]     Test net output #0: accuracy = 0.8105
I0506 04:55:12.641520 12834 solver.cpp:429]     Test net output #1: loss = 0.456567 (* 1 = 0.456567 loss)
I0506 04:55:12.644074 12834 solver.cpp:242] Iteration 156500 (84.1635 iter/s, 1.18816s/100 iter), loss = 0.511806
I0506 04:55:12.644094 12834 solver.cpp:261]     Train net output #0: loss = 0.511806 (* 1 = 0.511806 loss)
I0506 04:55:12.644103 12834 sgd_solver.cpp:106] Iteration 156500, lr = 3.51844e-06
I0506 04:55:13.577057 12834 solver.cpp:242] Iteration 156600 (93.8016 iter/s, 1.06608s/100 iter), loss = 1.11774
I0506 04:55:13.577098 12834 solver.cpp:261]     Train net output #0: loss = 1.11774 (* 1 = 1.11774 loss)
I0506 04:55:13.577108 12834 sgd_solver.cpp:106] Iteration 156600, lr = 3.51844e-06
I0506 04:55:13.581820 12834 solver.cpp:242] Iteration 156600 (106.643 iter/s, 0.937708s/100 iter), loss = 0.476223
I0506 04:55:13.581845 12834 solver.cpp:261]     Train net output #0: loss = 0.476223 (* 1 = 0.476223 loss)
I0506 04:55:13.581854 12834 sgd_solver.cpp:106] Iteration 156600, lr = 3.51844e-06
I0506 04:55:14.514670 12834 solver.cpp:242] Iteration 156700 (106.661 iter/s, 0.937546s/100 iter), loss = 2.27104
I0506 04:55:14.514708 12834 solver.cpp:261]     Train net output #0: loss = 2.27104 (* 1 = 2.27104 loss)
I0506 04:55:14.514717 12834 sgd_solver.cpp:106] Iteration 156700, lr = 3.51844e-06
I0506 04:55:14.519523 12834 solver.cpp:242] Iteration 156700 (106.65 iter/s, 0.93765s/100 iter), loss = 0.851158
I0506 04:55:14.519548 12834 solver.cpp:261]     Train net output #0: loss = 0.851158 (* 1 = 0.851158 loss)
I0506 04:55:14.519557 12834 sgd_solver.cpp:106] Iteration 156700, lr = 3.51844e-06
I0506 04:55:15.465598 12834 solver.cpp:242] Iteration 156800 (105.168 iter/s, 0.950864s/100 iter), loss = 0.350891
I0506 04:55:15.465636 12834 solver.cpp:261]     Train net output #0: loss = 0.350891 (* 1 = 0.350891 loss)
I0506 04:55:15.465646 12834 sgd_solver.cpp:106] Iteration 156800, lr = 3.51844e-06
I0506 04:55:15.470360 12834 solver.cpp:242] Iteration 156800 (105.175 iter/s, 0.950794s/100 iter), loss = 0.235689
I0506 04:55:15.470397 12834 solver.cpp:261]     Train net output #0: loss = 0.235689 (* 1 = 0.235689 loss)
I0506 04:55:15.470407 12834 sgd_solver.cpp:106] Iteration 156800, lr = 3.51844e-06
I0506 04:55:16.403105 12834 solver.cpp:242] Iteration 156900 (106.674 iter/s, 0.937437s/100 iter), loss = 1.2534
I0506 04:55:16.403142 12834 solver.cpp:261]     Train net output #0: loss = 1.2534 (* 1 = 1.2534 loss)
I0506 04:55:16.403152 12834 sgd_solver.cpp:106] Iteration 156900, lr = 3.51844e-06
I0506 04:55:16.407868 12834 solver.cpp:242] Iteration 156900 (106.672 iter/s, 0.937452s/100 iter), loss = 0.248164
I0506 04:55:16.407893 12834 solver.cpp:261]     Train net output #0: loss = 0.248164 (* 1 = 0.248164 loss)
I0506 04:55:16.407902 12834 sgd_solver.cpp:106] Iteration 156900, lr = 3.51844e-06
I0506 04:55:17.337549 12834 solver.cpp:362] Iteration 157000, Testing net (#0)
I0506 04:55:17.337574 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:17.460211 12834 solver.cpp:429]     Test net output #0: loss = 1.24875 (* 1 = 1.24875 loss)
I0506 04:55:17.462719 12834 solver.cpp:242] Iteration 157000 (94.379 iter/s, 1.05956s/100 iter), loss = 1.49359
I0506 04:55:17.462739 12834 solver.cpp:261]     Train net output #0: loss = 1.49359 (* 1 = 1.49359 loss)
I0506 04:55:17.462749 12834 sgd_solver.cpp:106] Iteration 157000, lr = 3.51844e-06
I0506 04:55:17.464560 12834 solver.cpp:362] Iteration 157000, Testing net (#0)
I0506 04:55:17.464573 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:17.593205 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7725
I0506 04:55:17.593225 12834 solver.cpp:429]     Test net output #1: loss = 0.519944 (* 1 = 0.519944 loss)
I0506 04:55:17.595779 12834 solver.cpp:242] Iteration 157000 (84.1846 iter/s, 1.18787s/100 iter), loss = 0.597942
I0506 04:55:17.595799 12834 solver.cpp:261]     Train net output #0: loss = 0.597942 (* 1 = 0.597942 loss)
I0506 04:55:17.595808 12834 sgd_solver.cpp:106] Iteration 157000, lr = 3.51844e-06
I0506 04:55:18.529386 12834 solver.cpp:242] Iteration 157100 (93.7546 iter/s, 1.06661s/100 iter), loss = 2.65172
I0506 04:55:18.529418 12834 solver.cpp:261]     Train net output #0: loss = 2.65172 (* 1 = 2.65172 loss)
I0506 04:55:18.529428 12834 sgd_solver.cpp:106] Iteration 157100, lr = 3.51844e-06
I0506 04:55:18.534147 12834 solver.cpp:242] Iteration 157100 (106.573 iter/s, 0.938328s/100 iter), loss = 0.784515
I0506 04:55:18.534170 12834 solver.cpp:261]     Train net output #0: loss = 0.784515 (* 1 = 0.784515 loss)
I0506 04:55:18.534179 12834 sgd_solver.cpp:106] Iteration 157100, lr = 3.51844e-06
I0506 04:55:19.466866 12834 solver.cpp:242] Iteration 157200 (106.676 iter/s, 0.937422s/100 iter), loss = 0.52391
I0506 04:55:19.466909 12834 solver.cpp:261]     Train net output #0: loss = 0.52391 (* 1 = 0.52391 loss)
I0506 04:55:19.466919 12834 sgd_solver.cpp:106] Iteration 157200, lr = 3.51844e-06
I0506 04:55:19.471645 12834 solver.cpp:242] Iteration 157200 (106.672 iter/s, 0.937457s/100 iter), loss = 0.543237
I0506 04:55:19.471671 12834 solver.cpp:261]     Train net output #0: loss = 0.543237 (* 1 = 0.543237 loss)
I0506 04:55:19.471681 12834 sgd_solver.cpp:106] Iteration 157200, lr = 3.51844e-06
I0506 04:55:20.406311 12834 solver.cpp:242] Iteration 157300 (106.455 iter/s, 0.939366s/100 iter), loss = 0.623501
I0506 04:55:20.406360 12834 solver.cpp:261]     Train net output #0: loss = 0.623501 (* 1 = 0.623501 loss)
I0506 04:55:20.406370 12834 sgd_solver.cpp:106] Iteration 157300, lr = 3.51844e-06
I0506 04:55:20.411185 12834 solver.cpp:242] Iteration 157300 (106.44 iter/s, 0.939493s/100 iter), loss = 0.468898
I0506 04:55:20.411211 12834 solver.cpp:261]     Train net output #0: loss = 0.468898 (* 1 = 0.468898 loss)
I0506 04:55:20.411219 12834 sgd_solver.cpp:106] Iteration 157300, lr = 3.51844e-06
I0506 04:55:21.357302 12834 solver.cpp:242] Iteration 157400 (105.161 iter/s, 0.950919s/100 iter), loss = 1.63485
I0506 04:55:21.357342 12834 solver.cpp:261]     Train net output #0: loss = 1.63485 (* 1 = 1.63485 loss)
I0506 04:55:21.357352 12834 sgd_solver.cpp:106] Iteration 157400, lr = 3.51844e-06
I0506 04:55:21.362078 12834 solver.cpp:242] Iteration 157400 (105.169 iter/s, 0.95085s/100 iter), loss = 0.5005
I0506 04:55:21.362103 12834 solver.cpp:261]     Train net output #0: loss = 0.5005 (* 1 = 0.5005 loss)
I0506 04:55:21.362112 12834 sgd_solver.cpp:106] Iteration 157400, lr = 3.51844e-06
I0506 04:55:22.291733 12834 solver.cpp:362] Iteration 157500, Testing net (#0)
I0506 04:55:22.291759 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:22.414535 12834 solver.cpp:429]     Test net output #0: loss = 1.1104 (* 1 = 1.1104 loss)
I0506 04:55:22.417070 12834 solver.cpp:242] Iteration 157500 (94.3654 iter/s, 1.05971s/100 iter), loss = 6.27141
I0506 04:55:22.417090 12834 solver.cpp:261]     Train net output #0: loss = 6.27141 (* 1 = 6.27141 loss)
I0506 04:55:22.417099 12834 sgd_solver.cpp:106] Iteration 157500, lr = 3.51844e-06
I0506 04:55:22.418915 12834 solver.cpp:362] Iteration 157500, Testing net (#0)
I0506 04:55:22.418927 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:22.547637 12834 solver.cpp:429]     Test net output #0: accuracy = 0.79
I0506 04:55:22.547657 12834 solver.cpp:429]     Test net output #1: loss = 0.495119 (* 1 = 0.495119 loss)
I0506 04:55:22.550209 12834 solver.cpp:242] Iteration 157500 (84.169 iter/s, 1.18809s/100 iter), loss = 0.676632
I0506 04:55:22.550230 12834 solver.cpp:261]     Train net output #0: loss = 0.676632 (* 1 = 0.676632 loss)
I0506 04:55:22.550240 12834 sgd_solver.cpp:106] Iteration 157500, lr = 3.51844e-06
I0506 04:55:23.482859 12834 solver.cpp:242] Iteration 157600 (93.8314 iter/s, 1.06574s/100 iter), loss = 0.824644
I0506 04:55:23.482903 12834 solver.cpp:261]     Train net output #0: loss = 0.824644 (* 1 = 0.824644 loss)
I0506 04:55:23.482913 12834 sgd_solver.cpp:106] Iteration 157600, lr = 3.51844e-06
I0506 04:55:23.487741 12834 solver.cpp:242] Iteration 157600 (106.669 iter/s, 0.937482s/100 iter), loss = 0.352551
I0506 04:55:23.487766 12834 solver.cpp:261]     Train net output #0: loss = 0.352551 (* 1 = 0.352551 loss)
I0506 04:55:23.487774 12834 sgd_solver.cpp:106] Iteration 157600, lr = 3.51844e-06
I0506 04:55:24.421005 12834 solver.cpp:242] Iteration 157700 (106.601 iter/s, 0.938074s/100 iter), loss = 0.783099
I0506 04:55:24.421043 12834 solver.cpp:261]     Train net output #0: loss = 0.783099 (* 1 = 0.783099 loss)
I0506 04:55:24.421053 12834 sgd_solver.cpp:106] Iteration 157700, lr = 3.51844e-06
I0506 04:55:24.425784 12834 solver.cpp:242] Iteration 157700 (106.61 iter/s, 0.938001s/100 iter), loss = 0.431039
I0506 04:55:24.425810 12834 solver.cpp:261]     Train net output #0: loss = 0.431039 (* 1 = 0.431039 loss)
I0506 04:55:24.425819 12834 sgd_solver.cpp:106] Iteration 157700, lr = 3.51844e-06
I0506 04:55:25.358366 12834 solver.cpp:242] Iteration 157800 (106.691 iter/s, 0.93729s/100 iter), loss = 0.5227
I0506 04:55:25.358404 12834 solver.cpp:261]     Train net output #0: loss = 0.5227 (* 1 = 0.5227 loss)
I0506 04:55:25.358413 12834 sgd_solver.cpp:106] Iteration 157800, lr = 3.51844e-06
I0506 04:55:25.363129 12834 solver.cpp:242] Iteration 157800 (106.689 iter/s, 0.937301s/100 iter), loss = 0.27243
I0506 04:55:25.363153 12834 solver.cpp:261]     Train net output #0: loss = 0.27243 (* 1 = 0.27243 loss)
I0506 04:55:25.363162 12834 sgd_solver.cpp:106] Iteration 157800, lr = 3.51844e-06
I0506 04:55:26.295822 12834 solver.cpp:242] Iteration 157900 (106.679 iter/s, 0.937392s/100 iter), loss = 0.593718
I0506 04:55:26.295861 12834 solver.cpp:261]     Train net output #0: loss = 0.593718 (* 1 = 0.593718 loss)
I0506 04:55:26.295871 12834 sgd_solver.cpp:106] Iteration 157900, lr = 3.51844e-06
I0506 04:55:26.300621 12834 solver.cpp:242] Iteration 157900 (106.673 iter/s, 0.937448s/100 iter), loss = 0.503393
I0506 04:55:26.300645 12834 solver.cpp:261]     Train net output #0: loss = 0.503393 (* 1 = 0.503393 loss)
I0506 04:55:26.300654 12834 sgd_solver.cpp:106] Iteration 157900, lr = 3.51844e-06
I0506 04:55:27.230643 12834 solver.cpp:362] Iteration 158000, Testing net (#0)
I0506 04:55:27.230666 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:27.353360 12834 solver.cpp:429]     Test net output #0: loss = 1.24849 (* 1 = 1.24849 loss)
I0506 04:55:27.355878 12834 solver.cpp:242] Iteration 158000 (94.3397 iter/s, 1.06s/100 iter), loss = 1.17908
I0506 04:55:27.355898 12834 solver.cpp:261]     Train net output #0: loss = 1.17908 (* 1 = 1.17908 loss)
I0506 04:55:27.355906 12834 sgd_solver.cpp:106] Iteration 158000, lr = 3.51844e-06
I0506 04:55:27.357771 12834 solver.cpp:362] Iteration 158000, Testing net (#0)
I0506 04:55:27.357785 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:27.486495 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:55:27.486515 12834 solver.cpp:429]     Test net output #1: loss = 0.525352 (* 1 = 0.525352 loss)
I0506 04:55:27.489068 12834 solver.cpp:242] Iteration 158000 (84.1466 iter/s, 1.1884s/100 iter), loss = 0.679215
I0506 04:55:27.489089 12834 solver.cpp:261]     Train net output #0: loss = 0.679215 (* 1 = 0.679215 loss)
I0506 04:55:27.489097 12834 sgd_solver.cpp:106] Iteration 158000, lr = 3.51844e-06
I0506 04:55:28.421823 12834 solver.cpp:242] Iteration 158100 (93.8177 iter/s, 1.0659s/100 iter), loss = 0.908393
I0506 04:55:28.421862 12834 solver.cpp:261]     Train net output #0: loss = 0.908393 (* 1 = 0.908393 loss)
I0506 04:55:28.421871 12834 sgd_solver.cpp:106] Iteration 158100, lr = 3.51844e-06
I0506 04:55:28.426592 12834 solver.cpp:242] Iteration 158100 (106.668 iter/s, 0.937486s/100 iter), loss = 0.449448
I0506 04:55:28.426617 12834 solver.cpp:261]     Train net output #0: loss = 0.449448 (* 1 = 0.449448 loss)
I0506 04:55:28.426626 12834 sgd_solver.cpp:106] Iteration 158100, lr = 3.51844e-06
I0506 04:55:29.359541 12834 solver.cpp:242] Iteration 158200 (106.65 iter/s, 0.937648s/100 iter), loss = 0.853355
I0506 04:55:29.359576 12834 solver.cpp:261]     Train net output #0: loss = 0.853355 (* 1 = 0.853355 loss)
I0506 04:55:29.359586 12834 sgd_solver.cpp:106] Iteration 158200, lr = 3.51844e-06
I0506 04:55:29.364349 12834 solver.cpp:242] Iteration 158200 (106.642 iter/s, 0.937714s/100 iter), loss = 0.390103
I0506 04:55:29.364373 12834 solver.cpp:261]     Train net output #0: loss = 0.390103 (* 1 = 0.390103 loss)
I0506 04:55:29.364382 12834 sgd_solver.cpp:106] Iteration 158200, lr = 3.51844e-06
I0506 04:55:30.297334 12834 solver.cpp:242] Iteration 158300 (106.64 iter/s, 0.937733s/100 iter), loss = 1.27211
I0506 04:55:30.297376 12834 solver.cpp:261]     Train net output #0: loss = 1.27211 (* 1 = 1.27211 loss)
I0506 04:55:30.297385 12834 sgd_solver.cpp:106] Iteration 158300, lr = 3.51844e-06
I0506 04:55:30.302130 12834 solver.cpp:242] Iteration 158300 (106.64 iter/s, 0.937738s/100 iter), loss = 0.582985
I0506 04:55:30.302155 12834 solver.cpp:261]     Train net output #0: loss = 0.582985 (* 1 = 0.582985 loss)
I0506 04:55:30.302165 12834 sgd_solver.cpp:106] Iteration 158300, lr = 3.51844e-06
I0506 04:55:31.303469 12834 solver.cpp:242] Iteration 158400 (99.3978 iter/s, 1.00606s/100 iter), loss = 1.10642
I0506 04:55:31.303519 12834 solver.cpp:261]     Train net output #0: loss = 1.10642 (* 1 = 1.10642 loss)
I0506 04:55:31.303532 12834 sgd_solver.cpp:106] Iteration 158400, lr = 3.51844e-06
I0506 04:55:31.308787 12834 solver.cpp:242] Iteration 158400 (99.3433 iter/s, 1.00661s/100 iter), loss = 0.959023
I0506 04:55:31.308817 12834 solver.cpp:261]     Train net output #0: loss = 0.959023 (* 1 = 0.959023 loss)
I0506 04:55:31.308828 12834 sgd_solver.cpp:106] Iteration 158400, lr = 3.51844e-06
I0506 04:55:32.272758 12834 solver.cpp:362] Iteration 158500, Testing net (#0)
I0506 04:55:32.272786 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:32.395392 12834 solver.cpp:429]     Test net output #0: loss = 1.10193 (* 1 = 1.10193 loss)
I0506 04:55:32.397914 12834 solver.cpp:242] Iteration 158500 (91.3762 iter/s, 1.09438s/100 iter), loss = 0.903678
I0506 04:55:32.397938 12834 solver.cpp:261]     Train net output #0: loss = 0.903678 (* 1 = 0.903678 loss)
I0506 04:55:32.397946 12834 sgd_solver.cpp:106] Iteration 158500, lr = 3.51844e-06
I0506 04:55:32.399838 12834 solver.cpp:362] Iteration 158500, Testing net (#0)
I0506 04:55:32.399860 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:32.528928 12834 solver.cpp:429]     Test net output #0: accuracy = 0.807
I0506 04:55:32.528949 12834 solver.cpp:429]     Test net output #1: loss = 0.470465 (* 1 = 0.470465 loss)
I0506 04:55:32.531518 12834 solver.cpp:242] Iteration 158500 (81.7875 iter/s, 1.22268s/100 iter), loss = 0.645436
I0506 04:55:32.531538 12834 solver.cpp:261]     Train net output #0: loss = 0.645436 (* 1 = 0.645436 loss)
I0506 04:55:32.531548 12834 sgd_solver.cpp:106] Iteration 158500, lr = 3.51844e-06
I0506 04:55:33.478087 12834 solver.cpp:242] Iteration 158600 (92.5822 iter/s, 1.08012s/100 iter), loss = 0.395731
I0506 04:55:33.478119 12834 solver.cpp:261]     Train net output #0: loss = 0.395731 (* 1 = 0.395731 loss)
I0506 04:55:33.478128 12834 sgd_solver.cpp:106] Iteration 158600, lr = 3.51844e-06
I0506 04:55:33.482857 12834 solver.cpp:242] Iteration 158600 (105.119 iter/s, 0.951299s/100 iter), loss = 0.549363
I0506 04:55:33.482882 12834 solver.cpp:261]     Train net output #0: loss = 0.549363 (* 1 = 0.549363 loss)
I0506 04:55:33.482892 12834 sgd_solver.cpp:106] Iteration 158600, lr = 3.51844e-06
I0506 04:55:34.415606 12834 solver.cpp:242] Iteration 158700 (106.671 iter/s, 0.937463s/100 iter), loss = 0.580316
I0506 04:55:34.415648 12834 solver.cpp:261]     Train net output #0: loss = 0.580316 (* 1 = 0.580316 loss)
I0506 04:55:34.415658 12834 sgd_solver.cpp:106] Iteration 158700, lr = 3.51844e-06
I0506 04:55:34.420377 12834 solver.cpp:242] Iteration 158700 (106.67 iter/s, 0.937469s/100 iter), loss = 0.550261
I0506 04:55:34.420402 12834 solver.cpp:261]     Train net output #0: loss = 0.550261 (* 1 = 0.550261 loss)
I0506 04:55:34.420410 12834 sgd_solver.cpp:106] Iteration 158700, lr = 3.51844e-06
I0506 04:55:35.353390 12834 solver.cpp:242] Iteration 158800 (106.642 iter/s, 0.937715s/100 iter), loss = 0.405587
I0506 04:55:35.353432 12834 solver.cpp:261]     Train net output #0: loss = 0.405587 (* 1 = 0.405587 loss)
I0506 04:55:35.353442 12834 sgd_solver.cpp:106] Iteration 158800, lr = 3.51844e-06
I0506 04:55:35.358172 12834 solver.cpp:242] Iteration 158800 (106.638 iter/s, 0.937753s/100 iter), loss = 0.317964
I0506 04:55:35.358196 12834 solver.cpp:261]     Train net output #0: loss = 0.317964 (* 1 = 0.317964 loss)
I0506 04:55:35.358204 12834 sgd_solver.cpp:106] Iteration 158800, lr = 3.51844e-06
I0506 04:55:36.291194 12834 solver.cpp:242] Iteration 158900 (106.641 iter/s, 0.937729s/100 iter), loss = 0.877862
I0506 04:55:36.291234 12834 solver.cpp:261]     Train net output #0: loss = 0.877862 (* 1 = 0.877862 loss)
I0506 04:55:36.291244 12834 sgd_solver.cpp:106] Iteration 158900, lr = 3.51844e-06
I0506 04:55:36.295984 12834 solver.cpp:242] Iteration 158900 (106.636 iter/s, 0.937769s/100 iter), loss = 0.378172
I0506 04:55:36.296006 12834 solver.cpp:261]     Train net output #0: loss = 0.378172 (* 1 = 0.378172 loss)
I0506 04:55:36.296015 12834 sgd_solver.cpp:106] Iteration 158900, lr = 3.51844e-06
I0506 04:55:37.294359 12834 solver.cpp:362] Iteration 159000, Testing net (#0)
I0506 04:55:37.294389 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:37.427338 12834 solver.cpp:429]     Test net output #0: loss = 1.23982 (* 1 = 1.23982 loss)
I0506 04:55:37.429978 12834 solver.cpp:242] Iteration 159000 (87.8176 iter/s, 1.13872s/100 iter), loss = 1.84114
I0506 04:55:37.430002 12834 solver.cpp:261]     Train net output #0: loss = 1.84114 (* 1 = 1.84114 loss)
I0506 04:55:37.430013 12834 sgd_solver.cpp:106] Iteration 159000, lr = 3.51844e-06
I0506 04:55:37.432201 12834 solver.cpp:362] Iteration 159000, Testing net (#0)
I0506 04:55:37.432216 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:37.573263 12834 solver.cpp:429]     Test net output #0: accuracy = 0.774
I0506 04:55:37.573287 12834 solver.cpp:429]     Test net output #1: loss = 0.523368 (* 1 = 0.523368 loss)
I0506 04:55:37.575990 12834 solver.cpp:242] Iteration 159000 (78.1274 iter/s, 1.27996s/100 iter), loss = 0.549085
I0506 04:55:37.576016 12834 solver.cpp:261]     Train net output #0: loss = 0.549085 (* 1 = 0.549085 loss)
I0506 04:55:37.576036 12834 sgd_solver.cpp:106] Iteration 159000, lr = 3.51844e-06
I0506 04:55:38.520217 12834 solver.cpp:242] Iteration 159100 (91.7279 iter/s, 1.09018s/100 iter), loss = 2.4995
I0506 04:55:38.520259 12834 solver.cpp:261]     Train net output #0: loss = 2.4995 (* 1 = 2.4995 loss)
I0506 04:55:38.520269 12834 sgd_solver.cpp:106] Iteration 159100, lr = 3.51844e-06
I0506 04:55:38.524986 12834 solver.cpp:242] Iteration 159100 (105.38 iter/s, 0.948951s/100 iter), loss = 0.455032
I0506 04:55:38.525009 12834 solver.cpp:261]     Train net output #0: loss = 0.455032 (* 1 = 0.455032 loss)
I0506 04:55:38.525018 12834 sgd_solver.cpp:106] Iteration 159100, lr = 3.51844e-06
I0506 04:55:39.457494 12834 solver.cpp:242] Iteration 159200 (106.7 iter/s, 0.937211s/100 iter), loss = 1.29398
I0506 04:55:39.457540 12834 solver.cpp:261]     Train net output #0: loss = 1.29398 (* 1 = 1.29398 loss)
I0506 04:55:39.457818 12834 sgd_solver.cpp:106] Iteration 159200, lr = 3.51844e-06
I0506 04:55:39.462640 12834 solver.cpp:242] Iteration 159200 (106.654 iter/s, 0.937612s/100 iter), loss = 0.420292
I0506 04:55:39.462666 12834 solver.cpp:261]     Train net output #0: loss = 0.420292 (* 1 = 0.420292 loss)
I0506 04:55:39.462674 12834 sgd_solver.cpp:106] Iteration 159200, lr = 3.51844e-06
I0506 04:55:40.395725 12834 solver.cpp:242] Iteration 159300 (106.592 iter/s, 0.938156s/100 iter), loss = 2.3731
I0506 04:55:40.395763 12834 solver.cpp:261]     Train net output #0: loss = 2.3731 (* 1 = 2.3731 loss)
I0506 04:55:40.395772 12834 sgd_solver.cpp:106] Iteration 159300, lr = 3.51844e-06
I0506 04:55:40.400521 12834 solver.cpp:242] Iteration 159300 (106.628 iter/s, 0.937839s/100 iter), loss = 0.548356
I0506 04:55:40.400547 12834 solver.cpp:261]     Train net output #0: loss = 0.548356 (* 1 = 0.548356 loss)
I0506 04:55:40.400560 12834 sgd_solver.cpp:106] Iteration 159300, lr = 3.51844e-06
I0506 04:55:41.333276 12834 solver.cpp:242] Iteration 159400 (106.668 iter/s, 0.937488s/100 iter), loss = 3.30446
I0506 04:55:41.333312 12834 solver.cpp:261]     Train net output #0: loss = 3.30446 (* 1 = 3.30446 loss)
I0506 04:55:41.333320 12834 sgd_solver.cpp:106] Iteration 159400, lr = 3.51844e-06
I0506 04:55:41.338127 12834 solver.cpp:242] Iteration 159400 (106.661 iter/s, 0.937553s/100 iter), loss = 0.650676
I0506 04:55:41.338152 12834 solver.cpp:261]     Train net output #0: loss = 0.650676 (* 1 = 0.650676 loss)
I0506 04:55:41.338162 12834 sgd_solver.cpp:106] Iteration 159400, lr = 3.51844e-06
I0506 04:55:42.267652 12834 solver.cpp:362] Iteration 159500, Testing net (#0)
I0506 04:55:42.267674 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:42.390311 12834 solver.cpp:429]     Test net output #0: loss = 1.09626 (* 1 = 1.09626 loss)
I0506 04:55:42.392837 12834 solver.cpp:242] Iteration 159500 (94.3837 iter/s, 1.05951s/100 iter), loss = 0.236008
I0506 04:55:42.392858 12834 solver.cpp:261]     Train net output #0: loss = 0.236008 (* 1 = 0.236008 loss)
I0506 04:55:42.392866 12834 sgd_solver.cpp:106] Iteration 159500, lr = 3.51844e-06
I0506 04:55:42.394686 12834 solver.cpp:362] Iteration 159500, Testing net (#0)
I0506 04:55:42.394698 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:42.523398 12834 solver.cpp:429]     Test net output #0: accuracy = 0.784
I0506 04:55:42.523418 12834 solver.cpp:429]     Test net output #1: loss = 0.497118 (* 1 = 0.497118 loss)
I0506 04:55:42.525976 12834 solver.cpp:242] Iteration 159500 (84.1891 iter/s, 1.1878s/100 iter), loss = 0.629377
I0506 04:55:42.525997 12834 solver.cpp:261]     Train net output #0: loss = 0.629377 (* 1 = 0.629377 loss)
I0506 04:55:42.526007 12834 sgd_solver.cpp:106] Iteration 159500, lr = 3.51844e-06
I0506 04:55:43.551331 12834 solver.cpp:242] Iteration 159600 (86.3227 iter/s, 1.15844s/100 iter), loss = 0.659676
I0506 04:55:43.551376 12834 solver.cpp:261]     Train net output #0: loss = 0.659676 (* 1 = 0.659676 loss)
I0506 04:55:43.551388 12834 sgd_solver.cpp:106] Iteration 159600, lr = 3.51844e-06
I0506 04:55:43.556749 12834 solver.cpp:242] Iteration 159600 (97.0194 iter/s, 1.03072s/100 iter), loss = 0.735463
I0506 04:55:43.556780 12834 solver.cpp:261]     Train net output #0: loss = 0.735463 (* 1 = 0.735463 loss)
I0506 04:55:43.556792 12834 sgd_solver.cpp:106] Iteration 159600, lr = 3.51844e-06
I0506 04:55:44.587111 12834 solver.cpp:242] Iteration 159700 (96.5524 iter/s, 1.03571s/100 iter), loss = 0.90012
I0506 04:55:44.587163 12834 solver.cpp:261]     Train net output #0: loss = 0.90012 (* 1 = 0.90012 loss)
I0506 04:55:44.587432 12834 sgd_solver.cpp:106] Iteration 159700, lr = 3.51844e-06
I0506 04:55:44.592242 12834 solver.cpp:242] Iteration 159700 (96.5769 iter/s, 1.03544s/100 iter), loss = 0.298598
I0506 04:55:44.592267 12834 solver.cpp:261]     Train net output #0: loss = 0.298598 (* 1 = 0.298598 loss)
I0506 04:55:44.592277 12834 sgd_solver.cpp:106] Iteration 159700, lr = 3.51844e-06
I0506 04:55:45.525485 12834 solver.cpp:242] Iteration 159800 (106.577 iter/s, 0.938292s/100 iter), loss = 3.85859
I0506 04:55:45.525519 12834 solver.cpp:261]     Train net output #0: loss = 3.85859 (* 1 = 3.85859 loss)
I0506 04:55:45.525529 12834 sgd_solver.cpp:106] Iteration 159800, lr = 3.51844e-06
I0506 04:55:45.530282 12834 solver.cpp:242] Iteration 159800 (106.61 iter/s, 0.937997s/100 iter), loss = 0.740486
I0506 04:55:45.530308 12834 solver.cpp:261]     Train net output #0: loss = 0.740486 (* 1 = 0.740486 loss)
I0506 04:55:45.530316 12834 sgd_solver.cpp:106] Iteration 159800, lr = 3.51844e-06
I0506 04:55:46.463454 12834 solver.cpp:242] Iteration 159900 (106.62 iter/s, 0.937908s/100 iter), loss = 1.34334
I0506 04:55:46.463495 12834 solver.cpp:261]     Train net output #0: loss = 1.34334 (* 1 = 1.34334 loss)
I0506 04:55:46.463505 12834 sgd_solver.cpp:106] Iteration 159900, lr = 3.51844e-06
I0506 04:55:46.468221 12834 solver.cpp:242] Iteration 159900 (106.622 iter/s, 0.937895s/100 iter), loss = 0.772249
I0506 04:55:46.468246 12834 solver.cpp:261]     Train net output #0: loss = 0.772249 (* 1 = 0.772249 loss)
I0506 04:55:46.468255 12834 sgd_solver.cpp:106] Iteration 159900, lr = 3.51844e-06
I0506 04:55:47.484463 12834 solver.cpp:362] Iteration 160000, Testing net (#0)
I0506 04:55:47.484496 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:47.617733 12834 solver.cpp:429]     Test net output #0: loss = 1.09972 (* 1 = 1.09972 loss)
I0506 04:55:47.620374 12834 solver.cpp:242] Iteration 160000 (86.441 iter/s, 1.15686s/100 iter), loss = 0.487067
I0506 04:55:47.620398 12834 solver.cpp:261]     Train net output #0: loss = 0.487067 (* 1 = 0.487067 loss)
I0506 04:55:47.620409 12834 sgd_solver.cpp:106] Iteration 160000, lr = 2.81475e-06
I0506 04:55:47.622637 12834 solver.cpp:362] Iteration 160000, Testing net (#0)
I0506 04:55:47.622653 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:47.763357 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7775
I0506 04:55:47.763381 12834 solver.cpp:429]     Test net output #1: loss = 0.508672 (* 1 = 0.508672 loss)
I0506 04:55:47.766067 12834 solver.cpp:242] Iteration 160000 (77.0536 iter/s, 1.2978s/100 iter), loss = 0.324165
I0506 04:55:47.766093 12834 solver.cpp:261]     Train net output #0: loss = 0.324165 (* 1 = 0.324165 loss)
I0506 04:55:47.766103 12834 sgd_solver.cpp:106] Iteration 160000, lr = 2.81475e-06
I0506 04:55:48.796116 12834 solver.cpp:242] Iteration 160100 (85.0566 iter/s, 1.17569s/100 iter), loss = 1.3069
I0506 04:55:48.796159 12834 solver.cpp:261]     Train net output #0: loss = 1.3069 (* 1 = 1.3069 loss)
I0506 04:55:48.796170 12834 sgd_solver.cpp:106] Iteration 160100, lr = 2.81475e-06
I0506 04:55:48.801398 12834 solver.cpp:242] Iteration 160100 (96.5916 iter/s, 1.03529s/100 iter), loss = 0.633513
I0506 04:55:48.801426 12834 solver.cpp:261]     Train net output #0: loss = 0.633513 (* 1 = 0.633513 loss)
I0506 04:55:48.801437 12834 sgd_solver.cpp:106] Iteration 160100, lr = 2.81475e-06
I0506 04:55:49.818559 12834 solver.cpp:242] Iteration 160200 (97.8119 iter/s, 1.02237s/100 iter), loss = 0.688033
I0506 04:55:49.818603 12834 solver.cpp:261]     Train net output #0: loss = 0.688033 (* 1 = 0.688033 loss)
I0506 04:55:49.818919 12834 sgd_solver.cpp:106] Iteration 160200, lr = 2.81475e-06
I0506 04:55:49.823709 12834 solver.cpp:242] Iteration 160200 (97.8221 iter/s, 1.02226s/100 iter), loss = 0.365952
I0506 04:55:49.823734 12834 solver.cpp:261]     Train net output #0: loss = 0.365952 (* 1 = 0.365952 loss)
I0506 04:55:49.823742 12834 sgd_solver.cpp:106] Iteration 160200, lr = 2.81475e-06
I0506 04:55:50.769675 12834 solver.cpp:242] Iteration 160300 (105.147 iter/s, 0.951052s/100 iter), loss = 0.479074
I0506 04:55:50.769704 12834 solver.cpp:261]     Train net output #0: loss = 0.479074 (* 1 = 0.479074 loss)
I0506 04:55:50.769713 12834 sgd_solver.cpp:106] Iteration 160300, lr = 2.81475e-06
I0506 04:55:50.774487 12834 solver.cpp:242] Iteration 160300 (105.183 iter/s, 0.950724s/100 iter), loss = 0.663206
I0506 04:55:50.774509 12834 solver.cpp:261]     Train net output #0: loss = 0.663206 (* 1 = 0.663206 loss)
I0506 04:55:50.774518 12834 sgd_solver.cpp:106] Iteration 160300, lr = 2.81475e-06
I0506 04:55:51.707108 12834 solver.cpp:242] Iteration 160400 (106.681 iter/s, 0.937374s/100 iter), loss = 3.33369
I0506 04:55:51.707149 12834 solver.cpp:261]     Train net output #0: loss = 3.33369 (* 1 = 3.33369 loss)
I0506 04:55:51.707159 12834 sgd_solver.cpp:106] Iteration 160400, lr = 2.81475e-06
I0506 04:55:51.711869 12834 solver.cpp:242] Iteration 160400 (106.685 iter/s, 0.93734s/100 iter), loss = 0.580052
I0506 04:55:51.711894 12834 solver.cpp:261]     Train net output #0: loss = 0.580052 (* 1 = 0.580052 loss)
I0506 04:55:51.711904 12834 sgd_solver.cpp:106] Iteration 160400, lr = 2.81475e-06
I0506 04:55:52.641387 12834 solver.cpp:362] Iteration 160500, Testing net (#0)
I0506 04:55:52.641415 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:52.764106 12834 solver.cpp:429]     Test net output #0: loss = 1.2357 (* 1 = 1.2357 loss)
I0506 04:55:52.766629 12834 solver.cpp:242] Iteration 160500 (94.3875 iter/s, 1.05946s/100 iter), loss = 1.02244
I0506 04:55:52.766650 12834 solver.cpp:261]     Train net output #0: loss = 1.02244 (* 1 = 1.02244 loss)
I0506 04:55:52.766659 12834 sgd_solver.cpp:106] Iteration 160500, lr = 2.81475e-06
I0506 04:55:52.768544 12834 solver.cpp:362] Iteration 160500, Testing net (#0)
I0506 04:55:52.768561 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:52.897300 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7835
I0506 04:55:52.897317 12834 solver.cpp:429]     Test net output #1: loss = 0.487215 (* 1 = 0.487215 loss)
I0506 04:55:52.899880 12834 solver.cpp:242] Iteration 160500 (84.1776 iter/s, 1.18796s/100 iter), loss = 0.504555
I0506 04:55:52.899900 12834 solver.cpp:261]     Train net output #0: loss = 0.504555 (* 1 = 0.504555 loss)
I0506 04:55:52.899909 12834 sgd_solver.cpp:106] Iteration 160500, lr = 2.81475e-06
I0506 04:55:53.833335 12834 solver.cpp:242] Iteration 160600 (93.751 iter/s, 1.06665s/100 iter), loss = 0.247249
I0506 04:55:53.833377 12834 solver.cpp:261]     Train net output #0: loss = 0.247249 (* 1 = 0.247249 loss)
I0506 04:55:53.833386 12834 sgd_solver.cpp:106] Iteration 160600, lr = 2.81475e-06
I0506 04:55:53.838122 12834 solver.cpp:242] Iteration 160600 (106.587 iter/s, 0.938204s/100 iter), loss = 0.538833
I0506 04:55:53.838146 12834 solver.cpp:261]     Train net output #0: loss = 0.538833 (* 1 = 0.538833 loss)
I0506 04:55:53.838155 12834 sgd_solver.cpp:106] Iteration 160600, lr = 2.81475e-06
I0506 04:55:54.790951 12834 solver.cpp:242] Iteration 160700 (104.434 iter/s, 0.957538s/100 iter), loss = 0.824062
I0506 04:55:54.791000 12834 solver.cpp:261]     Train net output #0: loss = 0.824062 (* 1 = 0.824062 loss)
I0506 04:55:54.791012 12834 sgd_solver.cpp:106] Iteration 160700, lr = 2.81475e-06
I0506 04:55:54.796234 12834 solver.cpp:242] Iteration 160700 (104.377 iter/s, 0.958069s/100 iter), loss = 0.478365
I0506 04:55:54.796267 12834 solver.cpp:261]     Train net output #0: loss = 0.478365 (* 1 = 0.478365 loss)
I0506 04:55:54.796277 12834 sgd_solver.cpp:106] Iteration 160700, lr = 2.81475e-06
I0506 04:55:55.743851 12834 solver.cpp:242] Iteration 160800 (104.951 iter/s, 0.952825s/100 iter), loss = 0.430598
I0506 04:55:55.743894 12834 solver.cpp:261]     Train net output #0: loss = 0.430598 (* 1 = 0.430598 loss)
I0506 04:55:55.743904 12834 sgd_solver.cpp:106] Iteration 160800, lr = 2.81475e-06
I0506 04:55:55.748651 12834 solver.cpp:242] Iteration 160800 (105.002 iter/s, 0.952366s/100 iter), loss = 0.437638
I0506 04:55:55.748674 12834 solver.cpp:261]     Train net output #0: loss = 0.437638 (* 1 = 0.437638 loss)
I0506 04:55:55.748683 12834 sgd_solver.cpp:106] Iteration 160800, lr = 2.81475e-06
I0506 04:55:56.681450 12834 solver.cpp:242] Iteration 160900 (106.664 iter/s, 0.937524s/100 iter), loss = 1.18665
I0506 04:55:56.681490 12834 solver.cpp:261]     Train net output #0: loss = 1.18665 (* 1 = 1.18665 loss)
I0506 04:55:56.681499 12834 sgd_solver.cpp:106] Iteration 160900, lr = 2.81475e-06
I0506 04:55:56.686223 12834 solver.cpp:242] Iteration 160900 (106.663 iter/s, 0.937529s/100 iter), loss = 0.50702
I0506 04:55:56.686245 12834 solver.cpp:261]     Train net output #0: loss = 0.50702 (* 1 = 0.50702 loss)
I0506 04:55:56.686254 12834 sgd_solver.cpp:106] Iteration 160900, lr = 2.81475e-06
I0506 04:55:57.615669 12834 solver.cpp:362] Iteration 161000, Testing net (#0)
I0506 04:55:57.615694 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:57.738466 12834 solver.cpp:429]     Test net output #0: loss = 1.14639 (* 1 = 1.14639 loss)
I0506 04:55:57.740978 12834 solver.cpp:242] Iteration 161000 (94.3868 iter/s, 1.05947s/100 iter), loss = 5.19143
I0506 04:55:57.740999 12834 solver.cpp:261]     Train net output #0: loss = 5.19143 (* 1 = 5.19143 loss)
I0506 04:55:57.741008 12834 sgd_solver.cpp:106] Iteration 161000, lr = 2.81475e-06
I0506 04:55:57.742832 12834 solver.cpp:362] Iteration 161000, Testing net (#0)
I0506 04:55:57.742846 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:55:57.871459 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7675
I0506 04:55:57.871479 12834 solver.cpp:429]     Test net output #1: loss = 0.523126 (* 1 = 0.523126 loss)
I0506 04:55:57.874047 12834 solver.cpp:242] Iteration 161000 (84.1907 iter/s, 1.18778s/100 iter), loss = 0.757836
I0506 04:55:57.874066 12834 solver.cpp:261]     Train net output #0: loss = 0.757836 (* 1 = 0.757836 loss)
I0506 04:55:57.874075 12834 sgd_solver.cpp:106] Iteration 161000, lr = 2.81475e-06
I0506 04:55:58.830940 12834 solver.cpp:242] Iteration 161100 (91.7512 iter/s, 1.0899s/100 iter), loss = 5.31379
I0506 04:55:58.830986 12834 solver.cpp:261]     Train net output #0: loss = 5.31379 (* 1 = 5.31379 loss)
I0506 04:55:58.830996 12834 sgd_solver.cpp:106] Iteration 161100, lr = 2.81475e-06
I0506 04:55:58.836225 12834 solver.cpp:242] Iteration 161100 (103.935 iter/s, 0.962139s/100 iter), loss = 0.757029
I0506 04:55:58.836256 12834 solver.cpp:261]     Train net output #0: loss = 0.757029 (* 1 = 0.757029 loss)
I0506 04:55:58.836267 12834 sgd_solver.cpp:106] Iteration 161100, lr = 2.81475e-06
I0506 04:55:59.861013 12834 solver.cpp:242] Iteration 161200 (97.0869 iter/s, 1.03s/100 iter), loss = 1.45001
I0506 04:55:59.861053 12834 solver.cpp:261]     Train net output #0: loss = 1.45001 (* 1 = 1.45001 loss)
I0506 04:55:59.861063 12834 sgd_solver.cpp:106] Iteration 161200, lr = 2.81475e-06
I0506 04:55:59.865852 12834 solver.cpp:242] Iteration 161200 (97.1282 iter/s, 1.02957s/100 iter), loss = 0.408507
I0506 04:55:59.865877 12834 solver.cpp:261]     Train net output #0: loss = 0.408507 (* 1 = 0.408507 loss)
I0506 04:55:59.865886 12834 sgd_solver.cpp:106] Iteration 161200, lr = 2.81475e-06
I0506 04:56:00.805076 12834 solver.cpp:242] Iteration 161300 (105.933 iter/s, 0.943993s/100 iter), loss = 0.538357
I0506 04:56:00.805119 12834 solver.cpp:261]     Train net output #0: loss = 0.538357 (* 1 = 0.538357 loss)
I0506 04:56:00.805129 12834 sgd_solver.cpp:106] Iteration 161300, lr = 2.81475e-06
I0506 04:56:00.809876 12834 solver.cpp:242] Iteration 161300 (105.934 iter/s, 0.943981s/100 iter), loss = 0.31508
I0506 04:56:00.809903 12834 solver.cpp:261]     Train net output #0: loss = 0.31508 (* 1 = 0.31508 loss)
I0506 04:56:00.809921 12834 sgd_solver.cpp:106] Iteration 161300, lr = 2.81475e-06
I0506 04:56:01.743114 12834 solver.cpp:242] Iteration 161400 (106.613 iter/s, 0.937974s/100 iter), loss = 1.44945
I0506 04:56:01.743151 12834 solver.cpp:261]     Train net output #0: loss = 1.44945 (* 1 = 1.44945 loss)
I0506 04:56:01.743161 12834 sgd_solver.cpp:106] Iteration 161400, lr = 2.81475e-06
I0506 04:56:01.747972 12834 solver.cpp:242] Iteration 161400 (106.605 iter/s, 0.938041s/100 iter), loss = 0.348278
I0506 04:56:01.747997 12834 solver.cpp:261]     Train net output #0: loss = 0.348278 (* 1 = 0.348278 loss)
I0506 04:56:01.748006 12834 sgd_solver.cpp:106] Iteration 161400, lr = 2.81475e-06
I0506 04:56:02.688217 12834 solver.cpp:362] Iteration 161500, Testing net (#0)
I0506 04:56:02.688241 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:02.813531 12834 solver.cpp:429]     Test net output #0: loss = 1.14161 (* 1 = 1.14161 loss)
I0506 04:56:02.816056 12834 solver.cpp:242] Iteration 161500 (93.2066 iter/s, 1.07288s/100 iter), loss = 0.615013
I0506 04:56:02.816076 12834 solver.cpp:261]     Train net output #0: loss = 0.615013 (* 1 = 0.615013 loss)
I0506 04:56:02.816084 12834 sgd_solver.cpp:106] Iteration 161500, lr = 2.81475e-06
I0506 04:56:02.817944 12834 solver.cpp:362] Iteration 161500, Testing net (#0)
I0506 04:56:02.817955 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:02.946410 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7875
I0506 04:56:02.946429 12834 solver.cpp:429]     Test net output #1: loss = 0.492697 (* 1 = 0.492697 loss)
I0506 04:56:02.948983 12834 solver.cpp:242] Iteration 161500 (83.2663 iter/s, 1.20097s/100 iter), loss = 0.335511
I0506 04:56:02.949004 12834 solver.cpp:261]     Train net output #0: loss = 0.335511 (* 1 = 0.335511 loss)
I0506 04:56:02.949012 12834 sgd_solver.cpp:106] Iteration 161500, lr = 2.81475e-06
I0506 04:56:03.882339 12834 solver.cpp:242] Iteration 161600 (93.7884 iter/s, 1.06623s/100 iter), loss = 1.77747
I0506 04:56:03.882374 12834 solver.cpp:261]     Train net output #0: loss = 1.77747 (* 1 = 1.77747 loss)
I0506 04:56:03.882382 12834 sgd_solver.cpp:106] Iteration 161600, lr = 2.81475e-06
I0506 04:56:03.887095 12834 solver.cpp:242] Iteration 161600 (106.602 iter/s, 0.938073s/100 iter), loss = 0.494704
I0506 04:56:03.887120 12834 solver.cpp:261]     Train net output #0: loss = 0.494704 (* 1 = 0.494704 loss)
I0506 04:56:03.887128 12834 sgd_solver.cpp:106] Iteration 161600, lr = 2.81475e-06
I0506 04:56:04.819223 12834 solver.cpp:242] Iteration 161700 (106.744 iter/s, 0.936825s/100 iter), loss = 1.45366
I0506 04:56:04.819258 12834 solver.cpp:261]     Train net output #0: loss = 1.45366 (* 1 = 1.45366 loss)
I0506 04:56:04.819267 12834 sgd_solver.cpp:106] Iteration 161700, lr = 2.81475e-06
I0506 04:56:04.824056 12834 solver.cpp:242] Iteration 161700 (106.733 iter/s, 0.936918s/100 iter), loss = 0.880852
I0506 04:56:04.824080 12834 solver.cpp:261]     Train net output #0: loss = 0.880852 (* 1 = 0.880852 loss)
I0506 04:56:04.824090 12834 sgd_solver.cpp:106] Iteration 161700, lr = 2.81475e-06
I0506 04:56:05.756707 12834 solver.cpp:242] Iteration 161800 (106.676 iter/s, 0.93742s/100 iter), loss = 1.33637
I0506 04:56:05.756738 12834 solver.cpp:261]     Train net output #0: loss = 1.33637 (* 1 = 1.33637 loss)
I0506 04:56:05.756748 12834 sgd_solver.cpp:106] Iteration 161800, lr = 2.81475e-06
I0506 04:56:05.761447 12834 solver.cpp:242] Iteration 161800 (106.684 iter/s, 0.93735s/100 iter), loss = 0.443147
I0506 04:56:05.761471 12834 solver.cpp:261]     Train net output #0: loss = 0.443147 (* 1 = 0.443147 loss)
I0506 04:56:05.761481 12834 sgd_solver.cpp:106] Iteration 161800, lr = 2.81475e-06
I0506 04:56:06.706280 12834 solver.cpp:242] Iteration 161900 (105.317 iter/s, 0.949514s/100 iter), loss = 2.37361
I0506 04:56:06.706331 12834 solver.cpp:261]     Train net output #0: loss = 2.37361 (* 1 = 2.37361 loss)
I0506 04:56:06.706341 12834 sgd_solver.cpp:106] Iteration 161900, lr = 2.81475e-06
I0506 04:56:06.711556 12834 solver.cpp:242] Iteration 161900 (105.256 iter/s, 0.950066s/100 iter), loss = 0.788397
I0506 04:56:06.711596 12834 solver.cpp:261]     Train net output #0: loss = 0.788397 (* 1 = 0.788397 loss)
I0506 04:56:06.711608 12834 sgd_solver.cpp:106] Iteration 161900, lr = 2.81475e-06
I0506 04:56:07.685075 12834 solver.cpp:362] Iteration 162000, Testing net (#0)
I0506 04:56:07.685101 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:07.807729 12834 solver.cpp:429]     Test net output #0: loss = 1.18023 (* 1 = 1.18023 loss)
I0506 04:56:07.810251 12834 solver.cpp:242] Iteration 162000 (90.5876 iter/s, 1.1039s/100 iter), loss = 2.71563
I0506 04:56:07.810272 12834 solver.cpp:261]     Train net output #0: loss = 2.71563 (* 1 = 2.71563 loss)
I0506 04:56:07.810281 12834 sgd_solver.cpp:106] Iteration 162000, lr = 2.81475e-06
I0506 04:56:07.812105 12834 solver.cpp:362] Iteration 162000, Testing net (#0)
I0506 04:56:07.812119 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:07.940999 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7745
I0506 04:56:07.941020 12834 solver.cpp:429]     Test net output #1: loss = 0.503984 (* 1 = 0.503984 loss)
I0506 04:56:07.943570 12834 solver.cpp:242] Iteration 162000 (81.1719 iter/s, 1.23195s/100 iter), loss = 0.602455
I0506 04:56:07.943590 12834 solver.cpp:261]     Train net output #0: loss = 0.602455 (* 1 = 0.602455 loss)
I0506 04:56:07.943599 12834 sgd_solver.cpp:106] Iteration 162000, lr = 2.81475e-06
I0506 04:56:08.876662 12834 solver.cpp:242] Iteration 162100 (93.7768 iter/s, 1.06636s/100 iter), loss = 0.319069
I0506 04:56:08.876701 12834 solver.cpp:261]     Train net output #0: loss = 0.319069 (* 1 = 0.319069 loss)
I0506 04:56:08.876711 12834 sgd_solver.cpp:106] Iteration 162100, lr = 2.81475e-06
I0506 04:56:08.881506 12834 solver.cpp:242] Iteration 162100 (106.623 iter/s, 0.937888s/100 iter), loss = 0.154122
I0506 04:56:08.881531 12834 solver.cpp:261]     Train net output #0: loss = 0.154122 (* 1 = 0.154122 loss)
I0506 04:56:08.881541 12834 sgd_solver.cpp:106] Iteration 162100, lr = 2.81475e-06
I0506 04:56:09.814509 12834 solver.cpp:242] Iteration 162200 (106.635 iter/s, 0.937778s/100 iter), loss = 1.08503
I0506 04:56:09.814548 12834 solver.cpp:261]     Train net output #0: loss = 1.08503 (* 1 = 1.08503 loss)
I0506 04:56:09.814558 12834 sgd_solver.cpp:106] Iteration 162200, lr = 2.81475e-06
I0506 04:56:09.819269 12834 solver.cpp:242] Iteration 162200 (106.642 iter/s, 0.93772s/100 iter), loss = 0.585736
I0506 04:56:09.819295 12834 solver.cpp:261]     Train net output #0: loss = 0.585736 (* 1 = 0.585736 loss)
I0506 04:56:09.819304 12834 sgd_solver.cpp:106] Iteration 162200, lr = 2.81475e-06
I0506 04:56:10.770953 12834 solver.cpp:242] Iteration 162300 (104.561 iter/s, 0.956379s/100 iter), loss = 0.666058
I0506 04:56:10.771004 12834 solver.cpp:261]     Train net output #0: loss = 0.666058 (* 1 = 0.666058 loss)
I0506 04:56:10.771136 12834 sgd_solver.cpp:106] Iteration 162300, lr = 2.81475e-06
I0506 04:56:10.776028 12834 solver.cpp:242] Iteration 162300 (104.525 iter/s, 0.956706s/100 iter), loss = 0.491168
I0506 04:56:10.776056 12834 solver.cpp:261]     Train net output #0: loss = 0.491168 (* 1 = 0.491168 loss)
I0506 04:56:10.776064 12834 sgd_solver.cpp:106] Iteration 162300, lr = 2.81475e-06
I0506 04:56:11.708719 12834 solver.cpp:242] Iteration 162400 (106.645 iter/s, 0.937689s/100 iter), loss = 0.5536
I0506 04:56:11.708760 12834 solver.cpp:261]     Train net output #0: loss = 0.5536 (* 1 = 0.5536 loss)
I0506 04:56:11.708768 12834 sgd_solver.cpp:106] Iteration 162400, lr = 2.81475e-06
I0506 04:56:11.713490 12834 solver.cpp:242] Iteration 162400 (106.676 iter/s, 0.937418s/100 iter), loss = 0.179571
I0506 04:56:11.713513 12834 solver.cpp:261]     Train net output #0: loss = 0.179571 (* 1 = 0.179571 loss)
I0506 04:56:11.713522 12834 sgd_solver.cpp:106] Iteration 162400, lr = 2.81475e-06
I0506 04:56:12.643616 12834 solver.cpp:362] Iteration 162500, Testing net (#0)
I0506 04:56:12.643641 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:12.766158 12834 solver.cpp:429]     Test net output #0: loss = 1.22432 (* 1 = 1.22432 loss)
I0506 04:56:12.768677 12834 solver.cpp:242] Iteration 162500 (94.3485 iter/s, 1.0599s/100 iter), loss = 1.00038
I0506 04:56:12.768698 12834 solver.cpp:261]     Train net output #0: loss = 1.00038 (* 1 = 1.00038 loss)
I0506 04:56:12.768707 12834 sgd_solver.cpp:106] Iteration 162500, lr = 2.81475e-06
I0506 04:56:12.770540 12834 solver.cpp:362] Iteration 162500, Testing net (#0)
I0506 04:56:12.770555 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:12.899889 12834 solver.cpp:429]     Test net output #0: accuracy = 0.784
I0506 04:56:12.899910 12834 solver.cpp:429]     Test net output #1: loss = 0.509669 (* 1 = 0.509669 loss)
I0506 04:56:12.902465 12834 solver.cpp:242] Iteration 162500 (84.1092 iter/s, 1.18893s/100 iter), loss = 0.436476
I0506 04:56:12.902485 12834 solver.cpp:261]     Train net output #0: loss = 0.436476 (* 1 = 0.436476 loss)
I0506 04:56:12.902494 12834 sgd_solver.cpp:106] Iteration 162500, lr = 2.81475e-06
I0506 04:56:13.835252 12834 solver.cpp:242] Iteration 162600 (93.7625 iter/s, 1.06652s/100 iter), loss = 1.97188
I0506 04:56:13.835289 12834 solver.cpp:261]     Train net output #0: loss = 1.97188 (* 1 = 1.97188 loss)
I0506 04:56:13.835299 12834 sgd_solver.cpp:106] Iteration 162600, lr = 2.81475e-06
I0506 04:56:13.840024 12834 solver.cpp:242] Iteration 162600 (106.664 iter/s, 0.937521s/100 iter), loss = 0.631974
I0506 04:56:13.840049 12834 solver.cpp:261]     Train net output #0: loss = 0.631974 (* 1 = 0.631974 loss)
I0506 04:56:13.840059 12834 sgd_solver.cpp:106] Iteration 162600, lr = 2.81475e-06
I0506 04:56:14.772691 12834 solver.cpp:242] Iteration 162700 (106.682 iter/s, 0.937369s/100 iter), loss = 0.717298
I0506 04:56:14.772727 12834 solver.cpp:261]     Train net output #0: loss = 0.717298 (* 1 = 0.717298 loss)
I0506 04:56:14.772737 12834 sgd_solver.cpp:106] Iteration 162700, lr = 2.81475e-06
I0506 04:56:14.777477 12834 solver.cpp:242] Iteration 162700 (106.677 iter/s, 0.937409s/100 iter), loss = 0.562285
I0506 04:56:14.777501 12834 solver.cpp:261]     Train net output #0: loss = 0.562285 (* 1 = 0.562285 loss)
I0506 04:56:14.777510 12834 sgd_solver.cpp:106] Iteration 162700, lr = 2.81475e-06
I0506 04:56:15.709547 12834 solver.cpp:242] Iteration 162800 (106.747 iter/s, 0.936794s/100 iter), loss = 0.508542
I0506 04:56:15.709583 12834 solver.cpp:261]     Train net output #0: loss = 0.508542 (* 1 = 0.508542 loss)
I0506 04:56:15.709592 12834 sgd_solver.cpp:106] Iteration 162800, lr = 2.81475e-06
I0506 04:56:15.714321 12834 solver.cpp:242] Iteration 162800 (106.746 iter/s, 0.936802s/100 iter), loss = 0.340583
I0506 04:56:15.714345 12834 solver.cpp:261]     Train net output #0: loss = 0.340583 (* 1 = 0.340583 loss)
I0506 04:56:15.714354 12834 sgd_solver.cpp:106] Iteration 162800, lr = 2.81475e-06
I0506 04:56:16.647931 12834 solver.cpp:242] Iteration 162900 (106.574 iter/s, 0.938317s/100 iter), loss = 0.417238
I0506 04:56:16.647967 12834 solver.cpp:261]     Train net output #0: loss = 0.417238 (* 1 = 0.417238 loss)
I0506 04:56:16.647976 12834 sgd_solver.cpp:106] Iteration 162900, lr = 2.81475e-06
I0506 04:56:16.652717 12834 solver.cpp:242] Iteration 162900 (106.57 iter/s, 0.938354s/100 iter), loss = 0.284995
I0506 04:56:16.652741 12834 solver.cpp:261]     Train net output #0: loss = 0.284995 (* 1 = 0.284995 loss)
I0506 04:56:16.652750 12834 sgd_solver.cpp:106] Iteration 162900, lr = 2.81475e-06
I0506 04:56:17.582356 12834 solver.cpp:362] Iteration 163000, Testing net (#0)
I0506 04:56:17.582378 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:17.704972 12834 solver.cpp:429]     Test net output #0: loss = 1.11991 (* 1 = 1.11991 loss)
I0506 04:56:17.707487 12834 solver.cpp:242] Iteration 163000 (94.384 iter/s, 1.0595s/100 iter), loss = 0.996619
I0506 04:56:17.707507 12834 solver.cpp:261]     Train net output #0: loss = 0.996619 (* 1 = 0.996619 loss)
I0506 04:56:17.707515 12834 sgd_solver.cpp:106] Iteration 163000, lr = 2.81475e-06
I0506 04:56:17.709414 12834 solver.cpp:362] Iteration 163000, Testing net (#0)
I0506 04:56:17.709436 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:17.837816 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7835
I0506 04:56:17.837834 12834 solver.cpp:429]     Test net output #1: loss = 0.496452 (* 1 = 0.496452 loss)
I0506 04:56:17.840396 12834 solver.cpp:242] Iteration 163000 (84.2009 iter/s, 1.18764s/100 iter), loss = 0.427575
I0506 04:56:17.840415 12834 solver.cpp:261]     Train net output #0: loss = 0.427575 (* 1 = 0.427575 loss)
I0506 04:56:17.840425 12834 sgd_solver.cpp:106] Iteration 163000, lr = 2.81475e-06
I0506 04:56:18.793261 12834 solver.cpp:242] Iteration 163100 (92.1047 iter/s, 1.08572s/100 iter), loss = 0.650804
I0506 04:56:18.793311 12834 solver.cpp:261]     Train net output #0: loss = 0.650804 (* 1 = 0.650804 loss)
I0506 04:56:18.793323 12834 sgd_solver.cpp:106] Iteration 163100, lr = 2.81475e-06
I0506 04:56:18.798553 12834 solver.cpp:242] Iteration 163100 (104.371 iter/s, 0.958118s/100 iter), loss = 0.420733
I0506 04:56:18.798580 12834 solver.cpp:261]     Train net output #0: loss = 0.420733 (* 1 = 0.420733 loss)
I0506 04:56:18.798591 12834 sgd_solver.cpp:106] Iteration 163100, lr = 2.81475e-06
I0506 04:56:19.828124 12834 solver.cpp:242] Iteration 163200 (96.6381 iter/s, 1.03479s/100 iter), loss = 0.62524
I0506 04:56:19.828158 12834 solver.cpp:261]     Train net output #0: loss = 0.62524 (* 1 = 0.62524 loss)
I0506 04:56:19.828169 12834 sgd_solver.cpp:106] Iteration 163200, lr = 2.81475e-06
I0506 04:56:19.833488 12834 solver.cpp:242] Iteration 163200 (96.6297 iter/s, 1.03488s/100 iter), loss = 0.323172
I0506 04:56:19.833515 12834 solver.cpp:261]     Train net output #0: loss = 0.323172 (* 1 = 0.323172 loss)
I0506 04:56:19.833526 12834 sgd_solver.cpp:106] Iteration 163200, lr = 2.81475e-06
I0506 04:56:20.849895 12834 solver.cpp:242] Iteration 163300 (97.8753 iter/s, 1.02171s/100 iter), loss = 3.24121
I0506 04:56:20.849933 12834 solver.cpp:261]     Train net output #0: loss = 3.24121 (* 1 = 3.24121 loss)
I0506 04:56:20.849943 12834 sgd_solver.cpp:106] Iteration 163300, lr = 2.81475e-06
I0506 04:56:20.854676 12834 solver.cpp:242] Iteration 163300 (97.9297 iter/s, 1.02114s/100 iter), loss = 0.675416
I0506 04:56:20.854701 12834 solver.cpp:261]     Train net output #0: loss = 0.675416 (* 1 = 0.675416 loss)
I0506 04:56:20.854709 12834 sgd_solver.cpp:106] Iteration 163300, lr = 2.81475e-06
I0506 04:56:21.788456 12834 solver.cpp:242] Iteration 163400 (106.554 iter/s, 0.93849s/100 iter), loss = 1.96163
I0506 04:56:21.788503 12834 solver.cpp:261]     Train net output #0: loss = 1.96163 (* 1 = 1.96163 loss)
I0506 04:56:21.788573 12834 sgd_solver.cpp:106] Iteration 163400, lr = 2.81475e-06
I0506 04:56:21.793375 12834 solver.cpp:242] Iteration 163400 (106.535 iter/s, 0.938657s/100 iter), loss = 0.814678
I0506 04:56:21.793400 12834 solver.cpp:261]     Train net output #0: loss = 0.814678 (* 1 = 0.814678 loss)
I0506 04:56:21.793408 12834 sgd_solver.cpp:106] Iteration 163400, lr = 2.81475e-06
I0506 04:56:22.744534 12834 solver.cpp:362] Iteration 163500, Testing net (#0)
I0506 04:56:22.744567 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:22.867240 12834 solver.cpp:429]     Test net output #0: loss = 1.16564 (* 1 = 1.16564 loss)
I0506 04:56:22.869747 12834 solver.cpp:242] Iteration 163500 (92.4875 iter/s, 1.08123s/100 iter), loss = 0.667912
I0506 04:56:22.869770 12834 solver.cpp:261]     Train net output #0: loss = 0.667912 (* 1 = 0.667912 loss)
I0506 04:56:22.869778 12834 sgd_solver.cpp:106] Iteration 163500, lr = 2.81475e-06
I0506 04:56:22.871598 12834 solver.cpp:362] Iteration 163500, Testing net (#0)
I0506 04:56:22.871613 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:23.000231 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7865
I0506 04:56:23.000250 12834 solver.cpp:429]     Test net output #1: loss = 0.511223 (* 1 = 0.511223 loss)
I0506 04:56:23.002810 12834 solver.cpp:242] Iteration 163500 (82.6864 iter/s, 1.20939s/100 iter), loss = 0.678562
I0506 04:56:23.002830 12834 solver.cpp:261]     Train net output #0: loss = 0.678562 (* 1 = 0.678562 loss)
I0506 04:56:23.002846 12834 sgd_solver.cpp:106] Iteration 163500, lr = 2.81475e-06
I0506 04:56:23.973080 12834 solver.cpp:242] Iteration 163600 (90.6393 iter/s, 1.10327s/100 iter), loss = 0.839112
I0506 04:56:23.973129 12834 solver.cpp:261]     Train net output #0: loss = 0.839112 (* 1 = 0.839112 loss)
I0506 04:56:23.973140 12834 sgd_solver.cpp:106] Iteration 163600, lr = 2.81475e-06
I0506 04:56:23.978351 12834 solver.cpp:242] Iteration 163600 (102.511 iter/s, 0.975501s/100 iter), loss = 0.407702
I0506 04:56:23.978382 12834 solver.cpp:261]     Train net output #0: loss = 0.407702 (* 1 = 0.407702 loss)
I0506 04:56:23.978394 12834 sgd_solver.cpp:106] Iteration 163600, lr = 2.81475e-06
I0506 04:56:25.008466 12834 solver.cpp:242] Iteration 163700 (96.5894 iter/s, 1.03531s/100 iter), loss = 0.667523
I0506 04:56:25.008514 12834 solver.cpp:261]     Train net output #0: loss = 0.667523 (* 1 = 0.667523 loss)
I0506 04:56:25.008527 12834 sgd_solver.cpp:106] Iteration 163700, lr = 2.81475e-06
I0506 04:56:25.013744 12834 solver.cpp:242] Iteration 163700 (96.5864 iter/s, 1.03534s/100 iter), loss = 0.856107
I0506 04:56:25.013775 12834 solver.cpp:261]     Train net output #0: loss = 0.856107 (* 1 = 0.856107 loss)
I0506 04:56:25.013787 12834 sgd_solver.cpp:106] Iteration 163700, lr = 2.81475e-06
I0506 04:56:25.978274 12834 solver.cpp:242] Iteration 163800 (103.122 iter/s, 0.969728s/100 iter), loss = 1.74681
I0506 04:56:25.978317 12834 solver.cpp:261]     Train net output #0: loss = 1.74681 (* 1 = 1.74681 loss)
I0506 04:56:25.978327 12834 sgd_solver.cpp:106] Iteration 163800, lr = 2.81475e-06
I0506 04:56:25.983062 12834 solver.cpp:242] Iteration 163800 (103.171 iter/s, 0.969269s/100 iter), loss = 0.510562
I0506 04:56:25.983088 12834 solver.cpp:261]     Train net output #0: loss = 0.510562 (* 1 = 0.510562 loss)
I0506 04:56:25.983098 12834 sgd_solver.cpp:106] Iteration 163800, lr = 2.81475e-06
I0506 04:56:26.915804 12834 solver.cpp:242] Iteration 163900 (106.671 iter/s, 0.937464s/100 iter), loss = 0.8972
I0506 04:56:26.915854 12834 solver.cpp:261]     Train net output #0: loss = 0.8972 (* 1 = 0.8972 loss)
I0506 04:56:26.915994 12834 sgd_solver.cpp:106] Iteration 163900, lr = 2.81475e-06
I0506 04:56:26.920892 12834 solver.cpp:242] Iteration 163900 (106.636 iter/s, 0.937773s/100 iter), loss = 0.80997
I0506 04:56:26.920919 12834 solver.cpp:261]     Train net output #0: loss = 0.80997 (* 1 = 0.80997 loss)
I0506 04:56:26.920928 12834 sgd_solver.cpp:106] Iteration 163900, lr = 2.81475e-06
I0506 04:56:27.851444 12834 solver.cpp:362] Iteration 164000, Testing net (#0)
I0506 04:56:27.851472 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:27.974195 12834 solver.cpp:429]     Test net output #0: loss = 1.187 (* 1 = 1.187 loss)
I0506 04:56:27.976719 12834 solver.cpp:242] Iteration 164000 (94.2642 iter/s, 1.06085s/100 iter), loss = 1.22455
I0506 04:56:27.976742 12834 solver.cpp:261]     Train net output #0: loss = 1.22455 (* 1 = 1.22455 loss)
I0506 04:56:27.976752 12834 sgd_solver.cpp:106] Iteration 164000, lr = 2.81475e-06
I0506 04:56:27.978565 12834 solver.cpp:362] Iteration 164000, Testing net (#0)
I0506 04:56:27.978579 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:28.107100 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7805
I0506 04:56:28.107121 12834 solver.cpp:429]     Test net output #1: loss = 0.497072 (* 1 = 0.497072 loss)
I0506 04:56:28.109678 12834 solver.cpp:242] Iteration 164000 (84.1229 iter/s, 1.18874s/100 iter), loss = 0.58593
I0506 04:56:28.109700 12834 solver.cpp:261]     Train net output #0: loss = 0.58593 (* 1 = 0.58593 loss)
I0506 04:56:28.109709 12834 sgd_solver.cpp:106] Iteration 164000, lr = 2.81475e-06
I0506 04:56:29.042486 12834 solver.cpp:242] Iteration 164100 (93.8335 iter/s, 1.06572s/100 iter), loss = 0.177804
I0506 04:56:29.042529 12834 solver.cpp:261]     Train net output #0: loss = 0.177804 (* 1 = 0.177804 loss)
I0506 04:56:29.042539 12834 sgd_solver.cpp:106] Iteration 164100, lr = 2.81475e-06
I0506 04:56:29.047338 12834 solver.cpp:242] Iteration 164100 (106.654 iter/s, 0.937609s/100 iter), loss = 0.592795
I0506 04:56:29.047374 12834 solver.cpp:261]     Train net output #0: loss = 0.592795 (* 1 = 0.592795 loss)
I0506 04:56:29.047384 12834 sgd_solver.cpp:106] Iteration 164100, lr = 2.81475e-06
I0506 04:56:29.980690 12834 solver.cpp:242] Iteration 164200 (106.595 iter/s, 0.938134s/100 iter), loss = 3.79749
I0506 04:56:29.980729 12834 solver.cpp:261]     Train net output #0: loss = 3.79749 (* 1 = 3.79749 loss)
I0506 04:56:29.980738 12834 sgd_solver.cpp:106] Iteration 164200, lr = 2.81475e-06
I0506 04:56:29.985465 12834 solver.cpp:242] Iteration 164200 (106.602 iter/s, 0.938073s/100 iter), loss = 0.585524
I0506 04:56:29.985491 12834 solver.cpp:261]     Train net output #0: loss = 0.585524 (* 1 = 0.585524 loss)
I0506 04:56:29.985501 12834 sgd_solver.cpp:106] Iteration 164200, lr = 2.81475e-06
I0506 04:56:30.953593 12834 solver.cpp:242] Iteration 164300 (102.793 iter/s, 0.972828s/100 iter), loss = 0.66074
I0506 04:56:30.953634 12834 solver.cpp:261]     Train net output #0: loss = 0.66074 (* 1 = 0.66074 loss)
I0506 04:56:30.953646 12834 sgd_solver.cpp:106] Iteration 164300, lr = 2.81475e-06
I0506 04:56:30.958881 12834 solver.cpp:242] Iteration 164300 (102.736 iter/s, 0.97337s/100 iter), loss = 0.363933
I0506 04:56:30.958911 12834 solver.cpp:261]     Train net output #0: loss = 0.363933 (* 1 = 0.363933 loss)
I0506 04:56:30.958922 12834 sgd_solver.cpp:106] Iteration 164300, lr = 2.81475e-06
I0506 04:56:31.989471 12834 solver.cpp:242] Iteration 164400 (96.543 iter/s, 1.03581s/100 iter), loss = 1.39044
I0506 04:56:31.989519 12834 solver.cpp:261]     Train net output #0: loss = 1.39044 (* 1 = 1.39044 loss)
I0506 04:56:31.989590 12834 sgd_solver.cpp:106] Iteration 164400, lr = 2.81475e-06
I0506 04:56:31.994391 12834 solver.cpp:242] Iteration 164400 (96.5754 iter/s, 1.03546s/100 iter), loss = 0.481728
I0506 04:56:31.994417 12834 solver.cpp:261]     Train net output #0: loss = 0.481728 (* 1 = 0.481728 loss)
I0506 04:56:31.994426 12834 sgd_solver.cpp:106] Iteration 164400, lr = 2.81475e-06
I0506 04:56:32.924875 12834 solver.cpp:362] Iteration 164500, Testing net (#0)
I0506 04:56:32.924901 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:33.047787 12834 solver.cpp:429]     Test net output #0: loss = 1.17797 (* 1 = 1.17797 loss)
I0506 04:56:33.050299 12834 solver.cpp:242] Iteration 164500 (94.2717 iter/s, 1.06076s/100 iter), loss = 1.18052
I0506 04:56:33.050320 12834 solver.cpp:261]     Train net output #0: loss = 1.18052 (* 1 = 1.18052 loss)
I0506 04:56:33.050328 12834 sgd_solver.cpp:106] Iteration 164500, lr = 2.81475e-06
I0506 04:56:33.052165 12834 solver.cpp:362] Iteration 164500, Testing net (#0)
I0506 04:56:33.052181 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:33.181079 12834 solver.cpp:429]     Test net output #0: accuracy = 0.776
I0506 04:56:33.181100 12834 solver.cpp:429]     Test net output #1: loss = 0.501784 (* 1 = 0.501784 loss)
I0506 04:56:33.183655 12834 solver.cpp:242] Iteration 164500 (84.089 iter/s, 1.18922s/100 iter), loss = 0.485201
I0506 04:56:33.183675 12834 solver.cpp:261]     Train net output #0: loss = 0.485201 (* 1 = 0.485201 loss)
I0506 04:56:33.183683 12834 sgd_solver.cpp:106] Iteration 164500, lr = 2.81475e-06
I0506 04:56:34.116276 12834 solver.cpp:242] Iteration 164600 (93.815 iter/s, 1.06593s/100 iter), loss = 1.32472
I0506 04:56:34.116312 12834 solver.cpp:261]     Train net output #0: loss = 1.32472 (* 1 = 1.32472 loss)
I0506 04:56:34.116322 12834 sgd_solver.cpp:106] Iteration 164600, lr = 2.81475e-06
I0506 04:56:34.121055 12834 solver.cpp:242] Iteration 164600 (106.682 iter/s, 0.937362s/100 iter), loss = 0.382769
I0506 04:56:34.121079 12834 solver.cpp:261]     Train net output #0: loss = 0.382769 (* 1 = 0.382769 loss)
I0506 04:56:34.121088 12834 sgd_solver.cpp:106] Iteration 164600, lr = 2.81475e-06
I0506 04:56:35.053555 12834 solver.cpp:242] Iteration 164700 (106.699 iter/s, 0.937213s/100 iter), loss = 0.574826
I0506 04:56:35.053588 12834 solver.cpp:261]     Train net output #0: loss = 0.574826 (* 1 = 0.574826 loss)
I0506 04:56:35.053609 12834 sgd_solver.cpp:106] Iteration 164700, lr = 2.81475e-06
I0506 04:56:35.058338 12834 solver.cpp:242] Iteration 164700 (106.696 iter/s, 0.937241s/100 iter), loss = 0.457363
I0506 04:56:35.058363 12834 solver.cpp:261]     Train net output #0: loss = 0.457363 (* 1 = 0.457363 loss)
I0506 04:56:35.058372 12834 sgd_solver.cpp:106] Iteration 164700, lr = 2.81475e-06
I0506 04:56:35.991214 12834 solver.cpp:242] Iteration 164800 (106.655 iter/s, 0.937602s/100 iter), loss = 0.561855
I0506 04:56:35.991242 12834 solver.cpp:261]     Train net output #0: loss = 0.561855 (* 1 = 0.561855 loss)
I0506 04:56:35.991251 12834 sgd_solver.cpp:106] Iteration 164800, lr = 2.81475e-06
I0506 04:56:35.995997 12834 solver.cpp:242] Iteration 164800 (106.653 iter/s, 0.937616s/100 iter), loss = 0.628573
I0506 04:56:35.996021 12834 solver.cpp:261]     Train net output #0: loss = 0.628573 (* 1 = 0.628573 loss)
I0506 04:56:35.996031 12834 sgd_solver.cpp:106] Iteration 164800, lr = 2.81475e-06
I0506 04:56:36.965137 12834 solver.cpp:242] Iteration 164900 (102.684 iter/s, 0.973861s/100 iter), loss = 3.43813
I0506 04:56:36.965185 12834 solver.cpp:261]     Train net output #0: loss = 3.43813 (* 1 = 3.43813 loss)
I0506 04:56:36.965196 12834 sgd_solver.cpp:106] Iteration 164900, lr = 2.81475e-06
I0506 04:56:36.970417 12834 solver.cpp:242] Iteration 164900 (102.63 iter/s, 0.974375s/100 iter), loss = 0.588342
I0506 04:56:36.970448 12834 solver.cpp:261]     Train net output #0: loss = 0.588342 (* 1 = 0.588342 loss)
I0506 04:56:36.970458 12834 sgd_solver.cpp:106] Iteration 164900, lr = 2.81475e-06
I0506 04:56:37.904490 12834 solver.cpp:362] Iteration 165000, Testing net (#0)
I0506 04:56:37.904518 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:38.027191 12834 solver.cpp:429]     Test net output #0: loss = 1.02867 (* 1 = 1.02867 loss)
I0506 04:56:38.029707 12834 solver.cpp:242] Iteration 165000 (93.9405 iter/s, 1.0645s/100 iter), loss = 1.3291
I0506 04:56:38.029728 12834 solver.cpp:261]     Train net output #0: loss = 1.3291 (* 1 = 1.3291 loss)
I0506 04:56:38.029736 12834 sgd_solver.cpp:106] Iteration 165000, lr = 2.81475e-06
I0506 04:56:38.031628 12834 solver.cpp:362] Iteration 165000, Testing net (#0)
I0506 04:56:38.031642 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:38.160419 12834 solver.cpp:429]     Test net output #0: accuracy = 0.788
I0506 04:56:38.160439 12834 solver.cpp:429]     Test net output #1: loss = 0.497546 (* 1 = 0.497546 loss)
I0506 04:56:38.163019 12834 solver.cpp:242] Iteration 165000 (83.8539 iter/s, 1.19255s/100 iter), loss = 0.633592
I0506 04:56:38.163039 12834 solver.cpp:261]     Train net output #0: loss = 0.633592 (* 1 = 0.633592 loss)
I0506 04:56:38.163048 12834 sgd_solver.cpp:106] Iteration 165000, lr = 2.81475e-06
I0506 04:56:39.096057 12834 solver.cpp:242] Iteration 165100 (93.7822 iter/s, 1.0663s/100 iter), loss = 0.393547
I0506 04:56:39.096091 12834 solver.cpp:261]     Train net output #0: loss = 0.393547 (* 1 = 0.393547 loss)
I0506 04:56:39.096099 12834 sgd_solver.cpp:106] Iteration 165100, lr = 2.81475e-06
I0506 04:56:39.100834 12834 solver.cpp:242] Iteration 165100 (106.635 iter/s, 0.937776s/100 iter), loss = 0.424033
I0506 04:56:39.100857 12834 solver.cpp:261]     Train net output #0: loss = 0.424033 (* 1 = 0.424033 loss)
I0506 04:56:39.100867 12834 sgd_solver.cpp:106] Iteration 165100, lr = 2.81475e-06
I0506 04:56:40.033836 12834 solver.cpp:242] Iteration 165200 (106.642 iter/s, 0.937714s/100 iter), loss = 2.90152
I0506 04:56:40.033876 12834 solver.cpp:261]     Train net output #0: loss = 2.90152 (* 1 = 2.90152 loss)
I0506 04:56:40.033886 12834 sgd_solver.cpp:106] Iteration 165200, lr = 2.81475e-06
I0506 04:56:40.038601 12834 solver.cpp:242] Iteration 165200 (106.641 iter/s, 0.937725s/100 iter), loss = 0.409597
I0506 04:56:40.038625 12834 solver.cpp:261]     Train net output #0: loss = 0.409597 (* 1 = 0.409597 loss)
I0506 04:56:40.038635 12834 sgd_solver.cpp:106] Iteration 165200, lr = 2.81475e-06
I0506 04:56:40.971705 12834 solver.cpp:242] Iteration 165300 (106.632 iter/s, 0.937803s/100 iter), loss = 0.74373
I0506 04:56:40.971757 12834 solver.cpp:261]     Train net output #0: loss = 0.74373 (* 1 = 0.74373 loss)
I0506 04:56:40.971767 12834 sgd_solver.cpp:106] Iteration 165300, lr = 2.81475e-06
I0506 04:56:40.976493 12834 solver.cpp:242] Iteration 165300 (106.627 iter/s, 0.937849s/100 iter), loss = 0.641616
I0506 04:56:40.976519 12834 solver.cpp:261]     Train net output #0: loss = 0.641616 (* 1 = 0.641616 loss)
I0506 04:56:40.976528 12834 sgd_solver.cpp:106] Iteration 165300, lr = 2.81475e-06
I0506 04:56:41.909576 12834 solver.cpp:242] Iteration 165400 (106.634 iter/s, 0.937788s/100 iter), loss = 0.880347
I0506 04:56:41.909615 12834 solver.cpp:261]     Train net output #0: loss = 0.880347 (* 1 = 0.880347 loss)
I0506 04:56:41.909626 12834 sgd_solver.cpp:106] Iteration 165400, lr = 2.81475e-06
I0506 04:56:41.914342 12834 solver.cpp:242] Iteration 165400 (106.632 iter/s, 0.937806s/100 iter), loss = 0.723563
I0506 04:56:41.914368 12834 solver.cpp:261]     Train net output #0: loss = 0.723563 (* 1 = 0.723563 loss)
I0506 04:56:41.914377 12834 sgd_solver.cpp:106] Iteration 165400, lr = 2.81475e-06
I0506 04:56:42.845717 12834 solver.cpp:362] Iteration 165500, Testing net (#0)
I0506 04:56:42.845747 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:42.968228 12834 solver.cpp:429]     Test net output #0: loss = 1.37002 (* 1 = 1.37002 loss)
I0506 04:56:42.970752 12834 solver.cpp:242] Iteration 165500 (94.2402 iter/s, 1.06112s/100 iter), loss = 1.04697
I0506 04:56:42.970777 12834 solver.cpp:261]     Train net output #0: loss = 1.04697 (* 1 = 1.04697 loss)
I0506 04:56:42.970787 12834 sgd_solver.cpp:106] Iteration 165500, lr = 2.81475e-06
I0506 04:56:42.972612 12834 solver.cpp:362] Iteration 165500, Testing net (#0)
I0506 04:56:42.972627 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:43.101286 12834 solver.cpp:429]     Test net output #0: accuracy = 0.792
I0506 04:56:43.101307 12834 solver.cpp:429]     Test net output #1: loss = 0.483029 (* 1 = 0.483029 loss)
I0506 04:56:43.103853 12834 solver.cpp:242] Iteration 165500 (84.0715 iter/s, 1.18946s/100 iter), loss = 0.393515
I0506 04:56:43.103875 12834 solver.cpp:261]     Train net output #0: loss = 0.393515 (* 1 = 0.393515 loss)
I0506 04:56:43.103883 12834 sgd_solver.cpp:106] Iteration 165500, lr = 2.81475e-06
I0506 04:56:44.036718 12834 solver.cpp:242] Iteration 165600 (93.8168 iter/s, 1.06591s/100 iter), loss = 1.14421
I0506 04:56:44.036759 12834 solver.cpp:261]     Train net output #0: loss = 1.14421 (* 1 = 1.14421 loss)
I0506 04:56:44.036769 12834 sgd_solver.cpp:106] Iteration 165600, lr = 2.81475e-06
I0506 04:56:44.041492 12834 solver.cpp:242] Iteration 165600 (106.655 iter/s, 0.9376s/100 iter), loss = 0.525041
I0506 04:56:44.041517 12834 solver.cpp:261]     Train net output #0: loss = 0.525041 (* 1 = 0.525041 loss)
I0506 04:56:44.041527 12834 sgd_solver.cpp:106] Iteration 165600, lr = 2.81475e-06
I0506 04:56:44.974405 12834 solver.cpp:242] Iteration 165700 (106.653 iter/s, 0.93762s/100 iter), loss = 1.39151
I0506 04:56:44.974442 12834 solver.cpp:261]     Train net output #0: loss = 1.39151 (* 1 = 1.39151 loss)
I0506 04:56:44.974452 12834 sgd_solver.cpp:106] Iteration 165700, lr = 2.81475e-06
I0506 04:56:44.979204 12834 solver.cpp:242] Iteration 165700 (106.647 iter/s, 0.937669s/100 iter), loss = 0.763388
I0506 04:56:44.979228 12834 solver.cpp:261]     Train net output #0: loss = 0.763388 (* 1 = 0.763388 loss)
I0506 04:56:44.979238 12834 sgd_solver.cpp:106] Iteration 165700, lr = 2.81475e-06
I0506 04:56:45.912109 12834 solver.cpp:242] Iteration 165800 (106.651 iter/s, 0.937636s/100 iter), loss = 0.975302
I0506 04:56:45.912144 12834 solver.cpp:261]     Train net output #0: loss = 0.975302 (* 1 = 0.975302 loss)
I0506 04:56:45.912153 12834 sgd_solver.cpp:106] Iteration 165800, lr = 2.81475e-06
I0506 04:56:45.916885 12834 solver.cpp:242] Iteration 165800 (106.651 iter/s, 0.937638s/100 iter), loss = 0.271555
I0506 04:56:45.916909 12834 solver.cpp:261]     Train net output #0: loss = 0.271555 (* 1 = 0.271555 loss)
I0506 04:56:45.916918 12834 sgd_solver.cpp:106] Iteration 165800, lr = 2.81475e-06
I0506 04:56:46.878144 12834 solver.cpp:242] Iteration 165900 (103.522 iter/s, 0.965975s/100 iter), loss = 0.284832
I0506 04:56:46.878183 12834 solver.cpp:261]     Train net output #0: loss = 0.284832 (* 1 = 0.284832 loss)
I0506 04:56:46.878195 12834 sgd_solver.cpp:106] Iteration 165900, lr = 2.81475e-06
I0506 04:56:46.883520 12834 solver.cpp:242] Iteration 165900 (103.458 iter/s, 0.96658s/100 iter), loss = 0.502595
I0506 04:56:46.883550 12834 solver.cpp:261]     Train net output #0: loss = 0.502595 (* 1 = 0.502595 loss)
I0506 04:56:46.883561 12834 sgd_solver.cpp:106] Iteration 165900, lr = 2.81475e-06
I0506 04:56:47.897857 12834 solver.cpp:362] Iteration 166000, Testing net (#0)
I0506 04:56:47.897881 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:48.020547 12834 solver.cpp:429]     Test net output #0: loss = 1.27005 (* 1 = 1.27005 loss)
I0506 04:56:48.023061 12834 solver.cpp:242] Iteration 166000 (87.347 iter/s, 1.14486s/100 iter), loss = 1.18785
I0506 04:56:48.023082 12834 solver.cpp:261]     Train net output #0: loss = 1.18785 (* 1 = 1.18785 loss)
I0506 04:56:48.023092 12834 sgd_solver.cpp:106] Iteration 166000, lr = 2.81475e-06
I0506 04:56:48.024912 12834 solver.cpp:362] Iteration 166000, Testing net (#0)
I0506 04:56:48.024925 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:48.153558 12834 solver.cpp:429]     Test net output #0: accuracy = 0.8005
I0506 04:56:48.153578 12834 solver.cpp:429]     Test net output #1: loss = 0.484613 (* 1 = 0.484613 loss)
I0506 04:56:48.156131 12834 solver.cpp:242] Iteration 166000 (78.5817 iter/s, 1.27256s/100 iter), loss = 1.00995
I0506 04:56:48.156152 12834 solver.cpp:261]     Train net output #0: loss = 1.00995 (* 1 = 1.00995 loss)
I0506 04:56:48.156159 12834 sgd_solver.cpp:106] Iteration 166000, lr = 2.81475e-06
I0506 04:56:49.142325 12834 solver.cpp:242] Iteration 166100 (89.3491 iter/s, 1.11921s/100 iter), loss = 1.54275
I0506 04:56:49.142367 12834 solver.cpp:261]     Train net output #0: loss = 1.54275 (* 1 = 1.54275 loss)
I0506 04:56:49.142379 12834 sgd_solver.cpp:106] Iteration 166100, lr = 2.81475e-06
I0506 04:56:49.147609 12834 solver.cpp:242] Iteration 166100 (100.864 iter/s, 0.991437s/100 iter), loss = 0.528176
I0506 04:56:49.147640 12834 solver.cpp:261]     Train net output #0: loss = 0.528176 (* 1 = 0.528176 loss)
I0506 04:56:49.147651 12834 sgd_solver.cpp:106] Iteration 166100, lr = 2.81475e-06
I0506 04:56:50.131719 12834 solver.cpp:242] Iteration 166200 (101.079 iter/s, 0.989326s/100 iter), loss = 1.02519
I0506 04:56:50.131752 12834 solver.cpp:261]     Train net output #0: loss = 1.02519 (* 1 = 1.02519 loss)
I0506 04:56:50.131762 12834 sgd_solver.cpp:106] Iteration 166200, lr = 2.81475e-06
I0506 04:56:50.136497 12834 solver.cpp:242] Iteration 166200 (101.129 iter/s, 0.988838s/100 iter), loss = 0.405671
I0506 04:56:50.136520 12834 solver.cpp:261]     Train net output #0: loss = 0.405671 (* 1 = 0.405671 loss)
I0506 04:56:50.136529 12834 sgd_solver.cpp:106] Iteration 166200, lr = 2.81475e-06
I0506 04:56:51.071779 12834 solver.cpp:242] Iteration 166300 (106.384 iter/s, 0.939995s/100 iter), loss = 0.693143
I0506 04:56:51.071820 12834 solver.cpp:261]     Train net output #0: loss = 0.693143 (* 1 = 0.693143 loss)
I0506 04:56:51.071830 12834 sgd_solver.cpp:106] Iteration 166300, lr = 2.81475e-06
I0506 04:56:51.076616 12834 solver.cpp:242] Iteration 166300 (106.374 iter/s, 0.940077s/100 iter), loss = 0.726033
I0506 04:56:51.076642 12834 solver.cpp:261]     Train net output #0: loss = 0.726033 (* 1 = 0.726033 loss)
I0506 04:56:51.076650 12834 sgd_solver.cpp:106] Iteration 166300, lr = 2.81475e-06
I0506 04:56:52.008991 12834 solver.cpp:242] Iteration 166400 (106.707 iter/s, 0.937144s/100 iter), loss = 0.586602
I0506 04:56:52.009032 12834 solver.cpp:261]     Train net output #0: loss = 0.586602 (* 1 = 0.586602 loss)
I0506 04:56:52.009042 12834 sgd_solver.cpp:106] Iteration 166400, lr = 2.81475e-06
I0506 04:56:52.013777 12834 solver.cpp:242] Iteration 166400 (106.71 iter/s, 0.937117s/100 iter), loss = 0.598567
I0506 04:56:52.013810 12834 solver.cpp:261]     Train net output #0: loss = 0.598567 (* 1 = 0.598567 loss)
I0506 04:56:52.013820 12834 sgd_solver.cpp:106] Iteration 166400, lr = 2.81475e-06
I0506 04:56:52.983261 12834 solver.cpp:362] Iteration 166500, Testing net (#0)
I0506 04:56:52.983301 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:53.106293 12834 solver.cpp:429]     Test net output #0: loss = 1.28715 (* 1 = 1.28715 loss)
I0506 04:56:53.108814 12834 solver.cpp:242] Iteration 166500 (90.9287 iter/s, 1.09976s/100 iter), loss = 0.463734
I0506 04:56:53.108836 12834 solver.cpp:261]     Train net output #0: loss = 0.463734 (* 1 = 0.463734 loss)
I0506 04:56:53.108845 12834 sgd_solver.cpp:106] Iteration 166500, lr = 2.81475e-06
I0506 04:56:53.110683 12834 solver.cpp:362] Iteration 166500, Testing net (#0)
I0506 04:56:53.110698 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:53.239387 12834 solver.cpp:429]     Test net output #0: accuracy = 0.794
I0506 04:56:53.239406 12834 solver.cpp:429]     Test net output #1: loss = 0.483354 (* 1 = 0.483354 loss)
I0506 04:56:53.241956 12834 solver.cpp:242] Iteration 166500 (81.4249 iter/s, 1.22813s/100 iter), loss = 0.456746
I0506 04:56:53.241976 12834 solver.cpp:261]     Train net output #0: loss = 0.456746 (* 1 = 0.456746 loss)
I0506 04:56:53.241986 12834 sgd_solver.cpp:106] Iteration 166500, lr = 2.81475e-06
I0506 04:56:54.175422 12834 solver.cpp:242] Iteration 166600 (93.7595 iter/s, 1.06656s/100 iter), loss = 2.34887
I0506 04:56:54.175463 12834 solver.cpp:261]     Train net output #0: loss = 2.34887 (* 1 = 2.34887 loss)
I0506 04:56:54.175473 12834 sgd_solver.cpp:106] Iteration 166600, lr = 2.81475e-06
I0506 04:56:54.180203 12834 solver.cpp:242] Iteration 166600 (106.586 iter/s, 0.938208s/100 iter), loss = 0.485366
I0506 04:56:54.180229 12834 solver.cpp:261]     Train net output #0: loss = 0.485366 (* 1 = 0.485366 loss)
I0506 04:56:54.180238 12834 sgd_solver.cpp:106] Iteration 166600, lr = 2.81475e-06
I0506 04:56:55.168437 12834 solver.cpp:242] Iteration 166700 (100.711 iter/s, 0.992941s/100 iter), loss = 1.27301
I0506 04:56:55.168486 12834 solver.cpp:261]     Train net output #0: loss = 1.27301 (* 1 = 1.27301 loss)
I0506 04:56:55.168498 12834 sgd_solver.cpp:106] Iteration 166700, lr = 2.81475e-06
I0506 04:56:55.173732 12834 solver.cpp:242] Iteration 166700 (100.656 iter/s, 0.993482s/100 iter), loss = 0.788653
I0506 04:56:55.173761 12834 solver.cpp:261]     Train net output #0: loss = 0.788653 (* 1 = 0.788653 loss)
I0506 04:56:55.173774 12834 sgd_solver.cpp:106] Iteration 166700, lr = 2.81475e-06
I0506 04:56:56.203563 12834 solver.cpp:242] Iteration 166800 (96.6136 iter/s, 1.03505s/100 iter), loss = 1.11317
I0506 04:56:56.203610 12834 solver.cpp:261]     Train net output #0: loss = 1.11317 (* 1 = 1.11317 loss)
I0506 04:56:56.203622 12834 sgd_solver.cpp:106] Iteration 166800, lr = 2.81475e-06
I0506 04:56:56.208938 12834 solver.cpp:242] Iteration 166800 (96.6048 iter/s, 1.03515s/100 iter), loss = 0.475402
I0506 04:56:56.208971 12834 solver.cpp:261]     Train net output #0: loss = 0.475402 (* 1 = 0.475402 loss)
I0506 04:56:56.208982 12834 sgd_solver.cpp:106] Iteration 166800, lr = 2.81475e-06
I0506 04:56:57.190026 12834 solver.cpp:242] Iteration 166900 (101.38 iter/s, 0.986389s/100 iter), loss = 0.541703
I0506 04:56:57.190066 12834 solver.cpp:261]     Train net output #0: loss = 0.541703 (* 1 = 0.541703 loss)
I0506 04:56:57.190076 12834 sgd_solver.cpp:106] Iteration 166900, lr = 2.81475e-06
I0506 04:56:57.194811 12834 solver.cpp:242] Iteration 166900 (101.438 iter/s, 0.985822s/100 iter), loss = 0.450513
I0506 04:56:57.194838 12834 solver.cpp:261]     Train net output #0: loss = 0.450513 (* 1 = 0.450513 loss)
I0506 04:56:57.194846 12834 sgd_solver.cpp:106] Iteration 166900, lr = 2.81475e-06
I0506 04:56:58.124300 12834 solver.cpp:362] Iteration 167000, Testing net (#0)
I0506 04:56:58.124330 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:58.247035 12834 solver.cpp:429]     Test net output #0: loss = 1.01205 (* 1 = 1.01205 loss)
I0506 04:56:58.249573 12834 solver.cpp:242] Iteration 167000 (94.3851 iter/s, 1.05949s/100 iter), loss = 0.839047
I0506 04:56:58.249595 12834 solver.cpp:261]     Train net output #0: loss = 0.839047 (* 1 = 0.839047 loss)
I0506 04:56:58.249604 12834 sgd_solver.cpp:106] Iteration 167000, lr = 2.81475e-06
I0506 04:56:58.251423 12834 solver.cpp:362] Iteration 167000, Testing net (#0)
I0506 04:56:58.251437 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:56:58.380506 12834 solver.cpp:429]     Test net output #0: accuracy = 0.781
I0506 04:56:58.380529 12834 solver.cpp:429]     Test net output #1: loss = 0.489215 (* 1 = 0.489215 loss)
I0506 04:56:58.383098 12834 solver.cpp:242] Iteration 167000 (84.1581 iter/s, 1.18824s/100 iter), loss = 0.507823
I0506 04:56:58.383118 12834 solver.cpp:261]     Train net output #0: loss = 0.507823 (* 1 = 0.507823 loss)
I0506 04:56:58.383127 12834 sgd_solver.cpp:106] Iteration 167000, lr = 2.81475e-06
I0506 04:56:59.315696 12834 solver.cpp:242] Iteration 167100 (93.8023 iter/s, 1.06607s/100 iter), loss = 3.56155
I0506 04:56:59.315737 12834 solver.cpp:261]     Train net output #0: loss = 3.56155 (* 1 = 3.56155 loss)
I0506 04:56:59.315745 12834 sgd_solver.cpp:106] Iteration 167100, lr = 2.81475e-06
I0506 04:56:59.320508 12834 solver.cpp:242] Iteration 167100 (106.682 iter/s, 0.93737s/100 iter), loss = 0.326221
I0506 04:56:59.320533 12834 solver.cpp:261]     Train net output #0: loss = 0.326221 (* 1 = 0.326221 loss)
I0506 04:56:59.320541 12834 sgd_solver.cpp:106] Iteration 167100, lr = 2.81475e-06
I0506 04:57:00.256247 12834 solver.cpp:242] Iteration 167200 (106.33 iter/s, 0.940469s/100 iter), loss = 1.24926
I0506 04:57:00.256299 12834 solver.cpp:261]     Train net output #0: loss = 1.24926 (* 1 = 1.24926 loss)
I0506 04:57:00.256310 12834 sgd_solver.cpp:106] Iteration 167200, lr = 2.81475e-06
I0506 04:57:00.261198 12834 solver.cpp:242] Iteration 167200 (106.31 iter/s, 0.940643s/100 iter), loss = 0.561363
I0506 04:57:00.261241 12834 solver.cpp:261]     Train net output #0: loss = 0.561363 (* 1 = 0.561363 loss)
I0506 04:57:00.261252 12834 sgd_solver.cpp:106] Iteration 167200, lr = 2.81475e-06
I0506 04:57:01.204887 12834 solver.cpp:242] Iteration 167300 (105.423 iter/s, 0.948561s/100 iter), loss = 2.02635
I0506 04:57:01.204928 12834 solver.cpp:261]     Train net output #0: loss = 2.02635 (* 1 = 2.02635 loss)
I0506 04:57:01.204938 12834 sgd_solver.cpp:106] Iteration 167300, lr = 2.81475e-06
I0506 04:57:01.209735 12834 solver.cpp:242] Iteration 167300 (105.432 iter/s, 0.948477s/100 iter), loss = 0.498055
I0506 04:57:01.209761 12834 solver.cpp:261]     Train net output #0: loss = 0.498055 (* 1 = 0.498055 loss)
I0506 04:57:01.209771 12834 sgd_solver.cpp:106] Iteration 167300, lr = 2.81475e-06
I0506 04:57:02.145069 12834 solver.cpp:242] Iteration 167400 (106.371 iter/s, 0.94011s/100 iter), loss = 0.373138
I0506 04:57:02.145108 12834 solver.cpp:261]     Train net output #0: loss = 0.373138 (* 1 = 0.373138 loss)
I0506 04:57:02.145117 12834 sgd_solver.cpp:106] Iteration 167400, lr = 2.81475e-06
I0506 04:57:02.149832 12834 solver.cpp:242] Iteration 167400 (106.377 iter/s, 0.940051s/100 iter), loss = 0.599706
I0506 04:57:02.149855 12834 solver.cpp:261]     Train net output #0: loss = 0.599706 (* 1 = 0.599706 loss)
I0506 04:57:02.149864 12834 sgd_solver.cpp:106] Iteration 167400, lr = 2.81475e-06
I0506 04:57:03.093515 12834 solver.cpp:362] Iteration 167500, Testing net (#0)
I0506 04:57:03.093540 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:03.216289 12834 solver.cpp:429]     Test net output #0: loss = 1.17514 (* 1 = 1.17514 loss)
I0506 04:57:03.218890 12834 solver.cpp:242] Iteration 167500 (93.1305 iter/s, 1.07376s/100 iter), loss = 1.62441
I0506 04:57:03.218914 12834 solver.cpp:261]     Train net output #0: loss = 1.62441 (* 1 = 1.62441 loss)
I0506 04:57:03.218924 12834 sgd_solver.cpp:106] Iteration 167500, lr = 2.81475e-06
I0506 04:57:03.220790 12834 solver.cpp:362] Iteration 167500, Testing net (#0)
I0506 04:57:03.220804 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:03.349387 12834 solver.cpp:429]     Test net output #0: accuracy = 0.792
I0506 04:57:03.349406 12834 solver.cpp:429]     Test net output #1: loss = 0.47458 (* 1 = 0.47458 loss)
I0506 04:57:03.351965 12834 solver.cpp:242] Iteration 167500 (83.1885 iter/s, 1.20209s/100 iter), loss = 0.543218
I0506 04:57:03.351985 12834 solver.cpp:261]     Train net output #0: loss = 0.543218 (* 1 = 0.543218 loss)
I0506 04:57:03.351994 12834 sgd_solver.cpp:106] Iteration 167500, lr = 2.81475e-06
I0506 04:57:04.284721 12834 solver.cpp:242] Iteration 167600 (93.8285 iter/s, 1.06577s/100 iter), loss = 0.639764
I0506 04:57:04.284759 12834 solver.cpp:261]     Train net output #0: loss = 0.639764 (* 1 = 0.639764 loss)
I0506 04:57:04.284767 12834 sgd_solver.cpp:106] Iteration 167600, lr = 2.81475e-06
I0506 04:57:04.289479 12834 solver.cpp:242] Iteration 167600 (106.67 iter/s, 0.937475s/100 iter), loss = 0.551305
I0506 04:57:04.289505 12834 solver.cpp:261]     Train net output #0: loss = 0.551305 (* 1 = 0.551305 loss)
I0506 04:57:04.289513 12834 sgd_solver.cpp:106] Iteration 167600, lr = 2.81475e-06
I0506 04:57:05.223117 12834 solver.cpp:242] Iteration 167700 (106.572 iter/s, 0.938335s/100 iter), loss = 0.734666
I0506 04:57:05.223152 12834 solver.cpp:261]     Train net output #0: loss = 0.734666 (* 1 = 0.734666 loss)
I0506 04:57:05.223162 12834 sgd_solver.cpp:106] Iteration 167700, lr = 2.81475e-06
I0506 04:57:05.227962 12834 solver.cpp:242] Iteration 167700 (106.561 iter/s, 0.938429s/100 iter), loss = 0.576525
I0506 04:57:05.227987 12834 solver.cpp:261]     Train net output #0: loss = 0.576525 (* 1 = 0.576525 loss)
I0506 04:57:05.227995 12834 sgd_solver.cpp:106] Iteration 167700, lr = 2.81475e-06
I0506 04:57:06.160607 12834 solver.cpp:242] Iteration 167800 (106.675 iter/s, 0.937429s/100 iter), loss = 1.41123
I0506 04:57:06.160636 12834 solver.cpp:261]     Train net output #0: loss = 1.41123 (* 1 = 1.41123 loss)
I0506 04:57:06.160645 12834 sgd_solver.cpp:106] Iteration 167800, lr = 2.81475e-06
I0506 04:57:06.165369 12834 solver.cpp:242] Iteration 167800 (106.682 iter/s, 0.937364s/100 iter), loss = 0.902747
I0506 04:57:06.165392 12834 solver.cpp:261]     Train net output #0: loss = 0.902747 (* 1 = 0.902747 loss)
I0506 04:57:06.165401 12834 sgd_solver.cpp:106] Iteration 167800, lr = 2.81475e-06
I0506 04:57:07.152621 12834 solver.cpp:242] Iteration 167900 (100.811 iter/s, 0.991958s/100 iter), loss = 1.01654
I0506 04:57:07.152671 12834 solver.cpp:261]     Train net output #0: loss = 1.01654 (* 1 = 1.01654 loss)
I0506 04:57:07.152683 12834 sgd_solver.cpp:106] Iteration 167900, lr = 2.81475e-06
I0506 04:57:07.158012 12834 solver.cpp:242] Iteration 167900 (100.746 iter/s, 0.992591s/100 iter), loss = 0.616123
I0506 04:57:07.158044 12834 solver.cpp:261]     Train net output #0: loss = 0.616123 (* 1 = 0.616123 loss)
I0506 04:57:07.158056 12834 sgd_solver.cpp:106] Iteration 167900, lr = 2.81475e-06
I0506 04:57:08.184783 12834 solver.cpp:362] Iteration 168000, Testing net (#0)
I0506 04:57:08.184816 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:08.317144 12834 solver.cpp:429]     Test net output #0: loss = 1.27447 (* 1 = 1.27447 loss)
I0506 04:57:08.319725 12834 solver.cpp:242] Iteration 168000 (85.6873 iter/s, 1.16703s/100 iter), loss = 1.14063
I0506 04:57:08.319752 12834 solver.cpp:261]     Train net output #0: loss = 1.14063 (* 1 = 1.14063 loss)
I0506 04:57:08.319762 12834 sgd_solver.cpp:106] Iteration 168000, lr = 2.81475e-06
I0506 04:57:08.321610 12834 solver.cpp:362] Iteration 168000, Testing net (#0)
I0506 04:57:08.321624 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:08.450322 12834 solver.cpp:429]     Test net output #0: accuracy = 0.784
I0506 04:57:08.450341 12834 solver.cpp:429]     Test net output #1: loss = 0.497054 (* 1 = 0.497054 loss)
I0506 04:57:08.452894 12834 solver.cpp:242] Iteration 168000 (77.2302 iter/s, 1.29483s/100 iter), loss = 0.871467
I0506 04:57:08.452915 12834 solver.cpp:261]     Train net output #0: loss = 0.871467 (* 1 = 0.871467 loss)
I0506 04:57:08.452924 12834 sgd_solver.cpp:106] Iteration 168000, lr = 2.81475e-06
I0506 04:57:09.385566 12834 solver.cpp:242] Iteration 168100 (93.8279 iter/s, 1.06578s/100 iter), loss = 0.848586
I0506 04:57:09.385598 12834 solver.cpp:261]     Train net output #0: loss = 0.848586 (* 1 = 0.848586 loss)
I0506 04:57:09.385607 12834 sgd_solver.cpp:106] Iteration 168100, lr = 2.81475e-06
I0506 04:57:09.390328 12834 solver.cpp:242] Iteration 168100 (106.679 iter/s, 0.937395s/100 iter), loss = 0.635504
I0506 04:57:09.390352 12834 solver.cpp:261]     Train net output #0: loss = 0.635504 (* 1 = 0.635504 loss)
I0506 04:57:09.390360 12834 sgd_solver.cpp:106] Iteration 168100, lr = 2.81475e-06
I0506 04:57:10.323189 12834 solver.cpp:242] Iteration 168200 (106.659 iter/s, 0.937564s/100 iter), loss = 0.995647
I0506 04:57:10.323230 12834 solver.cpp:261]     Train net output #0: loss = 0.995647 (* 1 = 0.995647 loss)
I0506 04:57:10.323240 12834 sgd_solver.cpp:106] Iteration 168200, lr = 2.81475e-06
I0506 04:57:10.327970 12834 solver.cpp:242] Iteration 168200 (106.655 iter/s, 0.9376s/100 iter), loss = 0.398778
I0506 04:57:10.327996 12834 solver.cpp:261]     Train net output #0: loss = 0.398778 (* 1 = 0.398778 loss)
I0506 04:57:10.328004 12834 sgd_solver.cpp:106] Iteration 168200, lr = 2.81475e-06
I0506 04:57:11.260519 12834 solver.cpp:242] Iteration 168300 (106.694 iter/s, 0.937258s/100 iter), loss = 0.484371
I0506 04:57:11.260563 12834 solver.cpp:261]     Train net output #0: loss = 0.484371 (* 1 = 0.484371 loss)
I0506 04:57:11.260573 12834 sgd_solver.cpp:106] Iteration 168300, lr = 2.81475e-06
I0506 04:57:11.265305 12834 solver.cpp:242] Iteration 168300 (106.691 iter/s, 0.93729s/100 iter), loss = 0.352582
I0506 04:57:11.265331 12834 solver.cpp:261]     Train net output #0: loss = 0.352582 (* 1 = 0.352582 loss)
I0506 04:57:11.265339 12834 sgd_solver.cpp:106] Iteration 168300, lr = 2.81475e-06
I0506 04:57:12.263372 12834 solver.cpp:242] Iteration 168400 (99.7228 iter/s, 1.00278s/100 iter), loss = 0.268794
I0506 04:57:12.263422 12834 solver.cpp:261]     Train net output #0: loss = 0.268794 (* 1 = 0.268794 loss)
I0506 04:57:12.263432 12834 sgd_solver.cpp:106] Iteration 168400, lr = 2.81475e-06
I0506 04:57:12.268666 12834 solver.cpp:242] Iteration 168400 (99.6696 iter/s, 1.00332s/100 iter), loss = 0.505232
I0506 04:57:12.268698 12834 solver.cpp:261]     Train net output #0: loss = 0.505232 (* 1 = 0.505232 loss)
I0506 04:57:12.268710 12834 sgd_solver.cpp:106] Iteration 168400, lr = 2.81475e-06
I0506 04:57:13.296473 12834 solver.cpp:362] Iteration 168500, Testing net (#0)
I0506 04:57:13.296504 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:13.425938 12834 solver.cpp:429]     Test net output #0: loss = 1.17199 (* 1 = 1.17199 loss)
I0506 04:57:13.428467 12834 solver.cpp:242] Iteration 168500 (85.835 iter/s, 1.16503s/100 iter), loss = 0.761341
I0506 04:57:13.428488 12834 solver.cpp:261]     Train net output #0: loss = 0.761341 (* 1 = 0.761341 loss)
I0506 04:57:13.428495 12834 sgd_solver.cpp:106] Iteration 168500, lr = 2.81475e-06
I0506 04:57:13.430330 12834 solver.cpp:362] Iteration 168500, Testing net (#0)
I0506 04:57:13.430346 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:13.558928 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7805
I0506 04:57:13.558949 12834 solver.cpp:429]     Test net output #1: loss = 0.511943 (* 1 = 0.511943 loss)
I0506 04:57:13.561497 12834 solver.cpp:242] Iteration 168500 (77.3528 iter/s, 1.29278s/100 iter), loss = 0.79078
I0506 04:57:13.561518 12834 solver.cpp:261]     Train net output #0: loss = 0.79078 (* 1 = 0.79078 loss)
I0506 04:57:13.561527 12834 sgd_solver.cpp:106] Iteration 168500, lr = 2.81475e-06
I0506 04:57:14.494904 12834 solver.cpp:242] Iteration 168600 (93.7745 iter/s, 1.06639s/100 iter), loss = 1.55536
I0506 04:57:14.494943 12834 solver.cpp:261]     Train net output #0: loss = 1.55536 (* 1 = 1.55536 loss)
I0506 04:57:14.494953 12834 sgd_solver.cpp:106] Iteration 168600, lr = 2.81475e-06
I0506 04:57:14.499785 12834 solver.cpp:242] Iteration 168600 (106.583 iter/s, 0.938238s/100 iter), loss = 0.62689
I0506 04:57:14.499820 12834 solver.cpp:261]     Train net output #0: loss = 0.62689 (* 1 = 0.62689 loss)
I0506 04:57:14.499830 12834 sgd_solver.cpp:106] Iteration 168600, lr = 2.81475e-06
I0506 04:57:15.432695 12834 solver.cpp:242] Iteration 168700 (106.641 iter/s, 0.937725s/100 iter), loss = 2.04607
I0506 04:57:15.432735 12834 solver.cpp:261]     Train net output #0: loss = 2.04607 (* 1 = 2.04607 loss)
I0506 04:57:15.432745 12834 sgd_solver.cpp:106] Iteration 168700, lr = 2.81475e-06
I0506 04:57:15.437465 12834 solver.cpp:242] Iteration 168700 (106.652 iter/s, 0.937628s/100 iter), loss = 0.638916
I0506 04:57:15.437492 12834 solver.cpp:261]     Train net output #0: loss = 0.638916 (* 1 = 0.638916 loss)
I0506 04:57:15.437501 12834 sgd_solver.cpp:106] Iteration 168700, lr = 2.81475e-06
I0506 04:57:16.371134 12834 solver.cpp:242] Iteration 168800 (106.567 iter/s, 0.938373s/100 iter), loss = 0.689502
I0506 04:57:16.371176 12834 solver.cpp:261]     Train net output #0: loss = 0.689502 (* 1 = 0.689502 loss)
I0506 04:57:16.371184 12834 sgd_solver.cpp:106] Iteration 168800, lr = 2.81475e-06
I0506 04:57:16.376015 12834 solver.cpp:242] Iteration 168800 (106.553 iter/s, 0.938497s/100 iter), loss = 0.109044
I0506 04:57:16.376042 12834 solver.cpp:261]     Train net output #0: loss = 0.109044 (* 1 = 0.109044 loss)
I0506 04:57:16.376050 12834 sgd_solver.cpp:106] Iteration 168800, lr = 2.81475e-06
I0506 04:57:17.309547 12834 solver.cpp:242] Iteration 168900 (106.571 iter/s, 0.938343s/100 iter), loss = 1.09294
I0506 04:57:17.309587 12834 solver.cpp:261]     Train net output #0: loss = 1.09294 (* 1 = 1.09294 loss)
I0506 04:57:17.309595 12834 sgd_solver.cpp:106] Iteration 168900, lr = 2.81475e-06
I0506 04:57:17.314308 12834 solver.cpp:242] Iteration 168900 (106.582 iter/s, 0.938248s/100 iter), loss = 0.668357
I0506 04:57:17.314337 12834 solver.cpp:261]     Train net output #0: loss = 0.668357 (* 1 = 0.668357 loss)
I0506 04:57:17.314345 12834 sgd_solver.cpp:106] Iteration 168900, lr = 2.81475e-06
I0506 04:57:18.244616 12834 solver.cpp:362] Iteration 169000, Testing net (#0)
I0506 04:57:18.244640 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:18.367344 12834 solver.cpp:429]     Test net output #0: loss = 1.22021 (* 1 = 1.22021 loss)
I0506 04:57:18.369866 12834 solver.cpp:242] Iteration 169000 (94.3164 iter/s, 1.06026s/100 iter), loss = 0.389652
I0506 04:57:18.369887 12834 solver.cpp:261]     Train net output #0: loss = 0.389652 (* 1 = 0.389652 loss)
I0506 04:57:18.369896 12834 sgd_solver.cpp:106] Iteration 169000, lr = 2.81475e-06
I0506 04:57:18.371716 12834 solver.cpp:362] Iteration 169000, Testing net (#0)
I0506 04:57:18.371731 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:18.500422 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7765
I0506 04:57:18.500447 12834 solver.cpp:429]     Test net output #1: loss = 0.533511 (* 1 = 0.533511 loss)
I0506 04:57:18.504187 12834 solver.cpp:242] Iteration 169000 (84.0462 iter/s, 1.18982s/100 iter), loss = 0.279971
I0506 04:57:18.504252 12834 solver.cpp:261]     Train net output #0: loss = 0.279971 (* 1 = 0.279971 loss)
I0506 04:57:18.504278 12834 sgd_solver.cpp:106] Iteration 169000, lr = 2.81475e-06
I0506 04:57:19.484575 12834 solver.cpp:242] Iteration 169100 (89.7138 iter/s, 1.11466s/100 iter), loss = 1.10642
I0506 04:57:19.484614 12834 solver.cpp:261]     Train net output #0: loss = 1.10642 (* 1 = 1.10642 loss)
I0506 04:57:19.484624 12834 sgd_solver.cpp:106] Iteration 169100, lr = 2.81475e-06
I0506 04:57:19.489426 12834 solver.cpp:242] Iteration 169100 (101.506 iter/s, 0.985162s/100 iter), loss = 0.520987
I0506 04:57:19.489454 12834 solver.cpp:261]     Train net output #0: loss = 0.520987 (* 1 = 0.520987 loss)
I0506 04:57:19.489462 12834 sgd_solver.cpp:106] Iteration 169100, lr = 2.81475e-06
I0506 04:57:20.422184 12834 solver.cpp:242] Iteration 169200 (106.662 iter/s, 0.937539s/100 iter), loss = 0.492984
I0506 04:57:20.422221 12834 solver.cpp:261]     Train net output #0: loss = 0.492984 (* 1 = 0.492984 loss)
I0506 04:57:20.422231 12834 sgd_solver.cpp:106] Iteration 169200, lr = 2.81475e-06
I0506 04:57:20.426956 12834 solver.cpp:242] Iteration 169200 (106.668 iter/s, 0.937485s/100 iter), loss = 0.414769
I0506 04:57:20.426982 12834 solver.cpp:261]     Train net output #0: loss = 0.414769 (* 1 = 0.414769 loss)
I0506 04:57:20.426991 12834 sgd_solver.cpp:106] Iteration 169200, lr = 2.81475e-06
I0506 04:57:21.359176 12834 solver.cpp:242] Iteration 169300 (106.732 iter/s, 0.93693s/100 iter), loss = 1.43666
I0506 04:57:21.359212 12834 solver.cpp:261]     Train net output #0: loss = 1.43666 (* 1 = 1.43666 loss)
I0506 04:57:21.359221 12834 sgd_solver.cpp:106] Iteration 169300, lr = 2.81475e-06
I0506 04:57:21.363973 12834 solver.cpp:242] Iteration 169300 (106.727 iter/s, 0.936973s/100 iter), loss = 0.61874
I0506 04:57:21.363998 12834 solver.cpp:261]     Train net output #0: loss = 0.61874 (* 1 = 0.61874 loss)
I0506 04:57:21.364008 12834 sgd_solver.cpp:106] Iteration 169300, lr = 2.81475e-06
I0506 04:57:22.296586 12834 solver.cpp:242] Iteration 169400 (106.684 iter/s, 0.937346s/100 iter), loss = 1.78537
I0506 04:57:22.296614 12834 solver.cpp:261]     Train net output #0: loss = 1.78537 (* 1 = 1.78537 loss)
I0506 04:57:22.296623 12834 sgd_solver.cpp:106] Iteration 169400, lr = 2.81475e-06
I0506 04:57:22.301337 12834 solver.cpp:242] Iteration 169400 (106.687 iter/s, 0.93732s/100 iter), loss = 0.863569
I0506 04:57:22.301363 12834 solver.cpp:261]     Train net output #0: loss = 0.863569 (* 1 = 0.863569 loss)
I0506 04:57:22.301373 12834 sgd_solver.cpp:106] Iteration 169400, lr = 2.81475e-06
I0506 04:57:23.231277 12834 solver.cpp:362] Iteration 169500, Testing net (#0)
I0506 04:57:23.231305 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:23.353945 12834 solver.cpp:429]     Test net output #0: loss = 1.24426 (* 1 = 1.24426 loss)
I0506 04:57:23.356474 12834 solver.cpp:242] Iteration 169500 (94.3538 iter/s, 1.05984s/100 iter), loss = 1.86289
I0506 04:57:23.356495 12834 solver.cpp:261]     Train net output #0: loss = 1.86289 (* 1 = 1.86289 loss)
I0506 04:57:23.356504 12834 sgd_solver.cpp:106] Iteration 169500, lr = 2.81475e-06
I0506 04:57:23.358409 12834 solver.cpp:362] Iteration 169500, Testing net (#0)
I0506 04:57:23.358424 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:23.487421 12834 solver.cpp:429]     Test net output #0: accuracy = 0.791
I0506 04:57:23.487440 12834 solver.cpp:429]     Test net output #1: loss = 0.506327 (* 1 = 0.506327 loss)
I0506 04:57:23.489990 12834 solver.cpp:242] Iteration 169500 (84.1321 iter/s, 1.18861s/100 iter), loss = 0.595892
I0506 04:57:23.490011 12834 solver.cpp:261]     Train net output #0: loss = 0.595892 (* 1 = 0.595892 loss)
I0506 04:57:23.490020 12834 sgd_solver.cpp:106] Iteration 169500, lr = 2.81475e-06
I0506 04:57:24.423030 12834 solver.cpp:242] Iteration 169600 (93.7644 iter/s, 1.0665s/100 iter), loss = 1.94356
I0506 04:57:24.423074 12834 solver.cpp:261]     Train net output #0: loss = 1.94356 (* 1 = 1.94356 loss)
I0506 04:57:24.423084 12834 sgd_solver.cpp:106] Iteration 169600, lr = 2.81475e-06
I0506 04:57:24.427821 12834 solver.cpp:242] Iteration 169600 (106.633 iter/s, 0.937792s/100 iter), loss = 0.729808
I0506 04:57:24.427847 12834 solver.cpp:261]     Train net output #0: loss = 0.729808 (* 1 = 0.729808 loss)
I0506 04:57:24.427856 12834 sgd_solver.cpp:106] Iteration 169600, lr = 2.81475e-06
I0506 04:57:25.360796 12834 solver.cpp:242] Iteration 169700 (106.644 iter/s, 0.937698s/100 iter), loss = 0.173192
I0506 04:57:25.360839 12834 solver.cpp:261]     Train net output #0: loss = 0.173192 (* 1 = 0.173192 loss)
I0506 04:57:25.360849 12834 sgd_solver.cpp:106] Iteration 169700, lr = 2.81475e-06
I0506 04:57:25.365648 12834 solver.cpp:242] Iteration 169700 (106.636 iter/s, 0.937773s/100 iter), loss = 0.550453
I0506 04:57:25.365674 12834 solver.cpp:261]     Train net output #0: loss = 0.550453 (* 1 = 0.550453 loss)
I0506 04:57:25.365684 12834 sgd_solver.cpp:106] Iteration 169700, lr = 2.81475e-06
I0506 04:57:26.298575 12834 solver.cpp:242] Iteration 169800 (106.643 iter/s, 0.937709s/100 iter), loss = 0.743183
I0506 04:57:26.298625 12834 solver.cpp:261]     Train net output #0: loss = 0.743183 (* 1 = 0.743183 loss)
I0506 04:57:26.298635 12834 sgd_solver.cpp:106] Iteration 169800, lr = 2.81475e-06
I0506 04:57:26.303375 12834 solver.cpp:242] Iteration 169800 (106.646 iter/s, 0.937683s/100 iter), loss = 0.634349
I0506 04:57:26.303400 12834 solver.cpp:261]     Train net output #0: loss = 0.634349 (* 1 = 0.634349 loss)
I0506 04:57:26.303408 12834 sgd_solver.cpp:106] Iteration 169800, lr = 2.81475e-06
I0506 04:57:27.235760 12834 solver.cpp:242] Iteration 169900 (106.712 iter/s, 0.937101s/100 iter), loss = 0.496446
I0506 04:57:27.235801 12834 solver.cpp:261]     Train net output #0: loss = 0.496446 (* 1 = 0.496446 loss)
I0506 04:57:27.235810 12834 sgd_solver.cpp:106] Iteration 169900, lr = 2.81475e-06
I0506 04:57:27.240618 12834 solver.cpp:242] Iteration 169900 (106.701 iter/s, 0.9372s/100 iter), loss = 0.418641
I0506 04:57:27.240644 12834 solver.cpp:261]     Train net output #0: loss = 0.418641 (* 1 = 0.418641 loss)
I0506 04:57:27.240653 12834 sgd_solver.cpp:106] Iteration 169900, lr = 2.81475e-06
I0506 04:57:28.170557 12834 solver.cpp:362] Iteration 170000, Testing net (#0)
I0506 04:57:28.170584 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:28.293229 12834 solver.cpp:429]     Test net output #0: loss = 1.21086 (* 1 = 1.21086 loss)
I0506 04:57:28.295750 12834 solver.cpp:242] Iteration 170000 (94.3457 iter/s, 1.05993s/100 iter), loss = 0.695713
I0506 04:57:28.295773 12834 solver.cpp:261]     Train net output #0: loss = 0.695713 (* 1 = 0.695713 loss)
I0506 04:57:28.295783 12834 sgd_solver.cpp:106] Iteration 170000, lr = 2.2518e-06
I0506 04:57:28.297607 12834 solver.cpp:362] Iteration 170000, Testing net (#0)
I0506 04:57:28.297621 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:28.426288 12834 solver.cpp:429]     Test net output #0: accuracy = 0.786
I0506 04:57:28.426307 12834 solver.cpp:429]     Test net output #1: loss = 0.498993 (* 1 = 0.498993 loss)
I0506 04:57:28.428850 12834 solver.cpp:242] Iteration 170000 (84.162 iter/s, 1.18819s/100 iter), loss = 0.214209
I0506 04:57:28.428871 12834 solver.cpp:261]     Train net output #0: loss = 0.214209 (* 1 = 0.214209 loss)
I0506 04:57:28.428880 12834 sgd_solver.cpp:106] Iteration 170000, lr = 2.2518e-06
I0506 04:57:29.361485 12834 solver.cpp:242] Iteration 170100 (93.8371 iter/s, 1.06568s/100 iter), loss = 2.29055
I0506 04:57:29.361524 12834 solver.cpp:261]     Train net output #0: loss = 2.29055 (* 1 = 2.29055 loss)
I0506 04:57:29.361533 12834 sgd_solver.cpp:106] Iteration 170100, lr = 2.2518e-06
I0506 04:57:29.366264 12834 solver.cpp:242] Iteration 170100 (106.681 iter/s, 0.937376s/100 iter), loss = 0.633092
I0506 04:57:29.366291 12834 solver.cpp:261]     Train net output #0: loss = 0.633092 (* 1 = 0.633092 loss)
I0506 04:57:29.366299 12834 sgd_solver.cpp:106] Iteration 170100, lr = 2.2518e-06
I0506 04:57:30.298708 12834 solver.cpp:242] Iteration 170200 (106.705 iter/s, 0.937159s/100 iter), loss = 1.49238
I0506 04:57:30.298746 12834 solver.cpp:261]     Train net output #0: loss = 1.49238 (* 1 = 1.49238 loss)
I0506 04:57:30.298755 12834 sgd_solver.cpp:106] Iteration 170200, lr = 2.2518e-06
I0506 04:57:30.303457 12834 solver.cpp:242] Iteration 170200 (106.706 iter/s, 0.93715s/100 iter), loss = 0.52335
I0506 04:57:30.303483 12834 solver.cpp:261]     Train net output #0: loss = 0.52335 (* 1 = 0.52335 loss)
I0506 04:57:30.303493 12834 sgd_solver.cpp:106] Iteration 170200, lr = 2.2518e-06
I0506 04:57:31.235947 12834 solver.cpp:242] Iteration 170300 (106.704 iter/s, 0.937171s/100 iter), loss = 0.620066
I0506 04:57:31.235985 12834 solver.cpp:261]     Train net output #0: loss = 0.620066 (* 1 = 0.620066 loss)
I0506 04:57:31.235994 12834 sgd_solver.cpp:106] Iteration 170300, lr = 2.2518e-06
I0506 04:57:31.240728 12834 solver.cpp:242] Iteration 170300 (106.698 iter/s, 0.937226s/100 iter), loss = 0.702185
I0506 04:57:31.240753 12834 solver.cpp:261]     Train net output #0: loss = 0.702185 (* 1 = 0.702185 loss)
I0506 04:57:31.240762 12834 sgd_solver.cpp:106] Iteration 170300, lr = 2.2518e-06
I0506 04:57:32.173106 12834 solver.cpp:242] Iteration 170400 (106.712 iter/s, 0.937099s/100 iter), loss = 1.58238
I0506 04:57:32.173142 12834 solver.cpp:261]     Train net output #0: loss = 1.58238 (* 1 = 1.58238 loss)
I0506 04:57:32.173151 12834 sgd_solver.cpp:106] Iteration 170400, lr = 2.2518e-06
I0506 04:57:32.177935 12834 solver.cpp:242] Iteration 170400 (106.706 iter/s, 0.937153s/100 iter), loss = 0.424831
I0506 04:57:32.177959 12834 solver.cpp:261]     Train net output #0: loss = 0.424831 (* 1 = 0.424831 loss)
I0506 04:57:32.177968 12834 sgd_solver.cpp:106] Iteration 170400, lr = 2.2518e-06
I0506 04:57:33.110079 12834 solver.cpp:362] Iteration 170500, Testing net (#0)
I0506 04:57:33.110100 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:33.232695 12834 solver.cpp:429]     Test net output #0: loss = 1.21926 (* 1 = 1.21926 loss)
I0506 04:57:33.235219 12834 solver.cpp:242] Iteration 170500 (94.1568 iter/s, 1.06206s/100 iter), loss = 1.25083
I0506 04:57:33.235239 12834 solver.cpp:261]     Train net output #0: loss = 1.25083 (* 1 = 1.25083 loss)
I0506 04:57:33.235247 12834 sgd_solver.cpp:106] Iteration 170500, lr = 2.2518e-06
I0506 04:57:33.237073 12834 solver.cpp:362] Iteration 170500, Testing net (#0)
I0506 04:57:33.237087 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:33.365708 12834 solver.cpp:429]     Test net output #0: accuracy = 0.777
I0506 04:57:33.365727 12834 solver.cpp:429]     Test net output #1: loss = 0.505625 (* 1 = 0.505625 loss)
I0506 04:57:33.368285 12834 solver.cpp:242] Iteration 170500 (84.0121 iter/s, 1.1903s/100 iter), loss = 0.6137
I0506 04:57:33.368304 12834 solver.cpp:261]     Train net output #0: loss = 0.6137 (* 1 = 0.6137 loss)
I0506 04:57:33.368314 12834 sgd_solver.cpp:106] Iteration 170500, lr = 2.2518e-06
I0506 04:57:34.301360 12834 solver.cpp:242] Iteration 170600 (93.8001 iter/s, 1.0661s/100 iter), loss = 0.209303
I0506 04:57:34.301389 12834 solver.cpp:261]     Train net output #0: loss = 0.209303 (* 1 = 0.209303 loss)
I0506 04:57:34.301399 12834 sgd_solver.cpp:106] Iteration 170600, lr = 2.2518e-06
I0506 04:57:34.306203 12834 solver.cpp:242] Iteration 170600 (106.625 iter/s, 0.937869s/100 iter), loss = 0.356463
I0506 04:57:34.306227 12834 solver.cpp:261]     Train net output #0: loss = 0.356463 (* 1 = 0.356463 loss)
I0506 04:57:34.306236 12834 sgd_solver.cpp:106] Iteration 170600, lr = 2.2518e-06
I0506 04:57:35.238807 12834 solver.cpp:242] Iteration 170700 (106.679 iter/s, 0.937389s/100 iter), loss = 1.27785
I0506 04:57:35.238864 12834 solver.cpp:261]     Train net output #0: loss = 1.27785 (* 1 = 1.27785 loss)
I0506 04:57:35.238874 12834 sgd_solver.cpp:106] Iteration 170700, lr = 2.2518e-06
I0506 04:57:35.243654 12834 solver.cpp:242] Iteration 170700 (106.677 iter/s, 0.93741s/100 iter), loss = 0.562918
I0506 04:57:35.243680 12834 solver.cpp:261]     Train net output #0: loss = 0.562918 (* 1 = 0.562918 loss)
I0506 04:57:35.243690 12834 sgd_solver.cpp:106] Iteration 170700, lr = 2.2518e-06
I0506 04:57:36.177124 12834 solver.cpp:242] Iteration 170800 (106.584 iter/s, 0.938227s/100 iter), loss = 0.826814
I0506 04:57:36.177168 12834 solver.cpp:261]     Train net output #0: loss = 0.826814 (* 1 = 0.826814 loss)
I0506 04:57:36.177179 12834 sgd_solver.cpp:106] Iteration 170800, lr = 2.2518e-06
I0506 04:57:36.181921 12834 solver.cpp:242] Iteration 170800 (106.585 iter/s, 0.938222s/100 iter), loss = 0.349584
I0506 04:57:36.181946 12834 solver.cpp:261]     Train net output #0: loss = 0.349584 (* 1 = 0.349584 loss)
I0506 04:57:36.181955 12834 sgd_solver.cpp:106] Iteration 170800, lr = 2.2518e-06
I0506 04:57:37.114773 12834 solver.cpp:242] Iteration 170900 (106.658 iter/s, 0.937577s/100 iter), loss = 2.95518
I0506 04:57:37.114814 12834 solver.cpp:261]     Train net output #0: loss = 2.95518 (* 1 = 2.95518 loss)
I0506 04:57:37.114823 12834 sgd_solver.cpp:106] Iteration 170900, lr = 2.2518e-06
I0506 04:57:37.119546 12834 solver.cpp:242] Iteration 170900 (106.657 iter/s, 0.937582s/100 iter), loss = 0.528417
I0506 04:57:37.119573 12834 solver.cpp:261]     Train net output #0: loss = 0.528417 (* 1 = 0.528417 loss)
I0506 04:57:37.119595 12834 sgd_solver.cpp:106] Iteration 170900, lr = 2.2518e-06
I0506 04:57:38.048825 12834 solver.cpp:362] Iteration 171000, Testing net (#0)
I0506 04:57:38.048852 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:38.171525 12834 solver.cpp:429]     Test net output #0: loss = 1.18302 (* 1 = 1.18302 loss)
I0506 04:57:38.174068 12834 solver.cpp:242] Iteration 171000 (94.4077 iter/s, 1.05924s/100 iter), loss = 0.885595
I0506 04:57:38.174093 12834 solver.cpp:261]     Train net output #0: loss = 0.885595 (* 1 = 0.885595 loss)
I0506 04:57:38.174103 12834 sgd_solver.cpp:106] Iteration 171000, lr = 2.2518e-06
I0506 04:57:38.175918 12834 solver.cpp:362] Iteration 171000, Testing net (#0)
I0506 04:57:38.175931 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:38.304672 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7905
I0506 04:57:38.304692 12834 solver.cpp:429]     Test net output #1: loss = 0.484576 (* 1 = 0.484576 loss)
I0506 04:57:38.307260 12834 solver.cpp:242] Iteration 171000 (84.1987 iter/s, 1.18767s/100 iter), loss = 0.345944
I0506 04:57:38.307279 12834 solver.cpp:261]     Train net output #0: loss = 0.345944 (* 1 = 0.345944 loss)
I0506 04:57:38.307288 12834 sgd_solver.cpp:106] Iteration 171000, lr = 2.2518e-06
I0506 04:57:39.239996 12834 solver.cpp:242] Iteration 171100 (93.8197 iter/s, 1.06587s/100 iter), loss = 1.1281
I0506 04:57:39.240036 12834 solver.cpp:261]     Train net output #0: loss = 1.1281 (* 1 = 1.1281 loss)
I0506 04:57:39.240046 12834 sgd_solver.cpp:106] Iteration 171100, lr = 2.2518e-06
I0506 04:57:39.244804 12834 solver.cpp:242] Iteration 171100 (106.666 iter/s, 0.937506s/100 iter), loss = 0.74148
I0506 04:57:39.244829 12834 solver.cpp:261]     Train net output #0: loss = 0.74148 (* 1 = 0.74148 loss)
I0506 04:57:39.244838 12834 sgd_solver.cpp:106] Iteration 171100, lr = 2.2518e-06
I0506 04:57:40.177636 12834 solver.cpp:242] Iteration 171200 (106.659 iter/s, 0.937569s/100 iter), loss = 0.879772
I0506 04:57:40.177675 12834 solver.cpp:261]     Train net output #0: loss = 0.879772 (* 1 = 0.879772 loss)
I0506 04:57:40.177685 12834 sgd_solver.cpp:106] Iteration 171200, lr = 2.2518e-06
I0506 04:57:40.182415 12834 solver.cpp:242] Iteration 171200 (106.659 iter/s, 0.937567s/100 iter), loss = 0.420168
I0506 04:57:40.182440 12834 solver.cpp:261]     Train net output #0: loss = 0.420168 (* 1 = 0.420168 loss)
I0506 04:57:40.182448 12834 sgd_solver.cpp:106] Iteration 171200, lr = 2.2518e-06
I0506 04:57:41.115097 12834 solver.cpp:242] Iteration 171300 (106.678 iter/s, 0.937397s/100 iter), loss = 4.19213
I0506 04:57:41.115137 12834 solver.cpp:261]     Train net output #0: loss = 4.19213 (* 1 = 4.19213 loss)
I0506 04:57:41.115146 12834 sgd_solver.cpp:106] Iteration 171300, lr = 2.2518e-06
I0506 04:57:41.119935 12834 solver.cpp:242] Iteration 171300 (106.67 iter/s, 0.937467s/100 iter), loss = 0.660578
I0506 04:57:41.119961 12834 solver.cpp:261]     Train net output #0: loss = 0.660578 (* 1 = 0.660578 loss)
I0506 04:57:41.119969 12834 sgd_solver.cpp:106] Iteration 171300, lr = 2.2518e-06
I0506 04:57:42.052156 12834 solver.cpp:242] Iteration 171400 (106.725 iter/s, 0.936992s/100 iter), loss = 0.475
I0506 04:57:42.052192 12834 solver.cpp:261]     Train net output #0: loss = 0.475 (* 1 = 0.475 loss)
I0506 04:57:42.052202 12834 sgd_solver.cpp:106] Iteration 171400, lr = 2.2518e-06
I0506 04:57:42.056939 12834 solver.cpp:242] Iteration 171400 (106.728 iter/s, 0.936961s/100 iter), loss = 0.385338
I0506 04:57:42.056963 12834 solver.cpp:261]     Train net output #0: loss = 0.385338 (* 1 = 0.385338 loss)
I0506 04:57:42.056972 12834 sgd_solver.cpp:106] Iteration 171400, lr = 2.2518e-06
I0506 04:57:42.986234 12834 solver.cpp:362] Iteration 171500, Testing net (#0)
I0506 04:57:42.986258 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:43.109151 12834 solver.cpp:429]     Test net output #0: loss = 1.18289 (* 1 = 1.18289 loss)
I0506 04:57:43.111676 12834 solver.cpp:242] Iteration 171500 (94.3872 iter/s, 1.05947s/100 iter), loss = 1.03698
I0506 04:57:43.111708 12834 solver.cpp:261]     Train net output #0: loss = 1.03698 (* 1 = 1.03698 loss)
I0506 04:57:43.111717 12834 sgd_solver.cpp:106] Iteration 171500, lr = 2.2518e-06
I0506 04:57:43.113621 12834 solver.cpp:362] Iteration 171500, Testing net (#0)
I0506 04:57:43.113636 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:43.242183 12834 solver.cpp:429]     Test net output #0: accuracy = 0.782
I0506 04:57:43.242203 12834 solver.cpp:429]     Test net output #1: loss = 0.497026 (* 1 = 0.497026 loss)
I0506 04:57:43.244763 12834 solver.cpp:242] Iteration 171500 (84.1908 iter/s, 1.18778s/100 iter), loss = 0.436563
I0506 04:57:43.244784 12834 solver.cpp:261]     Train net output #0: loss = 0.436563 (* 1 = 0.436563 loss)
I0506 04:57:43.244793 12834 sgd_solver.cpp:106] Iteration 171500, lr = 2.2518e-06
I0506 04:57:44.178083 12834 solver.cpp:242] Iteration 171600 (93.7782 iter/s, 1.06635s/100 iter), loss = 1.05291
I0506 04:57:44.178119 12834 solver.cpp:261]     Train net output #0: loss = 1.05291 (* 1 = 1.05291 loss)
I0506 04:57:44.178128 12834 sgd_solver.cpp:106] Iteration 171600, lr = 2.2518e-06
I0506 04:57:44.182853 12834 solver.cpp:242] Iteration 171600 (106.604 iter/s, 0.938051s/100 iter), loss = 0.327136
I0506 04:57:44.182876 12834 solver.cpp:261]     Train net output #0: loss = 0.327136 (* 1 = 0.327136 loss)
I0506 04:57:44.182885 12834 sgd_solver.cpp:106] Iteration 171600, lr = 2.2518e-06
I0506 04:57:45.115469 12834 solver.cpp:242] Iteration 171700 (106.687 iter/s, 0.937319s/100 iter), loss = 0.41959
I0506 04:57:45.115502 12834 solver.cpp:261]     Train net output #0: loss = 0.41959 (* 1 = 0.41959 loss)
I0506 04:57:45.115511 12834 sgd_solver.cpp:106] Iteration 171700, lr = 2.2518e-06
I0506 04:57:45.120265 12834 solver.cpp:242] Iteration 171700 (106.681 iter/s, 0.93737s/100 iter), loss = 0.361589
I0506 04:57:45.120288 12834 solver.cpp:261]     Train net output #0: loss = 0.361589 (* 1 = 0.361589 loss)
I0506 04:57:45.120297 12834 sgd_solver.cpp:106] Iteration 171700, lr = 2.2518e-06
I0506 04:57:46.053078 12834 solver.cpp:242] Iteration 171800 (106.661 iter/s, 0.937549s/100 iter), loss = 1.08707
I0506 04:57:46.053133 12834 solver.cpp:261]     Train net output #0: loss = 1.08707 (* 1 = 1.08707 loss)
I0506 04:57:46.053143 12834 sgd_solver.cpp:106] Iteration 171800, lr = 2.2518e-06
I0506 04:57:46.057906 12834 solver.cpp:242] Iteration 171800 (106.656 iter/s, 0.937598s/100 iter), loss = 0.400995
I0506 04:57:46.057932 12834 solver.cpp:261]     Train net output #0: loss = 0.400995 (* 1 = 0.400995 loss)
I0506 04:57:46.057942 12834 sgd_solver.cpp:106] Iteration 171800, lr = 2.2518e-06
I0506 04:57:46.990191 12834 solver.cpp:242] Iteration 171900 (106.721 iter/s, 0.937025s/100 iter), loss = 0.653426
I0506 04:57:46.990234 12834 solver.cpp:261]     Train net output #0: loss = 0.653426 (* 1 = 0.653426 loss)
I0506 04:57:46.990245 12834 sgd_solver.cpp:106] Iteration 171900, lr = 2.2518e-06
I0506 04:57:46.994951 12834 solver.cpp:242] Iteration 171900 (106.724 iter/s, 0.937s/100 iter), loss = 0.663756
I0506 04:57:46.994976 12834 solver.cpp:261]     Train net output #0: loss = 0.663756 (* 1 = 0.663756 loss)
I0506 04:57:46.994983 12834 sgd_solver.cpp:106] Iteration 171900, lr = 2.2518e-06
I0506 04:57:47.924201 12834 solver.cpp:362] Iteration 172000, Testing net (#0)
I0506 04:57:47.924229 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:48.046854 12834 solver.cpp:429]     Test net output #0: loss = 1.23946 (* 1 = 1.23946 loss)
I0506 04:57:48.049371 12834 solver.cpp:242] Iteration 172000 (94.4183 iter/s, 1.05912s/100 iter), loss = 0.590297
I0506 04:57:48.049391 12834 solver.cpp:261]     Train net output #0: loss = 0.590297 (* 1 = 0.590297 loss)
I0506 04:57:48.049401 12834 sgd_solver.cpp:106] Iteration 172000, lr = 2.2518e-06
I0506 04:57:48.051215 12834 solver.cpp:362] Iteration 172000, Testing net (#0)
I0506 04:57:48.051229 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:48.180042 12834 solver.cpp:429]     Test net output #0: accuracy = 0.793
I0506 04:57:48.180071 12834 solver.cpp:429]     Test net output #1: loss = 0.486695 (* 1 = 0.486695 loss)
I0506 04:57:48.182626 12834 solver.cpp:242] Iteration 172000 (84.2012 iter/s, 1.18763s/100 iter), loss = 0.472683
I0506 04:57:48.182647 12834 solver.cpp:261]     Train net output #0: loss = 0.472683 (* 1 = 0.472683 loss)
I0506 04:57:48.182657 12834 sgd_solver.cpp:106] Iteration 172000, lr = 2.2518e-06
I0506 04:57:49.135710 12834 solver.cpp:242] Iteration 172100 (92.0571 iter/s, 1.08628s/100 iter), loss = 1.01034
I0506 04:57:49.135756 12834 solver.cpp:261]     Train net output #0: loss = 1.01034 (* 1 = 1.01034 loss)
I0506 04:57:49.135766 12834 sgd_solver.cpp:106] Iteration 172100, lr = 2.2518e-06
I0506 04:57:49.140487 12834 solver.cpp:242] Iteration 172100 (104.404 iter/s, 0.957821s/100 iter), loss = 0.514989
I0506 04:57:49.140511 12834 solver.cpp:261]     Train net output #0: loss = 0.514989 (* 1 = 0.514989 loss)
I0506 04:57:49.140519 12834 sgd_solver.cpp:106] Iteration 172100, lr = 2.2518e-06
I0506 04:57:50.072901 12834 solver.cpp:242] Iteration 172200 (106.71 iter/s, 0.937119s/100 iter), loss = 1.13366
I0506 04:57:50.072940 12834 solver.cpp:261]     Train net output #0: loss = 1.13366 (* 1 = 1.13366 loss)
I0506 04:57:50.072949 12834 sgd_solver.cpp:106] Iteration 172200, lr = 2.2518e-06
I0506 04:57:50.077752 12834 solver.cpp:242] Iteration 172200 (106.699 iter/s, 0.937214s/100 iter), loss = 0.591808
I0506 04:57:50.077781 12834 solver.cpp:261]     Train net output #0: loss = 0.591808 (* 1 = 0.591808 loss)
I0506 04:57:50.077790 12834 sgd_solver.cpp:106] Iteration 172200, lr = 2.2518e-06
I0506 04:57:51.010529 12834 solver.cpp:242] Iteration 172300 (106.66 iter/s, 0.937562s/100 iter), loss = 0.853382
I0506 04:57:51.010571 12834 solver.cpp:261]     Train net output #0: loss = 0.853382 (* 1 = 0.853382 loss)
I0506 04:57:51.010579 12834 sgd_solver.cpp:106] Iteration 172300, lr = 2.2518e-06
I0506 04:57:51.015324 12834 solver.cpp:242] Iteration 172300 (106.664 iter/s, 0.937525s/100 iter), loss = 0.559788
I0506 04:57:51.015348 12834 solver.cpp:261]     Train net output #0: loss = 0.559788 (* 1 = 0.559788 loss)
I0506 04:57:51.015357 12834 sgd_solver.cpp:106] Iteration 172300, lr = 2.2518e-06
I0506 04:57:51.947924 12834 solver.cpp:242] Iteration 172400 (106.686 iter/s, 0.937332s/100 iter), loss = 1.03192
I0506 04:57:51.947963 12834 solver.cpp:261]     Train net output #0: loss = 1.03192 (* 1 = 1.03192 loss)
I0506 04:57:51.947973 12834 sgd_solver.cpp:106] Iteration 172400, lr = 2.2518e-06
I0506 04:57:51.952764 12834 solver.cpp:242] Iteration 172400 (106.679 iter/s, 0.937389s/100 iter), loss = 0.765909
I0506 04:57:51.952791 12834 solver.cpp:261]     Train net output #0: loss = 0.765909 (* 1 = 0.765909 loss)
I0506 04:57:51.952801 12834 sgd_solver.cpp:106] Iteration 172400, lr = 2.2518e-06
I0506 04:57:52.882319 12834 solver.cpp:362] Iteration 172500, Testing net (#0)
I0506 04:57:52.882345 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:53.005061 12834 solver.cpp:429]     Test net output #0: loss = 1.2444 (* 1 = 1.2444 loss)
I0506 04:57:53.007583 12834 solver.cpp:242] Iteration 172500 (94.3751 iter/s, 1.0596s/100 iter), loss = 3.00556
I0506 04:57:53.007603 12834 solver.cpp:261]     Train net output #0: loss = 3.00556 (* 1 = 3.00556 loss)
I0506 04:57:53.007612 12834 sgd_solver.cpp:106] Iteration 172500, lr = 2.2518e-06
I0506 04:57:53.009490 12834 solver.cpp:362] Iteration 172500, Testing net (#0)
I0506 04:57:53.009506 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:53.138233 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7865
I0506 04:57:53.138254 12834 solver.cpp:429]     Test net output #1: loss = 0.487634 (* 1 = 0.487634 loss)
I0506 04:57:53.140815 12834 solver.cpp:242] Iteration 172500 (84.1749 iter/s, 1.188s/100 iter), loss = 0.650794
I0506 04:57:53.140836 12834 solver.cpp:261]     Train net output #0: loss = 0.650794 (* 1 = 0.650794 loss)
I0506 04:57:53.140843 12834 sgd_solver.cpp:106] Iteration 172500, lr = 2.2518e-06
I0506 04:57:54.074048 12834 solver.cpp:242] Iteration 172600 (93.7725 iter/s, 1.06641s/100 iter), loss = 0.4909
I0506 04:57:54.074097 12834 solver.cpp:261]     Train net output #0: loss = 0.4909 (* 1 = 0.4909 loss)
I0506 04:57:54.074107 12834 sgd_solver.cpp:106] Iteration 172600, lr = 2.2518e-06
I0506 04:57:54.078861 12834 solver.cpp:242] Iteration 172600 (106.609 iter/s, 0.938008s/100 iter), loss = 0.463586
I0506 04:57:54.078889 12834 solver.cpp:261]     Train net output #0: loss = 0.463586 (* 1 = 0.463586 loss)
I0506 04:57:54.078898 12834 sgd_solver.cpp:106] Iteration 172600, lr = 2.2518e-06
I0506 04:57:55.011325 12834 solver.cpp:242] Iteration 172700 (106.701 iter/s, 0.937203s/100 iter), loss = 1.00139
I0506 04:57:55.011361 12834 solver.cpp:261]     Train net output #0: loss = 1.00139 (* 1 = 1.00139 loss)
I0506 04:57:55.011370 12834 sgd_solver.cpp:106] Iteration 172700, lr = 2.2518e-06
I0506 04:57:55.016103 12834 solver.cpp:242] Iteration 172700 (106.701 iter/s, 0.937195s/100 iter), loss = 0.772343
I0506 04:57:55.016127 12834 solver.cpp:261]     Train net output #0: loss = 0.772343 (* 1 = 0.772343 loss)
I0506 04:57:55.016137 12834 sgd_solver.cpp:106] Iteration 172700, lr = 2.2518e-06
I0506 04:57:55.948403 12834 solver.cpp:242] Iteration 172800 (106.722 iter/s, 0.93701s/100 iter), loss = 1.44906
I0506 04:57:55.948438 12834 solver.cpp:261]     Train net output #0: loss = 1.44906 (* 1 = 1.44906 loss)
I0506 04:57:55.948448 12834 sgd_solver.cpp:106] Iteration 172800, lr = 2.2518e-06
I0506 04:57:55.953181 12834 solver.cpp:242] Iteration 172800 (106.72 iter/s, 0.937035s/100 iter), loss = 0.595811
I0506 04:57:55.953204 12834 solver.cpp:261]     Train net output #0: loss = 0.595811 (* 1 = 0.595811 loss)
I0506 04:57:55.953213 12834 sgd_solver.cpp:106] Iteration 172800, lr = 2.2518e-06
I0506 04:57:56.885409 12834 solver.cpp:242] Iteration 172900 (106.73 iter/s, 0.936948s/100 iter), loss = 0.45563
I0506 04:57:56.885444 12834 solver.cpp:261]     Train net output #0: loss = 0.45563 (* 1 = 0.45563 loss)
I0506 04:57:56.885453 12834 sgd_solver.cpp:106] Iteration 172900, lr = 2.2518e-06
I0506 04:57:56.890166 12834 solver.cpp:242] Iteration 172900 (106.73 iter/s, 0.936943s/100 iter), loss = 0.514002
I0506 04:57:56.890190 12834 solver.cpp:261]     Train net output #0: loss = 0.514002 (* 1 = 0.514002 loss)
I0506 04:57:56.890199 12834 sgd_solver.cpp:106] Iteration 172900, lr = 2.2518e-06
I0506 04:57:57.820093 12834 solver.cpp:362] Iteration 173000, Testing net (#0)
I0506 04:57:57.820121 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:57.942728 12834 solver.cpp:429]     Test net output #0: loss = 1.31083 (* 1 = 1.31083 loss)
I0506 04:57:57.945241 12834 solver.cpp:242] Iteration 173000 (94.3593 iter/s, 1.05978s/100 iter), loss = 0.93984
I0506 04:57:57.945261 12834 solver.cpp:261]     Train net output #0: loss = 0.93984 (* 1 = 0.93984 loss)
I0506 04:57:57.945271 12834 sgd_solver.cpp:106] Iteration 173000, lr = 2.2518e-06
I0506 04:57:57.947088 12834 solver.cpp:362] Iteration 173000, Testing net (#0)
I0506 04:57:57.947100 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:57:58.076285 12834 solver.cpp:429]     Test net output #0: accuracy = 0.774
I0506 04:57:58.076305 12834 solver.cpp:429]     Test net output #1: loss = 0.513157 (* 1 = 0.513157 loss)
I0506 04:57:58.078856 12834 solver.cpp:242] Iteration 173000 (84.1294 iter/s, 1.18864s/100 iter), loss = 0.305939
I0506 04:57:58.078877 12834 solver.cpp:261]     Train net output #0: loss = 0.305939 (* 1 = 0.305939 loss)
I0506 04:57:58.078886 12834 sgd_solver.cpp:106] Iteration 173000, lr = 2.2518e-06
I0506 04:57:59.011167 12834 solver.cpp:242] Iteration 173100 (93.8193 iter/s, 1.06588s/100 iter), loss = 0.859079
I0506 04:57:59.011199 12834 solver.cpp:261]     Train net output #0: loss = 0.859079 (* 1 = 0.859079 loss)
I0506 04:57:59.011209 12834 sgd_solver.cpp:106] Iteration 173100, lr = 2.2518e-06
I0506 04:57:59.015934 12834 solver.cpp:242] Iteration 173100 (106.719 iter/s, 0.937039s/100 iter), loss = 0.760199
I0506 04:57:59.015959 12834 solver.cpp:261]     Train net output #0: loss = 0.760199 (* 1 = 0.760199 loss)
I0506 04:57:59.015967 12834 sgd_solver.cpp:106] Iteration 173100, lr = 2.2518e-06
I0506 04:57:59.948585 12834 solver.cpp:242] Iteration 173200 (106.683 iter/s, 0.937357s/100 iter), loss = 1.44342
I0506 04:57:59.948621 12834 solver.cpp:261]     Train net output #0: loss = 1.44342 (* 1 = 1.44342 loss)
I0506 04:57:59.948629 12834 sgd_solver.cpp:106] Iteration 173200, lr = 2.2518e-06
I0506 04:57:59.953358 12834 solver.cpp:242] Iteration 173200 (106.68 iter/s, 0.937382s/100 iter), loss = 0.347122
I0506 04:57:59.953382 12834 solver.cpp:261]     Train net output #0: loss = 0.347122 (* 1 = 0.347122 loss)
I0506 04:57:59.953392 12834 sgd_solver.cpp:106] Iteration 173200, lr = 2.2518e-06
I0506 04:58:00.898661 12834 solver.cpp:242] Iteration 173300 (105.261 iter/s, 0.950017s/100 iter), loss = 0.566006
I0506 04:58:00.898708 12834 solver.cpp:261]     Train net output #0: loss = 0.566006 (* 1 = 0.566006 loss)
I0506 04:58:00.898717 12834 sgd_solver.cpp:106] Iteration 173300, lr = 2.2518e-06
I0506 04:58:00.903523 12834 solver.cpp:242] Iteration 173300 (105.251 iter/s, 0.950113s/100 iter), loss = 0.280657
I0506 04:58:00.903550 12834 solver.cpp:261]     Train net output #0: loss = 0.280657 (* 1 = 0.280657 loss)
I0506 04:58:00.903559 12834 sgd_solver.cpp:106] Iteration 173300, lr = 2.2518e-06
I0506 04:58:01.836838 12834 solver.cpp:242] Iteration 173400 (106.598 iter/s, 0.938102s/100 iter), loss = 1.8664
I0506 04:58:01.836891 12834 solver.cpp:261]     Train net output #0: loss = 1.8664 (* 1 = 1.8664 loss)
I0506 04:58:01.836910 12834 sgd_solver.cpp:106] Iteration 173400, lr = 2.2518e-06
I0506 04:58:01.841665 12834 solver.cpp:242] Iteration 173400 (106.599 iter/s, 0.938097s/100 iter), loss = 0.42242
I0506 04:58:01.841691 12834 solver.cpp:261]     Train net output #0: loss = 0.42242 (* 1 = 0.42242 loss)
I0506 04:58:01.841711 12834 sgd_solver.cpp:106] Iteration 173400, lr = 2.2518e-06
I0506 04:58:02.771379 12834 solver.cpp:362] Iteration 173500, Testing net (#0)
I0506 04:58:02.771406 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:02.894062 12834 solver.cpp:429]     Test net output #0: loss = 1.16353 (* 1 = 1.16353 loss)
I0506 04:58:02.896579 12834 solver.cpp:242] Iteration 173500 (94.3692 iter/s, 1.05967s/100 iter), loss = 0.210714
I0506 04:58:02.896603 12834 solver.cpp:261]     Train net output #0: loss = 0.210714 (* 1 = 0.210714 loss)
I0506 04:58:02.896611 12834 sgd_solver.cpp:106] Iteration 173500, lr = 2.2518e-06
I0506 04:58:02.898422 12834 solver.cpp:362] Iteration 173500, Testing net (#0)
I0506 04:58:02.898435 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:03.027015 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7825
I0506 04:58:03.027035 12834 solver.cpp:429]     Test net output #1: loss = 0.510695 (* 1 = 0.510695 loss)
I0506 04:58:03.029587 12834 solver.cpp:242] Iteration 173500 (84.184 iter/s, 1.18787s/100 iter), loss = 0.449703
I0506 04:58:03.029609 12834 solver.cpp:261]     Train net output #0: loss = 0.449703 (* 1 = 0.449703 loss)
I0506 04:58:03.029618 12834 sgd_solver.cpp:106] Iteration 173500, lr = 2.2518e-06
I0506 04:58:03.962162 12834 solver.cpp:242] Iteration 173600 (93.8501 iter/s, 1.06553s/100 iter), loss = 0.203878
I0506 04:58:03.962205 12834 solver.cpp:261]     Train net output #0: loss = 0.203878 (* 1 = 0.203878 loss)
I0506 04:58:03.962215 12834 sgd_solver.cpp:106] Iteration 173600, lr = 2.2518e-06
I0506 04:58:03.966946 12834 solver.cpp:242] Iteration 173600 (106.687 iter/s, 0.937318s/100 iter), loss = 0.318116
I0506 04:58:03.966972 12834 solver.cpp:261]     Train net output #0: loss = 0.318116 (* 1 = 0.318116 loss)
I0506 04:58:03.966981 12834 sgd_solver.cpp:106] Iteration 173600, lr = 2.2518e-06
I0506 04:58:04.899722 12834 solver.cpp:242] Iteration 173700 (106.668 iter/s, 0.937485s/100 iter), loss = 0.169796
I0506 04:58:04.899762 12834 solver.cpp:261]     Train net output #0: loss = 0.169796 (* 1 = 0.169796 loss)
I0506 04:58:04.899771 12834 sgd_solver.cpp:106] Iteration 173700, lr = 2.2518e-06
I0506 04:58:04.904508 12834 solver.cpp:242] Iteration 173700 (106.665 iter/s, 0.937518s/100 iter), loss = 0.153438
I0506 04:58:04.904543 12834 solver.cpp:261]     Train net output #0: loss = 0.153438 (* 1 = 0.153438 loss)
I0506 04:58:04.904556 12834 sgd_solver.cpp:106] Iteration 173700, lr = 2.2518e-06
I0506 04:58:05.837323 12834 solver.cpp:242] Iteration 173800 (106.664 iter/s, 0.937525s/100 iter), loss = 0.524628
I0506 04:58:05.837363 12834 solver.cpp:261]     Train net output #0: loss = 0.524628 (* 1 = 0.524628 loss)
I0506 04:58:05.837373 12834 sgd_solver.cpp:106] Iteration 173800, lr = 2.2518e-06
I0506 04:58:05.842093 12834 solver.cpp:242] Iteration 173800 (106.663 iter/s, 0.937531s/100 iter), loss = 0.473541
I0506 04:58:05.842118 12834 solver.cpp:261]     Train net output #0: loss = 0.473541 (* 1 = 0.473541 loss)
I0506 04:58:05.842128 12834 sgd_solver.cpp:106] Iteration 173800, lr = 2.2518e-06
I0506 04:58:06.774273 12834 solver.cpp:242] Iteration 173900 (106.737 iter/s, 0.936881s/100 iter), loss = 2.05355
I0506 04:58:06.774310 12834 solver.cpp:261]     Train net output #0: loss = 2.05355 (* 1 = 2.05355 loss)
I0506 04:58:06.774319 12834 sgd_solver.cpp:106] Iteration 173900, lr = 2.2518e-06
I0506 04:58:06.779074 12834 solver.cpp:242] Iteration 173900 (106.731 iter/s, 0.936938s/100 iter), loss = 0.490847
I0506 04:58:06.779100 12834 solver.cpp:261]     Train net output #0: loss = 0.490847 (* 1 = 0.490847 loss)
I0506 04:58:06.779109 12834 sgd_solver.cpp:106] Iteration 173900, lr = 2.2518e-06
I0506 04:58:07.708994 12834 solver.cpp:362] Iteration 174000, Testing net (#0)
I0506 04:58:07.709020 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:07.831713 12834 solver.cpp:429]     Test net output #0: loss = 1.12465 (* 1 = 1.12465 loss)
I0506 04:58:07.834228 12834 solver.cpp:242] Iteration 174000 (94.3487 iter/s, 1.0599s/100 iter), loss = 1.23283
I0506 04:58:07.834249 12834 solver.cpp:261]     Train net output #0: loss = 1.23283 (* 1 = 1.23283 loss)
I0506 04:58:07.834259 12834 sgd_solver.cpp:106] Iteration 174000, lr = 2.2518e-06
I0506 04:58:07.836077 12834 solver.cpp:362] Iteration 174000, Testing net (#0)
I0506 04:58:07.836091 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:07.964689 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7755
I0506 04:58:07.964709 12834 solver.cpp:429]     Test net output #1: loss = 0.507547 (* 1 = 0.507547 loss)
I0506 04:58:07.967268 12834 solver.cpp:242] Iteration 174000 (84.1647 iter/s, 1.18815s/100 iter), loss = 0.541747
I0506 04:58:07.967288 12834 solver.cpp:261]     Train net output #0: loss = 0.541747 (* 1 = 0.541747 loss)
I0506 04:58:07.967298 12834 sgd_solver.cpp:106] Iteration 174000, lr = 2.2518e-06
I0506 04:58:08.900009 12834 solver.cpp:242] Iteration 174100 (93.8327 iter/s, 1.06573s/100 iter), loss = 0.926698
I0506 04:58:08.900046 12834 solver.cpp:261]     Train net output #0: loss = 0.926698 (* 1 = 0.926698 loss)
I0506 04:58:08.900056 12834 sgd_solver.cpp:106] Iteration 174100, lr = 2.2518e-06
I0506 04:58:08.904808 12834 solver.cpp:242] Iteration 174100 (106.667 iter/s, 0.937499s/100 iter), loss = 0.532369
I0506 04:58:08.904834 12834 solver.cpp:261]     Train net output #0: loss = 0.532369 (* 1 = 0.532369 loss)
I0506 04:58:08.904844 12834 sgd_solver.cpp:106] Iteration 174100, lr = 2.2518e-06
I0506 04:58:09.837569 12834 solver.cpp:242] Iteration 174200 (106.667 iter/s, 0.937498s/100 iter), loss = 0.491022
I0506 04:58:09.837608 12834 solver.cpp:261]     Train net output #0: loss = 0.491022 (* 1 = 0.491022 loss)
I0506 04:58:09.837620 12834 sgd_solver.cpp:106] Iteration 174200, lr = 2.2518e-06
I0506 04:58:09.842445 12834 solver.cpp:242] Iteration 174200 (106.657 iter/s, 0.937583s/100 iter), loss = 0.500585
I0506 04:58:09.842473 12834 solver.cpp:261]     Train net output #0: loss = 0.500585 (* 1 = 0.500585 loss)
I0506 04:58:09.842483 12834 sgd_solver.cpp:106] Iteration 174200, lr = 2.2518e-06
I0506 04:58:10.775032 12834 solver.cpp:242] Iteration 174300 (106.678 iter/s, 0.937396s/100 iter), loss = 0.41435
I0506 04:58:10.775068 12834 solver.cpp:261]     Train net output #0: loss = 0.41435 (* 1 = 0.41435 loss)
I0506 04:58:10.775079 12834 sgd_solver.cpp:106] Iteration 174300, lr = 2.2518e-06
I0506 04:58:10.779824 12834 solver.cpp:242] Iteration 174300 (106.686 iter/s, 0.937332s/100 iter), loss = 0.437724
I0506 04:58:10.779850 12834 solver.cpp:261]     Train net output #0: loss = 0.437724 (* 1 = 0.437724 loss)
I0506 04:58:10.779858 12834 sgd_solver.cpp:106] Iteration 174300, lr = 2.2518e-06
I0506 04:58:11.712491 12834 solver.cpp:242] Iteration 174400 (106.679 iter/s, 0.937389s/100 iter), loss = 0.730703
I0506 04:58:11.712535 12834 solver.cpp:261]     Train net output #0: loss = 0.730703 (* 1 = 0.730703 loss)
I0506 04:58:11.712545 12834 sgd_solver.cpp:106] Iteration 174400, lr = 2.2518e-06
I0506 04:58:11.717315 12834 solver.cpp:242] Iteration 174400 (106.673 iter/s, 0.937447s/100 iter), loss = 0.370049
I0506 04:58:11.717342 12834 solver.cpp:261]     Train net output #0: loss = 0.370049 (* 1 = 0.370049 loss)
I0506 04:58:11.717351 12834 sgd_solver.cpp:106] Iteration 174400, lr = 2.2518e-06
I0506 04:58:12.647625 12834 solver.cpp:362] Iteration 174500, Testing net (#0)
I0506 04:58:12.647656 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:12.770284 12834 solver.cpp:429]     Test net output #0: loss = 1.12777 (* 1 = 1.12777 loss)
I0506 04:58:12.772806 12834 solver.cpp:242] Iteration 174500 (94.3171 iter/s, 1.06025s/100 iter), loss = 1.32405
I0506 04:58:12.772827 12834 solver.cpp:261]     Train net output #0: loss = 1.32405 (* 1 = 1.32405 loss)
I0506 04:58:12.772835 12834 sgd_solver.cpp:106] Iteration 174500, lr = 2.2518e-06
I0506 04:58:12.774655 12834 solver.cpp:362] Iteration 174500, Testing net (#0)
I0506 04:58:12.774670 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:12.903218 12834 solver.cpp:429]     Test net output #0: accuracy = 0.786
I0506 04:58:12.903239 12834 solver.cpp:429]     Test net output #1: loss = 0.503343 (* 1 = 0.503343 loss)
I0506 04:58:12.905788 12834 solver.cpp:242] Iteration 174500 (84.1449 iter/s, 1.18843s/100 iter), loss = 0.544562
I0506 04:58:12.905808 12834 solver.cpp:261]     Train net output #0: loss = 0.544562 (* 1 = 0.544562 loss)
I0506 04:58:12.905817 12834 sgd_solver.cpp:106] Iteration 174500, lr = 2.2518e-06
I0506 04:58:13.838469 12834 solver.cpp:242] Iteration 174600 (93.8432 iter/s, 1.06561s/100 iter), loss = 0.778554
I0506 04:58:13.838510 12834 solver.cpp:261]     Train net output #0: loss = 0.778554 (* 1 = 0.778554 loss)
I0506 04:58:13.838521 12834 sgd_solver.cpp:106] Iteration 174600, lr = 2.2518e-06
I0506 04:58:13.843245 12834 solver.cpp:242] Iteration 174600 (106.676 iter/s, 0.937417s/100 iter), loss = 0.377584
I0506 04:58:13.843271 12834 solver.cpp:261]     Train net output #0: loss = 0.377584 (* 1 = 0.377584 loss)
I0506 04:58:13.843279 12834 sgd_solver.cpp:106] Iteration 174600, lr = 2.2518e-06
I0506 04:58:14.776120 12834 solver.cpp:242] Iteration 174700 (106.657 iter/s, 0.937583s/100 iter), loss = 1.39238
I0506 04:58:14.776162 12834 solver.cpp:261]     Train net output #0: loss = 1.39238 (* 1 = 1.39238 loss)
I0506 04:58:14.776171 12834 sgd_solver.cpp:106] Iteration 174700, lr = 2.2518e-06
I0506 04:58:14.780900 12834 solver.cpp:242] Iteration 174700 (106.654 iter/s, 0.937611s/100 iter), loss = 0.59316
I0506 04:58:14.780925 12834 solver.cpp:261]     Train net output #0: loss = 0.59316 (* 1 = 0.59316 loss)
I0506 04:58:14.780933 12834 sgd_solver.cpp:106] Iteration 174700, lr = 2.2518e-06
I0506 04:58:15.713650 12834 solver.cpp:242] Iteration 174800 (106.672 iter/s, 0.937455s/100 iter), loss = 1.09568
I0506 04:58:15.713692 12834 solver.cpp:261]     Train net output #0: loss = 1.09568 (* 1 = 1.09568 loss)
I0506 04:58:15.713701 12834 sgd_solver.cpp:106] Iteration 174800, lr = 2.2518e-06
I0506 04:58:15.718452 12834 solver.cpp:242] Iteration 174800 (106.666 iter/s, 0.93751s/100 iter), loss = 0.418232
I0506 04:58:15.718480 12834 solver.cpp:261]     Train net output #0: loss = 0.418232 (* 1 = 0.418232 loss)
I0506 04:58:15.718489 12834 sgd_solver.cpp:106] Iteration 174800, lr = 2.2518e-06
I0506 04:58:16.650871 12834 solver.cpp:242] Iteration 174900 (106.706 iter/s, 0.937154s/100 iter), loss = 1.55902
I0506 04:58:16.650912 12834 solver.cpp:261]     Train net output #0: loss = 1.55902 (* 1 = 1.55902 loss)
I0506 04:58:16.650930 12834 sgd_solver.cpp:106] Iteration 174900, lr = 2.2518e-06
I0506 04:58:16.655669 12834 solver.cpp:242] Iteration 174900 (106.704 iter/s, 0.937172s/100 iter), loss = 0.638102
I0506 04:58:16.655696 12834 solver.cpp:261]     Train net output #0: loss = 0.638102 (* 1 = 0.638102 loss)
I0506 04:58:16.655705 12834 sgd_solver.cpp:106] Iteration 174900, lr = 2.2518e-06
I0506 04:58:17.585211 12834 solver.cpp:362] Iteration 175000, Testing net (#0)
I0506 04:58:17.585237 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:17.708001 12834 solver.cpp:429]     Test net output #0: loss = 1.10801 (* 1 = 1.10801 loss)
I0506 04:58:17.710526 12834 solver.cpp:242] Iteration 175000 (94.3755 iter/s, 1.0596s/100 iter), loss = 0.608268
I0506 04:58:17.710547 12834 solver.cpp:261]     Train net output #0: loss = 0.608268 (* 1 = 0.608268 loss)
I0506 04:58:17.710556 12834 sgd_solver.cpp:106] Iteration 175000, lr = 2.2518e-06
I0506 04:58:17.712369 12834 solver.cpp:362] Iteration 175000, Testing net (#0)
I0506 04:58:17.712381 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:17.841641 12834 solver.cpp:429]     Test net output #0: accuracy = 0.789
I0506 04:58:17.841676 12834 solver.cpp:429]     Test net output #1: loss = 0.500736 (* 1 = 0.500736 loss)
I0506 04:58:17.844241 12834 solver.cpp:242] Iteration 175000 (84.1379 iter/s, 1.18853s/100 iter), loss = 0.495068
I0506 04:58:17.844264 12834 solver.cpp:261]     Train net output #0: loss = 0.495068 (* 1 = 0.495068 loss)
I0506 04:58:17.844272 12834 sgd_solver.cpp:106] Iteration 175000, lr = 2.2518e-06
I0506 04:58:18.776819 12834 solver.cpp:242] Iteration 175100 (93.7872 iter/s, 1.06624s/100 iter), loss = 1.39149
I0506 04:58:18.776859 12834 solver.cpp:261]     Train net output #0: loss = 1.39149 (* 1 = 1.39149 loss)
I0506 04:58:18.776867 12834 sgd_solver.cpp:106] Iteration 175100, lr = 2.2518e-06
I0506 04:58:18.781662 12834 solver.cpp:242] Iteration 175100 (106.682 iter/s, 0.937369s/100 iter), loss = 0.564073
I0506 04:58:18.781688 12834 solver.cpp:261]     Train net output #0: loss = 0.564073 (* 1 = 0.564073 loss)
I0506 04:58:18.781698 12834 sgd_solver.cpp:106] Iteration 175100, lr = 2.2518e-06
I0506 04:58:19.715040 12834 solver.cpp:242] Iteration 175200 (106.592 iter/s, 0.938154s/100 iter), loss = 1.68102
I0506 04:58:19.715091 12834 solver.cpp:261]     Train net output #0: loss = 1.68102 (* 1 = 1.68102 loss)
I0506 04:58:19.715101 12834 sgd_solver.cpp:106] Iteration 175200, lr = 2.2518e-06
I0506 04:58:19.719836 12834 solver.cpp:242] Iteration 175200 (106.595 iter/s, 0.938129s/100 iter), loss = 0.729604
I0506 04:58:19.719861 12834 solver.cpp:261]     Train net output #0: loss = 0.729604 (* 1 = 0.729604 loss)
I0506 04:58:19.719871 12834 sgd_solver.cpp:106] Iteration 175200, lr = 2.2518e-06
I0506 04:58:20.652396 12834 solver.cpp:242] Iteration 175300 (106.692 iter/s, 0.937282s/100 iter), loss = 3.05226
I0506 04:58:20.652433 12834 solver.cpp:261]     Train net output #0: loss = 3.05226 (* 1 = 3.05226 loss)
I0506 04:58:20.652443 12834 sgd_solver.cpp:106] Iteration 175300, lr = 2.2518e-06
I0506 04:58:20.657166 12834 solver.cpp:242] Iteration 175300 (106.692 iter/s, 0.937278s/100 iter), loss = 0.73046
I0506 04:58:20.657191 12834 solver.cpp:261]     Train net output #0: loss = 0.73046 (* 1 = 0.73046 loss)
I0506 04:58:20.657200 12834 sgd_solver.cpp:106] Iteration 175300, lr = 2.2518e-06
I0506 04:58:21.589303 12834 solver.cpp:242] Iteration 175400 (106.741 iter/s, 0.936845s/100 iter), loss = 0.635528
I0506 04:58:21.589332 12834 solver.cpp:261]     Train net output #0: loss = 0.635528 (* 1 = 0.635528 loss)
I0506 04:58:21.589341 12834 sgd_solver.cpp:106] Iteration 175400, lr = 2.2518e-06
I0506 04:58:21.594068 12834 solver.cpp:242] Iteration 175400 (106.74 iter/s, 0.936858s/100 iter), loss = 0.57589
I0506 04:58:21.594091 12834 solver.cpp:261]     Train net output #0: loss = 0.57589 (* 1 = 0.57589 loss)
I0506 04:58:21.594100 12834 sgd_solver.cpp:106] Iteration 175400, lr = 2.2518e-06
I0506 04:58:22.524041 12834 solver.cpp:362] Iteration 175500, Testing net (#0)
I0506 04:58:22.524070 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:22.646888 12834 solver.cpp:429]     Test net output #0: loss = 1.10995 (* 1 = 1.10995 loss)
I0506 04:58:22.649426 12834 solver.cpp:242] Iteration 175500 (94.333 iter/s, 1.06007s/100 iter), loss = 1.45187
I0506 04:58:22.649448 12834 solver.cpp:261]     Train net output #0: loss = 1.45187 (* 1 = 1.45187 loss)
I0506 04:58:22.649457 12834 sgd_solver.cpp:106] Iteration 175500, lr = 2.2518e-06
I0506 04:58:22.651275 12834 solver.cpp:362] Iteration 175500, Testing net (#0)
I0506 04:58:22.651288 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:22.780283 12834 solver.cpp:429]     Test net output #0: accuracy = 0.8095
I0506 04:58:22.780303 12834 solver.cpp:429]     Test net output #1: loss = 0.448119 (* 1 = 0.448119 loss)
I0506 04:58:22.782850 12834 solver.cpp:242] Iteration 175500 (84.1228 iter/s, 1.18874s/100 iter), loss = 0.516895
I0506 04:58:22.782871 12834 solver.cpp:261]     Train net output #0: loss = 0.516895 (* 1 = 0.516895 loss)
I0506 04:58:22.782881 12834 sgd_solver.cpp:106] Iteration 175500, lr = 2.2518e-06
I0506 04:58:23.715312 12834 solver.cpp:242] Iteration 175600 (93.8233 iter/s, 1.06583s/100 iter), loss = 3.86412
I0506 04:58:23.715356 12834 solver.cpp:261]     Train net output #0: loss = 3.86412 (* 1 = 3.86412 loss)
I0506 04:58:23.715365 12834 sgd_solver.cpp:106] Iteration 175600, lr = 2.2518e-06
I0506 04:58:23.720119 12834 solver.cpp:242] Iteration 175600 (106.697 iter/s, 0.937229s/100 iter), loss = 0.769259
I0506 04:58:23.720144 12834 solver.cpp:261]     Train net output #0: loss = 0.769259 (* 1 = 0.769259 loss)
I0506 04:58:23.720154 12834 sgd_solver.cpp:106] Iteration 175600, lr = 2.2518e-06
I0506 04:58:24.652770 12834 solver.cpp:242] Iteration 175700 (106.68 iter/s, 0.937382s/100 iter), loss = 2.07305
I0506 04:58:24.652809 12834 solver.cpp:261]     Train net output #0: loss = 2.07305 (* 1 = 2.07305 loss)
I0506 04:58:24.652818 12834 sgd_solver.cpp:106] Iteration 175700, lr = 2.2518e-06
I0506 04:58:24.657534 12834 solver.cpp:242] Iteration 175700 (106.681 iter/s, 0.937372s/100 iter), loss = 0.630794
I0506 04:58:24.657560 12834 solver.cpp:261]     Train net output #0: loss = 0.630794 (* 1 = 0.630794 loss)
I0506 04:58:24.657569 12834 sgd_solver.cpp:106] Iteration 175700, lr = 2.2518e-06
I0506 04:58:25.590720 12834 solver.cpp:242] Iteration 175800 (106.623 iter/s, 0.937884s/100 iter), loss = 0.936311
I0506 04:58:25.590768 12834 solver.cpp:261]     Train net output #0: loss = 0.936311 (* 1 = 0.936311 loss)
I0506 04:58:25.590780 12834 sgd_solver.cpp:106] Iteration 175800, lr = 2.2518e-06
I0506 04:58:25.595508 12834 solver.cpp:242] Iteration 175800 (106.618 iter/s, 0.93793s/100 iter), loss = 0.401846
I0506 04:58:25.595535 12834 solver.cpp:261]     Train net output #0: loss = 0.401846 (* 1 = 0.401846 loss)
I0506 04:58:25.595543 12834 sgd_solver.cpp:106] Iteration 175800, lr = 2.2518e-06
I0506 04:58:26.544647 12834 solver.cpp:242] Iteration 175900 (104.839 iter/s, 0.953846s/100 iter), loss = 0.569714
I0506 04:58:26.544695 12834 solver.cpp:261]     Train net output #0: loss = 0.569714 (* 1 = 0.569714 loss)
I0506 04:58:26.544708 12834 sgd_solver.cpp:106] Iteration 175900, lr = 2.2518e-06
I0506 04:58:26.549929 12834 solver.cpp:242] Iteration 175900 (104.78 iter/s, 0.954376s/100 iter), loss = 0.715754
I0506 04:58:26.549962 12834 solver.cpp:261]     Train net output #0: loss = 0.715754 (* 1 = 0.715754 loss)
I0506 04:58:26.549973 12834 sgd_solver.cpp:106] Iteration 175900, lr = 2.2518e-06
I0506 04:58:27.557008 12834 solver.cpp:362] Iteration 176000, Testing net (#0)
I0506 04:58:27.557035 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:27.679647 12834 solver.cpp:429]     Test net output #0: loss = 1.17246 (* 1 = 1.17246 loss)
I0506 04:58:27.682171 12834 solver.cpp:242] Iteration 176000 (87.9154 iter/s, 1.13746s/100 iter), loss = 0.854712
I0506 04:58:27.682196 12834 solver.cpp:261]     Train net output #0: loss = 0.854712 (* 1 = 0.854712 loss)
I0506 04:58:27.682215 12834 sgd_solver.cpp:106] Iteration 176000, lr = 2.2518e-06
I0506 04:58:27.684129 12834 solver.cpp:362] Iteration 176000, Testing net (#0)
I0506 04:58:27.684154 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:27.813150 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 04:58:27.813170 12834 solver.cpp:429]     Test net output #1: loss = 0.506789 (* 1 = 0.506789 loss)
I0506 04:58:27.815712 12834 solver.cpp:242] Iteration 176000 (79.0058 iter/s, 1.26573s/100 iter), loss = 0.532329
I0506 04:58:27.815733 12834 solver.cpp:261]     Train net output #0: loss = 0.532329 (* 1 = 0.532329 loss)
I0506 04:58:27.815742 12834 sgd_solver.cpp:106] Iteration 176000, lr = 2.2518e-06
I0506 04:58:28.748193 12834 solver.cpp:242] Iteration 176100 (93.8117 iter/s, 1.06597s/100 iter), loss = 3.80327
I0506 04:58:28.748245 12834 solver.cpp:261]     Train net output #0: loss = 3.80327 (* 1 = 3.80327 loss)
I0506 04:58:28.748256 12834 sgd_solver.cpp:106] Iteration 176100, lr = 2.2518e-06
I0506 04:58:28.753036 12834 solver.cpp:242] Iteration 176100 (106.691 iter/s, 0.937283s/100 iter), loss = 0.307823
I0506 04:58:28.753062 12834 solver.cpp:261]     Train net output #0: loss = 0.307823 (* 1 = 0.307823 loss)
I0506 04:58:28.753070 12834 sgd_solver.cpp:106] Iteration 176100, lr = 2.2518e-06
I0506 04:58:29.685747 12834 solver.cpp:242] Iteration 176200 (106.669 iter/s, 0.937479s/100 iter), loss = 0.800717
I0506 04:58:29.685786 12834 solver.cpp:261]     Train net output #0: loss = 0.800717 (* 1 = 0.800717 loss)
I0506 04:58:29.685796 12834 sgd_solver.cpp:106] Iteration 176200, lr = 2.2518e-06
I0506 04:58:29.690604 12834 solver.cpp:242] Iteration 176200 (106.665 iter/s, 0.937516s/100 iter), loss = 0.351705
I0506 04:58:29.690629 12834 solver.cpp:261]     Train net output #0: loss = 0.351705 (* 1 = 0.351705 loss)
I0506 04:58:29.690639 12834 sgd_solver.cpp:106] Iteration 176200, lr = 2.2518e-06
I0506 04:58:30.622956 12834 solver.cpp:242] Iteration 176300 (106.707 iter/s, 0.937143s/100 iter), loss = 1.20551
I0506 04:58:30.622994 12834 solver.cpp:261]     Train net output #0: loss = 1.20551 (* 1 = 1.20551 loss)
I0506 04:58:30.623004 12834 sgd_solver.cpp:106] Iteration 176300, lr = 2.2518e-06
I0506 04:58:30.627725 12834 solver.cpp:242] Iteration 176300 (106.715 iter/s, 0.937078s/100 iter), loss = 0.496669
I0506 04:58:30.627751 12834 solver.cpp:261]     Train net output #0: loss = 0.496669 (* 1 = 0.496669 loss)
I0506 04:58:30.627759 12834 sgd_solver.cpp:106] Iteration 176300, lr = 2.2518e-06
I0506 04:58:31.559934 12834 solver.cpp:242] Iteration 176400 (106.734 iter/s, 0.936909s/100 iter), loss = 2.31353
I0506 04:58:31.559973 12834 solver.cpp:261]     Train net output #0: loss = 2.31353 (* 1 = 2.31353 loss)
I0506 04:58:31.559983 12834 sgd_solver.cpp:106] Iteration 176400, lr = 2.2518e-06
I0506 04:58:31.564738 12834 solver.cpp:242] Iteration 176400 (106.727 iter/s, 0.936968s/100 iter), loss = 0.607601
I0506 04:58:31.564762 12834 solver.cpp:261]     Train net output #0: loss = 0.607601 (* 1 = 0.607601 loss)
I0506 04:58:31.564771 12834 sgd_solver.cpp:106] Iteration 176400, lr = 2.2518e-06
I0506 04:58:32.495023 12834 solver.cpp:362] Iteration 176500, Testing net (#0)
I0506 04:58:32.495041 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:32.617724 12834 solver.cpp:429]     Test net output #0: loss = 1.26899 (* 1 = 1.26899 loss)
I0506 04:58:32.620244 12834 solver.cpp:242] Iteration 176500 (94.3171 iter/s, 1.06025s/100 iter), loss = 0.363076
I0506 04:58:32.620265 12834 solver.cpp:261]     Train net output #0: loss = 0.363076 (* 1 = 0.363076 loss)
I0506 04:58:32.620272 12834 sgd_solver.cpp:106] Iteration 176500, lr = 2.2518e-06
I0506 04:58:32.622107 12834 solver.cpp:362] Iteration 176500, Testing net (#0)
I0506 04:58:32.622122 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:32.750777 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7815
I0506 04:58:32.750795 12834 solver.cpp:429]     Test net output #1: loss = 0.515373 (* 1 = 0.515373 loss)
I0506 04:58:32.753350 12834 solver.cpp:242] Iteration 176500 (84.1349 iter/s, 1.18857s/100 iter), loss = 0.318435
I0506 04:58:32.753381 12834 solver.cpp:261]     Train net output #0: loss = 0.318435 (* 1 = 0.318435 loss)
I0506 04:58:32.753389 12834 sgd_solver.cpp:106] Iteration 176500, lr = 2.2518e-06
I0506 04:58:33.686228 12834 solver.cpp:242] Iteration 176600 (93.8148 iter/s, 1.06593s/100 iter), loss = 0.661426
I0506 04:58:33.686261 12834 solver.cpp:261]     Train net output #0: loss = 0.661426 (* 1 = 0.661426 loss)
I0506 04:58:33.686271 12834 sgd_solver.cpp:106] Iteration 176600, lr = 2.2518e-06
I0506 04:58:33.690986 12834 solver.cpp:242] Iteration 176600 (106.657 iter/s, 0.937588s/100 iter), loss = 0.648341
I0506 04:58:33.691011 12834 solver.cpp:261]     Train net output #0: loss = 0.648341 (* 1 = 0.648341 loss)
I0506 04:58:33.691020 12834 sgd_solver.cpp:106] Iteration 176600, lr = 2.2518e-06
I0506 04:58:34.623649 12834 solver.cpp:242] Iteration 176700 (106.682 iter/s, 0.937364s/100 iter), loss = 0.755336
I0506 04:58:34.623685 12834 solver.cpp:261]     Train net output #0: loss = 0.755336 (* 1 = 0.755336 loss)
I0506 04:58:34.623695 12834 sgd_solver.cpp:106] Iteration 176700, lr = 2.2518e-06
I0506 04:58:34.628432 12834 solver.cpp:242] Iteration 176700 (106.678 iter/s, 0.937401s/100 iter), loss = 0.460719
I0506 04:58:34.628455 12834 solver.cpp:261]     Train net output #0: loss = 0.460719 (* 1 = 0.460719 loss)
I0506 04:58:34.628463 12834 sgd_solver.cpp:106] Iteration 176700, lr = 2.2518e-06
I0506 04:58:35.561796 12834 solver.cpp:242] Iteration 176800 (106.601 iter/s, 0.93808s/100 iter), loss = 1.33641
I0506 04:58:35.561836 12834 solver.cpp:261]     Train net output #0: loss = 1.33641 (* 1 = 1.33641 loss)
I0506 04:58:35.561846 12834 sgd_solver.cpp:106] Iteration 176800, lr = 2.2518e-06
I0506 04:58:35.566562 12834 solver.cpp:242] Iteration 176800 (106.6 iter/s, 0.938088s/100 iter), loss = 0.420467
I0506 04:58:35.566589 12834 solver.cpp:261]     Train net output #0: loss = 0.420467 (* 1 = 0.420467 loss)
I0506 04:58:35.566598 12834 sgd_solver.cpp:106] Iteration 176800, lr = 2.2518e-06
I0506 04:58:36.500289 12834 solver.cpp:242] Iteration 176900 (106.561 iter/s, 0.938428s/100 iter), loss = 1.02876
I0506 04:58:36.500330 12834 solver.cpp:261]     Train net output #0: loss = 1.02876 (* 1 = 1.02876 loss)
I0506 04:58:36.500339 12834 sgd_solver.cpp:106] Iteration 176900, lr = 2.2518e-06
I0506 04:58:36.505143 12834 solver.cpp:242] Iteration 176900 (106.55 iter/s, 0.938527s/100 iter), loss = 0.463186
I0506 04:58:36.505170 12834 solver.cpp:261]     Train net output #0: loss = 0.463186 (* 1 = 0.463186 loss)
I0506 04:58:36.505179 12834 sgd_solver.cpp:106] Iteration 176900, lr = 2.2518e-06
I0506 04:58:37.434965 12834 solver.cpp:362] Iteration 177000, Testing net (#0)
I0506 04:58:37.434991 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:37.557576 12834 solver.cpp:429]     Test net output #0: loss = 1.01608 (* 1 = 1.01608 loss)
I0506 04:58:37.560097 12834 solver.cpp:242] Iteration 177000 (94.3621 iter/s, 1.05975s/100 iter), loss = 0.598856
I0506 04:58:37.560122 12834 solver.cpp:261]     Train net output #0: loss = 0.598856 (* 1 = 0.598856 loss)
I0506 04:58:37.560132 12834 sgd_solver.cpp:106] Iteration 177000, lr = 2.2518e-06
I0506 04:58:37.561944 12834 solver.cpp:362] Iteration 177000, Testing net (#0)
I0506 04:58:37.561959 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:37.690809 12834 solver.cpp:429]     Test net output #0: accuracy = 0.784
I0506 04:58:37.690829 12834 solver.cpp:429]     Test net output #1: loss = 0.503742 (* 1 = 0.503742 loss)
I0506 04:58:37.693377 12834 solver.cpp:242] Iteration 177000 (84.1619 iter/s, 1.18819s/100 iter), loss = 0.599651
I0506 04:58:37.693398 12834 solver.cpp:261]     Train net output #0: loss = 0.599651 (* 1 = 0.599651 loss)
I0506 04:58:37.693406 12834 sgd_solver.cpp:106] Iteration 177000, lr = 2.2518e-06
I0506 04:58:38.625980 12834 solver.cpp:242] Iteration 177100 (93.8234 iter/s, 1.06583s/100 iter), loss = 0.896939
I0506 04:58:38.626021 12834 solver.cpp:261]     Train net output #0: loss = 0.896939 (* 1 = 0.896939 loss)
I0506 04:58:38.626039 12834 sgd_solver.cpp:106] Iteration 177100, lr = 2.2518e-06
I0506 04:58:38.630836 12834 solver.cpp:242] Iteration 177100 (106.677 iter/s, 0.93741s/100 iter), loss = 0.400467
I0506 04:58:38.630861 12834 solver.cpp:261]     Train net output #0: loss = 0.400467 (* 1 = 0.400467 loss)
I0506 04:58:38.630870 12834 sgd_solver.cpp:106] Iteration 177100, lr = 2.2518e-06
I0506 04:58:39.564112 12834 solver.cpp:242] Iteration 177200 (106.602 iter/s, 0.938065s/100 iter), loss = 0.435085
I0506 04:58:39.564165 12834 solver.cpp:261]     Train net output #0: loss = 0.435085 (* 1 = 0.435085 loss)
I0506 04:58:39.564179 12834 sgd_solver.cpp:106] Iteration 177200, lr = 2.2518e-06
I0506 04:58:39.568939 12834 solver.cpp:242] Iteration 177200 (106.603 iter/s, 0.938059s/100 iter), loss = 0.381914
I0506 04:58:39.568966 12834 solver.cpp:261]     Train net output #0: loss = 0.381914 (* 1 = 0.381914 loss)
I0506 04:58:39.568975 12834 sgd_solver.cpp:106] Iteration 177200, lr = 2.2518e-06
I0506 04:58:40.501461 12834 solver.cpp:242] Iteration 177300 (106.694 iter/s, 0.937263s/100 iter), loss = 0.670719
I0506 04:58:40.501500 12834 solver.cpp:261]     Train net output #0: loss = 0.670719 (* 1 = 0.670719 loss)
I0506 04:58:40.501510 12834 sgd_solver.cpp:106] Iteration 177300, lr = 2.2518e-06
I0506 04:58:40.506250 12834 solver.cpp:242] Iteration 177300 (106.693 iter/s, 0.937266s/100 iter), loss = 0.425118
I0506 04:58:40.506275 12834 solver.cpp:261]     Train net output #0: loss = 0.425118 (* 1 = 0.425118 loss)
I0506 04:58:40.506284 12834 sgd_solver.cpp:106] Iteration 177300, lr = 2.2518e-06
I0506 04:58:41.441632 12834 solver.cpp:242] Iteration 177400 (106.371 iter/s, 0.940106s/100 iter), loss = 1.53892
I0506 04:58:41.441675 12834 solver.cpp:261]     Train net output #0: loss = 1.53892 (* 1 = 1.53892 loss)
I0506 04:58:41.441686 12834 sgd_solver.cpp:106] Iteration 177400, lr = 2.2518e-06
I0506 04:58:41.446403 12834 solver.cpp:242] Iteration 177400 (106.371 iter/s, 0.940108s/100 iter), loss = 0.471135
I0506 04:58:41.446427 12834 solver.cpp:261]     Train net output #0: loss = 0.471135 (* 1 = 0.471135 loss)
I0506 04:58:41.446437 12834 sgd_solver.cpp:106] Iteration 177400, lr = 2.2518e-06
I0506 04:58:42.376554 12834 solver.cpp:362] Iteration 177500, Testing net (#0)
I0506 04:58:42.376580 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:42.499392 12834 solver.cpp:429]     Test net output #0: loss = 1.1529 (* 1 = 1.1529 loss)
I0506 04:58:42.501925 12834 solver.cpp:242] Iteration 177500 (94.319 iter/s, 1.06023s/100 iter), loss = 3.16448
I0506 04:58:42.501950 12834 solver.cpp:261]     Train net output #0: loss = 3.16448 (* 1 = 3.16448 loss)
I0506 04:58:42.501958 12834 sgd_solver.cpp:106] Iteration 177500, lr = 2.2518e-06
I0506 04:58:42.503779 12834 solver.cpp:362] Iteration 177500, Testing net (#0)
I0506 04:58:42.503793 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:42.632396 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7695
I0506 04:58:42.632416 12834 solver.cpp:429]     Test net output #1: loss = 0.538835 (* 1 = 0.538835 loss)
I0506 04:58:42.634987 12834 solver.cpp:242] Iteration 177500 (84.1369 iter/s, 1.18854s/100 iter), loss = 0.433103
I0506 04:58:42.635010 12834 solver.cpp:261]     Train net output #0: loss = 0.433103 (* 1 = 0.433103 loss)
I0506 04:58:42.635020 12834 sgd_solver.cpp:106] Iteration 177500, lr = 2.2518e-06
I0506 04:58:43.568174 12834 solver.cpp:242] Iteration 177600 (93.7912 iter/s, 1.0662s/100 iter), loss = 0.780764
I0506 04:58:43.568212 12834 solver.cpp:261]     Train net output #0: loss = 0.780764 (* 1 = 0.780764 loss)
I0506 04:58:43.568222 12834 sgd_solver.cpp:106] Iteration 177600, lr = 2.2518e-06
I0506 04:58:43.572952 12834 solver.cpp:242] Iteration 177600 (106.618 iter/s, 0.937924s/100 iter), loss = 0.420549
I0506 04:58:43.572976 12834 solver.cpp:261]     Train net output #0: loss = 0.420549 (* 1 = 0.420549 loss)
I0506 04:58:43.572985 12834 sgd_solver.cpp:106] Iteration 177600, lr = 2.2518e-06
I0506 04:58:44.505436 12834 solver.cpp:242] Iteration 177700 (106.702 iter/s, 0.937193s/100 iter), loss = 0.70678
I0506 04:58:44.505484 12834 solver.cpp:261]     Train net output #0: loss = 0.70678 (* 1 = 0.70678 loss)
I0506 04:58:44.505494 12834 sgd_solver.cpp:106] Iteration 177700, lr = 2.2518e-06
I0506 04:58:44.510221 12834 solver.cpp:242] Iteration 177700 (106.698 iter/s, 0.937226s/100 iter), loss = 0.499713
I0506 04:58:44.510246 12834 solver.cpp:261]     Train net output #0: loss = 0.499713 (* 1 = 0.499713 loss)
I0506 04:58:44.510255 12834 sgd_solver.cpp:106] Iteration 177700, lr = 2.2518e-06
I0506 04:58:45.443500 12834 solver.cpp:242] Iteration 177800 (106.611 iter/s, 0.937993s/100 iter), loss = 1.08731
I0506 04:58:45.443536 12834 solver.cpp:261]     Train net output #0: loss = 1.08731 (* 1 = 1.08731 loss)
I0506 04:58:45.443545 12834 sgd_solver.cpp:106] Iteration 177800, lr = 2.2518e-06
I0506 04:58:45.448346 12834 solver.cpp:242] Iteration 177800 (106.602 iter/s, 0.938072s/100 iter), loss = 0.44188
I0506 04:58:45.448371 12834 solver.cpp:261]     Train net output #0: loss = 0.44188 (* 1 = 0.44188 loss)
I0506 04:58:45.448380 12834 sgd_solver.cpp:106] Iteration 177800, lr = 2.2518e-06
I0506 04:58:46.381386 12834 solver.cpp:242] Iteration 177900 (106.63 iter/s, 0.937822s/100 iter), loss = 2.18184
I0506 04:58:46.381417 12834 solver.cpp:261]     Train net output #0: loss = 2.18184 (* 1 = 2.18184 loss)
I0506 04:58:46.381427 12834 sgd_solver.cpp:106] Iteration 177900, lr = 2.2518e-06
I0506 04:58:46.386138 12834 solver.cpp:242] Iteration 177900 (106.638 iter/s, 0.93775s/100 iter), loss = 0.85587
I0506 04:58:46.386162 12834 solver.cpp:261]     Train net output #0: loss = 0.85587 (* 1 = 0.85587 loss)
I0506 04:58:46.386171 12834 sgd_solver.cpp:106] Iteration 177900, lr = 2.2518e-06
I0506 04:58:47.315871 12834 solver.cpp:362] Iteration 178000, Testing net (#0)
I0506 04:58:47.315897 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:47.438606 12834 solver.cpp:429]     Test net output #0: loss = 1.25469 (* 1 = 1.25469 loss)
I0506 04:58:47.441124 12834 solver.cpp:242] Iteration 178000 (94.3674 iter/s, 1.05969s/100 iter), loss = 0.343126
I0506 04:58:47.441145 12834 solver.cpp:261]     Train net output #0: loss = 0.343126 (* 1 = 0.343126 loss)
I0506 04:58:47.441154 12834 sgd_solver.cpp:106] Iteration 178000, lr = 2.2518e-06
I0506 04:58:47.443053 12834 solver.cpp:362] Iteration 178000, Testing net (#0)
I0506 04:58:47.443066 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:47.571971 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7775
I0506 04:58:47.571991 12834 solver.cpp:429]     Test net output #1: loss = 0.497634 (* 1 = 0.497634 loss)
I0506 04:58:47.574554 12834 solver.cpp:242] Iteration 178000 (84.1488 iter/s, 1.18837s/100 iter), loss = 0.224456
I0506 04:58:47.574574 12834 solver.cpp:261]     Train net output #0: loss = 0.224456 (* 1 = 0.224456 loss)
I0506 04:58:47.574584 12834 sgd_solver.cpp:106] Iteration 178000, lr = 2.2518e-06
I0506 04:58:48.508143 12834 solver.cpp:242] Iteration 178100 (93.7234 iter/s, 1.06697s/100 iter), loss = 1.2396
I0506 04:58:48.508178 12834 solver.cpp:261]     Train net output #0: loss = 1.2396 (* 1 = 1.2396 loss)
I0506 04:58:48.508188 12834 sgd_solver.cpp:106] Iteration 178100, lr = 2.2518e-06
I0506 04:58:48.512925 12834 solver.cpp:242] Iteration 178100 (106.572 iter/s, 0.938331s/100 iter), loss = 0.248258
I0506 04:58:48.512949 12834 solver.cpp:261]     Train net output #0: loss = 0.248258 (* 1 = 0.248258 loss)
I0506 04:58:48.512959 12834 sgd_solver.cpp:106] Iteration 178100, lr = 2.2518e-06
I0506 04:58:49.445863 12834 solver.cpp:242] Iteration 178200 (106.649 iter/s, 0.937652s/100 iter), loss = 1.44435
I0506 04:58:49.445905 12834 solver.cpp:261]     Train net output #0: loss = 1.44435 (* 1 = 1.44435 loss)
I0506 04:58:49.445915 12834 sgd_solver.cpp:106] Iteration 178200, lr = 2.2518e-06
I0506 04:58:49.450623 12834 solver.cpp:242] Iteration 178200 (106.649 iter/s, 0.937654s/100 iter), loss = 0.585784
I0506 04:58:49.450649 12834 solver.cpp:261]     Train net output #0: loss = 0.585784 (* 1 = 0.585784 loss)
I0506 04:58:49.450657 12834 sgd_solver.cpp:106] Iteration 178200, lr = 2.2518e-06
I0506 04:58:50.383476 12834 solver.cpp:242] Iteration 178300 (106.662 iter/s, 0.937545s/100 iter), loss = 2.64642
I0506 04:58:50.383517 12834 solver.cpp:261]     Train net output #0: loss = 2.64642 (* 1 = 2.64642 loss)
I0506 04:58:50.383527 12834 sgd_solver.cpp:106] Iteration 178300, lr = 2.2518e-06
I0506 04:58:50.388245 12834 solver.cpp:242] Iteration 178300 (106.658 iter/s, 0.937578s/100 iter), loss = 0.779897
I0506 04:58:50.388272 12834 solver.cpp:261]     Train net output #0: loss = 0.779897 (* 1 = 0.779897 loss)
I0506 04:58:50.388279 12834 sgd_solver.cpp:106] Iteration 178300, lr = 2.2518e-06
I0506 04:58:51.323019 12834 solver.cpp:242] Iteration 178400 (106.443 iter/s, 0.939471s/100 iter), loss = 0.500669
I0506 04:58:51.323056 12834 solver.cpp:261]     Train net output #0: loss = 0.500669 (* 1 = 0.500669 loss)
I0506 04:58:51.323066 12834 sgd_solver.cpp:106] Iteration 178400, lr = 2.2518e-06
I0506 04:58:51.327790 12834 solver.cpp:242] Iteration 178400 (106.44 iter/s, 0.939501s/100 iter), loss = 0.522464
I0506 04:58:51.327813 12834 solver.cpp:261]     Train net output #0: loss = 0.522464 (* 1 = 0.522464 loss)
I0506 04:58:51.327822 12834 sgd_solver.cpp:106] Iteration 178400, lr = 2.2518e-06
I0506 04:58:52.257493 12834 solver.cpp:362] Iteration 178500, Testing net (#0)
I0506 04:58:52.257520 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:52.380327 12834 solver.cpp:429]     Test net output #0: loss = 1.1228 (* 1 = 1.1228 loss)
I0506 04:58:52.382853 12834 solver.cpp:242] Iteration 178500 (94.3595 iter/s, 1.05978s/100 iter), loss = 0.623012
I0506 04:58:52.382874 12834 solver.cpp:261]     Train net output #0: loss = 0.623012 (* 1 = 0.623012 loss)
I0506 04:58:52.382882 12834 sgd_solver.cpp:106] Iteration 178500, lr = 2.2518e-06
I0506 04:58:52.384701 12834 solver.cpp:362] Iteration 178500, Testing net (#0)
I0506 04:58:52.384716 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:52.513336 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7905
I0506 04:58:52.513357 12834 solver.cpp:429]     Test net output #1: loss = 0.493793 (* 1 = 0.493793 loss)
I0506 04:58:52.515913 12834 solver.cpp:242] Iteration 178500 (84.1695 iter/s, 1.18808s/100 iter), loss = 0.481675
I0506 04:58:52.515933 12834 solver.cpp:261]     Train net output #0: loss = 0.481675 (* 1 = 0.481675 loss)
I0506 04:58:52.515941 12834 sgd_solver.cpp:106] Iteration 178500, lr = 2.2518e-06
I0506 04:58:53.449829 12834 solver.cpp:242] Iteration 178600 (93.7276 iter/s, 1.06692s/100 iter), loss = 1.46648
I0506 04:58:53.449868 12834 solver.cpp:261]     Train net output #0: loss = 1.46648 (* 1 = 1.46648 loss)
I0506 04:58:53.449878 12834 sgd_solver.cpp:106] Iteration 178600, lr = 2.2518e-06
I0506 04:58:53.454614 12834 solver.cpp:242] Iteration 178600 (106.534 iter/s, 0.938664s/100 iter), loss = 0.45941
I0506 04:58:53.454641 12834 solver.cpp:261]     Train net output #0: loss = 0.45941 (* 1 = 0.45941 loss)
I0506 04:58:53.454650 12834 sgd_solver.cpp:106] Iteration 178600, lr = 2.2518e-06
I0506 04:58:54.387711 12834 solver.cpp:242] Iteration 178700 (106.631 iter/s, 0.937817s/100 iter), loss = 6.32631
I0506 04:58:54.387748 12834 solver.cpp:261]     Train net output #0: loss = 6.32631 (* 1 = 6.32631 loss)
I0506 04:58:54.387756 12834 sgd_solver.cpp:106] Iteration 178700, lr = 2.2518e-06
I0506 04:58:54.392577 12834 solver.cpp:242] Iteration 178700 (106.62 iter/s, 0.937907s/100 iter), loss = 0.665514
I0506 04:58:54.392603 12834 solver.cpp:261]     Train net output #0: loss = 0.665514 (* 1 = 0.665514 loss)
I0506 04:58:54.392612 12834 sgd_solver.cpp:106] Iteration 178700, lr = 2.2518e-06
I0506 04:58:55.325098 12834 solver.cpp:242] Iteration 178800 (106.687 iter/s, 0.937324s/100 iter), loss = 0.706899
I0506 04:58:55.325134 12834 solver.cpp:261]     Train net output #0: loss = 0.706899 (* 1 = 0.706899 loss)
I0506 04:58:55.325143 12834 sgd_solver.cpp:106] Iteration 178800, lr = 2.2518e-06
I0506 04:58:55.329885 12834 solver.cpp:242] Iteration 178800 (106.694 iter/s, 0.937264s/100 iter), loss = 0.33349
I0506 04:58:55.329921 12834 solver.cpp:261]     Train net output #0: loss = 0.33349 (* 1 = 0.33349 loss)
I0506 04:58:55.329931 12834 sgd_solver.cpp:106] Iteration 178800, lr = 2.2518e-06
I0506 04:58:56.263211 12834 solver.cpp:242] Iteration 178900 (106.604 iter/s, 0.938054s/100 iter), loss = 0.737992
I0506 04:58:56.263247 12834 solver.cpp:261]     Train net output #0: loss = 0.737992 (* 1 = 0.737992 loss)
I0506 04:58:56.263257 12834 sgd_solver.cpp:106] Iteration 178900, lr = 2.2518e-06
I0506 04:58:56.268045 12834 solver.cpp:242] Iteration 178900 (106.599 iter/s, 0.938098s/100 iter), loss = 0.424346
I0506 04:58:56.268069 12834 solver.cpp:261]     Train net output #0: loss = 0.424346 (* 1 = 0.424346 loss)
I0506 04:58:56.268079 12834 sgd_solver.cpp:106] Iteration 178900, lr = 2.2518e-06
I0506 04:58:57.197827 12834 solver.cpp:362] Iteration 179000, Testing net (#0)
I0506 04:58:57.197849 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:57.320389 12834 solver.cpp:429]     Test net output #0: loss = 1.15134 (* 1 = 1.15134 loss)
I0506 04:58:57.322911 12834 solver.cpp:242] Iteration 179000 (94.3712 iter/s, 1.05965s/100 iter), loss = 0.565901
I0506 04:58:57.322931 12834 solver.cpp:261]     Train net output #0: loss = 0.565901 (* 1 = 0.565901 loss)
I0506 04:58:57.322939 12834 sgd_solver.cpp:106] Iteration 179000, lr = 2.2518e-06
I0506 04:58:57.324767 12834 solver.cpp:362] Iteration 179000, Testing net (#0)
I0506 04:58:57.324782 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:58:57.453361 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7945
I0506 04:58:57.453382 12834 solver.cpp:429]     Test net output #1: loss = 0.483626 (* 1 = 0.483626 loss)
I0506 04:58:57.455934 12834 solver.cpp:242] Iteration 179000 (84.1862 iter/s, 1.18784s/100 iter), loss = 0.269785
I0506 04:58:57.455953 12834 solver.cpp:261]     Train net output #0: loss = 0.269785 (* 1 = 0.269785 loss)
I0506 04:58:57.455961 12834 sgd_solver.cpp:106] Iteration 179000, lr = 2.2518e-06
I0506 04:58:58.388545 12834 solver.cpp:242] Iteration 179100 (93.8455 iter/s, 1.06558s/100 iter), loss = 0.545091
I0506 04:58:58.388599 12834 solver.cpp:261]     Train net output #0: loss = 0.545091 (* 1 = 0.545091 loss)
I0506 04:58:58.388608 12834 sgd_solver.cpp:106] Iteration 179100, lr = 2.2518e-06
I0506 04:58:58.393344 12834 solver.cpp:242] Iteration 179100 (106.681 iter/s, 0.937372s/100 iter), loss = 0.483995
I0506 04:58:58.393369 12834 solver.cpp:261]     Train net output #0: loss = 0.483995 (* 1 = 0.483995 loss)
I0506 04:58:58.393378 12834 sgd_solver.cpp:106] Iteration 179100, lr = 2.2518e-06
I0506 04:58:59.326437 12834 solver.cpp:242] Iteration 179200 (106.631 iter/s, 0.937816s/100 iter), loss = 1.15996
I0506 04:58:59.326467 12834 solver.cpp:261]     Train net output #0: loss = 1.15996 (* 1 = 1.15996 loss)
I0506 04:58:59.326475 12834 sgd_solver.cpp:106] Iteration 179200, lr = 2.2518e-06
I0506 04:58:59.331208 12834 solver.cpp:242] Iteration 179200 (106.63 iter/s, 0.93782s/100 iter), loss = 0.669305
I0506 04:58:59.331233 12834 solver.cpp:261]     Train net output #0: loss = 0.669305 (* 1 = 0.669305 loss)
I0506 04:58:59.331241 12834 sgd_solver.cpp:106] Iteration 179200, lr = 2.2518e-06
I0506 04:59:00.275274 12834 solver.cpp:242] Iteration 179300 (105.399 iter/s, 0.948772s/100 iter), loss = 0.933946
I0506 04:59:00.275324 12834 solver.cpp:261]     Train net output #0: loss = 0.933946 (* 1 = 0.933946 loss)
I0506 04:59:00.275334 12834 sgd_solver.cpp:106] Iteration 179300, lr = 2.2518e-06
I0506 04:59:00.280110 12834 solver.cpp:242] Iteration 179300 (105.39 iter/s, 0.94886s/100 iter), loss = 0.446942
I0506 04:59:00.280138 12834 solver.cpp:261]     Train net output #0: loss = 0.446942 (* 1 = 0.446942 loss)
I0506 04:59:00.280146 12834 sgd_solver.cpp:106] Iteration 179300, lr = 2.2518e-06
I0506 04:59:01.218438 12834 solver.cpp:242] Iteration 179400 (106.035 iter/s, 0.943089s/100 iter), loss = 0.874573
I0506 04:59:01.218482 12834 solver.cpp:261]     Train net output #0: loss = 0.874573 (* 1 = 0.874573 loss)
I0506 04:59:01.218492 12834 sgd_solver.cpp:106] Iteration 179400, lr = 2.2518e-06
I0506 04:59:01.223282 12834 solver.cpp:242] Iteration 179400 (106.03 iter/s, 0.943126s/100 iter), loss = 0.373575
I0506 04:59:01.223309 12834 solver.cpp:261]     Train net output #0: loss = 0.373575 (* 1 = 0.373575 loss)
I0506 04:59:01.223318 12834 sgd_solver.cpp:106] Iteration 179400, lr = 2.2518e-06
I0506 04:59:02.153945 12834 solver.cpp:362] Iteration 179500, Testing net (#0)
I0506 04:59:02.153972 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:02.276558 12834 solver.cpp:429]     Test net output #0: loss = 1.29363 (* 1 = 1.29363 loss)
I0506 04:59:02.279078 12834 solver.cpp:242] Iteration 179500 (94.2883 iter/s, 1.06058s/100 iter), loss = 1.28528
I0506 04:59:02.279101 12834 solver.cpp:261]     Train net output #0: loss = 1.28528 (* 1 = 1.28528 loss)
I0506 04:59:02.279110 12834 sgd_solver.cpp:106] Iteration 179500, lr = 2.2518e-06
I0506 04:59:02.280930 12834 solver.cpp:362] Iteration 179500, Testing net (#0)
I0506 04:59:02.280942 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:02.409940 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7845
I0506 04:59:02.409960 12834 solver.cpp:429]     Test net output #1: loss = 0.493762 (* 1 = 0.493762 loss)
I0506 04:59:02.412524 12834 solver.cpp:242] Iteration 179500 (84.0905 iter/s, 1.1892s/100 iter), loss = 0.574753
I0506 04:59:02.412546 12834 solver.cpp:261]     Train net output #0: loss = 0.574753 (* 1 = 0.574753 loss)
I0506 04:59:02.412560 12834 sgd_solver.cpp:106] Iteration 179500, lr = 2.2518e-06
I0506 04:59:03.346285 12834 solver.cpp:242] Iteration 179600 (93.7071 iter/s, 1.06716s/100 iter), loss = 1.08264
I0506 04:59:03.346326 12834 solver.cpp:261]     Train net output #0: loss = 1.08264 (* 1 = 1.08264 loss)
I0506 04:59:03.346335 12834 sgd_solver.cpp:106] Iteration 179600, lr = 2.2518e-06
I0506 04:59:03.351140 12834 solver.cpp:242] Iteration 179600 (106.546 iter/s, 0.938565s/100 iter), loss = 0.989278
I0506 04:59:03.351166 12834 solver.cpp:261]     Train net output #0: loss = 0.989278 (* 1 = 0.989278 loss)
I0506 04:59:03.351174 12834 sgd_solver.cpp:106] Iteration 179600, lr = 2.2518e-06
I0506 04:59:04.283499 12834 solver.cpp:242] Iteration 179700 (106.707 iter/s, 0.937145s/100 iter), loss = 0.922638
I0506 04:59:04.283538 12834 solver.cpp:261]     Train net output #0: loss = 0.922638 (* 1 = 0.922638 loss)
I0506 04:59:04.283548 12834 sgd_solver.cpp:106] Iteration 179700, lr = 2.2518e-06
I0506 04:59:04.288293 12834 solver.cpp:242] Iteration 179700 (106.711 iter/s, 0.93711s/100 iter), loss = 0.63663
I0506 04:59:04.288318 12834 solver.cpp:261]     Train net output #0: loss = 0.63663 (* 1 = 0.63663 loss)
I0506 04:59:04.288327 12834 sgd_solver.cpp:106] Iteration 179700, lr = 2.2518e-06
I0506 04:59:05.221458 12834 solver.cpp:242] Iteration 179800 (106.622 iter/s, 0.937895s/100 iter), loss = 0.418406
I0506 04:59:05.221496 12834 solver.cpp:261]     Train net output #0: loss = 0.418406 (* 1 = 0.418406 loss)
I0506 04:59:05.221506 12834 sgd_solver.cpp:106] Iteration 179800, lr = 2.2518e-06
I0506 04:59:05.226292 12834 solver.cpp:242] Iteration 179800 (106.616 iter/s, 0.937947s/100 iter), loss = 0.565299
I0506 04:59:05.226317 12834 solver.cpp:261]     Train net output #0: loss = 0.565299 (* 1 = 0.565299 loss)
I0506 04:59:05.226327 12834 sgd_solver.cpp:106] Iteration 179800, lr = 2.2518e-06
I0506 04:59:06.159643 12834 solver.cpp:242] Iteration 179900 (106.596 iter/s, 0.93812s/100 iter), loss = 0.586714
I0506 04:59:06.159680 12834 solver.cpp:261]     Train net output #0: loss = 0.586714 (* 1 = 0.586714 loss)
I0506 04:59:06.159689 12834 sgd_solver.cpp:106] Iteration 179900, lr = 2.2518e-06
I0506 04:59:06.164425 12834 solver.cpp:242] Iteration 179900 (106.6 iter/s, 0.938088s/100 iter), loss = 0.549911
I0506 04:59:06.164449 12834 solver.cpp:261]     Train net output #0: loss = 0.549911 (* 1 = 0.549911 loss)
I0506 04:59:06.164458 12834 sgd_solver.cpp:106] Iteration 179900, lr = 2.2518e-06
I0506 04:59:07.094004 12834 solver.cpp:362] Iteration 180000, Testing net (#0)
I0506 04:59:07.094029 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:07.216936 12834 solver.cpp:429]     Test net output #0: loss = 1.22496 (* 1 = 1.22496 loss)
I0506 04:59:07.219452 12834 solver.cpp:242] Iteration 180000 (94.3615 iter/s, 1.05975s/100 iter), loss = 0.422246
I0506 04:59:07.219472 12834 solver.cpp:261]     Train net output #0: loss = 0.422246 (* 1 = 0.422246 loss)
I0506 04:59:07.219481 12834 sgd_solver.cpp:106] Iteration 180000, lr = 1.80144e-06
I0506 04:59:07.221343 12834 solver.cpp:362] Iteration 180000, Testing net (#0)
I0506 04:59:07.221359 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:07.350551 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7705
I0506 04:59:07.350572 12834 solver.cpp:429]     Test net output #1: loss = 0.515132 (* 1 = 0.515132 loss)
I0506 04:59:07.353124 12834 solver.cpp:242] Iteration 180000 (84.1287 iter/s, 1.18865s/100 iter), loss = 0.313519
I0506 04:59:07.353145 12834 solver.cpp:261]     Train net output #0: loss = 0.313519 (* 1 = 0.313519 loss)
I0506 04:59:07.353153 12834 sgd_solver.cpp:106] Iteration 180000, lr = 1.80144e-06
I0506 04:59:08.286844 12834 solver.cpp:242] Iteration 180100 (93.6907 iter/s, 1.06734s/100 iter), loss = 0.806161
I0506 04:59:08.286882 12834 solver.cpp:261]     Train net output #0: loss = 0.806161 (* 1 = 0.806161 loss)
I0506 04:59:08.286891 12834 sgd_solver.cpp:106] Iteration 180100, lr = 1.80144e-06
I0506 04:59:08.291623 12834 solver.cpp:242] Iteration 180100 (106.558 iter/s, 0.938459s/100 iter), loss = 0.376511
I0506 04:59:08.291649 12834 solver.cpp:261]     Train net output #0: loss = 0.376511 (* 1 = 0.376511 loss)
I0506 04:59:08.291658 12834 sgd_solver.cpp:106] Iteration 180100, lr = 1.80144e-06
I0506 04:59:09.224303 12834 solver.cpp:242] Iteration 180200 (106.679 iter/s, 0.937388s/100 iter), loss = 1.82237
I0506 04:59:09.224342 12834 solver.cpp:261]     Train net output #0: loss = 1.82237 (* 1 = 1.82237 loss)
I0506 04:59:09.224351 12834 sgd_solver.cpp:106] Iteration 180200, lr = 1.80144e-06
I0506 04:59:09.229113 12834 solver.cpp:242] Iteration 180200 (106.673 iter/s, 0.937445s/100 iter), loss = 0.532845
I0506 04:59:09.229140 12834 solver.cpp:261]     Train net output #0: loss = 0.532845 (* 1 = 0.532845 loss)
I0506 04:59:09.229148 12834 sgd_solver.cpp:106] Iteration 180200, lr = 1.80144e-06
I0506 04:59:10.161931 12834 solver.cpp:242] Iteration 180300 (106.659 iter/s, 0.937566s/100 iter), loss = 2.45447
I0506 04:59:10.161960 12834 solver.cpp:261]     Train net output #0: loss = 2.45447 (* 1 = 2.45447 loss)
I0506 04:59:10.161970 12834 sgd_solver.cpp:106] Iteration 180300, lr = 1.80144e-06
I0506 04:59:10.166692 12834 solver.cpp:242] Iteration 180300 (106.663 iter/s, 0.937533s/100 iter), loss = 0.476162
I0506 04:59:10.166714 12834 solver.cpp:261]     Train net output #0: loss = 0.476162 (* 1 = 0.476162 loss)
I0506 04:59:10.166723 12834 sgd_solver.cpp:106] Iteration 180300, lr = 1.80144e-06
I0506 04:59:11.099458 12834 solver.cpp:242] Iteration 180400 (106.67 iter/s, 0.937467s/100 iter), loss = 1.23179
I0506 04:59:11.099500 12834 solver.cpp:261]     Train net output #0: loss = 1.23179 (* 1 = 1.23179 loss)
I0506 04:59:11.099509 12834 sgd_solver.cpp:106] Iteration 180400, lr = 1.80144e-06
I0506 04:59:11.104244 12834 solver.cpp:242] Iteration 180400 (106.665 iter/s, 0.937511s/100 iter), loss = 0.40503
I0506 04:59:11.104269 12834 solver.cpp:261]     Train net output #0: loss = 0.40503 (* 1 = 0.40503 loss)
I0506 04:59:11.104279 12834 sgd_solver.cpp:106] Iteration 180400, lr = 1.80144e-06
I0506 04:59:12.033941 12834 solver.cpp:362] Iteration 180500, Testing net (#0)
I0506 04:59:12.033982 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:12.156826 12834 solver.cpp:429]     Test net output #0: loss = 1.20294 (* 1 = 1.20294 loss)
I0506 04:59:12.159356 12834 solver.cpp:242] Iteration 180500 (94.3541 iter/s, 1.05984s/100 iter), loss = 2.61261
I0506 04:59:12.159379 12834 solver.cpp:261]     Train net output #0: loss = 2.61261 (* 1 = 2.61261 loss)
I0506 04:59:12.159389 12834 sgd_solver.cpp:106] Iteration 180500, lr = 1.80144e-06
I0506 04:59:12.161283 12834 solver.cpp:362] Iteration 180500, Testing net (#0)
I0506 04:59:12.161305 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:12.290612 12834 solver.cpp:429]     Test net output #0: accuracy = 0.77
I0506 04:59:12.290632 12834 solver.cpp:429]     Test net output #1: loss = 0.523916 (* 1 = 0.523916 loss)
I0506 04:59:12.293211 12834 solver.cpp:242] Iteration 180500 (84.1099 iter/s, 1.18892s/100 iter), loss = 0.552305
I0506 04:59:12.293233 12834 solver.cpp:261]     Train net output #0: loss = 0.552305 (* 1 = 0.552305 loss)
I0506 04:59:12.293242 12834 sgd_solver.cpp:106] Iteration 180500, lr = 1.80144e-06
I0506 04:59:13.226712 12834 solver.cpp:242] Iteration 180600 (93.6942 iter/s, 1.0673s/100 iter), loss = 3.13553
I0506 04:59:13.226754 12834 solver.cpp:261]     Train net output #0: loss = 3.13553 (* 1 = 3.13553 loss)
I0506 04:59:13.226763 12834 sgd_solver.cpp:106] Iteration 180600, lr = 1.80144e-06
I0506 04:59:13.231487 12834 solver.cpp:242] Iteration 180600 (106.583 iter/s, 0.938236s/100 iter), loss = 0.609707
I0506 04:59:13.231514 12834 solver.cpp:261]     Train net output #0: loss = 0.609707 (* 1 = 0.609707 loss)
I0506 04:59:13.231523 12834 sgd_solver.cpp:106] Iteration 180600, lr = 1.80144e-06
I0506 04:59:14.184746 12834 solver.cpp:242] Iteration 180700 (104.388 iter/s, 0.957965s/100 iter), loss = 0.240703
I0506 04:59:14.184792 12834 solver.cpp:261]     Train net output #0: loss = 0.240703 (* 1 = 0.240703 loss)
I0506 04:59:14.184803 12834 sgd_solver.cpp:106] Iteration 180700, lr = 1.80144e-06
I0506 04:59:14.189612 12834 solver.cpp:242] Iteration 180700 (104.377 iter/s, 0.95807s/100 iter), loss = 0.632779
I0506 04:59:14.189641 12834 solver.cpp:261]     Train net output #0: loss = 0.632779 (* 1 = 0.632779 loss)
I0506 04:59:14.189651 12834 sgd_solver.cpp:106] Iteration 180700, lr = 1.80144e-06
I0506 04:59:15.122184 12834 solver.cpp:242] Iteration 180800 (106.682 iter/s, 0.937364s/100 iter), loss = 0.597091
I0506 04:59:15.122223 12834 solver.cpp:261]     Train net output #0: loss = 0.597091 (* 1 = 0.597091 loss)
I0506 04:59:15.122233 12834 sgd_solver.cpp:106] Iteration 180800, lr = 1.80144e-06
I0506 04:59:15.126963 12834 solver.cpp:242] Iteration 180800 (106.689 iter/s, 0.937305s/100 iter), loss = 0.713878
I0506 04:59:15.126988 12834 solver.cpp:261]     Train net output #0: loss = 0.713878 (* 1 = 0.713878 loss)
I0506 04:59:15.126997 12834 sgd_solver.cpp:106] Iteration 180800, lr = 1.80144e-06
I0506 04:59:16.060355 12834 solver.cpp:242] Iteration 180900 (106.598 iter/s, 0.938101s/100 iter), loss = 0.815092
I0506 04:59:16.060396 12834 solver.cpp:261]     Train net output #0: loss = 0.815092 (* 1 = 0.815092 loss)
I0506 04:59:16.060406 12834 sgd_solver.cpp:106] Iteration 180900, lr = 1.80144e-06
I0506 04:59:16.065136 12834 solver.cpp:242] Iteration 180900 (106.595 iter/s, 0.93813s/100 iter), loss = 0.290524
I0506 04:59:16.065161 12834 solver.cpp:261]     Train net output #0: loss = 0.290524 (* 1 = 0.290524 loss)
I0506 04:59:16.065171 12834 sgd_solver.cpp:106] Iteration 180900, lr = 1.80144e-06
I0506 04:59:16.995827 12834 solver.cpp:362] Iteration 181000, Testing net (#0)
I0506 04:59:16.995854 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:17.118844 12834 solver.cpp:429]     Test net output #0: loss = 1.05795 (* 1 = 1.05795 loss)
I0506 04:59:17.121361 12834 solver.cpp:242] Iteration 181000 (94.2555 iter/s, 1.06095s/100 iter), loss = 3.96984
I0506 04:59:17.121384 12834 solver.cpp:261]     Train net output #0: loss = 3.96984 (* 1 = 3.96984 loss)
I0506 04:59:17.121393 12834 sgd_solver.cpp:106] Iteration 181000, lr = 1.80144e-06
I0506 04:59:17.123211 12834 solver.cpp:362] Iteration 181000, Testing net (#0)
I0506 04:59:17.123225 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:17.251739 12834 solver.cpp:429]     Test net output #0: accuracy = 0.785
I0506 04:59:17.251772 12834 solver.cpp:429]     Test net output #1: loss = 0.487461 (* 1 = 0.487461 loss)
I0506 04:59:17.254340 12834 solver.cpp:242] Iteration 181000 (84.0932 iter/s, 1.18916s/100 iter), loss = 0.740513
I0506 04:59:17.254364 12834 solver.cpp:261]     Train net output #0: loss = 0.740513 (* 1 = 0.740513 loss)
I0506 04:59:17.254381 12834 sgd_solver.cpp:106] Iteration 181000, lr = 1.80144e-06
I0506 04:59:18.187777 12834 solver.cpp:242] Iteration 181100 (93.7772 iter/s, 1.06636s/100 iter), loss = 1.30187
I0506 04:59:18.187815 12834 solver.cpp:261]     Train net output #0: loss = 1.30187 (* 1 = 1.30187 loss)
I0506 04:59:18.187825 12834 sgd_solver.cpp:106] Iteration 181100, lr = 1.80144e-06
I0506 04:59:18.192567 12834 solver.cpp:242] Iteration 181100 (106.589 iter/s, 0.938185s/100 iter), loss = 0.741684
I0506 04:59:18.192594 12834 solver.cpp:261]     Train net output #0: loss = 0.741684 (* 1 = 0.741684 loss)
I0506 04:59:18.192602 12834 sgd_solver.cpp:106] Iteration 181100, lr = 1.80144e-06
I0506 04:59:19.125075 12834 solver.cpp:242] Iteration 181200 (106.697 iter/s, 0.937234s/100 iter), loss = 0.488298
I0506 04:59:19.125113 12834 solver.cpp:261]     Train net output #0: loss = 0.488298 (* 1 = 0.488298 loss)
I0506 04:59:19.125123 12834 sgd_solver.cpp:106] Iteration 181200, lr = 1.80144e-06
I0506 04:59:19.129849 12834 solver.cpp:242] Iteration 181200 (106.697 iter/s, 0.937238s/100 iter), loss = 0.303312
I0506 04:59:19.129875 12834 solver.cpp:261]     Train net output #0: loss = 0.303312 (* 1 = 0.303312 loss)
I0506 04:59:19.129884 12834 sgd_solver.cpp:106] Iteration 181200, lr = 1.80144e-06
I0506 04:59:20.063031 12834 solver.cpp:242] Iteration 181300 (106.623 iter/s, 0.937888s/100 iter), loss = 1.18168
I0506 04:59:20.063071 12834 solver.cpp:261]     Train net output #0: loss = 1.18168 (* 1 = 1.18168 loss)
I0506 04:59:20.063079 12834 sgd_solver.cpp:106] Iteration 181300, lr = 1.80144e-06
I0506 04:59:20.067837 12834 solver.cpp:242] Iteration 181300 (106.616 iter/s, 0.937944s/100 iter), loss = 0.591379
I0506 04:59:20.067862 12834 solver.cpp:261]     Train net output #0: loss = 0.591379 (* 1 = 0.591379 loss)
I0506 04:59:20.067872 12834 sgd_solver.cpp:106] Iteration 181300, lr = 1.80144e-06
I0506 04:59:21.000687 12834 solver.cpp:242] Iteration 181400 (106.656 iter/s, 0.937594s/100 iter), loss = 0.681228
I0506 04:59:21.000720 12834 solver.cpp:261]     Train net output #0: loss = 0.681228 (* 1 = 0.681228 loss)
I0506 04:59:21.000730 12834 sgd_solver.cpp:106] Iteration 181400, lr = 1.80144e-06
I0506 04:59:21.005445 12834 solver.cpp:242] Iteration 181400 (106.659 iter/s, 0.937565s/100 iter), loss = 0.362116
I0506 04:59:21.005470 12834 solver.cpp:261]     Train net output #0: loss = 0.362116 (* 1 = 0.362116 loss)
I0506 04:59:21.005480 12834 sgd_solver.cpp:106] Iteration 181400, lr = 1.80144e-06
I0506 04:59:21.935669 12834 solver.cpp:362] Iteration 181500, Testing net (#0)
I0506 04:59:21.935696 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:22.058425 12834 solver.cpp:429]     Test net output #0: loss = 1.2806 (* 1 = 1.2806 loss)
I0506 04:59:22.060935 12834 solver.cpp:242] Iteration 181500 (94.3221 iter/s, 1.0602s/100 iter), loss = 0.455402
I0506 04:59:22.060956 12834 solver.cpp:261]     Train net output #0: loss = 0.455402 (* 1 = 0.455402 loss)
I0506 04:59:22.060966 12834 sgd_solver.cpp:106] Iteration 181500, lr = 1.80144e-06
I0506 04:59:22.062786 12834 solver.cpp:362] Iteration 181500, Testing net (#0)
I0506 04:59:22.062799 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:22.191509 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7865
I0506 04:59:22.191529 12834 solver.cpp:429]     Test net output #1: loss = 0.494683 (* 1 = 0.494683 loss)
I0506 04:59:22.194103 12834 solver.cpp:242] Iteration 181500 (84.1317 iter/s, 1.18861s/100 iter), loss = 0.657414
I0506 04:59:22.194124 12834 solver.cpp:261]     Train net output #0: loss = 0.657414 (* 1 = 0.657414 loss)
I0506 04:59:22.194133 12834 sgd_solver.cpp:106] Iteration 181500, lr = 1.80144e-06
I0506 04:59:23.127938 12834 solver.cpp:242] Iteration 181600 (93.7247 iter/s, 1.06695s/100 iter), loss = 2.51973
I0506 04:59:23.127974 12834 solver.cpp:261]     Train net output #0: loss = 2.51973 (* 1 = 2.51973 loss)
I0506 04:59:23.127982 12834 sgd_solver.cpp:106] Iteration 181600, lr = 1.80144e-06
I0506 04:59:23.132817 12834 solver.cpp:242] Iteration 181600 (106.534 iter/s, 0.938664s/100 iter), loss = 0.526044
I0506 04:59:23.132841 12834 solver.cpp:261]     Train net output #0: loss = 0.526044 (* 1 = 0.526044 loss)
I0506 04:59:23.132850 12834 sgd_solver.cpp:106] Iteration 181600, lr = 1.80144e-06
I0506 04:59:24.065585 12834 solver.cpp:242] Iteration 181700 (106.657 iter/s, 0.937586s/100 iter), loss = 1.06173
I0506 04:59:24.065616 12834 solver.cpp:261]     Train net output #0: loss = 1.06173 (* 1 = 1.06173 loss)
I0506 04:59:24.065625 12834 sgd_solver.cpp:106] Iteration 181700, lr = 1.80144e-06
I0506 04:59:24.070336 12834 solver.cpp:242] Iteration 181700 (106.669 iter/s, 0.937477s/100 iter), loss = 0.507385
I0506 04:59:24.070361 12834 solver.cpp:261]     Train net output #0: loss = 0.507385 (* 1 = 0.507385 loss)
I0506 04:59:24.070370 12834 sgd_solver.cpp:106] Iteration 181700, lr = 1.80144e-06
I0506 04:59:25.003103 12834 solver.cpp:242] Iteration 181800 (106.672 iter/s, 0.937454s/100 iter), loss = 0.243397
I0506 04:59:25.003144 12834 solver.cpp:261]     Train net output #0: loss = 0.243397 (* 1 = 0.243397 loss)
I0506 04:59:25.003154 12834 sgd_solver.cpp:106] Iteration 181800, lr = 1.80144e-06
I0506 04:59:25.007892 12834 solver.cpp:242] Iteration 181800 (106.665 iter/s, 0.937514s/100 iter), loss = 0.537423
I0506 04:59:25.007917 12834 solver.cpp:261]     Train net output #0: loss = 0.537423 (* 1 = 0.537423 loss)
I0506 04:59:25.007926 12834 sgd_solver.cpp:106] Iteration 181800, lr = 1.80144e-06
I0506 04:59:25.942085 12834 solver.cpp:242] Iteration 181900 (106.506 iter/s, 0.938914s/100 iter), loss = 0.681441
I0506 04:59:25.942127 12834 solver.cpp:261]     Train net output #0: loss = 0.681441 (* 1 = 0.681441 loss)
I0506 04:59:25.942137 12834 sgd_solver.cpp:106] Iteration 181900, lr = 1.80144e-06
I0506 04:59:25.946861 12834 solver.cpp:242] Iteration 181900 (106.505 iter/s, 0.938925s/100 iter), loss = 0.460284
I0506 04:59:25.946887 12834 solver.cpp:261]     Train net output #0: loss = 0.460284 (* 1 = 0.460284 loss)
I0506 04:59:25.946897 12834 sgd_solver.cpp:106] Iteration 181900, lr = 1.80144e-06
I0506 04:59:26.929932 12834 solver.cpp:362] Iteration 182000, Testing net (#0)
I0506 04:59:26.929963 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:27.063141 12834 solver.cpp:429]     Test net output #0: loss = 1.23804 (* 1 = 1.23804 loss)
I0506 04:59:27.065798 12834 solver.cpp:242] Iteration 182000 (88.9957 iter/s, 1.12365s/100 iter), loss = 0.408006
I0506 04:59:27.065825 12834 solver.cpp:261]     Train net output #0: loss = 0.408006 (* 1 = 0.408006 loss)
I0506 04:59:27.065836 12834 sgd_solver.cpp:106] Iteration 182000, lr = 1.80144e-06
I0506 04:59:27.068011 12834 solver.cpp:362] Iteration 182000, Testing net (#0)
I0506 04:59:27.068025 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:27.209041 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7775
I0506 04:59:27.209065 12834 solver.cpp:429]     Test net output #1: loss = 0.49498 (* 1 = 0.49498 loss)
I0506 04:59:27.211766 12834 solver.cpp:242] Iteration 182000 (79.0604 iter/s, 1.26486s/100 iter), loss = 0.420295
I0506 04:59:27.211791 12834 solver.cpp:261]     Train net output #0: loss = 0.420295 (* 1 = 0.420295 loss)
I0506 04:59:27.211802 12834 sgd_solver.cpp:106] Iteration 182000, lr = 1.80144e-06
I0506 04:59:28.160320 12834 solver.cpp:242] Iteration 182100 (91.3686 iter/s, 1.09447s/100 iter), loss = 1.15737
I0506 04:59:28.160374 12834 solver.cpp:261]     Train net output #0: loss = 1.15737 (* 1 = 1.15737 loss)
I0506 04:59:28.160384 12834 sgd_solver.cpp:106] Iteration 182100, lr = 1.80144e-06
I0506 04:59:28.165148 12834 solver.cpp:242] Iteration 182100 (104.894 iter/s, 0.953341s/100 iter), loss = 0.50096
I0506 04:59:28.165174 12834 solver.cpp:261]     Train net output #0: loss = 0.50096 (* 1 = 0.50096 loss)
I0506 04:59:28.165184 12834 sgd_solver.cpp:106] Iteration 182100, lr = 1.80144e-06
I0506 04:59:29.098063 12834 solver.cpp:242] Iteration 182200 (106.649 iter/s, 0.937659s/100 iter), loss = 5.15204
I0506 04:59:29.098104 12834 solver.cpp:261]     Train net output #0: loss = 5.15204 (* 1 = 5.15204 loss)
I0506 04:59:29.098124 12834 sgd_solver.cpp:106] Iteration 182200, lr = 1.80144e-06
I0506 04:59:29.102850 12834 solver.cpp:242] Iteration 182200 (106.649 iter/s, 0.937658s/100 iter), loss = 0.74931
I0506 04:59:29.102876 12834 solver.cpp:261]     Train net output #0: loss = 0.74931 (* 1 = 0.74931 loss)
I0506 04:59:29.102885 12834 sgd_solver.cpp:106] Iteration 182200, lr = 1.80144e-06
I0506 04:59:30.035439 12834 solver.cpp:242] Iteration 182300 (106.688 iter/s, 0.937309s/100 iter), loss = 5.2673
I0506 04:59:30.035477 12834 solver.cpp:261]     Train net output #0: loss = 5.2673 (* 1 = 5.2673 loss)
I0506 04:59:30.035486 12834 sgd_solver.cpp:106] Iteration 182300, lr = 1.80144e-06
I0506 04:59:30.040201 12834 solver.cpp:242] Iteration 182300 (106.689 iter/s, 0.937307s/100 iter), loss = 0.730032
I0506 04:59:30.040225 12834 solver.cpp:261]     Train net output #0: loss = 0.730032 (* 1 = 0.730032 loss)
I0506 04:59:30.040235 12834 sgd_solver.cpp:106] Iteration 182300, lr = 1.80144e-06
I0506 04:59:30.972542 12834 solver.cpp:242] Iteration 182400 (106.72 iter/s, 0.937035s/100 iter), loss = 1.55043
I0506 04:59:30.972585 12834 solver.cpp:261]     Train net output #0: loss = 1.55043 (* 1 = 1.55043 loss)
I0506 04:59:30.972595 12834 sgd_solver.cpp:106] Iteration 182400, lr = 1.80144e-06
I0506 04:59:30.977314 12834 solver.cpp:242] Iteration 182400 (106.716 iter/s, 0.937071s/100 iter), loss = 0.402728
I0506 04:59:30.977340 12834 solver.cpp:261]     Train net output #0: loss = 0.402728 (* 1 = 0.402728 loss)
I0506 04:59:30.977349 12834 sgd_solver.cpp:106] Iteration 182400, lr = 1.80144e-06
I0506 04:59:31.907383 12834 solver.cpp:362] Iteration 182500, Testing net (#0)
I0506 04:59:31.907407 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:32.030073 12834 solver.cpp:429]     Test net output #0: loss = 1.19919 (* 1 = 1.19919 loss)
I0506 04:59:32.032598 12834 solver.cpp:242] Iteration 182500 (94.3402 iter/s, 1.05999s/100 iter), loss = 0.535518
I0506 04:59:32.032620 12834 solver.cpp:261]     Train net output #0: loss = 0.535518 (* 1 = 0.535518 loss)
I0506 04:59:32.032629 12834 sgd_solver.cpp:106] Iteration 182500, lr = 1.80144e-06
I0506 04:59:32.034525 12834 solver.cpp:362] Iteration 182500, Testing net (#0)
I0506 04:59:32.034538 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:32.163698 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7705
I0506 04:59:32.163717 12834 solver.cpp:429]     Test net output #1: loss = 0.495123 (* 1 = 0.495123 loss)
I0506 04:59:32.166265 12834 solver.cpp:242] Iteration 182500 (84.111 iter/s, 1.1889s/100 iter), loss = 0.315256
I0506 04:59:32.166286 12834 solver.cpp:261]     Train net output #0: loss = 0.315256 (* 1 = 0.315256 loss)
I0506 04:59:32.166295 12834 sgd_solver.cpp:106] Iteration 182500, lr = 1.80144e-06
I0506 04:59:33.098451 12834 solver.cpp:242] Iteration 182600 (93.8261 iter/s, 1.0658s/100 iter), loss = 1.34226
I0506 04:59:33.098489 12834 solver.cpp:261]     Train net output #0: loss = 1.34226 (* 1 = 1.34226 loss)
I0506 04:59:33.098500 12834 sgd_solver.cpp:106] Iteration 182600, lr = 1.80144e-06
I0506 04:59:33.103240 12834 solver.cpp:242] Iteration 182600 (106.731 iter/s, 0.936936s/100 iter), loss = 0.341535
I0506 04:59:33.103266 12834 solver.cpp:261]     Train net output #0: loss = 0.341535 (* 1 = 0.341535 loss)
I0506 04:59:33.103274 12834 sgd_solver.cpp:106] Iteration 182600, lr = 1.80144e-06
I0506 04:59:34.036172 12834 solver.cpp:242] Iteration 182700 (106.649 iter/s, 0.937651s/100 iter), loss = 0.592531
I0506 04:59:34.036207 12834 solver.cpp:261]     Train net output #0: loss = 0.592531 (* 1 = 0.592531 loss)
I0506 04:59:34.036217 12834 sgd_solver.cpp:106] Iteration 182700, lr = 1.80144e-06
I0506 04:59:34.040946 12834 solver.cpp:242] Iteration 182700 (106.648 iter/s, 0.937662s/100 iter), loss = 0.323587
I0506 04:59:34.040971 12834 solver.cpp:261]     Train net output #0: loss = 0.323587 (* 1 = 0.323587 loss)
I0506 04:59:34.040982 12834 sgd_solver.cpp:106] Iteration 182700, lr = 1.80144e-06
I0506 04:59:34.973551 12834 solver.cpp:242] Iteration 182800 (106.687 iter/s, 0.937318s/100 iter), loss = 1.68194
I0506 04:59:34.973598 12834 solver.cpp:261]     Train net output #0: loss = 1.68194 (* 1 = 1.68194 loss)
I0506 04:59:34.973608 12834 sgd_solver.cpp:106] Iteration 182800, lr = 1.80144e-06
I0506 04:59:34.978368 12834 solver.cpp:242] Iteration 182800 (106.681 iter/s, 0.937378s/100 iter), loss = 0.468207
I0506 04:59:34.978392 12834 solver.cpp:261]     Train net output #0: loss = 0.468207 (* 1 = 0.468207 loss)
I0506 04:59:34.978401 12834 sgd_solver.cpp:106] Iteration 182800, lr = 1.80144e-06
I0506 04:59:35.911418 12834 solver.cpp:242] Iteration 182900 (106.634 iter/s, 0.937791s/100 iter), loss = 1.47385
I0506 04:59:35.911463 12834 solver.cpp:261]     Train net output #0: loss = 1.47385 (* 1 = 1.47385 loss)
I0506 04:59:35.911473 12834 sgd_solver.cpp:106] Iteration 182900, lr = 1.80144e-06
I0506 04:59:35.916227 12834 solver.cpp:242] Iteration 182900 (106.631 iter/s, 0.937817s/100 iter), loss = 0.874202
I0506 04:59:35.916251 12834 solver.cpp:261]     Train net output #0: loss = 0.874202 (* 1 = 0.874202 loss)
I0506 04:59:35.916260 12834 sgd_solver.cpp:106] Iteration 182900, lr = 1.80144e-06
I0506 04:59:36.846544 12834 solver.cpp:362] Iteration 183000, Testing net (#0)
I0506 04:59:36.846571 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:36.969368 12834 solver.cpp:429]     Test net output #0: loss = 1.05772 (* 1 = 1.05772 loss)
I0506 04:59:36.971889 12834 solver.cpp:242] Iteration 183000 (94.3035 iter/s, 1.06041s/100 iter), loss = 1.30743
I0506 04:59:36.971909 12834 solver.cpp:261]     Train net output #0: loss = 1.30743 (* 1 = 1.30743 loss)
I0506 04:59:36.971917 12834 sgd_solver.cpp:106] Iteration 183000, lr = 1.80144e-06
I0506 04:59:36.973743 12834 solver.cpp:362] Iteration 183000, Testing net (#0)
I0506 04:59:36.973757 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:37.102427 12834 solver.cpp:429]     Test net output #0: accuracy = 0.8045
I0506 04:59:37.102447 12834 solver.cpp:429]     Test net output #1: loss = 0.455608 (* 1 = 0.455608 loss)
I0506 04:59:37.104996 12834 solver.cpp:242] Iteration 183000 (84.1238 iter/s, 1.18872s/100 iter), loss = 0.45225
I0506 04:59:37.105017 12834 solver.cpp:261]     Train net output #0: loss = 0.45225 (* 1 = 0.45225 loss)
I0506 04:59:37.105026 12834 sgd_solver.cpp:106] Iteration 183000, lr = 1.80144e-06
I0506 04:59:38.038336 12834 solver.cpp:242] Iteration 183100 (93.774 iter/s, 1.06639s/100 iter), loss = 2.34145
I0506 04:59:38.038378 12834 solver.cpp:261]     Train net output #0: loss = 2.34145 (* 1 = 2.34145 loss)
I0506 04:59:38.038388 12834 sgd_solver.cpp:106] Iteration 183100, lr = 1.80144e-06
I0506 04:59:38.043117 12834 solver.cpp:242] Iteration 183100 (106.601 iter/s, 0.93808s/100 iter), loss = 0.778946
I0506 04:59:38.043143 12834 solver.cpp:261]     Train net output #0: loss = 0.778946 (* 1 = 0.778946 loss)
I0506 04:59:38.043153 12834 sgd_solver.cpp:106] Iteration 183100, lr = 1.80144e-06
I0506 04:59:38.976264 12834 solver.cpp:242] Iteration 183200 (106.626 iter/s, 0.937861s/100 iter), loss = 2.74809
I0506 04:59:38.976320 12834 solver.cpp:261]     Train net output #0: loss = 2.74809 (* 1 = 2.74809 loss)
I0506 04:59:38.976336 12834 sgd_solver.cpp:106] Iteration 183200, lr = 1.80144e-06
I0506 04:59:38.981087 12834 solver.cpp:242] Iteration 183200 (106.618 iter/s, 0.937927s/100 iter), loss = 0.609323
I0506 04:59:38.981113 12834 solver.cpp:261]     Train net output #0: loss = 0.609323 (* 1 = 0.609323 loss)
I0506 04:59:38.981122 12834 sgd_solver.cpp:106] Iteration 183200, lr = 1.80144e-06
I0506 04:59:39.914113 12834 solver.cpp:242] Iteration 183300 (106.637 iter/s, 0.937763s/100 iter), loss = 0.311841
I0506 04:59:39.914155 12834 solver.cpp:261]     Train net output #0: loss = 0.311841 (* 1 = 0.311841 loss)
I0506 04:59:39.914165 12834 sgd_solver.cpp:106] Iteration 183300, lr = 1.80144e-06
I0506 04:59:39.918958 12834 solver.cpp:242] Iteration 183300 (106.629 iter/s, 0.937827s/100 iter), loss = 0.140519
I0506 04:59:39.918985 12834 solver.cpp:261]     Train net output #0: loss = 0.140519 (* 1 = 0.140519 loss)
I0506 04:59:39.919003 12834 sgd_solver.cpp:106] Iteration 183300, lr = 1.80144e-06
I0506 04:59:40.852651 12834 solver.cpp:242] Iteration 183400 (106.556 iter/s, 0.938474s/100 iter), loss = 1.10784
I0506 04:59:40.852692 12834 solver.cpp:261]     Train net output #0: loss = 1.10784 (* 1 = 1.10784 loss)
I0506 04:59:40.852701 12834 sgd_solver.cpp:106] Iteration 183400, lr = 1.80144e-06
I0506 04:59:40.857499 12834 solver.cpp:242] Iteration 183400 (106.555 iter/s, 0.938487s/100 iter), loss = 0.58009
I0506 04:59:40.857524 12834 solver.cpp:261]     Train net output #0: loss = 0.58009 (* 1 = 0.58009 loss)
I0506 04:59:40.857533 12834 sgd_solver.cpp:106] Iteration 183400, lr = 1.80144e-06
I0506 04:59:41.787719 12834 solver.cpp:362] Iteration 183500, Testing net (#0)
I0506 04:59:41.787744 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:41.910465 12834 solver.cpp:429]     Test net output #0: loss = 1.24565 (* 1 = 1.24565 loss)
I0506 04:59:41.912994 12834 solver.cpp:242] Iteration 183500 (94.3144 iter/s, 1.06028s/100 iter), loss = 0.595221
I0506 04:59:41.913015 12834 solver.cpp:261]     Train net output #0: loss = 0.595221 (* 1 = 0.595221 loss)
I0506 04:59:41.913023 12834 sgd_solver.cpp:106] Iteration 183500, lr = 1.80144e-06
I0506 04:59:41.914840 12834 solver.cpp:362] Iteration 183500, Testing net (#0)
I0506 04:59:41.914855 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:42.043659 12834 solver.cpp:429]     Test net output #0: accuracy = 0.786
I0506 04:59:42.043680 12834 solver.cpp:429]     Test net output #1: loss = 0.510392 (* 1 = 0.510392 loss)
I0506 04:59:42.046238 12834 solver.cpp:242] Iteration 183500 (84.1259 iter/s, 1.18869s/100 iter), loss = 0.47521
I0506 04:59:42.046258 12834 solver.cpp:261]     Train net output #0: loss = 0.47521 (* 1 = 0.47521 loss)
I0506 04:59:42.046267 12834 sgd_solver.cpp:106] Iteration 183500, lr = 1.80144e-06
I0506 04:59:42.979827 12834 solver.cpp:242] Iteration 183600 (93.7396 iter/s, 1.06678s/100 iter), loss = 0.536857
I0506 04:59:42.979871 12834 solver.cpp:261]     Train net output #0: loss = 0.536857 (* 1 = 0.536857 loss)
I0506 04:59:42.979881 12834 sgd_solver.cpp:106] Iteration 183600, lr = 1.80144e-06
I0506 04:59:42.984617 12834 solver.cpp:242] Iteration 183600 (106.572 iter/s, 0.93833s/100 iter), loss = 0.171019
I0506 04:59:42.984644 12834 solver.cpp:261]     Train net output #0: loss = 0.171019 (* 1 = 0.171019 loss)
I0506 04:59:42.984653 12834 sgd_solver.cpp:106] Iteration 183600, lr = 1.80144e-06
I0506 04:59:43.918910 12834 solver.cpp:242] Iteration 183700 (106.495 iter/s, 0.939014s/100 iter), loss = 0.928881
I0506 04:59:43.918949 12834 solver.cpp:261]     Train net output #0: loss = 0.928881 (* 1 = 0.928881 loss)
I0506 04:59:43.918959 12834 sgd_solver.cpp:106] Iteration 183700, lr = 1.80144e-06
I0506 04:59:43.923681 12834 solver.cpp:242] Iteration 183700 (106.494 iter/s, 0.939017s/100 iter), loss = 0.413085
I0506 04:59:43.923705 12834 solver.cpp:261]     Train net output #0: loss = 0.413085 (* 1 = 0.413085 loss)
I0506 04:59:43.923714 12834 sgd_solver.cpp:106] Iteration 183700, lr = 1.80144e-06
I0506 04:59:44.857362 12834 solver.cpp:242] Iteration 183800 (106.566 iter/s, 0.938381s/100 iter), loss = 1.93347
I0506 04:59:44.857401 12834 solver.cpp:261]     Train net output #0: loss = 1.93347 (* 1 = 1.93347 loss)
I0506 04:59:44.857411 12834 sgd_solver.cpp:106] Iteration 183800, lr = 1.80144e-06
I0506 04:59:44.862222 12834 solver.cpp:242] Iteration 183800 (106.553 iter/s, 0.938498s/100 iter), loss = 0.632342
I0506 04:59:44.862248 12834 solver.cpp:261]     Train net output #0: loss = 0.632342 (* 1 = 0.632342 loss)
I0506 04:59:44.862258 12834 sgd_solver.cpp:106] Iteration 183800, lr = 1.80144e-06
I0506 04:59:45.795262 12834 solver.cpp:242] Iteration 183900 (106.629 iter/s, 0.937834s/100 iter), loss = 0.658017
I0506 04:59:45.795300 12834 solver.cpp:261]     Train net output #0: loss = 0.658017 (* 1 = 0.658017 loss)
I0506 04:59:45.795310 12834 sgd_solver.cpp:106] Iteration 183900, lr = 1.80144e-06
I0506 04:59:45.800024 12834 solver.cpp:242] Iteration 183900 (106.637 iter/s, 0.937758s/100 iter), loss = 0.542502
I0506 04:59:45.800058 12834 solver.cpp:261]     Train net output #0: loss = 0.542502 (* 1 = 0.542502 loss)
I0506 04:59:45.800068 12834 sgd_solver.cpp:106] Iteration 183900, lr = 1.80144e-06
I0506 04:59:46.749837 12834 solver.cpp:362] Iteration 184000, Testing net (#0)
I0506 04:59:46.749860 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:46.872771 12834 solver.cpp:429]     Test net output #0: loss = 1.09623 (* 1 = 1.09623 loss)
I0506 04:59:46.875293 12834 solver.cpp:242] Iteration 184000 (92.5947 iter/s, 1.07998s/100 iter), loss = 0.477529
I0506 04:59:46.875314 12834 solver.cpp:261]     Train net output #0: loss = 0.477529 (* 1 = 0.477529 loss)
I0506 04:59:46.875324 12834 sgd_solver.cpp:106] Iteration 184000, lr = 1.80144e-06
I0506 04:59:46.877180 12834 solver.cpp:362] Iteration 184000, Testing net (#0)
I0506 04:59:46.877194 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:47.005969 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7905
I0506 04:59:47.005987 12834 solver.cpp:429]     Test net output #1: loss = 0.495687 (* 1 = 0.495687 loss)
I0506 04:59:47.008543 12834 solver.cpp:242] Iteration 184000 (82.7497 iter/s, 1.20846s/100 iter), loss = 0.321841
I0506 04:59:47.008579 12834 solver.cpp:261]     Train net output #0: loss = 0.321841 (* 1 = 0.321841 loss)
I0506 04:59:47.008589 12834 sgd_solver.cpp:106] Iteration 184000, lr = 1.80144e-06
I0506 04:59:47.942138 12834 solver.cpp:242] Iteration 184100 (93.7384 iter/s, 1.0668s/100 iter), loss = 0.354297
I0506 04:59:47.942173 12834 solver.cpp:261]     Train net output #0: loss = 0.354297 (* 1 = 0.354297 loss)
I0506 04:59:47.942183 12834 sgd_solver.cpp:106] Iteration 184100, lr = 1.80144e-06
I0506 04:59:47.946907 12834 solver.cpp:242] Iteration 184100 (106.575 iter/s, 0.93831s/100 iter), loss = 0.282815
I0506 04:59:47.946933 12834 solver.cpp:261]     Train net output #0: loss = 0.282815 (* 1 = 0.282815 loss)
I0506 04:59:47.946941 12834 sgd_solver.cpp:106] Iteration 184100, lr = 1.80144e-06
I0506 04:59:48.880288 12834 solver.cpp:242] Iteration 184200 (106.6 iter/s, 0.938084s/100 iter), loss = 0.923844
I0506 04:59:48.880329 12834 solver.cpp:261]     Train net output #0: loss = 0.923844 (* 1 = 0.923844 loss)
I0506 04:59:48.880339 12834 sgd_solver.cpp:106] Iteration 184200, lr = 1.80144e-06
I0506 04:59:48.885073 12834 solver.cpp:242] Iteration 184200 (106.596 iter/s, 0.938123s/100 iter), loss = 0.430101
I0506 04:59:48.885098 12834 solver.cpp:261]     Train net output #0: loss = 0.430101 (* 1 = 0.430101 loss)
I0506 04:59:48.885107 12834 sgd_solver.cpp:106] Iteration 184200, lr = 1.80144e-06
I0506 04:59:49.818208 12834 solver.cpp:242] Iteration 184300 (106.626 iter/s, 0.937855s/100 iter), loss = 0.645166
I0506 04:59:49.818253 12834 solver.cpp:261]     Train net output #0: loss = 0.645166 (* 1 = 0.645166 loss)
I0506 04:59:49.818262 12834 sgd_solver.cpp:106] Iteration 184300, lr = 1.80144e-06
I0506 04:59:49.823050 12834 solver.cpp:242] Iteration 184300 (106.619 iter/s, 0.937923s/100 iter), loss = 0.42527
I0506 04:59:49.823079 12834 solver.cpp:261]     Train net output #0: loss = 0.42527 (* 1 = 0.42527 loss)
I0506 04:59:49.823088 12834 sgd_solver.cpp:106] Iteration 184300, lr = 1.80144e-06
I0506 04:59:50.755978 12834 solver.cpp:242] Iteration 184400 (106.644 iter/s, 0.937698s/100 iter), loss = 0.62394
I0506 04:59:50.756019 12834 solver.cpp:261]     Train net output #0: loss = 0.62394 (* 1 = 0.62394 loss)
I0506 04:59:50.756028 12834 sgd_solver.cpp:106] Iteration 184400, lr = 1.80144e-06
I0506 04:59:50.760759 12834 solver.cpp:242] Iteration 184400 (106.648 iter/s, 0.937662s/100 iter), loss = 0.319422
I0506 04:59:50.760787 12834 solver.cpp:261]     Train net output #0: loss = 0.319422 (* 1 = 0.319422 loss)
I0506 04:59:50.760797 12834 sgd_solver.cpp:106] Iteration 184400, lr = 1.80144e-06
I0506 04:59:51.690605 12834 solver.cpp:362] Iteration 184500, Testing net (#0)
I0506 04:59:51.690632 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:51.813375 12834 solver.cpp:429]     Test net output #0: loss = 1.24617 (* 1 = 1.24617 loss)
I0506 04:59:51.815930 12834 solver.cpp:242] Iteration 184500 (94.3492 iter/s, 1.05989s/100 iter), loss = 3.28777
I0506 04:59:51.815956 12834 solver.cpp:261]     Train net output #0: loss = 3.28777 (* 1 = 3.28777 loss)
I0506 04:59:51.815965 12834 sgd_solver.cpp:106] Iteration 184500, lr = 1.80144e-06
I0506 04:59:51.817862 12834 solver.cpp:362] Iteration 184500, Testing net (#0)
I0506 04:59:51.817876 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:51.946590 12834 solver.cpp:429]     Test net output #0: accuracy = 0.78
I0506 04:59:51.946610 12834 solver.cpp:429]     Test net output #1: loss = 0.516655 (* 1 = 0.516655 loss)
I0506 04:59:51.949156 12834 solver.cpp:242] Iteration 184500 (84.1504 iter/s, 1.18835s/100 iter), loss = 0.682057
I0506 04:59:51.949179 12834 solver.cpp:261]     Train net output #0: loss = 0.682057 (* 1 = 0.682057 loss)
I0506 04:59:51.949188 12834 sgd_solver.cpp:106] Iteration 184500, lr = 1.80144e-06
I0506 04:59:52.882011 12834 solver.cpp:242] Iteration 184600 (93.8063 iter/s, 1.06603s/100 iter), loss = 1.83723
I0506 04:59:52.882053 12834 solver.cpp:261]     Train net output #0: loss = 1.83723 (* 1 = 1.83723 loss)
I0506 04:59:52.882062 12834 sgd_solver.cpp:106] Iteration 184600, lr = 1.80144e-06
I0506 04:59:52.886790 12834 solver.cpp:242] Iteration 184600 (106.656 iter/s, 0.937594s/100 iter), loss = 0.796554
I0506 04:59:52.886816 12834 solver.cpp:261]     Train net output #0: loss = 0.796554 (* 1 = 0.796554 loss)
I0506 04:59:52.886826 12834 sgd_solver.cpp:106] Iteration 184600, lr = 1.80144e-06
I0506 04:59:53.819970 12834 solver.cpp:242] Iteration 184700 (106.623 iter/s, 0.937886s/100 iter), loss = 0.606581
I0506 04:59:53.820011 12834 solver.cpp:261]     Train net output #0: loss = 0.606581 (* 1 = 0.606581 loss)
I0506 04:59:53.820021 12834 sgd_solver.cpp:106] Iteration 184700, lr = 1.80144e-06
I0506 04:59:53.824756 12834 solver.cpp:242] Iteration 184700 (106.619 iter/s, 0.937922s/100 iter), loss = 0.646262
I0506 04:59:53.824784 12834 solver.cpp:261]     Train net output #0: loss = 0.646262 (* 1 = 0.646262 loss)
I0506 04:59:53.824792 12834 sgd_solver.cpp:106] Iteration 184700, lr = 1.80144e-06
I0506 04:59:54.758986 12834 solver.cpp:242] Iteration 184800 (106.502 iter/s, 0.93895s/100 iter), loss = 0.819752
I0506 04:59:54.759027 12834 solver.cpp:261]     Train net output #0: loss = 0.819752 (* 1 = 0.819752 loss)
I0506 04:59:54.759035 12834 sgd_solver.cpp:106] Iteration 184800, lr = 1.80144e-06
I0506 04:59:54.763773 12834 solver.cpp:242] Iteration 184800 (106.499 iter/s, 0.938972s/100 iter), loss = 0.396495
I0506 04:59:54.763799 12834 solver.cpp:261]     Train net output #0: loss = 0.396495 (* 1 = 0.396495 loss)
I0506 04:59:54.763808 12834 sgd_solver.cpp:106] Iteration 184800, lr = 1.80144e-06
I0506 04:59:55.696079 12834 solver.cpp:242] Iteration 184900 (106.721 iter/s, 0.93702s/100 iter), loss = 0.663629
I0506 04:59:55.696118 12834 solver.cpp:261]     Train net output #0: loss = 0.663629 (* 1 = 0.663629 loss)
I0506 04:59:55.696127 12834 sgd_solver.cpp:106] Iteration 184900, lr = 1.80144e-06
I0506 04:59:55.700851 12834 solver.cpp:242] Iteration 184900 (106.72 iter/s, 0.937034s/100 iter), loss = 0.855078
I0506 04:59:55.700876 12834 solver.cpp:261]     Train net output #0: loss = 0.855078 (* 1 = 0.855078 loss)
I0506 04:59:55.700886 12834 sgd_solver.cpp:106] Iteration 184900, lr = 1.80144e-06
I0506 04:59:56.631141 12834 solver.cpp:362] Iteration 185000, Testing net (#0)
I0506 04:59:56.631166 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:56.753947 12834 solver.cpp:429]     Test net output #0: loss = 1.0669 (* 1 = 1.0669 loss)
I0506 04:59:56.756461 12834 solver.cpp:242] Iteration 185000 (94.3108 iter/s, 1.06032s/100 iter), loss = 1.70141
I0506 04:59:56.756484 12834 solver.cpp:261]     Train net output #0: loss = 1.70141 (* 1 = 1.70141 loss)
I0506 04:59:56.756494 12834 sgd_solver.cpp:106] Iteration 185000, lr = 1.80144e-06
I0506 04:59:56.758309 12834 solver.cpp:362] Iteration 185000, Testing net (#0)
I0506 04:59:56.758332 12834 net.cpp:723] Ignoring source layer parameters
I0506 04:59:56.887080 12834 solver.cpp:429]     Test net output #0: accuracy = 0.8105
I0506 04:59:56.887099 12834 solver.cpp:429]     Test net output #1: loss = 0.463084 (* 1 = 0.463084 loss)
I0506 04:59:56.889653 12834 solver.cpp:242] Iteration 185000 (84.1215 iter/s, 1.18876s/100 iter), loss = 0.508367
I0506 04:59:56.889674 12834 solver.cpp:261]     Train net output #0: loss = 0.508367 (* 1 = 0.508367 loss)
I0506 04:59:56.889683 12834 sgd_solver.cpp:106] Iteration 185000, lr = 1.80144e-06
I0506 04:59:57.823829 12834 solver.cpp:242] Iteration 185100 (93.6935 iter/s, 1.06731s/100 iter), loss = 0.821213
I0506 04:59:57.823875 12834 solver.cpp:261]     Train net output #0: loss = 0.821213 (* 1 = 0.821213 loss)
I0506 04:59:57.823885 12834 sgd_solver.cpp:106] Iteration 185100, lr = 1.80144e-06
I0506 04:59:57.828613 12834 solver.cpp:242] Iteration 185100 (106.505 iter/s, 0.93892s/100 iter), loss = 0.77706
I0506 04:59:57.828640 12834 solver.cpp:261]     Train net output #0: loss = 0.77706 (* 1 = 0.77706 loss)
I0506 04:59:57.828649 12834 sgd_solver.cpp:106] Iteration 185100, lr = 1.80144e-06
I0506 04:59:58.761373 12834 solver.cpp:242] Iteration 185200 (106.67 iter/s, 0.937475s/100 iter), loss = 1.24533
I0506 04:59:58.761406 12834 solver.cpp:261]     Train net output #0: loss = 1.24533 (* 1 = 1.24533 loss)
I0506 04:59:58.761415 12834 sgd_solver.cpp:106] Iteration 185200, lr = 1.80144e-06
I0506 04:59:58.766201 12834 solver.cpp:242] Iteration 185200 (106.663 iter/s, 0.937532s/100 iter), loss = 0.582832
I0506 04:59:58.766227 12834 solver.cpp:261]     Train net output #0: loss = 0.582832 (* 1 = 0.582832 loss)
I0506 04:59:58.766235 12834 sgd_solver.cpp:106] Iteration 185200, lr = 1.80144e-06
I0506 04:59:59.699038 12834 solver.cpp:242] Iteration 185300 (106.655 iter/s, 0.937606s/100 iter), loss = 0.170328
I0506 04:59:59.699069 12834 solver.cpp:261]     Train net output #0: loss = 0.170328 (* 1 = 0.170328 loss)
I0506 04:59:59.699079 12834 sgd_solver.cpp:106] Iteration 185300, lr = 1.80144e-06
I0506 04:59:59.703802 12834 solver.cpp:242] Iteration 185300 (106.66 iter/s, 0.937558s/100 iter), loss = 0.590696
I0506 04:59:59.703826 12834 solver.cpp:261]     Train net output #0: loss = 0.590696 (* 1 = 0.590696 loss)
I0506 04:59:59.703835 12834 sgd_solver.cpp:106] Iteration 185300, lr = 1.80144e-06
I0506 05:00:00.649371 12834 solver.cpp:242] Iteration 185400 (105.232 iter/s, 0.950277s/100 iter), loss = 3.53078
I0506 05:00:00.649418 12834 solver.cpp:261]     Train net output #0: loss = 3.53078 (* 1 = 3.53078 loss)
I0506 05:00:00.649428 12834 sgd_solver.cpp:106] Iteration 185400, lr = 1.80144e-06
I0506 05:00:00.654232 12834 solver.cpp:242] Iteration 185400 (105.221 iter/s, 0.950378s/100 iter), loss = 0.540658
I0506 05:00:00.654258 12834 solver.cpp:261]     Train net output #0: loss = 0.540658 (* 1 = 0.540658 loss)
I0506 05:00:00.654268 12834 sgd_solver.cpp:106] Iteration 185400, lr = 1.80144e-06
I0506 05:00:01.584350 12834 solver.cpp:362] Iteration 185500, Testing net (#0)
I0506 05:00:01.584378 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:01.707039 12834 solver.cpp:429]     Test net output #0: loss = 1.2356 (* 1 = 1.2356 loss)
I0506 05:00:01.709564 12834 solver.cpp:242] Iteration 185500 (94.3283 iter/s, 1.06013s/100 iter), loss = 0.588589
I0506 05:00:01.709585 12834 solver.cpp:261]     Train net output #0: loss = 0.588589 (* 1 = 0.588589 loss)
I0506 05:00:01.709594 12834 sgd_solver.cpp:106] Iteration 185500, lr = 1.80144e-06
I0506 05:00:01.711417 12834 solver.cpp:362] Iteration 185500, Testing net (#0)
I0506 05:00:01.711432 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:01.840247 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7745
I0506 05:00:01.840267 12834 solver.cpp:429]     Test net output #1: loss = 0.514349 (* 1 = 0.514349 loss)
I0506 05:00:01.842824 12834 solver.cpp:242] Iteration 185500 (84.1364 iter/s, 1.18855s/100 iter), loss = 0.360165
I0506 05:00:01.842844 12834 solver.cpp:261]     Train net output #0: loss = 0.360165 (* 1 = 0.360165 loss)
I0506 05:00:01.842860 12834 sgd_solver.cpp:106] Iteration 185500, lr = 1.80144e-06
I0506 05:00:02.776196 12834 solver.cpp:242] Iteration 185600 (93.7578 iter/s, 1.06658s/100 iter), loss = 1.3496
I0506 05:00:02.776227 12834 solver.cpp:261]     Train net output #0: loss = 1.3496 (* 1 = 1.3496 loss)
I0506 05:00:02.776237 12834 sgd_solver.cpp:106] Iteration 185600, lr = 1.80144e-06
I0506 05:00:02.780961 12834 solver.cpp:242] Iteration 185600 (106.599 iter/s, 0.938097s/100 iter), loss = 0.460823
I0506 05:00:02.780983 12834 solver.cpp:261]     Train net output #0: loss = 0.460823 (* 1 = 0.460823 loss)
I0506 05:00:02.780993 12834 sgd_solver.cpp:106] Iteration 185600, lr = 1.80144e-06
I0506 05:00:03.713822 12834 solver.cpp:242] Iteration 185700 (106.659 iter/s, 0.937568s/100 iter), loss = 1.30099
I0506 05:00:03.713863 12834 solver.cpp:261]     Train net output #0: loss = 1.30099 (* 1 = 1.30099 loss)
I0506 05:00:03.713873 12834 sgd_solver.cpp:106] Iteration 185700, lr = 1.80144e-06
I0506 05:00:03.718616 12834 solver.cpp:242] Iteration 185700 (106.654 iter/s, 0.937614s/100 iter), loss = 0.491342
I0506 05:00:03.718643 12834 solver.cpp:261]     Train net output #0: loss = 0.491342 (* 1 = 0.491342 loss)
I0506 05:00:03.718652 12834 sgd_solver.cpp:106] Iteration 185700, lr = 1.80144e-06
I0506 05:00:04.651721 12834 solver.cpp:242] Iteration 185800 (106.63 iter/s, 0.937826s/100 iter), loss = 1.33337
I0506 05:00:04.651762 12834 solver.cpp:261]     Train net output #0: loss = 1.33337 (* 1 = 1.33337 loss)
I0506 05:00:04.651772 12834 sgd_solver.cpp:106] Iteration 185800, lr = 1.80144e-06
I0506 05:00:04.656510 12834 solver.cpp:242] Iteration 185800 (106.627 iter/s, 0.937849s/100 iter), loss = 0.405221
I0506 05:00:04.656538 12834 solver.cpp:261]     Train net output #0: loss = 0.405221 (* 1 = 0.405221 loss)
I0506 05:00:04.656546 12834 sgd_solver.cpp:106] Iteration 185800, lr = 1.80144e-06
I0506 05:00:05.588883 12834 solver.cpp:242] Iteration 185900 (106.713 iter/s, 0.937096s/100 iter), loss = 0.558713
I0506 05:00:05.588922 12834 solver.cpp:261]     Train net output #0: loss = 0.558713 (* 1 = 0.558713 loss)
I0506 05:00:05.588932 12834 sgd_solver.cpp:106] Iteration 185900, lr = 1.80144e-06
I0506 05:00:05.593657 12834 solver.cpp:242] Iteration 185900 (106.712 iter/s, 0.937101s/100 iter), loss = 0.447894
I0506 05:00:05.593683 12834 solver.cpp:261]     Train net output #0: loss = 0.447894 (* 1 = 0.447894 loss)
I0506 05:00:05.593691 12834 sgd_solver.cpp:106] Iteration 185900, lr = 1.80144e-06
I0506 05:00:06.523736 12834 solver.cpp:362] Iteration 186000, Testing net (#0)
I0506 05:00:06.523761 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:06.646430 12834 solver.cpp:429]     Test net output #0: loss = 1.08785 (* 1 = 1.08785 loss)
I0506 05:00:06.648949 12834 solver.cpp:242] Iteration 186000 (94.339 iter/s, 1.06001s/100 iter), loss = 0.534028
I0506 05:00:06.648973 12834 solver.cpp:261]     Train net output #0: loss = 0.534028 (* 1 = 0.534028 loss)
I0506 05:00:06.648983 12834 sgd_solver.cpp:106] Iteration 186000, lr = 1.80144e-06
I0506 05:00:06.650800 12834 solver.cpp:362] Iteration 186000, Testing net (#0)
I0506 05:00:06.650813 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:06.779587 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7805
I0506 05:00:06.779608 12834 solver.cpp:429]     Test net output #1: loss = 0.498116 (* 1 = 0.498116 loss)
I0506 05:00:06.782171 12834 solver.cpp:242] Iteration 186000 (84.142 iter/s, 1.18847s/100 iter), loss = 0.632522
I0506 05:00:06.782193 12834 solver.cpp:261]     Train net output #0: loss = 0.632522 (* 1 = 0.632522 loss)
I0506 05:00:06.782202 12834 sgd_solver.cpp:106] Iteration 186000, lr = 1.80144e-06
I0506 05:00:07.715636 12834 solver.cpp:242] Iteration 186100 (93.7527 iter/s, 1.06664s/100 iter), loss = 3.34429
I0506 05:00:07.715673 12834 solver.cpp:261]     Train net output #0: loss = 3.34429 (* 1 = 3.34429 loss)
I0506 05:00:07.715683 12834 sgd_solver.cpp:106] Iteration 186100, lr = 1.80144e-06
I0506 05:00:07.720491 12834 solver.cpp:242] Iteration 186100 (106.579 iter/s, 0.93827s/100 iter), loss = 0.593336
I0506 05:00:07.720530 12834 solver.cpp:261]     Train net output #0: loss = 0.593336 (* 1 = 0.593336 loss)
I0506 05:00:07.720541 12834 sgd_solver.cpp:106] Iteration 186100, lr = 1.80144e-06
I0506 05:00:08.653051 12834 solver.cpp:242] Iteration 186200 (106.684 iter/s, 0.93735s/100 iter), loss = 1.25487
I0506 05:00:08.653090 12834 solver.cpp:261]     Train net output #0: loss = 1.25487 (* 1 = 1.25487 loss)
I0506 05:00:08.653100 12834 sgd_solver.cpp:106] Iteration 186200, lr = 1.80144e-06
I0506 05:00:08.657835 12834 solver.cpp:242] Iteration 186200 (106.691 iter/s, 0.937286s/100 iter), loss = 0.623537
I0506 05:00:08.657860 12834 solver.cpp:261]     Train net output #0: loss = 0.623537 (* 1 = 0.623537 loss)
I0506 05:00:08.657869 12834 sgd_solver.cpp:106] Iteration 186200, lr = 1.80144e-06
I0506 05:00:09.591007 12834 solver.cpp:242] Iteration 186300 (106.622 iter/s, 0.937894s/100 iter), loss = 0.407446
I0506 05:00:09.591044 12834 solver.cpp:261]     Train net output #0: loss = 0.407446 (* 1 = 0.407446 loss)
I0506 05:00:09.591053 12834 sgd_solver.cpp:106] Iteration 186300, lr = 1.80144e-06
I0506 05:00:09.595861 12834 solver.cpp:242] Iteration 186300 (106.613 iter/s, 0.937974s/100 iter), loss = 0.412048
I0506 05:00:09.595887 12834 solver.cpp:261]     Train net output #0: loss = 0.412048 (* 1 = 0.412048 loss)
I0506 05:00:09.595896 12834 sgd_solver.cpp:106] Iteration 186300, lr = 1.80144e-06
I0506 05:00:10.528946 12834 solver.cpp:242] Iteration 186400 (106.624 iter/s, 0.937876s/100 iter), loss = 2.92949
I0506 05:00:10.528977 12834 solver.cpp:261]     Train net output #0: loss = 2.92949 (* 1 = 2.92949 loss)
I0506 05:00:10.528987 12834 sgd_solver.cpp:106] Iteration 186400, lr = 1.80144e-06
I0506 05:00:10.533746 12834 solver.cpp:242] Iteration 186400 (106.628 iter/s, 0.93784s/100 iter), loss = 0.409712
I0506 05:00:10.533771 12834 solver.cpp:261]     Train net output #0: loss = 0.409712 (* 1 = 0.409712 loss)
I0506 05:00:10.533779 12834 sgd_solver.cpp:106] Iteration 186400, lr = 1.80144e-06
I0506 05:00:11.463989 12834 solver.cpp:362] Iteration 186500, Testing net (#0)
I0506 05:00:11.464018 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:11.586627 12834 solver.cpp:429]     Test net output #0: loss = 1.05657 (* 1 = 1.05657 loss)
I0506 05:00:11.589136 12834 solver.cpp:242] Iteration 186500 (94.3271 iter/s, 1.06014s/100 iter), loss = 0.68049
I0506 05:00:11.589159 12834 solver.cpp:261]     Train net output #0: loss = 0.68049 (* 1 = 0.68049 loss)
I0506 05:00:11.589169 12834 sgd_solver.cpp:106] Iteration 186500, lr = 1.80144e-06
I0506 05:00:11.590975 12834 solver.cpp:362] Iteration 186500, Testing net (#0)
I0506 05:00:11.590988 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:11.719645 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7725
I0506 05:00:11.719665 12834 solver.cpp:429]     Test net output #1: loss = 0.507374 (* 1 = 0.507374 loss)
I0506 05:00:11.722237 12834 solver.cpp:242] Iteration 186500 (84.1434 iter/s, 1.18845s/100 iter), loss = 0.652778
I0506 05:00:11.722257 12834 solver.cpp:261]     Train net output #0: loss = 0.652778 (* 1 = 0.652778 loss)
I0506 05:00:11.722266 12834 sgd_solver.cpp:106] Iteration 186500, lr = 1.80144e-06
I0506 05:00:12.655714 12834 solver.cpp:242] Iteration 186600 (93.7623 iter/s, 1.06653s/100 iter), loss = 0.239875
I0506 05:00:12.655748 12834 solver.cpp:261]     Train net output #0: loss = 0.239875 (* 1 = 0.239875 loss)
I0506 05:00:12.655758 12834 sgd_solver.cpp:106] Iteration 186600, lr = 1.80144e-06
I0506 05:00:12.660507 12834 solver.cpp:242] Iteration 186600 (106.583 iter/s, 0.938232s/100 iter), loss = 0.694847
I0506 05:00:12.660532 12834 solver.cpp:261]     Train net output #0: loss = 0.694847 (* 1 = 0.694847 loss)
I0506 05:00:12.660542 12834 sgd_solver.cpp:106] Iteration 186600, lr = 1.80144e-06
I0506 05:00:13.593222 12834 solver.cpp:242] Iteration 186700 (106.673 iter/s, 0.937442s/100 iter), loss = 1.04701
I0506 05:00:13.593253 12834 solver.cpp:261]     Train net output #0: loss = 1.04701 (* 1 = 1.04701 loss)
I0506 05:00:13.593272 12834 sgd_solver.cpp:106] Iteration 186700, lr = 1.80144e-06
I0506 05:00:13.597998 12834 solver.cpp:242] Iteration 186700 (106.673 iter/s, 0.937448s/100 iter), loss = 0.391953
I0506 05:00:13.598022 12834 solver.cpp:261]     Train net output #0: loss = 0.391953 (* 1 = 0.391953 loss)
I0506 05:00:13.598031 12834 sgd_solver.cpp:106] Iteration 186700, lr = 1.80144e-06
I0506 05:00:14.530796 12834 solver.cpp:242] Iteration 186800 (106.665 iter/s, 0.937517s/100 iter), loss = 1.07747
I0506 05:00:14.530836 12834 solver.cpp:261]     Train net output #0: loss = 1.07747 (* 1 = 1.07747 loss)
I0506 05:00:14.530846 12834 sgd_solver.cpp:106] Iteration 186800, lr = 1.80144e-06
I0506 05:00:14.535609 12834 solver.cpp:242] Iteration 186800 (106.659 iter/s, 0.937568s/100 iter), loss = 0.518082
I0506 05:00:14.535635 12834 solver.cpp:261]     Train net output #0: loss = 0.518082 (* 1 = 0.518082 loss)
I0506 05:00:14.535645 12834 sgd_solver.cpp:106] Iteration 186800, lr = 1.80144e-06
I0506 05:00:15.468211 12834 solver.cpp:242] Iteration 186900 (106.684 iter/s, 0.937344s/100 iter), loss = 1.45062
I0506 05:00:15.468252 12834 solver.cpp:261]     Train net output #0: loss = 1.45062 (* 1 = 1.45062 loss)
I0506 05:00:15.468261 12834 sgd_solver.cpp:106] Iteration 186900, lr = 1.80144e-06
I0506 05:00:15.472976 12834 solver.cpp:242] Iteration 186900 (106.687 iter/s, 0.937323s/100 iter), loss = 0.776315
I0506 05:00:15.473002 12834 solver.cpp:261]     Train net output #0: loss = 0.776315 (* 1 = 0.776315 loss)
I0506 05:00:15.473011 12834 sgd_solver.cpp:106] Iteration 186900, lr = 1.80144e-06
I0506 05:00:16.403153 12834 solver.cpp:362] Iteration 187000, Testing net (#0)
I0506 05:00:16.403179 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:16.525832 12834 solver.cpp:429]     Test net output #0: loss = 1.20728 (* 1 = 1.20728 loss)
I0506 05:00:16.528375 12834 solver.cpp:242] Iteration 187000 (94.3303 iter/s, 1.06011s/100 iter), loss = 0.945593
I0506 05:00:16.528398 12834 solver.cpp:261]     Train net output #0: loss = 0.945593 (* 1 = 0.945593 loss)
I0506 05:00:16.528408 12834 sgd_solver.cpp:106] Iteration 187000, lr = 1.80144e-06
I0506 05:00:16.530313 12834 solver.cpp:362] Iteration 187000, Testing net (#0)
I0506 05:00:16.530329 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:16.659137 12834 solver.cpp:429]     Test net output #0: accuracy = 0.795
I0506 05:00:16.659157 12834 solver.cpp:429]     Test net output #1: loss = 0.485758 (* 1 = 0.485758 loss)
I0506 05:00:16.661716 12834 solver.cpp:242] Iteration 187000 (84.1259 iter/s, 1.18869s/100 iter), loss = 0.263596
I0506 05:00:16.661736 12834 solver.cpp:261]     Train net output #0: loss = 0.263596 (* 1 = 0.263596 loss)
I0506 05:00:16.661746 12834 sgd_solver.cpp:106] Iteration 187000, lr = 1.80144e-06
I0506 05:00:17.594254 12834 solver.cpp:242] Iteration 187100 (93.8239 iter/s, 1.06583s/100 iter), loss = 0.260237
I0506 05:00:17.594293 12834 solver.cpp:261]     Train net output #0: loss = 0.260237 (* 1 = 0.260237 loss)
I0506 05:00:17.594303 12834 sgd_solver.cpp:106] Iteration 187100, lr = 1.80144e-06
I0506 05:00:17.599036 12834 solver.cpp:242] Iteration 187100 (106.692 iter/s, 0.937282s/100 iter), loss = 0.507492
I0506 05:00:17.599062 12834 solver.cpp:261]     Train net output #0: loss = 0.507492 (* 1 = 0.507492 loss)
I0506 05:00:17.599071 12834 sgd_solver.cpp:106] Iteration 187100, lr = 1.80144e-06
I0506 05:00:18.531188 12834 solver.cpp:242] Iteration 187200 (106.739 iter/s, 0.936869s/100 iter), loss = 1.13597
I0506 05:00:18.531227 12834 solver.cpp:261]     Train net output #0: loss = 1.13597 (* 1 = 1.13597 loss)
I0506 05:00:18.531236 12834 sgd_solver.cpp:106] Iteration 187200, lr = 1.80144e-06
I0506 05:00:18.536056 12834 solver.cpp:242] Iteration 187200 (106.727 iter/s, 0.936966s/100 iter), loss = 0.968768
I0506 05:00:18.536082 12834 solver.cpp:261]     Train net output #0: loss = 0.968768 (* 1 = 0.968768 loss)
I0506 05:00:18.536092 12834 sgd_solver.cpp:106] Iteration 187200, lr = 1.80144e-06
I0506 05:00:19.468420 12834 solver.cpp:242] Iteration 187300 (106.705 iter/s, 0.937167s/100 iter), loss = 1.5248
I0506 05:00:19.468468 12834 solver.cpp:261]     Train net output #0: loss = 1.5248 (* 1 = 1.5248 loss)
I0506 05:00:19.468479 12834 sgd_solver.cpp:106] Iteration 187300, lr = 1.80144e-06
I0506 05:00:19.473204 12834 solver.cpp:242] Iteration 187300 (106.712 iter/s, 0.937104s/100 iter), loss = 0.516386
I0506 05:00:19.473230 12834 solver.cpp:261]     Train net output #0: loss = 0.516386 (* 1 = 0.516386 loss)
I0506 05:00:19.473239 12834 sgd_solver.cpp:106] Iteration 187300, lr = 1.80144e-06
I0506 05:00:20.406234 12834 solver.cpp:242] Iteration 187400 (106.64 iter/s, 0.937734s/100 iter), loss = 0.991221
I0506 05:00:20.406272 12834 solver.cpp:261]     Train net output #0: loss = 0.991221 (* 1 = 0.991221 loss)
I0506 05:00:20.406282 12834 sgd_solver.cpp:106] Iteration 187400, lr = 1.80144e-06
I0506 05:00:20.411018 12834 solver.cpp:242] Iteration 187400 (106.636 iter/s, 0.937772s/100 iter), loss = 0.403433
I0506 05:00:20.411043 12834 solver.cpp:261]     Train net output #0: loss = 0.403433 (* 1 = 0.403433 loss)
I0506 05:00:20.411052 12834 sgd_solver.cpp:106] Iteration 187400, lr = 1.80144e-06
I0506 05:00:21.341241 12834 solver.cpp:362] Iteration 187500, Testing net (#0)
I0506 05:00:21.341264 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:21.464087 12834 solver.cpp:429]     Test net output #0: loss = 1.10467 (* 1 = 1.10467 loss)
I0506 05:00:21.466624 12834 solver.cpp:242] Iteration 187500 (94.31 iter/s, 1.06033s/100 iter), loss = 0.651498
I0506 05:00:21.466647 12834 solver.cpp:261]     Train net output #0: loss = 0.651498 (* 1 = 0.651498 loss)
I0506 05:00:21.466656 12834 sgd_solver.cpp:106] Iteration 187500, lr = 1.80144e-06
I0506 05:00:21.468478 12834 solver.cpp:362] Iteration 187500, Testing net (#0)
I0506 05:00:21.468492 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:21.597174 12834 solver.cpp:429]     Test net output #0: accuracy = 0.771
I0506 05:00:21.597206 12834 solver.cpp:429]     Test net output #1: loss = 0.518313 (* 1 = 0.518313 loss)
I0506 05:00:21.599779 12834 solver.cpp:242] Iteration 187500 (84.1244 iter/s, 1.18872s/100 iter), loss = 0.731373
I0506 05:00:21.599802 12834 solver.cpp:261]     Train net output #0: loss = 0.731373 (* 1 = 0.731373 loss)
I0506 05:00:21.599810 12834 sgd_solver.cpp:106] Iteration 187500, lr = 1.80144e-06
I0506 05:00:22.532693 12834 solver.cpp:242] Iteration 187600 (93.8077 iter/s, 1.06601s/100 iter), loss = 0.572604
I0506 05:00:22.532728 12834 solver.cpp:261]     Train net output #0: loss = 0.572604 (* 1 = 0.572604 loss)
I0506 05:00:22.532738 12834 sgd_solver.cpp:106] Iteration 187600, lr = 1.80144e-06
I0506 05:00:22.537446 12834 solver.cpp:242] Iteration 187600 (106.652 iter/s, 0.937628s/100 iter), loss = 0.59807
I0506 05:00:22.537472 12834 solver.cpp:261]     Train net output #0: loss = 0.59807 (* 1 = 0.59807 loss)
I0506 05:00:22.537482 12834 sgd_solver.cpp:106] Iteration 187600, lr = 1.80144e-06
I0506 05:00:23.470247 12834 solver.cpp:242] Iteration 187700 (106.667 iter/s, 0.937494s/100 iter), loss = 0.491468
I0506 05:00:23.470283 12834 solver.cpp:261]     Train net output #0: loss = 0.491468 (* 1 = 0.491468 loss)
I0506 05:00:23.470291 12834 sgd_solver.cpp:106] Iteration 187700, lr = 1.80144e-06
I0506 05:00:23.475000 12834 solver.cpp:242] Iteration 187700 (106.666 iter/s, 0.93751s/100 iter), loss = 0.478548
I0506 05:00:23.475025 12834 solver.cpp:261]     Train net output #0: loss = 0.478548 (* 1 = 0.478548 loss)
I0506 05:00:23.475033 12834 sgd_solver.cpp:106] Iteration 187700, lr = 1.80144e-06
I0506 05:00:24.408308 12834 solver.cpp:242] Iteration 187800 (106.61 iter/s, 0.937995s/100 iter), loss = 2.37949
I0506 05:00:24.408340 12834 solver.cpp:261]     Train net output #0: loss = 2.37949 (* 1 = 2.37949 loss)
I0506 05:00:24.408349 12834 sgd_solver.cpp:106] Iteration 187800, lr = 1.80144e-06
I0506 05:00:24.413066 12834 solver.cpp:242] Iteration 187800 (106.607 iter/s, 0.938024s/100 iter), loss = 0.485314
I0506 05:00:24.413091 12834 solver.cpp:261]     Train net output #0: loss = 0.485314 (* 1 = 0.485314 loss)
I0506 05:00:24.413110 12834 sgd_solver.cpp:106] Iteration 187800, lr = 1.80144e-06
I0506 05:00:25.345777 12834 solver.cpp:242] Iteration 187900 (106.676 iter/s, 0.937414s/100 iter), loss = 1.30861
I0506 05:00:25.345811 12834 solver.cpp:261]     Train net output #0: loss = 1.30861 (* 1 = 1.30861 loss)
I0506 05:00:25.345820 12834 sgd_solver.cpp:106] Iteration 187900, lr = 1.80144e-06
I0506 05:00:25.350618 12834 solver.cpp:242] Iteration 187900 (106.667 iter/s, 0.937499s/100 iter), loss = 0.781772
I0506 05:00:25.350643 12834 solver.cpp:261]     Train net output #0: loss = 0.781772 (* 1 = 0.781772 loss)
I0506 05:00:25.350652 12834 sgd_solver.cpp:106] Iteration 187900, lr = 1.80144e-06
I0506 05:00:26.281147 12834 solver.cpp:362] Iteration 188000, Testing net (#0)
I0506 05:00:26.281175 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:26.406669 12834 solver.cpp:429]     Test net output #0: loss = 1.08948 (* 1 = 1.08948 loss)
I0506 05:00:26.409323 12834 solver.cpp:242] Iteration 188000 (94.0299 iter/s, 1.06349s/100 iter), loss = 1.07008
I0506 05:00:26.409353 12834 solver.cpp:261]     Train net output #0: loss = 1.07008 (* 1 = 1.07008 loss)
I0506 05:00:26.409363 12834 sgd_solver.cpp:106] Iteration 188000, lr = 1.80144e-06
I0506 05:00:26.411550 12834 solver.cpp:362] Iteration 188000, Testing net (#0)
I0506 05:00:26.411563 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:26.552845 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7835
I0506 05:00:26.552870 12834 solver.cpp:429]     Test net output #1: loss = 0.494802 (* 1 = 0.494802 loss)
I0506 05:00:26.555565 12834 solver.cpp:242] Iteration 188000 (82.9944 iter/s, 1.2049s/100 iter), loss = 0.444203
I0506 05:00:26.555590 12834 solver.cpp:261]     Train net output #0: loss = 0.444203 (* 1 = 0.444203 loss)
I0506 05:00:26.555600 12834 sgd_solver.cpp:106] Iteration 188000, lr = 1.80144e-06
I0506 05:00:27.565644 12834 solver.cpp:242] Iteration 188100 (86.4854 iter/s, 1.15626s/100 iter), loss = 0.528042
I0506 05:00:27.565686 12834 solver.cpp:261]     Train net output #0: loss = 0.528042 (* 1 = 0.528042 loss)
I0506 05:00:27.565696 12834 sgd_solver.cpp:106] Iteration 188100, lr = 1.80144e-06
I0506 05:00:27.570523 12834 solver.cpp:242] Iteration 188100 (98.5315 iter/s, 1.0149s/100 iter), loss = 0.449022
I0506 05:00:27.570549 12834 solver.cpp:261]     Train net output #0: loss = 0.449022 (* 1 = 0.449022 loss)
I0506 05:00:27.570557 12834 sgd_solver.cpp:106] Iteration 188100, lr = 1.80144e-06
I0506 05:00:28.503219 12834 solver.cpp:242] Iteration 188200 (106.666 iter/s, 0.937506s/100 iter), loss = 0.793976
I0506 05:00:28.503262 12834 solver.cpp:261]     Train net output #0: loss = 0.793976 (* 1 = 0.793976 loss)
I0506 05:00:28.503273 12834 sgd_solver.cpp:106] Iteration 188200, lr = 1.80144e-06
I0506 05:00:28.508007 12834 solver.cpp:242] Iteration 188200 (106.673 iter/s, 0.93744s/100 iter), loss = 0.496344
I0506 05:00:28.508031 12834 solver.cpp:261]     Train net output #0: loss = 0.496344 (* 1 = 0.496344 loss)
I0506 05:00:28.508041 12834 sgd_solver.cpp:106] Iteration 188200, lr = 1.80144e-06
I0506 05:00:29.440598 12834 solver.cpp:242] Iteration 188300 (106.689 iter/s, 0.937304s/100 iter), loss = 3.63472
I0506 05:00:29.440639 12834 solver.cpp:261]     Train net output #0: loss = 3.63472 (* 1 = 3.63472 loss)
I0506 05:00:29.440649 12834 sgd_solver.cpp:106] Iteration 188300, lr = 1.80144e-06
I0506 05:00:29.445371 12834 solver.cpp:242] Iteration 188300 (106.687 iter/s, 0.93732s/100 iter), loss = 0.328162
I0506 05:00:29.445399 12834 solver.cpp:261]     Train net output #0: loss = 0.328162 (* 1 = 0.328162 loss)
I0506 05:00:29.445407 12834 sgd_solver.cpp:106] Iteration 188300, lr = 1.80144e-06
I0506 05:00:30.378985 12834 solver.cpp:242] Iteration 188400 (106.573 iter/s, 0.938321s/100 iter), loss = 1.23674
I0506 05:00:30.379025 12834 solver.cpp:261]     Train net output #0: loss = 1.23674 (* 1 = 1.23674 loss)
I0506 05:00:30.379035 12834 sgd_solver.cpp:106] Iteration 188400, lr = 1.80144e-06
I0506 05:00:30.383775 12834 solver.cpp:242] Iteration 188400 (106.569 iter/s, 0.938359s/100 iter), loss = 0.550754
I0506 05:00:30.383810 12834 solver.cpp:261]     Train net output #0: loss = 0.550754 (* 1 = 0.550754 loss)
I0506 05:00:30.383819 12834 sgd_solver.cpp:106] Iteration 188400, lr = 1.80144e-06
I0506 05:00:31.313699 12834 solver.cpp:362] Iteration 188500, Testing net (#0)
I0506 05:00:31.313724 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:31.436528 12834 solver.cpp:429]     Test net output #0: loss = 1.18193 (* 1 = 1.18193 loss)
I0506 05:00:31.439061 12834 solver.cpp:242] Iteration 188500 (94.3381 iter/s, 1.06002s/100 iter), loss = 2.07432
I0506 05:00:31.439086 12834 solver.cpp:261]     Train net output #0: loss = 2.07432 (* 1 = 2.07432 loss)
I0506 05:00:31.439095 12834 sgd_solver.cpp:106] Iteration 188500, lr = 1.80144e-06
I0506 05:00:31.440915 12834 solver.cpp:362] Iteration 188500, Testing net (#0)
I0506 05:00:31.440930 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:31.569802 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7745
I0506 05:00:31.569821 12834 solver.cpp:429]     Test net output #1: loss = 0.494308 (* 1 = 0.494308 loss)
I0506 05:00:31.572363 12834 solver.cpp:242] Iteration 188500 (84.1372 iter/s, 1.18853s/100 iter), loss = 0.507737
I0506 05:00:31.572386 12834 solver.cpp:261]     Train net output #0: loss = 0.507737 (* 1 = 0.507737 loss)
I0506 05:00:31.572393 12834 sgd_solver.cpp:106] Iteration 188500, lr = 1.80144e-06
I0506 05:00:32.505079 12834 solver.cpp:242] Iteration 188600 (93.8118 iter/s, 1.06596s/100 iter), loss = 0.380374
I0506 05:00:32.505120 12834 solver.cpp:261]     Train net output #0: loss = 0.380374 (* 1 = 0.380374 loss)
I0506 05:00:32.505129 12834 sgd_solver.cpp:106] Iteration 188600, lr = 1.80144e-06
I0506 05:00:32.509845 12834 solver.cpp:242] Iteration 188600 (106.673 iter/s, 0.937442s/100 iter), loss = 0.571649
I0506 05:00:32.509871 12834 solver.cpp:261]     Train net output #0: loss = 0.571649 (* 1 = 0.571649 loss)
I0506 05:00:32.509879 12834 sgd_solver.cpp:106] Iteration 188600, lr = 1.80144e-06
I0506 05:00:33.442925 12834 solver.cpp:242] Iteration 188700 (106.635 iter/s, 0.937776s/100 iter), loss = 1.59278
I0506 05:00:33.442965 12834 solver.cpp:261]     Train net output #0: loss = 1.59278 (* 1 = 1.59278 loss)
I0506 05:00:33.442975 12834 sgd_solver.cpp:106] Iteration 188700, lr = 1.80144e-06
I0506 05:00:33.447738 12834 solver.cpp:242] Iteration 188700 (106.627 iter/s, 0.93785s/100 iter), loss = 0.514802
I0506 05:00:33.447764 12834 solver.cpp:261]     Train net output #0: loss = 0.514802 (* 1 = 0.514802 loss)
I0506 05:00:33.447773 12834 sgd_solver.cpp:106] Iteration 188700, lr = 1.80144e-06
I0506 05:00:34.380719 12834 solver.cpp:242] Iteration 188800 (106.641 iter/s, 0.937729s/100 iter), loss = 0.581053
I0506 05:00:34.380755 12834 solver.cpp:261]     Train net output #0: loss = 0.581053 (* 1 = 0.581053 loss)
I0506 05:00:34.380764 12834 sgd_solver.cpp:106] Iteration 188800, lr = 1.80144e-06
I0506 05:00:34.385567 12834 solver.cpp:242] Iteration 188800 (106.635 iter/s, 0.937774s/100 iter), loss = 0.546549
I0506 05:00:34.385593 12834 solver.cpp:261]     Train net output #0: loss = 0.546549 (* 1 = 0.546549 loss)
I0506 05:00:34.385602 12834 sgd_solver.cpp:106] Iteration 188800, lr = 1.80144e-06
I0506 05:00:35.318583 12834 solver.cpp:242] Iteration 188900 (106.633 iter/s, 0.9378s/100 iter), loss = 0.693699
I0506 05:00:35.318620 12834 solver.cpp:261]     Train net output #0: loss = 0.693699 (* 1 = 0.693699 loss)
I0506 05:00:35.318630 12834 sgd_solver.cpp:106] Iteration 188900, lr = 1.80144e-06
I0506 05:00:35.323356 12834 solver.cpp:242] Iteration 188900 (106.639 iter/s, 0.937745s/100 iter), loss = 0.566961
I0506 05:00:35.323381 12834 solver.cpp:261]     Train net output #0: loss = 0.566961 (* 1 = 0.566961 loss)
I0506 05:00:35.323390 12834 sgd_solver.cpp:106] Iteration 188900, lr = 1.80144e-06
I0506 05:00:36.254015 12834 solver.cpp:362] Iteration 189000, Testing net (#0)
I0506 05:00:36.254034 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:36.376762 12834 solver.cpp:429]     Test net output #0: loss = 1.19247 (* 1 = 1.19247 loss)
I0506 05:00:36.379293 12834 solver.cpp:242] Iteration 189000 (94.2814 iter/s, 1.06065s/100 iter), loss = 1.34762
I0506 05:00:36.379314 12834 solver.cpp:261]     Train net output #0: loss = 1.34762 (* 1 = 1.34762 loss)
I0506 05:00:36.379323 12834 sgd_solver.cpp:106] Iteration 189000, lr = 1.80144e-06
I0506 05:00:36.381232 12834 solver.cpp:362] Iteration 189000, Testing net (#0)
I0506 05:00:36.381245 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:36.510284 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7875
I0506 05:00:36.510303 12834 solver.cpp:429]     Test net output #1: loss = 0.504004 (* 1 = 0.504004 loss)
I0506 05:00:36.512878 12834 solver.cpp:242] Iteration 189000 (84.0706 iter/s, 1.18948s/100 iter), loss = 0.904373
I0506 05:00:36.512899 12834 solver.cpp:261]     Train net output #0: loss = 0.904373 (* 1 = 0.904373 loss)
I0506 05:00:36.512907 12834 sgd_solver.cpp:106] Iteration 189000, lr = 1.80144e-06
I0506 05:00:37.446357 12834 solver.cpp:242] Iteration 189100 (93.7195 iter/s, 1.06701s/100 iter), loss = 0.982587
I0506 05:00:37.446389 12834 solver.cpp:261]     Train net output #0: loss = 0.982587 (* 1 = 0.982587 loss)
I0506 05:00:37.446399 12834 sgd_solver.cpp:106] Iteration 189100, lr = 1.80144e-06
I0506 05:00:37.451124 12834 solver.cpp:242] Iteration 189100 (106.586 iter/s, 0.938206s/100 iter), loss = 0.589543
I0506 05:00:37.451148 12834 solver.cpp:261]     Train net output #0: loss = 0.589543 (* 1 = 0.589543 loss)
I0506 05:00:37.451158 12834 sgd_solver.cpp:106] Iteration 189100, lr = 1.80144e-06
I0506 05:00:38.384373 12834 solver.cpp:242] Iteration 189200 (106.616 iter/s, 0.937949s/100 iter), loss = 1.10346
I0506 05:00:38.384415 12834 solver.cpp:261]     Train net output #0: loss = 1.10346 (* 1 = 1.10346 loss)
I0506 05:00:38.384424 12834 sgd_solver.cpp:106] Iteration 189200, lr = 1.80144e-06
I0506 05:00:38.389173 12834 solver.cpp:242] Iteration 189200 (106.609 iter/s, 0.938007s/100 iter), loss = 0.838247
I0506 05:00:38.389210 12834 solver.cpp:261]     Train net output #0: loss = 0.838247 (* 1 = 0.838247 loss)
I0506 05:00:38.389219 12834 sgd_solver.cpp:106] Iteration 189200, lr = 1.80144e-06
I0506 05:00:39.343173 12834 solver.cpp:242] Iteration 189300 (104.305 iter/s, 0.958729s/100 iter), loss = 0.824982
I0506 05:00:39.343221 12834 solver.cpp:261]     Train net output #0: loss = 0.824982 (* 1 = 0.824982 loss)
I0506 05:00:39.343232 12834 sgd_solver.cpp:106] Iteration 189300, lr = 1.80144e-06
I0506 05:00:39.347965 12834 solver.cpp:242] Iteration 189300 (104.304 iter/s, 0.958735s/100 iter), loss = 0.645713
I0506 05:00:39.347990 12834 solver.cpp:261]     Train net output #0: loss = 0.645713 (* 1 = 0.645713 loss)
I0506 05:00:39.347998 12834 sgd_solver.cpp:106] Iteration 189300, lr = 1.80144e-06
I0506 05:00:40.280381 12834 solver.cpp:242] Iteration 189400 (106.709 iter/s, 0.937129s/100 iter), loss = 1.04584
I0506 05:00:40.280422 12834 solver.cpp:261]     Train net output #0: loss = 1.04584 (* 1 = 1.04584 loss)
I0506 05:00:40.280432 12834 sgd_solver.cpp:106] Iteration 189400, lr = 1.80144e-06
I0506 05:00:40.285176 12834 solver.cpp:242] Iteration 189400 (106.704 iter/s, 0.937169s/100 iter), loss = 0.394233
I0506 05:00:40.285204 12834 solver.cpp:261]     Train net output #0: loss = 0.394233 (* 1 = 0.394233 loss)
I0506 05:00:40.285214 12834 sgd_solver.cpp:106] Iteration 189400, lr = 1.80144e-06
I0506 05:00:41.214907 12834 solver.cpp:362] Iteration 189500, Testing net (#0)
I0506 05:00:41.214936 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:41.337566 12834 solver.cpp:429]     Test net output #0: loss = 1.12544 (* 1 = 1.12544 loss)
I0506 05:00:41.340090 12834 solver.cpp:242] Iteration 189500 (94.3709 iter/s, 1.05965s/100 iter), loss = 0.44711
I0506 05:00:41.340114 12834 solver.cpp:261]     Train net output #0: loss = 0.44711 (* 1 = 0.44711 loss)
I0506 05:00:41.340123 12834 sgd_solver.cpp:106] Iteration 189500, lr = 1.80144e-06
I0506 05:00:41.341960 12834 solver.cpp:362] Iteration 189500, Testing net (#0)
I0506 05:00:41.341974 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:41.470650 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7925
I0506 05:00:41.470671 12834 solver.cpp:429]     Test net output #1: loss = 0.476673 (* 1 = 0.476673 loss)
I0506 05:00:41.473238 12834 solver.cpp:242] Iteration 189500 (84.1742 iter/s, 1.18801s/100 iter), loss = 0.350296
I0506 05:00:41.473259 12834 solver.cpp:261]     Train net output #0: loss = 0.350296 (* 1 = 0.350296 loss)
I0506 05:00:41.473268 12834 sgd_solver.cpp:106] Iteration 189500, lr = 1.80144e-06
I0506 05:00:42.406631 12834 solver.cpp:242] Iteration 189600 (93.7662 iter/s, 1.06648s/100 iter), loss = 0.275148
I0506 05:00:42.406688 12834 solver.cpp:261]     Train net output #0: loss = 0.275148 (* 1 = 0.275148 loss)
I0506 05:00:42.406703 12834 sgd_solver.cpp:106] Iteration 189600, lr = 1.80144e-06
I0506 05:00:42.411442 12834 solver.cpp:242] Iteration 189600 (106.591 iter/s, 0.938164s/100 iter), loss = 0.494467
I0506 05:00:42.411468 12834 solver.cpp:261]     Train net output #0: loss = 0.494467 (* 1 = 0.494467 loss)
I0506 05:00:42.411476 12834 sgd_solver.cpp:106] Iteration 189600, lr = 1.80144e-06
I0506 05:00:43.344017 12834 solver.cpp:242] Iteration 189700 (106.689 iter/s, 0.937306s/100 iter), loss = 0.738117
I0506 05:00:43.344056 12834 solver.cpp:261]     Train net output #0: loss = 0.738117 (* 1 = 0.738117 loss)
I0506 05:00:43.344066 12834 sgd_solver.cpp:106] Iteration 189700, lr = 1.80144e-06
I0506 05:00:43.348814 12834 solver.cpp:242] Iteration 189700 (106.686 iter/s, 0.937328s/100 iter), loss = 0.773828
I0506 05:00:43.348841 12834 solver.cpp:261]     Train net output #0: loss = 0.773828 (* 1 = 0.773828 loss)
I0506 05:00:43.348850 12834 sgd_solver.cpp:106] Iteration 189700, lr = 1.80144e-06
I0506 05:00:44.282032 12834 solver.cpp:242] Iteration 189800 (106.616 iter/s, 0.937946s/100 iter), loss = 1.43812
I0506 05:00:44.282068 12834 solver.cpp:261]     Train net output #0: loss = 1.43812 (* 1 = 1.43812 loss)
I0506 05:00:44.282078 12834 sgd_solver.cpp:106] Iteration 189800, lr = 1.80144e-06
I0506 05:00:44.286823 12834 solver.cpp:242] Iteration 189800 (106.614 iter/s, 0.937963s/100 iter), loss = 0.640973
I0506 05:00:44.286849 12834 solver.cpp:261]     Train net output #0: loss = 0.640973 (* 1 = 0.640973 loss)
I0506 05:00:44.286857 12834 sgd_solver.cpp:106] Iteration 189800, lr = 1.80144e-06
I0506 05:00:45.219661 12834 solver.cpp:242] Iteration 189900 (106.659 iter/s, 0.937569s/100 iter), loss = 2.0563
I0506 05:00:45.219698 12834 solver.cpp:261]     Train net output #0: loss = 2.0563 (* 1 = 2.0563 loss)
I0506 05:00:45.219708 12834 sgd_solver.cpp:106] Iteration 189900, lr = 1.80144e-06
I0506 05:00:45.224555 12834 solver.cpp:242] Iteration 189900 (106.647 iter/s, 0.937676s/100 iter), loss = 0.624049
I0506 05:00:45.224582 12834 solver.cpp:261]     Train net output #0: loss = 0.624049 (* 1 = 0.624049 loss)
I0506 05:00:45.224591 12834 sgd_solver.cpp:106] Iteration 189900, lr = 1.80144e-06
I0506 05:00:46.154528 12834 solver.cpp:362] Iteration 190000, Testing net (#0)
I0506 05:00:46.154553 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:46.277241 12834 solver.cpp:429]     Test net output #0: loss = 1.16342 (* 1 = 1.16342 loss)
I0506 05:00:46.279762 12834 solver.cpp:242] Iteration 190000 (94.3356 iter/s, 1.06004s/100 iter), loss = 0.663021
I0506 05:00:46.279783 12834 solver.cpp:261]     Train net output #0: loss = 0.663021 (* 1 = 0.663021 loss)
I0506 05:00:46.279791 12834 sgd_solver.cpp:106] Iteration 190000, lr = 1.44115e-06
I0506 05:00:46.281622 12834 solver.cpp:362] Iteration 190000, Testing net (#0)
I0506 05:00:46.281638 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:46.414135 12834 solver.cpp:429]     Test net output #0: accuracy = 0.782
I0506 05:00:46.414162 12834 solver.cpp:429]     Test net output #1: loss = 0.505535 (* 1 = 0.505535 loss)
I0506 05:00:46.416857 12834 solver.cpp:242] Iteration 190000 (83.8748 iter/s, 1.19225s/100 iter), loss = 0.107084
I0506 05:00:46.416882 12834 solver.cpp:261]     Train net output #0: loss = 0.107084 (* 1 = 0.107084 loss)
I0506 05:00:46.416893 12834 sgd_solver.cpp:106] Iteration 190000, lr = 1.44115e-06
I0506 05:00:47.440181 12834 solver.cpp:242] Iteration 190100 (86.1799 iter/s, 1.16036s/100 iter), loss = 0.905858
I0506 05:00:47.440233 12834 solver.cpp:261]     Train net output #0: loss = 0.905858 (* 1 = 0.905858 loss)
I0506 05:00:47.440243 12834 sgd_solver.cpp:106] Iteration 190100, lr = 1.44115e-06
I0506 05:00:47.445021 12834 solver.cpp:242] Iteration 190100 (97.2648 iter/s, 1.02812s/100 iter), loss = 0.644633
I0506 05:00:47.445046 12834 solver.cpp:261]     Train net output #0: loss = 0.644633 (* 1 = 0.644633 loss)
I0506 05:00:47.445055 12834 sgd_solver.cpp:106] Iteration 190100, lr = 1.44115e-06
I0506 05:00:48.377537 12834 solver.cpp:242] Iteration 190200 (106.692 iter/s, 0.937277s/100 iter), loss = 0.38171
I0506 05:00:48.377571 12834 solver.cpp:261]     Train net output #0: loss = 0.38171 (* 1 = 0.38171 loss)
I0506 05:00:48.377581 12834 sgd_solver.cpp:106] Iteration 190200, lr = 1.44115e-06
I0506 05:00:48.382306 12834 solver.cpp:242] Iteration 190200 (106.696 iter/s, 0.937241s/100 iter), loss = 0.266421
I0506 05:00:48.382333 12834 solver.cpp:261]     Train net output #0: loss = 0.266421 (* 1 = 0.266421 loss)
I0506 05:00:48.382342 12834 sgd_solver.cpp:106] Iteration 190200, lr = 1.44115e-06
I0506 05:00:49.314926 12834 solver.cpp:242] Iteration 190300 (106.687 iter/s, 0.937325s/100 iter), loss = 1.09836
I0506 05:00:49.314960 12834 solver.cpp:261]     Train net output #0: loss = 1.09836 (* 1 = 1.09836 loss)
I0506 05:00:49.314970 12834 sgd_solver.cpp:106] Iteration 190300, lr = 1.44115e-06
I0506 05:00:49.319722 12834 solver.cpp:242] Iteration 190300 (106.681 iter/s, 0.937372s/100 iter), loss = 0.504526
I0506 05:00:49.319747 12834 solver.cpp:261]     Train net output #0: loss = 0.504526 (* 1 = 0.504526 loss)
I0506 05:00:49.319756 12834 sgd_solver.cpp:106] Iteration 190300, lr = 1.44115e-06
I0506 05:00:50.252528 12834 solver.cpp:242] Iteration 190400 (106.662 iter/s, 0.937543s/100 iter), loss = 0.549482
I0506 05:00:50.252573 12834 solver.cpp:261]     Train net output #0: loss = 0.549482 (* 1 = 0.549482 loss)
I0506 05:00:50.252584 12834 sgd_solver.cpp:106] Iteration 190400, lr = 1.44115e-06
I0506 05:00:50.257306 12834 solver.cpp:242] Iteration 190400 (106.662 iter/s, 0.937541s/100 iter), loss = 0.407611
I0506 05:00:50.257330 12834 solver.cpp:261]     Train net output #0: loss = 0.407611 (* 1 = 0.407611 loss)
I0506 05:00:50.257339 12834 sgd_solver.cpp:106] Iteration 190400, lr = 1.44115e-06
I0506 05:00:51.187433 12834 solver.cpp:362] Iteration 190500, Testing net (#0)
I0506 05:00:51.187459 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:51.310231 12834 solver.cpp:429]     Test net output #0: loss = 1.2001 (* 1 = 1.2001 loss)
I0506 05:00:51.312750 12834 solver.cpp:242] Iteration 190500 (94.3255 iter/s, 1.06016s/100 iter), loss = 1.44168
I0506 05:00:51.312772 12834 solver.cpp:261]     Train net output #0: loss = 1.44168 (* 1 = 1.44168 loss)
I0506 05:00:51.312782 12834 sgd_solver.cpp:106] Iteration 190500, lr = 1.44115e-06
I0506 05:00:51.314592 12834 solver.cpp:362] Iteration 190500, Testing net (#0)
I0506 05:00:51.314604 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:51.443272 12834 solver.cpp:429]     Test net output #0: accuracy = 0.791
I0506 05:00:51.443292 12834 solver.cpp:429]     Test net output #1: loss = 0.4896 (* 1 = 0.4896 loss)
I0506 05:00:51.445857 12834 solver.cpp:242] Iteration 190500 (84.1394 iter/s, 1.1885s/100 iter), loss = 0.612107
I0506 05:00:51.445878 12834 solver.cpp:261]     Train net output #0: loss = 0.612107 (* 1 = 0.612107 loss)
I0506 05:00:51.445886 12834 sgd_solver.cpp:106] Iteration 190500, lr = 1.44115e-06
I0506 05:00:52.379039 12834 solver.cpp:242] Iteration 190600 (93.7874 iter/s, 1.06624s/100 iter), loss = 1.73109
I0506 05:00:52.379067 12834 solver.cpp:261]     Train net output #0: loss = 1.73109 (* 1 = 1.73109 loss)
I0506 05:00:52.379077 12834 sgd_solver.cpp:106] Iteration 190600, lr = 1.44115e-06
I0506 05:00:52.383816 12834 solver.cpp:242] Iteration 190600 (106.619 iter/s, 0.93792s/100 iter), loss = 0.867247
I0506 05:00:52.383848 12834 solver.cpp:261]     Train net output #0: loss = 0.867247 (* 1 = 0.867247 loss)
I0506 05:00:52.383857 12834 sgd_solver.cpp:106] Iteration 190600, lr = 1.44115e-06
I0506 05:00:53.316699 12834 solver.cpp:242] Iteration 190700 (106.655 iter/s, 0.9376s/100 iter), loss = 1.68533
I0506 05:00:53.316743 12834 solver.cpp:261]     Train net output #0: loss = 1.68533 (* 1 = 1.68533 loss)
I0506 05:00:53.316752 12834 sgd_solver.cpp:106] Iteration 190700, lr = 1.44115e-06
I0506 05:00:53.321471 12834 solver.cpp:242] Iteration 190700 (106.655 iter/s, 0.937606s/100 iter), loss = 0.596656
I0506 05:00:53.321497 12834 solver.cpp:261]     Train net output #0: loss = 0.596656 (* 1 = 0.596656 loss)
I0506 05:00:53.321506 12834 sgd_solver.cpp:106] Iteration 190700, lr = 1.44115e-06
I0506 05:00:54.254549 12834 solver.cpp:242] Iteration 190800 (106.635 iter/s, 0.937782s/100 iter), loss = 1.59881
I0506 05:00:54.254590 12834 solver.cpp:261]     Train net output #0: loss = 1.59881 (* 1 = 1.59881 loss)
I0506 05:00:54.254600 12834 sgd_solver.cpp:106] Iteration 190800, lr = 1.44115e-06
I0506 05:00:54.259392 12834 solver.cpp:242] Iteration 190800 (106.625 iter/s, 0.937868s/100 iter), loss = 0.697272
I0506 05:00:54.259420 12834 solver.cpp:261]     Train net output #0: loss = 0.697272 (* 1 = 0.697272 loss)
I0506 05:00:54.259429 12834 sgd_solver.cpp:106] Iteration 190800, lr = 1.44115e-06
I0506 05:00:55.191696 12834 solver.cpp:242] Iteration 190900 (106.714 iter/s, 0.93708s/100 iter), loss = 0.182147
I0506 05:00:55.191737 12834 solver.cpp:261]     Train net output #0: loss = 0.182147 (* 1 = 0.182147 loss)
I0506 05:00:55.191747 12834 sgd_solver.cpp:106] Iteration 190900, lr = 1.44115e-06
I0506 05:00:55.196473 12834 solver.cpp:242] Iteration 190900 (106.72 iter/s, 0.937036s/100 iter), loss = 0.516398
I0506 05:00:55.196498 12834 solver.cpp:261]     Train net output #0: loss = 0.516398 (* 1 = 0.516398 loss)
I0506 05:00:55.196507 12834 sgd_solver.cpp:106] Iteration 190900, lr = 1.44115e-06
I0506 05:00:56.126793 12834 solver.cpp:362] Iteration 191000, Testing net (#0)
I0506 05:00:56.126821 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:56.249559 12834 solver.cpp:429]     Test net output #0: loss = 1.15383 (* 1 = 1.15383 loss)
I0506 05:00:56.252073 12834 solver.cpp:242] Iteration 191000 (94.3114 iter/s, 1.06032s/100 iter), loss = 0.675499
I0506 05:00:56.252092 12834 solver.cpp:261]     Train net output #0: loss = 0.675499 (* 1 = 0.675499 loss)
I0506 05:00:56.252101 12834 sgd_solver.cpp:106] Iteration 191000, lr = 1.44115e-06
I0506 05:00:56.253921 12834 solver.cpp:362] Iteration 191000, Testing net (#0)
I0506 05:00:56.253937 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:00:56.382899 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7755
I0506 05:00:56.382920 12834 solver.cpp:429]     Test net output #1: loss = 0.49071 (* 1 = 0.49071 loss)
I0506 05:00:56.385470 12834 solver.cpp:242] Iteration 191000 (84.1078 iter/s, 1.18895s/100 iter), loss = 0.643459
I0506 05:00:56.385490 12834 solver.cpp:261]     Train net output #0: loss = 0.643459 (* 1 = 0.643459 loss)
I0506 05:00:56.385499 12834 sgd_solver.cpp:106] Iteration 191000, lr = 1.44115e-06
I0506 05:00:57.318452 12834 solver.cpp:242] Iteration 191100 (93.7796 iter/s, 1.06633s/100 iter), loss = 0.474238
I0506 05:00:57.318493 12834 solver.cpp:261]     Train net output #0: loss = 0.474238 (* 1 = 0.474238 loss)
I0506 05:00:57.318502 12834 sgd_solver.cpp:106] Iteration 191100, lr = 1.44115e-06
I0506 05:00:57.323227 12834 solver.cpp:242] Iteration 191100 (106.642 iter/s, 0.937718s/100 iter), loss = 0.396971
I0506 05:00:57.323252 12834 solver.cpp:261]     Train net output #0: loss = 0.396971 (* 1 = 0.396971 loss)
I0506 05:00:57.323261 12834 sgd_solver.cpp:106] Iteration 191100, lr = 1.44115e-06
I0506 05:00:58.256616 12834 solver.cpp:242] Iteration 191200 (106.6 iter/s, 0.938091s/100 iter), loss = 0.708625
I0506 05:00:58.256657 12834 solver.cpp:261]     Train net output #0: loss = 0.708625 (* 1 = 0.708625 loss)
I0506 05:00:58.256667 12834 sgd_solver.cpp:106] Iteration 191200, lr = 1.44115e-06
I0506 05:00:58.261412 12834 solver.cpp:242] Iteration 191200 (106.594 iter/s, 0.938143s/100 iter), loss = 0.220926
I0506 05:00:58.261437 12834 solver.cpp:261]     Train net output #0: loss = 0.220926 (* 1 = 0.220926 loss)
I0506 05:00:58.261446 12834 sgd_solver.cpp:106] Iteration 191200, lr = 1.44115e-06
I0506 05:00:59.193716 12834 solver.cpp:242] Iteration 191300 (106.72 iter/s, 0.937034s/100 iter), loss = 2.16337
I0506 05:00:59.193753 12834 solver.cpp:261]     Train net output #0: loss = 2.16337 (* 1 = 2.16337 loss)
I0506 05:00:59.193763 12834 sgd_solver.cpp:106] Iteration 191300, lr = 1.44115e-06
I0506 05:00:59.198482 12834 solver.cpp:242] Iteration 191300 (106.721 iter/s, 0.937027s/100 iter), loss = 0.61604
I0506 05:00:59.198508 12834 solver.cpp:261]     Train net output #0: loss = 0.61604 (* 1 = 0.61604 loss)
I0506 05:00:59.198516 12834 sgd_solver.cpp:106] Iteration 191300, lr = 1.44115e-06
I0506 05:01:00.131806 12834 solver.cpp:242] Iteration 191400 (106.607 iter/s, 0.938023s/100 iter), loss = 1.46827
I0506 05:01:00.131844 12834 solver.cpp:261]     Train net output #0: loss = 1.46827 (* 1 = 1.46827 loss)
I0506 05:01:00.131853 12834 sgd_solver.cpp:106] Iteration 191400, lr = 1.44115e-06
I0506 05:01:00.136584 12834 solver.cpp:242] Iteration 191400 (106.603 iter/s, 0.938058s/100 iter), loss = 0.522897
I0506 05:01:00.136610 12834 solver.cpp:261]     Train net output #0: loss = 0.522897 (* 1 = 0.522897 loss)
I0506 05:01:00.136620 12834 sgd_solver.cpp:106] Iteration 191400, lr = 1.44115e-06
I0506 05:01:01.081449 12834 solver.cpp:362] Iteration 191500, Testing net (#0)
I0506 05:01:01.081475 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:01.204388 12834 solver.cpp:429]     Test net output #0: loss = 1.04517 (* 1 = 1.04517 loss)
I0506 05:01:01.206917 12834 solver.cpp:242] Iteration 191500 (93.0188 iter/s, 1.07505s/100 iter), loss = 0.632176
I0506 05:01:01.206940 12834 solver.cpp:261]     Train net output #0: loss = 0.632176 (* 1 = 0.632176 loss)
I0506 05:01:01.206949 12834 sgd_solver.cpp:106] Iteration 191500, lr = 1.44115e-06
I0506 05:01:01.208796 12834 solver.cpp:362] Iteration 191500, Testing net (#0)
I0506 05:01:01.208809 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:01.337625 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7855
I0506 05:01:01.337646 12834 solver.cpp:429]     Test net output #1: loss = 0.489024 (* 1 = 0.489024 loss)
I0506 05:01:01.340206 12834 solver.cpp:242] Iteration 191500 (83.0859 iter/s, 1.20357s/100 iter), loss = 0.677679
I0506 05:01:01.340226 12834 solver.cpp:261]     Train net output #0: loss = 0.677679 (* 1 = 0.677679 loss)
I0506 05:01:01.340235 12834 sgd_solver.cpp:106] Iteration 191500, lr = 1.44115e-06
I0506 05:01:02.275041 12834 solver.cpp:242] Iteration 191600 (93.627 iter/s, 1.06807s/100 iter), loss = 1.53221
I0506 05:01:02.275079 12834 solver.cpp:261]     Train net output #0: loss = 1.53221 (* 1 = 1.53221 loss)
I0506 05:01:02.275089 12834 sgd_solver.cpp:106] Iteration 191600, lr = 1.44115e-06
I0506 05:01:02.279811 12834 solver.cpp:242] Iteration 191600 (106.432 iter/s, 0.939566s/100 iter), loss = 0.431582
I0506 05:01:02.279835 12834 solver.cpp:261]     Train net output #0: loss = 0.431582 (* 1 = 0.431582 loss)
I0506 05:01:02.279844 12834 sgd_solver.cpp:106] Iteration 191600, lr = 1.44115e-06
I0506 05:01:03.212581 12834 solver.cpp:242] Iteration 191700 (106.669 iter/s, 0.93748s/100 iter), loss = 1.22001
I0506 05:01:03.212613 12834 solver.cpp:261]     Train net output #0: loss = 1.22001 (* 1 = 1.22001 loss)
I0506 05:01:03.212623 12834 sgd_solver.cpp:106] Iteration 191700, lr = 1.44115e-06
I0506 05:01:03.217444 12834 solver.cpp:242] Iteration 191700 (106.657 iter/s, 0.937581s/100 iter), loss = 0.621571
I0506 05:01:03.217468 12834 solver.cpp:261]     Train net output #0: loss = 0.621571 (* 1 = 0.621571 loss)
I0506 05:01:03.217478 12834 sgd_solver.cpp:106] Iteration 191700, lr = 1.44115e-06
I0506 05:01:04.149988 12834 solver.cpp:242] Iteration 191800 (106.684 iter/s, 0.937348s/100 iter), loss = 0.187265
I0506 05:01:04.150041 12834 solver.cpp:261]     Train net output #0: loss = 0.187265 (* 1 = 0.187265 loss)
I0506 05:01:04.150051 12834 sgd_solver.cpp:106] Iteration 191800, lr = 1.44115e-06
I0506 05:01:04.154768 12834 solver.cpp:242] Iteration 191800 (106.691 iter/s, 0.937283s/100 iter), loss = 0.352108
I0506 05:01:04.154794 12834 solver.cpp:261]     Train net output #0: loss = 0.352108 (* 1 = 0.352108 loss)
I0506 05:01:04.154803 12834 sgd_solver.cpp:106] Iteration 191800, lr = 1.44115e-06
I0506 05:01:05.087692 12834 solver.cpp:242] Iteration 191900 (106.652 iter/s, 0.937628s/100 iter), loss = 1.21423
I0506 05:01:05.087733 12834 solver.cpp:261]     Train net output #0: loss = 1.21423 (* 1 = 1.21423 loss)
I0506 05:01:05.087741 12834 sgd_solver.cpp:106] Iteration 191900, lr = 1.44115e-06
I0506 05:01:05.092511 12834 solver.cpp:242] Iteration 191900 (106.645 iter/s, 0.93769s/100 iter), loss = 0.543451
I0506 05:01:05.092537 12834 solver.cpp:261]     Train net output #0: loss = 0.543451 (* 1 = 0.543451 loss)
I0506 05:01:05.092547 12834 sgd_solver.cpp:106] Iteration 191900, lr = 1.44115e-06
I0506 05:01:06.022167 12834 solver.cpp:362] Iteration 192000, Testing net (#0)
I0506 05:01:06.022195 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:06.144976 12834 solver.cpp:429]     Test net output #0: loss = 1.32065 (* 1 = 1.32065 loss)
I0506 05:01:06.147495 12834 solver.cpp:242] Iteration 192000 (94.3624 iter/s, 1.05974s/100 iter), loss = 0.807478
I0506 05:01:06.147518 12834 solver.cpp:261]     Train net output #0: loss = 0.807478 (* 1 = 0.807478 loss)
I0506 05:01:06.147527 12834 sgd_solver.cpp:106] Iteration 192000, lr = 1.44115e-06
I0506 05:01:06.149340 12834 solver.cpp:362] Iteration 192000, Testing net (#0)
I0506 05:01:06.149354 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:06.277947 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7965
I0506 05:01:06.277967 12834 solver.cpp:429]     Test net output #1: loss = 0.47409 (* 1 = 0.47409 loss)
I0506 05:01:06.280521 12834 solver.cpp:242] Iteration 192000 (84.1777 iter/s, 1.18796s/100 iter), loss = 0.343918
I0506 05:01:06.280542 12834 solver.cpp:261]     Train net output #0: loss = 0.343918 (* 1 = 0.343918 loss)
I0506 05:01:06.280555 12834 sgd_solver.cpp:106] Iteration 192000, lr = 1.44115e-06
I0506 05:01:07.213482 12834 solver.cpp:242] Iteration 192100 (93.815 iter/s, 1.06593s/100 iter), loss = 3.02791
I0506 05:01:07.213523 12834 solver.cpp:261]     Train net output #0: loss = 3.02791 (* 1 = 3.02791 loss)
I0506 05:01:07.213532 12834 sgd_solver.cpp:106] Iteration 192100, lr = 1.44115e-06
I0506 05:01:07.218250 12834 solver.cpp:242] Iteration 192100 (106.645 iter/s, 0.93769s/100 iter), loss = 0.542927
I0506 05:01:07.218276 12834 solver.cpp:261]     Train net output #0: loss = 0.542927 (* 1 = 0.542927 loss)
I0506 05:01:07.218286 12834 sgd_solver.cpp:106] Iteration 192100, lr = 1.44115e-06
I0506 05:01:08.151268 12834 solver.cpp:242] Iteration 192200 (106.642 iter/s, 0.93772s/100 iter), loss = 0.836437
I0506 05:01:08.151322 12834 solver.cpp:261]     Train net output #0: loss = 0.836437 (* 1 = 0.836437 loss)
I0506 05:01:08.151332 12834 sgd_solver.cpp:106] Iteration 192200, lr = 1.44115e-06
I0506 05:01:08.156111 12834 solver.cpp:242] Iteration 192200 (106.631 iter/s, 0.937816s/100 iter), loss = 0.339269
I0506 05:01:08.156136 12834 solver.cpp:261]     Train net output #0: loss = 0.339269 (* 1 = 0.339269 loss)
I0506 05:01:08.156146 12834 sgd_solver.cpp:106] Iteration 192200, lr = 1.44115e-06
I0506 05:01:09.088974 12834 solver.cpp:242] Iteration 192300 (106.653 iter/s, 0.937621s/100 iter), loss = 1.13869
I0506 05:01:09.089015 12834 solver.cpp:261]     Train net output #0: loss = 1.13869 (* 1 = 1.13869 loss)
I0506 05:01:09.089023 12834 sgd_solver.cpp:106] Iteration 192300, lr = 1.44115e-06
I0506 05:01:09.093755 12834 solver.cpp:242] Iteration 192300 (106.655 iter/s, 0.9376s/100 iter), loss = 0.748483
I0506 05:01:09.093780 12834 solver.cpp:261]     Train net output #0: loss = 0.748483 (* 1 = 0.748483 loss)
I0506 05:01:09.093789 12834 sgd_solver.cpp:106] Iteration 192300, lr = 1.44115e-06
I0506 05:01:10.026680 12834 solver.cpp:242] Iteration 192400 (106.651 iter/s, 0.937642s/100 iter), loss = 0.843051
I0506 05:01:10.026718 12834 solver.cpp:261]     Train net output #0: loss = 0.843051 (* 1 = 0.843051 loss)
I0506 05:01:10.026728 12834 sgd_solver.cpp:106] Iteration 192400, lr = 1.44115e-06
I0506 05:01:10.031445 12834 solver.cpp:242] Iteration 192400 (106.65 iter/s, 0.937646s/100 iter), loss = 0.419635
I0506 05:01:10.031468 12834 solver.cpp:261]     Train net output #0: loss = 0.419635 (* 1 = 0.419635 loss)
I0506 05:01:10.031477 12834 sgd_solver.cpp:106] Iteration 192400, lr = 1.44115e-06
I0506 05:01:10.961813 12834 solver.cpp:362] Iteration 192500, Testing net (#0)
I0506 05:01:10.961838 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:11.084636 12834 solver.cpp:429]     Test net output #0: loss = 1.2747 (* 1 = 1.2747 loss)
I0506 05:01:11.087172 12834 solver.cpp:242] Iteration 192500 (94.301 iter/s, 1.06043s/100 iter), loss = 4.1646
I0506 05:01:11.087191 12834 solver.cpp:261]     Train net output #0: loss = 4.1646 (* 1 = 4.1646 loss)
I0506 05:01:11.087199 12834 sgd_solver.cpp:106] Iteration 192500, lr = 1.44115e-06
I0506 05:01:11.089040 12834 solver.cpp:362] Iteration 192500, Testing net (#0)
I0506 05:01:11.089056 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:11.217705 12834 solver.cpp:429]     Test net output #0: accuracy = 0.794
I0506 05:01:11.217726 12834 solver.cpp:429]     Test net output #1: loss = 0.481844 (* 1 = 0.481844 loss)
I0506 05:01:11.220273 12834 solver.cpp:242] Iteration 192500 (84.1196 iter/s, 1.18878s/100 iter), loss = 0.642915
I0506 05:01:11.220293 12834 solver.cpp:261]     Train net output #0: loss = 0.642915 (* 1 = 0.642915 loss)
I0506 05:01:11.220301 12834 sgd_solver.cpp:106] Iteration 192500, lr = 1.44115e-06
I0506 05:01:12.155300 12834 solver.cpp:242] Iteration 192600 (93.6257 iter/s, 1.06808s/100 iter), loss = 0.423604
I0506 05:01:12.155339 12834 solver.cpp:261]     Train net output #0: loss = 0.423604 (* 1 = 0.423604 loss)
I0506 05:01:12.155349 12834 sgd_solver.cpp:106] Iteration 192600, lr = 1.44115e-06
I0506 05:01:12.160168 12834 solver.cpp:242] Iteration 192600 (106.4 iter/s, 0.939847s/100 iter), loss = 0.371612
I0506 05:01:12.160195 12834 solver.cpp:261]     Train net output #0: loss = 0.371612 (* 1 = 0.371612 loss)
I0506 05:01:12.160204 12834 sgd_solver.cpp:106] Iteration 192600, lr = 1.44115e-06
I0506 05:01:13.092648 12834 solver.cpp:242] Iteration 192700 (106.692 iter/s, 0.937282s/100 iter), loss = 1.07166
I0506 05:01:13.092684 12834 solver.cpp:261]     Train net output #0: loss = 1.07166 (* 1 = 1.07166 loss)
I0506 05:01:13.092694 12834 sgd_solver.cpp:106] Iteration 192700, lr = 1.44115e-06
I0506 05:01:13.097424 12834 solver.cpp:242] Iteration 192700 (106.699 iter/s, 0.937212s/100 iter), loss = 0.439355
I0506 05:01:13.097450 12834 solver.cpp:261]     Train net output #0: loss = 0.439355 (* 1 = 0.439355 loss)
I0506 05:01:13.097458 12834 sgd_solver.cpp:106] Iteration 192700, lr = 1.44115e-06
I0506 05:01:14.030252 12834 solver.cpp:242] Iteration 192800 (106.661 iter/s, 0.937547s/100 iter), loss = 1.04642
I0506 05:01:14.030284 12834 solver.cpp:261]     Train net output #0: loss = 1.04642 (* 1 = 1.04642 loss)
I0506 05:01:14.030294 12834 sgd_solver.cpp:106] Iteration 192800, lr = 1.44115e-06
I0506 05:01:14.035090 12834 solver.cpp:242] Iteration 192800 (106.654 iter/s, 0.937614s/100 iter), loss = 0.324956
I0506 05:01:14.035115 12834 solver.cpp:261]     Train net output #0: loss = 0.324956 (* 1 = 0.324956 loss)
I0506 05:01:14.035123 12834 sgd_solver.cpp:106] Iteration 192800, lr = 1.44115e-06
I0506 05:01:14.967505 12834 solver.cpp:242] Iteration 192900 (106.702 iter/s, 0.937192s/100 iter), loss = 0.405062
I0506 05:01:14.967546 12834 solver.cpp:261]     Train net output #0: loss = 0.405062 (* 1 = 0.405062 loss)
I0506 05:01:14.967556 12834 sgd_solver.cpp:106] Iteration 192900, lr = 1.44115e-06
I0506 05:01:14.972293 12834 solver.cpp:242] Iteration 192900 (106.705 iter/s, 0.937162s/100 iter), loss = 0.366375
I0506 05:01:14.972329 12834 solver.cpp:261]     Train net output #0: loss = 0.366375 (* 1 = 0.366375 loss)
I0506 05:01:14.972339 12834 sgd_solver.cpp:106] Iteration 192900, lr = 1.44115e-06
I0506 05:01:15.902086 12834 solver.cpp:362] Iteration 193000, Testing net (#0)
I0506 05:01:15.902113 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:16.024966 12834 solver.cpp:429]     Test net output #0: loss = 1.28897 (* 1 = 1.28897 loss)
I0506 05:01:16.027494 12834 solver.cpp:242] Iteration 193000 (94.3459 iter/s, 1.05993s/100 iter), loss = 1.10096
I0506 05:01:16.027514 12834 solver.cpp:261]     Train net output #0: loss = 1.10096 (* 1 = 1.10096 loss)
I0506 05:01:16.027523 12834 sgd_solver.cpp:106] Iteration 193000, lr = 1.44115e-06
I0506 05:01:16.029337 12834 solver.cpp:362] Iteration 193000, Testing net (#0)
I0506 05:01:16.029350 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:16.158637 12834 solver.cpp:429]     Test net output #0: accuracy = 0.791
I0506 05:01:16.158654 12834 solver.cpp:429]     Test net output #1: loss = 0.486922 (* 1 = 0.486922 loss)
I0506 05:01:16.161211 12834 solver.cpp:242] Iteration 193000 (84.1141 iter/s, 1.18886s/100 iter), loss = 0.39913
I0506 05:01:16.161231 12834 solver.cpp:261]     Train net output #0: loss = 0.39913 (* 1 = 0.39913 loss)
I0506 05:01:16.161239 12834 sgd_solver.cpp:106] Iteration 193000, lr = 1.44115e-06
I0506 05:01:17.094882 12834 solver.cpp:242] Iteration 193100 (93.6909 iter/s, 1.06734s/100 iter), loss = 0.565789
I0506 05:01:17.094925 12834 solver.cpp:261]     Train net output #0: loss = 0.565789 (* 1 = 0.565789 loss)
I0506 05:01:17.094935 12834 sgd_solver.cpp:106] Iteration 193100, lr = 1.44115e-06
I0506 05:01:17.099694 12834 solver.cpp:242] Iteration 193100 (106.559 iter/s, 0.938445s/100 iter), loss = 0.653158
I0506 05:01:17.099721 12834 solver.cpp:261]     Train net output #0: loss = 0.653158 (* 1 = 0.653158 loss)
I0506 05:01:17.099730 12834 sgd_solver.cpp:106] Iteration 193100, lr = 1.44115e-06
I0506 05:01:18.032488 12834 solver.cpp:242] Iteration 193200 (106.663 iter/s, 0.937531s/100 iter), loss = 0.566466
I0506 05:01:18.032532 12834 solver.cpp:261]     Train net output #0: loss = 0.566466 (* 1 = 0.566466 loss)
I0506 05:01:18.032541 12834 sgd_solver.cpp:106] Iteration 193200, lr = 1.44115e-06
I0506 05:01:18.037276 12834 solver.cpp:242] Iteration 193200 (106.663 iter/s, 0.937537s/100 iter), loss = 0.462901
I0506 05:01:18.037302 12834 solver.cpp:261]     Train net output #0: loss = 0.462901 (* 1 = 0.462901 loss)
I0506 05:01:18.037312 12834 sgd_solver.cpp:106] Iteration 193200, lr = 1.44115e-06
I0506 05:01:18.970927 12834 solver.cpp:242] Iteration 193300 (106.568 iter/s, 0.93837s/100 iter), loss = 0.932984
I0506 05:01:18.970983 12834 solver.cpp:261]     Train net output #0: loss = 0.932984 (* 1 = 0.932984 loss)
I0506 05:01:18.970993 12834 sgd_solver.cpp:106] Iteration 193300, lr = 1.44115e-06
I0506 05:01:18.975764 12834 solver.cpp:242] Iteration 193300 (106.559 iter/s, 0.938445s/100 iter), loss = 0.500123
I0506 05:01:18.975790 12834 solver.cpp:261]     Train net output #0: loss = 0.500123 (* 1 = 0.500123 loss)
I0506 05:01:18.975800 12834 sgd_solver.cpp:106] Iteration 193300, lr = 1.44115e-06
I0506 05:01:19.908532 12834 solver.cpp:242] Iteration 193400 (106.664 iter/s, 0.937519s/100 iter), loss = 1.10851
I0506 05:01:19.908576 12834 solver.cpp:261]     Train net output #0: loss = 1.10851 (* 1 = 1.10851 loss)
I0506 05:01:19.908586 12834 sgd_solver.cpp:106] Iteration 193400, lr = 1.44115e-06
I0506 05:01:19.913300 12834 solver.cpp:242] Iteration 193400 (106.668 iter/s, 0.937491s/100 iter), loss = 0.591311
I0506 05:01:19.913324 12834 solver.cpp:261]     Train net output #0: loss = 0.591311 (* 1 = 0.591311 loss)
I0506 05:01:19.913333 12834 sgd_solver.cpp:106] Iteration 193400, lr = 1.44115e-06
I0506 05:01:20.842789 12834 solver.cpp:362] Iteration 193500, Testing net (#0)
I0506 05:01:20.842814 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:20.965382 12834 solver.cpp:429]     Test net output #0: loss = 0.975682 (* 1 = 0.975682 loss)
I0506 05:01:20.967900 12834 solver.cpp:242] Iteration 193500 (94.4015 iter/s, 1.05931s/100 iter), loss = 0.835036
I0506 05:01:20.967929 12834 solver.cpp:261]     Train net output #0: loss = 0.835036 (* 1 = 0.835036 loss)
I0506 05:01:20.967939 12834 sgd_solver.cpp:106] Iteration 193500, lr = 1.44115e-06
I0506 05:01:20.969837 12834 solver.cpp:362] Iteration 193500, Testing net (#0)
I0506 05:01:20.969852 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:21.098392 12834 solver.cpp:429]     Test net output #0: accuracy = 0.796
I0506 05:01:21.098412 12834 solver.cpp:429]     Test net output #1: loss = 0.482451 (* 1 = 0.482451 loss)
I0506 05:01:21.100970 12834 solver.cpp:242] Iteration 193500 (84.2016 iter/s, 1.18763s/100 iter), loss = 0.538363
I0506 05:01:21.100991 12834 solver.cpp:261]     Train net output #0: loss = 0.538363 (* 1 = 0.538363 loss)
I0506 05:01:21.101001 12834 sgd_solver.cpp:106] Iteration 193500, lr = 1.44115e-06
I0506 05:01:22.034108 12834 solver.cpp:242] Iteration 193600 (93.7955 iter/s, 1.06615s/100 iter), loss = 1.01057
I0506 05:01:22.034148 12834 solver.cpp:261]     Train net output #0: loss = 1.01057 (* 1 = 1.01057 loss)
I0506 05:01:22.034157 12834 sgd_solver.cpp:106] Iteration 193600, lr = 1.44115e-06
I0506 05:01:22.038899 12834 solver.cpp:242] Iteration 193600 (106.622 iter/s, 0.93789s/100 iter), loss = 0.772764
I0506 05:01:22.038925 12834 solver.cpp:261]     Train net output #0: loss = 0.772764 (* 1 = 0.772764 loss)
I0506 05:01:22.038934 12834 sgd_solver.cpp:106] Iteration 193600, lr = 1.44115e-06
I0506 05:01:22.971776 12834 solver.cpp:242] Iteration 193700 (106.655 iter/s, 0.937605s/100 iter), loss = 2.88663
I0506 05:01:22.971814 12834 solver.cpp:261]     Train net output #0: loss = 2.88663 (* 1 = 2.88663 loss)
I0506 05:01:22.971824 12834 sgd_solver.cpp:106] Iteration 193700, lr = 1.44115e-06
I0506 05:01:22.976660 12834 solver.cpp:242] Iteration 193700 (106.643 iter/s, 0.937706s/100 iter), loss = 0.631
I0506 05:01:22.976686 12834 solver.cpp:261]     Train net output #0: loss = 0.631 (* 1 = 0.631 loss)
I0506 05:01:22.976694 12834 sgd_solver.cpp:106] Iteration 193700, lr = 1.44115e-06
I0506 05:01:23.909049 12834 solver.cpp:242] Iteration 193800 (106.7 iter/s, 0.93721s/100 iter), loss = 0.466731
I0506 05:01:23.909090 12834 solver.cpp:261]     Train net output #0: loss = 0.466731 (* 1 = 0.466731 loss)
I0506 05:01:23.909099 12834 sgd_solver.cpp:106] Iteration 193800, lr = 1.44115e-06
I0506 05:01:23.913805 12834 solver.cpp:242] Iteration 193800 (106.712 iter/s, 0.9371s/100 iter), loss = 0.457054
I0506 05:01:23.913831 12834 solver.cpp:261]     Train net output #0: loss = 0.457054 (* 1 = 0.457054 loss)
I0506 05:01:23.913841 12834 sgd_solver.cpp:106] Iteration 193800, lr = 1.44115e-06
I0506 05:01:24.847762 12834 solver.cpp:242] Iteration 193900 (106.537 iter/s, 0.938643s/100 iter), loss = 0.970146
I0506 05:01:24.847797 12834 solver.cpp:261]     Train net output #0: loss = 0.970146 (* 1 = 0.970146 loss)
I0506 05:01:24.847806 12834 sgd_solver.cpp:106] Iteration 193900, lr = 1.44115e-06
I0506 05:01:24.852530 12834 solver.cpp:242] Iteration 193900 (106.533 iter/s, 0.93868s/100 iter), loss = 0.770186
I0506 05:01:24.852560 12834 solver.cpp:261]     Train net output #0: loss = 0.770186 (* 1 = 0.770186 loss)
I0506 05:01:24.852571 12834 sgd_solver.cpp:106] Iteration 193900, lr = 1.44115e-06
I0506 05:01:25.783001 12834 solver.cpp:362] Iteration 194000, Testing net (#0)
I0506 05:01:25.783031 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:25.905742 12834 solver.cpp:429]     Test net output #0: loss = 1.14348 (* 1 = 1.14348 loss)
I0506 05:01:25.908263 12834 solver.cpp:242] Iteration 194000 (94.2998 iter/s, 1.06045s/100 iter), loss = 1.43224
I0506 05:01:25.908283 12834 solver.cpp:261]     Train net output #0: loss = 1.43224 (* 1 = 1.43224 loss)
I0506 05:01:25.908293 12834 sgd_solver.cpp:106] Iteration 194000, lr = 1.44115e-06
I0506 05:01:25.910114 12834 solver.cpp:362] Iteration 194000, Testing net (#0)
I0506 05:01:25.910126 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:26.038733 12834 solver.cpp:429]     Test net output #0: accuracy = 0.788
I0506 05:01:26.038761 12834 solver.cpp:429]     Test net output #1: loss = 0.463557 (* 1 = 0.463557 loss)
I0506 05:01:26.041328 12834 solver.cpp:242] Iteration 194000 (84.122 iter/s, 1.18875s/100 iter), loss = 0.608144
I0506 05:01:26.041350 12834 solver.cpp:261]     Train net output #0: loss = 0.608144 (* 1 = 0.608144 loss)
I0506 05:01:26.041358 12834 sgd_solver.cpp:106] Iteration 194000, lr = 1.44115e-06
I0506 05:01:27.036344 12834 solver.cpp:242] Iteration 194100 (88.6507 iter/s, 1.12802s/100 iter), loss = 0.45042
I0506 05:01:27.036382 12834 solver.cpp:261]     Train net output #0: loss = 0.45042 (* 1 = 0.45042 loss)
I0506 05:01:27.036394 12834 sgd_solver.cpp:106] Iteration 194100, lr = 1.44115e-06
I0506 05:01:27.041606 12834 solver.cpp:242] Iteration 194100 (99.9765 iter/s, 1.00024s/100 iter), loss = 0.510417
I0506 05:01:27.041635 12834 solver.cpp:261]     Train net output #0: loss = 0.510417 (* 1 = 0.510417 loss)
I0506 05:01:27.041646 12834 sgd_solver.cpp:106] Iteration 194100, lr = 1.44115e-06
I0506 05:01:28.005717 12834 solver.cpp:242] Iteration 194200 (103.166 iter/s, 0.969311s/100 iter), loss = 0.954981
I0506 05:01:28.005750 12834 solver.cpp:261]     Train net output #0: loss = 0.954981 (* 1 = 0.954981 loss)
I0506 05:01:28.005760 12834 sgd_solver.cpp:106] Iteration 194200, lr = 1.44115e-06
I0506 05:01:28.010479 12834 solver.cpp:242] Iteration 194200 (103.218 iter/s, 0.968826s/100 iter), loss = 0.305569
I0506 05:01:28.010504 12834 solver.cpp:261]     Train net output #0: loss = 0.305569 (* 1 = 0.305569 loss)
I0506 05:01:28.010514 12834 sgd_solver.cpp:106] Iteration 194200, lr = 1.44115e-06
I0506 05:01:28.943039 12834 solver.cpp:242] Iteration 194300 (106.694 iter/s, 0.937261s/100 iter), loss = 0.851439
I0506 05:01:28.943071 12834 solver.cpp:261]     Train net output #0: loss = 0.851439 (* 1 = 0.851439 loss)
I0506 05:01:28.943080 12834 sgd_solver.cpp:106] Iteration 194300, lr = 1.44115e-06
I0506 05:01:28.947811 12834 solver.cpp:242] Iteration 194300 (106.691 iter/s, 0.937289s/100 iter), loss = 0.744105
I0506 05:01:28.947835 12834 solver.cpp:261]     Train net output #0: loss = 0.744105 (* 1 = 0.744105 loss)
I0506 05:01:28.947844 12834 sgd_solver.cpp:106] Iteration 194300, lr = 1.44115e-06
I0506 05:01:29.880439 12834 solver.cpp:242] Iteration 194400 (106.685 iter/s, 0.937343s/100 iter), loss = 1.24018
I0506 05:01:29.880494 12834 solver.cpp:261]     Train net output #0: loss = 1.24018 (* 1 = 1.24018 loss)
I0506 05:01:29.880506 12834 sgd_solver.cpp:106] Iteration 194400, lr = 1.44115e-06
I0506 05:01:29.885349 12834 solver.cpp:242] Iteration 194400 (106.668 iter/s, 0.937484s/100 iter), loss = 0.34347
I0506 05:01:29.885386 12834 solver.cpp:261]     Train net output #0: loss = 0.34347 (* 1 = 0.34347 loss)
I0506 05:01:29.885396 12834 sgd_solver.cpp:106] Iteration 194400, lr = 1.44115e-06
I0506 05:01:30.816118 12834 solver.cpp:362] Iteration 194500, Testing net (#0)
I0506 05:01:30.816148 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:30.938746 12834 solver.cpp:429]     Test net output #0: loss = 1.20078 (* 1 = 1.20078 loss)
I0506 05:01:30.941274 12834 solver.cpp:242] Iteration 194500 (94.272 iter/s, 1.06076s/100 iter), loss = 0.582074
I0506 05:01:30.941299 12834 solver.cpp:261]     Train net output #0: loss = 0.582074 (* 1 = 0.582074 loss)
I0506 05:01:30.941308 12834 sgd_solver.cpp:106] Iteration 194500, lr = 1.44115e-06
I0506 05:01:30.943120 12834 solver.cpp:362] Iteration 194500, Testing net (#0)
I0506 05:01:30.943133 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:31.071871 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7895
I0506 05:01:31.071889 12834 solver.cpp:429]     Test net output #1: loss = 0.480725 (* 1 = 0.480725 loss)
I0506 05:01:31.074451 12834 solver.cpp:242] Iteration 194500 (84.1012 iter/s, 1.18904s/100 iter), loss = 0.268036
I0506 05:01:31.074473 12834 solver.cpp:261]     Train net output #0: loss = 0.268036 (* 1 = 0.268036 loss)
I0506 05:01:31.074482 12834 sgd_solver.cpp:106] Iteration 194500, lr = 1.44115e-06
I0506 05:01:32.006573 12834 solver.cpp:242] Iteration 194600 (93.8749 iter/s, 1.06525s/100 iter), loss = 1.79002
I0506 05:01:32.006614 12834 solver.cpp:261]     Train net output #0: loss = 1.79002 (* 1 = 1.79002 loss)
I0506 05:01:32.006623 12834 sgd_solver.cpp:106] Iteration 194600, lr = 1.44115e-06
I0506 05:01:32.011430 12834 solver.cpp:242] Iteration 194600 (106.732 iter/s, 0.936929s/100 iter), loss = 0.418809
I0506 05:01:32.011456 12834 solver.cpp:261]     Train net output #0: loss = 0.418809 (* 1 = 0.418809 loss)
I0506 05:01:32.011464 12834 sgd_solver.cpp:106] Iteration 194600, lr = 1.44115e-06
I0506 05:01:32.944543 12834 solver.cpp:242] Iteration 194700 (106.621 iter/s, 0.937902s/100 iter), loss = 0.233778
I0506 05:01:32.944587 12834 solver.cpp:261]     Train net output #0: loss = 0.233778 (* 1 = 0.233778 loss)
I0506 05:01:32.944597 12834 sgd_solver.cpp:106] Iteration 194700, lr = 1.44115e-06
I0506 05:01:32.949314 12834 solver.cpp:242] Iteration 194700 (106.628 iter/s, 0.937841s/100 iter), loss = 0.450787
I0506 05:01:32.949339 12834 solver.cpp:261]     Train net output #0: loss = 0.450787 (* 1 = 0.450787 loss)
I0506 05:01:32.949348 12834 sgd_solver.cpp:106] Iteration 194700, lr = 1.44115e-06
I0506 05:01:33.882510 12834 solver.cpp:242] Iteration 194800 (106.622 iter/s, 0.937891s/100 iter), loss = 0.217001
I0506 05:01:33.882552 12834 solver.cpp:261]     Train net output #0: loss = 0.217001 (* 1 = 0.217001 loss)
I0506 05:01:33.882561 12834 sgd_solver.cpp:106] Iteration 194800, lr = 1.44115e-06
I0506 05:01:33.887296 12834 solver.cpp:242] Iteration 194800 (106.617 iter/s, 0.937938s/100 iter), loss = 0.323243
I0506 05:01:33.887322 12834 solver.cpp:261]     Train net output #0: loss = 0.323243 (* 1 = 0.323243 loss)
I0506 05:01:33.887332 12834 sgd_solver.cpp:106] Iteration 194800, lr = 1.44115e-06
I0506 05:01:34.820482 12834 solver.cpp:242] Iteration 194900 (106.62 iter/s, 0.937906s/100 iter), loss = 0.169464
I0506 05:01:34.820521 12834 solver.cpp:261]     Train net output #0: loss = 0.169464 (* 1 = 0.169464 loss)
I0506 05:01:34.820530 12834 sgd_solver.cpp:106] Iteration 194900, lr = 1.44115e-06
I0506 05:01:34.825270 12834 solver.cpp:242] Iteration 194900 (106.618 iter/s, 0.93793s/100 iter), loss = 0.152337
I0506 05:01:34.825295 12834 solver.cpp:261]     Train net output #0: loss = 0.152337 (* 1 = 0.152337 loss)
I0506 05:01:34.825305 12834 sgd_solver.cpp:106] Iteration 194900, lr = 1.44115e-06
I0506 05:01:35.756163 12834 solver.cpp:362] Iteration 195000, Testing net (#0)
I0506 05:01:35.756191 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:35.878813 12834 solver.cpp:429]     Test net output #0: loss = 1.10452 (* 1 = 1.10452 loss)
I0506 05:01:35.881328 12834 solver.cpp:242] Iteration 195000 (94.2695 iter/s, 1.06079s/100 iter), loss = 0.579183
I0506 05:01:35.881351 12834 solver.cpp:261]     Train net output #0: loss = 0.579183 (* 1 = 0.579183 loss)
I0506 05:01:35.881361 12834 sgd_solver.cpp:106] Iteration 195000, lr = 1.44115e-06
I0506 05:01:35.883184 12834 solver.cpp:362] Iteration 195000, Testing net (#0)
I0506 05:01:35.883196 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:36.012037 12834 solver.cpp:429]     Test net output #0: accuracy = 0.782
I0506 05:01:36.012056 12834 solver.cpp:429]     Test net output #1: loss = 0.497432 (* 1 = 0.497432 loss)
I0506 05:01:36.014607 12834 solver.cpp:242] Iteration 195000 (84.0837 iter/s, 1.18929s/100 iter), loss = 0.481721
I0506 05:01:36.014629 12834 solver.cpp:261]     Train net output #0: loss = 0.481721 (* 1 = 0.481721 loss)
I0506 05:01:36.014638 12834 sgd_solver.cpp:106] Iteration 195000, lr = 1.44115e-06
I0506 05:01:36.947842 12834 solver.cpp:242] Iteration 195100 (93.7679 iter/s, 1.06646s/100 iter), loss = 2.07043
I0506 05:01:36.947881 12834 solver.cpp:261]     Train net output #0: loss = 2.07043 (* 1 = 2.07043 loss)
I0506 05:01:36.947891 12834 sgd_solver.cpp:106] Iteration 195100, lr = 1.44115e-06
I0506 05:01:36.952628 12834 solver.cpp:242] Iteration 195100 (106.612 iter/s, 0.93798s/100 iter), loss = 0.480475
I0506 05:01:36.952652 12834 solver.cpp:261]     Train net output #0: loss = 0.480475 (* 1 = 0.480475 loss)
I0506 05:01:36.952672 12834 sgd_solver.cpp:106] Iteration 195100, lr = 1.44115e-06
I0506 05:01:37.885551 12834 solver.cpp:242] Iteration 195200 (106.651 iter/s, 0.937639s/100 iter), loss = 1.16638
I0506 05:01:37.885588 12834 solver.cpp:261]     Train net output #0: loss = 1.16638 (* 1 = 1.16638 loss)
I0506 05:01:37.885597 12834 sgd_solver.cpp:106] Iteration 195200, lr = 1.44115e-06
I0506 05:01:37.890316 12834 solver.cpp:242] Iteration 195200 (106.65 iter/s, 0.937646s/100 iter), loss = 0.529255
I0506 05:01:37.890341 12834 solver.cpp:261]     Train net output #0: loss = 0.529255 (* 1 = 0.529255 loss)
I0506 05:01:37.890350 12834 sgd_solver.cpp:106] Iteration 195200, lr = 1.44115e-06
I0506 05:01:38.823074 12834 solver.cpp:242] Iteration 195300 (106.671 iter/s, 0.937464s/100 iter), loss = 0.841325
I0506 05:01:38.823108 12834 solver.cpp:261]     Train net output #0: loss = 0.841325 (* 1 = 0.841325 loss)
I0506 05:01:38.823118 12834 sgd_solver.cpp:106] Iteration 195300, lr = 1.44115e-06
I0506 05:01:38.827937 12834 solver.cpp:242] Iteration 195300 (106.659 iter/s, 0.937568s/100 iter), loss = 0.521508
I0506 05:01:38.827965 12834 solver.cpp:261]     Train net output #0: loss = 0.521508 (* 1 = 0.521508 loss)
I0506 05:01:38.827975 12834 sgd_solver.cpp:106] Iteration 195300, lr = 1.44115e-06
I0506 05:01:39.760466 12834 solver.cpp:242] Iteration 195400 (106.686 iter/s, 0.93733s/100 iter), loss = 0.473578
I0506 05:01:39.760499 12834 solver.cpp:261]     Train net output #0: loss = 0.473578 (* 1 = 0.473578 loss)
I0506 05:01:39.760509 12834 sgd_solver.cpp:106] Iteration 195400, lr = 1.44115e-06
I0506 05:01:39.765234 12834 solver.cpp:242] Iteration 195400 (106.695 iter/s, 0.937251s/100 iter), loss = 0.490915
I0506 05:01:39.765259 12834 solver.cpp:261]     Train net output #0: loss = 0.490915 (* 1 = 0.490915 loss)
I0506 05:01:39.765267 12834 sgd_solver.cpp:106] Iteration 195400, lr = 1.44115e-06
I0506 05:01:40.695545 12834 solver.cpp:362] Iteration 195500, Testing net (#0)
I0506 05:01:40.695587 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:40.818279 12834 solver.cpp:429]     Test net output #0: loss = 1.15147 (* 1 = 1.15147 loss)
I0506 05:01:40.820801 12834 solver.cpp:242] Iteration 195500 (94.3143 iter/s, 1.06028s/100 iter), loss = 0.410173
I0506 05:01:40.820823 12834 solver.cpp:261]     Train net output #0: loss = 0.410173 (* 1 = 0.410173 loss)
I0506 05:01:40.820832 12834 sgd_solver.cpp:106] Iteration 195500, lr = 1.44115e-06
I0506 05:01:40.822737 12834 solver.cpp:362] Iteration 195500, Testing net (#0)
I0506 05:01:40.822751 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:40.951704 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7855
I0506 05:01:40.951722 12834 solver.cpp:429]     Test net output #1: loss = 0.525059 (* 1 = 0.525059 loss)
I0506 05:01:40.954272 12834 solver.cpp:242] Iteration 195500 (84.1048 iter/s, 1.18899s/100 iter), loss = 0.443714
I0506 05:01:40.954293 12834 solver.cpp:261]     Train net output #0: loss = 0.443714 (* 1 = 0.443714 loss)
I0506 05:01:40.954300 12834 sgd_solver.cpp:106] Iteration 195500, lr = 1.44115e-06
I0506 05:01:41.886947 12834 solver.cpp:242] Iteration 195600 (93.8004 iter/s, 1.06609s/100 iter), loss = 0.708226
I0506 05:01:41.886988 12834 solver.cpp:261]     Train net output #0: loss = 0.708226 (* 1 = 0.708226 loss)
I0506 05:01:41.886998 12834 sgd_solver.cpp:106] Iteration 195600, lr = 1.44115e-06
I0506 05:01:41.891749 12834 solver.cpp:242] Iteration 195600 (106.674 iter/s, 0.937439s/100 iter), loss = 0.362906
I0506 05:01:41.891777 12834 solver.cpp:261]     Train net output #0: loss = 0.362906 (* 1 = 0.362906 loss)
I0506 05:01:41.891788 12834 sgd_solver.cpp:106] Iteration 195600, lr = 1.44115e-06
I0506 05:01:42.825628 12834 solver.cpp:242] Iteration 195700 (106.541 iter/s, 0.938608s/100 iter), loss = 1.31
I0506 05:01:42.825670 12834 solver.cpp:261]     Train net output #0: loss = 1.31 (* 1 = 1.31 loss)
I0506 05:01:42.825680 12834 sgd_solver.cpp:106] Iteration 195700, lr = 1.44115e-06
I0506 05:01:42.830430 12834 solver.cpp:242] Iteration 195700 (106.538 iter/s, 0.938636s/100 iter), loss = 0.540056
I0506 05:01:42.830456 12834 solver.cpp:261]     Train net output #0: loss = 0.540056 (* 1 = 0.540056 loss)
I0506 05:01:42.830466 12834 sgd_solver.cpp:106] Iteration 195700, lr = 1.44115e-06
I0506 05:01:43.763418 12834 solver.cpp:242] Iteration 195800 (106.641 iter/s, 0.937723s/100 iter), loss = 0.78457
I0506 05:01:43.763458 12834 solver.cpp:261]     Train net output #0: loss = 0.78457 (* 1 = 0.78457 loss)
I0506 05:01:43.763468 12834 sgd_solver.cpp:106] Iteration 195800, lr = 1.44115e-06
I0506 05:01:43.768187 12834 solver.cpp:242] Iteration 195800 (106.643 iter/s, 0.937712s/100 iter), loss = 0.377274
I0506 05:01:43.768213 12834 solver.cpp:261]     Train net output #0: loss = 0.377274 (* 1 = 0.377274 loss)
I0506 05:01:43.768221 12834 sgd_solver.cpp:106] Iteration 195800, lr = 1.44115e-06
I0506 05:01:44.700987 12834 solver.cpp:242] Iteration 195900 (106.667 iter/s, 0.937498s/100 iter), loss = 1.33859
I0506 05:01:44.701028 12834 solver.cpp:261]     Train net output #0: loss = 1.33859 (* 1 = 1.33859 loss)
I0506 05:01:44.701037 12834 sgd_solver.cpp:106] Iteration 195900, lr = 1.44115e-06
I0506 05:01:44.705765 12834 solver.cpp:242] Iteration 195900 (106.663 iter/s, 0.937534s/100 iter), loss = 0.592348
I0506 05:01:44.705790 12834 solver.cpp:261]     Train net output #0: loss = 0.592348 (* 1 = 0.592348 loss)
I0506 05:01:44.705799 12834 sgd_solver.cpp:106] Iteration 195900, lr = 1.44115e-06
I0506 05:01:45.635278 12834 solver.cpp:362] Iteration 196000, Testing net (#0)
I0506 05:01:45.635305 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:45.757983 12834 solver.cpp:429]     Test net output #0: loss = 1.20917 (* 1 = 1.20917 loss)
I0506 05:01:45.760531 12834 solver.cpp:242] Iteration 196000 (94.3855 iter/s, 1.05948s/100 iter), loss = 1.03955
I0506 05:01:45.760557 12834 solver.cpp:261]     Train net output #0: loss = 1.03955 (* 1 = 1.03955 loss)
I0506 05:01:45.760568 12834 sgd_solver.cpp:106] Iteration 196000, lr = 1.44115e-06
I0506 05:01:45.762437 12834 solver.cpp:362] Iteration 196000, Testing net (#0)
I0506 05:01:45.762454 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:45.891060 12834 solver.cpp:429]     Test net output #0: accuracy = 0.796
I0506 05:01:45.891082 12834 solver.cpp:429]     Test net output #1: loss = 0.50147 (* 1 = 0.50147 loss)
I0506 05:01:45.893648 12834 solver.cpp:242] Iteration 196000 (84.1866 iter/s, 1.18784s/100 iter), loss = 0.416845
I0506 05:01:45.893668 12834 solver.cpp:261]     Train net output #0: loss = 0.416845 (* 1 = 0.416845 loss)
I0506 05:01:45.893677 12834 sgd_solver.cpp:106] Iteration 196000, lr = 1.44115e-06
I0506 05:01:46.873777 12834 solver.cpp:242] Iteration 196100 (89.8325 iter/s, 1.11318s/100 iter), loss = 1.46756
I0506 05:01:46.873822 12834 solver.cpp:261]     Train net output #0: loss = 1.46756 (* 1 = 1.46756 loss)
I0506 05:01:46.873834 12834 sgd_solver.cpp:106] Iteration 196100, lr = 1.44115e-06
I0506 05:01:46.879045 12834 solver.cpp:242] Iteration 196100 (101.486 iter/s, 0.985357s/100 iter), loss = 0.635845
I0506 05:01:46.879076 12834 solver.cpp:261]     Train net output #0: loss = 0.635845 (* 1 = 0.635845 loss)
I0506 05:01:46.879086 12834 sgd_solver.cpp:106] Iteration 196100, lr = 1.44115e-06
I0506 05:01:47.858098 12834 solver.cpp:242] Iteration 196200 (101.6 iter/s, 0.984251s/100 iter), loss = 0.619054
I0506 05:01:47.858136 12834 solver.cpp:261]     Train net output #0: loss = 0.619054 (* 1 = 0.619054 loss)
I0506 05:01:47.858146 12834 sgd_solver.cpp:106] Iteration 196200, lr = 1.44115e-06
I0506 05:01:47.862941 12834 solver.cpp:242] Iteration 196200 (101.643 iter/s, 0.983836s/100 iter), loss = 0.501505
I0506 05:01:47.862965 12834 solver.cpp:261]     Train net output #0: loss = 0.501505 (* 1 = 0.501505 loss)
I0506 05:01:47.862975 12834 sgd_solver.cpp:106] Iteration 196200, lr = 1.44115e-06
I0506 05:01:48.795888 12834 solver.cpp:242] Iteration 196300 (106.641 iter/s, 0.937724s/100 iter), loss = 1.36766
I0506 05:01:48.795928 12834 solver.cpp:261]     Train net output #0: loss = 1.36766 (* 1 = 1.36766 loss)
I0506 05:01:48.795948 12834 sgd_solver.cpp:106] Iteration 196300, lr = 1.44115e-06
I0506 05:01:48.800673 12834 solver.cpp:242] Iteration 196300 (106.645 iter/s, 0.93769s/100 iter), loss = 0.574839
I0506 05:01:48.800698 12834 solver.cpp:261]     Train net output #0: loss = 0.574839 (* 1 = 0.574839 loss)
I0506 05:01:48.800707 12834 sgd_solver.cpp:106] Iteration 196300, lr = 1.44115e-06
I0506 05:01:49.733625 12834 solver.cpp:242] Iteration 196400 (106.647 iter/s, 0.937674s/100 iter), loss = 1.70022
I0506 05:01:49.733664 12834 solver.cpp:261]     Train net output #0: loss = 1.70022 (* 1 = 1.70022 loss)
I0506 05:01:49.733675 12834 sgd_solver.cpp:106] Iteration 196400, lr = 1.44115e-06
I0506 05:01:49.738521 12834 solver.cpp:242] Iteration 196400 (106.633 iter/s, 0.937797s/100 iter), loss = 0.724637
I0506 05:01:49.738548 12834 solver.cpp:261]     Train net output #0: loss = 0.724637 (* 1 = 0.724637 loss)
I0506 05:01:49.738557 12834 sgd_solver.cpp:106] Iteration 196400, lr = 1.44115e-06
I0506 05:01:50.668365 12834 solver.cpp:362] Iteration 196500, Testing net (#0)
I0506 05:01:50.668390 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:50.791092 12834 solver.cpp:429]     Test net output #0: loss = 1.19954 (* 1 = 1.19954 loss)
I0506 05:01:50.793642 12834 solver.cpp:242] Iteration 196500 (94.3433 iter/s, 1.05996s/100 iter), loss = 3.02914
I0506 05:01:50.793668 12834 solver.cpp:261]     Train net output #0: loss = 3.02914 (* 1 = 3.02914 loss)
I0506 05:01:50.793676 12834 sgd_solver.cpp:106] Iteration 196500, lr = 1.44115e-06
I0506 05:01:50.795497 12834 solver.cpp:362] Iteration 196500, Testing net (#0)
I0506 05:01:50.795511 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:50.924044 12834 solver.cpp:429]     Test net output #0: accuracy = 0.786
I0506 05:01:50.924063 12834 solver.cpp:429]     Test net output #1: loss = 0.496347 (* 1 = 0.496347 loss)
I0506 05:01:50.926626 12834 solver.cpp:242] Iteration 196500 (84.1711 iter/s, 1.18806s/100 iter), loss = 0.736757
I0506 05:01:50.926647 12834 solver.cpp:261]     Train net output #0: loss = 0.736757 (* 1 = 0.736757 loss)
I0506 05:01:50.926656 12834 sgd_solver.cpp:106] Iteration 196500, lr = 1.44115e-06
I0506 05:01:51.859287 12834 solver.cpp:242] Iteration 196600 (93.8452 iter/s, 1.06558s/100 iter), loss = 0.622892
I0506 05:01:51.859323 12834 solver.cpp:261]     Train net output #0: loss = 0.622892 (* 1 = 0.622892 loss)
I0506 05:01:51.859333 12834 sgd_solver.cpp:106] Iteration 196600, lr = 1.44115e-06
I0506 05:01:51.864087 12834 solver.cpp:242] Iteration 196600 (106.676 iter/s, 0.937422s/100 iter), loss = 0.571517
I0506 05:01:51.864114 12834 solver.cpp:261]     Train net output #0: loss = 0.571517 (* 1 = 0.571517 loss)
I0506 05:01:51.864122 12834 sgd_solver.cpp:106] Iteration 196600, lr = 1.44115e-06
I0506 05:01:52.796305 12834 solver.cpp:242] Iteration 196700 (106.729 iter/s, 0.936957s/100 iter), loss = 1.38558
I0506 05:01:52.796336 12834 solver.cpp:261]     Train net output #0: loss = 1.38558 (* 1 = 1.38558 loss)
I0506 05:01:52.796345 12834 sgd_solver.cpp:106] Iteration 196700, lr = 1.44115e-06
I0506 05:01:52.801066 12834 solver.cpp:242] Iteration 196700 (106.731 iter/s, 0.936934s/100 iter), loss = 0.525515
I0506 05:01:52.801090 12834 solver.cpp:261]     Train net output #0: loss = 0.525515 (* 1 = 0.525515 loss)
I0506 05:01:52.801100 12834 sgd_solver.cpp:106] Iteration 196700, lr = 1.44115e-06
I0506 05:01:53.734100 12834 solver.cpp:242] Iteration 196800 (106.64 iter/s, 0.937732s/100 iter), loss = 3.87402
I0506 05:01:53.734140 12834 solver.cpp:261]     Train net output #0: loss = 3.87402 (* 1 = 3.87402 loss)
I0506 05:01:53.734150 12834 sgd_solver.cpp:106] Iteration 196800, lr = 1.44115e-06
I0506 05:01:53.738876 12834 solver.cpp:242] Iteration 196800 (106.636 iter/s, 0.937768s/100 iter), loss = 0.773532
I0506 05:01:53.738903 12834 solver.cpp:261]     Train net output #0: loss = 0.773532 (* 1 = 0.773532 loss)
I0506 05:01:53.738911 12834 sgd_solver.cpp:106] Iteration 196800, lr = 1.44115e-06
I0506 05:01:54.671362 12834 solver.cpp:242] Iteration 196900 (106.701 iter/s, 0.937197s/100 iter), loss = 2.09454
I0506 05:01:54.671411 12834 solver.cpp:261]     Train net output #0: loss = 2.09454 (* 1 = 2.09454 loss)
I0506 05:01:54.671422 12834 sgd_solver.cpp:106] Iteration 196900, lr = 1.44115e-06
I0506 05:01:54.676163 12834 solver.cpp:242] Iteration 196900 (106.696 iter/s, 0.937244s/100 iter), loss = 0.637446
I0506 05:01:54.676190 12834 solver.cpp:261]     Train net output #0: loss = 0.637446 (* 1 = 0.637446 loss)
I0506 05:01:54.676199 12834 sgd_solver.cpp:106] Iteration 196900, lr = 1.44115e-06
I0506 05:01:55.605852 12834 solver.cpp:362] Iteration 197000, Testing net (#0)
I0506 05:01:55.605880 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:55.728556 12834 solver.cpp:429]     Test net output #0: loss = 1.22704 (* 1 = 1.22704 loss)
I0506 05:01:55.731081 12834 solver.cpp:242] Iteration 197000 (94.3707 iter/s, 1.05965s/100 iter), loss = 0.90181
I0506 05:01:55.731101 12834 solver.cpp:261]     Train net output #0: loss = 0.90181 (* 1 = 0.90181 loss)
I0506 05:01:55.731111 12834 sgd_solver.cpp:106] Iteration 197000, lr = 1.44115e-06
I0506 05:01:55.732924 12834 solver.cpp:362] Iteration 197000, Testing net (#0)
I0506 05:01:55.732939 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:01:55.861771 12834 solver.cpp:429]     Test net output #0: accuracy = 0.79
I0506 05:01:55.861791 12834 solver.cpp:429]     Test net output #1: loss = 0.497909 (* 1 = 0.497909 loss)
I0506 05:01:55.864354 12834 solver.cpp:242] Iteration 197000 (84.1649 iter/s, 1.18814s/100 iter), loss = 0.372404
I0506 05:01:55.864374 12834 solver.cpp:261]     Train net output #0: loss = 0.372404 (* 1 = 0.372404 loss)
I0506 05:01:55.864383 12834 sgd_solver.cpp:106] Iteration 197000, lr = 1.44115e-06
I0506 05:01:56.797089 12834 solver.cpp:242] Iteration 197100 (93.8122 iter/s, 1.06596s/100 iter), loss = 0.534618
I0506 05:01:56.797130 12834 solver.cpp:261]     Train net output #0: loss = 0.534618 (* 1 = 0.534618 loss)
I0506 05:01:56.797140 12834 sgd_solver.cpp:106] Iteration 197100, lr = 1.44115e-06
I0506 05:01:56.801931 12834 solver.cpp:242] Iteration 197100 (106.664 iter/s, 0.937527s/100 iter), loss = 0.731038
I0506 05:01:56.801959 12834 solver.cpp:261]     Train net output #0: loss = 0.731038 (* 1 = 0.731038 loss)
I0506 05:01:56.801967 12834 sgd_solver.cpp:106] Iteration 197100, lr = 1.44115e-06
I0506 05:01:57.734791 12834 solver.cpp:242] Iteration 197200 (106.652 iter/s, 0.937633s/100 iter), loss = 0.793213
I0506 05:01:57.734832 12834 solver.cpp:261]     Train net output #0: loss = 0.793213 (* 1 = 0.793213 loss)
I0506 05:01:57.734840 12834 sgd_solver.cpp:106] Iteration 197200, lr = 1.44115e-06
I0506 05:01:57.739583 12834 solver.cpp:242] Iteration 197200 (106.655 iter/s, 0.937606s/100 iter), loss = 0.507658
I0506 05:01:57.739610 12834 solver.cpp:261]     Train net output #0: loss = 0.507658 (* 1 = 0.507658 loss)
I0506 05:01:57.739619 12834 sgd_solver.cpp:106] Iteration 197200, lr = 1.44115e-06
I0506 05:01:58.672025 12834 solver.cpp:242] Iteration 197300 (106.704 iter/s, 0.937171s/100 iter), loss = 3.85384
I0506 05:01:58.672063 12834 solver.cpp:261]     Train net output #0: loss = 3.85384 (* 1 = 3.85384 loss)
I0506 05:01:58.672073 12834 sgd_solver.cpp:106] Iteration 197300, lr = 1.44115e-06
I0506 05:01:58.676869 12834 solver.cpp:242] Iteration 197300 (106.697 iter/s, 0.93723s/100 iter), loss = 0.312749
I0506 05:01:58.676898 12834 solver.cpp:261]     Train net output #0: loss = 0.312749 (* 1 = 0.312749 loss)
I0506 05:01:58.676908 12834 sgd_solver.cpp:106] Iteration 197300, lr = 1.44115e-06
I0506 05:01:59.610821 12834 solver.cpp:242] Iteration 197400 (106.527 iter/s, 0.93873s/100 iter), loss = 0.819091
I0506 05:01:59.610859 12834 solver.cpp:261]     Train net output #0: loss = 0.819091 (* 1 = 0.819091 loss)
I0506 05:01:59.610868 12834 sgd_solver.cpp:106] Iteration 197400, lr = 1.44115e-06
I0506 05:01:59.615602 12834 solver.cpp:242] Iteration 197400 (106.532 iter/s, 0.938685s/100 iter), loss = 0.339313
I0506 05:01:59.615628 12834 solver.cpp:261]     Train net output #0: loss = 0.339313 (* 1 = 0.339313 loss)
I0506 05:01:59.615645 12834 sgd_solver.cpp:106] Iteration 197400, lr = 1.44115e-06
I0506 05:02:00.557116 12834 solver.cpp:362] Iteration 197500, Testing net (#0)
I0506 05:02:00.557147 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:00.679994 12834 solver.cpp:429]     Test net output #0: loss = 1.12838 (* 1 = 1.12838 loss)
I0506 05:02:00.682515 12834 solver.cpp:242] Iteration 197500 (93.3151 iter/s, 1.07164s/100 iter), loss = 1.18895
I0506 05:02:00.682541 12834 solver.cpp:261]     Train net output #0: loss = 1.18895 (* 1 = 1.18895 loss)
I0506 05:02:00.682549 12834 sgd_solver.cpp:106] Iteration 197500, lr = 1.44115e-06
I0506 05:02:00.684389 12834 solver.cpp:362] Iteration 197500, Testing net (#0)
I0506 05:02:00.684402 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:00.813771 12834 solver.cpp:429]     Test net output #0: accuracy = 0.788
I0506 05:02:00.813791 12834 solver.cpp:429]     Test net output #1: loss = 0.476736 (* 1 = 0.476736 loss)
I0506 05:02:00.816367 12834 solver.cpp:242] Iteration 197500 (83.2835 iter/s, 1.20072s/100 iter), loss = 0.502695
I0506 05:02:00.816388 12834 solver.cpp:261]     Train net output #0: loss = 0.502695 (* 1 = 0.502695 loss)
I0506 05:02:00.816397 12834 sgd_solver.cpp:106] Iteration 197500, lr = 1.44115e-06
I0506 05:02:01.752104 12834 solver.cpp:242] Iteration 197600 (93.4987 iter/s, 1.06953s/100 iter), loss = 2.24101
I0506 05:02:01.752142 12834 solver.cpp:261]     Train net output #0: loss = 2.24101 (* 1 = 2.24101 loss)
I0506 05:02:01.752152 12834 sgd_solver.cpp:106] Iteration 197600, lr = 1.44115e-06
I0506 05:02:01.756886 12834 solver.cpp:242] Iteration 197600 (106.329 iter/s, 0.94048s/100 iter), loss = 0.606546
I0506 05:02:01.756911 12834 solver.cpp:261]     Train net output #0: loss = 0.606546 (* 1 = 0.606546 loss)
I0506 05:02:01.756920 12834 sgd_solver.cpp:106] Iteration 197600, lr = 1.44115e-06
I0506 05:02:02.689687 12834 solver.cpp:242] Iteration 197700 (106.665 iter/s, 0.937513s/100 iter), loss = 0.365437
I0506 05:02:02.689723 12834 solver.cpp:261]     Train net output #0: loss = 0.365437 (* 1 = 0.365437 loss)
I0506 05:02:02.689733 12834 sgd_solver.cpp:106] Iteration 197700, lr = 1.44115e-06
I0506 05:02:02.694473 12834 solver.cpp:242] Iteration 197700 (106.662 iter/s, 0.937544s/100 iter), loss = 0.315607
I0506 05:02:02.694499 12834 solver.cpp:261]     Train net output #0: loss = 0.315607 (* 1 = 0.315607 loss)
I0506 05:02:02.694507 12834 sgd_solver.cpp:106] Iteration 197700, lr = 1.44115e-06
I0506 05:02:03.627645 12834 solver.cpp:242] Iteration 197800 (106.621 iter/s, 0.937898s/100 iter), loss = 0.647125
I0506 05:02:03.627679 12834 solver.cpp:261]     Train net output #0: loss = 0.647125 (* 1 = 0.647125 loss)
I0506 05:02:03.627689 12834 sgd_solver.cpp:106] Iteration 197800, lr = 1.44115e-06
I0506 05:02:03.632428 12834 solver.cpp:242] Iteration 197800 (106.62 iter/s, 0.937911s/100 iter), loss = 0.636564
I0506 05:02:03.632452 12834 solver.cpp:261]     Train net output #0: loss = 0.636564 (* 1 = 0.636564 loss)
I0506 05:02:03.632460 12834 sgd_solver.cpp:106] Iteration 197800, lr = 1.44115e-06
I0506 05:02:04.586098 12834 solver.cpp:242] Iteration 197900 (104.342 iter/s, 0.958385s/100 iter), loss = 0.728967
I0506 05:02:04.586144 12834 solver.cpp:261]     Train net output #0: loss = 0.728967 (* 1 = 0.728967 loss)
I0506 05:02:04.586154 12834 sgd_solver.cpp:106] Iteration 197900, lr = 1.44115e-06
I0506 05:02:04.590862 12834 solver.cpp:242] Iteration 197900 (104.342 iter/s, 0.958391s/100 iter), loss = 0.464873
I0506 05:02:04.590888 12834 solver.cpp:261]     Train net output #0: loss = 0.464873 (* 1 = 0.464873 loss)
I0506 05:02:04.590896 12834 sgd_solver.cpp:106] Iteration 197900, lr = 1.44115e-06
I0506 05:02:05.522241 12834 solver.cpp:362] Iteration 198000, Testing net (#0)
I0506 05:02:05.522269 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:05.645031 12834 solver.cpp:429]     Test net output #0: loss = 1.19252 (* 1 = 1.19252 loss)
I0506 05:02:05.647552 12834 solver.cpp:242] Iteration 198000 (94.2161 iter/s, 1.06139s/100 iter), loss = 1.32722
I0506 05:02:05.647585 12834 solver.cpp:261]     Train net output #0: loss = 1.32722 (* 1 = 1.32722 loss)
I0506 05:02:05.647595 12834 sgd_solver.cpp:106] Iteration 198000, lr = 1.44115e-06
I0506 05:02:05.649420 12834 solver.cpp:362] Iteration 198000, Testing net (#0)
I0506 05:02:05.649433 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:05.778179 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7865
I0506 05:02:05.778199 12834 solver.cpp:429]     Test net output #1: loss = 0.491008 (* 1 = 0.491008 loss)
I0506 05:02:05.780761 12834 solver.cpp:242] Iteration 198000 (84.044 iter/s, 1.18985s/100 iter), loss = 0.403572
I0506 05:02:05.780783 12834 solver.cpp:261]     Train net output #0: loss = 0.403572 (* 1 = 0.403572 loss)
I0506 05:02:05.780791 12834 sgd_solver.cpp:106] Iteration 198000, lr = 1.44115e-06
I0506 05:02:06.714206 12834 solver.cpp:242] Iteration 198100 (93.7566 iter/s, 1.06659s/100 iter), loss = 1.05929
I0506 05:02:06.714241 12834 solver.cpp:261]     Train net output #0: loss = 1.05929 (* 1 = 1.05929 loss)
I0506 05:02:06.714251 12834 sgd_solver.cpp:106] Iteration 198100, lr = 1.44115e-06
I0506 05:02:06.718999 12834 solver.cpp:242] Iteration 198100 (106.587 iter/s, 0.938199s/100 iter), loss = 0.420909
I0506 05:02:06.719023 12834 solver.cpp:261]     Train net output #0: loss = 0.420909 (* 1 = 0.420909 loss)
I0506 05:02:06.719033 12834 sgd_solver.cpp:106] Iteration 198100, lr = 1.44115e-06
I0506 05:02:07.651551 12834 solver.cpp:242] Iteration 198200 (106.691 iter/s, 0.937286s/100 iter), loss = 0.622749
I0506 05:02:07.651592 12834 solver.cpp:261]     Train net output #0: loss = 0.622749 (* 1 = 0.622749 loss)
I0506 05:02:07.651600 12834 sgd_solver.cpp:106] Iteration 198200, lr = 1.44115e-06
I0506 05:02:07.656446 12834 solver.cpp:242] Iteration 198200 (106.679 iter/s, 0.937394s/100 iter), loss = 0.601609
I0506 05:02:07.656474 12834 solver.cpp:261]     Train net output #0: loss = 0.601609 (* 1 = 0.601609 loss)
I0506 05:02:07.656483 12834 sgd_solver.cpp:106] Iteration 198200, lr = 1.44115e-06
I0506 05:02:08.589558 12834 solver.cpp:242] Iteration 198300 (106.617 iter/s, 0.937939s/100 iter), loss = 0.86501
I0506 05:02:08.589598 12834 solver.cpp:261]     Train net output #0: loss = 0.86501 (* 1 = 0.86501 loss)
I0506 05:02:08.589607 12834 sgd_solver.cpp:106] Iteration 198300, lr = 1.44115e-06
I0506 05:02:08.594338 12834 solver.cpp:242] Iteration 198300 (106.627 iter/s, 0.937847s/100 iter), loss = 0.402954
I0506 05:02:08.594364 12834 solver.cpp:261]     Train net output #0: loss = 0.402954 (* 1 = 0.402954 loss)
I0506 05:02:08.594373 12834 sgd_solver.cpp:106] Iteration 198300, lr = 1.44115e-06
I0506 05:02:09.527511 12834 solver.cpp:242] Iteration 198400 (106.623 iter/s, 0.937882s/100 iter), loss = 0.418348
I0506 05:02:09.527561 12834 solver.cpp:261]     Train net output #0: loss = 0.418348 (* 1 = 0.418348 loss)
I0506 05:02:09.527571 12834 sgd_solver.cpp:106] Iteration 198400, lr = 1.44115e-06
I0506 05:02:09.532284 12834 solver.cpp:242] Iteration 198400 (106.621 iter/s, 0.937902s/100 iter), loss = 0.388583
I0506 05:02:09.532310 12834 solver.cpp:261]     Train net output #0: loss = 0.388583 (* 1 = 0.388583 loss)
I0506 05:02:09.532318 12834 sgd_solver.cpp:106] Iteration 198400, lr = 1.44115e-06
I0506 05:02:10.462402 12834 solver.cpp:362] Iteration 198500, Testing net (#0)
I0506 05:02:10.462429 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:10.585207 12834 solver.cpp:429]     Test net output #0: loss = 1.20512 (* 1 = 1.20512 loss)
I0506 05:02:10.587733 12834 solver.cpp:242] Iteration 198500 (94.3262 iter/s, 1.06015s/100 iter), loss = 0.666973
I0506 05:02:10.587756 12834 solver.cpp:261]     Train net output #0: loss = 0.666973 (* 1 = 0.666973 loss)
I0506 05:02:10.587765 12834 sgd_solver.cpp:106] Iteration 198500, lr = 1.44115e-06
I0506 05:02:10.589582 12834 solver.cpp:362] Iteration 198500, Testing net (#0)
I0506 05:02:10.589596 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:10.718178 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7875
I0506 05:02:10.718207 12834 solver.cpp:429]     Test net output #1: loss = 0.487184 (* 1 = 0.487184 loss)
I0506 05:02:10.720775 12834 solver.cpp:242] Iteration 198500 (84.1435 iter/s, 1.18845s/100 iter), loss = 0.42547
I0506 05:02:10.720798 12834 solver.cpp:261]     Train net output #0: loss = 0.42547 (* 1 = 0.42547 loss)
I0506 05:02:10.720808 12834 sgd_solver.cpp:106] Iteration 198500, lr = 1.44115e-06
I0506 05:02:11.653645 12834 solver.cpp:242] Iteration 198600 (93.8214 iter/s, 1.06586s/100 iter), loss = 1.55957
I0506 05:02:11.653697 12834 solver.cpp:261]     Train net output #0: loss = 1.55957 (* 1 = 1.55957 loss)
I0506 05:02:11.653713 12834 sgd_solver.cpp:106] Iteration 198600, lr = 1.44115e-06
I0506 05:02:11.658463 12834 solver.cpp:242] Iteration 198600 (106.65 iter/s, 0.937645s/100 iter), loss = 0.459394
I0506 05:02:11.658490 12834 solver.cpp:261]     Train net output #0: loss = 0.459394 (* 1 = 0.459394 loss)
I0506 05:02:11.658500 12834 sgd_solver.cpp:106] Iteration 198600, lr = 1.44115e-06
I0506 05:02:12.590909 12834 solver.cpp:242] Iteration 198700 (106.702 iter/s, 0.937187s/100 iter), loss = 3.12456
I0506 05:02:12.590948 12834 solver.cpp:261]     Train net output #0: loss = 3.12456 (* 1 = 3.12456 loss)
I0506 05:02:12.590958 12834 sgd_solver.cpp:106] Iteration 198700, lr = 1.44115e-06
I0506 05:02:12.595675 12834 solver.cpp:242] Iteration 198700 (106.705 iter/s, 0.937167s/100 iter), loss = 0.40532
I0506 05:02:12.595701 12834 solver.cpp:261]     Train net output #0: loss = 0.40532 (* 1 = 0.40532 loss)
I0506 05:02:12.595710 12834 sgd_solver.cpp:106] Iteration 198700, lr = 1.44115e-06
I0506 05:02:13.528591 12834 solver.cpp:242] Iteration 198800 (106.654 iter/s, 0.937611s/100 iter), loss = 0.728416
I0506 05:02:13.528630 12834 solver.cpp:261]     Train net output #0: loss = 0.728416 (* 1 = 0.728416 loss)
I0506 05:02:13.528640 12834 sgd_solver.cpp:106] Iteration 198800, lr = 1.44115e-06
I0506 05:02:13.533360 12834 solver.cpp:242] Iteration 198800 (106.651 iter/s, 0.937641s/100 iter), loss = 0.408034
I0506 05:02:13.533385 12834 solver.cpp:261]     Train net output #0: loss = 0.408034 (* 1 = 0.408034 loss)
I0506 05:02:13.533394 12834 sgd_solver.cpp:106] Iteration 198800, lr = 1.44115e-06
I0506 05:02:14.465843 12834 solver.cpp:242] Iteration 198900 (106.702 iter/s, 0.937191s/100 iter), loss = 0.685114
I0506 05:02:14.465876 12834 solver.cpp:261]     Train net output #0: loss = 0.685114 (* 1 = 0.685114 loss)
I0506 05:02:14.465886 12834 sgd_solver.cpp:106] Iteration 198900, lr = 1.44115e-06
I0506 05:02:14.470610 12834 solver.cpp:242] Iteration 198900 (106.7 iter/s, 0.937208s/100 iter), loss = 0.497805
I0506 05:02:14.470634 12834 solver.cpp:261]     Train net output #0: loss = 0.497805 (* 1 = 0.497805 loss)
I0506 05:02:14.470643 12834 sgd_solver.cpp:106] Iteration 198900, lr = 1.44115e-06
I0506 05:02:15.401036 12834 solver.cpp:362] Iteration 199000, Testing net (#0)
I0506 05:02:15.401056 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:15.523703 12834 solver.cpp:429]     Test net output #0: loss = 1.26164 (* 1 = 1.26164 loss)
I0506 05:02:15.526218 12834 solver.cpp:242] Iteration 199000 (94.3108 iter/s, 1.06032s/100 iter), loss = 1.07154
I0506 05:02:15.526238 12834 solver.cpp:261]     Train net output #0: loss = 1.07154 (* 1 = 1.07154 loss)
I0506 05:02:15.526247 12834 sgd_solver.cpp:106] Iteration 199000, lr = 1.44115e-06
I0506 05:02:15.528074 12834 solver.cpp:362] Iteration 199000, Testing net (#0)
I0506 05:02:15.528087 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:15.656767 12834 solver.cpp:429]     Test net output #0: accuracy = 0.7895
I0506 05:02:15.656788 12834 solver.cpp:429]     Test net output #1: loss = 0.487126 (* 1 = 0.487126 loss)
I0506 05:02:15.659334 12834 solver.cpp:242] Iteration 199000 (84.1269 iter/s, 1.18868s/100 iter), loss = 0.427928
I0506 05:02:15.659354 12834 solver.cpp:261]     Train net output #0: loss = 0.427928 (* 1 = 0.427928 loss)
I0506 05:02:15.659363 12834 sgd_solver.cpp:106] Iteration 199000, lr = 1.44115e-06
I0506 05:02:16.592188 12834 solver.cpp:242] Iteration 199100 (93.8154 iter/s, 1.06592s/100 iter), loss = 2.22304
I0506 05:02:16.592236 12834 solver.cpp:261]     Train net output #0: loss = 2.22304 (* 1 = 2.22304 loss)
I0506 05:02:16.592245 12834 sgd_solver.cpp:106] Iteration 199100, lr = 1.44115e-06
I0506 05:02:16.597031 12834 solver.cpp:242] Iteration 199100 (106.65 iter/s, 0.937647s/100 iter), loss = 0.870242
I0506 05:02:16.597057 12834 solver.cpp:261]     Train net output #0: loss = 0.870242 (* 1 = 0.870242 loss)
I0506 05:02:16.597066 12834 sgd_solver.cpp:106] Iteration 199100, lr = 1.44115e-06
I0506 05:02:17.530053 12834 solver.cpp:242] Iteration 199200 (106.633 iter/s, 0.937793s/100 iter), loss = 0.356663
I0506 05:02:17.530088 12834 solver.cpp:261]     Train net output #0: loss = 0.356663 (* 1 = 0.356663 loss)
I0506 05:02:17.530098 12834 sgd_solver.cpp:106] Iteration 199200, lr = 1.44115e-06
I0506 05:02:17.534839 12834 solver.cpp:242] Iteration 199200 (106.637 iter/s, 0.937765s/100 iter), loss = 0.223392
I0506 05:02:17.534863 12834 solver.cpp:261]     Train net output #0: loss = 0.223392 (* 1 = 0.223392 loss)
I0506 05:02:17.534873 12834 sgd_solver.cpp:106] Iteration 199200, lr = 1.44115e-06
I0506 05:02:18.468003 12834 solver.cpp:242] Iteration 199300 (106.623 iter/s, 0.937884s/100 iter), loss = 1.22617
I0506 05:02:18.468036 12834 solver.cpp:261]     Train net output #0: loss = 1.22617 (* 1 = 1.22617 loss)
I0506 05:02:18.468045 12834 sgd_solver.cpp:106] Iteration 199300, lr = 1.44115e-06
I0506 05:02:18.472781 12834 solver.cpp:242] Iteration 199300 (106.621 iter/s, 0.937899s/100 iter), loss = 0.247145
I0506 05:02:18.472805 12834 solver.cpp:261]     Train net output #0: loss = 0.247145 (* 1 = 0.247145 loss)
I0506 05:02:18.472815 12834 sgd_solver.cpp:106] Iteration 199300, lr = 1.44115e-06
I0506 05:02:19.406463 12834 solver.cpp:242] Iteration 199400 (106.564 iter/s, 0.938401s/100 iter), loss = 1.37665
I0506 05:02:19.406503 12834 solver.cpp:261]     Train net output #0: loss = 1.37665 (* 1 = 1.37665 loss)
I0506 05:02:19.406513 12834 sgd_solver.cpp:106] Iteration 199400, lr = 1.44115e-06
I0506 05:02:19.411253 12834 solver.cpp:242] Iteration 199400 (106.561 iter/s, 0.938429s/100 iter), loss = 0.577946
I0506 05:02:19.411278 12834 solver.cpp:261]     Train net output #0: loss = 0.577946 (* 1 = 0.577946 loss)
I0506 05:02:19.411288 12834 sgd_solver.cpp:106] Iteration 199400, lr = 1.44115e-06
I0506 05:02:20.341121 12834 solver.cpp:362] Iteration 199500, Testing net (#0)
I0506 05:02:20.341148 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:20.463827 12834 solver.cpp:429]     Test net output #0: loss = 1.2644 (* 1 = 1.2644 loss)
I0506 05:02:20.466347 12834 solver.cpp:242] Iteration 199500 (94.3552 iter/s, 1.05982s/100 iter), loss = 2.66187
I0506 05:02:20.466368 12834 solver.cpp:261]     Train net output #0: loss = 2.66187 (* 1 = 2.66187 loss)
I0506 05:02:20.466377 12834 sgd_solver.cpp:106] Iteration 199500, lr = 1.44115e-06
I0506 05:02:20.468197 12834 solver.cpp:362] Iteration 199500, Testing net (#0)
I0506 05:02:20.468209 12834 net.cpp:723] Ignoring source layer parameters
I0506 05:02:20.597268 12834 solver.cpp:429]     Test net output #0: accuracy = 0.779
I0506 05:02:20.597290 12834 solver.cpp:429]     Test net output #1: loss = 0.503397 (* 1 = 0.503397 loss)
I0506 05:02:20.599835 12834 solver.cpp:242] Iteration 199500 (84.137 iter/s, 1.18854s/100 iter), loss = 0.772922
I0506 05:02:20.599855 12834 solver.cpp:261]     Train net output #0: loss = 0.772922 (* 1 = 0.772922 loss)
I0506 05:02:20.599864 12834 sgd_solver.cpp:106] Iteration 199500, lr = 1.44115e-06
I0506 05:02:21.533803 12834 solver.cpp:242] Iteration 199600 (93.685 iter/s, 1.06741s/100 iter), loss = 0.505899
I0506 05:02:21.533845 12834 solver.cpp:261]     Train net output #0: loss = 0.505899 (* 1 = 0.505899 loss)
I0506 05:02:21.533854 12834 sgd_solver.cpp:106] Iteration 199600, lr = 1.44115e-06
I0506 05:02:21.538590 12834 solver.cpp:242] Iteration 199600 (106.528 iter/s, 0.938716s/100 iter), loss = 0.517058
I0506 05:02:21.538617 12834 solver.cpp:261]     Train net output #0: loss = 0.517058 (* 1 = 0.517058 loss)
I0506 05:02:21.538636 12834 sgd_solver.cpp:106] Iteration 199600, lr = 1.44115e-06
I0506 05:02:22.471518 12834 solver.cpp:242] Iteration 199700 (106.651 iter/s, 0.937642s/100 iter), loss = 0.677775
I0506 05:02:22.471573 12834 solver.cpp:261]     Train net output #0: loss = 0.677775 (* 1 = 0.677775 loss)
I0506 05:02:22.471585 12834 sgd_solver.cpp:106] Iteration 199700, lr = 1.44115e-06
I0506 05:02:22.476343 12834 solver.cpp:242] Iteration 199700 (106.643 iter/s, 0.937709s/100 iter), loss = 0.487074
I0506 05:02:22.476368 12834 solver.cpp:261]     Train net output #0: loss = 0.487074 (* 1 = 0.487074 loss)
I0506 05:02:22.476377 12834 sgd_solver.cpp:106] Iteration 199700, lr = 1.44115e-06
I0506 05:02:23.409040 12834 solver.cpp:242] Iteration 199800 (106.673 iter/s, 0.937442s/100 iter), loss = 1.35677
I0506 05:02:23.409092 12834 solver.cpp:261]     Train net output #0: loss = 1.35677 (* 1 = 1.35677 loss)
I0506 05:02:23.409102 12834 sgd_solver.cpp:106] Iteration 199800, lr = 1.44115e-06
I0506 05:02:23.413823 12834 solver.cpp:242] Iteration 199800 (106.674 iter/s, 0.937437s/100 iter), loss = 0.427568
I0506 05:02:23.413848 12834 solver.cpp:261]     Train net output #0: loss = 0.427568 (* 1 = 0.427568 loss)
I0506 05:02:23.413858 12834 sgd_solver.cpp:106] Iteration 199800, lr = 1.44115e-06
I0506 05:02:24.347013 12834 solver.cpp:242] Iteration 199900 (106.622 iter/s, 0.937891s/100 iter), loss = 6.38428
I0506 05:02:24.347050 12834 solver.cpp:261]     Train net output #0: loss = 6.38428 (* 1 = 6.38428 loss)
I0506 05:02:24.347060 12834 sgd_solver.cpp:106] Iteration 199900, lr = 1.44115e-06
I0506 05:02:24.351825 12834 solver.cpp:242] Iteration 199900 (106.614 iter/s, 0.937959s/100 iter), loss = 0.668684
I0506 05:02:24.351851 12834 solver.cpp:261]     Train net output #0: loss = 0.668684 (* 1 = 0.668684 loss)
I0506 05:02:24.351861 12834 sgd_solver.cpp:106] Iteration 199900, lr = 1.44115e-06
I0506 05:02:25.275496 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_200000.caffemodel
I0506 05:02:25.292455 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/parameter/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_200000.solverstate
I0506 05:02:25.305840 12834 solver.cpp:479] Snapshotting to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_200000.caffemodel
I0506 05:02:25.323047 12834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/purduethu/scratch/radon/d/deng106/CNNStatisticalModel/distributions/models/joint/distribution/50_dis_100_dim/huber_10_conv_k5_p2_64_64_max_128_128_128_fc_1024_512_share_layer_test_share_first_4_50_100_joint_1000_gpu1/_iter_200000.solverstate
